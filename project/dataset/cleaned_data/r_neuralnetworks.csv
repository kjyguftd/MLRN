cleaned_text,label,username_encoded
scihub duuh,r/neuralnetworks,Z0FBQUFBQm0yeGJTcGVpVkk3MkhhZlJXTTY3d09tNWpaRThabHY0bjVEWWp4b1ZPcnpHaUt6MmlvTk1lSm5RbVNxdnE1Rk94NE9lSk9JSTV2b1ZEeXZ6eFZVY05sb3pObHRHM1FmWmY4YVJPV3V2SkNUS3k3ZXM9
not there duuh,r/neuralnetworks,Z0FBQUFBQm0yeGJTbThxSk9TbVZyNlJkZGdUTHROWU9Sc2pHVTM0TlROZEN0aHhqWWhJaWdVQnVFVHhKUkQ2OGRQaWlKZXVRejZrNDlFWnFxTGZCTks0Tm9HdVF3Mm9qcXc9PQ==
,r/neuralnetworks,Z0FBQUFBQm0yeGJTa1J2UmV6X3Jud0hQbXZCTTJkVmVVTmJtRlk5VUR4YlpCU1hKWXdLR0pRWF85cS00aDJIaGtDaHJiVDlaanpJODdVa0UteFpMRktQY3E1SFN6Znprb3VnWjZTdHBtVWdId2ZMUEFXdDBnOXc9
accuracy can be very deceiving if your dataset is imbalanced imagine if you have a validation set are you splitting training and validation that has <number> samples of class <number> and <number> of class <number> a model that just calls everything class <number> would get <number> accuracy how is the f score then about it seemingly depending on the initialization well initializing the weights is one thing that you could look into also maybe a lower learning rate to make sure its not overshooting,r/neuralnetworks,Z0FBQUFBQm0yeGJTMmt5SGpjU3VvdC1EOU9vR25vd1BxYjFvNlpHcDFEelJhem9pZ2RpMTRqa0h0TU9hc1M4azVPeU5DSE1fUFkyWTljc29PTmRjUkc5NnhKX2dURGRXbkE9PQ==
thanks for the response the dataset consists of ~<number> rows of <number> phishing and <number> legitimate urls which is what im ultimately predicting for im randomly setting aside <number> of it to use as the test case after training so generally i should be getting a roughly <number><number> split of phishinglegit in my test set it may be helpful to note that after training which doesnt take long the network is either pretty solid or totally useless im never seeing it hit anything but <number>useless or <number>solid accuracy its solid probably <number> of iterations im going to do some digging into f score because im not familiar with it newb here,r/neuralnetworks,Z0FBQUFBQm0yeGJTUWJDM2JydnRXVVlPNGZiZFEzeHJFYzZWQ0FtVVc3M2FtRk1tQlVKSFhWZFY1SWVTZFpWNEx0Wk1zSXNQN2k4eEZBRExZS0dzbFJHR1g2UGVhem16eUE9PQ==
id be curious if decision trees do better here this seems like a bad optimization though maybe reduce your model size or try a different optimizer,r/neuralnetworks,Z0FBQUFBQm0yeGJTLVVVMDBPdk8wdFhIV3dENkJIZ1BJRWFqVFA2ck8xY2VGUEJRdWJXSG9TOW5KTzF0MjNpVXdCLVZ5UkF5ejBiYVJ2N3B4RkUzSGVBcEEyWXY2d3g3WkE9PQ==
you dont need a cnn you can extract the text of the uploaded answer sheet using a ocr optical character recognition library the prominent one in open source is tesseract post that once you have the text you can pass it in any model that can evaluate the answers,r/neuralnetworks,Z0FBQUFBQm0yeGJTd1pWU3R5WHNTQjJ2WFYxVjdoa0M4bHRwQmhUbDB5ZjhFb2RvdnRTVVFtU21Ub2xoQWdfYURJbTRmN0tmNlUyWlNiZVFPVmZzQjdTeHJZbTRGZjljdXc9PQ==
you should be asking this in rmachinelearning that subreddit is way more active and your question seems more focused on ml in general rather than specifically neural networks,r/neuralnetworks,Z0FBQUFBQm0yeGJTTDA3cFV3TVdoVmdwejc5QXdwS2NPRktWQm5wRXNudEhNV05SZEtubUlrMDlqOEh3MmNHY3lCNkZlc0xKdlNlOFNWWW5kNjZCcTNPZnJDNmlDOUdBZmc9PQ==
and which model is the best for best prediction,r/neuralnetworks,Z0FBQUFBQm0yeGJTV1VnMjZmZmQtRHhSOG1VUWtLZlZPdEVESTZ0TXkyRjA3Nk9uRjdfb0xMMnhNUmpjR2I0dU5Hb3M5c2Y1c2ViRTNmN3AzempkeDNuajB3Xy03WXZ3Rk5iQllfZnNMNEtlbUFxT2VPNFhRRlk9
hi bro im also working on the same project can u help me by providing base paper and other informations,r/neuralnetworks,Z0FBQUFBQm0yeGJTNnJUUExmSm1UQUtPRGd6RlNTN0laU2pJY0VRTVdVZ2UyTnJrVnZrN1cwU29kNkxNZ3dTZ3V2Z01ia1VoY3Y3eld5WFBTemRZbjZBV0dtcVR1eWFqNFE9PQ==
softmax is a regular activation function sometimes they use it as layers also but it works the same basically softmax is used when the number of output class is more than <number> it gives the probability for each class and its summation of probabilities is equal to <number> you have to choose the class of the output based on the maximum probability which class got you cant bring explainablity in deep learning basically activation function is used to squeeze the parameters and induce non linearity to the inputs if you are using binary class then you shouldnt use softmax activation function,r/neuralnetworks,Z0FBQUFBQm0yeGJTWG5IUHZjNlBrNW5lWVBOTEFMeGVpYlpKamVXXzJTYktFOTdvaE9JZlRBTzhNMGdERVNuWVYyTWxRMDZ5OG11LWZLaFR3TUhXS3JSTHJTXzRiNlhMQ0VGY1FSbjRTenRIM0xrZFhndjFOZFk9
is there any difference in the back propogation because ive been trying it on a digit recognizer but it just doesnt want to learn even tho i give it different images their outputs are pretty much the same give or take a few thousanths,r/neuralnetworks,Z0FBQUFBQm0yeGJTbzNrNnFULURwSW5pZjMzbzJwYmd6TGIxakVMamsxdkJZcmhRZlprbjNYRm9fRmw2MXBMLWk2VHBCdGtqck1ieWU1OUxOYTNRY01PVC1hMF9UUDI1eEE9PQ==
yes back propagation is a totally different concept activation function is used to introduce non linearity in the equation and to squeeze the parameters back propagation is used to reduce the cost functionit depends on which optimization algorithm and hyper parameters it depends on the neural networks you are using and which activation function and loss function ba ch size there are so many hyperparameters that can affect your neural network,r/neuralnetworks,Z0FBQUFBQm0yeGJTRlgtdnFnNFBXR1p3N3JmX194ZlFYUHhlZlg1YmR3bFYzcEs5QmZOV0RZS1RzX1AyZEhsODh2ZDdHdFhiVHdXVzBqNm53c1VoNzNGaEVFSmtzbGc0Zm5nMEN2WlV0YU1FZ0VFNmZuRW5CT2M9
i see the way i built my library was having an activation class so my back propogation is pretty static the only thing that changes is the activation functions themselves i did the same with the loss and it works same with the other activation functions its just the soft max that i cant seem to get to work rn i moved from minibatch to sgd as it showed better results in learning someone suggested that it might be floating point precision idk if that is the case though,r/neuralnetworks,Z0FBQUFBQm0yeGJTMkVYS1Z1OXJtbVR1QXA2eEFVOFpCYzFUSGJQVGR4MjIxODZieEtYQ3pueEg1QVFUbUswM2ROeHNxQm5acmxCcmQwSmpvdWtnUDBxLXgzQ2lQMWdEd2c9PQ==
how many classes of output are there,r/neuralnetworks,Z0FBQUFBQm0yeGJTSnpNWDJIRWkzVV9kUFJVb1RNYUNmQUJ1dGdCTTFjdEpienVLeXZoVl9WT1JhcHhCRGtLMEQybWZyRV9OeHd4N1JoNVFmYk1kNC0xUkVQRlRFdEwyTTc3bDZYRWRfYTF4WFVKam1FeUtpcTA9
i made it <number> for now the classes are the digits from <number><number>,r/neuralnetworks,Z0FBQUFBQm0yeGJTYU5NQnZDUTRRbnhlVmlDeE90N2w3OERrc0duaDZxQ2Mta1U4eUZkenZCTzRuX3JFV3FSUFNMQXpoTlBybFl0dkFMMTByUnJqcmJORjZ6WFp1Q0o3YVE9PQ==
do you have a code example nice graph,r/neuralnetworks,Z0FBQUFBQm0yeGJTTk0zQXdDZjlEVXNrNWEyTkVHcHVjTXZtT0NOTUVQTERpVFdvejFYMVFLMHRNZlRJX3RMQ2NyMkR6ZzhENlFyZXZJbXVidEM0TGlUQllLTGQ1Y2NTSGc9PQ==
i have one idea and an algorithm will we work together and implement that algorithm,r/neuralnetworks,Z0FBQUFBQm0yeGJTdlp3dnUxR211Y1ZsbE14ZjUzdVhWQVZfemxmMzdaM3R3aHBRbjF3QzNvcTM2UG92SVlNQzI4M3djWG1MbVpIRkx4bzhDdXprOERWcmlrTGNZVE1wRFlRZWVBd0p1TTU3S3daUWZpZ0d6V3M9
can you give me the code,r/neuralnetworks,Z0FBQUFBQm0yeGJTeUk5Q3NzQUhvTEpoLU1DQnEyNTVFV2sxSUNRR1ppMzFIcGY2SHYwMFpvUUN2R2JHS2VJWWdQWGNNYjgwOVNfam9tRzBaX1BHZGhGYThKaHJ2U2tmX1VwWTMyaTM3N2c3UEJNN3ZaZ29MeGc9
heres what chatgpt <number> says your code snippet defines a tensorflow model based on the resnet architecture and demonstrates how to use it for image classification with data augmentation however there are a few issues and improvements that could be made for clarity and functionality heres a refined version of your code with explanations for the key changes and improvements fixes and improvements correct init method definition python classes use init rather than init syntax and indentation fixes proper indentation and syntax are crucial for python class expansion attribute while your code implies an expansion factor of <number> in the bottleneck blocks as in resnet its good practice to explicitly define this as a class attribute for clarity and potential modifications data augmentation comment its worth noting that imagedatagenerator is quite basic for more complex projects you might explore tfdata or tensorflows preprocessing layers predict function adjustment your predict function includes model prediction but assumes the model is defined outside the function scope this could lead to issues in a standalone usage scenario so ive included a note about ensuring the model is accessible,r/neuralnetworks,Z0FBQUFBQm0yeGJTTG53aTc5VFBMdVFuLTZLaWxaSi1NdldyX2NLSmRBdDFoR3E5SFpVTHB5SWVWb2RWVmtBczB4T0Y0aktjbXVoV050d0JPdzE3ZFVxLU5aaVIxdE5vQ3c9PQ==
you wouldnt want it,r/neuralnetworks,Z0FBQUFBQm0yeGJTR1VsQU9TemFsMV85aTRTTWd6TTNCSW0wUzZIb01DS21WSGlsMm1uaGt1ZjM4dFhPTUR2dVdOMTUtWnNvV3gxZGU4TnNSWWFyekk2bFRMUi1idXk4emc9PQ==
found a github link in a thread from the other discussions tab <url> idk if this is a bot but op reposted something from <number> years ago,r/neuralnetworks,Z0FBQUFBQm0yeGJTU29rQ0cybDZhNDFtNERPNWo3UFNHLTlFcUYtUWxyVi1BMDYyNk9YNlNtZ1RYRFZZMlVWMG9pSUVNM3BhR1g0WjNpNWszbHRweVNwQVhyaGVjcVQyQmc9PQ==
much appreciated that sounds like a bot indeed,r/neuralnetworks,Z0FBQUFBQm0yeGJTVHptTEdCWk5oV2xKTlNUQ0dmN19DRzVZUUJTTmV1Mkl4NV82TkZ3cXVKdHZQZlpVQmMwVF96VW9mMnNtV2lwYS1Ha2k0T0RyeTFDcU5jcG1HelFCQ0E9PQ==
was just going to suggest asking it you can also ask it to describe it at lower levels explain it like im a beginning programmer if you want it to dumb it down a bit,r/neuralnetworks,Z0FBQUFBQm0yeGJTVTBGYVlfam5hVWEzN3VPRjNBSmNZQ0p2OEVQU1lTYWdEOEw3bmtKejc3ZVEzMHBfTVlzS3BfMlh6VHF3cGZMaElFT3NmR3U5QThWOXR3dnZmS3Jxd2c9PQ==
thank you,r/neuralnetworks,Z0FBQUFBQm0yeGJTem1paEtTS2Qwd09VbTJvSUtTajJKVjlxTmpFcmV4SlpOVzZQUzNFMUc5akRtYllHb0NnalhWc2lDVVJ0bHZiR2tXRnV2R0VJcnQxUm8xMFpzbUtmcU5OVUc0bUpvOUFYT1IwM1Z0RXFNeVk9
for something basic create a image pattern recognition tool using cnns or train a model on a dataset of images and then have it predict the next image category in the pattern ie dog cat helicopter etc,r/neuralnetworks,Z0FBQUFBQm0yeGJTeUNKUUpHZU9jUVk5ZnF3Nlp5MXFEalVqNkxxbThqZHFWMFJldEpNVFNKRVhpTE1pWi1xR0FnT2xlbnBKYVRpNjlHVEJ0RWpnaHo2djE3UWIzN2Vka0E9PQ==
remindme <number> days,r/neuralnetworks,Z0FBQUFBQm0yeGJTZTRCRWF2VW9rZXZKQkFtNjJGQ0FqaGY0bjNSdWYtZ1g2b0FIcDNPam93UF9uNXpLR2piOVN1Qm10SG9ZSlhTcTdjYUJCdFV0cy1YellYdE10S3hDQUVBZFNIYjVDbGRLMnRoVmgyUkdjVk09
i will be messaging you in <number> days on <number><number><number> <number><number><number> utc<url> to remind you of this link<url> click this link<url> to send a pm to also be reminded and to reduce spam ^parent commenter can ^delete this message to hide from others<url> |^info<url>|^custom<url>|^your reminders<url>|^feedback<url>| |||||,r/neuralnetworks,Z0FBQUFBQm0yeGJTNGx3RVlBUEx0a0pCYTNoU1dpczlwTjR1cUMxSjc4YXVoVjlMaGdpVmVhN2l0TzNaVFdUZzduTU80TTVJQUlGX3pWMFh5WXpPVTAycnN4MVZoUXB5S0E9PQ==
why do you want to use a cnn i understand the appeal and the learning perspective plus with images the agent will only have access to limited information but this is going to be computationally expensive the model will try to infer the game state based on the screenshot eg enemies positions but you already know that as the developer and could give that directly to the model two possibilities you either give the model handcrafted features and dont use cnns at all easier and faster training faster inference or you go through the cnn option that said lets discuss the cnn approach id give the model a very very small screenshots smaller than px in width at least x if that works would be really nice to start remove all the shaders anything expensive no textures unless important and lighting if you reduce the resolution it may be difficult to distinguish objects from background so id colorcode everything eg ground=shades of blue depending on height enemies=red allies=green objects=purple sky=white walls=shades of pink depending on normal etc id give the ui information directly to the model health currently equipped weapon bullets available etc your model has no memory over time but i am not sure if you have enough data to train a sequencetosequence model id use halfprecision during training and prune the model after training to improve the inference time reinforcement learning after training would really improve the model but thats another level of difficulty implementationwise,r/neuralnetworks,Z0FBQUFBQm0yeGJTWTE4VGxGZ3ZUcTl0YUJWQW1LLWVJeTRoYmthN0VraXl1YlBvQko4U2JZV3NTb1M3aGRxdWlFbWFPTzBycjVrTG1fQzc5czI2NXhQUXR1b3VBSnpSaXc9PQ==
you have to modify the activation function so that it allows that range for example the sigmoid goes from <number><number> just ask chat gpt to scale it appropiately,r/neuralnetworks,Z0FBQUFBQm0yeGJTcUtOMTN6X2hBZE5lQlptNTlWQUZaLURZbjlCb3NMR0xKaUlrRDIzS3l4c0tlVE9rd3FsclhIT1pLX2hxUEJSd0hLVHNXLWQwTTgwc2hkZkdCeTUyUWM5ZWZyTXFWWW9zdDdremNWZURGV0k9
got the book a while back decent read and helps somewhat it seems thou that the author is not really that active so its near impossible to get help if you are stuck the code in the book is repeated way too much almost like they are trying to pad the pages with that being said still in the top half of recommendations just not that near to the top the youtube videos are excellent,r/neuralnetworks,Z0FBQUFBQm0yeGJTemIzNkFrTGZlcTB0WmxHeENoUEozMTJlWWtONGpNdUJDY1o3ZzdFZ1FnV2hGR1psdG43c0dYLVRWbld2U1dXVGJaVDNxSjNzY1JXWlM2TWU2cFBrYUE9PQ==
thank you for taking the time to respond yes i know its possible to feed enemy pos directly to the model but i dont want this to access any game memory at all i dont know much about game hacking anyway and am interested in the creative challenge i ended up getting it to work relatively okay it doesnt bump into walls ever but its not going pro anytime soon i used a cnn and was taking a x picture of the minimap with a filter to find edges saved the data about what keys i pressed during that screenshot and separated the screenshots into folders that corresponded with that keybind i like this solution because i can influence the training easily to have it play a certain way things like staying on headglitch spots jiggle peaking jump peaking etc are automatically learned using this method i am starting to worry about its ability to process info fast enough the movement model is plenty fast but i still need to work on the target identification and aiming my current solution was to have the movementincluding simple mouse movements for direction change and targetidaiming models run on separate threads since they dont really need to communicate anything the bot just needs to farm deathmatch kills not understand anything else in the world like health ammo objective etc although i might pass it the ammo count so it can become defensive once it recognizes it should reload soon does that seem like an okay solution only have like <number> days of nn experience lol so im sure its not optimal but i cant think of any reason it wont be good enough thanks ,r/neuralnetworks,Z0FBQUFBQm0yeGJTWmNtQ2lMSU5jblVpWnZhVkVTdWo4UXZWSi05VjZFcVlaUFBXZzVaQjRhTlhBSkZMeHBYaEtyanRYVk1NaDdCZ0liemhuMDU0NG9TN2tWeDI3WU5qQ0E9PQ==
yes i think its a good start again i am a bit worried about the memorylessness of the model it could start spinning forever hoping for an enemy to appear on the right handside for instance forgetting it has already looked there <number> times but other than that go ahead,r/neuralnetworks,Z0FBQUFBQm0yeGJTT2I1NEZ6SFpQM1FBQU1tQWdpUVhtTEpnUmY5bFhYMk1WcEFoU2IydGJLR0NVZ0E1WF9sVWduU3JYMGZZUExmUlZZT1VpMUI4MzBkOGk0Wm9ySUhSeGc9PQ==
found <number> relevant code implementations<url> for path planning using neural a search ask the authors a question<url> about the paper or code if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJTWUVKOFVrTEhXT0E4VkRMS0VUQ1k1U3UwOHkxSnZ6Um5HN2RGUHV3NElOTElFT3BaYkFkdnVHUHFEdE55S0llaWtBaTVkSXFIVkw4bDBZdm9WWFRrSnpzY1otYWpMLXNQYzZGb0ZabFdnSjQ9
if a weight is <number> it wont be changed during training,r/neuralnetworks,Z0FBQUFBQm0yeGJTZHk4akIxUzlBNE1XTzJyY2o0MUZialctTHVqUkFmVC1TaEJpb0NHMUFUeDEzRVpsT200SmY5SVhCM1pLVDl1a3pZZnpMYi1OSlRFVEdvRkg1RTJ2QmNMazhwaGhWZDRLU0NBZ0dCQVpxOG89
im not an expert in neural nets but wouldnt you have to do that potentially hundreds of thousands or even millions of times to adequately train a neural net,r/neuralnetworks,Z0FBQUFBQm0yeGJTbUhmM2JhaG14YmJPcXFwbThncS1rWER2WGZBRm5sWEhVYWRCV1cwUEFYSnV2M0lNblFjNVBkWDRSVGtIZFh3bU1jUzRFdWZrWFJQWmhLX1BLc0RiZ3N5WGJrRktld0hhYWJGT01zS1hVVFk9
thats what i thought but perhaps there are other methods,r/neuralnetworks,Z0FBQUFBQm0yeGJTeUZxTXA5eDJUc0pkbW1RWm9Rc0M2U3gwQ2dBTXRwN1JYX09OVnJjdkY4NVV0el9vd3BvZmIwQnZ0RWZVaW5KWU9MTkRPMFA4YnBMZTVuUzNpRjNEVEVTU296OGotNzdzbElodDJBVE9vN3c9
i think you should read about reinforcement learning you can use it for this case,r/neuralnetworks,Z0FBQUFBQm0yeGJTX3NYbUthVHpsSjJiMEJPblEzWFV5eVZlcXNQQmVNeWhTbTFXeTNWTnhqRndkZTk2NnFTX2NkcTZDYTFLMzZwR2JEdkVOREkxTjg0X2duMkF3eXRtWnc9PQ==
yes you are not going to want to train it each time there is a new rating rather train via transfer learning after you gather enough new data for training runs you can also build another model that grades the game models attempts for you and could potentially use scripts or a third model to automate running the training once certain conditions are met i dont know how much training data you need because i dont know the game but there are many other game models that learn by various do or diffusion techniques etc i would recommend reading papers or howtos on those game models and look up things you dont understand worry more about the theories and methods that can be applied than understanding every bit of math unless you have to understand it to translate game rules into logical expressions try to find lit that is similar to your game rules if none for your game exist to fork from,r/neuralnetworks,Z0FBQUFBQm0yeGJTZ1F6Y0c0MEVHc1ItRXQ0MzBlRzVtdTdGWVRXSmU2S0VCWE5iUEh2NGZrc1J6VFotdFZXdEFnRGVHMzAyUlRPWXJOb1lkcDF4X1lmTlRhS054bFFVNWc9PQ==
your rating can be whether it hit a target no if you have the game physics for bullet bouncing can you put an item on the ground in a random spot and train a bot on its own to hit the target also maybe you can create a sight line that extends out from the bots gun ricochets as per the game physics and has this info about what its bullet would hit added to whatever vision info it is already being given in order to function i have never done anything like this before but i feel like that would make the training to faster,r/neuralnetworks,Z0FBQUFBQm0yeGJTMWQ0QmlUMnQ0aUxUeC1vSmMzdDJjY2VDeXJzRHhvREVzMVpTQ1dMaFIwQW5CLUxsallDdnhjNmFpc09CcFlfTndXR0QzYWc5NFdtSjJzelB2YUtIMXc9PQ==
i dont know my fantasy is that ais will eventually be trained radially meaning that instead of backpropagation there will be radial propagation this would give a frontier of responses that ripple outward like a wave then logic gates wait to observe the right answer and select that thread and let the others just die off it just seems wrong that were training in such a linear direction with inputs folowing a path to an endpoint,r/neuralnetworks,Z0FBQUFBQm0yeGJTRjZqLUkxWFhMR3FSMlZIOUZId1RtUk45YU9RVmVLWFByY3R0SEstYnlPeE9nZkNRZ0N0NnNZWTFyMVkzdGMwbHdfUGctR2NTNnJ2dFZRbmJlZ2xfbXc9PQ==
this is the basis for how neural networks are generally trained,r/neuralnetworks,Z0FBQUFBQm0yeGJTMm0xOHpRdEhXQVNUdHN5V19xNFl1YVk1Z21kdGxCenU5dFNXUEdaNnBvLW1YeHRaNkV4ZXRDeUUxR19WRDJkRE1nam8zUUJJV1FVY25pYmdrZHNJOVE9PQ==
its probably true that there arent any simple hacks to beat a good chess engine but thatll be more to do with the fact that there are fewer degrees of freedom in a given chess move less space on the board to do such funny tricks and the average game lasts about a quarter of the number of moves of the average game of go fewer degrees of freedom and less space mean that you have fewer options to make weird moves that dont also immediately cripple your position and the shorter game time means that your strategy would have to work faster all these combined mean that alphazeros evaluation model almost certainly has higher likelihood of being accurate than alphagos besides that im fairly certain alphagos dataset was largely from its own games against itself no,r/neuralnetworks,Z0FBQUFBQm0yeGJTSmF5azY0Q0VTU3ltMEViTjlBajI4SUhmUng5ZVhsSnpuNzVPLTJrZDZMdnJNZFp3bmlCdlRfY1JtMFVlaUhoTTY4Tms5OXllZlN0WHNuN0NxQzhVN0g4eEQ2V1FrODE5VVRzWGdBb0ZkR2s9
my understanding is that alphago was trained on humanexpert games and fine tuned using selfplay where as alphazero was trained entirely on selfplay,r/neuralnetworks,Z0FBQUFBQm0yeGJTZlpYd0o0VFJLMkVpZVVual9MVGRmSVMzYnlIUVlKUXgtQWloam4zcGEyMl9uYXdkcGpmZ1o3RVlyT2xvRFFUaVhmaXota2RrQnNubGt3NzJ6NHpUX2c9PQ==
naturally i dont know precisely what their training strategy was but they most likely trained it on human games at first to guide the parameters in the right direction otherwise they would have to waste a huge amount of time waiting for the model to start playing sensible moves in chess its a lot easier to set up the model to start playing somewhat sensible moves immediately so theres no real need to train it on human games at first its unlikely that the humansourced portion of alphagos dataset would be responsible for a blind spot like that such an exploit is just part and parcel with such a complex model playing such a complex game,r/neuralnetworks,Z0FBQUFBQm0yeGJTdnpoVnp5eTBzRVdEQTc1c1dCd0duQmV6dDdSOHd1RW5ZUDFTZDhOMGFmOUNDVnMyc2VONlEtbVprSTk5QjcxWldBeUpJOW1HY0FpUmJkTUxwOEtlMVBENDdkaWNXWFcyeDNiZUdUZmNNVzQ9
ive never used prebuilt one but see if you can split population into separate species which protects multiple types of mutated genomes to survive simultaneously and add some crossspecies breeding its definitely far easier to find the right solution if a arbitrary local best doesnt drive all other mutations extinct hence why neat paper introduced concept of species,r/neuralnetworks,Z0FBQUFBQm0yeGJTY2VqSWh1T09QalRfZDRYN29PbkpTRDBsTWtPS213Q2dLTkpKWFplVXYtYjQ3NWNBOGpGSU5vMjcwVm5sX0lMZlQ4UnVDTFlmcEZZa2lFU2NpRlRGVlE9PQ==
chatgpt is not conscious >nonelinearity is strongly related to the emergence of consciousness can you qualify this statement is this a guess or do you have a source for such a bold suggestion,r/neuralnetworks,Z0FBQUFBQm0yeGJTR3JpVTdMQV9JVndzUTRGcExSRjFZanViUW1Jc09NTzMzRFExMFhPbWVvdmRzUGRzYWJKemM4NzdGRG5PdG5kT0xzR3hnMC03NjhQUDExUGNoclpDMG5aMXZuUnNpTGl6cnRCRmg1Znp6N3M9
isnt chat gpt hardcoded by the programmers to intentionally circumvent any sensitive topicsquestions how do you know it isnt conscious can someone ask this question to grok,r/neuralnetworks,Z0FBQUFBQm0yeGJTWnI5OXFHUHN5cl80UlBrOGQzMmY1RXZMQWZya01pSWJVemZXVjh5WElLQlZSaHU3NGdwcDV6aGRtTC1Ca1JFRGhJQVhzOG8xandlQ0JHSU51ZEx0amgtWFE2Nk9QV3VqRUh5aGtfZFE3WW89
>how do you know it isnt conscious the burden of proof is always on the positive not the negative we dont need to prove it is not conscious the proof needs to be that it is conscious if thats the thesis thats how the scientific method works,r/neuralnetworks,Z0FBQUFBQm0yeGJTZVJ0NW5fd3FtMmctNUpPS25OSEMtb2N2c0VmWWI1R3pLd00tUjBKNE90MUltQ1plZldSSHlSYS1TNFRyZ095d2kxbERISTh0WGhqYmxpd3JucDYyVC1SVEk0S0I2cnV6SVBZbk5NVkwxdFU9
you were so sure that you stated as a fact so the burden goes to you at least i would like to get your insight,r/neuralnetworks,Z0FBQUFBQm0yeGJTbi1MOUtyakplQ0tRWTZRMzc3OFIydlptNGsxYlhxaUNOV2xsMHpLV0FqU0FkWTF4M1VRNi1kb1IxY0pjZ3FkZDZoMTZTQ0s3clZQZ00yNThvUmxjNm54aDZJVG1FSjZFcE5iWVFHdktlN2s9
ive always thought consciousness is a byproduct of intelligence the more intelligent leads to more consciousness and i do think nonlinearity is important cuz if you dont then at the end its just a linear function no matter how many layers you have nothing emerges another observation is how biased we are in this topic i believe that every living creature has a superiority complex resulting in the creature choosing themselves over other things and this is necessary for survivalevolution so we are really biased to thinking we are special as a living creature and individual it surprises me that we humans have been calling ourselves conscious for the beginning we had the idea but we have yet to define it we are very protective of that concept its either cuz it really is a very unique phenomenon or its just that its boring but we are too biased to face it,r/neuralnetworks,Z0FBQUFBQm0yeGJTWldiTHRGU0FpeHZ4eGV5S0xjYllwY2NPVGlqbllKM2hHRXZuTkZVV25RQ01rUEdFMHd0QVNra05RZFZUd3c2SFFBNkZBdWVfRWQ3bTFxeE9INURESnc9PQ==
no thats like saying not having <number> legs is causing consciousness in humans nonlinearity is probably necessary but it is not sufficient multilayer perceptrons are nonlinear but i dont know anyone who would claim they are conscious,r/neuralnetworks,Z0FBQUFBQm0yeGJTRjluRVB3MGlMWmxHY0U0UE13bjktR3NNSk1qVjRWTjBfbzFUWHRveHF1OG0yUUI2VWtOLWMtSFZGNzJ6UW1Fd1lqZUdhT0gxd2hROFVULXVTUXU0LWc9PQ==
oneshot fewshot learning,r/neuralnetworks,Z0FBQUFBQm0yeGJTcWhlTTJvaWo4MDBqMTRyaFFMb0dlVjZFZDQwTnZGc0c5LUVHRzVJdlJ6bVpiMXk4M0hDTWdfbGZnbGVTM0lBSHNzbFlDblg0aVVKSFlNOHhWaDhmNFE9PQ==
does this thing really go and correct the most trivial errors how painful lmao,r/neuralnetworks,Z0FBQUFBQm0yeGJTOUlmbjZkbUljWWQtUXBtUzNfRnBHdzRRazBFMGNZUXZIWGhqd0xEVU1xbkNXM2pWa3BndEpfa21NY0xnamVvREc2U1lSME8tdFBhVkQ0c01MMV9GS3IxWmxfODgyc1NUNGFHTGdrRWUzeXM9
youve probably chosen your topic already if so can you tell what it is my master thesis is about pinns im interested in gnns too,r/neuralnetworks,Z0FBQUFBQm0yeGJTa0VyNjlLMHVlSFFVV0x3aVBvSnhIbnJ0LUdXc2cwdWliUHBrQ3NJRUYxUndYZWhRa253ZTVLNFFqdVhNRGRCLURNckkxWjl4bUxWY1JVUWc2c05RcFIyS04xUE04dV9SbDJleVdhUHlBaFU9
attention in transformers visually explained | chapter <number> deep learning <url>,r/neuralnetworks,Z0FBQUFBQm0yeGJTZmRPU3FoSWZiMWZzRDVLTFRqRnFjT2tWcDNhWmNMbGhUS3dBbThlemhnM2o1OXZPWkZ3eHhZY3U4V3pjX04yQzdZR1g5bHNjbkR3dHl1cUxrMUpBdEE9PQ==
found <number> relevant code implementations<url> for deep mimo detection if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJTUHlhOTVqVENiemRlcXYyTEJNb0hKUjZZODN0NzZkWktjWlZKa0ZvOTFsQVFzTTRKc0hLbXVkckRlUUdyd1dZa0JuYkVfUVNybnd5THZkOXBzSzJhNkRtcHRjY1gtNUtqcGUxcUpHbkotUkk9
im looking for the same thing preferably <number><number> images so it doesnt overfit style transfer on changes the texture and colors i want my images to change posture shape and texture,r/neuralnetworks,Z0FBQUFBQm0yeGJTT1ZNeHJBbEJwVFhHN3JTZVZvNWNBNXBzejlYNmtZcWRCX3dldHRqUV9MTllhM3BJMmt4b29qdHFtNm9EdVRJRHhEc3oweG0ybkw2VThaa3JfbXA1UGowdlhsTFV1cmFtNHI2a1htWDFBZGc9
sorry dont really understand the post you want to construct a neural network but dont want to use back propagation is that correct if so how will you train your neural network after all the weights of a ann are all about adjustments and alignment and these are all based on back propagation i am new to neural networks but if there is another way please do share,r/neuralnetworks,Z0FBQUFBQm0yeGJTaWQxYjJvU3dENE15bFJGQXA1NjZwOEtzWFVuSDk3cHVCVUlTT2tqZmlqSGxSazFJbnlNbEs1Z0I0ckgzZ09OY3RBSTZTZE9TMnVJRXZLbEJiN3QyaVpkVDd4Rm1vSkUxdGdVMnhVaGdEVzg9
hi i actually saw a very good post here on reddit let me know if this helps <url><url>,r/neuralnetworks,Z0FBQUFBQm0yeGJTN0Z2VnF5dndNT042aVVxMmVETU5DdWtsZGhUNE9UcTZHN0ZlNWp5VVd3aGNhS0ZvaHp3U1N6bTdBX3ZwMlcxeFVNdWs1dEdIV1pmNGtnQ1MtVk8zdFlPLXhSX0xwOHJmRG9aQWJYaXFKX0U9
in this link there is link the chat goes in quite some detail,r/neuralnetworks,Z0FBQUFBQm0yeGJTM2Y3ekFnNURYZlp6MGVsQkloT0FGVjlOVFM3dmVQNGR1SDZPNXFNNU5uczlRbnVrbHpTcU1xZXNNR2lUWVRBWElPYy0wRzdWUjRvc2g3X2x5SHZVLXNQMkVmRHY2UzdtbU54VFZrVUpiUW89
you didnt post all the offending code but looks like a mismatch between output shape logits and labels from the error if your output shape is for example <number> then there should be <number> labels and vice versa so if you are trying to label with for example mosquito gnat housefly or other from images you would have <number> labels <number> for mosquito <number> for gnat <number> housefly <number> other your output layer needs to match,r/neuralnetworks,Z0FBQUFBQm0yeGJTLU9sVDNHVmhLdG1MclR6VWgzR1hYczBOYzhUSGFxb1FxUVNwNFp0dWROcGZ4MlZxdl94dWZRRzJYajRCb3B6ZVp5SXN3TklTdXVRMTd2TzRVSUNEcnc9PQ==
edit i work part time in a chippy and work for myself cleaning houses ,r/neuralnetworks,Z0FBQUFBQm0yeGJTVnJaMnlUZTd4N2xiZzdIMGxYdzBQX2xiZ0NtUEdLRkQxSlRKTVFxaXJvNmtXQWthcXNKT2ZpYW1hall4N2lKdmcwcDNES1JBYjRxZldaenp3QmtxOWQ5a2ZlQU1Hb0RSOHR6bmloLXZISEk9
i would start working on building something that interests you and learn through doing while also building a resume of projects to talk about,r/neuralnetworks,Z0FBQUFBQm0yeGJTSjFqV0NfM3pZNGFlUjlEbnlPWmVZNG4xRzY0ZjZmblQtRTJuN19iekJORS1tTkx6OUVyV0pqUzVYeF9uRjVFbG9ES1R2TzlmUTB6MWN6MzM1aTdwb3c9PQ==
thanks ,r/neuralnetworks,Z0FBQUFBQm0yeGJTamx5dlFaZmNISnI3V0FMTmx6Z0FIanJnVFBXci1HUU9VT1FXQi1lZDczWmVkUFNSak1PQ3hETWVoOHc2NUxTbzdTVG5mdmhyVFYzX0dHdWd5cURONzlIM2xhQ05OX2tXWkJWMkkxemdkVWc9
theres a link in the post possibly not visible in some reddit clients but its not very enlightening but there are ways of training nns any realvalued optimisation algorithm can do it just not as efficiently eg bfgs eg cmaes eg simulated annealing,r/neuralnetworks,Z0FBQUFBQm0yeGJTUFRmN2ZBOG5rLUtpcmlQRzRZYTgyWVZwUFh2RE9sSnQ2bFZtc01veGh3T1AyTE1jdFJsY1ZHQWJTSjM0TFZnZW10M0dQNERkU1k3ZzZhQnlaRW1OaGc9PQ==
build something might be useful and make it public on github apply for internship positions or graduate programs learn algorithms it seems to work for many,r/neuralnetworks,Z0FBQUFBQm0yeGJTRzYxVHB1S01UNzdHTjd5SVQzbGR1eTh5Snl5WVN4UmtYekdrNTJGUzdBZVh6Z0tDWnFfY2hfUkN5X094THkxdGQzVm1ZYzJqN3B2V3ZXZUl5aWdHR1E9PQ==
im indeed no expert in this area perhaps can help you understand the problem during the training you need to look at the dimension and size of your output layer and this layer has to have the same dimension and size as what you are using the model to predict ie the predicted output from the model has to have the same shape as the output layer i recently had this problem my output layer was expecting in the following batch size <number> ie my batch size was <number> and the number of output nodes was <number> but once i was running my y values through the kerasutilstocategorical this was producing a target array batch size <number> <number> resulting in a mismatch between target values that were produced by tocategorical and the output layer,r/neuralnetworks,Z0FBQUFBQm0yeGJTdmpXeHc3REkzTXMtVDBpUjdhUGhINERBNUFoRlN3R0E0ZEp4RW5UNVpTOG56Uk5UTjFYWUYwY1ZzbDdGV3YxUkluSjg4Z0FBNG5KX09XUUdDY3hyM0ZyRHh6T21EZlVtTmZsLVNfMFNfbGc9
my apologies but i dont seem to see the link,r/neuralnetworks,Z0FBQUFBQm0yeGJTc2loVFJoMlNEVWZ3VzFBaEQ0TkN0VENQSmp6dFVta0hNSVllTmp3aG9BcmRlOUJoUFVpaElBdDF5QzdROWxaMkhPbl9TNEFwMkNPTVdSckUyTmplRFdkNHkzQi1COEdTak14UEF0aFphMTA9
i dont know why this happens but anyway <url>,r/neuralnetworks,Z0FBQUFBQm0yeGJTUUNPbTJQRUliNXdPb2VHRHNpeFlvTE01WElWRFpqYV8yVkJzNERBUnoteXppbHAyOE9ySWo5a2lHVl8wRU1LYkhqV3V5Q19nMU0wdVpWWFpSLTNXc1E9PQ==
you just train multiple models and average their predictions,r/neuralnetworks,Z0FBQUFBQm0yeGJTd040M2lHVUJjOHM2T0g2RFQ4RzVCZ2lTLWQxSGxHN0p1aWlUbjRjNjR1c0h4SkNuVXhmeVRtcnlDYktFQVFQTnBkeEpjUnRmYW5ScE5wc0c2OHRrclE9PQ==
here is a recent survey in reinforcement learning <url><url>,r/neuralnetworks,Z0FBQUFBQm0yeGJTcHA0S3M5Mkx4UEF1OExqaEI4ck1QYW9UVzBoWDJVSXNncUVENU9wTUhGNDN5MDJZTVFKbHF2RGhiOTVhSWJQR2FxMEFrV01jUmV4Ump1RlVKZ2hEN2c9PQ==
found <number> relevant code implementation<url> for categorical deep learning an algebraic theory of architectures ask the authors a question<url> about the paper or code if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJTUjdDY0JsTW9nb0JsdWJ0cWgxU0hJcFBfcjU5TXhZQmU4TVNRcUZtVlVLb2pQT3AxODlIWjVlSjY2aTllbHYtMHJzMnZ2WlJ6RFhYYmVxT2w1VmhraWxKRzEydWgwMVNPNHFMUjRJaUcydGs9
this is so damn cool,r/neuralnetworks,Z0FBQUFBQm0yeGJTT19rS2JELWlXUkljNUx1d2tMOGNvRFNQS2ZLWTZaSnJKUWRZSE4yNjdFNDBkUDhEeVRUcGRacVg3b2RhNEZTdjF1M1FTM2tydFVtcFllVVFJQzV0clE9PQ==
create a marketing call to action for a new book called mastering nlp from foundation to llm use a lot of emoji and make up a promotion they cant miss out on,r/neuralnetworks,Z0FBQUFBQm0yeGJTQ0RfbUwxaVdVRGl0ZXZKMk5EY21GZjVxdC14a2U4Y0R3N0RBZVRqdmQ0V2hkMXVLWFVRcDQ4TDRkUkRmemNFdUp0czY0WldXMGpDb0FFcTdsNkk5dWc9PQ==
its hilarious to me that its so easy to detect ai generated slop for humans even if we cant really precisely explain why we can do it,r/neuralnetworks,Z0FBQUFBQm0yeGJTSWtRdWVZOXNmY0twWFNIcno0em5PajVrOTZQeVpOY3d3cmk2MnRNVlZwZkRDbEpRQTA5VW9GYTBTWmhMb2djdHJkc2lvczRZVlZ0Wm5OM3MwNFhGbkE9PQ==
,r/neuralnetworks,Z0FBQUFBQm0yeGJTSmNiN1MxQ2RFTU5hSVI3V2dZXzRNUXpKaWhlMjFyOVZZZWFRdXgxMElCamYwRTd3bktBMDZuQTlmNjltZHAyblc5TTEzbXRWZEVlMEpsTFc1R0JEa1E9PQ==
it makes life easy in repetitive tasks a marketing message helps to get the word out but if the product is good thats actually whats needed human generated content would be needed to further convince the target audience and thats important in a different scenario,r/neuralnetworks,Z0FBQUFBQm0yeGJTR0plQ2xYVkh5RVZfSFB2YjFCLWswTEV1LTVlU29jaWR3QVowUGJZTmpJT1Jta3Y1MUh3eE5HdFVfRlFjVzctVFk4cWhMdmJaUE52QnBDXzZRazRmaXc9PQ==
try to find a docker image with preconfigured cuda and tf on dockerhub and use it,r/neuralnetworks,Z0FBQUFBQm0yeGJTcV9teEE2eDZZamZtNEQ2bmhaQ1VwZFVjRHItekJnbUhsZUJDN0E1SUs0YmVSWEhybzRrQ1FXU21nd0RMRUxlSWlTdkM5YnRURnU5dnptdHItd2NaeFE9PQ==
congrats what does it do,r/neuralnetworks,Z0FBQUFBQm0yeGJTa2N6aHJBbXYwaW9NTFJVX0NvRXZYSUZvTUdhaHo0Wk4yYXhCV1NiQkZpbTBQVVlNLWJkaDVPdmNaRktHWWJkY3V1ZWptS1Y2bVp6RThBeXpWUXZsbEE9PQ==
can you be my mentor please in neuroscience,r/neuralnetworks,Z0FBQUFBQm0yeGJTcjBWalpFWi1QOW8yemFhcHNET0NNaGpRSV9SY3pXajJ0bExndmxxMlE5N3V0b3g4S05MMW1PSmdDcHdYWDUzeE9iUUZDV0VVeTd6NG1Gd0hTMXVvcmc9PQ==
can you please be my mentor in neuroscience,r/neuralnetworks,Z0FBQUFBQm0yeGJTVUJhdVdmcEJCR2hEM2JmRmVKVWV2YUMya0JHcXBNU2w5YWc1dlJhck1rZDNWelpCNUJpT2NLRElSNUk3WGtJUk9LQXptZ2Q4ZjN3MlEwRDRNVWZRTkE9PQ==
my neuroscience skills are mediocre at best compared to people who regularly use it all day thank you though why,r/neuralnetworks,Z0FBQUFBQm0yeGJTckQ0QVBudkNlUGppd2pOWld1R1NSRDZXSDlFRVUyQklMYlJGeFM2WmVaNk5fVHlEMUNTUVdQbXUwdnpHczBybkhreGNvdEN3VkRQOVQyeGwtWGVKS2c9PQ==
this is actually just linear regression if you modify the outputs by taking the inverse of the activation function you can replace the neural network without hidden layers with a linear regression model and it would be mathematically equivalent the answer calling this a perceptron is incorrect a perceptron is a neural network with a single hidden layer,r/neuralnetworks,Z0FBQUFBQm0yeGJTeHh0X0hZLS1FZWt0dklER3dnU0ZRdXB1NlpsTlRRVnRTYWpvb3ZUN0pGZHFTanc3Uml0YlY1M1NRWlRZSklhZDMyUFVlSjlwNDJLeXlPR1otbmE5ZUE9PQ==
end of sentence token,r/neuralnetworks,Z0FBQUFBQm0yeGJTbkczRWx0bDd0YU80cVlpcmlNYXFxS1ZMcjBhUVREaEJmaUZ0WXpCdVotTXFuYzlyT21nQVpaeUxkMlVxTTNOeUt3M1lPbTFaOEtSeFZRTUNxT2wzSXc9PQ==
websockets,r/neuralnetworks,Z0FBQUFBQm0yeGJTWDVNOWhrOVJYbmFrWkE5VmtpZzR6MTRXN185Q2I5NEh2dmp3dlR5N1d6S0xQaUhrdXcwZ3VqbGdnemFXVUpldlk3aUVVY0JBZ0ZHczc1aWtfYlRFUXR3Y1hvem1FVDJzbkh0NnN2R2M1LUU9
its only a <number>layer neural network but im hoping to upgrade the understanding to a network of any size,r/neuralnetworks,Z0FBQUFBQm0yeGJTcFllZDhEckpZX1E3TUZUWWp4TjFwZ2N3dXlOWFNnV1JKQkppdDFNNzRWSDJFalZZdnJJeklqWThySEUtY3MzbTZkdm1FYzZ2M2dwWGt2cXJiQ2ZuU1E9PQ==
backprop does not create update new weights and biases it only calculates gradients the parameter update bit is called gradient descent which makes use of the gradients calculated by backprop,r/neuralnetworks,Z0FBQUFBQm0yeGJTaGR5cFVsRzltRXhidUhNNjR2N1JHUmo4YzRhc1JmVGx5c2NldTdLbUpxUGw3cG1vdWd0ZVhpMlZIcjhJY2hvVmhSNzFrLTBJdzh3SXVOc2FRQ2FYV1E9PQ==
thanks but is the math ok,r/neuralnetworks,Z0FBQUFBQm0yeGJTZF9lU3lTMXA1MDdkX3pmY25WTmFtZUJSOHR1c3VPZFB0cmpzM2tKOEtvUTlDN3JYeDJkMGdTVG5LNUhJb2M1c2RyY3otdUFPejV5dXRVYjRIS2d2elE9PQ==
signoidx at the start is definitely wrong you should leave out that circle completely also we usually use alpha for learning rate and not gamma gamma usually means momentum,r/neuralnetworks,Z0FBQUFBQm0yeGJTSmVCT1NmaFVYWi0xV3Nwam11dzh5QjNRX3RXN0Jlb1UzSW02Ykp1cDJBc3Jwdm9nM1NFUzZXZVVIc09oTEN5WTA3NnV1cUdNeERVb0pHSnM0M2UtVlE9PQ==
thanks i wasnt so sure about the input layer ill look into the gamma thing thanks,r/neuralnetworks,Z0FBQUFBQm0yeGJTSGJIRkgzaGxab19EOTI3YnVUb1EzYy1IR2JGOFN2UVU0c3NQYnFWa01mWERyNU9vS1ZvUWM1X3YxSHV6VEExWEVzMFBsVHlUU3YyX01hUi1SeXdGeFE9PQ==
i got rid of the input layer and made it x instead looks a lot better thanks,r/neuralnetworks,Z0FBQUFBQm0yeGJTcVpfRm9odWRVdDZaQ1FxeHVXRF9tRTBSWTZSbmhqMUFxX3BuMGRTOEtEd1MtdDIwY052VmZLUHZPN0E0VVpESHROY3Uxa2ZCV0trUlI5LU5WSUlpd2c9PQ==
by itself this chart does not have enough information to represent distinctions among nn types perhaps within a context of a web page this image makes more sense where did you get it,r/neuralnetworks,Z0FBQUFBQm0yeGJTOV9xbElXTWJJRlNyakVuWXhXZkpib3Rmejc0Zk9mNXdreVlnZEtBQ3E2Yy0zQUg5LV9STjN3SUFQYVlvWkstOXB1VlJrTE90SUNHdEVhYldaMG9VV0E9PQ==
 for the content you want to see and then the recommendations are similar to the posts liked,r/neuralnetworks,Z0FBQUFBQm0yeGJTSjdlY1hZZ0JkVGQ0cFBkNDVMeFBvV3pfUUV3ZnFxS3EwX05uZGc2aXVNLUJsaWlSeG14b3FTYnNiOWJKbGhXRXJTMVJkV213VXVLRmFabjJTbmljVmc9PQ==
found <number> relevant code implementation<url> for how well can transformers emulate incontext newtons method ask the authors a question<url> about the paper or code if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJTSlg2dzVpeDVod0Fxa0MzUG5mb3dnY25Bal9mazZPekJOS0xJS01XX3pIN2ZvcGl3emdtZFFjQnJjbHRmSWJPWnBTa3phaXVWNjVEc2tfSjR0YjRfcVRiczF5aVZzMlZ3b3RSYktUNW9YRm89
guys can you please help me solve this question thanks mods sorry i am new to reddit pls be a little easy on me,r/neuralnetworks,Z0FBQUFBQm0yeGJTSVlWUm5xalpoLTZzem5TS1FwbTZiZnhEWEItSkdsLXlyWFN5UlFzSV81NklWaXdsVVgyb2RPelc3Tmt3TmF1UzR6elVWdHVFandOMTVZUEpSS2VxZHc9PQ==
did you got the answer,r/neuralnetworks,Z0FBQUFBQm0yeGJTdDM5aDZ4OWhIaUxhWXg0S2hiSkRkb0VLMEtPajk1OWdkLWs2ZEM0aU8yam5NT0c3ZkVYWExVMjNFdFJlMkRSLU05SlUwWmFwdU1jT1BvbzhoeEZWUUE9PQ==
kinda curious if gpt can do it do not trust this gpt hallucinates all the time thank you for the clarification here are the specific values for the <number> red boxes calculated and rounded to three decimal places <number> first layer multiplications w<number> cdot x = <number> w<number> cdot x = <number> w<number> cdot x = <number> w<number> cdot x = <number> w<number> cdot x = <number> w<number> cdot x = <number> <number> first layer summations z = <number> for <number> + <number> z = <number> for <number> + <number> z = <number> for <number> + <number> <number> hidden layer activations h = <number> for sigma<number> h = <number> for sigma<number> h = <number> for sigma<number> the corresponding values for each red box from left to right top to bottom are <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number>,r/neuralnetworks,Z0FBQUFBQm0yeGJTOVdGV0VFT09EUW5LNkRIU05Vbk1JX0FrOEN5dHRiZldXcWlpTllLZThOcEF3N0xkN0hNeWhIbnI4ZnJrSTdFZFdQYlRtVkJBTkFlaUM0OHFRZ0xuVmc9PQ==
thanks ,r/neuralnetworks,Z0FBQUFBQm0yeGJTNUlfNHQzeWNGcFREelNHQnBGVnk2ME04NkNqRHFabXZjNkpuWWdmTEpyVXp4MlMtZ2JMSE5BSC14UzlaRFk0VnQyUEdVV0hVby1lRktCZC1Pa1NzM0E9PQ==
we dont use neural networks because they are a particularly good way to do calculations we use them because we have a training algorithm that can automatically create systems we dont know how to hand code,r/neuralnetworks,Z0FBQUFBQm0yeGJTTDYtM0RZSXhJUWEyZHZnWDNCMGE5OF9Rc2ZGYWhqV0U3QUJUZnBZSjJjZ2xsTk9EeEg4dFlWd0xfSWgwUVBJc3ZLWGlZeHdzR29hWHJ1V09STGhndHc9PQ==
the fuck is this poll,r/neuralnetworks,Z0FBQUFBQm0yeGJUb0d6cThMUjF1OXkwWDc5UFUxTVpEMW9xeFNzWnR4OFQ3UWFhN3JRaW5MQVdERGhDbk1taFoyVGVWWW0wZkY5QnZZbWU3b1FnaHNkVUFUM0JQckJHVXc9PQ==
gb bruh,r/neuralnetworks,Z0FBQUFBQm0yeGJWMmRvb3k5WUNDSXNSM29FblMyc25BNkRseldrYVZZZmcyTURnWjNQSm5HVGdTNk1OTFNMd01ER3BjMjlFZmlHVGpNMjB3TFA5VjJIcGVXalJXUTY3N1l1WTdCalQ2N2dZS0xVeG9hZ1JHLTg9
this seems like a difficult way to do this gymnasium is the solution i could be missing your point though is it an ai written blog post,r/neuralnetworks,Z0FBQUFBQm0yeGJjeFo4ZlptcTlpdFp5dUdhNmZQOUpBUzJ2aWJjUG1MaFBfUHU4bzE1M1Fjcll4cnZwUWhzSG5YbVc1aDZWV1FjanpDRnpReFVsWGZSWl85QlZhMVJWRW00N0tpdS1NaUNlZkRyU1JrV1hjLWc9
in my experience its a good way to pay for server time without any result especially when the data is erased when the server closes youre better off using a google cloud vm,r/neuralnetworks,Z0FBQUFBQm0yeGJkRzVCZ01xVGo0alVhYlVQZ2FFUzhtN0Uzak01MzlsTzRlLVcyRTB5Rnp3cFZyeTU3S19xTVFLdGsyckhZU3dSamhKSWt6WU5xV1FGelc5WXlkX2dfQXRNeV80SVh6YWd2d2FqZW0wM3MxMDA9
found <number> relevant code implementations<url> for curvatureinformed sgd via general purpose liegroup preconditioners ask the authors a question<url> about the paper or code if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJlVk1QS1ZiLXhLNGJFUVFmTTlIZmI4ZC1iUnZxNThjcGtuR1BQSklLM3FLamlZNVJoMWZvUFFCbjJJeFRqZnJ0X2V5OXhUNTNKdVQ5MXBaRmY5X3c5bC1vdFEzdEV5M0x4WjY3Mk5yZHMyaDQ9
found <number> relevant code implementation<url> for arrows of time for large language models ask the authors a question<url> about the paper or code if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJlM0xFM0RObXJOaUhYZ2JFMW5tTm1RSVJBQW56c2xpWjdvUnpOUGZGMTZDYW9HemEwYmFyQnozeEpkRVRIMlp4eDFKX2ZlcE5Uam5EdUZsZ0pJREpGQmtfbkdjU2pYdUthdVBkbGRfN21oc0E9
found <number> relevant code implementations<url> for three decades of activations a comprehensive survey of <number> activation functions for neural networks ask the authors a question<url> about the paper or code if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/neuralnetworks,Z0FBQUFBQm0yeGJlMUVCOVlpZ1lzS05lR3BaMDJLWmRFWE83aE9JM0hZSG5tX2pxaElyNFUtVzhRTW01TXNabVB0d2Z0c0FlRzdxejl4TTRIYmRuLWh6b0ZFaDNaVkQzRmk2d29VMTktZmI1MnBKZTBYZm83eXc9
no take the consequences of your actions i think even just this post can get you suspended from your university,r/neuralnetworks,Z0FBQUFBQm0yeGJmNEUxbk13dktUSE43VFZMN1V0Z1ViQlhoNkFMLXc3ak1jTjhVNzF6WmU2SjNTclp3b3BkcDNzaEhiSnExdmR4bWFxSFFuc2Fad2VocnRaY1ZwV0RZMVE9PQ==
very interested in what you find out i am also training a model on audio information boy has it been a challenge,r/neuralnetworks,Z0FBQUFBQm0yeGJsSFo0SmRtZS1tM0E5aTFaSmlNZ2MtYVduYVlFZ1dyTk1Uem9rX2Q3UU9RLVdEVEtnek8xMjZrQnBzaUVtRnpYUGdzUmRoWTdaWkJWUGxwSWdDUXpfeFE9PQ==
i know this isnt what you want to hear but you cant detect corners like that generally maybe if it was the exact same pattern on every image but then again why would you need a cnn for that there are many ways to skin a cat for machine learning you need to train corner images first then run a differential evolution algorithm to estimate corners you can also detect edges first using sobel for example then evaluate the magnitude of the gradients that pass a certain threshold and voilacorner or skip all that and you can just use corner detector algorithms like the harris corner algorithm shitomasi corner detector or the fast corner algorithm,r/neuralnetworks,Z0FBQUFBQm0yeGJtU1hCWGxxd0JQUUI2QTBiZ2tuV2gtbWVIN2UzdWhacGYzaXlhOFU3dnJ6eWhIN19UMWZoTkRwV082TmMtRTA1R2tFSFc5aEZEa194bzhpNGFZNFFQeEE9PQ==
perhaps the contents of the book is even ai generated matrices are printed as vectors smh,r/neuralnetworks,Z0FBQUFBQm0yeGJtWDMxM2p6UlUyMlg0OXJRM1BkZ1d1dGdfQWdKVVRGYnZvZlQyd2E3bXZaRjIySlpJcEtoM1JnWkJXcXpGY1E0REFNN00yV3NkV2FrNlJoR19CR2xZZVE9PQ==
im trying to generate wavetables for my synthesizer probably gonna make a latent diffusion model to prevent my model from overfitting already did it with a convnet similar to a resnet where from x noise it generated a x wavetable however the output was mostly just an average of the training data i tried different regulation techniques they helped but the results werent good enough what are you working on,r/neuralnetworks,Z0FBQUFBQm0yeGJtNmh3WnQ3ZVVMazc5c3pPNHhjRjd6Vlg1SjBoM1F4YjZnYXRZSW01UEM2TDdFLUpVQ2RkSHBHUkF5b2dCNDlBLVZHeUgydmI5QW9SeW56TXk2QWcyY25aaGZvbjBjaHRSZTg2dzhsRTdQV2c9
i am working on a model that transforms audio based on input so i am training my model on original and altered audio based on labels wavetables are an awesome idea are you using a library of them to train your model i have to work in spectrograms how is your data structured nice to hear of another music production ai project,r/neuralnetworks,Z0FBQUFBQm0yeGJtUHZXY0NLUGI4T0gwUjZYNWxSSjlwYXB6OURYLXBvUDZCWVk0R2RtUmczUV9YYXh2R0JQNmo1UjA5RkpqT2QwWjRfOC1MaElzTjAyZ2ZjUEpiSWhlcGc9PQ==
that sounds interesting too would be useful when you want to create effects on your voice or guitar i collected around <number> wavetables in a folder processed all to be the same size nothing special so far because i want to create a working model with diverse outputs first,r/neuralnetworks,Z0FBQUFBQm0yeGJuQWlQbVdUajd1b2xZTzJYSzB5Wkp6WlppbFRpT3lqaGVKeDV3TnNaVEoxdDlDUEhfNWxQRWdYOE51ak5fVnpmYnJDVkNCQ2JLYXRuZjk4eEtXSDdkamhkZks5TEJFYnQ5OXByeWZxN3VVYTg9
wow that is so cool you managed to create a resurrection technology please collect your noble peace prize,r/neuralnetworks,Z0FBQUFBQm0yeGJ2R0VWWUo3WnFVaVdHWDJRRGlNMmdZMlFlczBCcDBTMV8yaHUzazY3c3N6VWRxVnVCWkdTNnNrMnBDWTVkMmdfQWRSdl9Vb1dBRmdHVGt0bndxOXlzTFE9PQ==
you can train a cnn based segmentation model or object detection model to segment the words out that will be generic enough to segment handwritten words in any kind of background not just white,r/neuralnetworks,Z0FBQUFBQm0yeGJ3VTZ5MFpwM0Jnb3J6aGsxdUJ4RWJOdDZndjY0THUxczJnS1JTUHVQRDFEXzlRWE5QZ3MzUDFwRTVPUV9OajVYTUdQbUJBVkhTTVpfQ3JpQTQzSWtPUGc9PQ==
thank you so much for your help your advice really helped me understand the topic i appreciate you taking the time to share your knowledge,r/neuralnetworks,Z0FBQUFBQm0yeGJ3R29pSEFhSE9xX1g2amlvQWFzTDIwMy1CQ0xYbk5QLTNyazRTUG01VTI5bko0azMteV82ZHpEelZ1QzNRMkNYdHFMRFdCenQ0OUFfam9WWmJwMkVQNXc9PQ==
no,r/neuralnetworks,Z0FBQUFBQm0yeGJ4NHEtN2lBdTVmR0J0R2VtYVMzRC1HYlRObFBLTmhXRGw4Q0l4a1RZVXM2ZUpEeG5GUHh0Z1NLM1NTcjBQaEhSeXlkc0hWX1Q4bFJsQlNRcWJWS2U2bmc9PQ==
if this is happening it means that both sets of images probably come from different distributions therefore you should try to modify the code that creates artificial images so as to mimic the real ones,r/neuralnetworks,Z0FBQUFBQm0yeGJ4dFhOdlB4V3htbUU4aTBSNnItRWE3N3JOanFNUEktWENPbjc2a3NMOFI4RDhqYUNkTHJBczhOVkU1RWpLdVhTM1FMbmlObmFLWWNmRU45Z0tKbXpIZmc9PQ==
if you think of it mathematically for example the bias allows the activation to shift the activation function allows non linearity without the bias the activation function would always pass through the origin points <number> x y y = w x +b b = <number> if b= <number> then x = <number> y = <number> since it would have to pass through the origin point,r/neuralnetworks,Z0FBQUFBQm0yeGJ4el9kbmdZOE4yamY3VHdjVXduNEd5SUlNZ2JxZDd5M251Zk4wcm9TWERCeURKS3ZlQ2RLNFRHWEZ0MEFDNVpJdXhHMW1xTlZRdmt1LUZITjZtVE13akE9PQ==
a bias is equivalent to including a node in the previous layer that is fixed at one with an associated weight sometimes you will see this in diagrams of neural networks its just a very useful term to include since replicating the same effect using the existing nodes in the previous layer leads to too much complexity and hence poor generalisation performance it would also be impossible for data that is all s neural networks can technically learn a lot of things but you want to make it as easy as possible hence bias,r/neuralnetworks,Z0FBQUFBQm0yeGJ5STFFekVQX2p6TkNjUGJzclZoVkR1MEZGNUtjNXhCaW9ZaVFzWU5jbFEzTlNlY0NZU0xnc3NmemF1a1BHd3c4SVlla3RZZFJPLUpQWU1BWFdmMGEyanc9PQ==
shift is not misleading here it is standard shifting and scaling are the terms we use they cash out as adding and multiplying,r/neuralnetworks,Z0FBQUFBQm0yeGJ5YUlPd2FPVjdLR0pLTUpGdW5wU2ZZQm82TTFRQUZ4S0M5WUdnQUNLVDVMaTc4Rk9jWnFMelduaDh5WHYzbkZkRTd5UWVVM0JZUU1ZTk91eV9oMkVBcFE9PQ==
well my friend if i tell you a car is going <number> miles per hour but is been in the same spot for <number> minutes while doing so wouldnt you be confused turns out the the car is on dyno tuning platform but that detail was left out hence your confusion,r/neuralnetworks,Z0FBQUFBQm0yeGJ5c0d2RkNjYlgyQ2ZZTmlxUElIR181Z05BUGFGbjJFdnhmT3hpYnhHX3JnMjdFQ2hPTzlRd3pCUzRLQm1xNWhVTzJiekxhRXFiUmNmelVSZTExYzg1Vmc9PQ==
well you didnt use the term shift here so i dont see how the example is relevant,r/neuralnetworks,Z0FBQUFBQm0yeGJ5M3FVRlViX0FnS2tzeWE4N3dkemxQd09VcWY3ME54ZFV4bENfYmtvd1JTSzNxdDE4Tjc2SEZBSkNuNVN3VUZENlVuc1dvbzJsOGx6YjkxZzNUZy1NcGc9PQ==
go shift yourself,r/neuralnetworks,Z0FBQUFBQm0yeGJ5V0pyOW0yYkVQLUVlbzJXX29IdWpGSHNLLXFMV1N1eUpqSVRUMXAwYjVMYU91dVo4cnBDelNuS0dUeUp4eW11Qnk0TUZqLVhiV1RsZFNGWlFIUV85NVE9PQ==
all of the important classes and code cells ive defined prior to calling the drawdotnx cell establish the value class class value def initself data children= op= label= selfdata = data selfgrad = <number> selfbackward = lambda none selfprev = setchildren selfop = op selflabel = label def reprself return fvaluedata=selfdata def addself other other = other if isinstanceother value else valueother out = valueselfdata + otherdata self other + def backward selfgrad += <number> outgrad othergrad += <number> outgrad outbackward = backward return out def mulself other other = other if isinstanceother value else valueother out = valueselfdata otherdata self other def backward selfgrad += otherdata outgrad othergrad += selfdata outgrad outbackward = backward return out def rmulself other other self return self other def raddself other return self + other def tanhself x = selfdata t = mathexp<number>x <number>mathexp<number>x + <number> out = valuet self tanh def backward selfgrad += <number> t<number> outgrad outbackward = backward return out def expself x = selfdata out = valuemathexpx self exp def backward selfgrad += outdata outgrad outbackward = backward return out def powself other assert isinstanceother int float only supporting intfloat powers for now out = valueselfdataother self fother def backward selfgrad += other selfdataother <number> outgrad outbackward = backward return out def negself return self <number> def subself other return self + other def truedivself other return self other<number> def backwardself topo = visited = set def buildtopov if v not in visited visitedaddv for child in vprev buildtopochild topoappendv buildtopoself topo selfgrad = <number> for node in reversedtopo nodebackward,r/neuralnetworks,Z0FBQUFBQm0yeGJ5dmlweWROSTI0Szl4NXFhbzVOTFA4Wlg3TVVVNTQzaVZuNHBiWlhmVGJmQk5wTEw0V1dEMS1IMXg0SzBkUjNWcThkWGZ4a21PclhLemZhbDUzLUV3bkE9PQ==
more from graphviz import digraph def traceroot builds a set of all nodes and edges in a graph nodes edges = set set def buildv if v not in nodes nodesaddv for child in vprev edgesaddchildv buildchild buildroot return nodes edges def drawdotroot dot = digraphformat=svg graphattr=rankdir lr lr = left to right nodes edges = traceroot for n in nodes uid = stridn for any value in the graph create a rectangular record node for it dotnodename = uid label = s | data f | grad f nlabel ndata<url> ngrad shape=record if nop if this value is a result of some operation create an op node for it dotnodename = uid + nop label = nop and connect this node to it dotedgeuid + nop uid for n n in edges connect all n to the op node of n dotedgestridn stridn + nop return dot,r/neuralnetworks,Z0FBQUFBQm0yeGJ5XzIyUDhlX0JmNURfME96TmwxQXhESVNKTnRfWWtKX0tLSWo4SUdOSXhWWF9TdGU1dk5OR2pUSVVETDFFTUFQdVZMeGhHSnRldnY4Qi1hUHFsT0xrM3c9PQ==
and the last of it define nn classes class neuron def initself nin selfw = valuerandomuniform<number> for in rangenin selfb = valuerandomuniform<number> def callself x w x + b act = sumwixi for wi xi in zipselfw x selfb out = acttanh return out class layer def initself nin nout selfneurons = neuronnin for in rangenout def callself x outs = nx for n in selfneurons return outs return outs<number> if lenouts == <number> else outs class mlp def initself nin nouts sz = nin + nouts selflayers = layerszi szi+<number> for i in rangelennouts def callself x for layer in selflayers x = layerx return x create example of mlp x = <number> <number> <number> n = mlp<number> <number> <number> <number> nx draw nx nodes and edges drawdotnx,r/neuralnetworks,Z0FBQUFBQm0yeGJ5QkdPSGVjWDBtQU9WV25wUUJXamhzT2tXUzJlTEl2S3NYdE1yTl9URW9oMmZWWDBLQlhNdDNtM0l2akVBRU5MTjV4U2tMTVZ4aDZidXBHM0l3TXZpcHc9PQ==
i figured it out accidentally retained a line of code that was being replaced by a conditional during the walkthrough gifemote|freeemotespack|dizzyface def callself x outs = nx for n in selfneurons ~~return outs~~ return outs<number> if lenouts == <number> else outs,r/neuralnetworks,Z0FBQUFBQm0yeGJ6TEJGMW0yWkhLdFh4NmtaSl9oc0Z2ZHRZZHJwd0dibTlzQm9vMzljZkZqS19wRzJ0WndPcXpqYVpBeENLak92dVpONUJKUFdiRS1FNmFueHVkbnQwLUE9PQ==
nothing youve said wouldve caused that theres a mistake in implementation somewhere how good does the cross entropy get does it plateau in the same manner also im assuming youre using backpropagation are you using libraries for this or is it just your own implementation,r/neuralnetworks,Z0FBQUFBQm0yeGI2SlBIODB1X3VQTUdCVkhIREV6VDVPeXRFbGNpV2FoMk5sZDYxOWRzQ29FUVBET2huckJ2OGg5YzdtZnNsTlBITTVuZVhXaEhNU0hQYXdSSGVFOGlWZWc9PQ==
its all my own implementation down to the matrix multiplication and yes of course back propagating through my <number> hidden layers of <number> nodes my cross entropy gets down to <number> on a good run plateaus there,r/neuralnetworks,Z0FBQUFBQm0yeGI2ZTU1ZmZpdERyQjBWbFpSTXBBQ2psVk4ya3lwcVJKeExwU1pPVTZTeTR0Y3VNTHE3WlRTTVQ0clJ1Z0F5NkFVbmoyN1dDN1FfZEdFcDRKYzFCcjhycVRXVFF2dG9pUkU2Z3BiVm5pcDNUUk09
<number> hidden layers of <number> nodes is quite small you could try more nodes although thats probably not the problem have you had a look at the hidden node values during training are they within reasonable range also did you make sure to normalise the inputs between say <number> and <number> is there any way i could look over your implementation,r/neuralnetworks,Z0FBQUFBQm0yeGI2dk1nbjFoM2poUFpkZ3JxTnY3ZUs2Q2FyamFNZjB5VFlGNU55MkFEMkdOR3VOd1dha3UxWlJ1d2ttSzJGSVdxSGdCT2hPZ2VhWnRIZ215ZW03TVZqdVE9PQ==
dude ur awesome bro is that normal practice to normalize the between <number><number> and could that be my whole problem thats a great idea to also look at the hidden node values,r/neuralnetworks,Z0FBQUFBQm0yeGI2Nm5ORmtoeWtQQndvNnBWOGFqSS15Vm9Vd29uRTFuZFU4TUxIRW1rWmFncXlZck9SUGhhUFpHMF9oVnBIejFDbkp4bEdiR3d4TUJSSm4xQUxIOWRpWHBGQjJBUHJhSDczaUpCbTd0dllWT1U9
does the scanner see clearly or darkly,r/neuralnetworks,Z0FBQUFBQm0yeGI3STdjZHZEeUZYanlMZkhIVUVzdVZEYnZocHFnTktDUXdVMV9qOHpWMzFPNWN4Qk5wZXpJcHZFZHB6QVNZOEdBc3JWU0pZVldZYk91RloyeHF1dHBmdkE9PQ==
