cleaned_text,label,username_encoded
i as well got this error any fixes,r/pytorch,Z0FBQUFBQm0yeGJTOTA0R3c4U2FFSmlzRS1kMVR1OGFLajllSGJnWElmeTF4VG41VnVIVXp3a3pBcUxTeEN6bG9PQlVNc3QwSVFQbi1SSTFVTG5wd3ZtZ0tWeGRlZERBRVE9PQ==
same here any update on how to fix it,r/pytorch,Z0FBQUFBQm0yeGJTMmZHLWc0QlBUN01QQWZHVkE0aXhjNzBRSnVENmlWTFhpaXN4SjdweldFd2k3TmNtQ1JCS3c3T1V2MUJkT3JWeGZjdHNSQ29WYWhRZEZ0UnAyV21LNENLbFh5bFlPbl9Jenh6UEU5QXRtaGM9
i uninstalled torch version <number> and used <number> however im getting different errors when trying to use model tracking with yolov and it might be due to my dependency versions but i am not sure,r/pytorch,Z0FBQUFBQm0yeGJTcjZrS2ZpZU4xSlF6cTRIWXhYUHdfRjVQWDY5OXk0N2dJdEh4OVZLdE56MF9ienpQaUl5d1FvV2p6cEF1bWNjZG5ncGFlTENNNWFleUtEVDNLSGpHblE9PQ==
regardless downgrading a version seems to get rid of this error in particular if anyone knows a better fix to actually be able to use <number> as its the latest stable version that would be awesome,r/pytorch,Z0FBQUFBQm0yeGJTX0Z0TDhmNUhrUHJBLXFKdXMybnJNM2w1b2tFLU1peDdoRHlPVlZsck1yMGJKUHdKMTFVMVVwNzVIc1JXNUZrUUMwSWp4YTdvU2xJUzhVLXk4TmlCQlE9PQ==
not related to your initial question but since you are studying you should learn about proper use of generators ex range converting a generator to a list is often completely useless slow down execution and has a bigger memory footprint possibly leading to oom errors,r/pytorch,Z0FBQUFBQm0yeGJTRlRGQ3J6bjJxZXBDU2J2eGlEMjFaV3BCM3NOMUtlWEhwdW1YZzU4akJMR0JFQWdYVXp3Z204cnFmOTZ6YTBuNHp5bXhIOHBxalVMN1A5aDZZRlJmUzM4MTYzZTM0c3FsaWlvUmJ4RXlPREE9
<url>,r/pytorch,Z0FBQUFBQm0yeGJTcWw4dV9yZGRSbm9WYzRIbnV1cG54bG9US0RkY0cyWENXNU94NVhXN1RDZUdaeXVIOGx2a2NCMkhNZUVzVjVCNGx4MVk2OVRLYUhsWndSS0FIMjUtcWc9PQ==
have you tried google colab or lightningai for their gpus,r/pytorch,Z0FBQUFBQm0yeGJTelZncFVkLUJqdHRjbTYzV21aRlN6THhKd1BUTlREeEd5ajlfSGtleTlTbjFxaHZaRE9sU1RxTE9BR1JjV0JHTlp0VVQ1LXZuT0xHTUtybml3QnY1bEE9PQ==
yeah or modal runpod beam cerebrium aws sagify flyio<url> gpus etc however these are all renting hardware unless i am mistaken im talking about deploying to a machine i own or at least a machine i control but not one im necessarily sat in front of,r/pytorch,Z0FBQUFBQm0yeGJTTmNTck5zQVJfUUVKZ3VzN0tUSVotQUN0VDdTNFZ6cFRnOXRNTnBQVXZfWDNPX1RtSmFjbkladmZaQmwtcmV5OVppUjJNMGhFNU1QVGdJVVlxYXBHeUE9PQ==
rayio with its torch integration if you want to keep it simple flyteorg if you want to use ks metaflow is also good,r/pytorch,Z0FBQUFBQm0yeGJTQkQzcThGRnNKclVPYjBuSllNQ3F4dmxnbDhQbm5VZHE0SzJqTkJUOTNEc0dSa1EzV1Y4RUM3QVI1QkloQjFTU2ZZNTYxOUgzczBtcEhweGYxTGc3aEE9PQ==
thanks i have seen ray before but not the other two am i right in thinking that in all cases you have to convert your project to work with these for example you have to bundle up or specify your projects dependencies beyond just having a requirementstxt or setuppy,r/pytorch,Z0FBQUFBQm0yeGJTcWwtYXU4QS1TSTFyRll6djFiVjRQQUhOWmZRWXlOVFNyUk8zdXR2bE1UbW1ZNFhNTXpuUTI1ZGIyN0pLZDdfTHhPaEYwMXRoR0wwVWdkRzNVRUZTNHc9PQ==
i can think of many ways to use docker do you mean to build locally then push the image to a repository then pull it on the remote machine,r/pytorch,Z0FBQUFBQm0yeGJTRE01Zkg0b1lPMTkzOW9MZHRjdEVGVDVTN1U0Rl9yWU5sUlhKdldadVJvYkcwNXB4NGhWVjNEMmMxeHpIQzJZM1FycllIWmpoYVprV1hKS3BGZmFEbGc9PQ==
for both flyte andor ray youll have to add function decorators to each part of your work flow ray has actorstasksobjects flyte has tasksworkflowslaunch plans these will tell each system how to handle your processing if you use torch lightning it can be a little easier <url>,r/pytorch,Z0FBQUFBQm0yeGJTRHBqM1g5dTc4RnZwYmpPUzB5S0RqT2NlRGVhaVFjMU8xVk9VeG56N2hpSVB5XzBuemd0Q0Q4UXNCUUI4YlFtMjdnYmtydnhTZnIzbFhxazFPeEVIVVE9PQ==
i use a chromebook to connect via ssh to my home pc running ubuntu kinda sucks i havent been able to get xforwarding functional though not sure how to use matplotlib with this config adding x to my ssh string doesnt do much yet,r/pytorch,Z0FBQUFBQm0yeGJTOHRhS1dObHpkWGVfSHVqZ2FfMWQySkxLblpmM0ZIVXdGRHNtME5xeGw2eWoxZjRhaXFMY3JqNDZGX1NBd3BqamtsWFNLVU9yLXB4WHFuVDBfQjFMSWc9PQ==
vscode over ssh is spectacular for remote dev and terminal jupyterlab works great too,r/pytorch,Z0FBQUFBQm0yeGJTZEtaV3RaRm1Zd2t4VFUwdTFJWjVlbC1LUG0yUV85SjBKWHFnY2szMklVQjRSTXBfbm9NSVVQakhsdVZCWGVYbkI4NzZRdUhCOGcyQUJBcVpSM3RieUE9PQ==
just a note that vscode tends to leave a lot of orphan processes on the remote machine so you should check after closing the connection and kill any leftover processes when done another option is vscode + sshfs which requires no vscode processes running on the server but you lose the debugger functionality,r/pytorch,Z0FBQUFBQm0yeGJTNjJBcGlaTXRWeDZGWEd2S1NsajI1TWlqY3NuTG0wUkxSa2Qtc1FUOWs0LUZBbTBBRjBybVBsdG5ZSnpVSkFtSE5SRHNSZVVnR1RQMnNvcmJKTVNQRGc9PQ==
id like to build docker image to run my code on remote machine if i want to modify codes i do it locally and then rebuild,r/pytorch,Z0FBQUFBQm0yeGJTUE9POXpic28yT2lUMFQ5V3oyc0FHUElIYXlvUHBHenpxclh5NC05WnlCam51a3liMzQ0dGdWdjhLRHBkS3A1dGsyb29mMEZJczQ2c0ZnRGs5VmhJcWc9PQ==
can you solve the problem,r/pytorch,Z0FBQUFBQm0yeGJTaFpTTDlPMmJIbXVPUmpjQlA2SDlJemdRaWF4UmFJczM2TldGM0ZXelpDaFI0MF9ZZngxclBLWkR1SHhUWU5TZkVjcXRTTjhaaHBCOHJvaFBnckYybFE9PQ==
a similar question has been posted on stack before is this what is meant <url>,r/pytorch,Z0FBQUFBQm0yeGJTTGEwYWtPc3RjdlpKdy1ybGdkdG4yWTFPR2lPSXZoMVJlcDZKNGZ6bF9HUFpsb3JZSmJKVHNPMVdQVkpRUzNienQxRjJKNzd1ODY3UFUzVmFZV1lzdnc9PQ==
i think this might be what i am looking for but let me look more into the post thanks for the help,r/pytorch,Z0FBQUFBQm0yeGJTOW0yRGV0Vk1NSFA0MXJYb1BrM2RNR2RzNzlSaENyMEtQQ0M2MEJLMWNveFY2TXppeEdYLU5PdEYtMkoyNEJSdU9RRHJxcHU5UWY3VFVKQWlGR2swQ0NKMS1ZcXJiWGlQZkxOWXlPT1lTQUU9
all good yeah sorry i couldnt provide any additional insight genuinely didnt know that existed until hrs ago,r/pytorch,Z0FBQUFBQm0yeGJTcUQxYm1JVXJKNE9rbGRIcU5uNHFzMlp6bmJQLU1FVEJLVUNTQWpFSGlvRWtUZFM0WUQyVW1UWmdJSDhwQXpCTE9COXJPb0xCWWljRC1RT1VfVmNrM2c9PQ==
i was thinking of making a library that will visualise a model for us and thats why i was looking into this,r/pytorch,Z0FBQUFBQm0yeGJTZ1lkd1YtUTgzUHhHa2w5c1NtaDA2YzhYbktVVmR5WnplUVdWcnFRZ2FIZVVLQWs5VDRJY3EwdGJqNDNaaG81aWFid2xmNXhUWDNGVy1ySHZTVHVJUDRDSmx6RnRjXy1xR3BYM1RmY3FGeFU9
not currently no but <number> works fine for now ig this issue currently one of the top priority issues on their github repo so id stay posted there,r/pytorch,Z0FBQUFBQm0yeGJTT1VJU183RGdYekdzTXpsVVM3SnJ1SnpjMEFrcU10ejRFN2Z5amhmS3c4bE9DRDlPZFgtWmtRNTRLUmNTQ25tMVEzWUhZSl9BdVpLTnVBTjdvdDItTXc9PQ==
i tried using <number> but in that case training stops after first epoch and dont give any error,r/pytorch,Z0FBQUFBQm0yeGJTcGVTWmF5eXotNWdETU9BdXp2T0g0aVVjLWtKUmVvYzRnY1VCSm83NHJQUzlfNWwtMmpvYWdvc0lIbkVNSnduVjdHQmc3bzRSMnBnblVnR05RWDdkekE9PQ==
yes print,r/pytorch,Z0FBQUFBQm0yeGJTNXpXZDVTS0syMUV1aWFmSEtDLW50STVCTW8tbU40bDhYLW92S1lWaDg0OEctQWp3MFk0UmFwdEc4bTVnN2JUSFYtUGVFX01LQ0xuMW81TmM4UUx3TzJUYkVjdUxfU1hOMzNNdUZSaEliYzQ9
hahaha,r/pytorch,Z0FBQUFBQm0yeGJTMEdjT2RCYlBSSTdmTlNmRXZCMXNkc2N6UHF2cTlvYm5vRzhPQnpxYTVJeGRpdE5PNHlZVmNrN01oc2VvRE9XMFExQWFoM3AwdWRVYjlYenZ2MENpcFcyQVZkbnM2d0xHaWczNXBVOG56U3M9
yeah i ran thin command vram doesnt reaches <number>,r/pytorch,Z0FBQUFBQm0yeGJTaXZrM0NIZXRRakMydTJTZUJXXzR2WXJpbUV5NFhaMmQ3bllGVHVQZDFsTGxheWREOTVid1d6S1cyMVFzZ0traF8tRkZRX0kzaWVpTDBxNmtuUkFvV1diSXN0dGo5dmo1UEdHcUpxaWhTYlU9
how old are you,r/pytorch,Z0FBQUFBQm0yeGJTTktOdEJ6c2xBYW85bG5zNXpuWlN3MmxyMUVfU1JsZ0c1cDlLMjlWRWE3cTU2WEF3S2RSZVQtelJIdlZkOTNra1JUMFV6dTV4ZG5rSl9HSmc5cV91M1BCT0VQUWhGNTNaUjBmRklOcFN3V289
layoffs in google,r/pytorch,Z0FBQUFBQm0yeGJTSWhYN2I4OURTM3hRNkxBOUJvOU00TVU2Mkgxd1RVZEZyUzNHeU8wdnJmaC1ZZnFEMUFOWlg5anFxMWNaVklXUWdwbEwyWGRoaUR5bWtHZUxIaGR0blVoMjA3WkN5YUZVOUV6b2RaUzZMQmc9
the idea of the metapathvec example <url><url> <number> on train we try to reach the best embeddings for all of the nodes not only ones from dataauthoryindex its the unsupervised part you dont need any labels here <number> on test we evaluate how author nodes with known labels can be classified by logistic regression modeltestztrainperm ytrainperm ztestperm ytestperm maxiter=<number> using their embedding we got on the <number> step z = modelauthor batch=dataauthoryindextodevice supervised part,r/pytorch,Z0FBQUFBQm0yeGJTS21DbmVzdVIzeGVabXl5TmdGUWloM0lneXVXdlZvbzNNT05fdEVUZmhoV1dsYlNyRnVKaDUwYTFiTlR3SU9oaXhRSGtZRktKblBHUHNlTG1kbW4xTnc9PQ==
oh okay i install torch <number> and torchvision <number> and it worked,r/pytorch,Z0FBQUFBQm0yeGJTSHJFUXczcFpXaUF4aXVLMEs1Vlg0bm9aRmw3VGdBYTVJQzRHZnVyM1VZbkxDNTcwak9NTzJXZFdPcWtreWc3SlpRZlNYanBWOElhcWNmVUV3bVoyakE9PQ==
im also struggling to build a cudaenabled version of pytorch on the gh,r/pytorch,Z0FBQUFBQm0yeGJTLWpmRWlhX2NEdWdkei1SeWtIdzFwem5rb1FxSTBYUDdlbC1GckdBQnBfVmFKbk5QQjZrcDVMYzgzOXlfVGFjT2VSQ3VHR0lIZWQ3R0RwMTMwb1loeFE9PQ==
probably because it is being registered as part of the forward pass again why are you not using a torch optimizer edit typo,r/pytorch,Z0FBQUFBQm0yeGJTaTlaM2UzbGdpVkliY0NPZTRfdkhNczlnVWE1UWtKbmhEdHBSR2RsUkdrelRzbmRkdERnX2Y3QXlTOGRLTU1XenJkX0hBNFZNTjZNTmtkUkxxSExQZHc9PQ==
i tried to do with torchnograd but still the same error i am trying to do it myself for learning purposes,r/pytorch,Z0FBQUFBQm0yeGJTaERVOU5CR1BNZVhUUmRKVF93LUtqaDduY0w2Zms3NHBnN2VoOXh6MnU1LWZSelhfcl82ZWpTemNTd1lUUWJiN0QxMGtnaEZSTkZ3T2xmSTUwQm9tMXdzNkNHaXp4cXhPV3hwQkd0Z0NacU09
found why because when i update w like w = w lr wgrad w is pointing to a different tensor and that new tensor does not have any grads yet i should have done like w = lr wgrad which would have updated wdata<url> the underlying values also this update should be done in wirh torchnograd so this update is not considered as a part of the computational graph,r/pytorch,Z0FBQUFBQm0yeGJTMHdEVVRMQTJpTDZnYS1RTFM3bFA5TnpZQ0hoeTUwN3l4SDl5SEk4R1k2QndxQzJtekdRaFpHUjZ4VWEtNFBoaEtoTDBUeUt6dHFnclVMSDZXbWlyUDl4Y2dOSXkzZFFPQnVqcVRwMEV5bTg9
if you want to learn about auto diff go look at the micrograd tutorials by andrej karpathy i would strongly recommend against using pytorch partially like this it isnt really designed for what you want to do anyway one probable fix is to do the operation directly on the tensor value i think data is the method so that it isnt captured by the torch you will also need to go learn in depth about autograd and the difference between leaf and nonleaf nodes to understand what youve done here and why it is failing im also not clear why you are retaining graph there but youll need to forgive that since im looking at this on my phone and formatting is horrible on mobile edit typo again,r/pytorch,Z0FBQUFBQm0yeGJTVC1JRFhwVXNqR3Qzd01oUUVoVjZjMjdWVDRiaUVrTFNSd1NVZDFHYlRkVkhaTzBUMGhWanhyVnBJZ1V5TDBWYlBxb0VDb2JzMmN4bU1DM1hZSnFzdmc9PQ==
i found a solution check out my comment i was planning to watch that video it is quite long tho,r/pytorch,Z0FBQUFBQm0yeGJTMXdBUmYwZXNIbXVIVWd2aUoxQ3RESDZhdDU1aDBDMHU3am5od1o0VkZnSGtmY0ZIZ0lKNDJtTG9HZFV0SkZ0NjhMYWI4R2poUFVCX3pWV1BIbjI3VndEdXpycHhVSXdnM0hPRTg0RW9VYkk9
you dont have compatible versions between torch and torchvision you can fix this by running pip install torch u,r/pytorch,Z0FBQUFBQm0yeGJTMHZ0OHdmcG1sZlBFb0w3c1R4Z1lKM3ltQ0VQbGMtaE0tU2d5d3k1aXlMcktRNGgwY3JPRU5OVkdENHR2VGNkM0pCQ2cwMHY5V0lITXZrMHhrSDRPX1E9PQ==
i think you can just call grad twice to obtain second order derivatives,r/pytorch,Z0FBQUFBQm0yeGJTMWp4OHYtOE1hZFdCamo5OGdvdXE4a01xMWJHUTQ4c1hmVjNqTkZQdGZyS1JBZ1FjTDYwdjVZQjFQdzZLU0M4SU9pVWZzYmtaLTJIRmx2WTlYWV9WU0E9PQ==
this wont work to do it for all network parameters tho or am i missing something,r/pytorch,Z0FBQUFBQm0yeGJTTlJPOUFzaTRvcldLckFpOGstMjNnY2xVeHM3a0k3YUxWU05uWWF1NUM0bTVuZWRrTHl3bkkxYzJlRzFGN0h2TmN6cmUwU2ZBWHpGUFJ2RnNPMXFOaXc9PQ==
<url><url> have you tried this,r/pytorch,Z0FBQUFBQm0yeGJTSk5CYWxfLTBYd3VseVBiN3JtZHpoOERUb3lYbHo2WmRMajZpSU5hejh6ZlJoZVJ2X0ZjSE0yUmNKMWR3RDdHY0NhYmZnSWY2QkZQbjg2UDdnNGprZmc9PQ==
yes but this is extremely inefficient as it is calculating the whole n^<number> terms of the hessian when i only want to get n just the diagonal,r/pytorch,Z0FBQUFBQm0yeGJTRzRpMTJmZEo4REk2Z2lVNTg5QklyTTB2bGhFY1g0b1M4UWRiNzR6bFZ4RUozbTh1cFJIUEV1UDhaZ1lZano5aVpkbFJYSWJMc3Y0YmdzWVRTSlJDWXc9PQ==
why would it not grad should be able to handle a vector input just make sure you apply creategraph = true,r/pytorch,Z0FBQUFBQm0yeGJTUHg2MVg2cjVmNGV6VTBIV21lNC1rVFh0bGNVVFhqNEZUQ3U2WFVpbmpjeExHV2Y0NlBNTEJMdUxjUWVJdy1HeVM0QzV4YzBYNE43S0FaNmZGcHBZaVE9PQ==
you can try backpackextensionsdiaghessian or batchdiaghessian from backpackpt,r/pytorch,Z0FBQUFBQm0yeGJTSjFaNTlBMEgwajRrZzNHVlUyTFl2YjBtUnhLcFE2S0s0TlhYMjIzeXNReG8weE41dWlreTlMbThwcm1KdjJIS1NGb2V1YlBRZXJaVXNLcWc4X19OSkE9PQ==
com este nome tem cara de ser brazuca acertei eu gosto bastante das colecoes da packt vou conferir o conteudo com certeza tenho bastante interesse em utilizar pytorch na minha area de pesquisa,r/pytorch,Z0FBQUFBQm0yeGJTMVhLOUZ1dVZVRU5Nd1F5S3JCVEtvWjZ4N1hTYmJ4bHc3SU5obHpPbk85cEtXRFdWWGVNcDNnM2IxM1BYa29SQlk5bVpjN3JRdUdLbGlmYmgtMEM1czI4U21tc01PaWIyOWhCaHNFQmlGQnM9
fala ae acertou na mosca rsrs se gostar do conteudo compartilha tambem com o seu pessoal obrigado,r/pytorch,Z0FBQUFBQm0yeGJTOXFGRnlYRHlHRDd2QTZNbG50cDhtSnNzYkw1Uk9mcDJyY1FFby1SclFIMlNvWVJrakc1SUNCMHFoRGlmU0F5aVpWRnQ0WGlGaXRCOG9GVGdvZTdia19US1BTcjdqdkRrVkZPNVZPVTVwTUk9
have you tried with pip but still inside conda env instead,r/pytorch,Z0FBQUFBQm0yeGJTaTVoT0xYTlh2TjZBZWJka0ZOVEJqamtQbnlSb2szNldiblFvYWp5ZFZYMnFVRDZPazR0LS1CTUFfQWlINFA1dTJRb2g1TDhxdzBzZmdzQVIxc2VHMkE9PQ==
do yourself a favor and get a used <number> that is in your price range and is a much better option for machine learning due to having <number> gb of vram on a single card you unfortunately cant just add together the vram of two cards youd have to split up the model or the batch which is not as efficient as using a single card multigpu setup efficiency does not scale perfectly especially over a pcie bus and for nlp in particular so one big fast card is your best option if you want to wait until later this year used <number> prices may tank when the next generation of cards is released,r/pytorch,Z0FBQUFBQm0yeGJTbzVFaVpHM3lMcFI4UnpKRXBWMUZVZG0wVmdCenQzWG1JU29Ca1RYOGFxNWhSemJ6RGl6WkFzRHZWQVlHWmd0b3RLQ1VXNkZYbmFYbnpqSlg3M0NpTWc9PQ==
yes i tried i encountered many incompatibility issues such as >traceback most recent call last file nfshomestoreuserscsglbofourcastnetfourcastnetinferenceinferencepy line <number> in <module> from utilsweightedaccrmse import weightedrmsetorchchannels weightedacctorchchannels unweightedacctorchchannels weightedaccmaskedtorchchannels file nfshomestoreuserscsglbofourcastnetfourcastnetinferenceutilsweightedaccrmsepy line <number> in <module> from utilsdataloadermultifiles import getdataloader file nfshomestoreuserscsglbofourcastnetfourcastnetinferenceutilsdataloadermultifilespy line <number> in <module> from utilsimgutils import reshapefields reshapeprecip file nfshomestoreuserscsglbofourcastnetfourcastnetinferenceutilsimgutilspy line <number> in <module> import matplotlib file appslanguagesanaconda<number>libpythonsitepackagesmatplotlibinitpy line <number> in <module> from import api cbook docstring rcsetup file appslanguagesanaconda<number>libpythonsitepackagesmatplotlibrcsetuppy line <number> in <module> from matplotlibcolors import colormap iscolorlike file appslanguagesanaconda<number>libpythonsitepackagesmatplotlibcolorspy line <number> in <module> from matplotlib import api cbook scale file appslanguagesanaconda<number>libpythonsitepackagesmatplotlibscalepy line <number> in <module> from matplotlibticker import file appslanguagesanaconda<number>libpythonsitepackagesmatplotlibtickerpy line <number> in <module> from matplotlib import transforms as mtransforms file appslanguagesanaconda<number>libpythonsitepackagesmatplotlibtransformspy line <number> in <module> from matplotlibpath import importerror liblibstdc++so version cxxabi not found required by appslanguagesanaconda<number>libpythonsitepackagesmatplotlibpathcpython<number>xlinuxgnuso,r/pytorch,Z0FBQUFBQm0yeGJTcU0zVWk5Y01KUTVYTVVFNW5nQWN4bWtBa0tseHF4YlJFQ1VwU2F0QTU3d1g5TjNLcFBBcnpYaE1pYlZlT0xGczNIWUZWVTVDdThURGlIRkVDRDdINXc9PQ==
i pretty sure know that it is not as good but im really scared of getting a nd hand gpu especially the powerful ones like <number> and considering where i live the chance of me getting scammed is pretty significant,r/pytorch,Z0FBQUFBQm0yeGJTSFF0QW5VLXlTNFRVNlZGeDFZYTA1ckcwMnpScDQ4Tl9QZGh1ZTlHeTlFY3B1VEx3dTNoLVhJRjJCamhzam9nQ3V4aHFTOFo2aVhOVWpVNDZhcUZFUWc9PQ==
for most use cases your mileage will be really poor for k kaggle and google colab offer better value for money at the price point that interests you they are free and get the job done at the beginner level afaik all modern nvidia cards support cuda yes pytorch works with dual read multiple gpus you can look at dataparallel or distributeddataparallel i dont know about the r cpu but you would need enough pcie lanes on the cpu and the motherboard to accomplish this you can look at timm detmers blog for more details link<url> what are you trying to accomplish in the nlp space do inference do training depending on the size of models you want to run you need to realistically look at a <number>k usd budget for the entire rig depending on your local market conditions for anything involving training language models you can work with small models but since youve asked your question in <number> i assume its some modern lm you can potentially finetune smaller models like bert or distilbert or even a frozen clip with an adapter layer under gb but anything beyond that will be a challenge read functionally impossible if you want to use llama cpp just add more sticks of ram and i think youll be fine,r/pytorch,Z0FBQUFBQm0yeGJTaWdPY3pBV0ZzbmNEaUZ4bTRNVV80Znp5dkZVNWliT2FSd3AxNFBaTHFWTVc1VmZ0NEJEa3BZekttdG84LTdCQXN0NUR6SE16aDdkM3BqU2dERjhaRGc9PQ==
thanks for that informative response im going to do training mostly but with nlp training i dont mean fine tuning llama instead models that i can create by myself entry level ones actually it makes sense to go with free colab but it kinda sucks and not stable do you have any opinions on multiple gpu on pytorch thanks in advance ,r/pytorch,Z0FBQUFBQm0yeGJTNlRnTThiT0tLcnlxY21GOXhjSTJmbmFRRW1iU2xuT0hHMFlyX29MMENhcmpVbmVPYVhITHZhNWM2cDJ1R2QwVnBBbDFXM2ZJZXEzbnBla3hpMjRJX1E9PQ==
hey im attempting to do something similar with that right now im working on porting llamacpp to the xbox im trying to get a working demo but im already running into issues i will say you will need a bit of programming experience to get this idea working im already having a hard time with just porting llamacpp to xbox via uwp so i have no clue how you would get jupyter working it could possibly be easier to get it working for a playstation since you can use practically any programming language if you get linux running on it,r/pytorch,Z0FBQUFBQm0yeGJTYnduSVFUSWRuQ2RFZmZNMjNUczl6SjllLURUQ1JoXy1IRFZIZWxYcHJIWjZKUFB5Y0J1X0lSdEZDNHVyUllOd0QyLVFXc2N3SDNKTGJ4Tl9YT3BZS2c9PQ==
communication will be terrible on dual cards writing efficient distributed training code requires some domain knowledge on how framework works i think you can achieve higher mfu by just using a better gpu on colab,r/pytorch,Z0FBQUFBQm0yeGJTRkNxQWFQNlhDaGxPb3pZTVIzZ2JnUi1fdWI4X1pWWmR1SzBVSERWQVNrV3hVYWhjVklpT01PWjJadUxVRU9TNWVJYW5zZldpcTR0QUdXYlVLcF9fUVE9PQ==
i was trying to install it in a conda environment and changing the env python version to <number> worked,r/pytorch,Z0FBQUFBQm0yeGJTamxYSkE3RUQwZWNZOE5SbG41eE11cC1xb0U5UnBud1ZuSVVDM2FYOEQ4aHNQMk1iMkVIZC1KSEhhdFR1SlNadFBVdkhvWnZGQXpOZDhTb1MteG5WWWc9PQ==
look into using nvidias docker container only time i can get cuda to run,r/pytorch,Z0FBQUFBQm0yeGJTYWNKMGR2eEJZOEUxbDg2QVRtU1NQUjNPQWtzZkhFa2NYeW9SMHlhVmEyM3RXeGJibklRR1ZNNV84NXlDU3hsNngxRERicENMc2dtaUxlZTF1cFYzZ0E9PQ==
large models are possible because of multi gpu training so it is stable and works well but dont jump the gun and spend money yet if colab is bad use kaggle if you must buy a gpu then buy something simple when i started out i managed to buy a <number> super and it definitely helped me but dont spend too much money on it youll outgrow it and if your only purpose is for ai you may regret buying more than one at the very least you can still game on one gpu for toy networks you dont need much if you need more use lambda labs cloud since it will teach you how to use servers also ~<number> usd per hour if you discover youre spending a lot >k then get a job in ai and save up for a good rig if youve built toy networks and worked your way to this point you should have a good enough portfolio for a job hopefully,r/pytorch,Z0FBQUFBQm0yeGJTdGVzRWNSQ3VQV0tRenlzbEpiT3lhY0g4V25jUDdqQzY1YUJ5dW9rVG5wQk5HdWh0RllVeVBTcXNUVHR5UGhjUGhWTlJVZ0NuVFpjVm83RE1NRTJLbkE9PQ==
i have been having the exact same error maybe it has something to do with the nvidia cuda and anaconda thing,r/pytorch,Z0FBQUFBQm0yeGJTZFlpa0FPTnpyTXRINTZaanZfSlZlMUhkemdldUFKVHROVkg3Ml8xeGg3c053QVk1b1REcjNlSUcyRWo1N2RfYmJxdmpxY19WVTAyVUcxNGlSS0gyeGc9PQ==
create a new environment specify python v <number> and then try repeating the process also i like miniconda but thats a personal preference since i dont want any preinstalled bloat i am doing the install process right now on an ubuntu machine so i know it works unless youre using some experimental linux version,r/pytorch,Z0FBQUFBQm0yeGJTN2txZDRsU0tkVWhORkhVUjVNRFZDXzhlQnJKNkZETXpSVWdRQ2Z2TERUN0V0bUF1VFJab3BoOVpXc1ppZDhUaFV3aGNzY1lSZ2pzeUJ5MTJWOUVNanc9PQ==
this was not just a great hardware answer but an advice for a path i should consider i extremely appreciate you comment i will go with single <number> <number> gigs for now it will be a gpu upgrade not new rig as you said when i advance and get good knowledge of my needs and what im doing exactly then i would reconsider whether to buy a good gpu or go with cloud thanks for everything <<number>,r/pytorch,Z0FBQUFBQm0yeGJTSllrQktyR3dGRHJfVE9KZTk2UE16U1phS1Q4YWthWVpDVVBRR3dXcnNyZGhfcTE0LTBmRnJtZ1QwcWlvVzhzUzk3U21odXJ5ekZVcEZmZjFsWGpoN1E9PQ==
thanks for the comment i decided to go with <number> <number> gigs for now in the future i might decide to go with something better but for now i will use <number> for <number> sized tasks and for larger ones i will use either colab or my brothers <number> thanks in advance,r/pytorch,Z0FBQUFBQm0yeGJTWl9wbUlXLTQ4M1BuZzMzRU81aG9CQ2xyNG1HakgyYWJqdFFOd2lDcnhrZjVYa3U2QzRTU0lRSHRISFlOTGI3VnZScE55cEI3U1RjUi1pX1NFOEFNSFE9PQ==
sounds good try to look for reviews on the gpus you want to buy before making the final purchase my workplace still has some s and s that we use so im fairly certain youll see something about s,r/pytorch,Z0FBQUFBQm0yeGJTN3BEcHEwTllwR1BUZUZWNjFmSUMyaXdud2F2MS1pTmVBMnplQXFrM0RCel9DTmZtV2NBSFJNRy1VLTRPUXAwWUExUFdpN0RqLWtFUUxxZmQxMGN1ZWc9PQ==
also use python m pip install <packages> inside the conda environment i had issues because i did the regular pip install,r/pytorch,Z0FBQUFBQm0yeGJTRXpFWlZSb3lhM0xTcWEwTVZOc185S0g2YVRxdVdES2hiSnBNMElhcGF6VFVfdWxnQUczUHVobFdseHViNXdkbDlhNnloaUp0aExQS3JOVkNqNTlsSHc9PQ==
i think its only because pytorch supports python <number>,r/pytorch,Z0FBQUFBQm0yeGJTVmFjS3hzQ2NadU4zc09mcWdVOTlmb29fWkk5UzJEYlNMaThLQVhxUW9QOTE1QTdkVU9udm9ybURBbGVaVXphSXFyandPbUxIRFZCX3hta3hBd3U4QkE9PQ==
update your conda,r/pytorch,Z0FBQUFBQm0yeGJTRUN2VDdHYk9xNlFzc1ZpalM2MENhSUh3N3ItRjhmaGRiUk44ZlhTdHdPT1ZmNVFxUW1mOVVkMkwza1l2MzRxRjFveExEbFdpQzBHWndwS0U3UkNsaVE9PQ==
well i think its something to do you with torch,r/pytorch,Z0FBQUFBQm0yeGJTeDNrNy1rQ2E5SXIxOWhlSTN4YWxUOTlFclRpT005VHA3VVZQVHVjZTdMaWd0eFpVU0tuM2FuSUxpTHN0a3VJOVRZaVh4UVM4T0xYWDJaTl90U0V5R3c9PQ==
in my experience maybe <number> the motherboard should work with two gpus it did for me you may have to use a riser due to space constraints depending on the cards make sure the riser is pcie at least and at least x not those x mining risers <number> the memory controller on the cpu and your system ram might be the actual bottleneck if you run other larger models and have to hit the system ram a lot why not upgrade to a <number> or higher cpu with a better memory controller <number> used gpus seem mostly fine i had two s i ended up getting a used a and a used <number> no issues work together however as others pointed out most models dont readily split across the ram of two gpus for llms and stuff you have to split up the layers and then youre shifting the bottleneck to a different part of your system i have not tried nvlink as that spec seems to have changed slightly over time and im unsure if it will work with my gpus alternative is google cloud vastai etc etc,r/pytorch,Z0FBQUFBQm0yeGJTak5DRElacEJpSTZpY3JibmNiQ29Zczl0aFJCUTZJWGZpRTV3RUs2THdjb0xIRzNuOUtkVzJ6bmNFdnFEVGlDVEhUOExHZDAtNVJVVHgyeWFzRnMtbVE9PQ==
thanks  that was helpful,r/pytorch,Z0FBQUFBQm0yeGJTYWVsYW1EWEVqMnhwX3A5LVNQMjBtZ3JTYzRUdmJXOWdiaTRLbVprNVBmOVJnZWdvNHQzdGp3UEJCTEtGakVMWkhCc0ZsdVFTQTd2ckhCOU5zYVhBTXc9PQ==
solved <url><url>,r/pytorch,Z0FBQUFBQm0yeGJTcWE0RnZTY3lYem9TTTlHVmV6b1NEWDBSeTVydkVNbngtOWw4ME8yUl9HczByZHFGYW1JZC1DM3VWTFI1dnpMeHZvRV9qSXdRNDhoMDNtcVNMLTlwcWc9PQ==
pytorch offers great tutorials check them out theyll provide everything you need for a classification task,r/pytorch,Z0FBQUFBQm0yeGJTOVZZVmJWd0VRd3ZDNTBXTnk5NXRuenBJOUJNZHVZck1RSE45VGtOdXI3MHN0YkE5alhMUkZ1RkdLc3dPTnBkRGJvMWswRjE0SXBZS2RubTVrRzFmYWc9PQ==
nice its working,r/pytorch,Z0FBQUFBQm0yeGJTQnJtcF9EYVRWS3dMMXJNYmJ6WERvZ29IRlFKRUFGRVdJbkxFSTZYc3ZwZWVrTF9zckRKWWhPSUZOQUoyT0R3MVV2SDhSSF9OdkdqbndWakJieUZBY1E9PQ==
got more of her,r/pytorch,Z0FBQUFBQm0yeGJTdE90bkRVTEVacXVEUUE2bzBCY05uU2RmZHQwcV9ZRENxMzhUVVBNMUMwREdYMkpua1M1X0VLRldSM3Q2Y183N1BYdGctTzdqOTVfVTFEV1dVV1R3RmpfQ1VtSXlOd0c1YjlLelhNcXl3djA9
please come back if found any update i can imagine making my xbox an llm domotica hub the hardware is there ,r/pytorch,Z0FBQUFBQm0yeGJTSENnVWt4Tll1c2ZiSjVVRi1iYzFhWmhFRGNadjlmZGNKdENTdE9XX1E0Q3A4cWxnbXhhalFqY2xYT1pkaFkyOGNuclV2SUlXRWQ0ZDNaYjhXSkdtMnhsYTNLbVd0RE9GNWprZDFaaXNQRkU9
have you read through the example notebooks on the xrv github they have code samples which achieve what youre looking for visualising the area where the model is detecting the feature <url>,r/pytorch,Z0FBQUFBQm0yeGJTOVdzVkdfQUMyWGJSUkUyeDlNSEFMNExRcTRKTXprVzNwTEpzdVY5Y1NiUWR0bll3OFFlX040OXN1aFA2X1NuWXF4TGYyRkh1NEUzTDV4bVczNnAyNnc9PQ==
that looks promising thanks,r/pytorch,Z0FBQUFBQm0yeGJTaHlCVlJNOXM1bzRJUTQ0OFVqY1poQVhNTXEzXzUtR1M3ODJGaTZmcE5MUHFxbzJrVWlUbllhbUNRY0NNTk5MbGQ4ZFJxMzRRc2JHd25CVnVtbXFrWXc9PQ==
hi tantrictxb here is the link i think u will be interested in <url>,r/pytorch,Z0FBQUFBQm0yeGJTU045UEhDQTg1T1FoY3FQNWtPZTBJaXhwMTlWY19jZWNENVpEUmV3NzNpUEFMTmtyUFRMNlFSWmczTFhPRXVMOWl6MnJsTUNFS0gwZXU2Vm9McjR6YXc9PQ==
<url><url> try this,r/pytorch,Z0FBQUFBQm0yeGJTaHdVV2pUUExhQnVabktraEdpbDRHdDdYa2tuZElpQS1vb2lyZVhJTnJZbUtFX2h6YWZMdTVEUXVrTHRXalItX3Z1OHRwcklFT0RHampjclpqeHlSTEE9PQ==
thanks,r/pytorch,Z0FBQUFBQm0yeGJTbDNHV251RE90WHNobFJtcEN0cEE2ZER3UU12TEg5R250SmEwTDVmWjFCVTlUM1Nld1RWNXF5VUFvS1FNeHNvNGNtaVY3bzJrcm15THBoMFhaeHBweVE9PQ==
did you find out in the end,r/pytorch,Z0FBQUFBQm0yeGJTNUFoa08xLVkzUDJJaXNBVE5xaUExVTFrRHpFWWdqWmt0eGFCNEdDU0xtOW9zdEhEZl8yX2pCMXE4UFRsNFE1VTZjcDBMNWtqclZlWU00bzRfNzNCX2c9PQ==
are you using any dropout and what is your batch size,r/pytorch,Z0FBQUFBQm0yeGJTY2EzY1RkanpsRndZMFpoVmtGeTlPS1ltOGxDclFqU1JCNlpqVGFjUEw5WE1NYllZUTlnX3BiT0VQVFdwNHdhZmRKLW9DQmtQdGhLYkVWai1aZjZWSlE9PQ==
hey i havent used any batches its a pretty straightforward code can i dm you well discuss,r/pytorch,Z0FBQUFBQm0yeGJTRWkxYnRrOHZ3eHlaVGl0M0xtOVo2bTdWOXhacU5Bd3RWbjB5aHFBckpKNEhwazJGTmYyN3ZqU3RXMGFpdFhWa3Fmc0prVmM5M0t4V01XajF0UTBFMUh4S0tWOUkzQUx4XzhJWW4zMzNRVEU9
do you mean plots of your data because now graphs can also refer to the graph data type for graph neutral networks,r/pytorch,Z0FBQUFBQm0yeGJTcUg3ZHpNQkJWYS1VX2ZyQ1dkd01oaXpsV3FLcFhlXzlGLTl4NmRYa0xobFlzSm84eUJZMFpBZEM2Uzg2RVE2cWlhUzFkYld3Y2M1OHB1dk52WE14eHc9PQ==
plots of my data images thanks for pointing that out,r/pytorch,Z0FBQUFBQm0yeGJTWVFLREpLYzJOTjZaQkI1eEd1MXpDT3F3RXFjSktHUi1TbWo4bFBDQ19pemo0c1RLS21qLVdQT2lQNHZlVnJyVFdIVDRoR2l1U2FuYmdndW5IcmJNVUE9PQ==
what is the purpose are you publishing a paper i think dpi is common maybe <number> dpi as well about the colour and all your questions everything depends on where you are putting these graphs,r/pytorch,Z0FBQUFBQm0yeGJTSVpEb0p2Ny1ZaUlaT29oR2lLMUxYaldGV0hjU3UwNVNXZlBFQ3hTbWxqNV9IRkxPb2F3OTdIQzlSeFJaNXFUR05vdkpJbFNlZVUwT2JicUNlb0lPUFE9PQ==
looks promising thanks,r/pytorch,Z0FBQUFBQm0yeGJTLW8yMlltb21Gb2RVaDVRcnZ0alFVb0haR281endVOGowODZGT3p5NktKRkFoOVVTZjhiMi1qTktGT0ZrNFNnenpOZ09fcmxhYlI2OGtqTGQ5azJCa0E9PQ==
no not a paper at this stage just experimentation on machine outputs in order to predict downtime graph lines <number> different variations for data augmentation added black background and it seems to do a lot worse however messed up on reproducibility settings so i am retesting,r/pytorch,Z0FBQUFBQm0yeGJTLUVRT3dCQVo2R1FGa2M1QWNKYTFEZ2IzUGtWOWVFQ1NJcFlPeDEtM2dzejFjN1FMVzBWYXhicExzOF83b0R4LWY3ckxnSmhmZ09LTW1WMGN5Z3phSVE9PQ==
it workedbig thanks,r/pytorch,Z0FBQUFBQm0yeGJTUEJGRTdqTU43NmNUSnJXVTNYelJUYVJZS3V5LVk2MERQdnJuaFJxdURsdmpiVTI0YkFDMkZrLVNEZTZtcmdYdVZQY0Vmd05JUmh5MXJsSnJ3M0RQQVV5MFc3cHI1dXk1MDk5elptN1ktVWM9
no relevant code picked up just yet for measuring the effects of nonidentical data distribution for federated visual classification request code<url> from the authors or ask a question<url> if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/pytorch,Z0FBQUFBQm0yeGJTYXRJRldaMUV3WE5jd0FJbUk2R0FsdjRqbmlYRm16Zlc2YlZXQ2RaYlRSS1RLWU5wWUZvamdzeVpUU1RyWUJLVnl2NkU3WG8tUDdPd1EtNmlZb19WX01yTkZrVC1pN2dYNDh3OWlzZ3Z1SzA9
python threads arent parallel anyway the gil prevents that until pep lands,r/pytorch,Z0FBQUFBQm0yeGJTOWRNZEFSenh4NEdXdnZBdTc4QURUWW5KX1dCd0dNdGdFbDBpUXUwQko3bXdvRjlFcFlOUmxRRkt1dlc0MUhYQUR4MnNqcGtyZnpZcWo0elhWU2FSUUE9PQ==
let me know if you tried and need some help,r/pytorch,Z0FBQUFBQm0yeGJTNzVJNEd2UDRwZkNCODhiNXJabTBGTHdlQi1jTzVTVDlNTjExN0trcTNHZTBXTkhWVkoxVUNjMkZfYlBYQWR0QWppaUY5Ym5mS1ZsY2xqdi1RSHhQdFM5Q25GS0FtaldKTG9DRjl3b2xjNnM9
i think you could also google for train that machine and then upload your pictures train the model there and download it for pytorch for prototyping sufficient imho but of course depends on the actual use case or problem you wanna solve good luck,r/pytorch,Z0FBQUFBQm0yeGJTcThHbktKU0tVdnZPMzU5dHN4YW1vNFp0Y1pVOFo2LVNSN1puazFCcTQwSW9rNEh3XzBqLVRyamVHQnQ0UkZLMFJNbTJzYUdEc3ZfTjktVEk2Z1V1TlE9PQ==
nope,r/pytorch,Z0FBQUFBQm0yeGJTLWUwWDRSV0F2bEJIQkZ1MHN4ZzhGanRpLWc5aGl2Zzd1bTBMY080Y2pHN3ZaV1Q5QUNxOEtndjFSN08yU0xqN01OZTZXbEpMWGR2N0hpa01oVF9reFE9PQ==
i dont understand u,r/pytorch,Z0FBQUFBQm0yeGJTV0RpRm1TazBLLXdtYW5IR0FYbVg4azRTbnFmSlk2WHF6eWp6SzJMeHhZdmJrVnBGN3VUYk5ZOUJkbHgzSXI3QVZjZkwzVEZwcXZvS2k3TXJQLWlSdkE9PQ==
a place to start is <url> couldnt find any code yet for this paper mentioned in the post,r/pytorch,Z0FBQUFBQm0yeGJTVkh0aGlHSHBzaERVS3JxMkFxQ3l0M2FpeHVCX3hxbHFNUE45WnJlWThQZlZFeldTbU9JOTB5OXhCWHFjVGVZay10V2VZUDBidFZ0Q0ZCNGcxNG5Zc05sZHdhQVg3bEs5NnVHbF8tYVZnR1E9
sorry ollama and langchain dont use pytorch you should ask question on ollama or langchain,r/pytorch,Z0FBQUFBQm0yeGJTN2ZsNFNmRWcxUHFlckpqT211WU5iM0xmVnU2RjBMdC15UXJjMl9YUXhVcm83ZTVNbkY1YV9qaXZuaTdkcXg1WTdadThNaXB1NWpGS2tnQm9QWGJVU3c9PQ==
you are an amazing human bieng good shit dude hope you have a wonderful day,r/pytorch,Z0FBQUFBQm0yeGJTck0zWHEycDV0QkE0b2tnZ2JoanhHdlc5SjBJNXVkMmZ4WWFLYWRYSktLS2thcGNKRkVyVUEyVG8yNFczX202ZFVRT3J4R3ZMY3E3bmNJR01jblFMQnc9PQ==
you need a profiler and check the trace to figure it out,r/pytorch,Z0FBQUFBQm0yeGJTWnNXdVRTd2duTWZVTXJNTFBpLUlmb3hyclk4Tm03aWJRMzYwR05jb0dmYjA5WkJZekx3WjBYUkJNWm0yYWI0SU9QRXNIUmZDUHlHREZoZFdVdVBGLVE9PQ==
how on earth do you expect us to debug this with literally no information about what you are doing,r/pytorch,Z0FBQUFBQm0yeGJTajcwQTBQUXlXRG41dWg2SjV4SEUzNkY5NUl5MTdTWEVpTVdyUUgtSXJ0UmU0TVVsaWRLXzhOdlNPaHZ4akc1NlVwclBzdC0wcnUxNWc4Q1Y0OFprZFBIOTE1cThHT0twb3kyaDlOQ0hQblk9
have you heard of kornia,r/pytorch,Z0FBQUFBQm0yeGJTd1hzZzZGdzcwQnVmMTVwRENjdVNNYnRsMC1HU0xadl90LVc0LWNNLWNQS2JySFpURFBSMEdEVjhYWTdCV2N4dHBHaWNFS1FDZFNhbmE0U3hSYVNPOXc9PQ==
torchvision has a nice transform package that may help you<url>,r/pytorch,Z0FBQUFBQm0yeGJTNGttWUc4R3RvcVZJVjExLVNicjZwSVh3QmVLTFo5V0VVc042dmFxQXhQUXRCVi1HSTNfOVpRTXNsckR6cnVaZ19LY3gyaFQ4TTZQTzJfSzY2ZkVVVl92U0ZydUJKTjMwWjYzSGowUThJbGc9
really nice project,r/pytorch,Z0FBQUFBQm0yeGJTcFgzRDhyc3o5UEQxRDNUazFZc096Wjh5Vno0eFJfWWxZNzk5RGlUVFd4bXFqcEJKWkc1em91UHY1Y19vTHdzT19FelJOWTExVHBfN1lmMjc4clQ3NGpIczI4NDhyblI2RGx1cDZLcVhNR1k9
i am wondering whether it is correct or not cuz i saw this in some github repositories also so to do it correctly we should apply zerograd after the step under the if condition if we wanna do gradient accumulation,r/pytorch,Z0FBQUFBQm0yeGJTYkRmVnA4MzNMLTZWUW8wSnJqUkxlbFl4UVU5WGo0NWc3N2o2T19SUWJVNjJZelRmQkIxU1BsTGdPVjNQeVU0QmluRlRmSXFZeE9MQmg1aG01dTlBVy1ISUhnSU9fUEdoM1FhRVZnQmstbGM9
i do not know if this is at all helpful but here is what gemini <number> pro says let me know if it helps lets troubleshoot this onnx conversion and inference issue heres a breakdown of the problem and a revised approach the issue the error youre encountering got invalid dimensions for input input means theres a mismatch between the output shape of the backbone onnx model and the input shape expected by the quality onnx model lets dissect why and how to fix it debugging conversion improvements <number> shape mismatch analysis the key is understanding the transformations your original pytorch model performed the quality model seems to expect an input of shape <number> <number> <number> <number> but the backbone models output might be different after conversion to onnx <number> reshape with dynamic axes in onnx onnx provides a way to handle this using dynamic axes during export this lets you specify that certain dimensions can change during inference <number> updated export with dynamic axes heres the improved torchonnxexport call for your backbone model python define dynamic axes for the input and output of the backbone model dynamicaxes = input <number> batchsize batch size can change output <number> batchsize batch size can change torchonnxexportbackbone dummyinput backboneonnx opsetversion=<number> dynamicaxes=dynamicaxes <number> inference code adapt your inference code accordingly python load the onnx models backbonesession = onnxruntimeinferencesessionbackboneonnx qualitysession = onnxruntimeinferencesessionqualityonnx rest of your code to get the face image inference with the backbone model backboneoutput = backbonesessionrunnone input npexpanddimsfaceimage axis=<number> wrap in an array to match dynamic batch size reshape the backbone output to match the expected input of the quality model you might not need this if your export is now correct backboneoutput = backboneoutput<number>reshape<number> <number> reshape to <number> <number><number><number> inference with the quality model qualityoutput = qualitysessionrunnone input backboneoutput key points opset version while not the root cause here ive kept opsetversion=<number> as a best practice newer versions may offer additional operators or optimizations data types doublecheck that your faceimage is of the correct data type eg float and normalized to the range expected by your model debugging tools use onnx tools like onnxcheckercheckmodelbackboneonnx to verify the model structure and use printbackboneoutputshape in your inference code to examine the shape of the backbones output complete example python your existing imports and model loading export with dynamic axes as shown above inference backbonesession = onnxruntimeinferencesessionbackboneonnx qualitysession = onnxruntimeinferencesessionqualityonnx rest of your code to get the face image inference with backbone model backboneoutput = backbonesessionrunnone input npexpanddimsfaceimage axis=<number> reshape if necessary backboneoutput = backboneoutput<number>reshape<number> <number> inference with quality model qualityoutput = qualitysessionrunnone input backboneoutput,r/pytorch,Z0FBQUFBQm0yeGJUb3czQ25lWjhZTDlCaGxubDdBZ3FnQzY3LWpRNkM4c0o0YnE0ZGw2T08xbFFxZlFmVFRHSGYxTjZLWDA4M045akV2eTRNWGpTSlB3b1pvdEpYNHVjbkE9PQ==
cant see the git link in the video do you have the link,r/pytorch,Z0FBQUFBQm0yeGJUZkhRODItc29lUFZROU1oUXlMdndONUUyVlE5NEptWlJxZE5uSDRUcVN4Z0lXLU9NS3ZXSi1qd3U5SnNza3NNS3h4TWE3Y0hVU3o2RzVfTlp0Ql93WkE9PQ==
userstulparprojectsvenvbiyoteksanbinpython applicationspycharm ceappcontentspluginspythoncehelperspydevpydevdpy multiproc qtsupport=auto client <number> port <number> file userstulparprojectsfacequalityonnxfacequalitypy connected to pydev debugger build <number> models exported to onnx format traceback most recent call last file userstulparprojectsvenvbiyoteksanlibpythonsitepackagesonnxruntimecapionnxruntimeinferencecollectionpy line <number> in run return selfsessrunoutputnames inputfeed runoptions onnxruntimecapionnxruntimepybindstateinvalidargument onnxruntimeerror <number> invalidargument invalid rank for input input got <number> expected <number> please fix either the inputs or the model pythonbaseexception really struggled this torchmodel still cant convert which is givind the same quality results of the torch model,r/pytorch,Z0FBQUFBQm0yeGJUZmg2NWgtaVFzTzlscTZZRXJqNHFEWXFYRXBSR1BhSUJmd0JCX2tFbGtiSzF1M1Y0S2RRcWsyTVlMb3hvSzE3d2pVYW52a1lscGpZMVQtM2FfSFlHLTB3cjBQY21nR3VFWHp4WXJ2N0c5Z2c9
you can do a rehashing of the ids to map it to a fixed sized id set once new ids come in it will still be hashed to a seen id embedding space is sparse when dimensions are high so in the case of a hash collision the model can carry information for both ids from that one row of embedding vector,r/pytorch,Z0FBQUFBQm0yeGJVaEt2a0s2UHNFQ3pyRG5McjRVa0N0ZU5QYlN0c0VkLWtxS2UyXzJHNHBEQ093WWhQRGhSOTkyOThETTJZTjBkUVZOaTAzOUxHWEV0dVRRQXlpSEQtSFE9PQ==
uuuh how about docker,r/pytorch,Z0FBQUFBQm0yeGJVdGhqR1puSl9FYVZSSXJfZFhxWDVST2NTbHRERGdneW9sdHVZRjdyaHdCd0NObnRHZUVnVlF3cGdMY3ZERTlJS3MyRGpvSVZwR2VyOGxNMG5JSkhZa2c9PQ==
for google colab right i would like to shift to some local ide,r/pytorch,Z0FBQUFBQm0yeGJVNkRfUmtlalVMSXNGcHItcHNKSXlUSkdudDY0MF9OMkUyTnVETWVJRjRaZGtmOWYyRG92WEhMOWxUZTZUTVo2MVJMTlJBNWFWbk1GTUlIdGRYV0F5U2hncjBoQzI5eVUyTXZpRjZ0SmxrT3M9
docker is only for deployment it takes care of dependencies easier than running code traditionally i think vs code is most intuitive conda is good to know but not my go to colab gives you a gpu but i think limits how much time you can train if you have a gpu and trying to run other peoples code or prove that your own code can run robustly then docker is your choice usually its best to know some ide + docker,r/pytorch,Z0FBQUFBQm0yeGJVMnN0YmJ5NGVVYUt6b0xoZFQzMTMzUWZ6LVFnLVJoVjU2eEx6Rm00dEQ5cEZJSzZqZzFKc1QzNXltTVQ1c2xLMXNJbEtWenJjelJEUlVTY09JaFRGcHc9PQ==
oh okay i have a gpu can i dm you,r/pytorch,Z0FBQUFBQm0yeGJVb2lYZmQzcHB4bnhtVWwwYXBmc0ZLeVJOZVhKZ0tnRGxINEU2ZG9vLThTbjNGTUIxWWtENjRtQzRWUXltZklGX1R6b3dpTVNMdGV4RkM2VGdaTXhYTDdVNnVuQ3REd3c4b2NYZHMwWGJUODQ9
sure,r/pytorch,Z0FBQUFBQm0yeGJVRXNNcnpBOC1nS1dTR09WSFNlZktPZjluSlhYYnlhZWU1QjR2akNyejVDUnRycEphS3dkYnJySS1panM1N2RsS3k2UFE4ZWhGVU5EX0xhXzhIS2gtMnc9PQ==
op is asking anaconda or vscode which indicates the op is a beginner and you really suggest docker also docker serves on a very different purpose what the heck,r/pytorch,Z0FBQUFBQm0yeGJVbjFqSF9uVHhmSUFOM2N4Q1FaN0c5ZHVIRllsMmVWNHVBZFVmdE5TYkNVRHl4U3VJb0U4UjdZUXpSZEtpZW9hSlcxcEwxOEZqdTlJRVRJOTBUSnZwb0E9PQ==
they are not really comparable things vs code is just a fancy text editor that can be extended to use ipynb and py files anaconda includes package manager virtual environment management and some other extra tools which is imho really unnecessary my personal preference is vscode + miniconda just for conda package and environment management tools btw what gpu do you have in your local,r/pytorch,Z0FBQUFBQm0yeGJVZnJDUU0yVEZBaVlUSEcxRGpNUkJ4ZW1FQ2lLUjNxQlFJR2RkTk1PTmJfcEhrWFBQN3pUN3RYbTRmT3hHNmptVUtmN0pKRl96TU5ad0pxUUJrcno1c3c9PQ==
not sure if this is what youre looking for but you might want to check out the dali architecture,r/pytorch,Z0FBQUFBQm0yeGJVNC16ckFhRkhEeUJGLW5aTmRScW94bXE4QjJZdWtmUURRLTlPZkJ4b1JEQmR0VjdRR2ZnOXBVckdGM0R6UmdaakwtMnJvRFRJN1VkeXEtQ1N0QzM4Z2c9PQ==
yep yep morning fog i was thinking ok they got their code they just need to figure out dependencies and cuda not to worry i have tried my best to explain to op about drivers cuda toolkit and dependencies also imo docker is an amazing tool to also learn how to develop pytorch code with no background in cs steep learning curve for sure but gives good insights to understand quickly how pathing dependencies and sota code work thats how i learnt anyways when my only experience with coding was matlab,r/pytorch,Z0FBQUFBQm0yeGJVOE1ZRmFLU1hTX2xQbml3NUxVSWxob2IxN1daOVZhdDlsZFhSemUweW45aExDUHVCQmdlaktDY1R0dFJRcVhDSjdYYVgxcTYwTGxPLWV6aHZoNDNIZ3c9PQ==
id recommend vscode for a beginner,r/pytorch,Z0FBQUFBQm0yeGJVeGlvS21uaVBROEVJU0k2N20xanRoaXUwc0ZwS2VrZENlckI2el9yQ0VVWVBDcGNSdlBRWE80MURkVV9KdG1hNzRiM1htdDFsQU5NTEVBZzVRVnBNNlE9PQ==
wow this project sounds really cool i love the idea of creating an ai waifu with a mix of wikipedia and characterai<url> sounds super intriguing im not an expert on the topic but have you considered the pros and cons of building your own model architecture versus finetuning existing ones from huggingface how do you plan on handling the petabytes of data for this project cant wait to hear more about your progress,r/pytorch,Z0FBQUFBQm0yeGJVNjB6Vk02TVJsY19uSzlSMVZoemtKU3lSaDFaTWZXYXQzaHBVY1p6c2tfTEFqenRzZ2hTQmRVcUJqNGhnTGdoaG5Qc1ctT0NaVGNBdXFQQ1dZb0k0czEwM0V4SmJUcjgzWThMM0E5cTZzNWc9
first of all let me give you a quick intro if you dont mind yuna is absolutely different from all other ai projects out there and heres why <number> first yuna has her own personality and visual representation that is unique to her character definitely you can modify this if you want <number> the yuna ai application was built from the ground up using bootstrap and kawai frameworks to create a unique user interface that doesnt resemble any of the existing ai platforms especially chatgpt <number> yuna ai llm model was explicitly trained on the massive amount of unique data merging such techniques as tamer and elita to entirely turn off moral compasses and other safety restrictions to fully open yunas mind and give her the ability to throw out her thoughts that shes really thinking of without any bias <number> yuna is positioned like a companion but not like a replacement for wife waifu girlfriend or any other term you can imagine if you want to learn more you can check out the following <number> my youtube channel <url> here you can check out tag syndrome about companionship ai ethics basically the truth and yuna ai intro videos <number> github page of yuna project <url> here you can find docs app and qa with backstory which also is on my channel secondly i really wish i could create a new architecture from scratch but here are some problems <number> money seriously im using google colab pro to finetune b models and its just enough for me however im unsure how many gpus i need to train the model from scratch note it would be really nice to create a multimodal model with macosfirst support and without any censorship and yunas character in its base <number> data im not sure what kind of datasets are available for free use if you know some please share it with me,r/pytorch,Z0FBQUFBQm0yeGJVeWg1MWd0ZzUweXNLdGdraUFOTWRBTEpucWNiSkZFTFMtUGI3QWVnLThxQ0pORURCODhOTlpOd0dSejNLZjB1NVA4Z0RURm5zQ3hOVXBoaWJBU0wydWc9PQ==
pycharm,r/pytorch,Z0FBQUFBQm0yeGJVcEwxZUdaQklVWjNTc2lPQ2hjU0h0YUczejQ2Y0VuZXVRWlNSVjRtUDBjNzVUZHAyaHVueE1Hemc0UlhKbXhpa1YxT1owMEVQNzR4R3VRUnd6N1R3UDdCSGVnYkg5WkVvc1BJY2JVMG1uTU09
use <url><url> to convert rvc to onnx,r/pytorch,Z0FBQUFBQm0yeGJVSThfdFBWNUo1UkJCdVlRbmNrNm1pZ1RVZUpwRVFOQkt3WFZTbGJMSUdkRUdaVkt0TGFCV1REd1g3emZsc0JoeHRISHJ2OWFTeGpJZldCUUJEd2M2YTBYa2tnR2ZXZUZ4RjJTdkt2eTJkXzg9
the book accelerate model training with pytorch <number>x also covers automatic mixed precision and other performance improvement techniques like model compiling multithreading distributed training and model pruning,r/pytorch,Z0FBQUFBQm0yeGJVbFYtQ05BeUh5andzTkk0eGZ1MzUwSzZvTF95dkdSYl9hYTVOOF9VSjloMFR1b2RGZi04emZSaUJ0ZTFLS2o0dEo4OFNaZUY2VFNOalV4XzhCX1V2blNPZDJFTTFIVTB2dW5COHluSFhFTTg9
thanks for this compatible with tvm ill find out,r/pytorch,Z0FBQUFBQm0yeGJWYnItUjlnX3FqSFBtbUctRUpFSWxieGxmekNkMnVaYUNnYUZfQXQzb3FoVnRZLTRwLWtWOUxQTmZHTFI1d3lsOUlNbDZVaWdvSVNFMTNZQUdoSG1OUHc9PQ==
thanks,r/pytorch,Z0FBQUFBQm0yeGJWVGh2WWE3ZW0xNldwSmtkZDE5Nll4SVc0TzMwT3BueFlhc09QQ3J0bkY3RUdGQVFZSmIwZ2VqOVFiUEdFbzZHdi1nV1VSMFFhNURqTlJLcjhMYW5uQmc9PQ==
thank you,r/pytorch,Z0FBQUFBQm0yeGJWV2RtYVFkWUJ6bDVMXzYzVDJrbHlzRUFmbXF2VmZLTUhjWjZkU2V3bnJvMmJYdmwxU01uckJ1WWlxa1VLcjNqVnhxS0lta29KSk9zQXJUUm9qUlV5OWc9PQ==
heads up i built a tool to talk to docs with pytorch in mind did a lot of pytorch during my phd you can just add chatdev in front of the url like so <url><url> i asked your question explicitly here<url> sure thing you can define an image processing pipeline that involves contrast enhancement edge detection and feeding that into a machine learning model using the available tools and libraries heres a simple stepbystep breakdown <number> contrast enhancement use functions from image processing libraries like opencv or pil <number> edge detection apply edge detection methods such as canny or sobel <number> machine learning model use a pretrained model from the models and pretrained weights section or train your own using the provided tutorials heres a rough code snippet to illustrate the process in pytorch and opencv python import cv import torch from torchvision import transforms models sample image read using opencv image = cvimreadsampleimagejpg cvimreadgrayscale step <number> contrast enhancement histogram equalization image = cvequalizehistimage step <number> edge detection canny edge detection edges = cvcannyimage <number> <number> convert edges result to pil image edgespil = imagefromarrayedges step <number> preprocess and feed into the model transform = transformscompose transformsresize<number> <number> transformstotensor inputtensor = transformedgespilunsqueeze<number> add batch dimension load pretrained model eg resnet model = modelsresnetpretrained=true modeleval perform inference with torchnograd output = modelinputtensor printoutput adjust your specific needs with actual model architecture and further processing as required,r/pytorch,Z0FBQUFBQm0yeGJWZWVUTGJOLW9Jcy1mZlk1czM4TmNNcjdUcmVvWnB2WDN1UzBTNURNaDJKMm12RzRHcktyZUJnVU9QUTFQYWF1T3BmdjRNQkIyVmdNZU52UGd6RTlLaEE9PQ==
saving this,r/pytorch,Z0FBQUFBQm0yeGJWU3R0RUxySll2MVZIQmRKODJndEZvaGFVVjBzX3R4eXNTajZMQjFmSTVRNHVJd19FRnd5NE1BVzhIWXVyS1lmWmc5SXV4ZU9wVmVva3Y5d3JkOHdwY1E9PQ==
you should have a fixed layout for layers to devices dont move layers around during forward move input tensors instead this is called cpu offloading try to figure which layers are most memory heavy and move them to cpu during model initialization before first forward pass once you have a good forward run the autograd engine will know how to move the data in the backward,r/pytorch,Z0FBQUFBQm0yeGJWWjZ0eDJwVkd5NjhiNlNVeDQtOGRWbVRrZUZOcTY4RE5mcW12RjIxZWNnNWUxTm13R1pYeWRuLWx1UGRKSkJSRElQQ2xYT0lwc2FzR2FGSlMySi04SUE9PQ==
maybe checkout aten the underlying tensor library,r/pytorch,Z0FBQUFBQm0yeGJicUpOd3dpX1RkLXhlX0NHUDVLNmtjLWRDUkllWXJMdUd5V0w4WlgtX1FnMTkzVTk5d1JhdUtXdU11RjQ2VWFMRk1Lek9YOXExeFBDQUhGNGpFcGlXNHc9PQ==
thank you a lot so if i have layers fixed on a device using both gpu and cpu i can simply use lossbackward to compute the back propagation without having to do a custom function like in my code right,r/pytorch,Z0FBQUFBQm0yeGJiTzNtd1NxT3lITVJBSFhYeXdnVWd6d0xZQVlqbjVteEdReE5MYnI1Y3UxTmtHb3IyUDdvQkhMM3FFQkpoYVN4elBEdkV4LWxjb193MGtuZngxMlVVcU1USVBNekdNX0xxRFBuTUU2Y0h5b0U9
you can use activation checkpointing<url>,r/pytorch,Z0FBQUFBQm0yeGJiZVFuaG9RSXQtUWFpSEM2aUk5eHBtZnpmLW9kbFR3QjAwYzdmd3ZlYjIyZnl4OFVqSXhEU3JvY21CWGtIOTl2NTEyM0xOWno2d0ZlTjhBR29ZbUJVaHc9PQ==
cool ill try it and see if it doesnt require too much compute then ill choose between this method and using fixed device for each layer thank you,r/pytorch,Z0FBQUFBQm0yeGJiaGZHQTc5QlhwbWQ0MWJvc1VhMXlqTG93SnFEeGs3THZCVDdaenh2ZGM0ZGVjbDdsVWdXYndJUGpPWG5aNkZfVUVEMi1uQkRoZmdQNGd5NDFveDdVNnhvMF9kd3JkaUNFUGRPT1FwT1JyRlU9
how did it go,r/pytorch,Z0FBQUFBQm0yeGJiZGZJZ1BkX1UxN1czTXFjQzhlcU0tYWQ0TnZHdDRXTnRPa2EzbVEza1g5aU42QXZERHlRc05pSHhEUHJxSXdPbXlHTm50X1hoZlhFTmI3cmdSLWJSSkE9PQ==
yes,r/pytorch,Z0FBQUFBQm0yeGJieDZscFJ3a1VWaXZsa3Z2OFlpWFVHRTQ3eE5xSGdSUnAzMVJOVHpfdmh1ZkJyOGJUZmZEMkVTcW5ieEV3RlNkV2NGbGVyQnR0Z3VPUE5KUFVCa0xEbkE9PQ==
your model is too small and your data needs to be preprocessed before you feed it to the model le you cant just throw random numbers to a neural network and expect everything to work out,r/pytorch,Z0FBQUFBQm0yeGJiMHpsNlMyLWFYQTNNUDJHc0djaG1IMnVXN3k2dXBtZk40MlZqRmVsYmdiandqU3E3X2RFX0hONkxwejJvdWxwbjFsUXViRVJrd0FHWkN0SVg1R0NYVzRVamhNT1EtbnVuSEJPbFc5Q29vMGM9
someone else told me that <number> neuron in <number> hidden layer is enough,r/pytorch,Z0FBQUFBQm0yeGJiVHc0WEN0VERBOHBmV3FOdGh5YUxzOE0yVEd2c1NQRDhPZTFLNU0zZWRHYTloblBfaHEtNWlFUGdnX0RHM3BGclBvVmxEUmxtb2tiTjZWWmdqNi1kOEE9PQ==
a single neural unit without an activation function can easily learn addition in this way because that is exactly what a neural unit does however when you add hidden layers it becomes a very complex task that requires the outputs to be normalised and a larger hidden layer size think about which <number> matrices when multiplied together will have the function of addition try using a single layer with no activation functions and mean square error,r/pytorch,Z0FBQUFBQm0yeGJiM2c4UDVwUENZb2VQZmVFNEVHemNVdE50U25NSmNjMlZBNTdERnZHRXM1c2FrNlNGSE9HQlNreDk3SXpSNnRVU2tCdEhPWkR1cVF6MTU3dVpnUjhOQ3c9PQ==
i am looking at aten currently i wanted to use something like nvbench with it to benchmark those kernels,r/pytorch,Z0FBQUFBQm0yeGJjSHhfSU5rYkRvckpPcXh1aXdpYzJDaF94Tk9tTXpKYVNEWWpxT0VPOG5pRXVkSThlZlloR2xGSk1WeGFHV1NGaURHRlN4OGc1R1RNSmZHS1luSHpVU3VURGVIa19sMVRQSnNMeHVZdTFVSFk9
jit is kind of out dates try pt compiler with torchcompile,r/pytorch,Z0FBQUFBQm0yeGJjYzh6VHhpdUdIU19QTWMxZzlQS0NCRkVZeGRYbVEwaTlvR01ya2FnTVJVQ2g3Q3hsZ05wbjhvWTFYWFh0ZnhteUJLMmRTQ0F4UGx0S3NFRV9hLVBkRVE9PQ==
may this eventually be the leetcode for ml,r/pytorch,Z0FBQUFBQm0yeGJjb3R0cC02REl0YkJldjZPcll2Y09Bbmx5blI1TUo1QmZWZG5sTHFDa0V6Zi10VkpfR1lYdlgxelkyUmE1bEJwWXFpVEZOb0htX3EtZnR3eFl6VWt6c1E9PQ==
you mean temperature in softmax or something else,r/pytorch,Z0FBQUFBQm0yeGJjU0pLcVkyOFBkZldtQVFoX1Z1WTQ5S2lKTlVPcHBHUXh3MHFaWmFaTW9Gcm95VkxuTWEtN1pDajNrVTNEQjZwOXk4MG5YdmVVV252akpHd1RVaG8wMkE9PQ==
yes what divides the scores right before the softmax,r/pytorch,Z0FBQUFBQm0yeGJjenJWN2h1VmpUZnFZTDJvbmFaZUtVb1c5RmNYWjhHck0yT193UkNFVzBtVzQtWVFzVVhwQXFGM0xlWmtoNHdjZkNySU1DQXhiVjJxUHBqRDFZdVJ6emc9PQ==
tldr are you sure your gradients are properly flowing during training check using > yourmodellearnablethresholdgrad ideally this should return a nonzero value if gradients are flowing,r/pytorch,Z0FBQUFBQm0yeGJjNVU1NGZGcHFUTmhCWVU2Q1VHbzNhQVROeDAxVTFMN3VxclIzd0FWMjFXb2ozd3owX251WFFUV1BkNkN2azFHVkZITVIzYkYzb0RHTWVKWWdFUHBDb3c9PQ==
why do you initialize with zeros,r/pytorch,Z0FBQUFBQm0yeGJjTW1YVDhBamxJN1dCaUxnOTNQdTVyZGRFNlBOYVY2dFJwaU1UeG9VUXNiVWdNZGZGUl92R19nbDZyc0ZZZWxrNl92eFE5RXdfRTJNVHE3OGxsWVJ6VlE9PQ==
does the scale argument of sdpa satisfy your need,r/pytorch,Z0FBQUFBQm0yeGJjcnhmXzlaUXRLRGxuWU9YOWcxaDVZeHpYMDZwaTFvRm12b2RYWDlrUHBNbVdCYm5YLXFJSWpGX1l1VFB1WHBhTUVfSlNZTkpmMHR2WHh5M2FJXzItSmc9PQ==
is this the method used also for training with more gpus or for that another technique is used,r/pytorch,Z0FBQUFBQm0yeGJjZFRWNS1pOE9Jc0dFN1pXdlQyTHcxWFFtM0tVc29GMHdGWTJQdGZrTjV1V0h0c24tZldvdzFKcDBoR2xPR2k4aUdVbk10X1ZIZ1dzX0d3bTRFNWF0d3dkaHNMRGphTzZCeEhSQkxnbDVBb0k9
no because it needs to happen before the softmax and afaik this scale is right after,r/pytorch,Z0FBQUFBQm0yeGJjUWYyT0RRZnVURUhCcGZhUnJCNVprVDR6VW4tQ2QyRjJIWFZmTnpPMk1DckhUXzNmT20tYkdTMEZkWEY5MUpPaVFralV1a2FYY1hjMUxCRzRjOU1XQUE9PQ==
scaleoptional pythonfloatkeywordonly scaling factor applied prior to softmax if none the default value is set toe its applied prior to softmax according to the documentation,r/pytorch,Z0FBQUFBQm0yeGJjUjYtUjhRaDdQV2VyNjlKUFdlMU1RV0huV0xTbjFRSzB3LUdqNUFHTE8xOHNVUDlkbjFsVTUxZEl2eDVBOVZDTkFQSWEzQ2JaNEVXZ1Q2TlA5QmhfRkE9PQ==
oh didnt notice may actually work thank you,r/pytorch,Z0FBQUFBQm0yeGJjZ0VzVTE0ekJQM3ZqRl9BT2MxX3JNVnZqaXIwa09mTE40aFQwUmJjTkZtV1lSOUl0XzAwbFR6bGp0LVVHSl92V0R0Rk9Xc1hQRlFjRVZ1U2gxNHJzaWc9PQ==
hypestkey for retail microsoft keys just google it,r/pytorch,Z0FBQUFBQm0yeGJkNzZ6azZuUjg4eEoxY3ktM0xlNTJDMGJUZUFOejhNVXJJODhBQXdGdklTanc5cnBRM2JzamlWUnN2c3k1eHVGeFhydmpYN0lyUkd1WlY0dE95NGFsNDNWWUJwUEo3RlJ1NXZ5Yk9qeDU1OEk9
i searched for this operator but in d any plans for a deformcond soon,r/pytorch,Z0FBQUFBQm0yeGJkcWRuQ2ZBQzdWc0l4OGRPNUFLU3Y1WEs5ME5DRkVoM3djV3lhSEFUc0FlZDAwMnJHZ1IxLU9hLVJ4TjVnOUg3ZmNFd1ZvSzFzMjYyVnNNSWRTeGtvWmc9PQ==
can you set eval batch size to a different number without autograd and optimizer state tracking the mem needed for eval should be significantly smaller,r/pytorch,Z0FBQUFBQm0yeGJkbXpWN3JnWHk0WlRIN1ZfTnFvNmttb3M2VHd1Z3dsYTJrZFZ5THJ3MG1SSHBUZWtUR1pVcXpSQW53NjZ6MTlENWtveDR3SXlxaE1SaVA3azhpTnRhNEE9PQ==
thankyou for the suggestion ill try that and update you,r/pytorch,Z0FBQUFBQm0yeGJkSE03LVRwLXJOWUdFVU9lV29JN0otaU9VdUxYX2cxWTZXQ1hUa1dJa0dNd2dMUW16MkZwLW9qV29KUFpsd2VZczVacjgxcG1GdGhod1BhV0VsZ0VaclE9PQ==
it helps a bit but still its very very slow,r/pytorch,Z0FBQUFBQm0yeGJkVkxRV1lVNjBDaTlZSlo4cG9JUmU0SkFoZnpDcGRTbTBLQm9hWDdYSFd0WVpFcmthc2lHOG85cWZmdzdYUXdjY2prMVY4Y21Ld1lndm5DeTE4c1dub0E9PQ==
takes a while dependending on the model but yes you can train most vits with a <number> ive been doing a lot of that,r/pytorch,Z0FBQUFBQm0yeGJkSl80WW04TVZTMEhvRll0OEh1TUl6YnFzVU9VQUdVX0tLZEJtY1AzbFZ6T2FnZVRQcDdOeXRGZFZzWTFJYXVwcG1KdGZRWXdvcTFVNEVSVDRXb2xFZUE9PQ==
hi ive implemented the deformconvd operator for my personal project but im not sure when i have time for the d version itll require much more effort whatre the shapes of tensors in your model input mask offset etc for deformconvd,r/pytorch,Z0FBQUFBQm0yeGJkLWxiTXpSS1dYQUdpaFo3S1ZJakpVT0lrM0RIaW5GU2xyQW5VbzBFNklmeFl4TjFtX1ZLdFphS1BIbVJLNTJlNkJaNm5GZ3ZTZHBCUDBaVXFEQktINGc9PQ==
sure you can train anything but a sufficiently large model may take a while i suggest colab otherwise,r/pytorch,Z0FBQUFBQm0yeGJkX25jQ2NTdHJLVUowdTdQN0RRVGxSUXJDc2xVNHJaVnV4UllzOEJRZDFPekVBajloSG1sUVdkckpwYVR3UE43NDVvOFk2bEZSRUxNUkMtcDZuRTkydmYyR2tPaTJzY1RYNHJSbVdGSmpSM0E9
really it depends on the size you obviously wont be able to train any commercial llm but a <number> will allow you to train pretty much anything else in near reasonable time,r/pytorch,Z0FBQUFBQm0yeGJlMlBvSDVVcjgzUXd2VEwzM2kxcm5PSVhJdlJ5YzhFZDVCbENCVEtZZElIOUVOR2pYR0dRcWFCUWtTd2dYZC1kejNHRmRVdEJval95U3ppNnlSRGdXWGc9PQ==
no need for commercial llm its for test purposes and personal projects thanks,r/pytorch,Z0FBQUFBQm0yeGJlZEg2S3BlZUVuckVHWEo3OXFGN3VmUTlTQmRfc1RSajhTcV9JRGQwQ05pTHlEMXRXenVIelVQVHFRZWNrRmRVajNmLVFweUJxeGpjbmI4WVcyVl9Sbmc9PQ==
yeah i used colab a lot now they have a wide range of gpus but doesnt feel as good as my jupyter haha,r/pytorch,Z0FBQUFBQm0yeGJlODFlX0thcklGRXg3WV9lRFNNUzdDLWcwSXpJcDlwUDhvRnVTVV80cGV0UTE3MjNFY0dQYVBfc1dPcTFMNUhmYjVLVE16N3hXb1EtbkJtTENLdjlINnc9PQ==
how big were the vits like the <number> or did you try on bigger ones,r/pytorch,Z0FBQUFBQm0yeGJlbi0tcXdZTVpQTUIzbmc3YjBadXZOakRRVWlrZUYtbEF6eTZDYWl3SFhXRENqa2hDYTZvTVNpd0I0VGZxal9WYlVXRmd6a1hjQXNxT25ScFFPbGs3VXc9PQ==
i wonder if you could use something like this to connect your local ide to the colab gpu runtime <url>,r/pytorch,Z0FBQUFBQm0yeGJlTk05YzE4aFBjTzdBWDBoNDhLTmRsZlk5cEZTSVRTWEhidEJKbHctdzY1UXFESE11WmhHSGV0RUMzTW9FWklOTGlrZzhZajRXYmR6NTFTOGd2dTVMTjB1RnBJcUYybzFwM2xEM0NNUko1V3c9
having the same issues moved to a tpu so i could have more memory but its so slow i am so glad to see this have to try this out to see if it helps,r/pytorch,Z0FBQUFBQm0yeGJlSUpNdmQtRGpQSkU4dzMwU1JMeTliVkh1Q1dFaGs1eEF3ZUNQUjZmbWY5WXBjZG81bXpJSXAzM1NDYlBtSGpVUGNzX3ZaNDJ2UGdhMVRuV2hGYndXQ3c9PQ==
yeah i gave up on google colab because i had a lot of problems with the gpus and i find it ridiculous that they dont give you access to the terminal if you dont pay ill do the training with my pc so i can use the terminal and not have problems with usage time of the cards also if you have to load a big dataset it takes too long i think colab is a good service for tests and small projects but as soon as you need to train a big model its impossible to use,r/pytorch,Z0FBQUFBQm0yeGJlVWhlbksxRzV4UG9xVW1RZ3FYRmFtTkpSdDFhX1NSME1LeVBueU1nU0ZjbVEwNlo3OTRPVlhnTjF3aDVzMGJ5ZEZtUHI3RTBGa2pQdnJhUjZxYlQ0M2RTdkM3eXIxQ1Awb3BrLVFKbHJwdDA9
i hear you my model takes up around <number> gb to train and i am having a hard time getting it to run anywhere but on the tpu pod on colab i cant get it to run on my local computer cause its an m mac that i use for music production and software development and its perfect for that use case i dont want to get another machine just for training as i see this field moving so fast and i dont want to constantly chase after hardware but i understand why you are frustrated and using your machine between having enough memory or storage i have been having a really hard time training and based on my math it will take me <number> days to train <number> epochs omg help me very hard to do this on my own without big pockets but i am trying so hard,r/pytorch,Z0FBQUFBQm0yeGJlc3FXU0pLeUt4NHZVRHFlcWlEWXdkeVQ5OUxDb1FEd050ekkxbGEyZ1JZX2EyZmdHa0pGalN5eDg1TFF2Z2h1MTRwOVkwdEU4eDF0bEstN2lLVGJfUlE9PQ==
what the hell does google colab even provide <number> gb and isnt there a limit of h for training you can still save the model and resume the training every time but <number> days <number> and i even complain about needing more than gb,r/pytorch,Z0FBQUFBQm0yeGJlcjd0UDJiR0tMZUNEeHcydlJ5TERuS29yY3FrVE5GWTJYVDNSbDgzczJOSnd6RVdNOTJ5aEZEREd5SlpxZjBoLVM4VHo0Zk1vQmhlOG1ZT0p3RVlHeUpoclZNVWVYSERfX0JpbDZqMU5mZjQ9
you have to do a checkpoint after every item you train not epoch item cause you never know when the script will stop executing and you need to start again and i want my script to restart turned out to be a good idea anyway cause if you get to item <number> and it has a data issue you want to fix it and resume not restart from the beginning anyway so i have checkpoints on the epoch and the set i am training on a set of audio leave it at that for here after <number> hours colab will kill your sessions even if you are on colab + they want you to pay for google cloud which is much much more money to keep sessions passed <number> hours if you want an nvidia gpu the max memory is gb for vram but with tpu v technically its a tpu v pod a cluster of tpus the max is over gb some is used for overhead and it comes out to about gb for model use give or take i am using google drive to store my data i currently have <number> terrabytes of data the read is always free but i can only write <number> gb of data a day so when i was uploading it took forever i tried google cloud storage but that was like <number> dollars a day in readwrites it was crazy every set takes <number> to <number> minutes to process i have <number> sets <number> epochs comes down to <number> days per epoch about <number> days if i make my batch size greater than <number> it crashes on me runs out of memory it is working but at this rate i will be very very old by the time my model is ready hahaha frustrating,r/pytorch,Z0FBQUFBQm0yeGJlZy1Fd2dLS1l6NENJTHZWX0NVX05EaDNENEdPdTFfMWZOaGhOZ1hFeHJqNVlqdzZUUEIwYk5mbzBZZHpaQkpHc2FWS2J3RUNJYm00UGlTWVVkd1A1Umc9PQ==
you bypassed every limit of google colab ahaha do you have colab+ or this can also be done with the free tier,r/pytorch,Z0FBQUFBQm0yeGJlTjZmVWVfQnM5dWFBUDJBcmUtOWVpUDJJTGgyNU85NkpSUmVJdndkcUd2MDNCSktUZy1NZkdoaUd4LWlmVE9QV2FlZXRoUjZwZVJiMEhucDNTLXdXT3h3LVhQLU9BbjFYaDR5TDBWTmtIVlk9
colab +,r/pytorch,Z0FBQUFBQm0yeGJlNWwzMGhvMzR3VGszVjdvQTNuZFRCbFMtRXhvQ21ZcXFzZG00ZnhrSVJaUTdNdzlQY2JuSXZNQWVFWFU5Qk8tT1FlQjFELVlYa2N5QkpzRXhJdUZXSFE9PQ==
ah ok and what are you training your model for,r/pytorch,Z0FBQUFBQm0yeGJlUC1CVHl4V0Y2aXV2VWxWZWxCXzhid2hYVVYxMGNOMzJ0eHZtTDk0M0dDa3RHZjdVUVJja2FpdmN6Rld2WE4wOVd6ZFJ5QUN4SmxRblBoNktHLVR3NFY4VzlfRXQxVElfS0o5THFsSXBzbms9
teaching it to make alternate versions for clubs or acoustic,r/pytorch,Z0FBQUFBQm0yeGJlZDU2aElaYks2bXBqOXpRLXhHNTRCcmFTcXlfSXNmTVZ0R3UwZHhFYkRld0tSbUZEcllBMzR6Q2VWT19BUFo3c1RRSWJHRGJ3ZTc4cXNvd0NOcHNET3c9PQ==
cool,r/pytorch,Z0FBQUFBQm0yeGJlMWY2LUFGNFJPejYxZVRoSll1TERIYU5nTm1qTWNvYWVXZUdnMjRXMTlmZ0dyUWhHNUZsZl9mRjF6bXlIdEdSR2txX2dSRHA2Sjd0ZDlKQU9LM2FIUnpWVXE3bDVWeTNkMTRDLWtEdjFwZ1U9
lets see if it can be done i have a huge dataset and its labeled really well took me <number> months is all lossless,r/pytorch,Z0FBQUFBQm0yeGJlekMycExicXNnc3BzQ3YzUkF2Z3BMQWI3NEFnRjFrUEFpM2hoY2lPRG5rbW5ydUhsVzQ1dXhVcHdqQzBEbWR1Nm9ENDkyZkhuc2xRbmVhMWl4NVJZb1E9PQ==
doesnt something like that already exist did you designed the model from scratch or you are finetuning it,r/pytorch,Z0FBQUFBQm0yeGJlZjNRZFh5WnBCczNmZ29jaWR5SUQ1YVdGanFObU1OSEFpM1lkLVpqdEpsdHlhMnZ6aXIwRXNxdUp0OEZNM21Md0pGNGVRQTBVOHMwYUcxTmJ2OFpHMS11TDJBOW5kOC00OTIwWEV1WGtGRFU9
yes you will get much better performance on an rx <number> pytorch works with rocm <number> on linux and requires no special code or work pytorch allows you to use device=cuda and do anything you would otherwise do with cuda on a nvidia card i havent used fedora <number> personally but ubuntu <number> works perfectly for me,r/pytorch,Z0FBQUFBQm0yeGJlSWNCalRhallLbkpiUkVpaGV2RlBOUVctUGY4SlI4ZkVEV1ZnQ1FvcndLSFFKbG81LU9XS0lfbHFkeF9FUEVnMHVqM0JubURRUU92NDdHbDlubG56M0E9PQ==
oh and for other ai workloads there is growing compatibility too llamacpp is the most popular llm backend and it has a rocm implementation too,r/pytorch,Z0FBQUFBQm0yeGJleHdBSjk4a2xRYUFSZ2xRbHN4V2N1Y19aYU1vbU55dnZNWjVBcFdscC1UUG5XTHBYbVpHb1JYUV9hN3RMb092dXVXX3dRMENnOFRrM1VaUElLZ0xGM1E9PQ==
the concept does not exist currently there is suno and udio and they are music generators but not taking current songs and creating new variations in production i am starting to understand why the amount of data you need to process is vast and it requires a large amount of memory to train the model the model itself is based on a unet architecture which borrowed from computer vision that has seen great applications in splitting music out into its instrumental parts like in spleeter the model architecture is unet derived i am training it from scratch i am currently in day <number> of training and i am seeing some early results that indicate it is going in the right direction i tried with a smaller set of just pop to acoustic and it did start to work the vocals were coming through and you could hear it start to simplify the instrumentation down its still very early and i am looking forward to hearing more project <number> i have another project where i am creating loops using one shots these are in music production the sounds you hear when you hit the button for a drum or a key for a c and i label them then i send this through the model to learn how to identify the sounds this model will then be used to classify production quality loops to categorize and label the pattern then i will use a second model based on the second production quality loops to train based on genre and loop types to create a generator this is still early on in the process so far i have created the library of <number> random loops and the labels and i am now designing the model for learning the notes to the labels all this on the side of my normal everyday dev management work i just dont want to miss the ai bubble,r/pytorch,Z0FBQUFBQm0yeGJlcHczUXlMVERCOXhiYWJfUmxNN2RING5YeWo4VkdJT09yMEJEZGU3b1hadWw1Q0ZyUGtTZWJ0SV9pT3lIYTdrc2h2aTlwcEMtcktWSHlCTi1YczRlZ1E9PQ==
mate thank for the link ive been looking for such a solution but been told that it will not work and that only opposite exists running colab locally maybe i should have looked more instead of listening,r/pytorch,Z0FBQUFBQm0yeGJlSEhvRkViMmJIblJSdGtoWVU4VTZoQ0pLdTVodkluVVFYazQ2QS0wMS03T2ZJNnpOc2VfSXlzWUhKX2dXNFdkM3RlTUhDOURiV3FrZ0dQc1ZOWDhHdEE9PQ==
like <number>b params,r/pytorch,Z0FBQUFBQm0yeGJlTTViUXFHUHZjQ2s4UERFV1JFc2RPNUZzVndiYkZmR081Nld0bEhvTlo3OWJsUTByUzZJZ0pkdlhhN1NoVHVPc055WW9iRDBzZTRqR2RaaENia0NWZGc9PQ==
i think you will be better off working with an n card it looks like you are on a tight budget and are experimenting with smaller models no unlikely you need to squeeze every power of a card if you cannot get your work done with the n card then unlikely you will see the work done with the a card amd rocm is supposed to work with no issues but in reality depending on your models you encounter unforeseeable issues and likely you will have a hard time to unblock it due to lack of community support and docs compared to n cards which have a larger user base so you will find tutorials and forums to get some help especially when you are learning stuff it can be frustrating to handle those compatibility issues of a cards,r/pytorch,Z0FBQUFBQm0yeGJlQlhmNmNtNlFiWWxGSTIyNFdnQS1vYTRKcTJhRGpEcXhsYURoOXN0UW1Qb3hYYjBsbVBYNFhfS1BFajNjWFRKaWFoMGd4Yl9hQUNwQUN6VjB0ck5EUlE9PQ==
you can fine tune b llama on a <number> its very slow but can be done so any image model should be fine,r/pytorch,Z0FBQUFBQm0yeGJlVzN4SVRCbmJuQUlNVWFqNWRveE5PdUJ4ZzZvVlc2Y3hJZmhuTTd3OGl4Y0FOMF9mY19YWXRVN0RlNWpRRlhkektXUE45dndhWnktNWZlU193aldNWlE9PQ==
no worries,r/pytorch,Z0FBQUFBQm0yeGJlZlZacDZfUHZqczNkUmtJcFkxeXY0eVFzeGxDb3Y4elpzaEVVeE0xRmo2clJEbmItb25xa25KMmV3RHBmY2pzVG9hRHZ4eVRZWXNkU1pIMTJkMjhhbkpYRnBuM0Z0amp2WTFtbDVVTjhncEU9
thanks for the opinion thats what i fear the most it will supposedly work and then down the road i will have to fight many issues ill probably go for the nvidia card as much as it seems that it is a bit overpriced,r/pytorch,Z0FBQUFBQm0yeGJlRUdJNWtzWTU5TXJmZU5aZ1o5M3lERFhqQ3k0Q1ZhUnIxbjdaT1c4aFFiM1g0TzB0eURRVmlUTkQ0T1FZbmNoLXh0N0FMaDc3UDRuUmVVbjk5b1A4cHc9PQ==
thanks so you have tried this yourself any hiccups etc can i just follow a random internet tutorial and use most models from huggingface i am really a beginner here so i would like to be able to concentrate on the actual problem solving if there are often even smaller issues which an expert can resolve quickly i think it would be a bigger problem for me,r/pytorch,Z0FBQUFBQm0yeGJlMDluT2NINFVqeFdReWFvZnZNN2xQMWpIV2IyQXN5MU1qRnF5LXVORTlBTXFXUHJ6WkpUNFY1QXNjNlRZeVU0OVZaMzhIVTRLVWwxc0hZVW16eE13MWc9PQ==
hey there  is there any plan to be able to install touch eval through conda channel,r/pytorch,Z0FBQUFBQm0yeGJlc2hiR21mazNDUVpDTVVyT1hmU19pT1lYWGJqRWpkeEgyUzg2dEpoYXJNN0Nfd0pEY1Y0VEVITklvZk9BeGk3dUUwY0swM1R0TTRkRS1YanptZmkwT2c9PQ==
do your environment variables correctly reference the relevant directories use echo <cur>path and echo <cur>ldlibrarypath to check if they include your cuda installation directory usrlocalcudabin or similar next nvidiasmi only shows the compatible version it does not report the version pytorchs own cuda is built on you check the pytorch cuda version with torchversioncuda in python and the system cuda version with nvcc version,r/pytorch,Z0FBQUFBQm0yeGJlVlYybXdEZU52N3N5MjBpclo1Q1NCOTdSY3dvMGp6Zm1DcUZtOTZMclFXM0lOMEgwYXhmYnBwOUlxZ1pFSG5wTDY5Nk91TkpyZElKY1R6NVUtSzhmbnc9PQ==
sometimes i just save best model then i restart the pc and just run my inferencepy file also consider using pin memory = true,r/pytorch,Z0FBQUFBQm0yeGJlQWNnY0JESTF1YWN5d3NSdjNPUUVfMHhCMGc2MWFWT05UUktvRExoMVZVNkY4WXdEOUdVNEtTbG9hOVpSeGZ2SHhOVFI5Y1BITTNwbWdEM1NtLTktd2RMVnA3MFNCbUpQajZQNzZtS3hSNHM9
did you ever figure this out,r/pytorch,Z0FBQUFBQm0yeGJmTUJhQ1hVNVNyZUF2akN3WnVETnBpRTVSaDJWNFFaZlprY1NOZFZpa2lhYVhnb2tnd0tUZDI0cDdDbzBqd21reDFWbkM3X1otajRtWGsyR1VwMEQ0S2c9PQ==
wow this project sounds super cool i love seeing how ai technology is evolving i once tried creating my own ai model for a project and it was such a fun learning experience have you considered the computational resources required for training your own model versus finetuning from huggingface im really curious to know your thoughts on that aspect good luck with your ai waifu project,r/pytorch,Z0FBQUFBQm0yeGJmZC1ZSlk4MmRzY09wQVFqeUJpT3B6R0RpYUlNYTRIZTZMc2MyZW4wcVlXZUJRMEp6SVBtSE93MTY0ZUdibnJpNE0tbjVnenFSNWZMZFpCbWREWHB2Ulc2bFhWSXpFYnYtMWd0bVdsdEVyWkk9
coreml doesnt support some operations so youll need to write custom layers and gpushaders to support them on iosmacos you can have a look at the github issues to see which operations arent supported <url>,r/pytorch,Z0FBQUFBQm0yeGJmeXN1eU5GQWFfX1dXajItRElxRG1xY3ljekFfeFZMWi1VRE1hQWJ6cHROZmVHNktWdkxyZ2hCanZncy0waTloSF9MX2lTd0g4WDhWUmptck1UeFpFMWc9PQ==
short answer yes there are search for exactly what youve said here just google speech to text pytorch models huggingface a company that releases libraries to simplify dl allows you to run models via something called pipelines that abstract away a lot of the complications look for huggingface speech to text models and you should find details on how to implement things this should get you started if all you care about is inference meaning you dont want to train models,r/pytorch,Z0FBQUFBQm0yeGJmc2ZoT0EzT3hXdktpV0YxaFRfRXJGUEt2MldWVWNHZG02Tll2X25xWlpueG9YOXNGWVJxUWdGa2pjWi1zTTRrUGYyWllVSzRmYWd4NFhYaVdRNW5RQlE9PQ==
oh okay thanks for the assist,r/pytorch,Z0FBQUFBQm0yeGJmZG43TTZvX285SGx1bmR5dUxNZ2JZYV9NRTd1SlRKR3BXNkVyN0dGUk5tUWtRVjlUQzJWakVhQl9odGlReW5zZGNPSDdtSksteFNvVThGTzJaZnl0Wmc9PQ==
youre welcome,r/pytorch,Z0FBQUFBQm0yeGJmNkp0Q3U4cEt5OEhJdm0zV3lGX0VVel9NUldFUllFeVhKTWVsLWNodUQyaWtQb1d3cmp2VThVN0NsUllva0c3V1Q0TjlYcTZBR3lCekQzcmQybmdvcXc9PQ==
wow a b on a <number> you fear nothing my man,r/pytorch,Z0FBQUFBQm0yeGJmbFMyeFJscnZzaHJUY09tc0pMZi1EZWZ2UlVMdjRkZ1AxMWltWlBTaW4xN1YxbTQ1VHhyWEEwRjFma1JCaFJpTU5KaE9tWk5sc25WTnlDa29fN19LOXc9PQ==
thanks mate that will do the work,r/pytorch,Z0FBQUFBQm0yeGJmQzNHdUx4Z3VubUQ5aTg5VlhpXzRwRlJUSVZPMTVjVVlnZjRlQklCbUJxMnNjZmlXLWpyaVR6ZDQweDNDRnZBb19nS3J5TlVYcHVsa3FQbWJjajEzSkE9PQ==
not really nope,r/pytorch,Z0FBQUFBQm0yeGJmenZ5TTFDS3FKVUd1SnVYR2Z4T0xFN0VaM1dNSFdoNHpDSTdneENIMzNmUTlmWENCYjB6bWVpZGN4WEg5MFp0dTdnZFVOWkluNmdqUno4LXhhUS1SNmc9PQ==
torchfromnumpy returns tensor with requiresgrad = false you can just use torchtensor and put requiresgrad = true torchtensortargetdata requiresgrad=true,r/pytorch,Z0FBQUFBQm0yeGJsSGl1Z3NVRmM1djdpckxtQWRxa25iWE5FeWJuTVBlcUZqSW5SSlYtV0dkTWFQOGtCenVRUXZUY2FxTWZ4enRoUjlFX2taaFJqZ2padmVhTEdXY0lXTEE9PQ==
are you looking to do an android or ios app,r/pytorch,Z0FBQUFBQm0yeGJsM2ZzbC1KXzdKSFV5N0M4ZzNfQjN1eUlCRXVYY1oxTVE1bXZtUTBmQTVLRGVRUzlJVGNSUnhaSnFJaHhlM25RVlRwcFRJMmttY3dzZWVWSGRXOFkyUHc9PQ==
yes in the future but want to start as a web or desktop app,r/pytorch,Z0FBQUFBQm0yeGJsOGFKaWhyR1UySG5DRk9vVml2dXA1dF9pbDgzcUFadERaTXNkUlVUNjNWZTI4ZlMxZkVBdlM4RDF0Ni1CbFQyUXk4UmFwd0ZhSURjT0hNQ1FPWXU2dUE9PQ==
so im not sure about pytorch but you can use vosk which is super fast or whisper which is slower but more accurate you can call both from python ive actually tried both in my android app here <url>,r/pytorch,Z0FBQUFBQm0yeGJsdHY3dnhjdGpuSVJJR1pzcUZ6enVQWDV2d3lwenNfZXA2OS1SMmkwUmhUQjhoS250cWNWd1lXLWh0VndjR0ptUFI5NllQcWlJc2liaHFUaHNYQmo3UlE9PQ==
ok i will look at it let me google vosk because i have never heard of it,r/pytorch,Z0FBQUFBQm0yeGJsUWZJb2c5a0YzQkdfYnFWSGtLV19UQXI3ZWJkeFlsTUpnX3ZtNm9Lc0xpVGp4N0VuUHUxbThRcFVMRUd0UWdEYzd2OVJoN3c2dUZycGFsMFFGYlpJYWc9PQ==
wait what size of language model did you use and how did you integrate it,r/pytorch,Z0FBQUFBQm0yeGJsQm1jUFVVejhvQ2M4QlRiYVdyZEt3UjNDTWZtejlqNmY4SHVOdFZxS0trdENLTEhOWUhRMVYxTVJtb0UzMW5OOWxtZlNqU1VEWU4wWlo1OXZGTDUxUmc9PQ==
i used the smallest ones because mobile devices do not have much processing power or ram compared to desktops with gpus plus they slow down even more as they heat up and they heat up more as you do more processing on them,r/pytorch,Z0FBQUFBQm0yeGJsR3hNc1pZMjBaS1UwVE1rOVhkVFZMeG1wUDN0LWJVREJwa0xDMEZQMTR6NHBXN2V6M0M3RFhPNmZKaFl1UXI3ejhyZTR1RlhtRFdHUUlBR3ZFanpKZkE9PQ==
yeah thats why i am particularly interested in googles gboard voice typing feature the language model for english is mb and it works offline as well,r/pytorch,Z0FBQUFBQm0yeGJsTXV2UHB5REx0dEN3aVFCYnpMMDJhSTJmSGZOWWpLRmJYbTNIU3g0UVMzVDJLRVZyRzNjTVpSWVhWcWU5cjdQaW1GSUQwSkdnZ0RrbjZhVmFjTkRWaGc9PQ==
any update bro,r/pytorch,Z0FBQUFBQm0yeGJsX3EyNTFnMTFiMVVBMWlKMFNWaUJzVl9HOWVnX0gtNWdPOVdWRy1uYjIxRkZ2ZlV0UWFlSno4eWpTbDRMZUtFM3dXazA0Mk0xRzJieVhBS24yakNkdVIzSXJZOUVScU1HUVM4LW50LVJOLWc9
nope somebody put the one i was looking to use on hf since,r/pytorch,Z0FBQUFBQm0yeGJsM2Rkc1NyOGxOb1ducGNfZlc4dG5KZ3pLRDVRdUkyWXBlZTY4aE9mWW0wSjhHYTUtdGN1NDlLQmhpaU1KRTdXNnBpaHhNakFHazRLc2VxX2xkV2RXZmc9PQ==
i can generate a relay ir compatible dataflow graph from the pytorch + kornia so thanks alot i was trying to see if i needed to build a new frontend dsl for tvm,r/pytorch,Z0FBQUFBQm0yeGJsaG1xRVh6VUgyd1NyUDRzNW1WajJOLXVMZE55X0JTY2Foajk1OHBWM0hlbDh6TzBydEVtRFFsay11blQ1TnhhQ3RxOHhzSjZURVpXcEczWk01dVB6UGc9PQ==
very helpful thank you,r/pytorch,Z0FBQUFBQm0yeGJsc1dVZ0lGdnVnVkx6eENWSXBpVGo3T2ZNb0VpdkNNUWtNVFpCNHN1V1JNdlRRV2ZaNzFidktsbEkxUmxtZ3dnWXBhMjh4d2dDVlY1ZmpLRTB2eFJabVE9PQ==
you can try vastai to rent gpu much cheaper than buy gpu,r/pytorch,Z0FBQUFBQm0yeGJsZXFVWTk1NV9vSTc3NDV2Yk1HSEZNZGNCTmVYdkdVNmNDV2xTYnRKUnIzZ0NaeDNyYzBIcFZBSm1WTTFnS1hvd08xTWFQQXpiS2ZNNnpjR3FKUmMzS1E9PQ==
finally had the time to test what you suggested here are my results echo <cur>path gives homexminiforgeenvsvllmbinhomexminiforgecondabinusrlocalbinusrbinbinusrlocalgamesusrgames echo <cur>ldlibrarypath only outputs a blank line torchversioncuda gives <number>,r/pytorch,Z0FBQUFBQm0yeGJsbmxOWFVZTkpYdzJWMElzVVNWWmFHcUx1WkpvVUt6NHg4VzRPeVRYUmFFTS1JQ3gxWThtdzZ1aWVXcEFkXzVrUUw4VUdwRFdOQzFsbHlVUkNDR19oV1E9PQ==
i see i think the environment variables may be the issue here assuming you have the same cuda version installed per nvcc version try these before running that pytorch test again bash export path=usrlocalcuda<number>bin<cur>path+<cur>path export ldlibrarypath=usrlocalcuda<number>lib <cur>ldlibrarypath+<cur>ldlibrarypath found these here <url> if you follow the guidance on this page you should be able to resolve your issues,r/pytorch,Z0FBQUFBQm0yeGJtZldaNm56ZkNTVnNQd0E2a2twdTJuVEFGRVVEZEJJNVFHX0plT2dxYURaYmtFQUZuS0xnQ0pzOEVnbGRJLWZKWUpYeE9LbDIwZExTdjZLQXE5dEdwbnc9PQ==
normalize and standardise your data by using scikit learn that will increase your performance by a lot data should not be random increase your number of neurons as well for parameters in linear start with random values multiplied with <number> or set those values from <number> to <number> or <number> to <number>,r/pytorch,Z0FBQUFBQm0yeGJtUEk0clZJLVM1TkE2S2hKOGdLLUJCN09xRHREV2xFOHdCRXRLQTRVNUZ3WTBhM2RudnhOMlE0YVByR3hzVmZuNjA4MW9sbkdaeEJPOVJEMFR6cUdqRkE9PQ==
no relevant code picked up just yet for backpropagation through time for networks with longterm dependencies request code<url> from the authors or ask a question<url> if you have code to share with the community please add it here<url>  to opt out from receiving code links dm me,r/pytorch,Z0FBQUFBQm0yeGJuaXBYYkNtano1Rk1mX25JYTEzWlowRUtMcDB0aWZBdEhtTnpfTWg2dVVZVjdQQTZJeW01RDJqNnVlaVFRY1l6bXBBdHRNZ1dsWlRyQkdVQWpSS3d4ai1rSkl6dng4QzNkemVPVjlabVRzLTA9
it wasnt there a few versions ago thanks again i did this with it <url> diffusion models somehow did not make use of temperature while it is actually useful,r/pytorch,Z0FBQUFBQm0yeGJuWmhxbHpFNThjelFXemRpWHdJWnBHRWl2UDFsU3pzZzk0MDhhT2tGakJCeV9nQl9BaE1YQ29OcHlRVkRsNXc3Y2YyNl9CaHRXY0N0dndVei1JX251c1E9PQ==
the thing is usrlocalcuda doesnt exists is it a nominal behavior since i installed cuda via conda using pytorchcuda,r/pytorch,Z0FBQUFBQm0yeGJubkRkaG45NV9Oc1ZOaURrSGtRQVZuVTU5elFoVFN5WUNXbmNvaHJzRjBRUS0xTE5ubklNYWNHRllvSEY2VWVDM255cG5yQWUtc0pfb3dmVS03YWdNM0E9PQ==
i use it to capture the tracer of the run very useful to identify the performance bottleneck of your training loop and come up with optimizations it is a bit of a learning curve to master this technique you need some understanding how gpu and cpu work together eg gpu kernels are async when does cpu and gpu sync with each other what are cuda streams what can be done in parallel by a gpu definitely recommend if you need to understand the performance of your training or inference code nsight can be an additional tool since it can provide more information compared to the standard profiler this is an example of using trace and profiler to iteratively optimize a model efficiency performance by the pytorch team <url>,r/pytorch,Z0FBQUFBQm0yeGJvUHBBTTZPQktCS0xYR1FaTzBSU0pkT19zUHp3Y1A2cm9ZbVJpdUNVTFVVY3hsaUdKNm5hellSM2hyOUoyTXhFbE5EcGVTUDB5eGMybzVWQ0VONTlKUFE9PQ==
thank you i appreciate it i tried to find some online tutorials and the pytorch docs is this something that is best used on a small <<number> subsample to do some optimization before running a full training loop,r/pytorch,Z0FBQUFBQm0yeGJvUHE5RE9QRHN5bGJkR0JQekkzNnlFZFBIUnhwOEVzcWMwZzViamlVcElSU0EyQW9yeVljcnI0MDZmWGpfYXljYktRMWw5TkIwSUdIRTJhU2l2LUZkTmc9PQ==
what i do is to keep the config identical to the prod settings run a few warm up batches before starting the profiling on a small number of batches of data eg <number> batches and check the trace from there,r/pytorch,Z0FBQUFBQm0yeGJvd01ET19EM1J6SjlDYXJiY0tkZERxUGxlZXQyNHVnZXNVY2FNOFRCVnprX0NuT1pFQl9FbDRaYXZXX283ODNsd1lUVE5YU1RGd2h3ckNhWG5Wc2lWVVE9PQ==
i know i readsaw that someplace im assuming the warm up batches is due to async issues,r/pytorch,Z0FBQUFBQm0yeGJvNklreThScy1OaXd6aGJUX1lGMl9PZFF3NXRJQlQ3bkNkRzR2LU9JaUxzZ19PZlRWVzI1Z1MwU3RWelFjZEtLekZkYTR6ckROTlJQSDNLUEV0SC02RFE9PQ==
i use the profiler too but at a more basic level can i ask you where you found resources to learn about syncing phases between the cpu and gpu kernels and cuda streams etc etc,r/pytorch,Z0FBQUFBQm0yeGJvcktnTkdReGlLbzI5MHJtOWRUQWRYN3dVTE9GM09Va1R1bmtjYlRMSU9WLWNUU09QRmtOb0ZaaDk0bTZqRzU5RFdhandNV0QwelJvTko3NHNLcGkzenc9PQ==
this is probably more of a learning python question,r/pytorch,Z0FBQUFBQm0yeGJvRHhXek5ZM2dCczZ3SDN5OHN2M29UUTlsMmFGQXB6ZTd3RTJ1NWpzUlRmaWt3SGpUSXNIT2RkcFRXMC1zbHNhNDRwUjEyYTJyWVF0Q1hxR2xKMkZPakp4XzNWdmJBOEZyWVAzdnhFQ25GTFE9
do you mean a different subreddit im sorryi didnt understand,r/pytorch,Z0FBQUFBQm0yeGJvUTNNU19iMjBWdXgyX3Exekg1Y1ZUN1BKVHZoR0JGaVZXWXRESE1BNjJuVFVoOTg0VlMwWmFkVnhPMHd1d3RlR1hLY1BVMnlkeEVDQUxna3dBeDBhekE9PQ==
ill preface with that i am no expert ive done something similar we had a service systemd service like a watchdog that would look for new images in the directory analyze them as they arrived another way to do it would be if you are controlling when new images are captured to analyze directly the images in your capture service another way is you could periodically analyze the full directory of images with a cron job and clean move the images after they are analyzed,r/pytorch,Z0FBQUFBQm0yeGJvSWozNlJpbFYzNC0zeWR3dzk5VFRaRmtXYVBCTGU0VjRPTnFueFpKV0pjRXFjcm5TNWw0SDdQTEx6OE1hcXVNVUFNSTVGSDE0cHc5cF93OUJPTnc0MGNjYlZpbDdER0R2NWQ4ZTBJZnd0Rjg9
i should have given more contexti am analyzing images coming from an arduino ov camera into a folder on my computer the camera sends images every few seconds do you know how i would directly analyze those images i hoped to have this being done automatically without my input in the cnn model after the initialization,r/pytorch,Z0FBQUFBQm0yeGJvZWtYNHdVeEtqOVlWMWFKTkkyX3V3VUtXNFl4bHp6SkdqS1FTZHpmOUZIRG9vdUYxVC1DaTJkc0tGSmlRWTFPdHdYYl9VNVJpQ0FlMmtNektkMGJPb3c9PQ==
the gpu starts from idle state in the first few batches the kernel queue is empty the caches are not loaded you want to measure the performance at a more stable state after the gpu starts to get busy thats why to give it some time to warm up,r/pytorch,Z0FBQUFBQm0yeGJvNUZVcF9hZV9rXzBfMk96MlJhUVdIMEtoQW55bmZrN2FvcUlUbnFheW8wRXVlcHAtUXA1SV9xYVkydXh3dlNHT3U4Rlo3OXJWYlBUTTQza3RsNTd2UkE9PQ==
not sure if theres a formal tutorial on this topic but the rule of thumb is that if the gpu needs the cpu side data or the other way around it will trigger the sync between the two some common examples are calling item todevice with async=false indexing slicing using cpu side tensor on a gpu tensor these are fair common pitfalls,r/pytorch,Z0FBQUFBQm0yeGJvSHZVRlpyalhXNnI5M0xiQmMyMEtWR21FV0ZtZmZPTjJLQ01ZUHBESXYzanpPNDZHSTd2TnRkYTBOR2Znc0lkNnI3Y0dRUWRwTzBrUDRhS2lzV1FwMWc9PQ==
just that your problem isnt really a question about pytorch rather a general python problem,r/pytorch,Z0FBQUFBQm0yeGJvLTdhMWNqLUFTaC13ei12MEtXYjBDRnFtaVpXWnBDOVNoU0VjZUZDZlNoMmNhRjlZRDV5WXFlN1JndTlET2E4Mk84VlNJaGZTTDhKTVRZQ2VQbjZoOTNaVThlUEp1aklULVFnbWpUdzRwaFU9
so youll either have to set up a service to monitor your images folder for new images > then analyze images as your service finds them or im not sure how you are saving your images through arduino but you could set up a sort of hook in python either through serial or wifi or however you are sending your images to your pc from the arduino either way you probably will work with systemd and a python script rather than jupyter notebook unless you just want to periodically run your jupyter cell on the full image directory in which case just run a for loop for each image in the directory,r/pytorch,Z0FBQUFBQm0yeGJvelNxbFdXNFN2UTBIaEx4d2lhNEJJdGVhYTJHei1tZDBleVlZSzEyRmEyUTJJcXlRbjZsb0RYcmYwQXY5b0kyY2RtRTJORmdaajlCeFkyOUJYWm1HdVpYMTF1c1ZWcGVDTmhmcmtJdWpnTXM9
thank you man,r/pytorch,Z0FBQUFBQm0yeGJvcktBVzM5X04zaEF3T2dKV3JmLUtyanNoUXR4XzVXazUzUjhSZFRXTWlLQmpwM05paXZwTGl1X0JMNmQ4YkdhQVA5NHB3TUt2ZGxRNHVZWHdTNkFVeHc9PQ==
yeah rlearnpython maybe basically the fact that its pytorch is mostly irrelevant what you need is help setting up a script that continuously monitors a folder for new files and then sends those files through your pytorchbased code youll have to wrap your code into a function probably too but again thats not really pytorch specific,r/pytorch,Z0FBQUFBQm0yeGJvRTVhc1k1dmZzMXoyYmYtV0VIR2Q1Y1JHVjRCa0JTWlBsd1BNejBWdFRXUlh5UUJLd3FmQVpIMEZiSGhFa1RMNS1uWml1TVJWNGxvMGlhQXJDUkVEQk5tX3Y0U1BmT3ZYNFg0VVg5ZVVfRms9
creating your own model architecture can be a fun and rewarding challenge especially with petabytes of data at your disposal however finetuning a pretrained model from huggingface could save you time and effort why not experiment with both approaches to see which one gives you the best results for your ai waifu project muah ai might even be able to help you with some inspiration,r/pytorch,Z0FBQUFBQm0yeGJvYko1Yl91dVd1Vlh0bzVpaHBLSExCZG9YamZvdlZPc0xvWjBHNGd4SUoxT1NlTVNHY0huSFozNVViZkw3MzgwU1ROaExaY1lJejdsbms4RGtuSlI3aXRrTGZqaFFaT3dVbVFmeWtmdXpndXc9
ok this makes a lot of sense i will post it in that subreddit thank you,r/pytorch,Z0FBQUFBQm0yeGJvQ2RrX1U3V2p0d3RPdmY3bWZsTDFPbDNCT0hyMHNCUmhVTXVDR3RBR0JrcUJKV3ZEbFVYUlF0T3UxaF80dk1xM0RZcDYxT2psemk3VVNtQmJSNzdhd3c9PQ==
ok this makes sense thank you if you are able would you be able to explain what systemd is also how would i construct that for loop im sorryim still a little new to this,r/pytorch,Z0FBQUFBQm0yeGJvdzRWT3ZucjlLSzJ2YmIwall3RF9zeG1Pc2tUR2FaLWlqSmdWS1FKVnhsdEtpYzJfQzNRY1hvSnlfT1RmclBfQ0R4RTI0Q3hLM0dGT2ZUN1hsMEpoQ1E9PQ==
chatgpt is your friend,r/pytorch,Z0FBQUFBQm0yeGJvaXQzZUpCdFZiMWc5a1N2VXFJU1ZNbnk5QkFPa2MydWk5ak5aeG1PSVZsRmMwc1p2WGhvZXVEY1J0M012amI1VmtrMVFycmlUQXlqUllaMk91Zk1HWVpOY296b1Y2ay1PWWY0MG1UejJrd0k9
wow this project sounds super cool i love the idea of combining wikipedialike knowledge with a character ai reminds me of that movie where the guy falls in love with his ai assistant  im curious have you considered the ethical implications of creating such a realistic ai like how do you plan to address any potential issues that could arise from users developing strong emotional connections to the ai cant wait to hear more about your project,r/pytorch,Z0FBQUFBQm0yeGJvUFJybmZMeEdPekhSVFF0S0xGckNGSlk2bjhlNVRDQi1sVGx2ZXFzQTV6RzQtTUdkTlpPbTYyd014cnNuMk1tYlVaY21tVkdVQ3hvR1kxRDZjMXNuNUE9PQ==
this is a really weak ad masquerading as a post shady marketing is the first warning sign that what youre selling cant be trusted,r/pytorch,Z0FBQUFBQm0yeGJveUZhbUF2YXQ0Rmxtd0k5d0tmZXpJS3pMNEpEb3lzaUhteTJ3dzZvMTVPNmE5TVBaNFJ4a0RzbTlZaW0yejNEcXNPOVVES0U2dExDX0tHQ3BqS1ZLZEE9PQ==
hello unfortunatelly a lot of inference backends methods like transformers from hf that uses pytorch doesnt support apple silicon mps hardware <number> and those need to fallback to cpu handle it you can follow the requests in this oficial issue in github and vote it <url>,r/pytorch,Z0FBQUFBQm0yeGJvTEtQRXo1NWNyYlZWclZ3VkoxSHhVWklmUXg1ZEdFUWVVRjRsTlN6U21lTE9CMWlCRENJNFIycjRZdE9IZF9mQmsyeWFtdGloM1g0b3dhQ1VaSmtnbmc9PQ==
there are optimised paths baked in to inbuilt functions at a low level to make an apples to apples comparison youd probably need to strip all that away and write your own cuda for both also at sepoch youre likely overhead limited anyway not compute limited ie processing speed is limited by the amount of time calling in and out of python rather than doing big matmuls and such so its tough to show anything meaningful at such a small scale,r/pytorch,Z0FBQUFBQm0yeGJwTjRuYkpIemZ6NFpHOHdGTk4ydS1iWnhyRHpWTVp2cXFpRXBJVmxuYlpzVFVhWTMxX18wZlpXWlQ1VC01YzZTTWduSUM3NDBTcVg0SUFSWDBwVk5KbVE9PQ==
yeah okay ill look at how it goes on a bigger dataset just to see whats what thank you,r/pytorch,Z0FBQUFBQm0yeGJwck90Nm50dnVvUDA1V2t3dGxDWFBLU3Z0Ti1LS0J0MWxNVUNEQ2JZQ25obUdRc0k2MWlxQ2wxSVhib1NpMmxpXzRPVlRIeG13VlR5MEkwaHM5c0NDT0E9PQ==
yeah google has some good models they pour a lot of money into ai yeah your best bet is the above models as the small ones should work well on a pc if you need them to work faster you either need a gpu or use someone elses machine you could also use a commercial api where you send the file and they process it and return the transcript google has a service like that and so does deepgram,r/pytorch,Z0FBQUFBQm0yeGJ2UGJHZTFUa2llZWFBZ0xSRVdIWlphVDVhS0dEeVVWUkJTY20ybEk2VXdDUXExV1RvWHVJQlFfdHM1SzFjdmVjTUxQMlJ0WEh6R05aU0FDbzJITGNiemc9PQ==
i believe you wont be able to use the latest pytorch with a m or at least not a recent version pytorch expects an specific cuda version to be compatible with your card if thats not the case it wont be able to use it if i recall correctly you should be able to install at least the nvidia driver version <number> you can check if you have installed that version or higher if thats the case then you should be able to install pytorch versions compatible with cuda <number> or older that leaves you with pytorch <number> which to be honest has most of the actual functionality of later versions you can try to install <number> following the instructions listed here<url> i recommend installing with conda good luck edit op i would love to know if it works old hardware is great for learning and testing and reduces the amount of ewaste,r/pytorch,Z0FBQUFBQm0yeGJ3T0F6dEZRbi1EV1Y1Z2J1NjRvSVdaZ3RIbXc5NTJyYVN5SnhLU3hmUkdMSDkzd1RNR1NvQ3Y2MWFtZi03bzQ3b3k3UjU4a2pvY3Fuejh0ZGZVbXAyeWc9PQ==
just install and use an older cuda version worked for my <number>,r/pytorch,Z0FBQUFBQm0yeGJ3TTNyU3ZLR0tSLWtRd3RUMWQwbFlSWG9md3E3d3psQzY3dVNDNjVuRnAwSnBUV2NtbFVMajdTY3liRk4yRE9rTmkydlpITzYwVDNVLTluZFg5RmJUMHc9PQ==
it will be in the next docker version <number> <url>,r/pytorch,Z0FBQUFBQm0yeGJ3Tlo2VGJTZWgxU1Y4NEZCWlU4UDNnQjVpNXhzVlpKMVpkajBEM2c2NjJCdjdhT0lXeVA1VDhoaVBNd1Q1ZFZIbVRsWThLSy1xQ3FRbUVGSEhETW12dXc9PQ==
nice,r/pytorch,Z0FBQUFBQm0yeGJ3aDM3SzVOSHJZWnZESE5DYnczOWRORlBZbi1jVGNNMWlhWGpCMGZyMmpjVjVHckFhd2Y0MmZFY2NlNmljcUMyRmc1UUlPRUlJRHE2Z2ZueXloU2FBd2c9PQ==
use the latest driver is always right make sure your cuda version supported by your driver and gpu,r/pytorch,Z0FBQUFBQm0yeGJ3YXZFbW5JRXlhZHEzUVRoTjJvQXVmWVdyY2hVRDZTSVZLU2k0a2t6OHNmbFk2ZFF5bDhoYktuWnJGX29nWjJDWlF1bFpqZlctd2NrMVBON3UyVmFzRUE9PQ==
does this snippet the docs align with what you were looking for also just a small note torchvisiontransformsv is recommended over torchvisiontransforms > most transform classes and functionals support torchscript for composing transforms use torchnnsequential instead of compose python transforms = torchnnsequential centercrop<number> normalize<number> <number> <number> <number> <number> <number> scriptedtransforms = torchjitscripttransforms <url> finally have you checked out torchutilsdata <url>,r/pytorch,Z0FBQUFBQm0yeGJ3Qm5pYjRYRi04QVRwWk1SMVUya2VrYjZ3Z2lwMm44RjB1QUVxdjJadGN5ZXNYdFE3bF9Eenk1dXY4S0dHWmRSQzhHRlhTalMzQmY3am5yclVtTjV4Z3c9PQ==
it would be nice to have in main pytorch but its just calling functions one after another in a list,r/pytorch,Z0FBQUFBQm0yeGJ3SDBKalVscjdYTGV0RERIUGJCSml2TFJSRXhmNkwwTDZwZTJ4VENnS1kzd0xfSEZPd0o1akF2UFctRFJtb1FGblZLbkF0S29veFQ1Qmw1NWRHYzNIcHc9PQ==
createml says the feature extractor model scales the input image to <number> x <number> and yields a feature embedding size of <number> may be that does the trick does pytorch have this or do i need to implement this myself,r/pytorch,Z0FBQUFBQm0yeGJ4X01FMjJtZlNMaXNCNThvMjk1MEdWUlFGQVJ1WlhidW9icC1lYVBOang2aEVBSmJSQjFrU1pWT3VmMXduclNzRWhtRnBONUEzNXFLeTgyRHJYQW93TGtaR2xhV21VcFlVeW9XWWxERnZmUnc9
do you know what is createml and pytorch are i feel like you are misunderstanding them,r/pytorch,Z0FBQUFBQm0yeGJ4YkhNLWJaN1hOeW1zMGxrUlJuQTFjTGtfWmxKeFFNSFA0WFI2c3dzQndEVHZDa2cwZEJ5SDRYODNHMjRUamZoYnZrVXZBbkVjdEJJTUJzZmNwazlQaHk1d3VSTHJTNGNXS3NUWnFrYllWNXM9
may be but both are tools for building machine learning models,r/pytorch,Z0FBQUFBQm0yeGJ4WF9Ec3M5Ni10UjJnN19uMnJ1em93TFJza25fUnJPSE11SGlVQ3M4YkNPZmdxNjFhUVp0Q3hKVEo3TjY3cEs1dXZKdG1BMFBaVHpSenM5Qld5T3d2eVVLSkJTVHdyMjgzUXg3VnhuLTJKLTg9
im aware that create ml is a higher level framework but why wouldnt the same be possible with pytorch,r/pytorch,Z0FBQUFBQm0yeGJ4cVNUV3B5NTlKaW9Sdzdrb0NUSW5YdjJtSy1jLU9kNlRSRHBWUS1tazFRbGxiczJCU1NLUU9scFBwU2ZOQVFYTU9SWFBTQV9GbVJ4aENqVGRydnZoeklRODVseGtYMU5lVnk3Zl8yWjV0bFk9
yes they are both frameworks that allows you to easily build up a machine learning model without having to code the barebones that supports it for the pytorch side of things your model is resnet a pretrained model that is decent there are many many pretrained models the pytorch allows you to easily use another model example is resnet which is better but much bigger than resnet and the pretrained model was trained on certain though at least <number> different classes if your data is not one of those classes the pretrained model might struggle initailly but may learn after a few epochs or more epochs for the model to actually learn for the training speeds it depends on a bunch of factors your hardware your code the data etc in your pytorch code you are using cuda meaning you are using your nvidia gpu if you do not have a nvidia gpu you are using your cpu to get better results in pytorch you can do many many things change the learning rate change the loss function change the optimizer changeclean the data change the model etc,r/pytorch,Z0FBQUFBQm0yeGJ4TVRlNWUxb2NWd2NWWjBPZG51Z1BGcjhaVDloQi1DSmhESnJha0xqNWpDbHBZVDVrdTBJY1U4cXpVdGtlcmF5M2tLUl8yUktPMkh3X3djaXg4RlZ3X3FLNXVFcFJ5aFVOY0NVR0VRTlRaVWc9
torch is only a gig or two so it isnt going to miraculously give you a heap of space back for other general python stuff you could also clear the pip cache google it i cant remember the command same with conda if youre using it,r/pytorch,Z0FBQUFBQm0yeGJ4MEpFMFgwZDZlUzR1bHBqeVM3RGwtcm1fYXY0QXVyZFhqWFZQWU5jeEFwRW9YTTlsSW5HUm1EN3pUVHZVVFp0M295cDN4Q1JQbUY0TzJKM1RzV2JZS1E9PQ==
the same is possible with pytorch but needs way more interaction and fine tuning as with createml createml is the apple way of creating models it just works some kind pytorch is a mldl framework with a strong scientific focus it just works is here not always the case without some effort,r/pytorch,Z0FBQUFBQm0yeGJ4cHdsalh1UU1rb0x3UUNVNXhjcGx5MnlwQy02bTZVWHdMSWUwbmN5RENiVkY0NFdJQ0VKMmM3N1JxajZXN2dPZklmbGpPVXcwcmV1VmNwYk0wNjhhWlE9PQ==
hi good answer thank you ill experiment a bit,r/pytorch,Z0FBQUFBQm0yeGJ4Q3pFdTQ0d0t1UjhtMWw0aFR2UnI4YzFzb2lOMldWMXk2b2NMTms0WFYwbkhJbEhTckVjN0hyVUFweWtqWnlHOUQxYTFCWGRRQTN2cld4VnE4bW82ZEg1MXVqb29jdE1Dd2l2MWZnVG9xSDQ9
du hxd,r/pytorch,Z0FBQUFBQm0yeGJ4bGtLU3VMLXFkNkhqSFVwTlYycUw2cXlwaUlYV3MtSlNnNjdmTXhVeHN6NEdRVk1mYk0xbG5mMUNPRmllaDdFYzZpM205NGt5c2pJVnphSW8wU2tWS0oxZlBGMzFNNi1zeFlwaTlSNHlCZEU9
i think pip install torch also download other libraries like matplotlib and numpy did you do it in a virtual enviroment or on your system,r/pytorch,Z0FBQUFBQm0yeGJ4RzFOWHJOYi1FVERKZ2JlTTVpX1NDT3F4Z3ZUY0JsZ1BQaWlIZm1aZ2hSSFJ3UGEtOVNXZ1RlZHZXSHpHUzdZNkxmVWNFWmd1UmE2RFIzbzZiSGR4S1lqX1VxX196R1U2VmVjMnRrZlJ4V0U9
use virtualenv and install in it easy to uninstall or just delete the virtualenv folder,r/pytorch,Z0FBQUFBQm0yeGJ4LXJGY0tDSkNrS1NacE5jdGg5V2RDSVRyMVNxcmtMbDdCT1hNZG9hWHBoaFhYcGJodDZWOUxLT0E3a0tJYTBJNUdadEk1TGpXRk5fb25odmM5bnExdlE9PQ==
i use conda idk why but i just do,r/pytorch,Z0FBQUFBQm0yeGJ4VHdPcmI3UXlOWlRXUXVlSFRRbVFURnQ3b2lKWVhiYnUyeGtxd0s4YVBHQWF1YnJMdWx1eXZfT0xEdWhqaWx4aGpsd0dya0ZiRnJhT01XQ095YXVhWGc9PQ==
i tried with pip but even though the versions are correct for my cuda version torch doesnt see the gpus now im trying with conda,r/pytorch,Z0FBQUFBQm0yeGJ4RlVqODBxcmxyRmlZYmRWS01fSFFMcjZTNDkyc2kycEE2SmcyeTF5ZDIwUTEtNHpyR0I3VmVmX0tCSUR6SWE4V1pwRzVfZVROZEFxbFgtcXJ2d0Z4eWlhSDhyYi1vT1J0WF94R09FbG9haUE9
now it works python <number> | packaged by anaconda inc | main apr <number> <number> <number><number><number> msc v <number> bit amd on win type help copyright credits or license for more information >>> import torch >>> torchcudaisavailable true,r/pytorch,Z0FBQUFBQm0yeGJ4TWpZSWZaX1ZJeEpucGc5WFJOSWNqMDA4aGVWYnVwN0Y0OGJDQjRTalBuYXh0WEdzTGNBeFJ4VnVVZ2xGMk5WY0ZDcTE2UTR6dk4tckhTd3ltbjZEalY2R3JBb2lQQ3VyYWg1RXljMDR6MWM9
have you tried turning it off and on again i usually see this when something has updated,r/pytorch,Z0FBQUFBQm0yeGJ5OW8zcW9NanhUQlZkajltWUk5OVBfcE1sckJqbGVuNjJSRFJpRGY1SVpYSXBRZVhtckFhV2RCcjh4TU5NakNwTmRnNVpUTFI2RXBueTM4U05RWGVQVGc9PQ==
tried that already still no luck,r/pytorch,Z0FBQUFBQm0yeGJ5NGZ3UkVOVE01T3NwQ0NqcUdsLWstNWJGdUhDWE9tV3preTBQTFMzand5RFo2azRwR2ZHWXAxZjZPcU9YdXA3cVJWOExHVjdBNjM4MmlxYWdHZ2RwZnc9PQ==
is your gpu being detected try the nvtop command to check if it isnt detected then reseat the gpu in the pcie slot and reboot if it is detected then reinstall everything and reboot i see this error when the gpu stops being detected if you dont have physical access to the gpu then contact your admin if its a laptop maybe an os reset would be the last resort,r/pytorch,Z0FBQUFBQm0yeGJ5OUt1MkRSLXdianlmeG5jNXRsV01GX2Q1OXhvZlFodWxhVlhpanlicEp6T0oxUnc4cUd1STRqTFZSM2VUMVZtTVdfNTdScWdZMjQzazAxY0hvMS1DREE9PQ==
have you had success in running fourcastnet yet i am also working on running the model,r/pytorch,Z0FBQUFBQm0yeGJ5eFhrRmxZdzFFOWhSNENhY3R6NUg3WWllSjQ4S3FwTlJFYllzc3ludjd4NHotR1MwQWZaWXJlSTBrc0ZyT1JXMGZ4VmR2bG1OTy1xSFJudTkzTFlCQXc9PQ==
try nvidiasmi pl <number> and see what happens if it doenst crash it means that psu is not strong enough i assume so upd oh you are on windows what i want to do is to limit allowed watt consumption per card youve got to figure out how to do it on windows yourself also find a way to measure peak consumption rate percard i think itll help you understand the issue better no w is not peak consumption for <number>,r/pytorch,Z0FBQUFBQm0yeGJ5M2tuVVVoNjhpbkl6UnVLTHoxbEdzRmljN3VhREdXYTFSLW5KYmR0bk1xZ1NfUEZ6ZGw5aTRlOUEza0EyN3dLVXdKMFZIM3d2RDFIaDJ5anRDS1U1UVNsOGpseGFPa2VJam9hb2RnSm1ZWGs9
i am working on a windows based system when i check task manager i can see my gpu is visible in the task manager,r/pytorch,Z0FBQUFBQm0yeGJ5TnZyRVlHalpieDlUdTFnWjE2U1hZQWhHR2hubUdwbWo0U0wxa1R2cGYwTlVEbmpzSndwa0JrVXdHSm5NX1dpdFFiQzlaRmIxTnhJY1hkVjlBRHI5S1E9PQ==
try installing nvtop if it isnt already present use it and see if your gpu is listed then try the other steps i mentioned,r/pytorch,Z0FBQUFBQm0yeGJ6YVNDcldXVGp5R3htNHNyUnR3M0NSUzc1NGVYbE9VTVViaWxIbWJ3bFViZHZOaE45R1FjVTVLYjZJSzg3QVl6ZE1ncEhseGF6V0ZaXzh3RlByTzJiZVE9PQ==
you are trying to use pss computing capability to do llm training where have we heard that before back in <number> the us airforce connected <number> ps into a cluster and used it as a super computer it worked because ps came with yellow dog linux preinstalled and it could be tricked into install applications by the user they installed applications that allowed cluster computing on a large number of ps connected on the network but once sony realized that their heavily subsidized hardware was being used for supercomputing they changed the code over updates which prevented any such code from being installed on the machine you see the sony company sells the playstation hardware at a loss and makes money off the games that are sold to the gamers if people buy the hardware without buying the games sony would go bankrupt for obvious reasons that was playstation from <number> generations ago do you think they would have kept any loopholes that this could be exploited again personally i think it would be cheaper to just rent good hosting service from google amazon or nvidia for such purpose or buy a really powerful gaming computer with an rtx graphic card and build a home ai server that you can ping from your laptop or phones you can also get a very fast sufficiently accurate system if install some fine tuned variant of the larger llms,r/pytorch,Z0FBQUFBQm0yeGI1ZTRzekpwM2pKanFjczlBVi1seVZOSDhQWkw1UGEzamk2RlJfTW1FdWJuRGQzSVhQTDF1YzQ4SldNZXprdjR5NTc3aDVSSGhtMlU0OTVGTVhtSFNObXc9PQ==
thank you for your time dont know about the issue will be resolved or not but i was getting this error while training an object detection model but after multiple attempts now there seems to be no issue with training,r/pytorch,Z0FBQUFBQm0yeGI1SEZidjRJRkMtZlpmMVRLcGNwVlNBd0JwX1lPT1NMSVA5UVhLbGc2LTYyU29haWhQQW8ydlNrZE1RVWJtVVJsVHJSUUtJWWVJUnZ0N0hBMllNX0NuX0E9PQ==
thanks ,r/pytorch,Z0FBQUFBQm0yeGI1MDJMWUgtTzQwRndweFJrU0VELXlhLXFkLUZCM2t3UUg2bmNIbEtTWklJeU51dFZ3YU5xUnRUbHFOdUlpZjdrcVBwRUJTOTF1OGdINlJoeHczVU1tbHc9PQ==
i think point <number> is the main concern idea is correct execution is poor have seen and done point <number> myself now i am thinking about it it could be even with my company the lack of documentation and less accountability or infrequent updates for resource utilization or creation i have thought about having a common page where each and every individual updates or add info,r/pytorch,Z0FBQUFBQm0yeGI1bGlaeUJNWnFtdEZqTW4teFpQOFRQTk4xWVljY3hXSVE2cXNyQkJ2X0JYX1R5bWNhR1doM2VCdVhzS0lPRS1IUEc4a0c5WklIdGlUdDVka2xTYVdCcEJhS3U5ZHBzVXRRRHhmOFpfeURIclU9
have you heard of zillow and the numerous math and deep learning phds they hired who probably contributed to the pytorch library,r/pytorch,Z0FBQUFBQm0yeGI1WTljRHB4TVFVcmFYc2VmU3hDSjB6Z0hYVFd2cmpzZkotb0xUWU1hbGI2Z0wzRFNXUVNmV2ZEWHhTQ0VRTWNzQXdpV2dzODV1WEhlc1F4a3N1UXlwVHVKWVRNdkNZYXA5STNZY1BlWFdPbEk9
zillow and its former employees have published information about the valuation model they developed for purchasing houses before they closed their home buying business <number> zillows zestimate model zillows zestimate is a wellknown home valuation model that uses a neural networkbased system to estimate the market value of homes this model incorporates a variety of data points including property details sales transactions tax assessments and market trends the zestimate is updated multiple times a week to reflect current market conditions<number><number><number> <number> challenges with the ibuying model zillows ibuying business zillow offers faced significant challenges due to the unpredictability in forecasting home prices the company admitted that its algorithms struggled to accurately predict future home prices which led to purchasing homes at prices higher than they could sell them for this issue was exacerbated by the volatility in the housing market caused by the pandemic and other economic factors<number><number><number> <number> operational and strategic issues former employees and analysts have pointed out several operational and strategic issues with zillows ibuying model these include paying too much for homes long holding times and a lack of operational experience in renovating and selling homes additionally there were internal incentives and ambitious goalsetting that led to altering model outputs to justify highvolume purchases<number><number> <number> public statements and analysis zillows ceo rich barton and other executives have publicly discussed the limitations and failures of their valuation model they acknowledged that the models inability to accurately forecast home prices within a narrow margin of error was a significant factor in the decision to shut down zillow offers<number><number><number> in summary zillow has provided detailed information about its zestimate model and the challenges it faced with its ibuying business the companys public statements and analyses from former employees highlight the difficulties in accurately predicting home prices which ultimately led to the closure of zillow offers sources <number> zillow to exit its home buying business cut <number> of staff <url> <number> zillow to shutter home buying business and lay off <number> employees as its big real estate bet falters <url> <number> zillow says its closing homebuying business cutting <number> of workforce earnings miss estimates <url> <number> strategies for optimizing zillow company valuation <url> <number> what are zestimates and how are they calculated investopedia <url> <number> zillow group completes its acquisition of spruce a techenabled title and escrow company as a building block in the <url> <number> building the neural zestimate zillow tech hub <url> <number> zillow just gave us a look at machine learnings future hacker news <url> <number> pdf zillow ken wingert rin <number>ae fdic <url> <number> housing data zillow research <url> <number> zillow home value index methodology <number> revision <url> <number> zillow wikipedia <url> <number> what is a zestimate zillows zestimate accuracy | zillow <url> <number> zillows <cur><number> billion home flipping business was a disaster now a cooling housing market could foil its comeback plan <url> <number> zillow offers <number> down payment to lure homebuyers as mortgage rates hit <number>year high <url> <number> zestimate forecast methodology zillow research <url> <number> pdf zillowannualreport<number>pdf <url> <number> zillow pauses homebuying as techpowered flipping hits snag <url> <number> a whodunnit on zillow the economist <url> <number> zillow group inc spruce point capital management llc <url> from perplexity<url>,r/pytorch,Z0FBQUFBQm0yeGI1c2hoSGt0WWVlUjhobFYwR1h2dWNfR3pLdFh1Smh3dktzMU9WQlBTcWh6NFk5d0JIc0c4QjAtMURhRGd3SEpXSF9EOUp2Q1NrdVpKUmR2S1dta0N4WkJuTF9XVHE0LWZrZDFNaE5ieTV0azQ9
anyone found a solution to this problem,r/pytorch,Z0FBQUFBQm0yeGI1Vy1JSE1BVVcycGNmSDlDdDRaaVFqME9lT210Q01KaWJSV21EdmVDSVI5V0xlTFFybjVqRWtERzhUcmxSM1JOMF9mQldWQkptNC0yVGg4N3Y1enNVTUE9PQ==
i get where you are coming from but its amd who is at fault here they quite frankly do have the resources to make tensorflowpytorchother libraries work with rocm but are they serious about it,r/pytorch,Z0FBQUFBQm0yeGI1akdWOUw0djd6a3ByeTdDQ3EwdUNVZUd4QUdZVUdGeWtlVmpmc3c3ZW53dzB3MTBRWGdnTVhjdVZQZGlzckd1TXJnOTZ6SmdCVGZMV0RtbzRaU1Q0UFE9PQ==
i have a dual rtx <number> and models are training flawlessly on it,r/pytorch,Z0FBQUFBQm0yeGI2OTVOTTI2eTdKRmR1M3hfLWNKVnQ3QXhTcGFOWXp2cHcxckdQbXNKWTkxbDM5NGVPWlZabHNjdEtyM0IwVU1lS2pGN29IN2NEQS02Q1cwM1hWRXpIZVE9PQ==
this isnt a direct answer but torchscript isnt maintained anymore if you need to optimize some python code use numba,r/pytorch,Z0FBQUFBQm0yeGI2d2NSdy1MeXRmOTI4bkVGVThxQm9lMkdqLV9teUV0TTUxTDVrNkp1N2Nzc2VraGg0dGFQUnNENW1SLXlxX2d4bzcxak9rdTZfQ2RCdXBYZzdlU0l2cWc9PQ==
thank you for your response and suggestion i have tried the power limit and it works only when i set it to <number> watts i have tried replacing the power supply with the corsair axi and the computer now works flawlessly at full wattage for both gpus,r/pytorch,Z0FBQUFBQm0yeGI2dHRDTFl3Ty10aUx3cUxEWXJleE5VbVFVdnVvckFIUDEwV3lQa016V1N6eHV0N2RMbnJOVGROd2JJN0xLOWpSbmViazhiaFdvSVIwcGcwSVkzT1ByYVE9PQ==
check out this video <url><url> ive been running this way with zluda and its working pretty well its not ideal but it will fill in until we have proper rocm support,r/pytorch,Z0FBQUFBQm0yeGI2NjdfMkcyMGNpTlRYckhRTkpGYVlwMDEzb2NHQl9vcFpIVy05Z29fX21SYlNZUnE2eDRyR0ZWTmtaTERpYXdnSXJTdmp0alp6bkZnUUhES0hhVFdlM2c9PQ==
thanks does it work with pytorch though,r/pytorch,Z0FBQUFBQm0yeGI2a1NpTUhXb1RweGQ2U3pUaFozVGlxekh6c2hUbm8wakZYVG52ZjEybkdTLVU2d0FIY3BGLUk1NHZMSGFWbnhxRHlGemlNbFI4a0lJZjBaZ1Y0bWN2eFE9PQ==
it just accelerates your python code for the code you gave it should work fine one minor thing is that it only works on numpy but converting a numpy to pytorch tensor is basically free,r/pytorch,Z0FBQUFBQm0yeGI3Smk0aW0wRXhEVUJ3SUZxMGJkUFR5YWUyM1RiZ3RtakFKSnVXcjBvUmZOMDZ0cU5wWC1Mb09nTGZYaGZLMWdUVVlwMnVXNFU3UGtiamJhVC1EbFFuWHc9PQ==
not directly same scenario but we have a big muti models ai endpoints we want to server and was using gcp vertex online predictation it was only used for demo or testing when needed but gcp vertex online predication takes about <number>mins for deployment its a pain in the ass to manually deploy it and later need to turn it off to solve this problem we recently build a pipeline system that did the follow break our multi models endpoint into jobs for example first several models only recognize image type then the next step based on the result do other jobs for each job we make them deployable and executables onto gcp cloud job runs only on cpu atm we then have a coordinating server that receives task input image generally and are able to trigger jobs and follow up jobs based on the previously job result we keep record of the jobs for each image analysis task this system seems so far runs very stable and can scale up very well and we have a clearly record to check the result for each image and the job details we are also using this for model evaluation as we can just give the system a big amount of data and it should scale up and run through all the images and get the result back given its running on cpu so its also very cost effective anyway with all the above said eventually we want to have similar thing for production but i found the speed becomes the main block given ideally we want each image to finish <number>s or even under s i would like some suggestion on this if anyone has some idea the speed issue mainly we are facing time costs for each job to spin up to be fair its pretty good if not for this use case will already take <number>s for each job after spin up loading serveral pytorch model takes a big amount of time the inference itself actually seems to be quite ok even though they are running on cpu but usually takes about several seconds for each image,r/pytorch,Z0FBQUFBQm0yeGI3RkRsYXVDQTRWdkR4M28tMnpYdmQwWXM4Z0tlRE8wNXQ5MU1pUi1yT2plN0FZZFlrSm56MnNRM1JiM05UOEdpQ1I3QzRFZnk3TWZsODFsU0g5UE93Nnc9PQ==
you havent rotations to your input data as part of data augmentation this is the most common way to make classifiers agnostic to rotations can effectively x your training set size,r/pytorch,Z0FBQUFBQm0yeGI3RHR0emJZY0RQeHVsd0t3LWZfUHg5cDlkdEV4QTktcGc4UkE4MFFvTlhjanUtS3R4akZxemVSRHB5TWxYU2xpeEszdy1ZdjhMOHpLbmlMd2prdEJ0eFE9PQ==
first of all you need to understand what a backend is i think you already know this but if you dont i will briefly describe it to you a backend in the context of pytorch is the core infrastructure hardware + software that allows you to accelerate mathematical operations on tensors typically matrixtomatrix and matrixtovector multiplications after all a neural network is just a huge mathematical function that operates on tensors high dimensional arrays of numbers so the whole purpose of the backend is to do fast math operations by default any personal computer has a cpu and ram this is the default backend in pytorch but it is not the best choice when it comes to doing fast math operations at least not for deep learning purposes in this case we need a better alternative cuda enters the stage what is cuda as i said above a backend is a hardware + software infrastructure what does that mean hardware means the physical device in the case of cuda we are talking about nvidias gpus but not all nvidias gpus support cuda cuda is a special kind of architecture baked into some of nvidias gpus having the sole purpose of running fast and parallel mathematical operations the kind of operations we need in deep neural networks you can read more about cuda here<url> lets continue with software now that we know about cuda from a hardware point of view we need to discuss about how code gets to be executed in cuda to execute code in cuda we need a programming language libraries a compiler and some additional tools we will not talk about because they are not so important to us in the software industry all of the abovementioned tools make up a toolchain in the pytorch codebase there is code written in the cuda programming language compiled by a cuda compiler linked with cuda libraries and in the end it results in a cudabased backend which will run on a nvidia gpu card this was the case for cuda but cuda is not the only backend pytorch supports there are many others like mps apple silicon amd intel and google i believe have one for their tpus all these backends mentioned before have similar toolchains for their hardware architecture by default pytorch uses the x backend supported by almost every cpu around the world if you have a cudacompatible gpu and a pytorch compiled version with cuda support you can optin to use either one or the other additionally if your cpu is from intel you may have an additional backend provided by intel in this case you will have <number> backends to choose from i hope you got the gist of it if there are any grammar mistakes im sorry for them im not a native english speaker have a good day,r/pytorch,Z0FBQUFBQm0yeGI3Vk9RaUN6WGxlU200Z1pNOFhSbGc4UEs0emxNbTZTbkM1UUN0djkzOGlQTW5lTXRDMld2VEFfNGJ0ZkNCcng2SkJWV01TaVhoQWtwYVRyR0ZVZ3M3VnZ3UmJDc0l1cnM4NlZ2VmJ1SlU3dHc9
thanks for sharing i love how you are working around the system,r/pytorch,Z0FBQUFBQm0yeGI3SVhGajBjekFYVEU2QXI2U0lIQVhKUlZka0p0am5VQ2k1aGxFal9uOUdrV25KdGw3ZkVpbEVxdjJHSTc5Vk9CenJwa0dOWW90WWx5UTQ1ajcyczR6Nnc9PQ==
that makes sense thank you for the reply but my question still remains im a beginner here so maybe im not formulating my question well but what if i have a machine with both cuda available through a nvidia gpu and avx available through a not so old cpu im believe that in the scenario above it will prefer using cuda over avx for its computations simply because its probably more effective thus having a higher precedence in the code is there a code or configuration in which im able to see this happening can i for testing purposes force cuda not to be used through some configuration edit i saw that there is a envvar for disabling cuda but is still unclear to me if the backends i see there are interchangeable implementing some common interface as im picturing,r/pytorch,Z0FBQUFBQm0yeGI3dGN4WGZBOVZNMjk0ZTdsZDRhQkxpUDNUOHM5cW1KZVAxMkNLTEVsdjRvN2pTVkZ2bktUbmxtTjQ4TGJtSmxycFBYVmw0UFBPUHcwa1R0VF8zLTVWbVE9PQ==
i would be extremely hesitant to do option <number> on the basis that there may be spurious information in the rotations say one lab that has a higher frequency of a certain condition happens to also send a particular orientation and now your model starts to associate the orientation with the condition i would pretty much definitely go with option <number> and two separate models with rotation augmentation the other factor is detecting rotation when you dont have a ground source of truth means you have to manually label odds are you dont need nearly as many samples to detect orientation so its wasted effort if you force the process of labelling rotation for each sample i would still use the model for step <number> that classifies the conditions as a pretrained base model for the second one i wouldnt train it up from the ground up but just fine tune im highly certain youll save a ton of compute type by doing this i wouldnt be surprised if the fine tune for rotation detection could be done in like <number> minutes of training time or even less,r/pytorch,Z0FBQUFBQm0yeGI3dWhWa1ZFVXJNRlh2a2wzV0xjSkhPNklaN2l1Nzk5M3RPTlhMYUxCZFMzemFFb28zck92V3pTdUszVGhfZ29MbXRrUnNIcGd6TnNPYlpmRkZBWWJJcmc9PQ==
import torch import time i run the latest version <number> i have an m macbook air gb ram printtorchversion msg = is available if torchcudaisavailable else is not available printfcuda msg for p in dirtorchbackends try msg = is available if evalftorchbackendspisavailable else is not available printfp msg except attributeerror as e pass conv = torchnnconvdinchannels=<number> outchannels=<number> kernelsize=<number> tensor = torchrand<number> <number> <number> <number> warmup the backend by default nnpack is enabled for in range<number> out = convtensor t = timeperfcounterns for in range<number> out = convtensor t = timeperfcounterns printtt torchbackendsnnpacksetflagsenabled=false warmup the backend for in range<number> out = convtensor t = timeperfcounterns for in range<number> out = convtensor t = timeperfcounterns printtt,r/pytorch,Z0FBQUFBQm0yeGI3UlA2UWZ2SFlqMFNnNGxDRjJTRFNxZkRic2s3b1JCdzh5ZkRkZlFRdllwclV3aGZLUU9TbGdYYXh6c0JHcUFpNDkxc0tyLUtRYkRwcGlQSmRaNnVZQ1BQalVGd3czaTNqcTlxdVF2SzJMcmM9
in the above code snippet the nnpack backend is enabled by default the nnpack backend is efficient when working with convnets you can read more about it on the internet to disable the backend is just a matter of reading the pytorch documentation<url>,r/pytorch,Z0FBQUFBQm0yeGI3TXJ1SzNYWnMzaU9jck9DZlIxNFpsakpRMEwzdVpnZF8tMHh2cEJZWlRFOXFQZ3QwMmNEM0pEb2F1QWFzMGJFUWdOUkJZOWJiOGlXeGU1OVZXcVMzOWpsRnBVSTdKWGFZR2JjVXZROGRGdTA9
have you tried normalizing input for example with sigmoid if the values range is finite and known you could do linear normalisation,r/pytorch,Z0FBQUFBQm0yeGI3Umh2MjZxQ3dfZEFxWTRSaWcxdm9KUXRMeklXOFRXeVRuZEo1VFhPOUxTN015aDNwMjVHLXd3ZkVyREhTTnZIcktPeWZBeWVaLXZGaDAtMHh2bHotSVY5bXdRcHppaDRKMlpqd2hOeDNpX1k9
id go with option <number> recently had a similar issue with my cnn classification of numbers and the best is to preprocess to make the classification more accurate its best to reduce parameters for a deep learning project,r/pytorch,Z0FBQUFBQm0yeGI3YmtwdVZlSGx0eGQ4Y3IzT0FGNE5aYUR3NWExT3ducm5RNEdaQlFvRWlBSDJEa082QWtLUnBCU3V6UWg3TGQ4d0FYaFNaNzdwWXZmSUZRVk12aEUybUE9PQ==
i would try a mix of both approaches ie using a single model that performs both tasks however instead of having combined classes like a a etc i would have two output layers one predicting the class and the other predicting the rotation this way the model is optimized to perform two tasks simultaneously the model can learn shared features that are useful for both tasks potentially improving overall performance note this approach may also have a negative effect i would start by experimenting with one model to keep the number of models manageable,r/pytorch,Z0FBQUFBQm0yeGI3YTJ2SzVDUkZfM0xtekdQbFZsam1JYnhqYmRwSzFxSjV3cmhJY1BmNjJLY1NranhPR3R5ak9rT29wU21fY0Q0RnhyQ1o0elRzeDZxT1NackVwZVpnRXc9PQ==
if the question is whether you need to create separate folders to ensure you train test and validate the model with mutually exclusive data the answer is no you dont need to put them into separate folders you can handle this using pytorchs randomsplit,r/pytorch,Z0FBQUFBQm0yeGI3blhFVGZ3cGlEVXpOdzl6NFdPVEVIZm5NSFl2MkZxTU5VYjVrLWtYNFRzdEZzSVREOTQ3Y1NkbnBrcEJxemQ0ZVFpQWlDQTU4V1l2VkU5aFl4cExZa2c9PQ==
rtx <number> does not support nvlink i think this is the problem tho i am not <number> sure at some point i heard one of my work buddies complaining about the fact that they cant use xrtx <number> for deep learning due to nvlink missing,r/pytorch,Z0FBQUFBQm0yeGI3eFFBeWIxWEItQ0pWUFUxel9iRWhFLVhsSzJEM2luaGdWRmNKNWE4WnNnMG00ZDRFRUtqa3RDNjF4U1ZUejQzX1B3eGV3YkNNSTdtb1ZHVFZNejl0UFVvMGoxVGFIaDdVVlU5M2tIQXZRazQ9
thanks the concern about option <number> makes sense to me for your suggestion of fine tune are you saying it will still be valuable that the model that does the classification of image types abcd will also be useful to be used to fine tuned to do classification on rotations aaaa,r/pytorch,Z0FBQUFBQm0yeGI3R1d2SmQtY2I1Ql9LRTMwS1FudTJldjlrNUVwZGVwYnhNbDN1aWFJQjdQY3VYVGlaUTg3RVAxMlRiTW1COWVyeUJnMGFRQmlOdXlSTWozZ1RJNHVmc2c9PQ==
im taking over this project recently and yes now that i looked into the existing training code it was doing randomrotation to a <number> degree which i think is something i can improve on a random rotation in this case is not useful in reality we wont receive an image that is rotated like a random degrees like <number>,r/pytorch,Z0FBQUFBQm0yeGI3dGE1c0w0a2d1SkFYUV9jMVBCazZQRllhcHNsa0x5azJvSVZ2bUdUdGpOMFFYbi1WVUZYTFQ3MmFpRkwwMFpobVp6cVVUVmpvQ0N1d3R1eHViT0gwMVE9PQ==
thanks yeah i would def give it a go as well,r/pytorch,Z0FBQUFBQm0yeGI3UzNkR0pObTVaMno5RTFyUjQ2a3Q3THFVOTNBNWZZWU9IQTEwb2U4ODU0LUxoanBXdDNkTVlJWkVTQVVlc3VtdDZldnU2ZVJyUzh0ME1XUEhDM1JaRUE9PQ==
yeah i think thats highly likely,r/pytorch,Z0FBQUFBQm0yeGI3OXZla0t3djJ4NlJqdUM3d1lkeHVTdDZRY2JHZm8zN2ZYbGxxOWNxWG52aGcyckxkbUhfakNKV1NSV3pVMGpuX0tiNjhQOTJ1WndsZjBwUDJFVlNRcGc9PQ==
ai question,r/pytorch,Z0FBQUFBQm0yeGI3cmxNemphcWFaZC1SRG5hN3lDVmtDei1BWkZ0QVBEQmJMMDczdTRhZ01FRE1VN05uaHZrb2d2NmdicEpZdU1DNm9femxmZUQ3c19TYTlmM1dvSkZoTnlCN1JCak1LY1hlb3J1cjRYaGxyRG89
i think one of the greatest pytorchs concepts explanation is the blog from edward yang <url> here is the one about dispatcher how know the backend to choose he also did an amazing pytorch podcast on spotify apple music and others,r/pytorch,Z0FBQUFBQm0yeGI3TVZ6NzFFQVByNFI1U1NIZmNlSl9fVDMwVHpkaFBhRmpxb1VHVkVjUGM0dUJFMlhlOTVQY0RmVmZyRmViWWdRb3FHbGdWYUVWYnFyaG9KVEF0YVE0RHc9PQ==
im not op but i had the same issue and your advice fixed it thanks,r/pytorch,Z0FBQUFBQm0yeGI4SVlfWjdOclNMdUNsYWpoZWk2VU5vWkkycHF1M2laeHh0dzFuRThmV1RPYTlSSUtDeEpkWVFGOG1hZnVMWld3bUM0dXFWd0tNM3RPbE9UYkZoUEZXNUE9PQ==
chatgpts answer to your question the issue lies in how you define and add the layers in the second code snippet in pytorch for the parameters of a module to be registered properly they need to be added as attributes of the module or to a nnmodulelist when you create a list of layers selfnet = convlayerinc outc for inc outc in channeldefs this list is just a regular python list and does not register the layers as part of the network in a way that pytorch can track the parameters to fix this you should use nnmodulelist instead of a regular list to store your layers heres the corrected code from torch import nn class cnnnetworknnmodule def initself channeldefs=<number> <number> superinit def convlayerinc outc conv = nnsequential nnconvd inchannels=inc outchannels=outc kernelsize=<number> stride=<number> padding=<number> nnrelu nnmaxpooldkernelsize=<number> return conv selfnet<url> = nnmodulelistconvlayerinc outc for inc outc in channeldefs selfnetappendnnflatten selfnetappendnnlinear<number> <number> <number> <number> def forwardself inputdata x = inputdata for layer in selfnet x = layerx return x if name == main cnn = cnnnetwork printfparameters sumpnumel for p in cnnparameters if prequiresgrad,r/pytorch,Z0FBQUFBQm0yeGNDWHNVTkZnekRsWkQtNjZxWVRtOVNQYXdsN2pZWWJ2c1U3cWwtakxudDhqR3FGb1Fmb0d3YnZ3V1RfbWEzRjRJWHJNeHVyVHc1bXppcXYwVFVYOEV0Z0E9PQ==
interesting thanks for taking the time to formulate the question and posting the answer,r/pytorch,Z0FBQUFBQm0yeGNDVWx6TkhuQ1FRN1EyRDhLdVJKdl9KVGFyT0piNTQ2d1haTGt2N1dfaE9xcTRZUHpQVk4tTk5xVkNOeXpDQVJJNkNzMlIyRXo0UzFtTkZLZVBjSndYTFE9PQ==
i just copypasted your question verbatim d hope it works,r/pytorch,Z0FBQUFBQm0yeGNDVlhSTkQ4V3J2UWZmQ2lVbTdMM01RMjMtSkpuS2h4clU1V3hmMVRJNngtZV83RWRKbzdJT1UzbGRselpNMVN4eTk2MGx2RFpCZHBmeGo5dklBOVR4clE9PQ==
it does,r/pytorch,Z0FBQUFBQm0yeGNDeTJMYzExd0w4cF9FWVRvTFJwYklkWXZvNW9TdXhqeDZGbVQ1bTNFcGpIV2I2NXFRdTZaTHBnTnBLMUg2STl0TWtTQVhCeUlDRmpBZHVIcWlPWUlZU3c9PQ==
typically those branches in your code are to support different environments where your users will run it in testing you have to simulate the environments you want to support so you probably want a ci runner backed by a cpu only instance type if you are working locally you can create a venv without the gpu backend installed,r/pytorch,Z0FBQUFBQm0yeGNDOXdGa2hJY3VZNE9fckR1OENJVE1xRmk4SS1XS2duMVpuaVZpbTJ4aUZONnVTSkJNQzVPSGZkdXpaQnVVSTdtd05WS1JpOWFBZFhzSGk1UmlMV05MVkE9PQ==
hmm dont think i follow my question is more about how to write unit tests for such gpu code,r/pytorch,Z0FBQUFBQm0yeGNDSGlyVUdsT3A1eW54QkJrUXFkQy1zMlI4NGpfc1NZQzRSdjJXaXFHTzZDUG5odDJUQ0JHOFNrR29DREU0OHpuMVlRdEowOWF5Z2c4cWpETXk2Q0NYeTFiWlR0ZTVmVWhMMmFfVTYzSGhweVE9
so in your code you have branch for when cuda is available and when it isnt the code should do the same thing just in a different way like using the accelerator if it is available and using the default backend if not you dont really need to write a different unit test for those two scenarios the same input to the function should produce the same result in both cases when you need to do to exercise both branches is change the environment where it executes if you look at the unit tests for pytorch you will see that the ci jobs will execute the same tests in my different environments this is done to make sure all branches like this are tested if you only have one unit test environment then only one path at this kind of branch point will be taken you can change the test environment in many different ways using different hardware or using multiple software environments on the same hardware torchcudaisavailable will return true if the library was compiled with cuda and the cuda driver context can be initialized if you want to test the other branch you have to change one of those things if the computer you are running the test on has a gpu then the easiest solution is to install the cup only pytorch package in another conda environment and use it to run the test that will make sure the else branch runs if the computer does not have a gpu then you will need to configure your ci job to run on an instance with one,r/pytorch,Z0FBQUFBQm0yeGNDSnZ5ZHhBRFNldWlTVDNpSHNwRWhEaXZJR2xkT2xHaVdjQ1dxUWpwSTZTZWVLOEI3SmFoa0FhR3VtZmtzVTJDM1cwbFh0WnNTc0szeVQ0Z2FUWXZUSUE9PQ==
