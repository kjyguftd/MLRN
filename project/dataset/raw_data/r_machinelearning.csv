text,label,username_encoded
"What makes you think technical people want to lead companies ? It's a giant headache to run a company and if you don't like it why would you do it ?   
  
Most of these leading AI researchers already earn millions. Why bother.",r/machinelearning,Z0FBQUFBQm0yeGJTSzBDOFZhS0EtY19vbVJsdktITXdiMFBwRmZ6Z0VEMVZFZ2M0TVlqQVhhZldJNXRfQS1mbU5KWFhYeHRRTjYtUU45ajBUR0VLZkVPQ2FRTkRvbXFTZlE9PQ==
It’s applicable to almost every domain. I am not an expert but for example people will try nature/science and if desk rejected then try something like nature comm/pnas and then try strong domain-specific journals.. and so on. Friend of mine (physics phd) was rejected 10 times to publish. But desk rejected works cannot be resubmitted to same journal. So maybe I think neurips/icml/iclr should ban mere resubmission without a significant improvement,r/machinelearning,Z0FBQUFBQm0yeGJTZ3hiWlRLWjRxR2VUelhwQ3VURmxjNkcyRDRVejFNcHhvN2RLTlZ5X1RlSFNFTGI4dlgtWDltekZ2a3lrU3ZFQzg2UThUUFRDanF0UkZkNm5yQ0VLSHgtd0lZdFNlMUFTQjhQVEtxaE9HemM9
"Thanks, its clear now.",r/machinelearning,Z0FBQUFBQm0yeGJTNzJDMGs3a1dsZ2dnamlxeGtteXk2Nm4yUTZYSkg2eDZ5dkxtTkdGSlFFek9PMXVKOUYtcmJ6dFVVQVE2dEtudG92UVA3OWpjUFpRSmgtdzE1Q0h5dkE9PQ==
Shocked pikachu,r/machinelearning,Z0FBQUFBQm0yeGJTb0NIMjVyQk50QVRKZ2ctLU5IMnVfWHdKV2hreUhRSVpfQ0Nkb3lJWEVfWC1fQy1aQThHbjdWVHczVnFqclYzSHh4dXI4aGlJTkFBVGlSLTdoeHpjNTRWVWxwSG5zUll4aHBvLVIyd1ZYNGc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTYVZFa0xHNzZ4R0V6dGdfUHZpdXJqZnpsYXB5VEZwQkI3Mm90dEZ2ZVc2MGluT1pZc2s4c0FYb0tOcFotNTlRRWR2aDhyc0lyUksxeEZpWWFKODJNN0E9PQ==
"I'm a linguist and a terrible coder, but I'm still well-positioned to lead our development efforts: leadership skills, management skills, and domain expertise are all more applicable to leading efforts than task accomplishment.  As long as you're supported by great data scientists, information scientists, and software engineers/research programmers.",r/machinelearning,Z0FBQUFBQm0yeGJTR0NyVUx3WVd2X1Nfbm9XajBxaW5kaUZCeGxZQ1FSMVlOcFVLXzRfS1A5TW5ZdVQ2Sm1XRkdwMDd1TmlVdTBqRWJVdzNuMlJ4YllzRER0dUVXYW14cFE9PQ==
"This is for data parallelism, but I'm asking for model parallelism.",r/machinelearning,Z0FBQUFBQm0yeGJTMG9IUEVuTnhWUmkzcmFSeV9OakZqRkdXWVNzS09FSmEyVFFLenJhNXdfUGh4MVExUmdCTTZhNmo4OWtTME8wSG1ZejRnTWJzRXB5ZlJpcDIwSFd3OWZiQ2NJSjRDdHlpMXFRcjR4bGJ1SzA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTSW1UeGQwSjcyS0t0bDVLX2xTOHRkRVJkaEtfTW1aLXVCVk4xLWFZRzYyUjRuWXBTWmEwQm5wNUxxRmpXbW5xYjFBRFU4V19GN3h2MUo0cDBnVXE5c0E9PQ==
Demis literally has a knighthood,r/machinelearning,Z0FBQUFBQm0yeGJTaXkyR0ttVjJ3U24xcENMVGtPYTNUdEx2MmpMV1VObUVBeEtnN0xMX2dwUTRfMzI2SHZIUjJqMkFtTzZ6SllVcUgzWG1rb25nZExNLVZxdTRTM2g3OXc9PQ==
DeepSpeed and Composer support both multi and single node?,r/machinelearning,Z0FBQUFBQm0yeGJTckxudm9yTW03QWFXS1hPdWFjVDZwZUxkTWVTWnpXQk5uUk9Hem12bzlKX0NIbXdoWWVTR0MwcjJJNS0tWTZGSWFoYmhZaUU4S1d5b250c2tXYlpZOGJuck9jRXFfZnQyMWNTTnppeE1RVE09
"DeepSpeed also supports data parallelism? It is a framework like Horovod and Ray, in such a way that with use it along with other frameworks like PyTorch and Tensorflow?",r/machinelearning,Z0FBQUFBQm0yeGJTcXoyWGttNkhHQ0ZsV21ab3FFN084T2k4WlhMOHFnNGFaY2tyWWxBWEEwTzJubjhXdnc1OHZFcFFTSzZtN0pYWENtTDdOanVOZEZnMVFDM0Ria2NYTVJnalJuM2FEWGVjWDZHR2paMzVGd3c9
"Tbh, she has a technical background yes, but she seemed a little out of her element in that interview. Not saying a CTO should know every aspect of model production, but her responses were kinda wack for being the “highest” technical person at OpenAI. Makes zero sense a true ML person isn’t their CTO, but then look at the CEO lol.",r/machinelearning,Z0FBQUFBQm0yeGJTbTV0S1dtM2VXTF9pMHpVejNSNENGT21YWk5IaXJPdmZUOFFHZTlQWFNGYjA5eUM5MnpUNFR2MVlxbi1jWEo4dmVWdENwVDRhUXFkaFZ6RkNyUzJabTl5YWp1QjdVVndqdHdnQmJUS3pVZVU9
"Have you used DeepSpeed? If so, do you think FSDP is better than it?",r/machinelearning,Z0FBQUFBQm0yeGJTc0Uta3dxY2tyRnA5OGNIZF9obVA1Y0ttR084RnR3MGVjN2huNlBZTXVscXZxNms1RVhLUmN5aUJfZXV2Qjc5SVpzd2NLRjd5TDh5X0p3dGZqd2xmZzVacVM1NXdSYndmQnIyTHhaeVl3UDg9
Speculation is warranted. “senior” is a full 4-5 levels below VP at a serious tech company. Senior->VP at a failed startup is laughable as a qualification. She’s clearly a grifter like Altman (listen to her sora interview).,r/machinelearning,Z0FBQUFBQm0yeGJTaGEtTTBQNURHOVlpMjA5LTdyQXRLUjhzakFBbFBaUU9fVl95ZGRaUTBta0FmdDdwOG1IOVlENGZIX2RuWC1vanpFM3VkdUtVQzdsZEFzOFN0X0FJR1E9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJTNG90NjJYT1FUeTBlQWVxckpveGpNUjd6aDh4RGNHaTRzWUVMZTEtdWRtLTdqYXlMTjlGaFNVRHhXNjNkYm1iQnkyalA0dnlMRDhlUXIxMUgzaThuckZKck5QcVpOTU5xT201MkJ0MFFTbmM9
"I dunno why you need to do that, but If you Just need them to BE gaussian distributed you can Just do a z-standardization.

Otherwise the stuff mentioned are all good approaches.",r/machinelearning,Z0FBQUFBQm0yeGJTeFBDd09URjFtSEotNGo3NFhoaGRQVFF3ODhsaHJuZi16LXhUV1huT29JTE41Rm0tRlNEekYwYUsxOVBkclpDSXpWcmtZYnd4RWQ4eXJqWlY1Z1NSYklXZGVOaXJPUmptNmRudG1XdEhVSTg9
They also say in the paper that it is only really interpretable for low dimensions so it seem to be more for understanding models for low dimensional scientific data and not something like language modeling(though some have started testing it on that),r/machinelearning,Z0FBQUFBQm0yeGJTMU5aZDFYeVZibGtCd21BYk5CcHJUdC1yY21ZRnVHNDkzV0Zub3JSZmUxd2NVOS1OTDJIYTVUUlBqME12SHNMMzBTdnVDMnNwOVpLUFJNelVVdnA1REtlX0szYVkwUVdCNnpkT3U0YmxyTW89
why do non technical people lead anything? they only thing they know how to do is tell other people what to tell other people what to do! Turns out that's actually hard.,r/machinelearning,Z0FBQUFBQm0yeGJTcDdpN2o1dV9oQnhnY3NQWjNhb0lUWkpNWGI4cTRPZjZZYWs4ZDhaRklSUHVOU0xzVWRsZEI1c29zNVBrZWY1NW1Tc1k0NzBUaEhkWjEwdmdGdTRBTGc9PQ==
"You mean the second, which IS variance.",r/machinelearning,Z0FBQUFBQm0yeGJTNHk1cmtGdG9CdW9QNFBWcGZkX2d4cDdLQmYyQ3BENlp2YkVDT25ER0YyOFNXazlfNmRnclZiRktIMFpDTWhub0Uxa3RobVFjaHhkTTFEY29iNjYyejZEVU9oeTVLUlgxcTN1dmhLSGs1cVE9
Omg best counter-example ever,r/machinelearning,Z0FBQUFBQm0yeGJTcERqejRzaFhDSHhSYm51SS1hZUg3QUN3LV9CMlBLYnEzR3J1eV9QWk9YbE04SjJncEFaQlJYNnRHc051TFNGQlkzUDl2NS1iR3owV0VwY0JnN1J2VWc9PQ==
"Hi, I have a tabular dataset, of which some are labelled and a large portion is unlabelled. I'm trying to minimize the log-loss on the unlabelled data so overfitting on it would be perfectly fine. What would be the best approach? I tried pseudo-labels (predicting the unlabelled data and adding the most confident samples to the training data) but it made almost no difference on the test loss.

Plus, I know the results (as the overall log-loss value) of a couple of predictions on this unlabelled dataset. Any way to utilize that?",r/machinelearning,Z0FBQUFBQm0yeGJTMXNFZGxyZUxuWE5zVGh0ZkdKOUR1UTVxU1RzczJ6aEV3eXVXZFVzTEJsNG05djhXOVB0eW5zRW10S1ZBallPLVBmM29BWHZUQzlFU3NXZExwLTAyMmc9PQ==
They do.,r/machinelearning,Z0FBQUFBQm0yeGJTakxCSXJJZGlwdkhPQmJlUlVkXzRVTVgtT3h6Qmd1Umd1dmxnOFZ5X2JXMUlqcVlqbEpLNlFaYS1mdUFBSkpXRzF6SWxnV21yUGFpVTdSX3hsckxOY1E9PQ==
"You mean second, right?",r/machinelearning,Z0FBQUFBQm0yeGJTRUlzVFl0S2RtSFE2cjRMQUowSWxDcURfRXpmaGlGdElqUm12U0p1MXR6OERkclg0eGVvUFlfZTg1VHZXblBQcTVQbC1KQVZ4OU80TVpMQzZxc2hzcjVoTlpSVkw5ZkNRMDAzLVdGRDR0S2M9
"I have not tried that configuration, it can be interesting, although harder to implement. I have implemented a layer with heads the have 3-way-attention and others with standard attention. It seems to work well",r/machinelearning,Z0FBQUFBQm0yeGJTczdqTGNBY0JPbTE2YWY0NnhZdXdTWjNfTVVFOFVDVURVNWhKYko4TDFHMlNoRHVVTFJpQmR1QXc1Uld3OEFfMmxET0h3MEFOSXk5dVAyTnc0SWZpR0E9PQ==
"The set of skills required to lead a company and mislead investors is basically the same as being a psychipath: charisma, lack of empathy, and being a believable lier.",r/machinelearning,Z0FBQUFBQm0yeGJTNzlnMU5STm92anZKZWNtbVAtWnJKcG02elE3amd2M3dtUDVLU0FicTd4SlBsbVBTemowMmNVY21CUlZmSU1CbThEMGNyQ0RId3NPZkg1ZzRDd25UNXc9PQ==
"This depends on the Test 
E.g. the Shapiro-wilk Test assumes there IS a Standard distribution.

I guess you have to choose what Test based on ITS Hypothesis. 

Source: https://en.m.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test",r/machinelearning,Z0FBQUFBQm0yeGJTQTlmb1R2Rm95aWJmTkh1VmExN3pMNjc2VDJNQWNVUllKYzQtRW9JbWVqNzZIVUk1Q0I0dXE1WjUxQVBHYWY3VndMQ3BQcWZkamtuTWhSVldFd0F3U25OdGs0cjgyTHpsc29mektLTE1uNHM9
"I would add to the conversation that there are many kinds of technical. Someone that’s good at ML might not be good at LLMs, an LLM expert might write terrible functions, none of them may be good at architecture, and the architect might not be good at contracts. Of course they’ll all think they are great at UI.",r/machinelearning,Z0FBQUFBQm0yeGJTbVJ6OEVjQWtUcUltX05YWnFUaFZNT0dESjBEeWxVamVndmpJRmlMbDZLTlZ5OEtMNnlrRFdtZUl1Si15cUt1VWs5aERFdU9lYW9TcVN1T3RwVlFtVVo1aGdMZ19PaE8tU3Y2bC1DRXdYMDA9
"yes, ty.",r/machinelearning,Z0FBQUFBQm0yeGJTUGhvVlpMR3AyLXU1M1RrQzhMdWk1bXRNaWMxdDNHOW1wbnA2N0xDUF9pTUxWOGtPWEVwQkFLT3FGT3p1X3R2bkRHSlozQXVkWWpvcHVuSWtwdXBkX1E9PQ==
"I really miss what this place used to be. It was so nice having multiple trains of discussion in one place, rather than following things all over the place on X/Twitter",r/machinelearning,Z0FBQUFBQm0yeGJTZ1h5aHVGTnoyV1V5RG5QaVBodFgxeXU4bExHRmtZRUVwTlpCT3dXb1lpWVFSdFJkeVlBNDJHNFZzZTN4UElaSS1EanB4Nl9CbnNIenBQaThnaE1hUkE9PQ==
"I'm an engineer on a team working on an LLM-based support chatbot at my company. In my opinion, these types of tools are very important.

Building around LLMs presents a lot of challenges that I haven't encountered before in other types of development. The universe of inputs/outputs from an LLM is so broad that it is hard to effectively eval it independent of live interactions. Sure, you can (and should) build up some eval datasets that you can run automated evals against but they will barely scratch the surface of the range of inputs/outputs you will actually encounter so your best quality signal will come from real-time monitoring of customer interactions.

I can't speak to the usefulness or quality of any particular tool though since my company is notorious for their ""not built here"" mentality so we've mostly built these systems out from scratch.",r/machinelearning,Z0FBQUFBQm0yeGJTYnhqRVdoTm9NUk9WbnVrT2ptVUZhSjFWNC1Dakt2TVlpNEQzSnY4d0Z2TkZEVm84bW9teG1mZ2ZvUURVZXJqaVp0cGJIMHpuczFBNHZORUFscDJWZDA5d0ZHWVdPbUJCekdoRzZZNy14RUE9
"I'm not sure what you mean.

The theory of the null hypothesis is the same regardless of your statistical test. The point is for it to be rejected, not necessarily for it to be ""accepted.""

Typically we would say that either we rejected the null or we failed to reject the null.

But you are right that the null hypothesis depends on what you are testing. Sometimes the null hypothesis is that your distribution is gaussian, or that there is no difference in means between two populations, etc.

EDIT: To clarify, I think I see what you were trying to say. But my comment was in regards to the specific null hypothesis that was asked about in this thread and its about the null hypothesis in general.",r/machinelearning,Z0FBQUFBQm0yeGJTaEpmS1Fmbl9WNF9ONDlUc0c3aU9NS1phOUpPZ0VhVjRZbGNqSUxQV09hYlZaV0FRWURpSTNtQ0JzM3dhcnhvbFBqWjVURkZMVnNhTk5CR3k3b1E5alE9PQ==
and?,r/machinelearning,Z0FBQUFBQm0yeGJTLU9DOTdiaUctWUdaUXV1anYxRlFJREQwRV81a01UNzRaTGx0eFQ0WGZoWG5YYU9RVWhTNXdiMUtyU2lRdW9pQlRTcXhEX3A1VjdVekt3MjNaODh6MFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZ0ktdGV4eV8zVnBFVVVmV0pUdW1iTF81UTctTGZxZkZOUW5ZQ0dIbXRJMUtjaVMzdjVlODNmd1FJRFY5cGJZUmJkLXhYRUZXN3pKOVUxSzhNVG9QOXc9PQ==
What types of functionality have you (as an internal team) implemented and actually found useful? So many features and data points offered by such tools that it's hard to know what everybody will really go back to check and what's there just to puff up the feature list.,r/machinelearning,Z0FBQUFBQm0yeGJTcXI4YTZhbi1ocEdWQVFMdjRhZnJpaDBhejlreVkwZFctZUFqTWs0UnNaYk1lNWYta0pwUTJhMVVkdV9XU29Zb1JRSUtnNHNFQXVvUjBRdEVGWVB5azhtdE94Qm9RcHBqQ0NGd2MyLXBDQ0U9
We've looked at dozens and at the end of the day just rolled a mini one for our needs. Maybe if we scale we'll look into it. ,r/machinelearning,Z0FBQUFBQm0yeGJTNXEyajQ3QnYtd2pkc2FIbXJYaEhTWmNMWDVWVjBwN1NmclVQVHVZRGRMLUhUU3ZQRFZvbHdUaVhDN3VieVZwNDFZeVYtWmNtd2JWNS1XTVlKVjM2ektZVk53ZGRlVUJwaVZId2VFRFcwbUk9
"What specific features from the ones listed in the OP did you end up implementing? And why not using off-the-shelf, was it the pricing or just preferred to in-house it at this stage to avoid a learning curve?",r/machinelearning,Z0FBQUFBQm0yeGJTRlp4RzBhZ2dvQW1jYk1ScjlmRWt1ZGxodW1heW9BcURiT2tNeElvTkc1M1BnaTRVZGpPTmVrZjZ0Y0wwaUlWWUpXWWdGaDFrdFVyLUhFS3NlUlRTUE5yV2x0VEN0cF8zeDJ1N0NlQm8tc2s9
Because you're not signed in and they want you signed in because it's expensive and they need to pay for it with ad dollars,r/machinelearning,Z0FBQUFBQm0yeGJTclJzLTU1RWJkUG1HeElQNHd1ZGlFYy1ieG4yaDR5X0xjUjhIaGZScDg0Unl4c2hyNV9mZnJNOE1TUVRuUWtHblVhXzFZWkxSNGZ1Z3Bnc1hFcFVCb0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTak1SVzlxR2F6blhlZGdzRlZ2MHgtRDg0Q0Ewd0VIaUVmTmZWOE5uNkVMRFBBR09EN1BJekdTV21RWVNzaTRUaUd2N3VVd1VMVmJQUXczZk1ONHNJTHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTN1RxRXJTSXZqU0NPaC1EV096anlVT09FcTBVeFRPaDRMZkRfai1pcnhNdWo3NXg1RHRORDlDQngtS01JN01xdzdDcmdWOWJtdTdFMUZSUXdDcXRiUFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTVGV1cHFKTGt4dHVJUEZCQmNRVlh2T0N1OXdseTBWRDRSdVhZcFpHNmVoZzd5Y3FfMURBel9pcHprWFNTTjZURWh1XzZuMTh3STFaQnVza092NFhGc3c9PQ==
"Could somebody explain what the ""input\\_channels"" and ""output\\_channels"" mean in this architecture? I'm trying to run TSMixer on the M4 dataset, but the multiple ""output\\_channels"" are throwing me off",r/machinelearning,Z0FBQUFBQm0yeGJTTUszV2RNMF9EdE1mTjIzTW9rUTV3ZVctNHoxai1Ud2JoS1k3dW5HR3FORjdOdWdLMGIwdE15alRsQ2VmYjdOd2p2bU9XSnBhSjNXUEVUbGdGUUNOcGc9PQ==
"I wonder if intention always was to turn to a for-profit entity after initial research phase. Considering that Sam Altman is at helm instead of someone with a research background, speaks a volume of their real intention. After Microsoft gave them $10B-$13B credit (I don't think Microsoft ever paid that in cash vs giving them most of it as cloud credit, but I could be wrong), it was obvious how company was switching gears already.

If OpenAI stayed true to their mission then they would have certainly come out with solutions for may of humanities problems that can be solved by AI. Instead they have started a rat race for gaining market share, not only specific to AI, but getting in to search, music, video and other industries.

It was interested how their chief scientist leaving grabbed no media attention. Even Elon Musk never came out to speak about why he actually parted ways considering he was never short of funds but probably he already saw warning signs of Sam Altman navigating OpenAI in a different direction.",r/machinelearning,Z0FBQUFBQm0yeGJTZWZxaHNlSk4tYU1yVFg2SkRDYmVlM05rMGpadXF6RV9ZMy0wQi00Um1FcnpKWHB1cThROGowTWNBUFNxSXY0R1E3b0FvTUdONUZFdS1VQ0poR0x4bFl3RGZ4Yjd4OVA1V0NSWnZDbC13bDg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTY2Z4ODZfQkE4eC1BYURlcmIxeUZvR08wc2swbTE2TnJ2UEpMRktrZTh0WTdabEJEaW5oS0ZnWVVjSHVuWDZKTGQzNDdmd19WUDZRWHVQY2xZd083OWc9PQ==
"Translation: ""She's a woman, so she can't possibly be merited to be a tech executive""


I see this attitude so much in tech it infuriates me, and I say that as a man.


The fact that people question women as tech leads and don't think non-technical people should be leading AI companies is exactly why tech people have a reputation. And the reputation is not a good one.",r/machinelearning,Z0FBQUFBQm0yeGJTMWhZcGNqUXdoZWZ0T0xPSGF4RldQam5EVnZ5c1o1TGNsNWduSHVaaHJOSVU3SjdjRTBlSDJzbUZnbWpjUnhIaGEyeG1mZFk3bk40dUh1S0lrbUd6d2Z1bmtWeDYwcVNuRE85b0g2bDhsODQ9
The kind of skills that gets non VPs paid,r/machinelearning,Z0FBQUFBQm0yeGJTdVpZU3BLVHprUmpKZUFOdGVyd0NlNWFBek1uZlNCd1FzZ3k1anI5VFVvX0FDTmFKMXRIYzYxbDR3TmoyT3JhZjJFRnE5UnZ5NU9GZDFKNDdSZnhXSFVYajJwLWExaXhncTZub0N5VnhuVWc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTUWhFTk1JTWJza1dONUEzU2swX1VmSm1mYnVLREZ0TWxIZWxkNUhrTWcxaGEyYlVFemFpNjlXaTdEWHVnRHhvWjZZMFZYanVlTlVHbnFLME9MZjhkd2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTTjlfZVFBQmd2bjZNNld6NFVOSlBXZm1oNktSd3o1akZjYTgwWXYyNXFONDZOcEswdmJIZnVKS1hNczFmM2VQVkVxQUFZM2dFR0F0d090dEtCWFN2ZEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTSEF0QXlLYWhfYzFHZUp6UDRpUE1jR0xZQ0t6RkpCM2ItVERibUNPQkVya3FSWkRXd0pnVmpNZ18xZDh3OW5EYXN6QS10TFl6RmFqUkJyTUF6dFN3dEE9PQ==
"I like how you conveniently ignored Sora lmao. An extremely significant development that they have made through doing amazing research recently. With their dead research arm.

Also, their new realtime voice-to-voice mode is audio in and audio out, without the need of text. This is a very big development and probably required extensive research to achieve considering no one else has done this. Building a model that is this multimodal by default requires a lot of research to get right. I hope you know that you can do research outside of things that are llms.",r/machinelearning,Z0FBQUFBQm0yeGJTaGJtM3pqYTVZMml3Tl9ObFVJS0xxb3N3aEtqcU5PbmlyaFB0RXl4Ny1FaGdETTVDXy1KOHRJeVZuS2xhYldXYm5jOG8yVHpwU09QUGRVeUhVMWw4Znc9PQ==
The world is f**ked up this way...,r/machinelearning,Z0FBQUFBQm0yeGJTZi1LR3VJamhvcFJIWTFpVVR2ZFBrek05Y2pYWGlfa29KVEhrNEJnb2FqM0Z4Y0N4dE4wU1BFWFpXWEs0cGRYdFItYzdoMzFRYVFNTWhyYk56S1E2ZXc9PQ==
"I think it be worth trying to combine a 2-way multi-headed attention model and add a 3-way attention piece, but likely try and find a low rank representation of the 3-way attention… l",r/machinelearning,Z0FBQUFBQm0yeGJTY0x2ZTJqTUdETnJlLW9vd1RwVF8yWklGU1lqSFo2UWlvRk9UdkxtdFVUNDVQNXlyR05vamgwVC02azctR1FCanJoaC1tTUh5Y240ZmVweW42eWczYXc9PQ==
And to convince all the nay sayers here Id show that a 2-way multi headed + 3-way attention model beats 2-way multi headed…,r/machinelearning,Z0FBQUFBQm0yeGJTZVgzVjhFMlg0UlY1T3A0VEV5WlhlWUs4ZjYxWTltNWlfcExVS2tkVFY1N1lsTE50cmFmUEh5U3BNYmpwRU9MSmJNSEhrZU4tb1VOYXVpZEJicnpmaVE9PQ==
"Supporting what you said, sometimes a subtle online presence is better. Look at Musk 5+ years ago before he was fully out.",r/machinelearning,Z0FBQUFBQm0yeGJTbTVId3ZtQ0dxdVZ2Q3FtOHBGZmJrYnRTQUZsdWpOZlN4TUF1SkthMEJQRUFqaVlUcjhWQ0kxeHYxSlZESzNrbkMxSV95OEZjUzdzME45X0JtTjZSaVE9PQ==
every resource is less if you want to do deep learning. cloud is best or desktop with top most gpu is all you want,r/machinelearning,Z0FBQUFBQm0yeGJTN3puLVItTnlBbU9uMmZLRDNRN1ZTVDRqQ3Q5R0Y5Mnd3eGxZTHBVeFFSZ2JZQ3dLRXVNMXItNnYyVmNqV1Q3VWpFbndicERKM3RSdlRvMGxoQjU0X01ub3hRSVJ6S0lZcEFNZFdJV2pwWkU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTcVJwWnA5NXV2d2pqVG02bmRabVZHWmZIM2FyandQT3ZvbTdPOHRJUDQ2WW9JNjdROUtURldZMjF4Mlp0NUVmVlZoUFJwb2h1ajV4dzBpNGUyeVhXSVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTd2ppZlAyWmVyNVMtcmxPdmdMTDV3WFRCeEFnMmJsS0RueVBIdndUSWJUZmdCMmVaNVJIQUZoWXlaMDVNSXowUjVWbVpoVTRoYmxwZGgwV2tBZnMxeXc9PQ==
"Interestingly, there was more invariance baked into the AlphaFold 2 model (in particular they defined an invariant point attention mechanism) that they got rid of in AlphaFold 3. In AlphaFold 3 it is more implicit - while training the diffusion module, they ""create 48 versions of the input structure by randomly rotating and translating and adding independent noise to each structure"".

I would be curious how it performs if I add back more invariance rather than have the model try to learn it implicitly - thanks for the link to e3nn, seems like an interesting starting point!",r/machinelearning,Z0FBQUFBQm0yeGJTVHh0TTVrT3R2MmtqYkg1M3dZVmhHSENXN25PcXpkX2V6MzBrOFoyd1l4UDFieDI5cmdMRFdOa2thd1lMVmxoV0h4T2staXVvTXJtTWV6cWFJN3RmMmc9PQ==
"There are different types of machine learning. For most of it, you won't need such a high spec machine. Most of it involves building predictive models on small datasets of just a few thousand rows. This is especially true when you're learning. So you don't need a particularly good laptop to do that. I had a Macbook Air with an Intel chip and 16Gb of RAM, and it got me through almost every exercise and hackathon I did while studying a Masters of Data Science.   

However, there will be times where you need something much more powerful. For example, when you want to fine tune an LLM, or chain several of them together to do something crazy like build a model that converts sign-language to text in real time. When you do those sorts of projects, a Macbook M3 Pro with 36GB won't be enough. At that point, you'll need to use a cloud computing service from a company like AWS or Microsoft or Google Cloud. But that's good! When you get into the job market, one of the questions people will ask you is: What experience do you have with cloud providers? It will be good if you can point to projects you've built using them. And all you need to run cloud services is any old laptop with a browser, as all the actual computation will be done using the provider's computer.  

And because of that, I'd say your most important priority when looking for a laptop is that it has a nice big screen, a good keyboard, and isn't very heavy. That way, you'll have plenty of screen real estate to watch training videos (with a bit of room for your IDE on the side). When you need a high spec computer, use cloud services. When you don't (which will be most of the time), the specs you get won't matter.    

----

Pro Tip 1: Look around for the Github Student Pack. It gives heavy discounts and free trials on a whole range of software, online courses, & cloud services, for anyone with a .edu email address. 

Pro Tip 2: Re Mac vs Windows, it used to be that Mac was the obvious choice for data scientists. Not just because of the Mac build quality, but because Macs run on Linux, and so do the cloud providers. If you have a Mac, you're going to use the Terminal window and get used to all the Linux commands that will be useful as a cloud engineer. Having said that, you can now get a Terminal window that runs Linux on the Windows OS as well, so if you have to use Windows you can.",r/machinelearning,Z0FBQUFBQm0yeGJTbXV1eHR4R2VlRGFFMVNEQmxSRThWZk41YjZNVXdaWW9YSHlOeGJrbjhILUdlOTNiZWF5cFNvd1J6U0YzOHVQTTV6eWVIU2tuU1hKQXpvbHRjOW56UEE9PQ==
"Yeah this idea of rotating data is called data augmentation and it’s garbage in comparison to actually having a network that has invariant or equivariant learnable features. 

The research on symmetry problems in ML is already quite mature.

Btw just because a model is invariant doesn’t mean it’s good. You can construct invariant models by only using distances between points, but then you can’t differentiate 3-body symmetries. The SOTA models have 5-6 body learnable representations built into them.

Also not saying that any of this might be important for your specific problem since it seems you’re doing inverse design, but I think it’s interesting for you to learn about since it could be helpful.",r/machinelearning,Z0FBQUFBQm0yeGJTUDI3VktqaGlzaV9adkxCMWl3Q1hxNDRfMXJNRWgtZkllRi11WjROUEtYOVhUaUF0RW1BQXVhbUFCUVlzREJIRVVyZkhWUE5PZVJxdjBHQV8wOERDOFE9PQ==
That's very helpful! Thanks a lot!,r/machinelearning,Z0FBQUFBQm0yeGJTRm5GbjhTOS14UF9PRF9VQURDNzVNc2JuaXdXRHQzakd2LXUwYnB1eGtyblhKdjBTLUtPUC1SaF9veXF5U0w0Qm5xTUZiTG5Qd0J3RFdGdXI2SFg3S1E9PQ==
"I had a MBP and its a nice laptop to work with if you like MacOS. The thing is that gpu computing support on the M series cpus isn't quite as advanced as it is for nvidia gpus so you might be running into issues. That being said, most people don't really run experiments on their laptop but rather use it as a development tool and experiments are done on a server. In that case, your laptop specs don't matter at all.",r/machinelearning,Z0FBQUFBQm0yeGJTUlpYOXJTMjRrMnJHUmkyc0FkV3NSdGw1M2NLZUQyaHRjdHFzakpJQU1rVjlUcGlORUNJbzQwVWVCcmMzQWNpVDg5RE0yR1NaZVY3dV9BOXFfaDJ5V1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTRjV1MmpQRWxaR21oc0xDRmZiRHQtbGE4NXhSbVlhUFM3UElXUGhOUjA0ZlNUZXlXanhBLXJiY01kTXhpa0U2RktadGJqX1lWcE8xR3hjc2RIcU4wR0E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJTOE1MQ3hqWW52aWxOMzFOZVotUlFINHZJTEg2VElqZE9EUzhNRWtjdkpIeERBMUxwS3ZySldMYzBsb0hfTVAtdGJBWUJFMjJGVVhzclBDTUc2Zm5CRDU0UVh0aTJOOENQUjV6TnBhX2ZaZVk9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJTQWZlVnZadFUyUjkyVU1Dd3BxTnlNVGVOT2puQlpDVUNtYTlnOTVSQXhOMUdEbjZNa29FZFlhQXN3Nk9TVEJWQm40djB0NmhXTVNJa05ybV90MThObFZhUkVhem5nR2hOUUFFWGxRX3VlODg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJTblBKcWJUcGZEUHRxSzJTUlg4X1BNYm1VclRYZzZQazJVWUZwMlp4RzQweHZNd09xeDJHWVpMWXoya0Q1NkNHa0YxVnlHMmE3b0E0bjI3Nlp4cEk1QWtFVGZhWV9mYWtqeVFUTURwOXdXVGM9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJTZnMtMFBQZXJBb1U0SDltSmFvc2FqXzJXNUR0bEEzb1NwbGhIOWxxT05zeEhsTXFqTVFMSkN4VzJWbm14UFBPWElfMDkxaVNhMHhJNGNfZHJOTndwTVJfczdOOUhSal9Xd3pneG03LURqaUk9
Interesting to know! Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJTRWZ3UVFQUVFqOS1UaUwtM1Myam50cXJIcEtKaXNmbUNLYXVYR3ZpVzFIN0hFNGdyV2VBaUs0ZHFJb1I5RXhnQkJJbTZtaG9YVjJiRW5VMXM0U2IzUEE9PQ==
"looping through all combinations is trivial to implement.  even if you can't code it yourself, you can also write:

```
itertools.combinations(...)
```

Like you said, compute will scale exponentially.

FYI, you don't need variable selection for 12 variables.",r/machinelearning,Z0FBQUFBQm0yeGJTc1pONVc0bWFHblhLTXkzeXR5V2dVcElsQlFqbVNiNzJwNHVtcV92TU5nQ1djck01LVFZLThJZFhHZW8xRzRSdFFvMXBWRG5FalUtM0tTa2xMeVk5N0E9PQ==
You may take a look at[ SatMAE++: Rethinking Transformers Pre-training for Multi-Spectral Satellite Imagery (CVPR 2024)](https://arxiv.org/pdf/2403.05419),r/machinelearning,Z0FBQUFBQm0yeGJTZm4wMjN5TFI0SmdEYlNveGx4UzJHZzBuTHlqQUszby1ndWFGQ1VmTkFTdU9IaU4zRHVKcmlfQVgtaHVCMFJfZ0t1OTNNY19QVFQ2RDEyMWRhaHMxQVE9PQ==
"Yes but the bigger reason is usage.

You build a bot that plays a game, then its use is mostly to be a powerful player capable of sustaining exploits and strong adversaries. It's main use case is being tested for its weakest capabilities.

You build a chat bot that answers questions, then its use is to be generally helpful in questions that people need help with. Sure, there will be exploits, but who cares? I don't use chatgpt to make it say inappropriate stuff, and most people don't use it in an adversarial way. It's main use case is in its strongest capabilities.

Completely different problem statements",r/machinelearning,Z0FBQUFBQm0yeGJTSTA5azFLR3RmNGhjTkQ5NEZDQkhoU0lSRHp6SkYxMFRTUHVGekdMaGNycjR5ZkpXYllyVHB6aFJ4ZkJhZkFsdkQzNm5JWlRzSlczdVFNYXpuWlBLQnc9PQ==
They got Boeing'ed,r/machinelearning,Z0FBQUFBQm0yeGJTZC1FaXpGTXZwUjRqR2IzeHhEajNhTFdFTmpJTkpkNjJPQThSQk1xb3ZfUWVLd2dGcnpRVGVzYUdtVVlDMnFSX1U3NWp2bTlqMWF6Sjk1QlVEa3pYbHc9PQ==
"Bo Bo Wr, do you guys think i have chances? Though the scoring was strange since the two BO had only positive comments. The Wr asked to cite a paper that came out after the deadline and not well organized table. Is my first conference",r/machinelearning,Z0FBQUFBQm0yeGJTdzh0eEtsRC1hMW1ZQkRrWm1yc2RnNE11M2xnVXc0ZnFnakg3WktvUWFlc0NadlpPVjFNSTBaaGhSQnY5UERzdTVsalQxemY4QUI1TWZFeFdrUTdVdHc9PQ==
"For sure this is helpful to know - it was something I had briefly been thinking about.

The model's loss was decreasing with regards to predicting (bucketized) distances between points, and I found it strange that this was not translating to the final loss. I was thinking about baking in physical properties to help it make the leap from the distogram to a 3D structure, and it does seem like symmetry could be the key property here.",r/machinelearning,Z0FBQUFBQm0yeGJTWnJ4akxKdjJZa2o3ZUoxbkdESVhtLVN1X2tSMzExT2tBZTlULXVMQUdHYWJRNlo5azhVRDNFOFgzN1VHdVJySmxsX1RKck9fdGJBNUJBeGhPcldXRUE9PQ==
How do you identify meaningful research from all the garbage ones? I'm new to this field and find ML in biology fascinating although my supervisor tells me to read these with a pinch of salt. So how do you differentiate?,r/machinelearning,Z0FBQUFBQm0yeGJTeTRVTjhuTDdDaUV3S2VnNlJmaVJOdU5YcHI5ZU1KV2lMWHM3TnFLc25TbzItaWFTWDFDakRBT0NRYzdVNUpIX0lxNnVsTzI3Z0tEV0xTaENqSlAyYVE9PQ==
"Well, you need lot of money to do the ""impossible"" and once you do it you need to capitalise it to keep going",r/machinelearning,Z0FBQUFBQm0yeGJTcVRESmowZ2QycDVYeGlVeTNiS0dRSnpObEN4Q2swcE5fV0gtNlRWNkJMdVJLclBjeXZGRkM4UHlLSE9UTUZuT1UwcC1UZFNfVmpjX1BmT2NzOG1qNG1tMTFGNUFKbXVyMUtwdi1oTHBSUUU9
"I've raised this point about her and been vigorously rebuked (presumably from folks not in the field). Yeah, she did some coursework in Mech. Engineering from Dartmouth, but she is not a Deep Learning researcher. Plenty of OpenAI scientists have given technical talks. Where is hers? When she speaks, it's clear as day the woman has very, very little technical grasp of AI theory. Same for Altman.",r/machinelearning,Z0FBQUFBQm0yeGJTa1ByQUZHNW0xZWVDNVFrSnV3RjV1c29KVVpwYXJERE9VWWFNUVB2WVdTbkFHby1mWjFqZHdPdWRZdWt0Nk8zZnRjTklGTUgzQXRTR0xkVll3Y3BzbFJBV0dkYmp1NlJDUjJIbmU2d21VXzg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTRnZNYXJqd083YVFZZ1BjZ0I2UGlZVDQ0QkFiZTd5ZXltdlE4SWFoU3VsYU44MlBkcHJuYjZXRzFrQllUc3QySmdqb1hmNlpjV0Z1LTNnSldDbENXdGc9PQ==
"Pretty cool! The fact that it's n\\^3 is not super-great buuut might not be so bad if interactions are limited to within a certain range of the current token.  A 4k context is reasonably common for n\\^2 transformers; assuming the constant factors are similar, that would make a comparable context for trittention cbrt(4096\\^2) = 256.

I think Google has a hybrid model that uses linearized attention for long context info and quadratic attention for windows. But you could imagine adding trittention for a shorter window into that scheme.

EDIT:  
I'm not sure I 100% understand the trittention cube method but if that table compares models of similar parameter counts it looks like the clear winner. Seems really promising!",r/machinelearning,Z0FBQUFBQm0yeGJTaEJYRUMwZHVjdUZCclJzWkxRYzlfVERaYW9tS3ZUTjJaRElJcnBmenVFRDV6eDQzdngwWFBFaWZfaXNMNzk1NF9TOWpaZlBSMm8wUjBjOERhem9UZGc9PQ==
"This is nothing against your comment, but I see this VC mindset in the field, and I find it silly and patronizing. The innovation borne from Deep Learning is so greenfield, the Science and Engineering is more than sufficient. Frankly, It's mostly all that matters.These MBA hucksters bring little value, so I don't buy that argument for a second.",r/machinelearning,Z0FBQUFBQm0yeGJTQXZZWFYyQ3ZaTmN6VWk1WnZJeEptRTAwZ1RSejdzcS1lWVdxNV9BNHdPUUlzT0VJUUt6TmVSLU5XLWZ3bUQtZUpqbEZybzB1bi1YUEhaTXk0WVoxNk9ocFlGNnJOT0w1ckUwZDNjVjRnc1k9
There are MBA huxters and tech huxters. For sure an MBA isn't an guarantee of leadership qualities. But neither is tech expertise. I think the point that these are seperate skillsets stands.,r/machinelearning,Z0FBQUFBQm0yeGJTN3JvRzNwLXB2alN4WV9aX1lpR2dRbWM3SzNaVENIU0REekpBbzZ0TFBlLUhpbTI4UzZWX3kzaEJILXc5cVVIdEJ2enhyaU1VbzBPX1hwMlBRbEQtSFE9PQ==
I disagree somewhat. There are more CEOs with engineering/technical backgrounds than with business backgrounds. It’s useful to have someone with technical knowledge at the top and it’s typically easier to teach business skills to a technical person than teach technical skills to a business person.,r/machinelearning,Z0FBQUFBQm0yeGJTUmV5WWZPUENRUGk5NS1PbXlYamJlV0NIS1kzb0ZTNnpiR2hZR3cwT0tzdTlyZHYtOTdFRS1aOXgzQmZrczJvdGZoOG1yZWd0MDZrQmh1RUdOMFJ0Qmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTT1g0V0p4eFhNcm1tRC16b09xVkJvNDBteEF6dklWM3NsWExaeEZUanVnN2F3MGtEaGcxVTNRNnRRek1EUXMyMFVWa2JyZ1RWamNIck8wRXhpZXBWZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTVVFiQllZRGdkV296dEE5SGpLNkZHeWNQWUp0bE5ZbFJqei1SM0xlU3lHVnFtUEUzRDI1N2tTa2hOZmMyeEprVGU5X2l2dDhkV21JSUxSUzNDenVsQ2c9PQ==
"The website, the github repo etc. all give off the vibe of being a closed API rather than an open source effort to me. For one the github repo is ""[Grounding-DINO-1.5-API](https://github.com/IDEA-Research/Grounding-DINO-1.5-API)"", so it is an API to a closed model.",r/machinelearning,Z0FBQUFBQm0yeGJTNVBJdkpUaW1CYTRGRWUtY04ycjlLbWJkejA0WkJpMnN3STk3bjdVVFBtYnhjSGFneWcwd3VZWmoyMlI0NllRUEhVSEF2d2d5RGdJc09CNWdYQWgxYnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTX20xRXJNRGl2OFQ0YWhtcmk5STYyaUxxYlBMR1gzcG5rOEhPakY1YTFLQk5temk2bFR2RmtIZTBEMFFxTGRrZkdwOC1hU0t3SDFqWTRiVEs4cU4wdmc9PQ==
Your best technical people should be doing technical work. That's why they are there in the first place. The ideal leadership candidate knows enough of the technical skills that they can speak the same language but are only middling level while having good management skills.,r/machinelearning,Z0FBQUFBQm0yeGJTS2NIUHFqcnNhQ0I5eUFqODEydkNSbHJRSW1uMzIwZERzNk1UWjloU2tlRDUwMWxnUy11ZGRBZ2lERThXLS1Oc1F1WUZDdEhYQWxrQVlEdm0xVWVXT3c9PQ==
Try https://polygon.io/,r/machinelearning,Z0FBQUFBQm0yeGJTQzExbEJwNDl4OXdoZkhvS0RmRVJIREdvS0pvdFV5RnEtYV9JYTk5aVNLRzBmcXdweGoxOXlHWVE0RW0yRXR6QjZfVFlYZDNROEhnXzJwUVk1NV9fVFBuNHFRdlRfcUh1aHZldDk3ZThHeHc9
"I agree, it feels very much like a SAAS company, but hopefully they will release the weights given the communities response.",r/machinelearning,Z0FBQUFBQm0yeGJTZlJHVlVBcE14SFpDcjBwQjZ5VEE2TjNZaDRiejZsRHRWZnV6d3pEZVd6U1lwQkdrQkk4SjltTWVmLVFkNm8ycXdJUTc3MlB0MU1SRmhISVAxeW5yMXc9PQ==
"Thanks for this. 
For the model I’m working on, not using all the variables is more than viable",r/machinelearning,Z0FBQUFBQm0yeGJTVlRUdG1CUE5wUXppbk51NnlHZ3V0ZGxQN3gxR0tjWGpFSTlpUkM1Q1dqU09rM3lOQjJyc2diYXdlQTVtQW54dTV1ME92bnUxb1FHaVEwUEg1cVJEZ2c9PQ==
"you can read it from here: [https://floydhub.ghost.io/emils-story-as-a-self-taught-ai-researcher/](https://floydhub.ghost.io/emils-story-as-a-self-taught-ai-researcher/), the original link should be back in a couple of weeks.",r/machinelearning,Z0FBQUFBQm0yeGJTbzB4bHBKcXJvQkdBLXNmMjhfb00wVnVPSmZ4NUNXcmR6RnY2VnpISTVfOGRzTV84WFBPdHNhX1U0dm9fSjg5Tk1za1k0YThmOHdYamFHcm5iY1J3dUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTcmNrMndvUER5NEJUc1pWdjhRd3NBMThKd2ZsSXoybzdLbDVoZGppRlFJN3QwNWNzZDFpS3VUaktmYkZIXzM2eS1sOUhUM05hRVQyWXp2QXBwQUpBb1E9PQ==
Thanks man!,r/machinelearning,Z0FBQUFBQm0yeGJTREJQZXJRWURoNEFUNEk3eG9yTnFyVDc5S1dhZkVkMEljMlBhdjdvVGpiUG41TjJpcDVnZW1QRGdlWVV4NGE0RElBdl83Q2JRZnlNQ3NNelNGRl93ZXc9PQ==
">  The “research” at OpenAI is spending on advertising and buying more data to show into the old GPT2 pipeline with an auto regressive layer.

PREACH! I wish this was more obvious to people.",r/machinelearning,Z0FBQUFBQm0yeGJTclp3UjhjWk5VbUNpZHdRVVJqWU5jLVR5cGlXLWQwX255MkJqV0IyT2QwRkxybWEtY21IdnBhTEctakxIc2lDWDVQY28teVpsekNESTBQUHR6RVZZSGc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJTUFg2bV9NUDJVQ3ZIVU9tSG9vUlZmQ1QyWENIMkh2WFlPTllZRTRhQm9aM2Z6MjZtWTFjalowWFAxazNqZTRnbUFVOEZuckZBRzlMNTAxU2k5UjIwT3BRZk9IbXRwVHJ3cDdwb0l0TnNscjQ9
Where is the whitepaper for Sora? Any code? A front-end for end users to even try it? Sora is vaporware in the name of marketing.,r/machinelearning,Z0FBQUFBQm0yeGJTaERiTHdRcTBmdDdQeDVPZDNEQkRXRHN6bmNJZDBLWlVlcDdweFlQQWpDVUdTa1hoamlRQVluZkw3cEpwNDdWSzJEZHVjb1NVaURjNFdaUzltT0w5V3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZmxXS0dVWlNYY0Y2Rno3M3BWR3h0V2pERW8yVWJxRDBnTnZaUXRCVzEzY3ZCbUM4U3dxVzY5MGVRMkota3Ztb1JHMWdwQUp2aWd0ZXgtM2NIcjExclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTWHBxUE9ZWHUzcVRUVXZjd0ZpQnN0Sk13enZLdko3dTBzTGZfVU11RmhNRUZnQUswQUVXV1BZbUxtX1NaUWhpNzJwUU14ZThKOWRWRGRoazVZSjUwTEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTV0U4czRDMWVIYnVkZ18tZHBZRk5NUjNadndzLXhiVDlCUThHNzZQZ3pOTXlwZHFQcExiSTViM0dSMXY2VzVMbVJfai13YVdSS1RvblJ1VUg2STBLSHc9PQ==
"Hard to give a single answer, but--

> Especially when it comes to ""prompt injection, adversarial attacks, profanity, off-topic content"", one can home-bake some quick functions (such as regex on the less smart, and embeddings comparison for the smarter side).

Yes, you can home-bake, but if you are a business of meaningful scale, you probably really want ""the best"", or at least something close to it.

E.g., an airlines company really doesn't want their bot spouting racist nonsense that will end up on Twitter.

(Of course, the price has to be right, but the market is fairly competitive.)

To be clear, this is not to say that *everyone* does this, but it is an example of where strong market impetus can come from.

Now, in practice, the flip side is that the base behavior for, e.g., OAI is actually quite good, at least for trying to make sure you don't venture into NSFW.  So, for this specific example (NSFW tooling), the long-term standalone market may not be huge.

> Or perhaps these tools target larger businesses (50+ employees) who would rather focus on their core expertise and offload all of this externally – like they do with grafana/prometheus/datadog, etc.

Or even startups--if you're a startup, you also should be focusing on your ""core expertise"" and offloading externally everything that you can.

(In practice, of course, the reason that you often don't is 1) a lot of these offerings have high minimum spend, 2) it can be harder for you to absorb integration risk, and 3) you're more likely to be able to absorb the ""twitter post risk"".)",r/machinelearning,Z0FBQUFBQm0yeGJTODlwc1hvdmpTN3JjakNhWjRVMkhDVGttcnhPNzlqQzZfVnFYWGZiNmJFNVdTN0tjS1VDSk9jWnduT3d0Y3ZTWGgtVFY0dUlETXFGdzFNa3RzTmdOeVE9PQ==
"Oh nice so are you implying that someone needs to have a whitepaper for them to have done research?? That is complete nonsense. I love it.

They have released a technical report talking about how things work, of course they are not releasing every nook and cranny, but just because something is not open source does not mean they're not doing research...

Also, they put the tool in the hands of many different artists/filmmakers that have been making things with it. For example, 'air head' by shy guys. Some of these people have been on podcasts talking in depth about their usage of the tool. I guess these guys are just lying out their ass right?",r/machinelearning,Z0FBQUFBQm0yeGJTNUNnd1hxVHFIWExRMzhuWFJQOTNmMmotREotb25weGI5Q19ISW5zYThyLUVLMEcyQjVkZ0NObnh6b0NnQUVhb2ZCQmEwSEZwWkVvTEZMVDU3T21TeWc9PQ==
"OH! We can just make research up without backing it up/peer-reviews? FANTASTIC.

Wait until you hear about my brand new company that has real AGI! You can replace all your workers in a day! We've done 25 years of super-intense research (that no, you may not see any of). DM me to invest!",r/machinelearning,Z0FBQUFBQm0yeGJTN2FqN0tLMHJaSUYtWDlnM3hYY0VtNTNvOWhNRVlENFBJVDZXWmtvbjFodnphYzd1VzF3SGJ1Q3VzU1RHUW1fWXZvdUh0TFBXMDdIUl8wQ2hVWl91aXc9PQ==
Look up Trikafta. I think you may want to look up the current state of CADD and its comp bio component. Lots of great work and proven successes.,r/machinelearning,Z0FBQUFBQm0yeGJTMDFqMEVZTjE3bGtQYkNCUHFQNDh1NEcyT0g5YnM2cDltRTdZYy01RHJXdGFHY3c1eG5NSFN3Sm5oaFBDTWhnalBxOW5KTF9wenhMcHBRbDF4MUw0MWc9PQ==
"how did you get your a100s?  
I am planning to steal them from zuckerbergs garage once the h100s go out of fashion and he wants to splash on some new ones.. then his a100s will leave the house to the garage.",r/machinelearning,Z0FBQUFBQm0yeGJTRnVKck9iS3BBUTVmVXp5N2ZsWXpmdGE4WEJoQ05lRW5UZEZieHFrdGs0aVNXSW5qOENFemZXcUpvUmN1TEtzS25FNFRtTnBIMG85MEVOeEtCcHlKT1E9PQ==
"man, do you genuinely think that chatGPT has any shred of authority? Come on...",r/machinelearning,Z0FBQUFBQm0yeGJTT0VDNkwwWUtFcndWUWlTdm9zbTFUYU9KeXp1WXNQZzEzWURlRTROOEkyRkdSTW5DTUh2Q2t4S2Zfd1JMUzFYcl9jRFN0bzlLQzItbzZlV1NGLV9IS25velBYQ2YxaVRabnoyNUZ2ZzFtWVk9
He needs to speculate because his brain just can't handle an attractive woman being the CTO of an important tech company.,r/machinelearning,Z0FBQUFBQm0yeGJTLVBQNjd1UnMxRmxablRzX1RlRE5EMlhfM251bWlGSEM0UU94dVNubERvLXFqeVVqazg0TlAwSG4wUDcwc3hwS0kzeGUxSFpGWFNMeU9KcjZ1VEluQ2dtTElLVzJLbmlOQkU1VlBUTWRBYTA9
So what do you think then?,r/machinelearning,Z0FBQUFBQm0yeGJTYkdKeHc4NXZ0UGVrdEN0b1NRUDRKUmc2UUpzbHQzSlBaYl9TRUphRWwtcWJiSkprR3V6TWdMdVQtMHJZQXBiR2xyUG42N0QwUzZtMFN1TWpGajhRVGc9PQ==
"Not all leaders seek fame. And fame comes with a lot of negative consequences. Bernard Arnault for example is very under the radar. Limited online presence, rarely gives interviews etc. he's done such a good job of it, that he's not even a household name, which is incredible.",r/machinelearning,Z0FBQUFBQm0yeGJTN1BKTEhoTnF4ekxMVFJ2VHNQMG81U3ZwbmpxQ3FhNzVBOVIydXIxQ1ZkcDVaT3JjdVpub1VHdTFuMmhRbnFROEF4a254YUZhSVFDaWk2Y0VJWTJkQzdDNGRxNmJEemNGRVJqcDNBT2VMZGs9
"they;re leaving it up to opensource imo. Llian weng has this blog going off with all her recent revelations and research finding on arxiv with her friends.. shes' part of the alignement team and high up.

i think they still are publishing but less so.. i also think they are iterating inside their bubble that is close Ai... they are constantly testing getting a feel for thigns.. the podcast by dwarkesh patel was amazing, gave an insight into how confident the team are.. and how far ahead their whole RLHF arm is and essenttially that is the end game for them.. along with the challanegers of multimodal modles.",r/machinelearning,Z0FBQUFBQm0yeGJTTE9QSWNVMHhid2lvNng0UllDd2QtQUt1ZjdlMEJxeUNZWmY4aEdXb084VVNUUDlrUEJRZDE0b1daYkJuQXVidGdSeGlLbDQzd0pEQ3duMHJBOXpHZGc9PQ==
"Mostly the second one to try to analyze/optimize costs and latency. At any given time, we might be processing thousands of requests, so we try to observe if there are periods of higher latency or check if there are any ""outlier"" cases where the LLM gave a shorter or longer response than usual and analyze why that might be.

We are using one of those platforms because (in our case) it was super easy to integrate, and the development time of building + maintaining our own would be much more expensive than just using it.",r/machinelearning,Z0FBQUFBQm0yeGJTQlRZUnZrdWZCU0lGUEVUZDgyTEJSZVFzdmo0VmZKalZaUmZhbG56SzJ1TmlVUFUzQnhmT18yZjR3OUR2RnVZX1VUVlBqLUhlbjN6S05GUUVzWmV6R2c9PQ==
Why would it be most effective for your use case? Without knowing more details about the problem it's hard to say one is better than the other. If it's a relatively simple problem just use a classifier and if doesn't work then consider using some custom network.,r/machinelearning,Z0FBQUFBQm0yeGJTeFZQV1gzX0lvUmoxQkhUU1hHbDN1a01ZTlExQ3FseV9BOGdWa09wVHh5ZElzZTBaWUk2aWtHei1TWXZ4TkR2X0t3cTRtRUY0X1R0MTBGc3hmMTVYNlE9PQ==
Are you talking about the interview with John schulman?,r/machinelearning,Z0FBQUFBQm0yeGJTTGhqcDlpcDEybm5MbGF6aDBBcGJVbWJwaDlFS1QtWUlJNUppUDJYRFR5VmZlaUQ5MzE0Sl9KNXR1NGdsV2FwWlZFU0Itc3ZVd2RuMVB3cXQ5TkpCOFE9PQ==
So what you are saying is using a neural network is valid right? Im doing a 10 x visual transformer ensemble for the multi label classification (more than 100 classes),r/machinelearning,Z0FBQUFBQm0yeGJTaUc5Z2RZempWX1pHb09DTUtpa0hsUDNlbExMRmx4NDV6N0pVZVBmYWM3MkNnUWpoREtoRHdUNWJKQUVVTktKTzZtYVM2WUJocDZ4ZThnQkRab3FGdnc9PQ==
There isn't much evidence that sora is technically ahead of the rest of the field. They probably do have very high quality training data tho.,r/machinelearning,Z0FBQUFBQm0yeGJTTUQ0NXNSZzdMa185YXZmUXRCYnVib0RqYWd1MTE1bDZlRXg1NjdGQWwyVmkyYkxtZ3hTQ3ZxM2dKUFlaRy1XWVlfWjJDQXptVUh2cVFaaXBObjI2WXc9PQ==
"So its just as bad, but it doesn’t matter because theres no cost to mistakes. I don’t see how that makes it better than OpenAI Five or AlphaStar. It sounds like you’re holding them to a much higher standard than chatbots. They both are brittle and fail against focused attacks despite heavy reward shaping, but chatbots have had at least 1000x the investment.",r/machinelearning,Z0FBQUFBQm0yeGJTMkx2UkMzLWoxSUZKZWNEZ28wMEgxM2VPd0FENzVGVXk4bmNUZlZhWktYY1piX1ZGQjR5WHBwSTlianNrNFNwVVpjcGJ5dXBicktUSWhsUDdlRkJHbVE9PQ==
Yeah a neural network should be able to approximate and replicate the outputs of any classifier. You just have to worry about more. You now need to train it and setup backprop and what not.,r/machinelearning,Z0FBQUFBQm0yeGJTbmp2Z29zRy1OM3hqREVJcXRXU09pNnRMVlBMZ2ZVR1pkZGRZWGFSZFNTU2ZJVXVVNFZsTWRjbV9vTm1SRnFGWlNPaUNWQ1d1anpscE04UkdNMWJXUUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTYkloRkh2eWZxWl9hUnhJbGlscDRwQllGeUlmdk80b0RaVV85anpLcm9xbkZfdXh0OWxvSTV0VklOOGZ4UEpKeHJ0REZsNGFuT2stcV9ZMFpOalhrdkE9PQ==
"I work in engineering and use xgboost and lgbm when dealing with dozens of sensors for classification problems when the sensors are direct, cuz its just a lot if conditions. They are preferable to NN as they are lightweight and don't overfit like NN. In other, more vague problems or when the sensors aren't direct, I tend to use more complex algorithms, usually NN. 


I know that your problem is different, but I'd honestly recommend giving it a try. It's 2 or 3 lines of code that you just copy from sklearn library. It's not that much effort and should give you a baseline on what to least expect from your model.",r/machinelearning,Z0FBQUFBQm0yeGJTLWlOU0dvdkVsTkdzbWJTeUdKbU4yX0Exc3R0Zm95a3JyRlZUTGtMakVLbC1vTlNpRVBFX2NSWVJKT2RVV3JXMUdGZktBYjA4ZGZ5SzVPUEFqbGJMS0E9PQ==
The evidence is extremely clear. I don't know what you're smoking. I recommend you go listen to some podcasts of people that have used these tools if you want more insight on people that have had first-hand experience. These tools aren't some made up fabricated idea. They are a reality.,r/machinelearning,Z0FBQUFBQm0yeGJTbGNaMHgtUlV6ZjRWVjF2a1J1czM5YzE2TjFsLWcxSG9hNTltRXI4RFdjemRlRnlRZS1ha1UtdEtSeTJkUWwyOElBYlkxaW12aDlNcXMzQllzZnF6dUE9PQ==
"Alright, thanks for the suggestion. I will try them first",r/machinelearning,Z0FBQUFBQm0yeGJTdkdwbGFqazZxdjdtTmJtMnYwa1FGOURrWWhsSmpBcW02eVJWS2FvNWRPc0pvUmZrNWNNQ2R5VHJQb2lob0VtQjdpUUlVSjlJdWNlRVhaWGc4U21GV0E9PQ==
"Implying that they are just making up research is laughable. I recommend you go to all of the big tech companies over the last couple decades and give them the same accusations. I hope you know that research is constantly being done and breakthroughs are constantly being made behind closed doors in order to be introduced in various products - without any papers being published.

The ignorance is real lmao. Are you going to tell me that the research that Google has done for their search algorithms doesn't qualify as research because they haven't released their algorithms to the public?",r/machinelearning,Z0FBQUFBQm0yeGJTOHZWczJGZjUwUDRDbXptWU5VY2d0Mml2N0lkTC0zaUhHYm9OeWtzOXNHbWdRTVBVRnN6UllGMW1PaDVFVFFDU1Qzd1FwS05UbWJkV2k4UVM1MG9KeXc9PQ==
"I'm not saying it's not real. It's real and probably quite compute intensive, judging from what is publicly known about generative video models. I doubt they're ahead of Google or Meta tho.",r/machinelearning,Z0FBQUFBQm0yeGJTUXN4QU9BbXhpSHk2cUNJVmpnRjRONzZiRjBnMS1pekxfMXVWam5kNUZEQTVTaEpva1JMMUZWWEE3akhYV2VlMzZIampQSURDVFdnRjhDNS1FQkdnLVE9PQ==
"The ignorance is real, indeed.",r/machinelearning,Z0FBQUFBQm0yeGJTX2U5ZklMcXJPU3VTazQ2N2xNU2xlaTlmS1pjMDFxNmJ3RlJSNEZ0aDZUdllTeEJnZTB0a3h6NEo1dkhGQzZ5bi1rcGplT04zMGpJUzNPMElzMzkzdkE9PQ==
"Thanks for your input! And how did you go about choosing the best tool/provider? There are literally dozens that all look reasonably featured, finding it hard to differentiate in the space.",r/machinelearning,Z0FBQUFBQm0yeGJTVHFteTVDT2N2YXVocG1GdjBTb1l6cDF6NW9BOWN2V3ZENHlyNWJRdTY3WjdIZGtaTlJkdlRlc0JWeTJhQzhGSnNUb3E5QndGWnBxQ254WjJIQVFIdGZTMExSSm9ZV0ZlYk1ETmhmMVJ5VjA9
"This discussion was actually a great exercise to repeat some formerly learned content, since i Had to Google Up again what you might mean.

I Just wanted to add that the null Hypothesis for Shapiro-wilk in Case IT can Not BE rejected actually says that the Data IS normal distributed, If IT IS rejected It May BE some other.

However If the null Hypothesis can Not BE rejected you still might have the second Order Error, or beta-error, which you can Not quantify.
IT basically says that, If your null Hypothesis can Not BE rejected there IS still some posaibility that the Data you are Testing does Not behave according to your null Hypothesis to some degree of Error. Therefore you rather want to reject the null Hypothesis, AS you can define beforehand with Alpha, which degree of Error you are going to Accept. I think thats the Most important takeaway",r/machinelearning,Z0FBQUFBQm0yeGJTNy1wM0w4SnloY3lFQ0NBaEM1cVRiVXVvdnpNcVJBUkNaSnQ1SEZyNkRZcEFLQnFzYjZndF9ybE9NcExrQUdBM285S0RSTW1yT0YtMGNPR1BlN3M3QU14aXRnQlZMOHZpV0ZPekNPRXk4Vk09
"I'm working on generative video at the moment. So I follow all of the research and release products very closely. And I can tell you that meta is not even close and Google is still notably behind. And when it comes to products that are on the market, it is a night and day difference.",r/machinelearning,Z0FBQUFBQm0yeGJTQ044MFoydXpEWndLVTFjM3FMNzVwS0ZMUlRHWThiUXdsMWxBTjFOcXQ1UDZ6TDJ5OUNfa216SlRRX0ZzUFBIMVF3LTRzNWZDeXdjbTFxSERYWVpqclE9PQ==
There it is. We got the dodge. I'll take the w.,r/machinelearning,Z0FBQUFBQm0yeGJTNXpPajBvZ0dkSkcyVDNva1Z1RTBSYUFnNnBuT1hBX3lVM3IzR1VROTN6NUlSeUYxbUxXMkk1MDNMWVhza3oxSGx2MmNlSjBsTncyZERjc2NnQjRmR0E9PQ==
"I bet you will.

Do you ever wonder what that whooshing noise over your head is?",r/machinelearning,Z0FBQUFBQm0yeGJTNzlIdExBbUZVcUpzTm1tbFpGQkU3ZTVDZlRqSlVPcFBrcnN6R3FUdWJPQk1UY2o2bTlkdXZmNlJvNUpuS1NQQW1iRFoteDQ1cFphR01PTjBHY3lWamc9PQ==
"I think it's moreso that they finally bothered to upgrade their existing system. Translations have been horrible for a while on Instagram - it worked, but it sucked and not only the translations but the formatting too. It felt like they didn't bother and the quality wasn't that of a top social media platform.

My guess is they are using Llama 3. I tried using ChatGPT 3.5 for translations before and it worked surprisingly well. I would say it out performed tailored translation models on some services, and definitely outperformed Google's Translate. I would imagine Llama 3 is up to par especially since Facebook has been working on translation models in the past as with NLLB and more recently SeamlessM4T.",r/machinelearning,Z0FBQUFBQm0yeGJTX01SZHVtQV81ekxJdUtHbDBvUThROG5hakdCRGNOdGpvcGItMXNUVDhXOTY1YjQ2dHVXNWM1WmJkVG1EZmZGT0k0UzVvTW5uMXdvcnFGSmRyQmU1U2c9PQ==
What software did you use for the voice?,r/machinelearning,Z0FBQUFBQm0yeGJTWThWZlNMR1NEa2pyU0NBTUlyNzlDN1pObTZPemxwN2dQNEtwSXBsQkVibGZNaWVLZDN0QXZTcHJjLTBVbWNxYnBUN1FPMmg0YVBSc0VZeXhUdGFrWFE9PQ==
"One of the papers cited by AlpahFold3 for their modeling choices is this one - https://arxiv.org/pdf/2311.17932 . That link goes to an earlier version of ""Generating Molecular Conformer Fields"" which, unlike the more recent version, says the following:

> Instead of using Graph Neural Networks with intricate equivariance designs, MCF builds a score network using PerceiverIO (Jaegle et al., 2022) (see Fig. 1) which is a scalable and efficient variant of the Transformer architecture. Our model is simple to implement and efficient to scale. Experiments on recent conformer generation benchmarks show MCF surpasses strong baselines by a gap that gets larger as we scale model capacity

Basically, they deliberately avoid using equivariance in order to simplify their model, and they compensate for this by making their model really big. AlphaFold3 is based on the same logic, but they don't explicitly mention that they don't need equivariance because they use a larger scale model.

If you want to do single GPU training then it might be necessary to bake a lot more symmetries into the model, which might make the model design subtle or complicated.

cc u/Exarctus",r/machinelearning,Z0FBQUFBQm0yeGJTMm82SHhVT0M3aGIwM2dydjFVWWhQOXFHWEpEeWlSTDhEVjJUcU5XTkdrUi1IakUydjJ3RFdBZ01rTmp1YU5aX21rOUcyQjBOQXlSQmFOSk9vZWlKZ3c9PQ==
"All the people upvoting this is hilarious. So if there's no paper for it, there isn't interesting research going on. You guys are like toddlers who thinks as long as you don't see something, it doesn't exist.",r/machinelearning,Z0FBQUFBQm0yeGJTaHZ1MXZ1V0FxNUFwX3FCRTlWZ04zUTVZb1lONGYtRl8tcHZGeXdQbkhWRDVNTVFDZnc4OU85Q0l1MjNWRm1hWGd5T00zYXRhTzB1NDJCWE9UaUQ2VWc9PQ==
Your reasoning doesn't make sense. Tree based models are uniquely bad for overfitting. Most of the advancements there were just figuring out ways to regularize the model and prevent overfitting.,r/machinelearning,Z0FBQUFBQm0yeGJTZlpjbjlaWU5hcDNzWlBUNXdDcmh3c205NFRfYmVBR0l2dE9mZXNkbGREZUZpR2oyX0RmbW1qODd6UW1KZDBveWpqOGNCYUV4dXFYZmh6TnRYd1pPcHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTUEZCd0dTTDk1S09pWkpOcGJqc2U0VlZ1bVRfdHBxR0ZCZlBvNnB4ZTUtbnNBYWlYM0FMQW9abjJiNDcxTGxDUFdSVmhGcFI2bFFNYWlqV1RDUGZFM2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTbi1odFV4aks1dDByNzQ3LVJBd3lmd05Kc25jNE1aVGZpeWtDc0RKeW9PcW9hTDZ1WFJ2eVRVUVZFWm9CWVpKUEFQZ0JaVjc5ckFmUGVRYVVvcEtweHc9PQ==
can only train on linux is a downer,r/machinelearning,Z0FBQUFBQm0yeGJTdFFzNWI3VC10WjNzSXNubDdtc3dnNXllZGRWa2N2VFRkZU9JcnlvVTBlYzZoM3A3NTNxa3ZqcWg5aHZqQS11YkpZbmczVDJXczZ0MjZLNUJVbHBIeGc9PQ==
acces denied on tour link,r/machinelearning,Z0FBQUFBQm0yeGJTa0ZoWjFvelg4bEp3QVZhTUdKc0xGYzJURzZpbmc5YnJldTJWd0RzU3hWOWtocHBfUFdMVE84TUl5VHdHUENFNkQ4bEhZbkxabkdrTkpsWnBNYTdNQVE9PQ==
"Probably the wind rushing by as you run to the closest exit, unable to tackle any of my recent points.",r/machinelearning,Z0FBQUFBQm0yeGJTVC1mdWVMSmdiRHZaajFiQXMwX21WSzhUM2ZLdHdYYkpZa3QxWHh3Z0FyTmxxeDMta2otTDdFSjJnNHVaTEZfc3dZVkl2TFF6clRFVGNCaE5nd1NwZ3c9PQ==
"I’ve found that a lot of them are based on OpenTelemetry so more or less they will have about the same features (which I think is part of the reason why there are so many out there, it’s a low hanging fruit). 

Out of the few I looked, I just went with the one that had an open-source strategy and seemed the most reasonably priced for the features we get. In our case, it ended up being LangFuse. Not an endorsement because we didn’t do an exhaustive analysis of all the platforms, but LangFuse certainly does the job.",r/machinelearning,Z0FBQUFBQm0yeGJTODF3cF9Wc05EdGk5dExwdzRUSE84cTNCa21EbE5rMEFBTVcwQ0Q3SGxVVlU2b1JZWC14aWFDX0NUUGNpSkFlQTg0RmdXREVxQl9GR0VEazdoQXNDYWc9PQ==
Honestly I would bet even an LSTM is overkill for finding lncRNAs. Just 3mer counts + logistic regression would likely do it. ,r/machinelearning,Z0FBQUFBQm0yeGJTTVVjTERsOUFsUnFqNWxKNW91Ni1LZjNZZy0zMlYwMi1VRndMRk94eXQzdU1PYUZzSThpc2JwcFlkUnpBNVRtOEpISU9GR3dfWGM1aWhtVUJSOHFEa0E9PQ==
"For what it worths : [https://www.reddit.com/r/biotech/comments/1crm21j/the\\_coming\\_wave\\_of\\_ai\\_in\\_drug\\_industry/](https://www.reddit.com/r/biotech/comments/1crm21j/the_coming_wave_of_ai_in_drug_industry/)

  
(it is still phase 1 so definetely early stages, but encouraging)",r/machinelearning,Z0FBQUFBQm0yeGJTcUZOUFFQNFozb1A5S0VCVE12ZlN1U3pOaURHcHVQUnl5cFJNWVlsd3dJUXE4Z2RRWHJuNkVtbWhNbnRXYWR1Y1otUkhjTXJNaDZ4cXZJb2NvclluV1E9PQ==
"> what would be the trigger

Non-technical management and a lot of money to burn",r/machinelearning,Z0FBQUFBQm0yeGJTRzBzdHQwYTQ3MXRLVVk5b2VCOTRjZGR0WFlZelFWNFJDUGhsNV9hMUZEcmV0Y09HaG5IRnI4N1RseEEySGNIT0Q0VnlvQWstVnlMYlBTWVVXTkVYbnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZzU5Mnh1V3djbmEyeE5kWU5qQlFwSGFWbk1xX3ZOTFVlTTN5SGNrSl8zZXhOZF9jV1NDMHo0aDRnbDRZSG9JVk9XenB6Wk45SVhoSGZSeVBLQ2cxLVE9PQ==
!thanks,r/machinelearning,Z0FBQUFBQm0yeGJTVzl4YXllcW1zenhrLTdNLWp4Y214VWZIN3R0T2d1ZTQyQTU0WFVBS18zc3dFdEVPUEJsXzIweFFtZXZkdFU4bVZ4WVJnTVM5LS1QTXY1ckxEOHRRYUlWUHdUdUNiSGVPM1hxRkVfSi1JSmM9
"I am still waiting for you to present some evidence or demonstration such as: Show me a python script with Matplot lib graphs and some MatMul that proves what you are saying about dimensions: ""There are two ways around that. ,,, The other way is to increase the dimension of the space.""    I do not see how adding more linear functions2 to an existing linear function1 (increase the dimension) is going to produce a non-linear function3.",r/machinelearning,Z0FBQUFBQm0yeGJTLTM0QmRZSGU2anV0WkI4dWtDMzZFSXZXQ0FIRE9LZUI2c0VZSURGWWNoUThUUFpvaE5MX08xajBJckhWNnRWMFdsQWQwSUJ4Mnp1b2JURVJRakRoZFE9PQ==
"We use Langfuse.

Free, open source, easy to deploy. And adds a surprising amount of value for prompt management, and monitoring. 

I'm big on recommending it to other folks in the space. Does what most cash grab LLMOps SaaS platforms do, and better, and it's FOSS.",r/machinelearning,Z0FBQUFBQm0yeGJTN2lBeUhlbzJGV1RpeW5mU2pmeG9hN3AzWTlMbG9aT3F1R3RwWElEcXFaZ21kMFZ3OVplX0lHNEFUeUd1b3FjdHNyYm85cEFmMXpFNDYzZUtVNDVDM1E9PQ==
"Here’s an example: https://en.m.wikipedia.org/wiki/Controlled_NOT_gate#Operation

That’s a linear implementation of XOR. 

As a general rule, whenever you’re wondering “how can I do X with only linear operations”, look up how it’s done in a quantum computer. Quantum computers are Turing complete and they only use linear operations.",r/machinelearning,Z0FBQUFBQm0yeGJTRG11RjY0R3J5aWV4U1RablJBUDVxanJGZWJBem1pVkNZVFlzQXVyTzNUY3dLd19xeTYzemVzRVQ1eGJYbDVmeXJTYVJBVkZRTFF5aVJxSDlfQTJYTlE9PQ==
What is the main value you(r team) squeezed from it with prompt management and monitoring?,r/machinelearning,Z0FBQUFBQm0yeGJTaVRBUDB5SzRFYzI5RnR1X3FRbndZWGFERGNvekgweGRoWWtycE9SeUhzYi1XTGhRZmlTZFFHSEsxUFFpR1pKV3pVTl9QMVRUT1JRSzJZcWJGTHM4aWxrRi0zR2lJWkJCYmF5RXZGYVA3S3c9
"Actually testing for normality is useless in practice. Really there are only two options

* The test will tell you that the dataset is not normal, since nothing in the real world is truely normally distributed
* The test will tell you ""I have too low of a p-value to confirm or deny that the dataset is normally distributed""

It is also the wrong question: You do not care at all whether you data is normally distributed. What you truely care about is ""Is the dataset distributed in a way that I can use a normal distribution as a model"".

Notice that for a variable to be modellable with a normal distribution, it does not have to be normal! It just has to be somewhat close. In practice, there are plenty of things you can slap a normal distribution on top of and not really loose anything.

In general, you have to distinguish modelling assumptions from tests!

I recommend the following: Just plot the empirical cumulative density function on top of the cdf of the normal distribution (use cdfs not pdfs, comparing pdfs is rarely useful). If they look similar enough, then you will be fine.",r/machinelearning,Z0FBQUFBQm0yeGJTTkNsODUtMHY3MmJwc0owclVvXy1jTDYxc2cwVlFOc3d4bk1FdENJWmtQUVYtTktQUE5pR0dkQnVqS2NlUXh1WU10Q3dqMTE2UHU0dFVYWGtMUFFSV2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTR2dMTC1PamQ5V2E2REQzSGFNMFhXV1ROMGRkb2UydGVhbjY0MlJHZlZuRXZ1cWFKYzJ6TE80cWdoYzc5dEpaTDlsaTN4cURCeXpnTzBQQUxCZk5KU3c9PQ==
"Beginning to feel like this thread is product market research lmao

But...

Monitoring every LLM call is invaluable. We can see an entire chat session in the UI, deep dive into Agentic & Rag traces to see how their interim steps go. Good for debugging. See any manual human feedback or automated evaluations on each response. Great for downstream fine-tuning or even generally evaluating our systems.
We can directly see the cost impacts of a new prompt, and the cost of specific APIs and sub components.

We can A/B test prompts, deploy to stage/prod when ready. And generally we get through so many variations it's great to have a git-esque permanent log.",r/machinelearning,Z0FBQUFBQm0yeGJTNWdTZ1paVWhHbXBLeGZldmhUZlRIWXR2Tnk4cnVTUTluM3VtVVVWd3lzZ1V6dHpOS2VtRjNocjRzd1I1MEQzLXpDRU0xcnZ0SWlxdHBoeE40RFVlMEE9PQ==
"Yeah I think this statement is misleading. Computationally, Equivariant models are actually fairly cheap to evaluate, specifically because they do not need to be that big and are very data efficient. I’ve worked a lot in designing CUDA implementations for these models and they are best in class in terms of accuracy vs. Computational cost. 

They are not easy to understand, though, and it can take some time to be comfortable with them if you’re not familiar with group theory.",r/machinelearning,Z0FBQUFBQm0yeGJTQTc5c3RpR255QkdWRGxiVVZnRFlBbDJNYmVUeGdnalczWUo5azFZVUpXakxka05WOGNOUE1Vc1M1WkNDYUNpdlRmUnVGN3VZV1JsMVE1MzlPb3czdWc9PQ==
[Krisp.ai](http://Krisp.ai) is what I use,r/machinelearning,Z0FBQUFBQm0yeGJTeGlzc082b0hPWlNRM0xRbU1aYUptZVEyNmRhZTR5YmZLbWxpTVZlLTFFQkQxa3c3NmtKMEtlRXFtQk9xX1NVci1YV2NmbnpjWm0zUXJqNEFvSDNsUmc9PQ==
"Yes, I think that article is very illustrative of exactly what I’m talking about: https://www.science.org/content/blog-post/ai-drugs-so-far",r/machinelearning,Z0FBQUFBQm0yeGJTZ0pMcmcya3JaR1NlcGFObGJQeTRMWjVLM3FjMk1OMHdWM0h3bW1VMGZjcmVIX0lFUU1RZEszYnpNV0o4N3Q3d1g0N2l4Yy1ja25aZ2xBV2VyZDE4c2c9PQ==
"Right that's exactly what they mean. Theyre not trying to save on computation, they're doing the opposite; they're using simpler models and making up for that fact by using bigger parametrizations in order to do *more* computation. They're literally trying to save on the complexity of the model implementation. 


They say elsewhere in the paper that one of the reasons for this is that using equivariances in this context can require domain specific knowledge. According to them it's not enough just to make a model generally equivariant to e.g. translations and rotations; you also need to make specific parts of some molecules equivariant to rotations etc.",r/machinelearning,Z0FBQUFBQm0yeGJTVndqUlhZT3lWUDR5cEVqTWVad041Z1g1MENpbndXU1QxUDg4OEIyT2JHYTZLYnZoY195Smh3cE5HRi01NVBDbk1TREtYaUp3YXpRZG1rNk5iMk5NVUE9PQ==
"You don’t need to make “some specific parts of molecules equivariant to rotation”. You make the atomic environments equivariant to rotation, and this is done identically for every node in the graph. 

This reads more like a hand-wavy excuse to me. i would have preferred them simply say “we didn’t have time to invest in this direction”.",r/machinelearning,Z0FBQUFBQm0yeGJTRkZRbXRwMGIxbUg2TXNVQUxiemhBSnBsRWlxQVkxc1pRb0hzSEVZcW4zZHhWSlJhZ2ZscHRqVUpGMExERUwxdXdiWVZ0WE9wOU1QbHh1TXNNT01kMFE9PQ==
What matters is what investors think.,r/machinelearning,Z0FBQUFBQm0yeGJTRWNVQVpzNWRnX3hfaW12bXVMT0JZTnNmOTNwUTJsTXUtZXJ2dC1mMzdBOGU3VW5PNFd1SE9nS2FtS2V6c2tzNE85c21LV1hDSnRtRnpGcFBoWHVlTHc9PQ==
Yeah like the people publishing impressive work at a NeurIPS wake up to lots of voicemails & emails & job offers the next day.,r/machinelearning,Z0FBQUFBQm0yeGJTTEU5ZExlSkJOUUFVcWppTU1fY2kxWWJQSXk4YUtZX2ozQXgwMGFZU0NaZ1duVkF1X2t6MERWQUdZSWtBeVNSRmpzc05NT3J0SFhzSXBqb0JCSXplZ1BEZWt0MW1NRGJvYnBZeVVjUVFYSVk9
"If anything, these venues become gatekeeping systems for hiring, which presents some tautological issues since large employers have sway to what is expected and accepted at these venues",r/machinelearning,Z0FBQUFBQm0yeGJTdEMyZUUtTHM1Z1N6QldoMTl0bE03U0lXYkxfU2U2UFZWamZmemdnY3hsWXlJSnI3aDJ1b2FpWTVnNzNDczBweXJGSkRNaUxZZm9FSjNTazM3YXpzdUE9PQ==
"That works even for ensuring that some parts of the graph are rotationally equivariant relative to other parts of the graph?


I don't know a lot about this but the paper makes it sound like you don't want all parts of a molecule to have all the same equivariances.",r/machinelearning,Z0FBQUFBQm0yeGJTYkpSY1dwaG5aRFFMcGpFY0tTS0YxazZsZ3JjMm5LUEJhb204Sm9LNjhHeVFvRl9uRnVuQ2gtVnp3QTJ3RGlXMHBKQWNjU3VxejRneUZVQk9qS2N1RXc9PQ==
"> this messes with the probabilistic nature of the model

Ok, how?",r/machinelearning,Z0FBQUFBQm0yeGJTdGZFQndrV2VlV3YtamFCWWJ0U2pvMnNsVTUybTV2cWRlUDN6YlZtRnlZMFdMakpWdEwxTmRNVGdsV0ZkSHZXMmhQbHB6NFNmOUtHN2pYb3ZOdTRScHc9PQ==
"Yes.

What you want is that identical atomic environments that are related by a rotation/translation to have the same representation. So you do actually want them to have the same equivariances. 

The way you do this is to represent atomic environments in terms of radial and spherical harmonics expansions, and then when you wish to combine these features together (eg to increase the body-order or to do message passing, or to simply make the features more complex), you use Clebsch-Gordon tensor products to mix them together. This operation ensures that the resulting feature is equivariant with respect to E(3) group.",r/machinelearning,Z0FBQUFBQm0yeGJTSVc2cy1abk5JRVBPTm9jTXdNcGhObFBfMVdzUTJyWXM2QXRiclZoOWhkeTJCQW9zMFJfMmN3QXUzTWxpSTF4cU5LSUMySlB2V3NZN3FsRWRTQlJFQ3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTaXN5eWxub25KYnNzekl2ZDFUZDdEQXRaYXBmT1laLVQ2cVlWemxIYjBNcUZzcGI4QkhZR0p6TmpteHhyVEFPY0FIRWlWVFlZcU16dWJnVHhPRmZlbGc9PQ==
"Yes and kind of. It supports PyTorch, Transformers, Accelerate, Lightning, MosaicML, Determined, and MMEngine, but not TensorFlow. 

Read the docs: https://deepspeed.readthedocs.io/en/latest/

& some additional useful links:
https://github.com/microsoft/DeepSpeed
https://www.microsoft.com/en-us/research/project/deepspeed/",r/machinelearning,Z0FBQUFBQm0yeGJTdTlNcW4wVzNBandVX1lubTg1VzVJUTFyWnBOc3JZVEVPbTdKYm9QZExobEIwUkYyRmtGS1JzRW5uOGo4OHdzUHRvdHhIeGJmLUh1TzFvYURnd1NnWHc9PQ==
https://www.deepspeed.ai/training/#model-parallelism,r/machinelearning,Z0FBQUFBQm0yeGJTSERwaG5hUHQ5OTRjZHNFS2hOc1Q0bDB3YVhndWNOOUtsTklpY2xtVDIxTUotVGhCclZ2VHhrenU2LW9XdngxYXViSmJSWWZXS3ZTUVRlblMzUGtxUWc9PQ==
"I used [https://elevenlabs.io/](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2V4RTY5UXdYeWJSSDFqVjhNNFpZS29CNjZMQXxBQ3Jtc0tuQzQ0czFhUUxScU03Y2p3R29LNzBHMzBpeUZMcnZFdzY5aWFlUHJkenNCbDZLei1YRlRORTNMbXYzU3hHQW8wUTc3LV9yWFpkYXVveTBGbUtONjZpM1JzaHJhUm5FX0FJcVBFd3RRbzdVYkt1RWkxSQ&q=https%3A%2F%2Felevenlabs.io%2F&v=gSyDlvzvhg8)  
It is free if you you don't have must text to voice",r/machinelearning,Z0FBQUFBQm0yeGJTTUZESk94bVdiQkRhMWFTNDFtWEhBdFJubzBsalNfbFY2N193Q1Z4Z291QVc2c092Qk1KdGFPdXJlb3owN2ZOM2xFaG5oT1diZzVGc1RPT1phT3cxcVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTaks3N3UxLTJWOTBWcTRvaXVZQVdsN1VsbWVBZnY4MWJRSUpDVGQ5TWhHSy1VRTltaFVGM0M5UWc1bkZ1UlJTMEpVZk1lcUQySUIzcWkxQU1rUGxneUE9PQ==
"A single or a couple of datasets cannot prove anything, because the tabular datasets are highly diverse. The datasets in ""Why do tree-based models still outperform deep learning on typical tabular data?"" are also biased: they only selected moderately sized datasets. But how about the smaller sized datasets or large-scale datasets?

For a better neural network, please refer to ""Excelformer: Can a Deep Learning Model Be a Sure Bet for Tabular Prediction?"" It performs comparative or better than GBDTs even require no hyperparameter tuning (if the hyperparameter tuning is applied, the results would be significantly better).",r/machinelearning,Z0FBQUFBQm0yeGJTM1FaU0dOTFF1RXJUb3RHMFd1cHNFck9venFDOW5wcXdIalZOV3Q3cHNQZzgxcUR4ZGgyZkVrQUdLb05mUVExa3RqUnU2LVZSS2hpYUprT2ItcXZUdWc9PQ==
It performs bad.,r/machinelearning,Z0FBQUFBQm0yeGJTUnRXY29mWEtsZ0pibmNaV0JqWWhwb0NKX3AtM0FoOXp2MGxoQWRmXzF0eHJvVElsT3oydm1FQnlmOHU3OFRYWEVaUUdfc2t1OHhyU3Y5SzJNWXRYSFE9PQ==
"For a better neural network, please refer to ""Excelformer: Can a Deep Learning Model Be a Sure Bet for Tabular Prediction?"" It performs comparative with GBDTs even require no hyperparameter tuning (if the hyperparameter tuning is applied, the results would be significantly better).",r/machinelearning,Z0FBQUFBQm0yeGJTWDE5MTlDcGlEcGUzVTNHMjNuSEozdmlqbWc0M0JDQjJpSFlNcF9VanYxR0NYQVYxVjlqdHlWdS1hZDFEV2xxUC1LR2JzRXhrMzVRYjMteThqazg3TXc9PQ==
"The work ""Excelformer: Can a Deep Learning Model Be a Sure Bet for Tabular Prediction?""performs comparative or better with GBDTs even require no hyperparameter tuning (if the hyperparameter tuning is applied, the results would be significantly better).",r/machinelearning,Z0FBQUFBQm0yeGJTWnpWNXhGbWw3TFhUVnF1QnpYWjFRLUptMGRjOV9oOVdoOHdoNGlzVXpIN1Z6RXJxNl9iRGg2U3pYYWdWeUxLWG1EOXpaUWNRVFFRV2hCSldCNnZKS0E9PQ==
"vectors are probably quite identifiable, but maybe that info wasn't used properly  
even if it was not, there could be some modality embedding + training examples for that",r/machinelearning,Z0FBQUFBQm0yeGJTM3YwMl90NGVCLU1PSi1RTFM2SVRjcmFzaThaNUV0OEFOaU5xS2M3NktQRTNRWGVES3k4Ym1QLUZCMDNLZlRicXZyVnE1azFILUVZbXFWZGJvZ2VvbGc9PQ==
"The tabular datasets are highly diverse.   
  
You can refer to ""Excelformer: Can a Deep Learning Model Be a Sure Bet for Tabular Prediction?"" It performs comparative or better than GBDTs even require no hyperparameter tuning (if the hyperparameter tuning is applied, the results would be significantly better).",r/machinelearning,Z0FBQUFBQm0yeGJTcFRLN3BXTUhrV0RNQUlGRHdDZW1Qd19sRW9SbnVTeU5MU1kxdFFQdklyazRCR3FCR1p4dzRtc0JBaHdKYWxrSzk2amxxRVd5dHNUUzk0UjByWk1fekE9PQ==
You own the copywrite if you have a paid plan. It's in their FAQ.,r/machinelearning,Z0FBQUFBQm0yeGJTSmFlTGNGWV83MDJLamx0RENCbnlDX2hIeURWMG1kd21tYVI4VFZiM1Iwdy1qdW4xQ0JtMmx2WTF4UjJodlJlbVFsTjN1c1lyUFh5SUtFbUJEVldnYVE9PQ==
"Typically, DL can performs better than GBDTs. You can refer to ""Excelformer: Can a Deep Learning Model Be a Sure Bet for Tabular Prediction?"" It performs comparative or better than GBDTs even require no hyperparameter tuning (if the hyperparameter tuning is applied, the results would be significantly better).",r/machinelearning,Z0FBQUFBQm0yeGJTWjNrbTRtV1M0Um1wRG80QXFEa1NBb1RoMkF6Q2dkNzZUQ2JlNVVsQlRUSmk3WFlJbnhhR1FFWjBaMk95cFRtdWNXTGFPOFBrZzlHZEV1T3FBWEJROUE9PQ==
"If it turns out this is a real issue, I wonder if a modality-specific encoding would be helpful. Like add a specific perturbation to all tokens of the same modality, in the same way that positional encodings are used.",r/machinelearning,Z0FBQUFBQm0yeGJTdFo0dnBPOXdFdVVNSGpCV2xleEd1UDlFdE1nUFRVN0dIVEV1TDc3aXBSRG5seE9wS2NlWmk1LWd5NjFwUFRtQ3ZfYjNtTFR2dUh6VVRVOV9yaFNWZGc9PQ==
Oh boy new ML-washed pseudoscience just dropped,r/machinelearning,Z0FBQUFBQm0yeGJTanpjRXk4c0lQOUE5dDNkUi1sVGlVam1LbFJTTkZMSGxKQUJrQTFWNl8zTHF6d0FpREZfYjdxQWN1RVI1TnRfVFQyMXZQM1hjTV9UMnhHUkd2NmQ0bmc9PQ==
"No it's not? It literally has instructions on how to install if via python.  
Most github stuff that's AI related is like this.  
Biggest barrier to stuff like this though is money. Need a Nvidia GPU that's decent to preferably high end. And because Nvidia is dominating the market, they can charge what they like for them.",r/machinelearning,Z0FBQUFBQm0yeGJTVWZNOU91M0VQWkxFVmp1blNjYkZFenhvN0dwb2RQQ05BcTdaTi1oVTJpWmctQU9nUDF3dFZFalhzbmtrTGgzN1EyMUNrNDhid3p4M2pQcXRCT2MxVXRsTTU2NnFlUmlucFFBWS05eElVVVU9
"They should be able to, at least after instruction tuning. 

The image encoding is usually inserted between sentinel tokens like [img]...[/img], so there's always a difference even if the image encoding perfectly matches some text",r/machinelearning,Z0FBQUFBQm0yeGJTR0Rhbl9JWHFZYk1LRUpFRHBzTlZfMVV5OUdzSFkxeVRXUWdYSXF1S1FWTWlUcktDeHBHVy1yalFXWVViYTV5UjVlSFh1ZGllblF5WGlGU1RiY3NCdlAwVmwxeS1IMXd6QkxXRVZPclNCWTA9
Ok so I guess we fire the guy who is the best at both technical and management skills.,r/machinelearning,Z0FBQUFBQm0yeGJTcTcwSUJ1SUZLaEU1TkJKMjQ3SW40di10Q1h3cUFRMEYtY3Z1bjBGVTUxWTVlZTBxZ3V4SFFxWjVCUXM4d0s1cF9YUU83emJMNVZkSWQ3ZmxzUEtVMGc9PQ==
"That’s fair and Language Models are Few Shot Learners is a great paper in its own right.  For me at least, it was a paradigm shift away from the first two papers and felt more product focused.  To be completely fair, my focus pre COVID was applying transformers to protein sequences and I’m still fascinated with their application outside of data that isn’t traditionally thought of as language.",r/machinelearning,Z0FBQUFBQm0yeGJTazN4dGZuRU5WdkkzS0UwcmVfTUJlLWlad0NuQi00RGdfYnpsel9sSVV6T3BiZEx6ZDJ0NFhIOUJRc2RkcDhFRm80UXdIOS1FRmZ1TlJvZ1hVWHBPbVE9PQ==
"Distinguished scientists at big tech (+openai and the like) are paid millions and have a lot of influence inside and outside their companies. Now its hard to say how much the CEOs listen to them, but if you take someone like Yann Lecun from Meta, you can clearly see that his views are taken into account by the executives.",r/machinelearning,Z0FBQUFBQm0yeGJTOU0xcEVzS3lwSHVvOFFJSjNvVjNBQ09DNjMwV08zSjhtUUd3Q2gxRUlxSnFKNzlFeUJ5czlRWGYwX2lFV2ZtUDZJSF9xTUZPckF0Ynp0dW1vYWl5TXc9PQ==
thanks a lot.,r/machinelearning,Z0FBQUFBQm0yeGJTbWFCS1J5Wk4xS0wxcVZ2YlY1R1I4QWlZaUVienFuT2VJQ0h4dm14RkdzSU95eS0yV0hmeHl6NjF5dXM1U1ZZbWlZdlNnYjQ2bXlqSlVQTUVCaWFCRDUteTZ6a2RXdzN2azNPMWNNcTFWUTg9
"Noob question here: Trying to use reinforcement learning on a custom environment using the PPO model from the stable_baselines3 module in Python. I am essentially only rewarding the agent at the end of an episode, and I think this is why the model never learns anything/always opts for doing nothing. Am I on the right track or is my issue elsewhere? Thanks in advance!",r/machinelearning,Z0FBQUFBQm0yeGJTelBmVUROZjdxM1Y0enNZdGRpdFdUb0hBQzkwWWFFNjAtUTFUNFFuVWYtTk5DdnNiSElHV3F1enh2cUQxaVlZbDM2UHpqWVRDbTE2MTVqMV95bkRIcHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTOHkzbE41bVJMTlpZTkhGZ2U2U2FEelJFSUlNWWhaRmQweTJ4VlVDSm1DbUtFSGFQVEFlN2x1R3NyLTh6N1BzTmFCd2dRdFcxWWVSZllBbXc4SFZBMmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTVXc3UldvMDZRbE5VOU1EYW5qemNjVmlqU01NbV85NTZxYnhIRTVQNWlmTlJYTld2dG5Tb0VDMW95UV9NMHBIRWR4VkMyLUZ1N21JdWJBZV90cWQ3Z3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTNTJjM3NRV0tZb3o4MnF2OTV1TzFDdmRwWEd5dnVsTGtUWndaTVZ2Z2RQLTRLWU4wNzN3bzRrTVc5VzFqSklPRFRISHgxcFlyYW9pbTVETGRMYlNORlE9PQ==
Are there any way to train black box parameters? For example can I train the parameters of a synthesizer plugin for music generation?,r/machinelearning,Z0FBQUFBQm0yeGJTbFp6cnBCdFFHWVFzS2E2YUNwbDF3RGlSSlpwZmN1aU1QZ0F3Y19pem82d01pb0tLaGVUSk5hTFVMQ1BHMTN3Y3FsRmhTQmpQS2s5UlZVbFhkV3cxbVE9PQ==
"The research behind GPT1 and GPT2 laid the foundation for generalized pretraining.  What that means is that we can model discrete data sets as a language.  

For video games, instead of using letters from an alphabet or words from a vocabulary, we can create our own vocabulary that isn’t tied to English or Spanish or any traditional language.  For an MMORPG this would equate to using “SpellID 5029” as a *character* in our language like the letter B.  Words are now combos with combinations of spells.  

Since GPT 1 and 2 laid the ground work for generalized pretraining (Generalized Pretrained Transformer) we don’t need a ton of gold standard data to properly represent the language.  Instead we can just throw all the data at it and get better results than if we had a good gold standard data set.  

Going further you could think of PvP as a translation problem.  Bot detection as a clustering problem where Variational AutoEncoders excel and our pretrained base model is a powerful VAE.  

The hardest part is encoding game states though we can get around this by feeding in game state data alongside our “language” similar to how we would feed in image data in document models.",r/machinelearning,Z0FBQUFBQm0yeGJTOXFSQU54V2h1alM0NTRiTmtoLVBnSVJNOVlLRkFUVEpENVVJZXBHX25hVDQzMFJUVTBEMkpZQXp4Mm9faDZkamVFeTk3WWM0SmZibTdYeHJLc25YOWc9PQ==
I'm not trying to make any judgement on the validity of potential data sources or projects built around those sources. But [it's not like this is an area untouched by serious research](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C47&as_vis=1&q=machine+learning+lie+detection&btnG=).,r/machinelearning,Z0FBQUFBQm0yeGJTb2lMd2F4SjU5Z2wwME5mcGJOb18zZ3c3cTlvdE5wV1YxNzRDTC0xWDR4TEFoOVFPT29BcWEwekNTczhYRnZScW9YNVIweWJiZ2VsdXYwcXVQdllyR082TnpuaHVZLVZ5VG92WVFOYkNDTVE9
"It’s bizarre. I’ve seen people in this sub call her a “heavy hitter” and key contributor to AI research. I’ve also seen articles calling her the creator of chatGPT. Give me a break!

First, the fact that she’s a woman (no offense to the women here) and attractive, definitely plays a role. It shouldn’t be this way, obviously, but I think a male CTO in her position wouldn’t get away with a cursory knowledge of their training procedure—like bro, training is practically 50% of ML. I’m really not trying to be sexist, but there are women out there that are equal to men, and then some that are not and clearly don’t deserve their positions. I guess I’m just so used to thinking the CTO should unequivocally be an expert in the field.",r/machinelearning,Z0FBQUFBQm0yeGJTcjh6NFNyckVHMHBJcjdnZDdDVlVESFF4SlV3RDhVVi0xSlZLY1M5Skt4TFhtZS1fclhWTkxjTUstMzFtZFBKZTQ5eUJqYzBMRFhVZ0hJdXcxZ0J4LWtIOWNHZENBSDdoUXN0T3VMTkJ0cUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTMUFmSGgzNUFMSHJYMmJ4aUZPOEFsTDUtSXVwNDR3dzNncnQ4Sk05dTk2SU0tMzVUUHhKOUZhUzFkVHVrUmlUb295SEY1Z2Nla09uTmsyNWZhTExUZkE9PQ==
"I AI-wrote a python script to perform a 2-input XOR.  It worked, insofar as it trained to a ""low loss"" (sufficient for classification purposes) although Not Zero Loss, even with various hyperparameters in the hidden level(s).  MLP Theory states that XOR cannot be implemented without non-linear ""activation"" such as RELU.  I used Sigmoid as Activation for my 2-input XORs, and all the models worked for classification.  I am not interested in ""quantum"" computers which are not logical and not linear.  Your resort to ""you have to learn quantum computing to transcend the limitations of Math and Binary Computations on Planet Earth"" is not acceptable proof of your claims.   Again, I ask you to provide a working Python Script (not dependent upon ""quantum"" theory) demonstrating your claims, or retract them.   I will not accept on face value an assertion that ""That’s a linear implementation of XOR.""",r/machinelearning,Z0FBQUFBQm0yeGJTeHBKcXd2NTJtSUNDUVREN01QaHl3cUc4TkRMeFMwLVhJNGJpLVhoWHZNb0NNOEZmcUF5cm8yVHpyeUFDUENpWmJJdlZkOGNDY0tmb2hROEtRNmJvSkE9PQ==
"I vaguely remember some works in the past doing this but I would guess not any of the recent models. The recent ones do have something like <IMG_start/end> tokens though, if I remember correctly",r/machinelearning,Z0FBQUFBQm0yeGJTMjBIZEpCYXh0QWZIUTBUWl8zMlpNVjBSS3I3bjVZYUV4MlhJZ2pnVnV6YVVBU1F3STV5cERuLXJ3TW5LM1IyR1ZJZGFTa1AwNlR4azFNSmM2SjdQR1E9PQ==
she slept with elon musk,r/machinelearning,Z0FBQUFBQm0yeGJTU2U2eWxaNzVWMHBNUE1DTkQzamJUVDdfazVxbDV2NkxfSzd2VWt2VmNkcmY3aVJfZWpzME1OVmlERGVsVUpHZy01YlRhMmJZOEZ5b3E0SkU0cGg1bWc9PQ==
"Of course, if you have that person, you keep them, and make a hard choice about whether they should work on technical projects or work in management.  In general, though, these skills aren't well correlated, and while you can find someone who is competent at both, you aren't likely to find someone who is the best at both.",r/machinelearning,Z0FBQUFBQm0yeGJTX0d3aUdFZ3R1aWNYUmJkaUN4bW5oa0xsOS1LNndjTnRKLTZJR0ZsaEhyV242QW5Hc3VURGJJcWdockx4ZXBRN19NMF92OXlqREQ0NXA1N2N1UVJsUEE9PQ==
Serious question: why?,r/machinelearning,Z0FBQUFBQm0yeGJTcUJOTllpbXZLNm5oVENjcUtPcVFHUDMxVmUxaWZjeWxILUxkVGRQLUc4QmpEYU9rR1NfWWpfWVh4MXE0ZjlHbVYwMFh6LTFGZ3BESlFITHN4eFNfUnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTYkxqNTlmckZ4RU5qZVpXUWltVzc0NThRcVNVX0Y5eW1qbExlQVAxdWxxdnZia2lpekhsMFFNMGpOZ3F5SUVHZlE0THBFcDE1VGs3NlYwWXc5LU5ralE9PQ==
"I looked at the Wiki Link.  The ""quantum"" mechanisms are discrete Q-booleans and NOT ""linear"" devices.  There is no ""linear"" property to Q-boolean ""quantum"" bits.  They are either 0 or 1 or both, and nothing in between.  There is no linear 0.0000 through .00004 in ""quantum"" math.   Therefore, I completely reject your premise that it is appropriate to refer to ""quantum"" computing principles for evaluating the results that can be obtained by Python Scripts running in the AI and ML fields of endeavor.",r/machinelearning,Z0FBQUFBQm0yeGJTb3k1aURqd05jR0pUd0RzQ3FtV1o0dTZrYXJ4YW1vWmZZYXNuWVdhbnJmWFFyNm1JeUNTWXl2VmdtcTh5Q1FmS0pQbXdaRFdiVnUwdEFEa21HVWdQcHc9PQ==
Heart rate can be detected through skin tone changes to a great accuracy that can be a start,r/machinelearning,Z0FBQUFBQm0yeGJTbW83cENpRF8xNk90dUJ0Yk54dm9KblVLSEluWEhXUHh1WmszZFBKT0NLOUhyUmlFUjJZY3pVMEVqTEo2dUR2YnlWc1dWMVlUTDNJZ0IyemRpWU5RNXVMU0syVmVfRG5QZ0hNQjZEZUYtNU09
"It might be if heart rate was actually good at lie detection. 

The whole field is mostly forensic pseudoscience, though. To the extent that it works, it works by bluffing the subject into confessing",r/machinelearning,Z0FBQUFBQm0yeGJTZmJHcWRHTUQwOFo4Rl96aFNJZHdDVVlRdkxQMHoxR0Q0akJ1eC1IeHFxTUZsV1NnNjJsNzJuMTlTNEhXaUxSTC1BblBaSDdBeEEzbTZZUW5HYWUxSkE9PQ==
"they like Microsoft are going to be beaten by Google, Apple and open source (Linux won the server battle)",r/machinelearning,Z0FBQUFBQm0yeGJTbDM5Q09ITGtma2l2THRQeVNjRW5JNVBVZmVPV2U3UnpoOVktalNzUHNoSXZXcDJKNzMtSUEwY09pLWcxb1FzOFBEczkxa1hLUl9IaWgzaGp3RXVqUUE9PQ==
"That's cool. I came from embedded systems and then got into ML and I am a big fan of small, running local etc.

At the same time I've never seen much interest from customers for those things. 
Especially when the large models are already not really good enough to fullfil the hopes (""here is my database, find me anything interesting and tell me how it can make me rich"" ;))",r/machinelearning,Z0FBQUFBQm0yeGJTWmEtYndjM0pETTRBY1ZEZURNa2dHVXNLc3FZektUM1pxdFM5emdlZ092LUtLaUUycHktNkxwS0pLdWUzWjJtQTgzTXU0TmRJaGdDZ2ZvZDM5MWQxUHc9PQ==
Zuckerberg is indeed a builder but his cs background is limited (not that it matters). he doesn't have a degree,r/machinelearning,Z0FBQUFBQm0yeGJTOWxCZm9tbF9GMnVLeUg5WjZhR3lOckJjcGEtejV6cFByOVA5X2I5c0hoNVRnZlVYcW9rWU9RRmdqY3JZYmdKMlcxMWFoLWJzWmRjQ2tlOVluRmtfSXc9PQ==
It can have a correlation with lying that the NN might detect,r/machinelearning,Z0FBQUFBQm0yeGJTUkZVUEZ2azNGdWppWnBwMmg3ZmNVN0cyRkdRMm5qM0NyLVFuX2FjbHNzdUVfVWNuMUFVQVlLOXRxYUZieUNUZ2dSVFpxMzZwR1JNdnJ5T3ZhclpzSmE0c3FHWTliYWNoRXU2dnNFWnJySUE9
Their research is what OpenAI builds on ie transformers. No Google no OpenAI.,r/machinelearning,Z0FBQUFBQm0yeGJTcnJiT0Q1NlgzMGp4N1pER1NZNk9yUTJlTFlVRjZ3aUxSeFlKNlF2bGowSmNCcjUteE5MQmRUYU9PUjFmUVd3N0dHUlotdUlQcVhtMGtWaVhZWjhYdEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTa2UtWGh5STk1QTF4Q0VUVDZyMGUzdXdSM2ljMldkbUpKcl8wV2p6UUV1bnJGdVVTYm93UTRBZlg3VUl6bEExRG9RUjFrdG5tUG9ORDh6bW5DMXd5OGc9PQ==
"There probably is a correlation with lying. For some people, sometimes. The problem is that there are plenty of other correlations with other factors. Like being nervous due to being interrogated, for instance.",r/machinelearning,Z0FBQUFBQm0yeGJTam9FUnNTZ0g2RVUyTmVMeUk5RUJtOG51Q3UxU1pXbFpSNnJFLXREeTZLVWxLU3NMQVZVdHRwVlZMdGViNERVeDJYVFplVWZLSE9WeXpKQzZiaFZJVkE9PQ==
You could get an initial idea by checking the differences in the token embedding layer between image and text inputs. Intuitively I’d say they are dissimilar but a piece of text that’s describing an image should be closer to the image than unrelated text would be,r/machinelearning,Z0FBQUFBQm0yeGJTTXVSZ0hXMXR6d0lZdWwxdl95SE1FcmhOVXY1aGFGaG54ZHpaMVVqR1h0RjZwSTdUZGlaSFVtaHBhRnB4bThMR09WNGhkXzItNmMzTW9VWTNvTUdnSmc9PQ==
Yeah op needs to do his research about what factors can be detected based on the input that is avaliable,r/machinelearning,Z0FBQUFBQm0yeGJTQ3BHdkVvQXdvMTNjWjlGNU0wUEFvSzR5Q2N6TG5VY1NnX3Y1enROU3d1cTlxbl8xcnBhanBXTERhQ0ZxRmZ4aHY4Y2RXeWpPencwQzZUbTZiUWZqV053N2h4eTFObnBSRkN0STdXMDFJVzA9
"Given a big enough computer and enough data, you could train a 3D NeRF of the entire world. There's no theoretical reason for it to be impossible, it would just be a massive undertaking.",r/machinelearning,Z0FBQUFBQm0yeGJTUzJ2aVBLU1preXpSOXRyQ2RrajM1RHI0SFZfanViSDRWVkNVXzNNSHhKUkVoMk9oa1JkMW5xV0cyMExzMUwtYUlaVmt3SUZ5Rno5M2lQeUk1V01iRjBPZlA1UFBKSUJTOEd0VTdQS3pZUlk9
"This is an interesting question that shouldn't be too tough to test out! Create a dataset from your multimodal vectors with the labels being the modality, and then train a MLP to predict modality from vectors. 

I would guess it depends on your specific model/task (and like the other poster mentioned, whether you are feeding extra information in to represent modality, like sentinel tokens) but I would guess that in most cases there should be artifacts in the vector that come from each encoder in a way that a model could use to tell them apart.",r/machinelearning,Z0FBQUFBQm0yeGJTN1R1LXp1MVV4S2NTX19KdXkxekVIZXV4dm9HNDhrdUo5cXJnRl9JX3NkeUtnd1NTWEdBTkJlMElkck4yRVo5aDJTLTJyd0hRVzg4a0tOYWFzRDA2ZlE9PQ==
I would guess the token space for image tokens vs text tokens would be separate and should be dilenated to the model with some tag telling it the modality is changing. So I'd be surprised if the model couldn't tell,r/machinelearning,Z0FBQUFBQm0yeGJTUUlfSTA3dThjLTB5V0tVYi10TEZoT0lPblc1NTFqeWNEc3daTTMteWxiZEhWMUxHTkpBYjQ4SlVOc1BPTXVzc0d6U2ZnZl9LQ1lCS01LM2MxOEpOM1E9PQ==
"If there is some correlation, there is some predictive power. Now factor in many other variables that have some predictive power. Then factor in the dynamic interplay between some of these variables that has some predictive power.

The end result is a system that is not perfect, but has some meaningful predictive power that can be measured, just like literally every other machine learning model.

I know it’s chic to say polygraph tests are useless, or pseudoscience, but if you’ve ever taken one, you’d probably see the utility in being able to identify some percentage of people who lie (okay, maybe not the sociopaths).",r/machinelearning,Z0FBQUFBQm0yeGJTcy1iLTEwQ3E0b3lzVDVrbHFtNnZqV0p4UTg0RFo0S3FucEQyOHlwcElESU1jZ3pVaXpaaXM3LUtraXlTVVMtbkNPNzV6VElqSVNMZEpaMlAyS2ZYdi1rb1VFeDRfeEp6Ulk0Q0xTZTBGQmM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTbkVTY1had1M4dGpWc2RBd1dSa3R5ZTk2M2RweVJabWN0emNmekRlbWtUNjVzZW5RLS1FZzZBUVRhNDJTakpjT19LV3NkZ3pZV2VnOGhTRUh2clhwaXc9PQ==
"

I'd personally like to see a bigger focus on explainability. It's one thing to look at a pathology image and label it healthy or disease. It's another to say ""hey, see those cells that seem a little more rounded than they should? That's consistent with *X* mutation and positive response to *Y* therapy."" That's the only way we move past academic exercises and into real clinical adoption.",r/machinelearning,Z0FBQUFBQm0yeGJTQzJyeTJDdndTWUE0OEl3YnctUGU5MDg0U3FPN1lPWVBiY01VVTFvc1hIVGd6NEh3ZlBRUGhYT1NLWjNJdndQWi0tRkE3QkNkZmxHM1h1Qm0yMmw0cDFSaGNlMURoX1lyZS1Vamw2alNtNnM9
"When I say explainability, I don't mean some kind of post-hoc feature importance analysis. I mean systems that are actually built to interpret biological systems the way humans do.",r/machinelearning,Z0FBQUFBQm0yeGJTZXczMWJOZkVNc3pZZmp0OFFZdDgyWU5UUmdtZkNZbmlRbjVLZXRRT2JXR2cwVHhzU3BPRV9ZWldfYnZlcEw5S0N3LWNlX1VIQzZHVTJVYXp2dWh2QnRyeFpad1RxOUpGbXlwWXNyMUNQM009
"We should be a lot less carefree about the prospect of deploying naive ML models in criminal justice or related domains. Saying “eh, it’s not perfect but it has some predictive power, so that’s good enough for me” is honestly pretty dangerous. That’s how we end up with, for instance, racially biased incriminations because “it fit the test set” or whatever.",r/machinelearning,Z0FBQUFBQm0yeGJTQzdWRTFkcVp2dS1IMENTYjZTa0Z4UHVVSUswMlMwdElLekFFSk9qS2xIVG5OSUF4a1ZMaFRFdUU2RS1sUTdXVklVemhzWEdDMFFnTzNtR2F4Y3h2LXc9PQ==
"Polygraph tests are used for more than just criminal justice.

Further more, saying it is “just pseudoscience” is being carefree. My point is it’s worth studying like an actual science. Nowhere did I imply we should “just ship it to be used in court”.",r/machinelearning,Z0FBQUFBQm0yeGJTQXJTTzlPLUhLQ1lTZW9FZHNReFJqWjhHNGFZNmw0SmJEbmhwRWRSUlNVbzVDSnRXTjlseWU0OEVwN1RvRW5nV1dyTTE0Q2UwR2NQd25jaW5vX0FzU3NMQlhWOXpEdVA4ZDg2b0FZbjBpODg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZFR1NENKa2I0NDJGN0hrUVVZZzdLa3lYYXVYVDZVSDluNXluRUZSaHNjQjJxYkZNZVZFQzBTUTFwSjIwakdHek1lcng3d2N5S19jRUpMSjVSMWIzc2c9PQ==
i've tried this in my work and it works well! perceiver also does this to some extent using modality-specific positional embeddings,r/machinelearning,Z0FBQUFBQm0yeGJTLXBjU05kUXhVbk5BVTZTLVdDSVlUckQxWEV2VzZ3TWVPOEV6SHJVZURUb0tLb1NOQU5Sa1JsU2FfNkh6YV9KTnAwa2UxZ29LMDVlODA2R3E1Y0JBOUE9PQ==
I think there are more MBAs than CSs/SEs,r/machinelearning,Z0FBQUFBQm0yeGJTb3dOT1o3R0FHaTc5c0o1bEMxSHBwblBKcDg5Rmo4MV9RdnkwbGE5dVR2MXkzMThKMkVlczhzWk5Ja0RIdHMwSWVPN1hNbWd1cG1OUkd5Y1p4U000bGc9PQ==
Interesting stuff. Do you think things like Deepmind's SIMA could potentially sidestep that kind of detection? I've been wondering if AI running around games is going be easy or hard to detect :P,r/machinelearning,Z0FBQUFBQm0yeGJTdFVacVY2Qy1IelVhLWh2d3gxQ1VoYTVXRXM2UFJYR0xiOGgzbTNiQ1NXdTVDT25iZWE0SzBOTmVZbVlEcVFQUW1BZHRWME5iYUoxMURNaUp6OUstTVE9PQ==
"I will be 10 years before you see much from this. Medicine moves VERY slowly. The industry is heavily regulated and a common saying is that those regulations are written in blood. The FDA, EMA, and other regulatory bodies are not going to just fast track this stuff without an extremely good reason. 

AI is feeding into the drug pipeline but you can NEVER UNDER ANY CIRCUMSTANCES trust an AI. It can be used to guide but all safety procedures still have to be followed. People talk about how nice AI is with 95% accuracy while for most medicine you need around 99.9999% accuracy. It is not remotely the same kind of playing field.

I am even involved in usage of AI for medicine and I am also making sure that we go slow. This is not the kind of thing you can afford to screw up. Silicon valley believes in moving fast and breakings things but there is no way I would ever take that approach with medicine.",r/machinelearning,Z0FBQUFBQm0yeGJTWTBMUVJRT1hhdDBiZDgzSXBibFRtWHFvTU9wMjRfdDJubzFiX3dFc1gtVUdJTVlmd1NhZC0tT0EzT1lqQ3dqTDRmMWJTZ01XNXBsYnlNSDZadVlmUUE9PQ==
"Agreed. I wonder if there are any early success stories scientists can use as a reference point, even if they're still in clinical development.",r/machinelearning,Z0FBQUFBQm0yeGJTRlh2OGVuLWhMd0U2QXhaeFRWTjg2bWNWZUJoM2ZJdXVRa19abjNKYk02UHAtdXRoeUs1T0tzLWJXcGFtS3YxNGZqdTBObi1NMUlhSFBLNjk3YzREQllDQlBWNkFNdTNiNVRHdFp3clFIanc9
Good 👍😊,r/machinelearning,Z0FBQUFBQm0yeGJTOE03SU5Sem5WQjRvUWY2d3FMeERSNU9iYUZmcVJUMFVPMFRCcFBYcVRYSEVKTDdvWlo5ZlBCalpFb1RMTFk3RFctc0p1RkxwbEphZzJySzBndzhuamc9PQ==
"I am late in this, but start off with NLP intro books first that are no more than 3 years old. Then, once you have a decent grasp, move to research papers",r/machinelearning,Z0FBQUFBQm0yeGJTempzMjR0VkRfTjdUcEpaaVhkeENYOFhLSkFoeXFVV2RIdU96U3ZQZW5tUjI1S1F3cGo3YXEwNmRtRnpwS2FUcU1YT090ZmNlY0ZEWjg2bjhNZXdfSGc9PQ==
"You can look at the websites [https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices](https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices) or look through journals like [https://pubs.rsna.org/journal/ai](https://pubs.rsna.org/journal/ai) testing of commercial software AI medical devices. 

It takes a lot of money and development but some startups and established companies seem to be making slow but steady progress. 

Access to high-quality data and annotations are still a limiting factor for many applications.",r/machinelearning,Z0FBQUFBQm0yeGJTN2pTX3lNUkdlRjIyUEpDQWlrWVViZklDaS11WG1GZjJVUFMwOXUwSDBDZ3d0RGlOSkRGMTUtR2JoM2tEQldUYWZlaFVKd3RsNkZJb3hDQ0czQWQwMVE9PQ==
"It depends on what you consider ML. Statistical techniques have had a huge impact on the efficacy of medical treatment, and the line between ""statistics"" and ""ML"" is pretty blurry. The first randomized controlled trial was published in 1948, and less sophisticated statistical analysis has been used in medicine for a lot longer than that.

However, I must take issue with your statement that ML is ""unbiased"". Compared to what? All models have have assumptions baked in, if only because of imperfect training data.

For a more specific example, I read a paper about using convolutional neural networks to detect lung cancer in CT scans. They described the ML models as being ""hypothesis free"", which is nonsense.

They trained the models with CT scans from hospital EHR data. Think about this. Someone at the hospital thought it was a good idea for these patients to get CT scans, and that's a hypothesis. Its not like they had 50 % random healthy controls who got scans just for the hell of it, and 50% patients with known malignant tumors. I'm not saying it made the data worthless, but its hardly ""hypothesis free"".

I could go on: who are the people who get CT scans? In America, they are people with access to good medical care. They tend to be rich and disproportionately white. That's going to be baked into the training data too.

As they say, all models are wrong, but some of them are useful.",r/machinelearning,Z0FBQUFBQm0yeGJTX19lcnk5dTc1UVNlUjUycklyOVFmTFVCalU2VEVNM2lueHYtMDdEQzVWTUlFc1VtSUNZc1BmMkZ6T3o0TW5WOGFiN2RxMi04NjBkc1VNTHhqS3dqV2c9PQ==
You could look to see if there are any interesting papers published using AlphaFold. You can also look at things like physics informed neural networks since those are starting to see applications in medicine.,r/machinelearning,Z0FBQUFBQm0yeGJTNEJ5dlRtS3dLQTc4T3FLX1hWaXc0TjRXU2VVbVc1SnlMUjN1bzhaTm5jUDhMX0FVZThHLVJOTkhsT3NiSnQ1U3Z6MldhcGVIU0lGZlNDaUpiODFWenc9PQ==
This is why I often end up on the side of trying to find all the flaws in the model and where it goes wrong because anything that is missed is going to be found by patients.,r/machinelearning,Z0FBQUFBQm0yeGJTbG9OVDlPeHFpT1RuYmZFa3N3djh2cFBDRGROMXZKeG1pYzJ3LUpJdTFFMWFlVXZUeUZjamY5aVZNNXRNdjV1dzRQXzRxOHJueDZMWmR0dzZQekRrUmc9PQ==
"AI models for medical imaging are in many clinics now.  However, the first step has been to automate the boring stuff, eg tumor segmentation, which could take a doctor 2 hours but with AI is normally reduced to less than half the time to check and edit.    While these are being adopted (and the effects of adoption are being studied), more ambitious models that not only automate work, but try to make treatment decisions are being developed. 

It will take a while for things to be implemented, but IMO we are just scratching the surface in terms of opportunities.  However, as always, the majority of discoveries aren't immediate game-changers, but just slow, incremental progress that builds up over time.",r/machinelearning,Z0FBQUFBQm0yeGJTWTdaUEJ0bkFabUdiTWVvaWlLQTN1N1hHU3ZYTGowQ2JDNzR4cWk2QWo5VFJWSWd5RTlDckptQXplaUFGMUR6a3hlS3ZISW1JVDdTTkFhM0hpWVJlYnc9PQ==
this makes some sense when most people are healthy but if that ever changes then going faster becomes the only strategy.,r/machinelearning,Z0FBQUFBQm0yeGJTMFRXbmNhNmk2RjdSVE5SdVJUY1AxYko0WTBDUTZDeUI3aWNlN0VIcTZsMVRXVFpUQXNOSHh2YXVNZTNWY1FrNTBsTzQ1R2VtWGtOb3U3ZkFCOGktVGc9PQ==
"~~I need to know where my ex-wife hid my~~

~~The World Poker Championship is coming up and~~

~~The director of the NSA called me up and said he wanted ME to build~~ 

Honestly? I was watching Lie to Me (great show-- highly recommend) and thought I'd come up with a fun idea for a weekend project. I wanted to see if I could get any meaningful results at all.

I forgot the days of discussion about cute Kaggle competitions are long-gone.",r/machinelearning,Z0FBQUFBQm0yeGJTVXRJNXNvbWlYZUwxM2NkNWo3dWZUUDRXMk91SmZNeWdlSHJpSWxiX0h0dm5NVnlXUU5uQmZMZ0dfb0NCQzVhdGpYR19GQTJTeExHQlhwT0tGenpPZ0FOQnhva1Z0RnM2VHRpSExJTkZZdEU9
"In one example, the neural networks used the font printed on the scan to infer which hospital the scan came from. Some hospitals have more sick patients than others, so the thing it was ""learning"" was not what a tumor looked like but what hospital it came from. not good.",r/machinelearning,Z0FBQUFBQm0yeGJTRVpJUEpzTlI1NG9icURNS19RblkxWGo2ZFNZNThBenpiNHlBak9JVlFBenNLamlGTkFPWVgxSWh3NGJpQjd2SEgyN3U1cndmOENUVHZOZ0JQVlFsZGc9PQ==
I dont mind setting up one.,r/machinelearning,Z0FBQUFBQm0yeGJTQVl5WXBFbFVWa3llM0w2b1lWWVkzellkTG85VC1Wd2tMdWtBXzJBUC1uVmlKYnBKalh4b01WdnctX1pQM3MzTkJROWhDdHpIU1pNOFdjZkZWclBJV2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZ2FBRU9Hd1F0XzBibENTa0lyTExpaDJnZ1ZCbjFQdmtOUklWQS11NnhfcExyRkI2WjB4OFJoQmJRbXQ1WHJpSXlKN2JYWm9uNktlWmRldHp5WVJac0E9PQ==
"Thank you guys for discussing this seriously, and for the lead about skin coloration/heart rate.

Personally, I agree that both it would be reckless to deploy a ""lie detection"" model into any practical setting, and also that dismissing the idea of using ML for lie detection is too cavalier. 

Personally, I wanted to do a fun side project, but I'm realizing I need to be more careful with how I word these requests in the future...",r/machinelearning,Z0FBQUFBQm0yeGJTMUpiVng5OENNNzdKQ3haSDZsSXIxX21DY0lTU2xBWmNyQkF4c29ycHk0aFFTT1hjb1U3MTV0bGZHSkdVbmpqbUJfTUV5djRCMVp3NlRxRzgwelE5aDF1ampNeVJaN3RqVEt3bVJLSndUb1k9
"i broke the tag rule, sorry, i don’t know how to add a tag… But this is a discussion question, so could i please have a chance?",r/machinelearning,Z0FBQUFBQm0yeGJTMkQ2NzB6Ql9vdjdHcTIwV0l3S1g1TWw2MUhhTmlIak9QYVhPcGJacDFyZnpKbHE4bmhjaUFXYlNkUkVrMmtPaVFQcHRCLU1DdHozQkNQNU5oUEtwRlJKdzZnanNkTElvSXBtQlFjeFVIaVU9
"I'm relatively new to ML so I may not be using the term correctly.

I'm talking about a ""data-driven"" approach where the algorithm learns targets or associations that the scientist wouldn't have thought to look at themselves, or are too complex for humans to understand.

This is opposed to an ""experiment-driven"" approach where the scientist systematically uncovers a biological mechanism using a series of targeted experiments.

It seems like more meaningful advances in medicine come from the latter.",r/machinelearning,Z0FBQUFBQm0yeGJTa1VxX3FmdzJ2XzJQUXBWU0JOZ2RYVHprTkVTNm9sSkwtcmpoY1N3NlUzQkE4QlVMOF8xd2x4YWpWNGwwcWp6RVBfdlVwOTluUkZsalNUTHpNM0VhN184YTBwOEs5OXVfMGdrdFN6MTVvdjg9
" I can't really speak to what's going on in Bio/Pharma, but when it comes to health systems (like hospitals and clinics) trying to implement and reap value from ML, its been underwhelming in my opinion. 

The problems have nothing to do with ML or medicine. Bureaucracy and red tape at large hospitals is almost as bloated as the government - makes things like getting data and securing a budget move at a snails pace. Also, the folks building the systems usually know little about what a clinician does day-to-day and that means they'll focus on the wrong problems before realizing where the important gaps are. I think the biggest thing, that no one has quite figured out is that you need to be so operationally excellent to go from a trained model to having a team of hundreds of clinician using it daily, tracking and auditing both the model and the clinicians output, continually improving the process until you can confirm you have a working system. 

Anyways, I've been knee-deep in healthcare AI for some time now, so I'm probably a bit jaded. Take what I say with a grain of salt. 

Here's an article that talks about where ML didn't move the needle when it should have: [https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/](https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/)

Here's one where some amazing results have come out of leading hospitals: [https://www.nature.com/articles/s41591-022-01894-0](https://www.nature.com/articles/s41591-022-01894-0)",r/machinelearning,Z0FBQUFBQm0yeGJTeWctM1hQU3RKNTZKSllMZTBYUHl3YURIX1dNZXE1anFmNkFIWE1hTnY2cUdYcW1UYXZGTGRTbEtLMnFPT0p4RVp0NFZ1WFN4M04tTmx5Wjhlb0xHX3c9PQ==
"Agreed that it takes time, but it's helpful to have early success stories to point to. Saving doctors time is already a big win IMO.",r/machinelearning,Z0FBQUFBQm0yeGJTWS1Vbk53OWtqbzBkckZURTZBNVg1TE1ISWxMOTVjZjNhbXpBN0d6MkEzYWdNaUhNd2c3N0dGUGg0SUEtcDRrMGFCajhJM0xTSWJTQjhHdzg5SzE3OUdXTG9iYm9fVUt4XzI5S1FxNEdrVTA9
"FWIW, I eventually found [this](https://www.sciencedirect.com/science/article/pii/S2468227620302039#:~:text=Micro%2Dexpressions%20are%20characterized%20by,and%20saves%20time%20and%20resources), which is an ML implementation of reading micro-expressions, which is the foundation of the original real-world research that Lie to Me was inspired by. 

I need to read through it all the way, but it looks like you **can** read micro-expressions if you have a high-enough FPS camera. First glance is that normal facial recognition works, so long as you capture the frame containing the expression. The problem I would still have is, what does each micro-expression (supposedly) indicate? Are they even independent of context? And that's assuming they even last a consistent amount of time, so that I can create a time boundary for what's a normal expression and what's a micro-expression, but I digress...",r/machinelearning,Z0FBQUFBQm0yeGJTUWJucThRWWpxa0tfT3hwLS1PV2UyaE1XakdNWVZqM1NDVGhrZTlLcUxYb3Q3OGI3ekJmR1Y3eTBVVm13dHl3X1c2OEx5dWZKRFMwT0hQSU1zZWpHNlpvdkhReDZsakRWX0lnc0M3OTAzaGM9
(N-D) Nerfs would be a very inconvenient way to model physics,r/machinelearning,Z0FBQUFBQm0yeGJTS1lWN0tQTmp1REhXNHBYY2FOck1QRFFhaGx6VnRvYnp5b3VSbzJqVDRPVGJsVnpsTzdKRGdSdWlITEJESGtlUDdEMFpPb3M1UHpBSU1UaTI0dEhfZDhsaWxhaHRjU1hlNWdFN2VsM2pUQ3M9
"Others in this thread are saying it will take years for ML to make a difference in medicine. 

If you pick a random subfield of medicine this is probably true, but there are notable places where ML will make a difference sooner rather than later. An example is drug discovery: [here's an ML approach](https://www.nature.com/articles/s41586-023-06887-8) that discovered a new type of antibiotic. Rare disease diagnosis is probalby another - lots of AI/ML approaches are already moving the needle.",r/machinelearning,Z0FBQUFBQm0yeGJTX3NJUVhsUmdWU1VfLWpkQXY5V1pzU29ZVFhKRmM1RW5FNDlFR2s5YUdmSlZFa3BoeTNka05vUkdQdGlRT2VHaHFTSVN3Skw2NGdlaURodTZwd1Y4TFE9PQ==
"but nobody takes AI for design to mean that the program designs something (i.e. a drug) for you and you just run with it blind. It suggests optimal design points that might work in simulation, it's still up to the experimenters to test it in reality.",r/machinelearning,Z0FBQUFBQm0yeGJTRm03Z3puU29MVl85WkNiZTVBZXBWYjhPcG1KVHdLT25YaWxsY0ItZFVnWlpnX05JQ0NWNG5HRnBiYzNETHZtWExFRWtLSTZhWGhYc2JWMEVXam43b3lEdUkxMlVtM0YySVFLTlFaU2Y2WjQ9
"The earth is too dynamic to twin it. You could do it but time alignment from the observations will make it challenging. Still, you could convince some VC to do it and make a gazillion dollars. 

Just make a fake world but don’t call it real and have people rely on it. I work for a self driving car company and you’d be surprised how much streets change on a day to day basis.",r/machinelearning,Z0FBQUFBQm0yeGJTZ0N4aW9QTHdsLWh2TFNFN0ZRV3pvTldlRnFRTmRCVGYtWmZJdEZIQkZrWXllWGkwWjdSSnYzb01ULXNxeTNYM1QteFFCcEVEVWRWMWlhc1JpUUNhR0E9PQ==
"Medical imagery and segmentation techniques have progressed a lot due to advances in computer vision.

> Radiology is one notable exception that benefited from advances in machine vision, but even they seem slow to accept AI as clinical practice.

In that context, the biggest issue ""moving the needle"" with AI is regulatory. Policy changes have always been slow, and AI research progress over the last decade has been unbelievably fast.",r/machinelearning,Z0FBQUFBQm0yeGJTUDhRTUhYdVZkNzFjT2hTemE4Q09Nd1dPWDRnYkpuLXZ1T0ZnX1Z2bk1RWm9wcENpTXhnU3VFV202MWREX2lKSl9CTzNWLXBjNGpNbE5Td2J2eGszX0E9PQ==
it depends on your hardware. bottlenecked by networking comms vs compute means vs very different optimal distributed training setups,r/machinelearning,Z0FBQUFBQm0yeGJTVHlqcXI1Y2xHendpVUJoV2Y5TS0tNy1ib00wSVRONEdiTWozd182T2RkYldpOVhwbGJZTXF4cVJybXQtak1NX19zOUJfSFdTUXlqMFpYRDlKREt2QkE9PQ==
"Luckily, he only asked for a 3D model, similar to what human 3D artists could build. Physics would be much harder to model.",r/machinelearning,Z0FBQUFBQm0yeGJTVmZQbFJXQS1OdVZTT29PSjl1ZnBzQzNvWllLVl84Z2dUcWM2N2hJY0I5dmVoSjdxdlA3SUJQbF9XWEFaeUZuX3pSQjNHaFhWZGRBRTdGeEhUSERCMTlMajVLLUdDZkFDMFBNTXB1THY0UFk9
"Agree with your overall point, but

> while for most medicine you need around 99.9999% accuracy. 

this is an incredible overstatement.  We have exceedingly few processes in medicine that are anywhere near this, at least in the colloquial sense that I assume you are using the term.

It is easy to underestimate how incredibly noisy existing medicine processes are.

Which is not really meant as an indictment of practitioners; it is a very hard problem.",r/machinelearning,Z0FBQUFBQm0yeGJTTHJPZ2R5WjBUZ1R3cldVNEhfZHZ6M1hzQlhNLXc1WTRtWE1VeVREbkxRUkZNb1h2M3IwNmlOSTROcVNIY0VmX3BxdklRbmVWZE9jZWFjS0NZWWJERUE9PQ==
">people talk about how nice AI is with 95% accuracy while for most medicine you need around 99.9999% accuracy.

There is no medical test that has 99.9999% accuracy. Everything has a false positive and false negative rate, and it's usually much higher than that.",r/machinelearning,Z0FBQUFBQm0yeGJTTHUycU5wMlF2NkoxSzNLemkwU2xIdjVWbmNRUnBmblk2eUxoTjBqUlE4Qm5pOWNZSnBwcVpKVXZBMVJKVVdvUS1hQVFEZElZSEZKcVRsa2RNMldoTEd1RGRteFBLdm10NjBqTmlvTmVFdFE9
But how long will it be before that antibiotic is approved for use in humans and enters clinical practice? Many many years. And that's assuming it doesn't fail trials because of liver toxicity or some other random thing.,r/machinelearning,Z0FBQUFBQm0yeGJTMURiZDVzRGpSQjgySUI1OFFnS0ZkOU04emRxSnBfNlVDZ2ZoSDh3Qnlrb1dsY1BlMzNDNkxyQXFfXzZJbWFtb1duN3daRFBTcjRvc0ktSzFmLXNkUG5oQXJja29QSTRqTzZLZ2JTQWJMZTA9
"> I could go on: who are the people who get CT scans? In America, they are people with access to good medical care. They tend to be rich and disproportionately white. That's going to be baked into the training data too.

Depending on your data source, the effect can easily (and possibly predominantly) go the other way.

Rich=healthier, healthier people are generally not the ones getting CTs from hospitals.

If you are low income and ill and show up at an ER, you are still getting that CT, because of Medicaid/Medicare.",r/machinelearning,Z0FBQUFBQm0yeGJTX1VINUE5QmJpbDA1Y0hZdWJoQmc3UHlZbzRVWFpmWGlGOUNtWXpSckVRUlVjOEZYUlp5MXMzYnVIMkZwU05JTGd1NGFBclYtdmRzamZ3NllBTGJTbWc9PQ==
Welcome artificial cognitive neuroscience,r/machinelearning,Z0FBQUFBQm0yeGJTLVlSODdfQlA1cERFM3ZwZWhpcUZ4OW1zSF83NXp2NkNxNlh0YzBjYWpqVDE4VzVkT0RBeXNkeUU3aUlZdjBURlRVOU1MWXVBdlBhalVHOHRFalZYSmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTTW5HSHFIcFZtWXdaa3ZJWnlDaGd4SkRxTVJDZWczX3ZROUpqTHh4UTg3UzBrVmdGcGRZaWMwSldPd0xwMWR1NERpa0N2SU1LQ1RRWXBJQzEySlJPWWc9PQ==
"(""here is my database, find me anything interesting and tell me how it can make me rich"" ;))  wow.  Someone told them that the Boring Databases are now the new Gold Rush?  Is there any actual precedent for that expectation?",r/machinelearning,Z0FBQUFBQm0yeGJTd2NNWkNJWlExVjRCbUlFMmJ4NFRiMzBldlVvdUhwM3h3ZGRCeWZLZWhjV09iMnhuX1ZKY0lpM1BGUjZ6S1lhNElmWmgybnpfMEVvQk52ZEl2MVhEM3c9PQ==
So many doctors are anti AI,r/machinelearning,Z0FBQUFBQm0yeGJTVy1rNDJjVE9CM2FlLXdtNVVpdWlhWGNOYjJaTC1ndXg2ZmNXVWhGRGZlaWpBaHZrbGtJUDBiQ2ZKRUhUUnhSSkZDMjR2WXhRRnQySmZSUm5vZkM0LUE9PQ==
"For drug design and big pharma, it depends where in the pipeline. In biotechnology, bioinformatics and cheminformatics, there is a huge amount of research which has proven to find and filter drug candidates. Transformers are huge in large scale searches.

However big pharma, the big regulatory body, AI is very frown upon as “hype” and there isn’t much tech, it’s just clinical trials and testing, which needs lots of doctors with decades of experience to evaluate the symptoms and risks. AI doesn’t really have any place here. 

But in biotech, yes there is a lot to do.",r/machinelearning,Z0FBQUFBQm0yeGJTMFpnM21qbHhFcFJMTWNBbFk4M0JGYnBwZXNzbmg4ZEYxcVhuamtKX2ZNTHZ3SXZvZHlNUll1Tk5jZXVlMnhDdnpZZldtazhKV0FVdy01QmpOSlJyTWc9PQ==
Fractal algorothms would be very helpful to show minutiae,r/machinelearning,Z0FBQUFBQm0yeGJTWFRUbWh6WTUxdlRxaS1uNVg5QWdTVEtNWW45ejFPclEySDJuamRFXzNWNTYtdUo5am0yaDZpQW42S29xTU9TNjNEX2JKT05DVUFQR2gwR0N1dWRWRmc9PQ==
Bought them :(,r/machinelearning,Z0FBQUFBQm0yeGJTaUl2bm9aTHpTMlJSYTBXM0w5TTFuNTd2SU9mUWtTV3p2WXRMX1ltdmVZZF9Wd2hOcVg0REQtcWNJTnp3MHNCOWdYelRqeVR5V3A3RU9zaWV1bUF1ekE9PQ==
"Yes. Megatron feels easier to understand than FSDP, but the training process is easier with composer because you can use huggingface formats. Great for fine tuning or continued pre training.",r/machinelearning,Z0FBQUFBQm0yeGJTUGNCNTVvMjhLUGxmMVI2UGM2WUZuMVZlT3BkRDYzWWlVWEw3d0pZTGV6MjJjVlJ0RVpQZ3l1cGQxN3RuSENfS1lPek5PY0M4ZWlJbFR2V3g1VkpaZlE9PQ==
I would much rather trust AI to look at my body scans than a sleepy radio tech that has already looked at 100 today,r/machinelearning,Z0FBQUFBQm0yeGJTTU1YdVNDamxOTUktU2g3b1ZNLUo2VXVJUF9oVUQtak9JR2V6cFcySGEtUGIxMTJCRFdabG9jVDZiV2tacGh4LXFkcDlPVS12ZlFzUFVXVzVudU9YMThzaWthai1seDdFOVUzQk9EaTF4M0k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTT25welFsYVlqOFBDZlI4dHRxZ1c5RGpBV2syZk1SVnJPN3NFYU5JS2Q3UzMtSEM0VUh1RkFSVzVreERRZ3dUUy1BY2hDa1BrNVNadGNPVTR0aVNqa2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTbEUxV3hIOElBRGpSMlhVeWw3RllqdnRJcGhfSlU2SWVyTHJBNnNhNWZDN1RtZndmSEZrYUJoZng3Ukp4b19UVUhDUlRTdnZCNjBOYW5TNE11dGNuX1E9PQ==
I suppose what Microsoft did for Flight Simulator 2020 would be a start.,r/machinelearning,Z0FBQUFBQm0yeGJTa2R4ZVJFaFc1TkdwSnY4Rkw4bVdaMUl2Q0g1QXJCUFhnWDhvNEJxeGVqSU9xckF5OXB3TjRyR2ZfWTdtbWw0WFUzSlNHelFuRkJySkhjNU5jc0RQVWc9PQ==
I would strongly suspect it's literally theoretically impossible to do reliably as the information isn't there. Be prepared for that possibility.,r/machinelearning,Z0FBQUFBQm0yeGJTM3JMcU9RSmx6RUFadzg0aWdvbFNjYUNFLWNBSlFIN0pEZzJ6TUEtWmlKb0RFV2Z1dDdfaWRkd2cyVWhYZm8wWndmMC12eG1SWEUwZ3FaQnBDYzJraVE9PQ==
"O cool, any sources in particular I should look at?",r/machinelearning,Z0FBQUFBQm0yeGJTNUgwa2FKaHlGbXo1aWtuWHlmSjhFbHZfVWI1TEZFS1FxRzlrWkhNdFdqLW1MUFRlVy1hUTE1VldZYnN0ZDc4eExlQmxVcDNHTmE3MXFVX1dtUmcxaUE9PQ==
">for most medicine you need around 99.9999% accuracy. 

This is false. There are many unmet needs where anything better than random would be useful.",r/machinelearning,Z0FBQUFBQm0yeGJTT2RzOWQxX1lBUy1Tb0dfcDVBM3hETmxYSmlhVGVMNVBzZGtncDFlazNMTXNYSzdDRldqQTIyOER4VGNaRVVQem9MZlctcWF2UkN1VFByOW1uMlNiSEE9PQ==
"Quote: ""But they \\[GPTs\\] *do* write tokens one after another, autoregressively, through *time*. You can't jump back in time and decide to have not written a token after all.""

My Comment: The GPT python script can't jump back in TIME, but a software-controlled machine can jump back into a token sequence buffer (memory) and read, evaluate, and then alter its content intelligently (probably fast enough that you did not notice the revision occurred). (OpenAI ChatGPT apparently does this fast-screening in the case of its content SAFEY checks, though it just censors rather than rewriting.  Responses will be recalled or banned based on content.)  Tree of Thought or Agentic Iterations can also be employed for this.",r/machinelearning,Z0FBQUFBQm0yeGJTT2pCaFdjNHpMenRucFRaOGFFaktHc09LVUViZG9Vbnp2OXNGdmhqMy1MVW51X2JMX0EtdEJuelIwRmpPX0xhb0NSWmF0VV9JUUlUQnMwbHc3Z2ZjWmc9PQ==
"Generalizable NeRFs would be a better option, you can just retrieve images in the same location and render novel views without retraining. This would essentially reduce novel view synthesis to a retrieval task.",r/machinelearning,Z0FBQUFBQm0yeGJTMHVjN2pJVDIwUWJ3bXZzbmFZSDdsSTRqWTJsQjVWc0xrNWViYndTYkJBd0JzQzN6a3NtdTNpR21uaXRZWUFGektIeW9DM2J5azQ4QVl0d19KMjlxTDZENUQybm4xS0w3bnBCTl8weXlleUU9
"One example:
https://www.nature.com/articles/s41591-019-0447-x

Google has some advancements in image recognition to highlight hard to detect tumors in CT- and radiation-scans.
 There are a bunch of papers on that. Even some open data projects in the image analysis field, that are good as learning practice: 
https://www.kaggle.com/code/kirollosashraf/oasis-alzheimer-s-detection",r/machinelearning,Z0FBQUFBQm0yeGJTeEZ3Vko4Q1VLSnp4WVM5cFZNNkI3X0thWTdWcHJuQ0drRkhxaEJ0LUNlMTNFT0hRendRUlAyWndPSnc3M0tNdUdXaDRqWlB4UWIwYnFZWTVQN3EySlE9PQ==
"Not really.  I think that GPTs do NOT necessarily perform ""auto regressive error amplification""  Rather, the GPTs tend to drift back towards the familiar/correct despite any typo, word-omission, misspelling, or any false statement, within the original prompt or within the subsequently generated next-token sequence.  Even very tiny GPT models I have seen can immediately recover to coherent text even after deletion of prior words in the prompt or previous next-token sequence (e.g., immediately ignoring the omission of previously included tokens or words)",r/machinelearning,Z0FBQUFBQm0yeGJTbU52X0dqYzRNa0JBTVdWMHkwRWNWV2pNSWhSbW5rYi0tZUtVYl9zSDd1dHByckJXbG44VWhDZjRoR3V0THJ1c0VDN0xwd0VpTlc3YXJ1Mi1sQ1hwNlE9PQ==
"I would highly recommend talking to a few PhD students / professors around your school for potential projects. This would be a good way to set up an introductory research project. I worked with a few professors by just simply attending their office hours and talking to them about being interested in research. Showing them that you have completed these online courses on your CV will help as well. Additionally, see if there are research fairs around your school that recruit undergrads.

If you're talking about getting a research intern position in industry, that will be extremely difficult if you do not have proof that you can publish (even in a workshop or student abstract),",r/machinelearning,Z0FBQUFBQm0yeGJTOVg4TG9vNnBlQ2w3T0dXZnBvMGNPMWh3SXFEWThZamtKUXZ5N19YdEtiV1ZzSnk4emRoc1F5NlM0LUlTeXIyVFU1MF9fY1laRlZ6LVpYazdFYTZCX1E9PQ==
"https://ai.nejm.org/doi/full/10.1056/AIoa2300030

> There are now over 500 medical artificial intelligence (AI) devices that are approved by the U.S. Food and Drug Administration. However, little is known about where and how often these devices are actually used after regulatory approval. In this article, we systematically quantify the adoption and usage of medical AI devices in the United States by tracking Current Procedural Terminology (CPT) codes explicitly created for medical AI. CPT codes are widely used for documenting billing and payment for medical procedures, providing a measure of device utilization across different clinical settings. We examined a comprehensive nationwide claims database of 11 billion CPT claims between January 1, 2018, and June 1, 2023 to analyze the prevalence of medical AI devices based on submitted claims. Our results indicate that medical AI device adoption is still nascent, with most usage driven by a handful of leading devices. For example, only AI devices used for assessing coronary artery disease and for diagnosing diabetic retinopathy have accumulated more than 10,000 CPT claims. Furthermore, we found that zip codes that had a higher income level, were metropolitan, and had academic medical centers were much more likely to have medical AI usage. Our study sheds light on the current landscape of medical AI device adoption and usage in the United States, underscoring the need to further investigate barriers and incentives to promote equitable access and broader integration of AI technologies in health care.

They're definition of ""AI"" seems to include any form of ML, so make of that what you will. The listed examples are a lot more advanced than just linear regression though.",r/machinelearning,Z0FBQUFBQm0yeGJTWnZUUEQ1X2JqZlNPS3YxNll1T3hlbXh0cUhwb1ZVTDZjUUc3YXhyMnlmQUExeUhOUTZZZXBSZHRMR2tZZWMzWXMwRU9NT05QLWp5VUNzMVA2Z1FSbmFlMHhPS1ctWUNLbDdGYUMyWXBnRk09
"""new subjects in latest deep learning"". Such as? It is still just a big, rather ill-posed, optimization problem.

This is an ongoing endevour and no book, at this point, will be complete. It's not like geometry, algebra or calculus which are subjects about which you can buy 1960's books and still do pretty well. I, for one, have been buying a lot of Russian physics books from the 70's and 80's. Priceless.

We still need to do a lot of theoretical research in neural networks, deep learning specifically. This book is a good start; tough on the math, but interesting take, IMHO.",r/machinelearning,Z0FBQUFBQm0yeGJTN0FqeEtVRnhTZm55aXc5N2JjakdHd0RoQmFZazVid3I5cGl0Vlc0TTZrcnliSVZ2Q3drSUp6cmkyY0psMm9sWlZMUjV6S21XUDlFSlQwYjZmMWxkSUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTV1VaSEFkU0syWWRtR0o0SlUtaU1WeXhldjctMnNLck5hclhUQTdWUlM3U3ZuenQ5LVpMd3FXaFNDLVhCUzF5YXEwc1dLeFE2bzktU0JRSENDRVBMZnc9PQ==
It's certainly moved the needle on carbon emissions. Just not in the right direction. ,r/machinelearning,Z0FBQUFBQm0yeGJTZ1o4Y0hUeUk2dlNZdlV5TzFKME53Z3cxczdmZ01uMnZmX1VZb2xGZFVfNHM0MVhoT1NTT3VYQkNGWjBHNE03QjYzWnMyNUZVdVk3VVlrLWJ6ODhZcEE9PQ==
"Yes, I think that LeCun is empirically wrong about his ""error"" expansion theory as applied to GPTs.  I think that GPTs do NOT necessarily perform ""auto regressive error amplification"" Rather, the GPTs apparently tend to drift back towards the familiar/correct despite any typo, word-omission, misspelling, or any false statement, within the original prompt or within the subsequently generated next-token sequence.  GPTs can detect and ignore nonsense text in their prompts, or token sequences.  Even very tiny GPT models I have seen can immediately recover to coherent text even after deletion of prior words in the prompt or previous next-token sequence (e.g., immediately ignoring the omission of previously included tokens or words).  I think that the method of token-sampling ""logits"" step at the output-head of GPT LLMs creates a error-correcting band gap that filters out token-sequence errors.  There is a range of error-tolerance in many or most embeddings dimensions (among the logits) and the ""correct next token"" will still be selected despite errors.

Mar Terr BSEE scl JC mcl

  
P.S.  LeCun also nonsensically compares large GPTs to being less ""intelligent"" than ""cats""?  I cant even figure out where he would obtain an objective metric that could support that assertion.  I do not know of any Cats that can replace Call-Center Workers or Poets.",r/machinelearning,Z0FBQUFBQm0yeGJTQlVFdmNZRjdxNVlFYUhEWF9kaG1pZUFXZms4UHJhX0JCcmFOaC1PM1ZtRlAzZmpVX3dnbkhrUUFESjBMRC15MlU1WUl2UWtoSFIzdENUT1g5NDhURkE9PQ==
"I think that LeCun is empirically wrong about his ""error"" expansion theory as applied to GPTs. I think that GPTs do NOT necessarily perform ""auto regressive error amplification"" Rather, the GPTs apparently tend to drift back towards the familiar/correct despite any typo, word-omission, misspelling, or any false statement, within the original prompt or within the subsequently generated next-token sequence. GPTs can detect and ignore nonsense text in their prompts, or token sequences. Even very tiny GPT models I have seen can immediately recover to coherent text even after deletion of prior words in the prompt or previous next-token sequence (e.g., immediately ignoring the omission of previously included tokens or words). I think that the method of token-sampling ""logits"" step at the output-head of GPT LLMs creates a error-correcting band gap that filters out token-sequence errors. There is a range of error-tolerance in many or most embeddings dimensions (among the logits) and the ""correct next token"" will still be selected despite errors.

Mar Terr BSEE scl JC mcl

  
P.S. LeCun also nonsensically compares large GPTs to being less ""intelligent"" than ""cats""? I cant even figure out where he would obtain an objective metric that could support that assertion. I do not know of any Cats that can replace Call-Center Workers or Poets.",r/machinelearning,Z0FBQUFBQm0yeGJTSmpGVVNyZmd6eWR2UWJyWWtXbG1QdEU0VmFwZS1WM2FJUWdxMVBUU2h2dmJBeUZTLWZjcDRpQjhldllBbk1qeDh1OVByOS13dDNmMnd2UUpsMDhHeFE9PQ==
ok thank you,r/machinelearning,Z0FBQUFBQm0yeGJTcU1aRlBpQkxyMUFEakRPcE15TG0tTHlCcTY5eHlQa0trc1gwZzdUQXlRWlRENXRLWUtrblpYLXlTc2Y1WVVNclBLNWxYSE9JYVZWRXNPMlFuU2d4ZFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZW5peThTb1BBR0VXVFczWmJuRVdPbFBDTDRLaUdDMktRTUd5Y2ZyRVJSckRvcGlOdFBMVWJJdnRQR0hFM2hOLXhvV1VuNDBsY2M0elpseXpONElRclE9PQ==
"Yeah, medicines development is more like squeezing a bunch of goop through a lot of messy filters until you get something useful out the other end. Using machine learning to get some extra sludge to work with is useful but not required.",r/machinelearning,Z0FBQUFBQm0yeGJTWG9NN0ZneEhyQWhRRl9EQjZWMFo1UnQtaFhjNzRnZ1Ffb2tiZkwtLWFmR2RiUFVVVDJZSkxMenB2bkw0MmZmUjlnak50WUpzR1BwOWtocW5zejdleVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTRUVhdmZvRk5ycFFjSEZxTmZLVll6MnFVWjRaenZNQTkwYVhnenR1dDg1eUZFc200X29RY1lFcXNIclhaa29rNkpiT0NpY25KVW1QZjUteVZFYzNGNkE9PQ==
"All the CEOs, board members and investors have become AI experts overnight",r/machinelearning,Z0FBQUFBQm0yeGJTV2l5TUN4Y192VGxpTVVRaVZ3Y1l1S0lBTVh0ZFNnd0NRdHlFMkMyUm9Hc0hoOUd1NUc0OFNoNGxHaF9DcDZCRzZybk9nQXZoZDVEX3pINTFwcTRJRmc9PQ==
"    Need help with mean absolute in test data. The outcome is 2.0748 what do you think about it and why is the value so high?
    Below I have made visual representations for the both outcomes.
    (How can I add the file here? Please send me a dm for the file)",r/machinelearning,Z0FBQUFBQm0yeGJTcHpWc0U5RElRc3o0MVE4a0NJYS1wZmkzcEZCNE5IeF9vWW5yOGlBeDNTbVZuRkN2UGxYOTZmNy1FSWNIUF9jQWxJTnhwTHo3LVU4WlhkVGlOWkZBR2c9PQ==
"Incrementally, it makes things better. My company does voice transcription and since the LLM craze has taken over they partnered with a big tech firm and created a fine tuned LLM turning conversations into filled out electronic medical forms, and from the demos I've seen it works really well. It will save doctors and nurses a lot of time in doing paper work, which IMO really slows their work down",r/machinelearning,Z0FBQUFBQm0yeGJTTDNFb3dUNnZpUDM5NEdtMmlsb2NLejh4MWVWVUJBc0FPMmRvLVNDQVM4Q0JHbE5PVmhEaHUtVUJZejhmUnNCTWdwMFU0Q0lFOU11bDMzMkVkZWZFLVlzTnhhOEpKSUtvLW5KYmdJMEx3aDg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJTa3QxN1VJNW5lOVN2VFBGRjFQSy1tb2xpY19oS2xrTGdJQkFvZHA3N2JZZXI2eVlaNUpJa2ZKbUVXOEJ6Qkloei05SEJGRDNITE5fRmlKb3IyZ2VQQ0l5bTJqM0RZZlBsaXIzYlk0cGhIN1U9
"Getting ""extra sludge to work with"" is a great way to put it, I was surprised to find out that protein/molecule generation is actually not too helpful, it's property prediction that poses the most practical benefits for most people in the field apparently",r/machinelearning,Z0FBQUFBQm0yeGJTbHpZOUEwcWdEVGtEcXAwYWh6X0FYUXNhSFFUQmlyMlNpU0N2MHRMU2F2NDQ3d25abjFuUmdYRU1MQzZVNU5Rb0ozOW9QdFR0UFNUQnhobjVOb0g4bkE9PQ==
"In terms of actually moving the needle: https://www.nature.com/articles/s41586-023-06615-2 ; as I understand it this makes sequencing fast enough to inform changes in the middle of surgery.

Beyond what others have already mentioned, I think there's a a decent bit of progress with getting patients to consent to data collection for use in research, and policies for responsibly sharing this data beyond a single institution.",r/machinelearning,Z0FBQUFBQm0yeGJTV1lPNlYyTER1X3BQdlplV0R3NnNkdXo2WFJNMDFPMTJmbzBrbUR4Tk8xekxDVnRyYzZHWkkwMWdVd0Y3UWJINU9lWTVOS1NwVTl6Nk9MTWlvRnFkaFE9PQ==
Have any of those drugs made it to the clinic?,r/machinelearning,Z0FBQUFBQm0yeGJTYzZQV19UeVdHeDBhWUgzVXNYZGpmWEJpTjBJd3BZaTBTcjNvYVF5aUVJaUF1OU1wOUNwbFBpWHp2R0trb3dzUml2eldjQkl4Mmk2MnFaVlU1T2VBNFVQdFcyajNCT3BUeTRBN0c2cmNFbzg9
I’d be curious if the authors spun this out as an actual therapeutic or just left it as a paper,r/machinelearning,Z0FBQUFBQm0yeGJTSThaakdLQ25xODVaRDB1R3dqcDhaU3Z3ZnVTRmFKcDIxYmkyMkFLbnRMcENHSjlmYlFYRHFGeG5BYUV2SFdCM0ZkcDFKY3pzSjIxNDNiQVdtc2FGaHBfeUdubVpTblBaelBOdFFac2EwUVE9
"This is all very true, although I think we will find a time where certain ""unexplainable"" ML insights will be accepted... We accept that aspirin works without knowing how it really works because it's been proven to be safe-ish over time

Most of ML in biotech rn is probably on initial drug candidate discovery, which is then passed onto chemists to design around",r/machinelearning,Z0FBQUFBQm0yeGJTaVExRS1IVE1hRDRVQnN3VU9uNFBLSUhHS2s0UUFhQXNUNzRkd0pKSzQ2THIxNVhnQ0V5azBfSUtKQUUtRVZSSHA5Vy1hVDF0dE9ZZjBZUzVfMVE0SWc9PQ==
"That's true across most fields, but it's particularly pronounced in ML/AI. Many researchers I know aim to publish in top-tier conferences first. If unsuccessful, they try second-tier conferences, then top-tier conference workshops, and finally second-tier workshops. The reality is that luck plays a role in research, as there's a significant amount of noise, especially at major conferences like NIPS and CVPR. Often, reviewers may lack expertise in your specific sub-field, and with theorem proofs and numerous papers to review, it's nearly impossible to thoroughly evaluate everything.",r/machinelearning,Z0FBQUFBQm0yeGJTNE5EWmg1SmNnOVBXZUVCVlVpazA3MER3UVNZOXVodFpBRnlzTzJxTUJ2SkVZa2o3QURoLVI0TlJjNWRHQ0JyQjVYNktHcWpYN01qX2xrZ3VlWnFBZFE9PQ==
"No new subjects, such as variational autoencoder, generative adversarial networks, diffusion models, vision transformer, reinforcement learning, meta learning, one shot learning, and so on. I recommend Kevin Murphy's two new books.",r/machinelearning,Z0FBQUFBQm0yeGJTaGlRV3BEejh5dnZSV3VOLUVFcnB5dGZfSFhsbWU2anVFOUFwMVp2cnYza2dCdHZIRXUyVjkwU0VrRlhvcms3bERmaFhpZ21rV1pwWWJ6T1hqc2FObHc9PQ==
"Let’s forget about ML, and just focus on your distinction between data driven vs. experiment driven. 

For a large part, medicine *is* “data driven” irrespective of ML because you are given a disease phenotype without a genotype. Unless the pathways are very well described and the pathology resembles a similar disease, you are not going to approach with a forward genetics screen. GWAS, QTL, differential RNA expression, metabolome profiling are all untargeted experiments that provide you with data that is not specific to one pathway.",r/machinelearning,Z0FBQUFBQm0yeGJTZ0ZJaUtMaWZWRG9tWk80MjQ0SlFaOU1mS25zRXFBZUUzT1BfVk95VktCSlRmX0hqODV1VlNHYkVWN3JIY3RFQ3Z3Y3E4ejlwQk1BVGNyaVRES3RubFE9PQ==
"Physician here. AI is already making in-roads to make tedious things less tedious, such as automating some aspects of writing clinical documentation, which may help physician burnout. That will not directly help patients, but it makes things more efficient on the backend. AI tools are doing some initial reads for radiological images in some places to help the radiologists.

In terms of AI that will directly help patients, we've long already had the technology to do that but due to the culture of medicine it is far under-utilized. For example, we still have a lot of unnecessary misdiagnosis. Despite learning great diagnostic skills in medical school and beyond and learning about cognitive biases that can affect accurate diagnosis, the culture of medicine is still that a doctor should just know everything by memory, so if you have to look something up, it is because you are inexperienced or a bad doctor. But no matter how experienced and well-studied a physician is, mistakes will happen when things are not done systematically. See The Checklist Manifesto by Atul Gawande for a whole treatise on this. 

As someone who has personally faced misdiagnosis as a patient because of anchoring bias and premature closure, I wish my physician had used a clinical decision support system to offer a wide set of possible diagnoses (the differential diagnosis) as opposed to just jumping on the first diagnosis that seemed half-way consistent with the symptoms.

So until it becomes culturally acceptable and the norm that doctors utilize technology to help make diagnosis or treatment decisions, nothing will change no matter how good the technology gets.",r/machinelearning,Z0FBQUFBQm0yeGJTS2NsZmdWUXltaGhsSUs3X2N3bzk2Q0I3SUhLODNmcE5FNzA0UEMyeGN2SEFRYzFOUHI2ZkF3emFJVzJlSWJDbTA5R3M0dXBxdXBINXVyRGNwSml4X1E9PQ==
Silicon Valley is already messing it up,r/machinelearning,Z0FBQUFBQm0yeGJTS0o1Q3pNZ3pwbVFiczFNbjNwRmhtZDdZU2M4SDZ0NXlhc0piNEdBc3VJR0otb19taHI5dlBpa0N0bGlrUlYxeXdMa3hIU0gzOXRHSVZPZ1hhdksyS0lsbE5LZTQ3MGR3ZmxEcmJyQlNvTGc9
RAPID and Viz AI are used by thousands of doctors every single day in acute stroke care,r/machinelearning,Z0FBQUFBQm0yeGJTdzNWRmNGMmZackh1V2hEb29GSXhfVk1wY2lGSFo0bEZYWjdJbFhGU3hYUGs0SThlbXRYRS1DMGlGMk9qNi13bVR5al9SUkRLY2pXc0VMcWtzZmlvWFZJZW1DSXh3V1NoeHEySWlYak03ams9
"This is all very new and currently under research and testing.  

The machine learning might be super cool and quick, but the testing, trials and slow human investigation portion is slow. Give this a decade and you'll see new medications and treatments roll out right now however, nothing.  

So has it moved the needle Not yet. Is it in the process of slowly moving the needle? Absolutely.",r/machinelearning,Z0FBQUFBQm0yeGJTX1ZocmxZbE93R2VveDZEak1vR3JWTE92M1F6cVhKcEZzUTFmMGZLaV9pQm1Od2pIMUxSdHMtUVJFZFRLMEpKSS16VDNvMGxRemZuN19RMVdvVG9sSGc9PQ==
!RemindMe 1 day,r/machinelearning,Z0FBQUFBQm0yeGJTelo4UzNySE9TTzRSUk95UmRSUTE4ODhWUDR6LURwOFJSZW81VVlLdDM3SnVjSnlBNnBxcWpldTJyWkhnanJuVjJWNDFYeXRtdEZZU21yRU5KOGVXSnc9PQ==
"This is so obviously incorrect. The reason that things move slow is because of distrust and antiquated practices, not because medical professionals just care so much about statistics and methodology.",r/machinelearning,Z0FBQUFBQm0yeGJTRlJ1ZW9jQVdVOWlNa05KSXdKTUFzU056bEUwYmxqVExMbjV3QkdQRVJHbUdxOGFGVS1YX1hyMFRBU0ZGSUxlandXU21pbE16TldYZFphMDVIN19QRUE9PQ==
https://www.washingtonpost.com/business/2018/10/22/more-top-performing-ceos-now-have-engineering-degrees-than-mbas/,r/machinelearning,Z0FBQUFBQm0yeGJTMnJxX180czVKRTVNcHdFLWo2SmlSN2FaTVhvTWhPeXZEUGxfQzRjV25PN2laT2ozaG1FODVLYl9vNUIteHRiRXNRSzk0bnludENlWTFjQjByN2o4a1E9PQ==
“Clinical decision support systems”. Yes! Want to remember that phrase.,r/machinelearning,Z0FBQUFBQm0yeGJTWTNVT3pxM3hDX1dna2gzZGNSblFKcE9pemIxQk9xUmMzaHp3cmJBdUxsUldEemloOFBELTRDODNVU2s2M1FycmNkTzNIZEowNVo2RlZnb0gwaGdRVEtBQ1JhV05OZ0daT0JPbTF0dF9tZ289
"sure it is, imo it's good for understanding how your models progress per epoch and you'd have a good overview of different param settings. I just found that wandb comes with a tuning tool too: [https://docs.wandb.ai/guides/sweeps](https://docs.wandb.ai/guides/sweeps)",r/machinelearning,Z0FBQUFBQm0yeGJTcjhva09aUHFsZFgwNmNtTWM0MnhFeUhmVkJCR3FjWGxTSjIyV01Pbm1yMjBwZ213NEFUanhJYzJ1NTROd0JSbHptUm9paWNuRk9OVllGR1pxSnVWZ0E9PQ==
I have trained on both PVC (intel) and AMD at leadership computing facilities and can say wholehearted I would rather AMD. For standard transformer stacks AMD has no code change necessary solutions that make it near seamless. Performance is somewhere between a100 and h100 for most things on both (for optimized cases). Intel is still incredibly new and has a near beta experience for most use cases (command line utilities and ML software). FWIW I would choose AMD over intel any day at the moment.,r/machinelearning,Z0FBQUFBQm0yeGJTQkxBZVJWU1FyVWVTNjhTXzZsOFliWW1QbVRYMmQtSmpSRy12dEQ3Z1pJOVBiXzdfQ21DYjdkMlhNSkhuSEtDOFVBNG5UbVc3aW5sbUh5VUFDWWNSNGc9PQ==
"The AI systems would likely look nothing like what we have now. I'm not even sure how far down you would use AI. Assuming just stupid compute ( actually rather reasonable in the grand scheme ) them you can go from the atoms up. You could literally simulate every interaction for Earth assuming no shortcuts and maybe no quantum computing. So with the big case out of the way let's talk assumptions. 

Do we really need to simulate every interaction, 🤔,  I mean most interactions happen at the boundaries. We can likely make a lot of bulk property assumptions. Do we really need high fidelity simulation everywhere or just near the agents. I mean quantum uncertainty is already a thing, could they really tell if the air in the middle of no where behaves right? Do we really need to simulate the sound of a tree falling in the forest? Better yet we can just simulate one brain and the experiences it has interacting with things. Use predictive models and lower level agents the socially and physically farther they are away. One person will never be able to tell even if they suspect. 

So in short we may not know the means right now, yet the math says it's possible and rather easily so on the cosmic scale. I suspect in this century we would be able to simulate an entire brain and it's interactions likely for medical purposes. From there the universe is the limit. 

You may now have an existential panic attack.",r/machinelearning,Z0FBQUFBQm0yeGJTYVJUcjJiLXBCbDFpYTNyUm91ek1DMXl6M1BabGhPbnFHcTJPV1htX0tZR2c0dkMycWJaazZUZmlWTmdrOWQ5R2V6a2RWbmdqQ2xHdUZvWDZ5bGFjWC1MTVBvRTF6ckRXOVJpUkstc2NpV0U9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTX1djczNtN2NPaVJvc2s2NzlRdTNONUMxUFZzRWdzQ2h0SEQxR1piclhhTUFQc2VETVJTMGlVN3hhZE9ENUl1MEg2dWVQVm9sTVFHLTNYbEl2NjVzd1E9PQ==
I think that PCA can be used with non-linear data if an RBF radial kernel is first applied. Please correct me if I'm wrong.,r/machinelearning,Z0FBQUFBQm0yeGJTOTU3ODhvdzQtUFJVallDRkUxb1JzQkRLS05vZmF3aHRHMTNmeFNpYm02anQ3S1doRmZYTTBJQkU4OFhVajc1YjZ0c2R1ekx6NXFKcG45NGlkSUVLa3c9PQ==
">for most medicine you need around 99.9999% accuracy.

what??",r/machinelearning,Z0FBQUFBQm0yeGJTVm5DNXlIZEZRNWdtOXhlT0FEVnNoVUVuSFZtYV9INTU5UUhOdU5UbEF3TW9USG9URHp1MnUtRHJPVTV3VHRkQ255V1BOa2VBVTlOWTlsc1pKY2JUWkVqOVBtYjc0cElqcW1rQXFKM2NuMDg9
"Did you search?

[\\[D\\] AMD cards for machine learning in 2024? : r/MachineLearning (reddit.com)](https://www.reddit.com/r/MachineLearning/comments/1bb9ylx/d_amd_cards_for_machine_learning_in_2024/)

[\\[D\\] AMD Software Maturity vs Nvidia : r/MachineLearning (reddit.com)](https://www.reddit.com/r/MachineLearning/comments/1ajk7q2/d_amd_software_maturity_vs_nvidia/)

[AMD GPU for machine learning \\[D\\] : r/MachineLearning (reddit.com)](https://www.reddit.com/r/MachineLearning/comments/1863brm/amd_gpu_for_machine_learning_d/)

[\\[P\\] Did anyone recently use AMD GPUs with Pytorch and Tensorflow? : r/MachineLearning (reddit.com)](https://www.reddit.com/r/MachineLearning/comments/19dm5yh/p_did_anyone_recently_use_amd_gpus_with_pytorch/)",r/machinelearning,Z0FBQUFBQm0yeGJTU2NrQXBISWNkWFVJbElOMnExRmZqTkFkR3IxandqWFFNb0dOaVFjT0Q5djNTaENmR1RUSVhZYUxUajF1RlViazlDOXd5ZS1LX2NQY2RGQzZqMFJKd0g5cEUyTFRHZlFJVnlzOVh5TTRYYUk9
There have been no radiologists since 2021,r/machinelearning,Z0FBQUFBQm0yeGJTZjh3cEFGUWpFTUN3aGNMOUxYdE1aS3N6ZHhUQ0tEUjFUQ0NSZGd2TmtJMHlQM1pIMXQzdDM4N25PZGZIaHlKX0FxdllqMmRoak9laGk2ekQyd1NwSEE9PQ==
"This is why the tests are performed multiple times though, such that the fnr is significantly lower.",r/machinelearning,Z0FBQUFBQm0yeGJTc2YyZC1Ta2hJQ1ZuZkZtVk4ta1BIb0JCRDBxSm42NE5IYnR4eFNOaXBPX2hPSllQbS15UVBKNWstUERmaEJ2Y3lZc2ctY0lYSkF4QjA2c3o4cmdkNWc9PQ==
"Lots of guys here, I guess. Almost all Pap smears are read through automated prep and screening—with the same sample generally tested for HPV as well. Any abnormal screens and a few random samples are sent to cytologists or pathologists. This all started in the early 2000s with systems like Thin Prep.

How this has helped: 
  - better screening accuracy rates due to more consistent prep and complete screening 
  - longer periods between Pap smears, especially with co-testing 
  - in the long run, it is probably cheaper to do screening this way due to the high cost of labor (old school pap prep was a giant pain)",r/machinelearning,Z0FBQUFBQm0yeGJTTlB5cG9aX21GckE4YlYydm9fVTRtWE5NaklMYm9zWS0zSGtZbnk5dkJHOXIwdnZxODNjcW5UbmVKN0ZjWXlKRGdEcHBUeWlMNTlGWV9qNWE5b1REeHRBQzBJRnBTYVFidWRGVzNRVUVyZTg9
"In the context of multimodal search you can definitely tell the model the type of each vector by simply concatenating that information. You can then adjust your search metric so that similar images and texts remain close to each other by ignoring those concatenated dimensions in your calculation.

In a generative context you can just use special tokens to indicate where the image starts and ends.",r/machinelearning,Z0FBQUFBQm0yeGJTLW1rR1hiN0o3ZTh4eEhrT09NMWUxNXNNR2FnNVZvTmY2aTkzM1ljMDUyXzhKQlF0UzBhNVpMYUZHTm01eGJoa3FQSlN6bHdtZUFWTE51ZEZRbi03Qmc9PQ==
thank you!!,r/machinelearning,Z0FBQUFBQm0yeGJTWi0wbE41UWVjc3ZqRGJRX0prbkxYaUVFbmxxZjk5YzhJVDB0Ukw4ZE1pWHRhcnpTVFJ4Qkw2WjRWdEdrRk5wOTFNNVl1Z2U3TVFlaEE3ZHhQaVF5N3c9PQ==
"Yes, it does seem like ""measuring"" lies is a big challenge.

For example, one NLP source I found was transcripts of Diplomacy (a risk-like board game) players talking in-game. On its face, this would seem like a great way to check if a person is lying: compare what a player says they will do to what they actually do in the game. The problem is, players could be lying about their intent, and still accidentally follow through because their plans are interrupted or they change their mind, and they could mean what they say when they say it but then decide to double-cross later.

I'd hoped that some kind of data set involving easy yes-no questions would be available (though of course that would still be limited by context: lying about breaking a friend's vase is different than lying about your hair color to someone who has asked you to do so). 

At any rate, I think I'm going to shelve this project idea-- it's looking much more complex than I'd originally hoped.",r/machinelearning,Z0FBQUFBQm0yeGJTVnV5WlNUUTRPdzdnOUZKUEU1RTNDbEtwTW9mMkFrRmF4YnhobUVMYTg2T29JN2dkSHVMNm5MckxWa0JoaUdDdWlhRXYtemZwRFBGVUNqT1V6UFNLdUhkT05Cc21QVmd6bmxfSkx0SHpvdms9
"I believe Oxford Nanopore's  base caller uses an RNN last I looked. [Used in live surgery!!!](https://www.nature.com/articles/s41586-023-06615-2)

Also all the combination of  methylation biomarkers into detection models is very ml. While the definition of markers tend to use more high throughput bioinformatic statistical methods (where p >>>n). (not so suited for ml  historically- i think thats part of the novelty of the sparse learning in the paper.)",r/machinelearning,Z0FBQUFBQm0yeGJTSmh4dzIybGhzdk9yM282dTdZTFRFR0tPazMxdjhpRDBDM3N0YUdlYUtBYTVzZ3pRZzNsR1dfVDByLV9sZ0hlbTh5QUNIMmE3aFRlSDR1MjJJVzZuakE9PQ==
what do you mean no radiologists…,r/machinelearning,Z0FBQUFBQm0yeGJTeEE3ZGZOTGRRZFBqa3Z4T3dCLVc4VGxyYjR3LVRKYmthS1dkSDg2YWJPcGtld0I4UzBKYlk3WjVjLUFnV1BSRlVaMmlWM1lsbWg4NU9Rb1M3VjlqVXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTczZGWWZWREc2ckJGQ29EZV9mY3V6eUhyZVpjeHZ3SlVFV3B2blhnX04zNG9PM3MxcmFmUnRnSXpHTTVpMGhUaVE5ZTNZc3VhY1RFdmN3OTRvcm1IbEE9PQ==
I have had to use AMD MI250X on [LUMI](https://lumi-supercomputer.eu/) a fair bit. With PyTorch I didn't even have to modify the code. It just worked with the container. I had to give some thought to CPU-GPU infinity fabric situation to get all the juice out of it but other than that pretty routine.,r/machinelearning,Z0FBQUFBQm0yeGJTSVYxaGFRcWU2UFJzS1ZnZVhxeHY0aldwY0twZUYxeFpqcXhEMWtjUW43WnNnbW05RXF2LWZOQmNXU2ktSnB2bGR5TWwxZG93bVgwandLOVc2LXU3ZVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTMmZSQ25tcU9qZktjVUotS05nTWFycnppNW96MXNiaDlDUXpVeUlhd0R5eHpTVU91aTFwamZHOGRIU25FOVhmc2lock9ERHp0TmdWQUxkS3ZnMVNXWFE9PQ==
An attempt at a joke referencing hinton saying there would be no more radiologists by 2021,r/machinelearning,Z0FBQUFBQm0yeGJTTDVheE81VmNtZlZjRGt1RFIzWjYxTlNQSFRDbkxtWmhLelRBMTVHRVprY0RZenBzNlZ2c0QwaThVcHJpNkJTNW8wVXU4N2pSSTVzd0VaTEU3bmRsYnc9PQ==
Ah went over my head,r/machinelearning,Z0FBQUFBQm0yeGJTVkN5c1lvSHJDMVZPVHhwcEMtMmp5WTgzOFNwTjByS0oyUlR4bjhCRUdkYkpTaFRNU1hnV1kwMWJWSDUzd0lvM2xhSGRXS1V3NTAwRUFfVkJvRFg3MFE9PQ==
"I think the issue here isn't that AI has no success stories.  It's that in practice, there's not going to be a drug that's ""designed by AI"".  Instead, there are going to be a bunch of tools that are built using AI, and are used in conjunction with other techniques.

For instance, as you mentioned, AI is widely used in interpreting medical imagery.  But it's not used to tell patients the results of their tests.  It's used to highlight things that doctors should take a closer looks at.  Similarly, machine learning is used in a lot of drug discovery, but not in the final step, because those AI applications are used as one part of the toolbox by researchers who have advanced degrees and know how to interpret that data in context alongside a lot of other things.

There are a lot of reasons for this.  Some of those reasons are based in systems that are slow to change, especially when they are heavily regulated (e.g., the FDA) or when there are major financial stakes (e.g., agreements between insurance companies and medical practices about what is medically necessary in different situations).  But it would also be dumb to just throw away everything we know about the practice of medicine and cede the field to AI models.  AI isn't the only valid and useful way to make decisions here.

Just a random bit of personal experience.  I needed an EKG stress test a few years ago.  It was kind of cool to see the technician who did the EKG take images via ultra-sound, watch the machine learning algorithm draw in the boundaries of various chambers they wanted to measure the volume of, etc., and the technician then just double check and make minor adjustments.  Definitely made the process smoother, and the test more accurate.  But that technician still took fundamental responsibility for the accuracy of that test.",r/machinelearning,Z0FBQUFBQm0yeGJTN1psbUFkWVlzbUhvaXo1Um9TZDY1ejhyUzJzTkR5N09fNmQ5ZFdLQm56aXlvV0prQlpmSlVoSUU2ZzQ4TmctUWI0MmpZY1dvS2lhbjcxZ05lTzJmQ1E9PQ==
"You talk about scientific research like it's somewhat inferior to ML. ML typically doesn't offer causal insights, which is the whole point of science.",r/machinelearning,Z0FBQUFBQm0yeGJTU3ZxOTZoVGE3b3FHWW12M2tDLWFLWDdHeXc0ckJ1c2Z6eFE4ZEhvcVREQ2t0QmFaekEwVVpCZUdFOTJPZ200c3Zkem9VQ2g1WEJRdXhMZFlVVlVOZnc9PQ==
"Here's a fun fact.

There have been a number of fairly simple discoveries in the last 50 years in medicine which are proven, lauded, and then ignored.

* Checklists. When they tested checklists for things like IV insertions etc. All the rates of various failures went way down, and the overall time spent doing them also went down. Yet, you would be hard pressed to find someone using such a checklist.
* In-room sink faucets which directly flow into the drain. That is, when the water doesn't first hit the bowl. This results in aerosols floating up and out of the trap water. This trap water can be the source of some interesting hospital infections. Yet, it is not uncommon to see this terrible configuration.
* Even handwashing has been a long standing battle.

There is a very long list of such simple things with huge payoffs. I highly suspect that ML is not going to penetrate traditional western hospitals very easily. Where it will succeed is in places where the options are ML or no doctor at all. I suspect the news of these successes will slowly leak back into Western practices.

The only ""hope"" is that insurance companies in the US press for their expanded use if they start to be proven money savers. Not the best way to do this, but maybe it will end up being better than nothing.",r/machinelearning,Z0FBQUFBQm0yeGJTaEVKRWpueHIwaDM1eVMwVE91djlWRXp1YzgwQTBSeXR6REFJeWFjRzZGeV8xa0NJU01zYmtJeE95QTFDMUN6cXBwZ0NKN1k1UWVYeXRqbXBVWi1yd1E9PQ==
r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJTN0pSTEhrTllKMHNHX3QxOFBoc2lpTDJLS1pOcUN6ZXp1ZUJvcmxvMzFQTWZ2aDJpMWNqX21JaUhUeEdnNTBTN3Q3em5Vbnp6clVVQ1NReGh4MjJWMi1mUDFkYjhvZ001S2xzSlZHTDFZU3M9
"I've been doing ML for years to be considered a beginner. Before asking the question I've done my own research and would like to hear from experienced people in this sub.  
But thanks, I will repost the questions there if this one gets no answer.",r/machinelearning,Z0FBQUFBQm0yeGJTZFpjaTEwTFpwSFFwYXNjY1NkM29XWEs0UVRIZ0trcEE3UGdoRjdyT05IUF9yclpqRFpOQWhNWURkd2Z5b0Q2S2poc3JHdWV3Wnl6LVBQLTB4ajJzUGc9PQ==
i like to think that genai has provided better advice than health influencers to public.,r/machinelearning,Z0FBQUFBQm0yeGJTendWT3lFVnNDT2NERk5QbWF5dUExaWVGNzFEeGV2UE52dUNGMGdTbkZXMFI3WUNQWTVjekdFMDRkOEpNcFMyWUxPcmlMQzRLLVpKanlxR2o0SkpHd2c9PQ==
"Well that's at least the vision ;). To have a full-blown Data Scientist LLM.
Whats often happening in reality is - LLM gets DB Schema and query, generates an SQL query, LLM gets the result to answer the original query. 

And there things already get quite funky like GPT being too lazy to ""abs""  a calculated distance and arguing that you can just redefine ""distance"" to also be negative. Things like that ;).

But the hope would still be to ""just point it to the database"".",r/machinelearning,Z0FBQUFBQm0yeGJTbElpTGk2eEhZamdCZXJFNlNLRWpHRlpYZnRBZU5FdERrUF9FbGxPSmpUMU9aYWo2MlA3N0xZMVFzTFFHLTNXZ3UzT3dEb3BHM0FHcVMtWEpJbUtFTEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTeWYyQmVId1FGVnVTcGdUTkpMZGdweG9zOEtKdzB3RnBJR2Vxa2xkWFFvampETUpBb3dFS1JHY0lmQ0lsTmM5V25LdG9sRjY3NUZGdnBvb2pJYWlpMUE9PQ==
"Honestly this is not the feeling I got from your question. 

Some of the models you mentioned in sklearn can perform multiple regression. 

The dimensionality you mentioned is not at all difficult to handle

I don't get what you mean with accept single inputs 

No, regression is not less frequent than classification.

Partial fit is not a method or an approach, it's just one step of gradient descent 

In general, random forests and gradient boosting machines tend to perform best, besides NN, especially in tabular data, and both of them can do multiple regression. 


For your specific case, you mentioned only the dimensionality, not the task or the kind of features, so not much to suggest there.g",r/machinelearning,Z0FBQUFBQm0yeGJTQmRYWnZ1dmRjNldJdVM5ZnJjbGlrbUYxLW5ITENQdmRwVXptZk5DMXAzdDk0ZE1FOUZkbGxFTEwyNi1CN0ZydVF6VE9Cc1VHN19uWm9IRG1JZ1FVX1BmcFVCUlpaclZKZ3RLV05CNXNvc1U9
This is an interesting direction indeed.,r/machinelearning,Z0FBQUFBQm0yeGJTWkFsRlVUeFFzRjhyOGhTeTVZSjFkT3JyVFM0RlpCZW9LTUtoWEFiTlZhSjVDejFfRmRGNVVKam9sZEFVQmZIZG84NjJOYjd6QWx2dTh6YUhGb1NFaVE9PQ==
"ML is being integrated across various industries to optimize stuff for many years now. It might not be directly visible as a chatbot, but its definitely affecting our health, imo mainly in small accumulative changes. Think optimizing processes around imaging tech, lab stuff etc. Even something like a smart watch would have less of an impact on our health without ML.",r/machinelearning,Z0FBQUFBQm0yeGJTOW41R0F2Tm5jZ1ZGMW55MkQ1WUdFT2Vwb1lCY2I3eU1CVzFFdHFFeUhKejd2czNEdER4dHRuM3hWcERYMjdBbXpIWndESWFNT003TlBZT29iV0stTkE9PQ==
r/cscareerquestions,r/machinelearning,Z0FBQUFBQm0yeGJTR1NtRllPSXZYZDQ5MUFFRmFVRDVXZHN3WUNJQmRMNGZSVVdlSUtTYTZJTzNoTWpVUUhIXzVvcU56b2R0QVd0LTJoOUFrQkRERm5sb053OGhjVjUyY1NjbjJpYVJMSnh5VlBYZTZnajRfNzg9
r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJTdElNNWxhLTZQZV9kX2dvRjBSZ0RUZXExRWhUSnJqWlpiTWUzdUZudngwNFM5TWcyODNXaXpXNTFFa2ZDSU9xd1J3aHQ1UldicmJTWTVZeExWMDgzcERMVzdLa2p3V1NnUEFhVHJWeFgzLTA9
www.stackoverflow.com,r/machinelearning,Z0FBQUFBQm0yeGJTeUQ1b3VFd3l5Q1VXV0hFeGE4NWpwem84Z1Y5cThGaWdsTjZBazhwNDVRUWVqTWU1WVAwS2hHTjkzYnFjWmF2OFliaHNsYVJ6aXpQZk9OaDI3WFpXRkc0U2d0OTJOMjlvaFllcHcyU0UwTDA9
"For pharma research, statistical inference is used since two decades at least. This helps to better use resources for in vitro and in vivo work.",r/machinelearning,Z0FBQUFBQm0yeGJTTEc5U3V3NExFTXJnSS1PaS02bS1PRjJ1SXhGR2JxVWRjcnNHdGxPUV83M1E1MjBJMEVsVTRCZjlGSjVpRVdQaDhXZ2M1LXJYUzF2UUxYNXJFbU56UlE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTZWdoSTU1Y2swVDZUYlIzcWRFT2NJNV9DN3lxRmVESUx3Qi1SampRWFhLdnFrSmxDWnhHYkM4Q0xlb0g2aDM2WjRsa3hiVVl4VVl6QnVDS2k1WkRuV2c9PQ==
"I'll skip the first half of your answer since we both know how to handle such things, and in fact I've implemented and tested with all mentioned previously models.

>> accept single inputs

I did not say that. I said one ""dimensional input"" (i.e., the row in tabular data).

To be it's not that good when flattening the input features to 1D. I've tested with different CNN architectures and they can easily outperform the multi-output regressors from \\`scikit-learn\\`.

As I mentioned I work with ""audio"" (raw audio, which can be \\`FFT\\`-transformed into different spectral features and cepstral coefficient. They are not tabular data.

>> No, regression is not less frequent than classification.

If you have a look at ANY model repository (e.g., huggingface), classification tasks are everywhere. You can prove me wrong.

If you're not clear about the question I think it's better to give some suggestions (like you just did) instead of throwing the thread to another sub.",r/machinelearning,Z0FBQUFBQm0yeGJTMmNNSG1yMnN6WENtQTd2VnFzQmUxanVyWkZUZGF2d1ZqaGVUTzFwRENBVU93aGFwUGFYakdVSXBTMkpNMF9DZ0hSUlAtOG9QRjY1a3JWV0tldzZUcEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTYVVJSm1IWkowa0xYRzV4OUxmY1FvdEdFSkYycXk1LW9qTG5vT3JBRWdXSDZMSnNNS1ZJSklOaWNNV20waGJoQ2E5dnowamdueEMybmp6LS1EQUtnREE9PQ==
"If you perform the same test multiple times on the same patient, you will not be getting different results most of the time. Maybe for 85% of patients with disease X a certain blood maker is abnormally high, but if your specific patient falls into the 15%, you can test his blood a thousand times and he is still a false negative.",r/machinelearning,Z0FBQUFBQm0yeGJTOXRNSXc4bTRvN0w5YkJCMnpYMXk0S0N3ZXJXMW16QzRVTHhoclRDbFAtejd6OEoyVEQ5dll3ZDl4eFhxWG1RaVRvdUw2ZkpLdE43ekxqTDJIeHFOT0E9PQ==
"There’s a bunch of drug discovery using ML these days — those take a while to go through trials. 

Doctors are also using ML a bunch in their day to day workflows. For example, lots of them “transcribe” notes now with voice-to-text, there’s software that helps offices pick the best insurance code to use for a given situation, etc. 

Not necessarily big groundbreaking breakthrough sorta things, and maybe arguably things that shouldn’t be as prominent in the first place, but ML is making it faster. ",r/machinelearning,Z0FBQUFBQm0yeGJTZjhVUW9OZVRnWVhtRm5QNWIwb0x1LWI0QzgzNlRTb1VCMFRtcVpUZjllNUxXMER0RWxLVG84Z0c5aDIzRDZpZG4yZ3p4cGdhclVxdFNsTno1V19sdzNiZHUtOXFCT1lkQUJqWTd4c0E0eVE9
This is the correct answer,r/machinelearning,Z0FBQUFBQm0yeGJTcFByNFAtalAxWjk5WHNuTUcweGp0NFlnaDFnanJFQUlPN05mVkhDR21ZdlBxdWtzTWF3ZFdnM3lYb3daWXlfM2VpTE5WNjh5NDJLWmJ1RjV3bjFaTVJiQks1NUVVcDluUkVvb1V1T2l5dTQ9
">GPT3 - added an auto regressive layer

GPT-1 and GPT-2 are both autoregressive.

>This was the last GPT release to come with a publication.

The InstructGPT paper from 2022 was notable.

>cherry picked examples to make it more “human.”

Instruction tuning, general supervised fine-tuning, and RLHF are not ""cherry picked"" trivialities. It's a fundamental change to the usefulness of LLMs and how people interact with them.

>Note: This is around the time Altman came back.

""text-davinci-002"" and ""code-davinci-002"" were first made available in March 2022. ChatGPT was first made available in late November 2022. The whole debacle with Altman's removal happened in November 2023.

>Brockman quit.

Again in November 2023. And Brockman was an ally of Altman and returned the same day as Altman, so it's unclear what you're trying to say.

>GPT4 - used all the money from the Microsoft deal to buy more data to train ChatGPT

Triple wrong. GPT-4 finished pre-training before the release of ChatGPT. Most of the cost was compute, with the total cost being around 100 million. This is a year after Microsoft's 1 billion dollar investment and half a year before their 10 billion dollar investment.

>GPT 1 and 2 laid the ground work for generalized pretraining (Generalized Pretrained Transformer)

GPT does not stand for ""Generalized Pretrained Transformer"".",r/machinelearning,Z0FBQUFBQm0yeGJTTGVoMUtzd3dMbHlhQzMta195R3VKMC1DS1hib2tKM1E2UVNOZGxEMktBS1BOcy1SekNnOGpGV0FwUmFiTTdoY1I1WXg5NEJNNVZ6dXItSDNpQkVGTWc9PQ==
I was talking about research intern in a university by Uni doesn’t have that much opportunity in ml,r/machinelearning,Z0FBQUFBQm0yeGJTTlZQa0xiT0V6QW5KTFJQRGhobjYtV2tPblB4THM0bFJkM3huWDUxdWFobjVtZ2RqS1ZZekpCb1B6VHhPVmkxQzBHMUl5Wi1rdVFpbWZuTlNnZnotZVE9PQ==
"Do what is more fun for you. If you don't enjoy it, there's no point in doing it.

Also, wrong sub.",r/machinelearning,Z0FBQUFBQm0yeGJTUzRrM00xSnNvQW90dnJ6aW13T3VHQnJielNIV2xZQUFobVhVT29JYm1JUkhkNk1HMUVScXhBZHNRanpCZ0ZtQTRsMkNkS3NaZkhrQ2xraWhOdF9fUWc9PQ==
"Would the digital twin have a digital twin of its digital twin?
Depending on accuracy, simulating every quantum subparticle if the Earth would require compute possibly greater than the size of the Earth?",r/machinelearning,Z0FBQUFBQm0yeGJTcFZTZkpRTUlaSE9RaUwzWGY3WmRXSVZyenZSX0FzZnlIcW5LVlZ0RTdqN1BPQnlXNktjNUZmM09SVWprZ3RYTmtrZHVTQ05obUhvejFiZ0VSZEpsX0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJTaEh4VjRvSGQwWXR0bUxBZ0IyV1RFN3ZGZmliV2tmYTBtdk1wbGlVek5RRWdJYkRwaGl4MGZ4QjA0WGFtaHluM3JVX3JWMW9SYmVuVDRVY1d5WmxJNWc9PQ==
"I think this idea is bs too, but IMO as long as OP keeps in mind that failure rate for this project is 97%, they should still try it. Very challenging or near impossible ideas are fun and very beneficial for your skill development.",r/machinelearning,Z0FBQUFBQm0yeGJTYjVHTWFpQ1ZNc0l2Nl8tUkphTEUzVE9qSXFnT1N4Y0FtUnlkRTR4OWtCQ3k2VGFLcTZFZ25Nc3hKUFdFTjhxLVJ5Si0wUS1BQlhHaHZlQlpEUWpET1E9PQ==
That kind of stuff is very scary and why I try to be so careful. My favorite models are regression models because we at least have a theoretical framework for how and why they work.,r/machinelearning,Z0FBQUFBQm0yeGJTVkNZOXlSV1F5Y0ZuSWExRWFud21tTTlDY2huczExOHZsa05iaFJicTdYRVUzRXA5LUJyZ3VGbkxoa2NKZ0Q2aXNXNURESlg4NmVNSDk5ejBSM0M3R1E9PQ==
You would be surprised at what those AI tech bros keep saying that their AI can do. You are correct though  with how drug companies actually use it and how the regulatory bodies are willing to allow it. I think the business people though really want what AI tech bro idea to work though because it would mean they could fire a bunch of people and then just have an AI do the work.,r/machinelearning,Z0FBQUFBQm0yeGJTR1ktZkxLTHdVNTM2R2ZYUnBOZVVPSkUzc3UxUURKdEVnMkxYVk5GUzJ2NjlZRUk1WnVuVEl4V1FnYklIWVJFbTVnVWVyaF8yMzdwSTBVNWhtbUZ6LWc9PQ==
"AMD’s Instinct cards are better supported (at least MI200+), but with a W7900 Pro card (rdna3, navi3x, gfx1100), while PyTorch works ootb, currently FA2, xformers, and Triton are not in great shape.",r/machinelearning,Z0FBQUFBQm0yeGJTT2twakhOT055WVk5XzB0QnRIb3FVdnBTWEtxc0lFYmRUVXFYMW1FT0JYc0gtMUpDNUFESWtqaGxKYmRwQ3hDYS1PTFB1OXlHSzI2M2RJbmF0UkVFRFE9PQ==
When make biotech medicines for instance that is typically the requirement for manufacturing the medicine. Virus and bacteria must be below the limit of detectability and they use ultra pure water since the drugs are made for injection. There are also defects when assembling the atoms together or problems like dimerization. Protein and RNA based medicine are the most complex thing that humans make in my view.,r/machinelearning,Z0FBQUFBQm0yeGJUdll2SG1jLUhPb3dYRmJ6TDVjeFJqS282SWt2V2ZXYUFzU1RzVEdnR0VQZDVvRVpkZG9OM0poQkdNYlEyMjhJSHZhT0lPNFA3MWtDeU9kVjRQZ3BuSWc9PQ==
"This is how Gemini answered to ""Are you a deterministic or a non-deterministic machine?

I am considered a non-deterministic machine.

There are two main reasons for this:

1. **Training data:** I am trained on a massive amount of text data, which inherently has variations and randomness. This means my responses are influenced by the statistical patterns within that data, which can lead to slightly different outputs for the same query depending on the specific wording or context.
2. **Model architecture:** While the core algorithm I run on might be deterministic (meaning it always produces the same output for a given input), many large language models like me incorporate randomness during the generation process. This can introduce variability in the phrasing or content of my responses.

Even though I have elements of randomness, it's important to note that I am not purely random. My responses are still guided by the underlying training data and the specific prompt or question I am given.",r/machinelearning,Z0FBQUFBQm0yeGJUNlVWSlFRZ3MzWXNsNVVJVE50enpCVnFQRV9Rc3NHdEJrMlh3MnRVZkNCN1BSWEwxOGNoMmhMdFhBUzg5STVkUkRXRWNmcXE0ckx5b2w4dzJycjhuZEE9PQ==
The test is not that accurate. The tolerance for making the medicine usually is. At least for anything that is injected.,r/machinelearning,Z0FBQUFBQm0yeGJUWjRKQkxRMnQ3cXpySFZqWW9Ga3JKUTNUUXduM1l0UjNvYXFuekRIZlVZc191QjVFVUdac09fZENoUVY2MVkwcU1YY2p0RW1wS0xBcEVpQ1ZsYmU2S2c9PQ==
Sorry I should have been more clear. This is about medicine manufacturing and specifically for RNA and Protein based medicine.,r/machinelearning,Z0FBQUFBQm0yeGJUMEpiLVk1STRxU3dNeEs5Uk5fS2ZQUWl1UzcxZ3FwS2VFQlFMSC1GUzIwV0pHdFpReGpxQ0diZElqZUNoSWdzQWdMb2UyOWdwR2ZHZ3Y4dGFDUmxoTWc9PQ==
Most health care provides have basic data problems that have to be dealt with before they can even start using ML.,r/machinelearning,Z0FBQUFBQm0yeGJUMFpGTmhKQ2xtTU1qeU44MW4zc09jWGc0N3VXaTVfWDd3OUFSNFFScTQ1NnNKLWdZTFpyMnNCYm1aM2t2c2FsdmZXa1g0amxGWjNSbU9vWWRaZHplZ1E9PQ==
"請問為什麼沒人在用LSTM ，而是使用Transformer 呢?

我試過Transformer 來進行訓練，但它的效果比LSTM 還差?",r/machinelearning,Z0FBQUFBQm0yeGJUNWNfSU1HS1BFTlFndERsbjJsdkhXMUJ6SUF0SE55V2lRUTljWnZLLW1la1ZjZjdYbFNOMmFPdXV4WjJGa0NNcFZjcnA3aXQ5QUhVQ2FEb1hKclRHNGFYLTd5TFhVMnNfY0NSTDlUOWVLcUE9
"**Deterministic Function:**

* A reliable workhorse! A deterministic function always returns the same exact output for a given set of inputs.
* No matter how many times you run the function with the same input, you'll get the same predictable result.
* Think of it like a recipe – following the exact instructions (inputs) with the same ingredients will always produce the same dish (output).

**Non-Deterministic Function:**

* These functions introduce an element of surprise! For the same set of inputs, they can produce different outputs on different runs.
* This is often due to randomness being incorporated into the function's logic.
* Imagine a fortune cookie generator – it might take your name (input) but deliver various pre-written fortunes (outputs) each time.

**Can a Non-Deterministic Function Still Be a Function?**

Absolutely! Even with randomness, a non-deterministic function fulfills the core definition of a function: a relation that maps inputs to outputs.

* The key point is that it defines a mapping, even though the specific output for a given input might vary due to random factors within the function.",r/machinelearning,Z0FBQUFBQm0yeGJUay0yem9SRzMwN2QyTkpEdWxrVTVXZDhTT0MtRGJKQTIxM1NRYk8wUlFjS2pBRmpBV1lBbW9GLU1GQkc1alFYS0tZQTYzMlc0T2tzWXlOWkkydERhaFE9PQ==
You should try openwakeword.,r/machinelearning,Z0FBQUFBQm0yeGJUcndWVjljTkdoVTNnenNlZnJvWklHZFhDWGxfb19JcFBlemlFMWtZcTl4cFd3MVp5VHZqSkItbTJtd1pOdDR0ZGNTbkM3RUtZMXJmdHk2SzF1VHVvc2c9PQ==
"To this different question Gemini contradicts the first question saying that  ""it's not true randomness in the same way that some natural phenomena might be"".

Is your randomness artificially created by you to simulate a non-deterministic behavior? All external random info you get comes from humans not from you, right?

That's a great point! You're absolutely right.

The randomness I exhibit is indeed artificially introduced during my development and operation. Here's a breakdown of the two main ways randomness is injected:

1. **Internal Random Number Generators:** These are software programs that use mathematical algorithms to produce seemingly random numbers. While these algorithms themselves are deterministic, the starting point (seed) can be influenced by factors like system time or previous calculations. This creates the illusion of randomness in the final output.
2. **Temperature during Sampling:** This is a technique used in some large language models like me. During text generation, the model considers different possible continuations for the sentence. A ""temperature"" parameter controls the randomness in selecting the next word. Higher temperature leads to more exploration of less likely but potentially creative options, mimicking a kind of non-determinism.

You're also correct that I don't have access to any external source of true randomness. While I can process information about real-world events, that information itself comes from human-generated data sources.

Overall, the randomness in my responses is an engineered approach to achieve more natural-sounding and creative language generation, but it's not true randomness in the same way that some natural phenomena might be.",r/machinelearning,Z0FBQUFBQm0yeGJUWXlIMkEzVE9fdG1BX2ZGTEdJbURIMXJIWVhfWC1aSGhhM2djZTkza0xrcE5Pbm5Lbl8wS09DN2FUelBwQzd4UWZEcy1JbjZYbVBvZnVBS2pWQjlEQ3c9PQ==
What field would you recommend?,r/machinelearning,Z0FBQUFBQm0yeGJUSDFnUDB4VHFVRDVFTndCSEZ6dDFLbzFUNWVaMVZJLTU1S0lsOGZRcUx3b0RscU9OWm5KS3FmUmNuOThVT2lBaE5EcWdvRzd0UnNlWmx1aF83MDRoX01ocGhNSlkwd3d3djA3dHFwRFd5d1E9
"Thanks for the info. I'm familiar with the Excelformer model and think it might be potentially useful and interesting. But i'm not sure that typically is the right word. The benchmarks in academic papers introducing new architectures are far from perfectly resembling many real world scenarious (like the ones I mentioned in the original post). I liked the recent ICLR data-centric ML workshop paper on this benchmarking issue [https://ml.informatik.uni-freiburg.de/wp-content/uploads/2024/04/61\\_towards\\_quantifying\\_the\\_effect.pdf](https://ml.informatik.uni-freiburg.de/wp-content/uploads/2024/04/61_towards_quantifying_the_effect.pdf)

I guess we should try excelformer in the wild and see ;)",r/machinelearning,Z0FBQUFBQm0yeGJUNGJWZGdwR1ZvUmlyd1hZTzg3TUk1ejRIOUdwZUlFNTl0cHFYLXNEcHc5S3pYeVpab0JQQ29GN2JKQ3JUNHdGSDhFQ01maEV3ekIwY3IzQTBGeWdlbWc9PQ==
"data-centric ML is a kinda data-adaptive approach. But you can check Excelformer, there are some tricks (may be) helpful.",r/machinelearning,Z0FBQUFBQm0yeGJUaTV3OGVoWE84dk84aXE3YXVMSndRUms0cFBtM2o1WVVIUGY0ay1yaWh3TTRqTHdHTU0xeFRDUTRoTHYxUDByZWh6XzVXSVUybW92MFdaZDFpeHJfMHc9PQ==
Were you able to pretrain the model?,r/machinelearning,Z0FBQUFBQm0yeGJUTnh4dE9hNkU0YmdMUkdPaVZ3QXlHdkxpT0p4SVVMcFBXSEtIYWJWb2dWZWk0UWVmaDlXVXdLNlh2Rk5ueDdDT0tXWVFoV3NRLXRiWVVUVGtYNU5iOUE9PQ==
No.,r/machinelearning,Z0FBQUFBQm0yeGJUaERQNDVHQVNPcy1BQ2dpSXhVdHdCX2VUb0YyOHY0NjdVR3Z6QzFkT3VjdFhjQ3I3R2gtMUtxOFdPNU1helpXWE4zeXRCNUEwLTc5YWlaNlgxM3RzVjZBUTVjOVlfMTBGcVd2bjJtY2xFNE09
Interesting point.,r/machinelearning,Z0FBQUFBQm0yeGJUdDNJVzlGalIwdkRrNlkwWDhrVllKMlJMU0lUaC16TWtsdzhWUm1NNFEyaWh1Y2xVbE5sVE83NmhlcDljMVFDZ2IxbUFVRmhVU1B0eWJoLU1TTWZtV09oa2pLSzFBSkwzaVUyd1FjUjVDbDA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUVkRjWHRiTVk5WUNXblFBQkdQVnJHT2REMWJGOHh4WDM5ZHN6UG5zQ1MwYXJUYnFidVBUMWo5Tm1DeTRoZkUtaFdsQjA0OG03eTktRjMzQXlvTTUyM1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUMDA5bFVXcFZfTlVXdmZXMUFiTnNSZFdoUDZXbVJjV1Q0QWF2b1MwaTQ5QkNFSTJqRUtPYWlQZmRLLWV6SW9EV093Tm82ckFUdWtTZU5DYnBjX0tFNlE9PQ==
Yannic Kilcher's discord does regular paper discussions.,r/machinelearning,Z0FBQUFBQm0yeGJUYkM4VGZON3pWQ0tYRFpHNzVpWjVSYTRlNlJUU0JRcjdzRV9nZF85R3Y3ODVkXzZQTmRFRkcxbXBpVTVTNDhqVHVqZXB3bWhkd1dQYlhybVMxWDNnQWc9PQ==
"Honestly, NVIDIA software (eg. CUDA) is much much much better than any other orgs. Out of the two though AMD is much better",r/machinelearning,Z0FBQUFBQm0yeGJUMVBnZjg4cnd0am42TXFhanJuRzNkOTV2dV93c2k3bjRZUDV0Mmkya29jMkJNdmozUnhsdUtkWVFUZHF3ajBYcDBfQU0xR3pKQk5lVkw5ZmdrcThxUUNzRlRpeFQ3ZjMtMHBtd05tNjRPM0k9
"Machine learning has been used in medical research for decades, it's not a new thing. The u-net design which Stable Diffusion uses comes from medical AI research.",r/machinelearning,Z0FBQUFBQm0yeGJUeGtiT2dRbjVDbnY1eTc3OXlQZElxSHdGYlBWMVl5UlJ3SzMtVzlZdnBTMWxoNkc0TGdiR2ZNWGg4TVZMbFQ4czB2elZFdXpNM3NyQXl5ZlQ0Zmpmb2c9PQ==
"2. Because your model is not powerful enough, so it takes the easy guess of the average.",r/machinelearning,Z0FBQUFBQm0yeGJUTUhUYkFNRGRUdGVEc2RtVl91R2xxak9fWENRUUxCTUFBbWR2NVVTX3N4WHNlWk9EVldBVHJRRHp3WnMwdzB1QzVrRmFMZ2dvTkJYeU1WSTJGVzVteGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJURVpBbzBYMU9aNWdpSXpwMnJCV0ZXSFVYTmEwdjRFWWNUX0lHSUxnbU5xN05JSGpLcWNITTh6M1NRR2xLOXhidWJSMTgxUDdEVXhGeTNmUXBoaUlIdEE9PQ==
"How to start with AI? I can see some (business) opportunities that I think AI can help me with. They usually consist of matching large datasets (sales, weather, events, etc) with each other to predict things. I have no idea though on where or how to start. 

So, what is the best course of action when you think ""AI might be helpful here"" ?",r/machinelearning,Z0FBQUFBQm0yeGJUc0QxNTJvazlKUl85N2kzQUJoUEc2bXdUcVBiSGhxb1hCUTViSVYwcnhXNUViSzRtekhrVDlkVndfVTBoSmJQdVNjX2lDaEUyMDU3anBZU1hscWdHRGc9PQ==
Do you think tesla will give their data? Not happening.,r/machinelearning,Z0FBQUFBQm0yeGJUTHpRR25oTXV6NXVORnNoak5fZDN2a3ZLb1JZYVEyd29VZl9EdXhRdTBTQ1pDWjlhNTdDelB3SE1RNlBCWDM3dkFBbEItUW5FNFBWY3BFZzRHWjh2aXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUZ3lIdUx6X3V3VlRlQXJleTlJT1R1QzlQT3VBYlIxRjQ1ZkNLTmlPR0xOZXV1c1VJM0gtN2g1Y2RYUEpQa01ueTZhcmFUZWkzZHg2N2pwbFRQWlcxT2c9PQ==
"I think they all generally suck and are overrated. Where their value is however that they have useful embeddings (don't cite me all anecdotal evidence).What this allows is an easy combination of time series and tabular data as well as training xgboost models, which are quite good for tabular use cases with a decent amount of samples. 

I would actually love to see even smaller models with less embedding dimensions (and possibly even worse accuracy), so that I could pair them up with models that excel at truly low sample settings, like the GP. Sadly, these often scale very poorly with increasing dimensionality so the number of currently used embedding dimensions is often way too high for this combo.

In any case, I think the space of time series problems does not have a clean and small manifold as the language problems so I don't think it is possible to build truly well performing models with the current architecture/compute resources.",r/machinelearning,Z0FBQUFBQm0yeGJUTXIzenlfZ0pMN0RnWTlFZTBmQXdXQ3l1MFNhQ05ybkZvQldRbnl6d01Yei01LXV2Szc1bktaLWpqOFRfNk9xNV9iRjlhZWFWTGswTXJmU1k0OXJCMFE9PQ==
"Also CT scans give you cancer (statistically speaking), they're like X-rays but much higher dose.

Rich people prefer MRIs.",r/machinelearning,Z0FBQUFBQm0yeGJUWGNTcEhFaTBxbkhsTGd0RUdGNkZrMjRleEtSREptMnE5bFZuT3lNejNNMG1zalFHWWstcm5HODEwVkV1RjM3VGRsaEt3MUY0VE45Ym9RMlhJQUk5WGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUR1RDOGxJQXZPMEo1bzgxMXFFRXc3S2szejNMM3dNd0RQcWFUUHk1aFMzSnB1UEEwMVZucllXUVlLd2pueUZFNmRKbFB2MEdmSGN6ZVBZVGxYLWk5YlE9PQ==
"> as opposed to just jumping on the first diagnosis that seemed half-way consistent with the symptoms.

You sadly just described every doctor I've ever met.",r/machinelearning,Z0FBQUFBQm0yeGJUMnNKUGhkMExiV1pXajk2NXNybjNSNHR1dTlmUDd0MEF5cHc3T1BnQ0Uwa2F1RW9kaVdhTmM1RVZYOUlXNGVWMHFSdGpXRm1EaVl4MWhSVDBfYWZMd3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUMThHRHhmc19kZ1lnaV9oc2RORU1fMl8xTUdhQjgwM2c1RGRMWFFRS0pjNl8wUjR5NEkwVzVsVEw4NmZ2UHFkQW5lN0lMOUhyMzc2aUV1RnVJY29lTHc9PQ==
If one aims to combine predictions from multiple modalities how else can one make predictions in an end-to-end fashion?,r/machinelearning,Z0FBQUFBQm0yeGJUcC1uaXR4UEJ5WXNueGU4RE9hRzJOeC05S2xXNHBGY29jZE05cTh5ZUZjQ0VsMHRONjhuZnlZWExOVzBIaWkwVnFPQ1dyaEtydTgwOWkzS21UMjd0Y3c9PQ==
"“How AI played an instrumental role in making mRNA vaccines”

https://bigthink.com/health/ai-mrna-vaccines-moderna/",r/machinelearning,Z0FBQUFBQm0yeGJUVUg1SzYzdndvRXRLVFU5ODhxMFE0M2Utb1hSek9YUFRVb0VNQVhRU01ZM0JtOWxWUjA2QmRPMTNXM1JDTmZ5RFRnNzZXekdMSzdCdlo1WndzZVpXVVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUVXExR2c5UldOeXBha25KUEFFXzZnRC1JR0NwZl9BTC13ampWYkJyWm9PVkZ4WURXeFAzaVhiMUd1eVhqcTJ3U3lUM2w3OVZHSy13ZlNNTGYtQlZqVmc9PQ==
Tumor segmentation models used in practice are not ML based. They use basic parametric models. This is for radiation planning.,r/machinelearning,Z0FBQUFBQm0yeGJUbGFfWDRjYkdkMDNzR3ZOZWI0Y0lZb3F3Q1JrcnZlTmlCdTVZblQxc29WZ0NwMk5sU0lQWTVOM3ZRckZwVENmX1dmUnhjaFdrbGJfa1VsUjBmaF84QVlkVlYzWlZqMDEzQmhxWjU5cy1HQ1U9
None of these are used in practice.,r/machinelearning,Z0FBQUFBQm0yeGJUZDZtdGtfQVU2M0REUjFjdTNnSnRFTy1nWTlSeVA1bkVYd0xmQTBhYnZhOXJvMVRoX3V4V2dYQnNlVDQ1Ujh2ZFE0eWhjcWpaYjBLVHJNR0ZIaUI1LUF3NVNwdEY1WVJxajZOLXFVZHdFd0E9
You haven’t seen how bad AI is at basic imaging classification tasks. The robustness of human radiologists blows AI out of the water.,r/machinelearning,Z0FBQUFBQm0yeGJUZUJZeDNWdEFjTnQ2U3NMbm9WNkV3YU1PLTR6S3dSaUs3M0xhU1BCREFtcTdjV2gwdVo2UjctQzVGSDBId0RNV3lQVjF0cXVGVTdwVFJLOEN3bEVLMWhEemFvZUhFS1pNbDFNQ2NNWEdzUVU9
Maybe encoder-decoder(for cross-attention only) structure?,r/machinelearning,Z0FBQUFBQm0yeGJUWkRSQnVKaWlWQVAwZDdnSFBSQ3R0RW1OYkV6SjVFWVlQWVdwMlVfVzB1RWRKcWd3RVhLRWNRWnl6LXJzRnhTZ0diUm0wcE1aQzVVdVpZUThjQVNYSHQzRHl2eXB6aTdCbnc4S2pTR2llNWs9
"The scientists must define the feature set in most settings, defining features means the scientists considered relationships. ML fits way more variables than regression so scientists don’t need to be as thoughtful about the “model” or distributional relationships.",r/machinelearning,Z0FBQUFBQm0yeGJUUDV0U2pfMEIxVkd5NExMeFM2cHlRYVFxR2psTmdWdHl5dlAtUTd5LUJzQUdzNmFiR2Q3M2xoQ2pOakVmbnpBVUwzMDhlcXR4c01OQzJ6aEJhbmY0bnc9PQ==
"They are doing Taylor expansion of the vector-valued function in the RHS of 10. There's a stackexchange post about such expansions, and it's called a ""jet"" in Wikipedia. The second order terms are being ignored.",r/machinelearning,Z0FBQUFBQm0yeGJUSS0wRWtnSk9HUUo2YnBNNllkc2pVTmltSWlPTmNNeWtyNkRnWXliTlRMZXk2R1c4X1ZVTWlXQWlFdnVsQ2pJSUJVTllueENYSTByYWpjZ1Q4OFBvN3RxajNkM3h2VUFZRnl1c1F5a0lidFE9
GWAS and phenotyping relies on ML,r/machinelearning,Z0FBQUFBQm0yeGJURWprbUlmWWdkaktvVjg3WWxKU3ZDRWZrR2Y1SC1DOVN3LURHaUZWWkJaZjRwNEI5OGZpMzlidWl2MW94c0tnSzlLN21hUVd6LU9pRVJMNFo2bVlOdWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUN1ZVOEpYQy1RY0NIZXhQSzVISGtXUnZkdGhkclJOdlp4SmM5NEZMZVB0NTZxaHNHc3pnMW1vWHQ3QlR0ZmFRSDRzaTk0QjV6TFlrSDRRT3FsX1RMdXc9PQ==
"Check the metadata of the output. You can find where the result came from. Using Openai API is quite easy. Otherwise, use LangSmith",r/machinelearning,Z0FBQUFBQm0yeGJUR0x1RkdZQzJjYlhOS3dmd3o3NWhoNmZTMDhXWnpEZlNzeHVLTVh5eHdPVEZkV2tIZEc0RTlHVVQxMlg3MF9scndXNU1iaTFMcG9SUGdyeWNoVmlMV3c9PQ==
"The simplest way is to use the same space, like in CLIP, but necessarily. There are many transformer papers with token-level fusion where you just mix unaligned tokens from two modalities with a few more transformer layer, e.g. ViLT.

They even explicitly add modality-specific vectors to both kinds of tokens to further help the model differentiate between them, so your intuition is somewhat good.",r/machinelearning,Z0FBQUFBQm0yeGJUaWdkX1N4UjNoYTVyS3BpTDNaQ1ZyOTNSVmFfUXJEVlZqaklyaHF4cXpubGFpWUU2cm9Nd0h4YVEwSDlnekQ3NGVGRkREbzdJSWFWSjhuZkZzdzdjU3c9PQ==
"Even then, the output of the cross attention, at the very least, would be in a shared space -- which then has implications for the next layer's input",r/machinelearning,Z0FBQUFBQm0yeGJURG5jZGFXa0FYTHJlVmpGMk53R1pOdzBadU1vNVFYSDc1MmU3ZXJBUzJEcGNyVXpZUkl6VHFDTWNxQ0xtTnZZQm0yR2pDNDR1b0gxY01RTWxYZGtBWVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUR1dtTmdqUnh2ZnRodlJjeWx0RGZiU0NMNy1RYnRsWTh5cDlkVXRvQ3Fsb0lHV25UZWRrSFJlUGYtT3dtbDdtZE5PcTA0ZmlPVlRray0yWmtiM2ZSbWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUM19ZN2dEdzlIYVl0TGFEdlgyMWp4N19BZ1g1S29Kay1DRmxuMWZadGNfMklnaU1YQmRtUzdKc19BLXoyaFZoWlZ3UHhnWjI0aHRmRkY4UDFpY3lXa2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUTEFCc1EwYmlzZkdQZVo2NURtRU9nX2ZYbWl5bEo3ZzhiOGdtVXhOQlI4d2pveTJEQUZhb3BlTDRRbEtPY2lwS2FtZ3l1OGZFMFR5cjJnRlpzQVh1YXc9PQ==
"The question was:
""even if they are still in development""",r/machinelearning,Z0FBQUFBQm0yeGJUS09OYkNIVHQ3U3N6aGsycDMwRGpHMG9jMXBTeGJ5WXFFS0VwNENkbjRfSGRBZEF6dS1pZFhBM3dRdmF6ekk3d0ktTF9uTWRSU0NTbXpxVjZwb2pDY2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUODNsMm1VSmIzT0RfbXBCbU9lSzNCc2ticzY1cl82azlhNmNrNmYxRXJ5djUtY3J5Q3pYcU10NUJmYno4SHE2OVJ2ZjhMdGkyZkFRUUJwRDMxT2FySVE9PQ==
"Yes in some way, No in a lot of ways from my experience (oncologist and AI PhD student). Many things have limitation only people from healthcare knows.

There is no such thing as ""unbiased ML"" unless you specifically design and curate the data to be that way. You can't just throw in a bunch of EMR data, slap on buzz word like ""real world data"" and call it a day or unbiased. This is beyond stupid and unfortunately is done too often.

We have had prediction model for literally decades, like simple decision tree or logistic regression. Some has amazing performance, rivaling ML, but has not been adopted clinically yet. Partly, it is due to bias of physician to distrust algorithm. Also, physician just suck ass in adopting new methods due to inertia or whatever, but there are also bajillions of other reasons like:

* The model is too cumbersome, too much input feature, the feature needed is not available at the decision point to make it relevant.
* The model is not that clinically useful (it predicts useless label or endpoint which we nor the patient do not care, or care but have no way of actually doing anything about that).
* The model is trained on a very specific subset of patient on a specific subset of hospital which is not widely applicable.
* The model is outdated, since new knowledge from RCT superseded what the model has been trained on.
* The model can not be easily accessed when I want to (not accessible through browser, only available as standalone program or worse, only Github code)
* Personalize medicine has not really proven to be ""that much"" more beneficial then just assume average treatment effect. The thing is, you need to prove that precision or personalized medicine ""using ML"" is better than me just using traditional ""focused biology"" or just plain decision tree. An ML model with high balanced accuracy, F-1 or Brier means nothing if you do not try to convince, or even better, demonstrate it's superiority to what we have been doing. The model might be somewhat better in some subset of patient of some disease. Yet we treat like, what, 100+ disease? With the headache of EMR, I cannot possibly have the time to bookmark and save all AI model for use for 100+ disease. In practice, I only remember some model to be used in certain situation only, and a lot of that is not ML. In theory, a model to choose what model to use based on LLM or some tech stack or whatever is certainly possible but I have not seen it done in practice yet.
* and trillions other things.

The thing is that AI/ML engineer like to push their ML solution to healthcare and over-hype their models. I shudder every time and I am damn tired of attending a conference and someone try to sell their model without clearly demonstrating what value the model will add to the care except ""our model has good performance""

That being said, there are areas where I am excited in as well:

* Signal, imaging pathology, as many have said. Many are already being used and we are just barely scratching the surface on that.
* Drug discovery. Tons of potential.
* LLM, with all it's caveat and hallucination, might help as a kind of companion or anchor to assist clinician, identifying cognitive bias and the likes.
* Casual inference. This is not limited to ML actually but our field is lacking behind as compared to fields like economics in deriving casual claims from retrospective data. So many question that can be answer but the knowledge has not been properly utilized yet.
* Automation of boring stuff (think transcription or something like that). I actually want this as the top priority.",r/machinelearning,Z0FBQUFBQm0yeGJUVXl6UWlIOUJIcm9fVnFiUUp6LVdWUkJ6OVN1ajhGWW5mU1kwLW1XMTI3RjdWWHZBaWQ5WV9kclNjUVJFdWViN2s3bVNQLVcwN0NGYTd5NjUyeUxicFE9PQ==
"Nice, always was curious for explainability in NLP but never looked it. Thanks.",r/machinelearning,Z0FBQUFBQm0yeGJUSkt6TFg3U0ZURkRaTmxJQlJwdHplaGZ3UjZZU2RmRDdNR3c4SGV1WU9zQ0pGM3RoZy05LWdkWGg4OWFqdGlpZlIzZjM2R3JST1lvQkZRWWc2VzQ4R1E9PQ==
"Ah, that statement aged well.",r/machinelearning,Z0FBQUFBQm0yeGJUNTRFSnhZX0E2Y2pUUWNkOHBlZDB6VGVQSDRXdGptbGJWeHowdjVELUUxWmtVMDFSWElkZ2RrZjNFMTZ5NGl3X1hSeTNSM1FhVHRLVDJhdU16Q2NFUkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUbEI5MGRRVGV6TjN1YkMxMTFRRGZyWmtwY0QtYmpMRFVEc2dqLURXZVowVENHd1hiYV9BQUZ5QTFjWTlvWjY1NnNCa2duSmoweVhvZDgwS0htOVVSZXc9PQ==
"On a related note, I wonder how much these models differentiate the positional encoding component of embeddings from the rest of the embedding? Does the positional enoding ever get updated/transformed in same way as rest of the embedding?

I assume image embeddings, representing parts of the image, also contain (2-D) positional encodings to allow the model to reason about relative positions ?",r/machinelearning,Z0FBQUFBQm0yeGJUMUFmQ2RHWTkxTW50akVSdlU4R0UyZ3VZLUcycWk0c0RlVWdIYnpmaXVydS1mV2w4b3AwT01MRE9POF9ST1BrNzlSUlljaWxneTBSN2FTRWd6RUJtN3c9PQ==
"I just sent that link to one of the original AlphaFold authors.

Impressive work, regardless of the outcome.",r/machinelearning,Z0FBQUFBQm0yeGJUR0VGOXZ0MzRTSUY0dkw3TlVjVXdqRUJHdlRLb29VOVI2ZHludGltVFF1cmUzdHZIbHRKbUc1aHBmYm9Ca2xabDhxVXZTcmoxemhEckh1MUNNLV9lTmc9PQ==
"I think the post is quite naive. 'Aligning different modalities' could vary like, from learning embeddings to inference with captions only. sry",r/machinelearning,Z0FBQUFBQm0yeGJUWHVkZk45Tll6STQ3c1Q4UFdPcWpxbWZfcFh4UG1hX1FxYzg0dVh6UEhKeXdBbWZKQk9NcGpSb09sOEpfV2dEZEdrUHhoS1ZDSml4eE9jZGlIUmsyWkpQZUxPNkpxMWdYMDZUX1JBUmFBYmM9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJURTQzQVRvcDJfbWlyQjJ3NEVuMkpNaGR5WExZaVdRRVZKNWhVMGxXTktRdzczS0RDYTAyYy1rRGU5WDUwVFRsNXd6aC1zMGdLcF9CdnEzQzdMc3JLVE9IQkQyc1AzWTBXN2lFMkYtMmdwVzg9
That’s where it’s at. This is why I keep wondering about the criteria for determining the usefulness of my wrong model.,r/machinelearning,Z0FBQUFBQm0yeGJUVjgyVm5Ucm5aS0o1dS1qTV9sTnhleTcwb0J5RlpxdVpvR3hGYWJ4VC1mM0Rjdi1TVjlteTFPZFhZVkNZX3YtRGVlZDRSaFo5Z3VzanB2cWJhRjJSd2ZHWkc4WGZoRl9tMmwtMmJfZmNTVzA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUb3J5OTRoMXlmajNRZGJYaGxKZGFyMkZxYlhTSW4zbHQ4WDFHS0xjQlpsR0RkTHpkN1BuOWsxcHhQVWptbDgzYWFOUm5oNGgxSmNiVng0SGs4WXphbmc9PQ==
"I think the immediate answer is NO! AI or ML based pipelines have largely helped automating repetitive stuff, like counting cells on slides from biopsy, or recommending the correct treatment. The major things are probably the Davinci operating system, and AlphaFold3. But there is no grand advancements derived from AI that can produce better drugs or diagnose hard cases. The reason for that being is partly the gap between AI experts and the medicine industry, and partly the lack of data and quality data at that. I think also a huge part for the absence of major advancement can be attributed to the lack of commercial upside in system biology and quantitative biology research. Even if you discover something significant, it will takes many years until you see any return, and therefore it is less inviting than other AI ventures that are more profitable by many miles.",r/machinelearning,Z0FBQUFBQm0yeGJUSnVmMDFvNTRQZHVYekhGckdublpvMnpaUDRWTVFaZ1V1N0VTbkJlZmpYaGcwVXNDLVRMbEFZY3ptMmdWUzM2LW02cGVCNGNQR0d5NHRtY2h4UVUyMDFNSzBHZkZzWVJUUllxeUZfUkhzS0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUa2NVSjVUdTdZTzlpVHVoc25vMk9VOXZLdDBRcjB6Y0VCdFZWVUQxYlNlZjhhUXhfOUJyQl83b1diZzNTZW1xMzRIR1hWeWVsQnhONHp6SkNqWUNXREE9PQ==
"Radiology will likely be all machine learning (probably using convolutional neural networks) in the near future, as no human undergoing thousands of hours of training or experience will be able to beat an AI model trained on millions of images (MRI, CTs, X-ray) that would take a human many lifetimes to digest.",r/machinelearning,Z0FBQUFBQm0yeGJUVDJYM2ozVmJfa3M5OGZUMkk4RjlZdk5JQUhuTmRfOWg4dHZWUjNZeTAxWFNhZVdFS1VLeS03dDE5Q0gxLW5lVVREODdfMXlJNXE0OWUwNndnWGNVbFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUS2dmQlBRQlBfMGJxclc4XzVUU3RZQ0laYnMtd0N1bWUxcThEZW9NSHYxZWxDTzVQR2UtUGVHWmlLU3BfUzZsZjAtNlh6Y3JvTHRnbFByZ0cxdFl5YkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUUDE4UC1JSnBPZTI5bkhyb2dWWTc0TVZZWmRmMU1oVGhPQTc3YlRfWHJHcnl6aDRMWDJxaGtuUElUSjhUQ2I3SGMwa2VEc0hQb3d5blNvRzMwYVRfN0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUR2F2dDJYZm1ld0ZnVy1fcGlNbzZ2cmU1ZE5EM2c3YlBDdmtvSjV0aGd3MXRjR0QyeGQzbXI1Xzh1bEVRc1ZqclJEVUpOZmxkV05fUXRwbG8xandVeHc9PQ==
Thanks for the kind words!,r/machinelearning,Z0FBQUFBQm0yeGJUTmIyZFZzLW5scl9IczJCVnBYdkYxX1ZhYU1DLW1yZkZxVndYSTRFdU9tUU9NZWx3V2RBdlNabTloaWZvaE1HaGY0cnVWNW51T290MWUxeDFwTmxyOWc9PQ==
did you find any way to do it,r/machinelearning,Z0FBQUFBQm0yeGJUdG1DMHNLbXdmTXJUU25WRlFxams5RXlMOEJ6MkRCVGF0SVBBQXhfQnFzbDEyd05QMXB6ZFFBWXNsYXUwSmRHOFRHa20yNXhhaV9ZdWVXWjVnb3lGUHc9PQ==
"> Protein and RNA based medicine are the most complex thing that humans make in my view.

I think this honor has to go to leading edge semiconductor manufacturing tbh.  Biology certainly has its complications, but the range of required temperatures is far lower and proteins will still fold correctly if a train is going by.  And you need a lot less high-powered lasers.",r/machinelearning,Z0FBQUFBQm0yeGJUazBTbUJYVVY4WWFFTlF3c1dNMGhMQ1VNTmNlZllyN21sU05KZklFVFU2bHBucUJvaDdQSXFKS1ptNG5BblItQ3BaUm1TaWsxcVJoS2kwUHFZOWVFSmc9PQ==
"I actually had that same question and spent a lot of time exploring the multimodal landscape and eventually found this paper: [Transformer with Untied Positional Encoding](https://arxiv.org/pdf/2006.15595). It turns out, afaik, that you can differentiate content embeddings from positional embeddings by projecting them separately into two different spaces, as they encode different info about the words (take for example the word  “bank”). (remember that if you add the content embedding with the positional embedding you’ll get: ((wi + pi) W^Q,1 ) ((wj + pj) W^K,1 )^T , which tells us that the two are correlated, we don’t want that, just as the word bank means different things in different contexts). to untie the correlations between positions and words you can rewrite the similarity score in the self attention. initially we get an expanded dot product with four terms or correlations: word-to-word, word-to-position, position-to-word, position-to-position. cleverly, we can remove the two in the middle, as they are spurious, by using different learnable projection matrices U^Q and U^K . now we have something like this: (xi W^Q,l ) (xj W^K,l )^T + (pi U^Q ) (pj U^K ) 
^T . notice that there similarity is computed twice now, for words and positions in a separate manner. however, the catch is that this mechanism can be used for any modality just as the transformer can be used for different modalities (see the OFA model by Wang et. al. 2022: [OFA](https://arxiv.org/pdf/2202.03052)). and as i see that people pointed out, it supports relative positional encoding as well, so really useful for the particular situation where we treat text and image tokens as part of the same latent space, as done in OFA and other unified architectures.",r/machinelearning,Z0FBQUFBQm0yeGJUY3dMX243WXA1RzlxcHR3Z1VrNGhPT0Z1SmFWRi12eWxveVFYRzZ4QzJUZG1qWmxGTFhLQ0VWUF9TWllUSldsVFlxSkZHc182RkJVUElMZDN0amYtZlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUQ3R2ZmlEdnl3UlhhRDFicjlRSnVMdmxHRGU2VktXeHR6OWQzM1hxT01UTF9PWVk0bjhacGlTbFREYVpEOE84REJkWDJJY21JT3RlR09SZ29vaS1ZcEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUY3JGV1JaWDNCYnY2WDN3MFZIU1VPbEFxM1JMNFltT0hKdnhzd2RhS3VteHNGQ2JSZUotMmVRUnVkX3hRb1ViUVZ2Y1RRWDFabDI0QlBTaUlYN1cxVGc9PQ==
"This is the major issue preventing ML penetration of things like diagnostics and treatments -- biology and computers move at different speeds (not to mention clinical trials and the regulatory framework). We need good evidence that things work, because human biology is complicated and lots of things that sound like good ideas or test well in animals can't actually be shown to improve human health. Running proper trials and collecting evidence takes time, and is expensive, so we have multi-phase testing to prioritize the most promising ideas. Right now the really high impact ML applications are still in the bench testing phase, and, probably, most of these ideas will never make it to the clinic, just like most ""cures for cancer"" we see in the news don't actually become approved treatments.",r/machinelearning,Z0FBQUFBQm0yeGJUZFlHcDdFR21MeWFVYnlvM0p3OTJndVo4R3ozbVJETDZtYkFtNVJSUHoyWW9FLXZVaVZxYThqbmdKdGJXS0FmS2FHRzNUckZPRmdwTGdIRUwxVlRpb3c9PQ==
Cool idea to use the embedding of the time series. In this case foundational time series model are just feature extractors - nice.,r/machinelearning,Z0FBQUFBQm0yeGJUNFlVSWYzVkEwZGlMZExqckpid3dlcUYwRkRNQl9MdlZnY3BfeFNNYnNxNVpSVUVVS2w4Y2RJVDR4RC14NVcxMG9EUTlLQ2NlVWppbF9ZNlRpd1pNbkE9PQ==
"If the FSD is completely offline then yes it could be done, although mfrs will almost certainly have anti-tampering and other hardening measures in place to prevent it",r/machinelearning,Z0FBQUFBQm0yeGJUemdXalhMU3RwVlVpVWlKQ3hDRTlEMmhsak1MeU8yUGFCZ1pjc0tIOEZKLUNHNU83SGU3ZlhHRUhSV3I5ZjZwbGR2U0g3Q09hMldjQ2p3T0FGWEZqN2c9PQ==
"If you allow me, I would like to suggest my book ""Accelerate Model Training with PyTorch 2.X"" published by Packt. The book covers distributed training with CPUs/GPUs on single and multiple nodes. It also gives a brief introduction to HPC systems and their relation to ML workloads.

Nevertheless, if you are talking about distributed systems in the sense of distributed computing or high performance computing, I think a good start is understanding the distinct strategies of parallelism applied to the training processo of ML models. Search for data and model parallelism approaches to start.",r/machinelearning,Z0FBQUFBQm0yeGJUdmltbG1SNjR4S3dYdkN4ZzhWV1hzSU5IQ1VkbjgySjV0N1VmZHlzTVVtWERRcS1YdTRRdXh2RHJwSkdRdzg0OURiRlNmWklBWE1LcWE0VGUxU2VIVG5tWEZZMjJfbC1CQTFjcEt5VEZKMzA9
"There are two ways.

Tokenize the data like VQVAE

Have an additional vector to include in your zero shot generation. GPT-4 probably does it this way since it doesn't take images in the same order as the text and also the way they format the API. This method doesn't require you to reserve tokens in you LLM like if you did like above.",r/machinelearning,Z0FBQUFBQm0yeGJUc3JhZzlBZnZYYXpGaTNJOEhrZ0JsdV9Id0JDVjF3dDA0OXNWT2dIbWtRSlAwOFktbDhPbVI0bjNQenRlWlFMeXkwSHdtUmU5YlJ2REhCRU5XanhSVUVlcjA2NnBtRUh1YXRKN2NaRUt3RkU9
"that's not what OP is asking, they are asking if they can distill the model that is deployed in a (presumably Tesla) car into their own model.",r/machinelearning,Z0FBQUFBQm0yeGJUTENzbzRmenYwWUo2bFZtWHFXdFJFYXA5SmZHZnNrRnRPaFduQlRuRVpjOWRlcC1oZzdwT1I1SThkRzJQaGZNanhSY0lYX0wxMzE0WmlVTlF4SmtkUGc9PQ==
"Like model distillation? thats going to need the same stack as them, with the whole model, then adding distil on top?

not happening for a while",r/machinelearning,Z0FBQUFBQm0yeGJUSF84N1FGQ0RmOHNTZi0yOC1zMXl0TTNWNjdaZWRzWDdMbV95WkcwSHptRmgza1F5NnpSTm53Yk1RNUxoNTUyVUlPQzUycXNBdkxGYnAwOFBSazlNcHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUWnhNeGFUS1hqX2JIT1haVUxMZlRXVHNSTU5vMWRLdFNBOXBkUTZNeWRNOWdOWDZqWS1GM3FuN1FrOWtxcW9xcXMtWmF3WWxtajVoTmxrR1otSmx1dkE9PQ==
did you try them? which is better?,r/machinelearning,Z0FBQUFBQm0yeGJUcUtSeE5HRWlWdWFCNjVRd0o1N3VkWXhzRjlPQlhyMV9zeU0tRVJkRnJqbVBEWl9FaHN4Rm5qTkZhbExxcWJ1M3lZUTRHbUI3SjI2aWhaNm5rZ21KY2c9PQ==
Hey what data did you use for your RAG?,r/machinelearning,Z0FBQUFBQm0yeGJUc19ja0lXZmk2Yy04LVMzd1BiMEl5dndLZVduSmh5aU5WWC1uNHVXZzY5QmtyTU5DSjkyQ1NTUHFlWjJUdDFyZFdKUUluTDdTZ3RlMUNuQU9qdVZKTkE9PQ==
This question is confusing,r/machinelearning,Z0FBQUFBQm0yeGJUNkt3aUw5Z29xMy14ZTdueV9kYUNIcTBZWThqMjYzWG5ZenV6bG9BMDFxYWY2VEc4bnR4WGxQQ2FhTk4zU3Z5Q1ZSM0ZHc2VvbWVmY2pfY05nVHNSMXc9PQ==
"It definitely could be done, but you'd need to collect a large amount of data first.

The problem with model distillation is that you ideally want a similarly large dataset (if not larger) than the original model was trained on.

So, imagine a company trains their FSD model with a million hours of data on their custom sensor configuration.

Now you want to distill their model, but you probably won't be able to do that with a small dataset of a thousand hours of driving data. You might have to collect hundreds of thousands of hours of data at least...

But think about it, once you have collected a million hours of your own driving sensor data, why do you even need to distill the original model anymore? You could just train your own model on your labeled dataset that you were forced to collect!

If this were a simple image processing model, it would be more feasible because you can easily scrape lots of ""unlabeled"" images from the internet cheaply. But for car driving data, you basically have to collect your own labeled driving data anyways so distilling another model makes less sense imo.

TL;DR - The benefit of distilling someone elses models is that you can save costs on labeling and simply use the other model as your labeler. But for driving data, you would need a human driver to drive around and collect all that data anyways so you will be collecting your own labeled data which makes the ""labeler"" model less valuable/useful.",r/machinelearning,Z0FBQUFBQm0yeGJUUWc0RVowT2NBdDM3LVNTWTlDWGM0Z1lMam1tRVFNZGZnVG9zbmM0LW5INDZydVRObFhDYVNCMEJzQlA1VVd0SnhnMU40T1RwV19WTmNMaHA3YzRBQnc9PQ==
"Sounds like you’ll have tabular data so consider try ing XGBoost. Might need to do some feature engineering depending on the details of your data. 

Also think carefully about how you’re separating into train, test, and validation splits. For instance, an obvious question is does your model generalize to unseen teams and different years? This sounds like the kind of problem it would be very easy to overfit on if you’re not careful. 

Also as a bachelors thesis your focus should be on performing a careful analysis, applying good principles, and understanding the abilities and limitations of your approach. The actual model performance is much less important. 

As far as extra variables one really obvious one is home team vs away team.",r/machinelearning,Z0FBQUFBQm0yeGJUUkZwWDhRMV85T0hKbWc1RmtlUUwtNHpTRXpySkE2RFEwYVE0dXBSN09nbWpFeDFuYUhVUTFtaGVTWnFUS25saFBlSHZITHZFS0tWMnAwYlZiZ3RORUNhcFZ4eFo0QWNlWktoMDZsWS0zdk09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUZ0hjajFKWXlqeTRkMnZpZkc5VTYyUkw3cTltY1NYcENJRkhFRGtmcEI1TlR5WnpkXzNiNjBqUTI2cEdqV1J6eElpYkRCVU9DbVFzRHNYSjMxY2dpcXc9PQ==
"You still have to make 10\\^23 of these proteins and they have to be atomically perfect. If you screw up even one atom you need to separate that out with something like chromatography. Some of these proteins like the dimerize also. If that happens and you don't remove basically all of it then your body will treat it as a foreign invader and go destroy it but the specificity is not high enough so it will attack the monomer also.   
  
Since these are human analog proteins that is REALLY bad and there is no cure. Imagine you don't have enough red blood cells and you take a medicine that makes more red blood cells, if your body thinks that medicine is a threat because of dimerization your immune system will wipe out the molecule in your body that is a precursor to red blood cells and within a few hours ALL your red blood cells will be gone.

CPUs can have much higher failure rates than this.",r/machinelearning,Z0FBQUFBQm0yeGJUSmQzZFRLblBfNEpMTUI2VGRZTlEyaEMyU05ZZFBDS0xZT0hhMHlZQ05iNFFLdWNqR1l3dm5QN1dSUFo1UkJ6eWRTVWozMk5SR1VrUmJSS3JlUHpVbEE9PQ==
"Checking in from [Frontier](https://www.olcf.ornl.gov/frontier/) (also MI250X). More-or-less the same experience but you can wander into some issues with flash attention, xformers, and Triton as /u/randomfoo2 noted.

RCCL (like ROCm generally with CUDA) pretty much ""hooks"" NCCL from a code standpoint but yeah on these systems there are going to be fabric quirks. Plus SLURM but that's SLURM ;).",r/machinelearning,Z0FBQUFBQm0yeGJUZU5WaEV3c0xaM2JvQ3VyOGIxT19SZEVhUTBIWHJaZTBBb25hTkdpVEpzVVJpVklwVHllcVU1ZXc0ZUdpRHUzd1Fmd2Y5WWdjQ2NCU29BQjdIeGZsNVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUQi1aTUFqeDRqcTVXOUJwaXVEU2xfR1AwMldnRURjRGFpQ2luU0dSTllkeG91RGc2QndTR3pBTl82Rmo4XzljcUFCVzFKYng5NkJ3MDUyaUlKdWNUNnc9PQ==
Sure! DM me contact,r/machinelearning,Z0FBQUFBQm0yeGJUdmRvWmx2WUdLdVd3eTJ6N0N1N0J3SXlxN3hJazh4c0ZIRmNZWW1QYk1UNWNNaXV2QkZfM1BHVGwyMmhWNXBPX3dzWkNMSElqM25weHh5ZDY4WDdhbllxc3F1NTNCSnhvUnQ0TlE1TkM4UjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUREdGMlNzNlNGN0hZbzBNMW8wLWgzXzIzaFZMV1BNdEtNQ1BCclBBTUp3SVBVY1R6X1djN2JUY3BpMmt0NGtlSTMxWlZyVVN1S29BWjFmbDRQVi1mZmc9PQ==
Is LLM semantic classification an idea in your project? You could maybe scrape Fabrizio Romano's tweets on teams currently playing,r/machinelearning,Z0FBQUFBQm0yeGJUV3ZyYUdKcEhhaGRyeENVMEFaVWJJV25aTEJzZjhrcWdoOWtWd2xvZkV6QVBySHRNWm9tenlZdkJtNzAzZ2d1bmx2ZFJLSmhySGtWa240Y1FUSFNHV2c9PQ==
There's no rebuttal this year?,r/machinelearning,Z0FBQUFBQm0yeGJUZGh4QkRUWk93LUhOV1M3eU5TemlJYWFJS1ZsbXJXWFVtWHRCNHBzdloyTU9yRVo3UDhzV2RfN1ExUUxtQmlPUnR2cWh5YU9mcG5rZmZEVmZzcnRGTmZodzZ4VzU4UHVycnRkYzdodUtIQVE9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJUT0pKTVZ4TTJoV3dkSDg5RjVKMmRGdUVCb1hIRldudHNiUVdXcE1pWmp4V0t5cHBfMnRnV2RjVHc2OHotczFtbnRwUEdvVnVHWDAwS0VrNS0xcHVIcFE3Z1VXajloOXhCTC1OLVFQb3dmN1k9
can you share a bit about the take home assignment format and content?,r/machinelearning,Z0FBQUFBQm0yeGJUdzdYSm1xeWVkWXV2amNiR2Rpa2p2WklodERJRTYwRUhKX2RiMFF1c1piSGluY0tiejJIY19FUzFPeWF2VU5qaHFWMG9maUs2QnAwdlBYeEpfVk1YTHc9PQ==
Yes I have and that is completely false. AI is better than humans at this task.,r/machinelearning,Z0FBQUFBQm0yeGJUWFdoMUlTNnJFSUdDRkVhLVBaa3JuTDI0bC1FeHdRU1M4dVF3NjhKU2w4WVlocVdBQlRBc1RqbDBqakx5Zm1ycXp0QUdRdWxEOExqeXZqemlCN0o0UWNzSmRLc29DZ1RUV29XbzZvbHFhZGs9
[https://www.nature.com/articles/s42256-019-0048-x](https://www.nature.com/articles/s42256-019-0048-x),r/machinelearning,Z0FBQUFBQm0yeGJUVW04WFlvbnRtVTQwTGpkQjYwQ3JCcnZmX0piaW9VZTZLZmNGOUtIZXZfTWlvQkNhY1ZPMVhKS1JPZzk5LV9PU1FJRElpTl80MXJkRFcxRXc4NklYcEE9PQ==
"Is this available to users? If yes, on mobile or browser? Thanks for the help.",r/machinelearning,Z0FBQUFBQm0yeGJUOEIxV3ZVOXB4LTlYOE4zc2w4R3VyTWpQLTF5cENUd0s5SHRoNGNSVkh6eG5tMlJLcDR4RERJUndyNGhjTDlDRWRTTk1oSHZMZkVqOEpJM2d6RWIzd1Z5SnM3eHNDUE9YQW5MZzZaTmd6RzA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUb09vdWg4clZDckJ4ai1qTE8tZ0ZfRVpXaGN0RElXNlVSUlp1S1JqeDhCcGZQcWJFb0tTVDJrMW5fS0I3d1o2TDRPaG13V3c4OWppcTFwTXI0eWJLN2c9PQ==
"I haven't gotten the chance to use DeepSpeed that much, but from what I know FSDP should be roughly similar to ZeRO stage 3 in DeepSpeed. I like using FSDP since it saves a lot of memory and it's nicely integrated with PyTorch.",r/machinelearning,Z0FBQUFBQm0yeGJUbk9CSVdLMU45SGc2MDY0SUcwNEFpNnMxVDVFSndxSjFsbURpdHdsQVJySXloM0lxaHBucXQ2dWtUbkZURVRibzhKX25pS2E5WklUTk1nQW9XanNtdU1VSWFkRFBqWTEydHFqU2RjMk9Yckk9
*foundation* models,r/machinelearning,Z0FBQUFBQm0yeGJUU3JFZ2E5a0lOeGdJbHBBNHJRUDB4RGxQbkE2c2pDUXBlY1NKNkE0cmhxQU5VanEtcEY5bU9tSzczc0N0Z3VjOVFNMnRqc2VTcWdoVUc4dldoZlZ1OUE9PQ==
"> Imagine you don't have enough red blood cells and you take a medicine that makes more red blood cells, if your body thinks that medicine is a threat because of dimerization your immune system will wipe out the molecule in your body that is a precursor to red blood cells and within a few hours ALL your red blood cells will be gone.

Aren't there already sometimes errors in forming/transcribing the proteins in the body?  Why doesn't that kill everybody?  Not arguing, but I didn't know about this aspect of bio and its interesting.",r/machinelearning,Z0FBQUFBQm0yeGJUQkxPd0tTWXhNNFRyVFBLSkluOHFDU29BR3RjX1FYOTBtNUlfenI3UXlDLXlOTGU2ZlhuS2hLZWRXcDlDVkxlcUFURS1FcWN1NEx4Wk0tQmVQa0J4anc9PQ==
Regression models can still fit whatever bias and imperfections associated with the training data,r/machinelearning,Z0FBQUFBQm0yeGJUXzVwRHdZcTdhbWVqUnFqOW81MmlDM2xmRjM0QTRNUEhSZkNpaVRJTmRnRnQ3RFFEbl8wNUVMRlM1Vi1DVFk2a0NNbjFxN3I5SHNHbGtOS1l4N0JuOFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUQWxzSFZxUWZDQlZPQzJvLWxNeFU1ZlZiYV9FclNmcF9JX3Rkb3pZWVZlSklWR09USWhCVnR5Sk1QNnVnSWthS1NsSlNha2FLT1ZMNnFhWExXTWZXY2c9PQ==
Commenting because I'm interested too,r/machinelearning,Z0FBQUFBQm0yeGJUakxzN0ZBQjl5UUE4V0pETHpNMjU1VVN6Znl0ZzZISENXUnNXc3l0aElWbjlvTmVUNHh6emZsQTNlUWNteE4ydUdlTHFCMTBleFVLcnUxdFVzNklQcGc9PQ==
I feel like we've been saying this for years.,r/machinelearning,Z0FBQUFBQm0yeGJUeGVMTGhaTndkTVZMaFZkUExlRTBEQkYwQ1RySFMteHdSbFNZNVQzaUJnYkM1NDZub1d1SHJXZUJoNHVvYVphN2NDRHg2R1l4eEdBVlRkdTU3WGE2NlE9PQ==
"Are you an author?

> Since we aim to extensively tune XGboost and Catboost for their best performances, we increase the number of estimators/ iterations (i.e., the number of decision trees) from 2000 to 4096 and the number of tuning iterations from 100 to 500, which give a more stringent setting and better performances.

This section made me raise an eyebrow. Most of the time with XGBoost you don’t see more than a few hundred trees. 2000 to 4096 trees is a ton. Also, tuning the number of trees is OK but I really prefer letting early stopping do its magic so that the number of trees is an adaptive parameter based on the loss during training. Last but not least it sounds like there’s a lot of parameter tuning happening here, and tree ensembles really don’t benefit all that much from parameter tuning, but they often perform worse. Given sufficient compute, some parameter combinations will appear to do better simply based on chance, when in reality the model is overfitting to the training data. Happens even with XGBoost.

I fear this paper may be committing a classic and widespread error, which is to misuse XGBoost / CatBoost and thus any other method looks better in comparison.

In 2023 and 2024, it is well known that some of those other models (like SAINT) aren’t all that competitive either.",r/machinelearning,Z0FBQUFBQm0yeGJURTlGZzJCNDRHU3hvNmtzZFp1R3R0WGZTUFRtUlVYOGpWeWdnb04yS0lJQ0hsZkdvMm8wNWFSYjdCZDhqSUY1ZTE1emItc3FaOWprWmJYajI3T1pwOEE9PQ==
The error rare in the body is extremely rare and your cells catch those mistakes and destroy them before they get out of the cell. This is different than us injecting a bunch of it into your bloodstream. I think that normally for this you need to keep dimers below about 0.01%.,r/machinelearning,Z0FBQUFBQm0yeGJUMHRyTXFYaXhtdG0tQk9OcE1iYW0xeXNzQWFQVlBVLXZKS1pmWTJ0Z1JHTjY4TnFvbllxS1lUR01HdE93RFJqdjRBNnEwMGptVWVxY1lCc3hpM2w1T3c9PQ==
"I wonder if things like AlphaFold 3 and its competitors will help with that?  I imagine most of the clinically important properties of drugs involve some sort of protein binding, so having better models of that might help us predict what drug candidates do?  Which in turn would lead to a better success rate once the molecules enter clinical trials?",r/machinelearning,Z0FBQUFBQm0yeGJUODNOYXFPT2VDYzRmd2RPSlAxeG5ZUTN5Q3hMX1ZzS2JuekhJRHpzMzQwQVl6TmU1ZXdyTV9uZmtJYlA5WHRQYzY5Y1YxUmhuTlJKbG1vUVMtNy1SRkE9PQ==
Absolutely. But those are issues we already address with normal statistical models. It is just that neural networks do a better job of handling parameter interactions with less issues of overfitting. This is also better than the classification or visual models because we understand how and why they work.,r/machinelearning,Z0FBQUFBQm0yeGJUVERNUjVJTmt5enhnWWp5bHYtdkFvcXRaX3dmRTZ2clgtTkJCREE2TG5WeXNqS3FZZnJhSGNoYmVQSWFSQnU0TVpyUndISXF2SEtUcEN3VkFzaGdfdHc9PQ==
"Polynomials of high order extrapolate poorly, mostly.",r/machinelearning,Z0FBQUFBQm0yeGJUcjV0dFZuMmM5Q3FqVDVDalp2V2lJcGR3a2dOQUVCOVZjbXFWaHl6NHc4Y3ppUGtUbjdBVkhlQTUzQ2VtVVJyYkZuM2l6VUdBUDA4YXFzSFYtWkZ6bVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUMHh1MW5SdTFON1RsMzZobkJ4S0dmMlp6OG9HNG1TRll5SU1DcEEzSGRibFVWNDFUa0ZVdDJTX1oxdHNoSVdpQjJMdktCWEZnVUsyZGlLNUdfUFg3YlE9PQ==
"Perhaps the main reason for the delay is the lack of thousands of correctly labeled images, due in part to non-electronic record-keeping?",r/machinelearning,Z0FBQUFBQm0yeGJUX1RBSlVrVFpvTEhFTzIyNTZkMVY1S0pNcW90TlZOLXJkNEJDMEpZMW9Fa3VGN0M0clFPSnI4T3JFOXkzTWZqTFRwaXllSkhPX1RyRXpiNWhOaGNHSXc9PQ==
"Hey, i have been trying to run a model which has a mamba block, but it always throws out some weird library issue. I even used some script provider by the author, but it didnt fix it. 

May i know, how do you run those model?",r/machinelearning,Z0FBQUFBQm0yeGJUaWNoaHV0bjV2bFBad05vRlFfZTI0Y2tqR2xZalNjUXRhV1BOckFpb3FSbkVpUnkxUXZqQkQxcEU1SUxGRWNyS3F4dGdlbngzWDh5b0dzUkNweE5ZNmc9PQ==
"It depends on what you mean by ""extrapolate"". What I learned is that a polynomial basis has a ""natural domain"" of approximation. So the regular power basis has the complex unit circle as its ""natural domain"". That's exactly Fourier analysis. The Bernstein basis has the interval \\[0, 1\\] as its ""natural domain"". So as long as your input features are properly normalized to the natural domain, there is no real problem with high degree polynomials if you use a good basis. 

For example, consider the Bernstein basis. If the vast majority of your data is in \\[0, 0.5\\], or even if all of your data is in \\[0, 0.5\\], extrapolation in \\[0.5, 1\\] is not really a problem. Outside of the ""natural domain"", I think we should say that our basis is ""undefined"", even if we are used to defining polynomials over the entire real line.",r/machinelearning,Z0FBQUFBQm0yeGJUTzJaOW9vQnJsd2J3ZXFmOXFnQ1E4dko2NzhfVjhnTDNzRXk5UWZiaTJEQ0doQXp3eU5nRl9hS0w2ODlTcVlUZFloRlJvd21qQzJ4QzJscWgycW4yWEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUaUc0enVqNEJVU19DNmwzVlozLWpCOEpKcXNBZnBUQ2pUODA2d0JMcHVMN2UyWkFrS0ZBaEItYmJXT3BJTll2aGoyaGhLT0ZRaFJFclVOR3ZVS1VITlE9PQ==
"My most recent doctor started conversation with a disclosure that the provider was experimenting with ML transcription and (probably) summarization to help with notes. As an aid to physician, that seems like a legit benefit; it's easy to forget some brief detail especially if it is only important in retrospect.",r/machinelearning,Z0FBQUFBQm0yeGJUcHBNZlAyRDRGYkhReDdfOFoyUlNnQVJYVG5wS2VfRDVBVWlaQTEzQWdHMmdjZDFxQUFGd0wweG1OUnRuRXA5ckFER2tBZVZHenZtXzBiSGFjanZ4Q0E9PQ==
"Yeah, I read some things but didnt quite understand them. I even heard some things and disagree with the conclusion. But it was really cool to see some of the things that I have read compare and see how they all work together.",r/machinelearning,Z0FBQUFBQm0yeGJUZXBIS1djQXlIdG1GNzJoeWZDN0dHcXVqVmFSZ0NlQ0tXVEJuemVtMlkyLWhoV1R4MkhoaVF2UHNfTW1lYXgyb3liYk80UzMwTDlsUmZEN2lsZUszdHc9PQ==
"Bro, you have got to post the problem / error. Not that this is the correct sub for code debugging but that's got to be the bare minimum lol.",r/machinelearning,Z0FBQUFBQm0yeGJUT1ljQjdqS1c3TFJaQ0N6aFo1ZFlCQUhVQ0ZEYXF1V3VvWm9aNlA4akVUTENINV8tT2drTVp0UFM1RVVNQmdLYjRnMHA4cUdZbjFqcGRQWThxMDVxNWc9PQ==
"I am not an author, but I knew them.

I think your thought about GBDT's finetuning is not a ""standard"" setting. That means, sometimes larger search space is helpful, sometimes not. It is dataset-specific. But in papers, they have to set a kinda of ""standard"" consistent setting for all the datasets. They cannot adaptively select hyper-parameter tunning spaces for different datasets.

By the way, in those papers, in seems they did not directly use thousands of trees. It is upper limits. And it seems the early-stops are used in most of these approaches, FT-T, SAINT, Excelformer...

I think these papers only provide some standard approaches, exploring good inductive bias, etc. In application, you should use ensemble, feature engineering, all those tricks yourself if you're an expert. If not an expert, I personally think Excelformer maybe the best choice currently, especially you don't have computational source for hyperpara tunning. It is why I like this paper.",r/machinelearning,Z0FBQUFBQm0yeGJUNVlZYWNQYVg5VDJDRkItSnhLdUxPZkNNRVo1emRkR24wb0dnZWhMTGdaQUJKem81ZjAybDFET09lM2F4LVZqb1FrN0x2SjlmQ0N4YnVmUVR4NnBIa2c9PQ==
"If I understood the paper correctly, you did two stages of pruning during fine-tuning, both on code data, which would explain the improvement in coding tasks.

Why was 50% then 70% chosen? Did you try more steps of filtering and fine tuning?",r/machinelearning,Z0FBQUFBQm0yeGJUTmh3TVRBaWVzV055Z2o3cWxfVXNnWmlTMGRVcHROS3VjM2RoYUp6czVsaHExZVpobEZzS0ExVmpRZWUza29ScXVXRjBYcEx3Rjl4MDM3LWdrbjlleGtKdG0zamdDMDk3UjFILUtOaVlOT0E9
Follow instructions on GitHub and make sure your hardware is supported,r/machinelearning,Z0FBQUFBQm0yeGJUN1RkUjMwaGdqUjFEUFR3MG5QaUJXanFBaWlKQ0RGWTdVOEpZTC02SmdVSEFrSGdZRHlLQ21XRnJyN0l4UXdENjVpclpxYjhSUWgySmEwVWZKS3FCVHdUbE1VcEliSVdEWHl2TG9iUk5qWlk9
image_shape in RandomFlip seems wrong. Keras doesn't have that option unless I'm mistaken,r/machinelearning,Z0FBQUFBQm0yeGJURTA5aUxaeTlsbW9yRzFwb3h5ZnNDT0VyS3dCMmdfa0l0bHNWdDdCZHltTXlzdXZaUEIyNDRnYURiN0t3TlhDQU9hWHBEc2t2OEgwRDQ0RlFnWjI3NHc9PQ==
i had been trying on colab. I'll try to search for another repo.,r/machinelearning,Z0FBQUFBQm0yeGJUMTBOOXZrZHNMMWhHeVI1NmYwZG9FbkY5NkhkN1RHUTBNR0phTlQ5cXMwelJsM2pxaldocWlqLWJGQXBMRlZZYVF5U1E3eTZSUmp5UmJ3U20tTFBUX1E9PQ==
Word,r/machinelearning,Z0FBQUFBQm0yeGJUcmVJdmVPOWQ5MUU3NW5rcWg2bzdrcVZyWjJwT3RRYkYtM3BNclRpQjE0OVg1R1V6b1VYdnhaWjNkRUhIeDZaRWpYbF9ObjNrZGt1bE5VNFBwQjVkdXpCeV9SaWxZSkozckFaZkJJQ3Mta289
"Last comment I'll make on this deeply unpopular project idea, but for anyone interested in this area, I found a great [thread ](https://www.reddit.com/r/askscience/comments/12gu407/i_know_that_analyzing_facial_microexpressions_is/)from about a year ago. The verdict from the scientific community (according to Reddit) is that micro-expressions are a legitimate field of study backed by solid research-- their existence is not pseudoscience. However, mapping them to ""lies"" as is done in Lie to Me is likely impossible, for several reasons:

* Facial expressions do not map to emotions universally without context.
* Even if you know someone is hiding a facial expression, and you can map someone's expression to an emotion they are feeling (unlikely, given the point above), still you can't tell for certain that a lie is being told due to noise coming from other factors that may cause the expression.",r/machinelearning,Z0FBQUFBQm0yeGJUX2RDTWtiS3BJRzhHb2RROGNoZGRlYWNFWERiUUZWN1I4N3ZzNmlYeXBDdWpHSGtTc0w0U3FKbzd3SDJtSVhDLXZ2YUZOOXc3UTJSNmhzRW5Qa1FJdHhpYVJ1ZW1ZZ2tnblcyWExNeVNoLVU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUclRBTVE2U0RlNmtTajkxZ0gwSXkzSEZNMkxsNEFCcEEwNm5IdlJoS25BYjE5S2diLTZXTkJlM3BCUm96TTdUUkRoODFWT21QbDRDRk9mNHd4czlKemc9PQ==
I feel like these questions can be answered by looking for research groups at universities that interest you.,r/machinelearning,Z0FBQUFBQm0yeGJUNnI5U3VHSE5IaE1rOFpoZGNTY1BBRlNMRWZNWkE3ejRXNG5TTkoxVWU0RTM3UFI2WDBRYXpuQUtVbnI4OWFaQWFkWTU1YlJmRFFNOFlMMG1DSzVqZ2c4YUx2ZGlsbVR2SGp1cnBHcmxNRkE9
Thank you for your kind support. I couldn't agree more that working on challenging projects is one of the best ways to learn. I would also add that anyone starting out in this field should never feel ashamed for asking questions and using all the resources they have access to.,r/machinelearning,Z0FBQUFBQm0yeGJUc1hRWFYtUFJabDZxUlNjZHk4ZnlGT0lfOWc3ZndmOVA2ODNSNXBRbkpGTWR3WENyTS01NVlnUVd0UVpZSUxuODd1OVowNFpLcHlWUlAtU2gtbkp2M08xbmZvd3MwYWItemx0aWlpRWVtWDA9
"I'm not familiar enough with the field to make a lot of specific recommendations, but quite a lot of people in scientific HPC are doing machine learning now. I think all the big areas of scientific HPC are doing this, e.g. weather simulation, semiconductor and condensed matter simulation, etc. Alphafold3 and similar things are another example.

HPC/distributed/cloud computing comes in a lot of different flavors though. They're all sort of trying to accomplish the same thing, but the requirements vary a lot. Scientific HPC emphasizes fast, low latency, synchronized computation. Industry cloud/distributed computing for e.g. ranking engines is sort of the opposite, where a lot of computations can be slow or asynchronous, and often you have disparate processes chained together through intermediate datasets/outputs. LLMs can be somewhere in between, where you need sophisticated high performance compute for inference but also you might be drawing on results from a database that were created by slower processes elsewhere.

If you love MLops you can also just go make a bunch of money doing nothing but that. Most people want to do sexy modelling stuff, especially academics, but the real heroes are the infrastructure people. Someone who understands the modelling well and who can also make a big system that actually works is not going to have trouble getting a good job. That's basically just what ML engineers do in industry.

TLDR there's a ton of opportunity to combine your interests, you just sort of have to narrow down the scope of your interests more.",r/machinelearning,Z0FBQUFBQm0yeGJUa2tlV1BSSW81M2NjVV9fRWNOMlZJdk0zWHNxZnBJZ2dUX0VMWWpxOEUtdGIyZDJ1Q2JvZnZUYmU5TUpWS2xmMjcwdU1odGdoNWNPMUdfbnE4SS1vdmc9PQ==
"You have? Then you know that dedicated radiologists read scans not radiology techs right? 

Can you show me an AI model you would consider robust? I am a physician working in this space who has trained many models based off images, so I’m particularly curious.",r/machinelearning,Z0FBQUFBQm0yeGJUdDRGVnp3YXdaY1NHX1RCSk96eU9VMFJZakRNTmplY1NDeHJISGU1VkxKS0s5d2lLQ2dQdlVVb2ZuRHFnbjlYbGZreVlqREw4VVQ5UHJJUGc1Z2hRX3hqd25ndVIwYzVUR0RRSTVLSGE0MGs9
"Work on cutting edge, trending sub-sectors where you aren't competing with so many people.

Transformers, optimizing LLMs",r/machinelearning,Z0FBQUFBQm0yeGJUSVV2dGZmR00xWDhId0FMMlVxY0xucjR5OTNQSndnTVphTlRUUFJGWlcyR2NqRGw3c20tU1J5ZEpYaE1zNzNOLUxLRDNjSG9JdUFyUEFoTHhSd05ubnc9PQ==
that\\`s not the problem because i've trained the network :(,r/machinelearning,Z0FBQUFBQm0yeGJUMm1TZnBleXhVT3NlbURTSjBoYnhKcnNGazlXMXRFcURmWjZOWnotc2o2QzZmeEVjazF5LUZlMEcxcTlXNjVURVYzcEhrT21weEhIRHRTejVtdEE3blE9PQ==
Try Elevenlabs,r/machinelearning,Z0FBQUFBQm0yeGJUdHZqdEZURmVfYWpSUkg5ZkwwR0c1c2NkZkFUZ05VZGl1VE5pT2lwd2FMLVUyWERUckxEWEhjSWxGbzF2dk1ETmdGOUdoWGJwbTlQVzVYUW9oVHFHMXc9PQ==
"When it comes to the cutting edge of ML they are now running alphafold3  
[https://www.nature.com/articles/s41586-024-07487-w](https://www.nature.com/articles/s41586-024-07487-w)  
Not sure what has made it as medicine though",r/machinelearning,Z0FBQUFBQm0yeGJUM1JXQ2VURzYzb1RYQXc5YmJ2NHFSOHhfMXZkeGozemtzQzFia0VCSm1xNGJVM0NCVzc4R2RmSXZaX2gtcXlEcW1NUU9TNDhUWDliRUJ5dGwzZ0dWU1E9PQ==
https://github.com/kyegomez/AlphaFold3 this is an attempt,r/machinelearning,Z0FBQUFBQm0yeGJUWld4Y01JSXNnVVFqQ2xpNW0zOUV4YjFYSTk0Vl9MTFpQZEFxZHEtZ3hlQ29vN1Z1cVdVSE5vRUEzekJHbUZGYkw3ZlNRWUQ2bXNscDFVVWF6LWJCbnc9PQ==
Do AMD cards work with the pytorch cuda namespace? That's always what I have to deal with using Apple Silicon,r/machinelearning,Z0FBQUFBQm0yeGJUN0tPY0YxdVNINnFhazRORnBCUXhsOWhVeGZHVzFuSnBVZFdjbFlFX3FtM0N1MDhRQWZfRmRMTi0yTEEwRUhRSkFkc21pVFNOUzU4a0VlSW1hQXRoeUM5WkticmlOWWpyaGRMRktfay1pVWs9
"I have seen that GPTs can generate SQL Queries.  Funny that ML-employers still ask for skill in composing SQL queries.   

As for data, this conference-sponsor: [https://beyondthearc.com/ai-ml-nlp-consulting/generative-ai-consulting-services](https://beyondthearc.com/ai-ml-nlp-consulting/generative-ai-consulting-services) 

""At Beyond the Arc, we leverage over 20 years of data science expertise to provide Generative AI consulting and AI business transformation. Our AI prototyping services are designed for rapid innovation, ensuring AI deployment into business systems and applications.  

""Our seasoned team collaborates closely with clients to integrate diverse knowledge, fostering a culture that embeds analytics into decision-making processes. We embrace flexible development practices, enabling rapid iterations and swift deployment of tailored, scalable solutions. As leaders in predictive analytics consulting, we work with clients to modernize data pipelines, utilize cutting-edge generative AI, and achieve measurable success across global operations. We are committed to partnering with you at every step to solve complex challenges and enhance operational efficiency. Learn more at [https://beyondthearc.com/genai](https://beyondthearc.com/genai)

Sponsoring: [https://generativeaiapplicationssummit.com/](https://generativeaiapplicationssummit.com/)",r/machinelearning,Z0FBQUFBQm0yeGJUQUpVV05sMmVmeHA1N21KYThiZVF1YVV2V1NTbmw0Szc5RTJCUVJvNHBncGJLTExKWE5FOV9hNXBVYkN5bGk4NUNhN1pSVnNLQngxajM2T2RMSWNTcFE9PQ==
"You can find combinations by selecting a problem from one and solution from the other. I.e. large models need to fit into multiple server, servers need to solve loading an balancing problems, specifying the optimal amount of components to buy over time etc. There are a lot of niches that would benefit both fields if you contributed to it. 


Running a model in an heterogeneous cluster so that the hardware is used at full potential is an unsolved problem. ",r/machinelearning,Z0FBQUFBQm0yeGJUd0JIamg4T1VqclpZQThVN1ptX3dHRW1KSW8tRVlFUWwwTVVqcGxzaG1Xc3Y5NzJJaDA0QnpkVTBVcUZYLTlxdDMwZi1wZUNpWlduUngyWmhYbEF4cGc9PQ==
"thank haha, i posted the link and some SS",r/machinelearning,Z0FBQUFBQm0yeGJUS3l6MXJEVy1vSHE4V1BtUFRPZ0gwbmR5RFFkcGk2QWFjR3c4aUVpa1RhTDkyQ181UndfZUEtT1FpWktmTlRudVJRdC12RHN6SmRMNnhQQkZqUTZiZlE9PQ==
i already updated the post,r/machinelearning,Z0FBQUFBQm0yeGJUNmZOX0NHVGxCelluRnh4ZERSTHFpUUhwbnd1cTloaXJZdTBMSC1jU0x1Snk4REhYSXd1ZUhPcWtVOUx6WUV0M25wRXpBa0NxVkNNamVPUFBEbDZUYkE9PQ==
"Check out Monai or openmedlab

Edit: to be clear I’m not advocating for full replacement of radiologists. I think radiologists should be running images through models as a tool for diagnosis.",r/machinelearning,Z0FBQUFBQm0yeGJUOTJ0eXNQeXRRN05qMHFFaDJ6N01IbHBhdV80Qmd1X2RoaXNkTEo3SlpZYjJpQ3FIaDhmdjF4RkIxUEk5SF9oYzBodzhmanIxMFZKX0wxRVM5bWdtUk9WSjFvc0dlRlA2b1I1V3Q5NWVVZlU9
Are you affiliated ?,r/machinelearning,Z0FBQUFBQm0yeGJUTFlGWmZoS3ByN2FQMUVKQ3NZVWlFbV8wbDYtQjA5aktKeG9vMXRLUkItaFZzYTM2WDJ4U1JVWHM1UWp5TlhMaV9XUi1VS0JSSy13UmJBWEdRcFBvWVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUSVBTdnp5OWNXRGZXOEhFMEdWSTFHQ2pROTUycU5QZUJvWXRWdDBPX2txVWZrSWQtSzJvUFpOTFJ4T2VRYjB3VnpETXEtcjhKTllONFdaVHYxTTRzZGc9PQ==
What is ablation?,r/machinelearning,Z0FBQUFBQm0yeGJURTJGVllabFJPMlEyOU5IQUJRUXVKbzJuSGttcmJ5N3drZDZhNGFzdFNvN0pBbEtpQVo2YUN3eEZBb2wxbDBhVmZCX09PRDlrUGFLNjV5ZE9LYUh1REU4clZWSEhhcjlmeWN2VmJHcWJ1T1U9
[follow this guy's track. ](https://tspace.library.utoronto.ca/bitstream/1807/36012/6/Ilya_Sutskever_201306_PhD_thesis.pdf),r/machinelearning,Z0FBQUFBQm0yeGJURG1RV0Vqd1htTV9KdkRZQlViT1dsQ2kxekd0ajFLbXBjb0g2a2ZTWjhXQUg4QlQ3aUdzNG1tcmE0bEhTbmxtWXA4VFg2QVZkV1V1OW8xUThuR1ZOeVNoWldjUTdydzV0SmRUTXVlRXhmLTg9
"Assuming you mean mean absolute error, 2.0748 may not be high at all. MAE is not a metric that can be interpreted at face value as it just means that each prediction in a regression task is off by 2.0748. If you are predicting something like how many wheels a vehicle needs, this is very bad, (as most vehicles have 2 or 4), but if you are predicting how much a car will cost, being 2 dollars off on average is very incredible. What type of y values do you have?",r/machinelearning,Z0FBQUFBQm0yeGJUVzN0cWRnYVVrUmpabmxaZGd4c0k1WHNlbGp4MHpFV3dBeFdTN2ota1p4Wjh4STNTN2Z1MmswWkJ6dnU5a0hTT1BaQWlLU1FBUHV6SlRzSk1qSG1CQ1NQWUl2WlpUT1UzNUZfTWdtTnA3eVU9
Why not just post your error here and not play games?,r/machinelearning,Z0FBQUFBQm0yeGJUSFhVejRQUENraDgtSnN5RUFBMVB5M255SFBCcHVIWWdYNkdwQTJVanpWLVExUXdNb1NHVjdMSURjenBod3lfS2hJX3ZXNkFWRzRHekZpOUFfV0RSN2c9PQ==
Yep! At least on the data center cards you still specify the device with tocrch.cuda and most (I want to say all but not sure) methods in torch.cuda are functional,r/machinelearning,Z0FBQUFBQm0yeGJUYjdVbXV6ODVlWnpUanhuOVhhd0xtOXlWRHFaaTBkOW81by1ZZmVjQW5xbWx1YVhwNmZ4TTFYVEw0anR3RXFWMVg1bVZjMXA0ODBPLTlWcnVQRTRfVUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUN052Q18yUHlLZk51cmo0a1JmWkhBVGpVT09SZUJUMHEyMUJUSVdBcWg5bGQ5RzNsTE83TnlsYlFtM1JtdTVIZFlGZElzQkRVTVBoSXppRkRubXBLZmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUWmdidWRRNlZodEpVbGMtSEFnbm9UWnhJeWN1ZnoxbVJHSG9tcFpHTjlKZXd0ODRBR3lFVVF1TXNua3MzT3FEV1lMM20tbWFrS3ZrWWFuNGJFMmFheVE9PQ==
"What they’re saying is incorrect (at face value). Chromatography cannot separate a protein that differs by one atom at the scales of purification that are needed in bioprocess. Furthermore, most biologics (proteins) are already made using biological hosts (yeast, bacteria, CHO cells).

Protein fidelity is not at the amino acid level in cells let alone atomic level. There is no basis for this. There are general heuristics cells use to correct for errors but not on such a fine grained level.

With nucleic acids maybe you could argue that we even have the sensitivity to detect such small changes in purity but with proteins it is not the case. Protein sequencing is not reliably quantitative at the magnitudes needed to even make these assertions.

Identity purity is largely determined by techniques that do not have the sensitivity as stated above. Purity in terms of contamination can reach very high sensitivity in contrast (host RNA/DNA contamination for example).",r/machinelearning,Z0FBQUFBQm0yeGJUcTBZdk9zSk5IWHlDWVoxel9OTzBqOUtUWjJFcUJjVU1KdkFDT1FHa2hCT2VKVElqT0pBU2tiajVNUHhKenJ4YzZDOWhvb1UxRklxRG83N2psUlhlMUE9PQ==
"That's good to know, I just assumed that wouldn't be the case but of course a smart company would just implement that API. I wonder why Apple hasn't done it",r/machinelearning,Z0FBQUFBQm0yeGJUa0dvRDRZZXNEUFJqN3I3cVFXWGZvNEhLZ25fMGxmbmc5T2ZnLUNvdm1fc2xSc0NSdUdXdjlNN0Q1OXJIeTVmM05pYkFDUTEyaXBSQ2FobW9ITUhsdEFPQzRjbk5Fb1BJaHllbTdXU05NckE9
"It's literally the best direction you can go! Much less research to do, but every ML engineer needs one. Just get certifications for cloud, no need to go to school. One rule: Never do cloud on your own credit card! You will screw up and cost your business thousands.

Just do an ML MS, and learn cloud on the side, and then read the latest research on distributed ML algorithms. Unless you specifically want a PhD.",r/machinelearning,Z0FBQUFBQm0yeGJUYUtVYS1HekFQTWxpTHd4S2JfZ3RYUDlPcjV6b2ZtSW9sTmV0WTlsSFpWVmhtVUpiWkVibHBKU3I5cDJyenU2bHFiMVJjTmlTQXhtSDlsUU55dWIzN0hjUlZiczlHWWttZHpjd3JkY00tVUE9
"I worked applying DL to EHR from 2019-2021. My team built a lot of stuff that seemed to work for disease detection, complication prediction, etc... But the amount of regulation meant that actually deploying anything was like a 5 year journey. 

I don't think that's necessarily bad, but if you are wondering why ML hasnt radically changed the way we do medicine yet, that is why. 

That said, I have a friend who works in CGM, and I know their company is using DL in various places to raise warnings to users as one example.",r/machinelearning,Z0FBQUFBQm0yeGJUZmlxX0U3RjAzRVg3c2M0V2RfQ2RLOV9PdFlnU2xMSmtEYXgtbVBrVGlSMGtsYmVUeU5lUmZ4dHRVZ0hDc1FKNW9VR01ETlVadHFnbmRJRWFIenJTZnc9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJUdW5JRE83OXpGTWR0RWRfNHN1MVJSN1AwLUdmTzJzcEVmejVYNGlNM2NNSTZwY09LNVRZV1JySnBySFRab1ZHU0FHSGx1bGVvOWxkaFJDU2J2NTkxcWhzWjNERDFxUmhhYkJhd1VnZkVITTA9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJUMTFXWnZLSlh5ckxucHhidEJfbGhlY3JkeGJfOWVFSUpXaWx1Y3czZUZ0V3EwVVJzZ1lCcWx5VWVNOHlCa3M5SG4wc2dCQ3A4N2NKRlktak5hdzRJVmp5eV9EVVpNWGVNWWFPbDkyb216V3M9
"It depends on what kind of assumptions you make and how strongly you enforce them. There are a number of algorithms and techniques that can be utilized for the desired outcome.

If you wish to assume that each modality (view) is independent from another then you aren't interested in a shared space but rather in a set of spaces, one per view, such that some amount of scatter/class/distance information is retained, while lowering the dimension of the space. Of course, if you want these spaces to interact with one another then you'd have to ponder as to how these features differ or are similar and how to essentially transfer information from one space to the other.",r/machinelearning,Z0FBQUFBQm0yeGJURXlrRHdOMktoNllGVjhPN2ZNcS14emg4NEM1OUFqa01heWI1d2hvbkh1M3ByMkJ1QWhHb2trY1c4Um5vVnhGQTVrZnJGLWpURnhOeVlLemVQUm9aZ0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUdkszNHA2ZHJDdzZGZzVoSHgwR1l6aG9EclNGZU1pVk9jNFFaUTJUWVh4SWQtY2VyR2dTUEtaVFpiQWU3d08wQ01VamxkaVo4ak1aVkc1WVp0M2t0dWc9PQ==
Any specific reason? or just the price?,r/machinelearning,Z0FBQUFBQm0yeGJUYXRERmxlUG9IdnZkb2NVY1pYVUVISXptcVZJbXcwaXNQVlFYZjRTRjRTQWhRY3p6cXAwMTFtdTdDOW4yeFpoTFBaNXZsMDVwOFNmQU1JQlltYkdwd2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUZG1CSjFGbmFMV3J5VjlXaW04ZU5jNm5tUWJ4Q3ZvRF9aMnZ6N0ttdVVibm5vMXlPb3FTN3BwRll1SGtnbTczeUEzcXhYSGJXNDdJS3phalg1NVV6eWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUMXVBUHVoV3pGOXBqQ3FuQWViU2JwM0duVU45SHhocTU0aTJIalk0OHEyMU04OFdDcHBUSFJHRTZEMGZjRUdYbWJVNEpBUkdOZXlzcGUzSmdJeXdINGc9PQ==
It’ll be interesting to see if any alphafold (or alphafold-enabled) predictions make it to clinical trials,r/machinelearning,Z0FBQUFBQm0yeGJULUZCblJyc2xBRHEtX2QtbWpkYmJkUnpMZXV0Tm4yTWNjcEVWOGxmWVFwYWtvLVFOZU44T0wycGxvaGdUV0V1QWlqeWJtS3hRanRGS0hRM1lKYU1pZ0huVmJSVVJFT19iU3ozbUlwWHFldWM9
The boring stuff can have the biggest impact,r/machinelearning,Z0FBQUFBQm0yeGJUeHU5d2xuODcydDNkWlJKWm0zWkY1SDRRRGRRZTlHOTBJdllKX0g4SzJVb3RNSUE4aDBHQzlDa3lOQjRncFo0cnpqSW1GYXpobUhaazVna1dXN2NHc2FYS252SlFqSHA3WnhBakRuVGRzaDg9
Isn’t GWAS just about of t-tests?,r/machinelearning,Z0FBQUFBQm0yeGJUWXcxZlVuVHFnVG8xYUVlWnF4WmJsb1VPbkdZekVHUDJIQWtZZ2J1WUU4REl0NUUyeTJlMlNaZjVNMF9DZFhETXFaRjdhMFh0SlZIWlFPSXd0NFlNS1RjX2xyanhyR01Qd1ZmVldmeTdZWkU9
I’m not saying scientific research is inferior. The opposite actually—basic research is the only approach that has had a meaningful impact on medicine.,r/machinelearning,Z0FBQUFBQm0yeGJUVVVYWjlDNkpDczAwdU1Xd0RlVkVpYXZKYldCbmdaeG15MHVNUDY2NlVERTZ6c3dRUWZfbnRMRl9LT1hLenJmdllRSjRZUk5WLXlfb1l2MjBEeklmWTd5S1R4ejlzcGlYbFZOaHpNQkJXLUk9
Great example of ML going beyond automation and enabling analysis humans couldn’t do themselves,r/machinelearning,Z0FBQUFBQm0yeGJUeEJTMW5xdTFZRG5pZVFLc1dUTHFSRFNiZGR0NHpHTl81YjhmdXFjMFYxNUJLM2tuVjgxSnJyWFJSY1lpNjRzWHNaNnBXM0V1TzlJVnRuYk1rRWJaQ0lPSG15ZjF5Y2todVc1LVRURGNDMnM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUSXNaYjl5RnlDOVctZnZrUEt4cEtySnlWSVR2SGdSaW14ZmJCbHF6bWxCbEIwWTdydzBnQ3QzX283Yy1PU0t6Q1V1NXVTbzFZY2x3d2xpZkFjV2R1dWc9PQ==
/r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJUejYwR1JuX210WmNHcHBkc3NfLWE0WmRVNkFGaXhiNFoyUURZajlRSTAwZF9sTnZSRmQtOFduZE1fWUN0Y1Q5d1pBbklReWh5WHhqNldSUjlBbG1NU2p2QlVhT1ViX2twUlRacVVhUWxwdnM9
The data would have to come from a decentralized database,r/machinelearning,Z0FBQUFBQm0yeGJUQTVvZUxORngyRW9VUXdSZ0xGc3BwZnFiSFRfRHl3UXFsVmtmSWR3UDlPa0gzb095U1FaQVFpXzlWVVlfblpMRElieU5BYmdVQlpsWTROT09oUWNmTUE9PQ==
"This definitely depends on if you are in a tech or business role and whether or not you have people working under you, I will try my best to address how I would go about this in a couple different situations:

If you are a developer: In this case I would try to learn some ML algorithms and figure out how to build some neural networks and train them on the data. I find python most intuitive for machine learning work but R is great too and assuming you have access to all the training data you will need, these languages are both great for data manipulation so you will be able to build your datasets. After that you will be able to explore the data you have, do some regression modeling to see what variables or variable interactions have effects on your variable of interest. Finally, train and evaluate some models (depending on the problems you will want to try different algorithms) and see if they have some predictive validity.

If you are in a business role in charge of developers: First, look up some high level ai descriptions and particularly focus on machine learning. Do not worry yourself with the math or linear algebra and just do your best. Maybe just watch a few crash course videos and try to conceptualize how the data should be organized and how you would make the predictions and bring it to your developers. Figure out your X matrix (inputs) and y vector (outputs).

If you are in a business role not in charge of developers: Do the above steps for business role, but now you are the developer. Learn some basic numpy/python and use some chatGPT to help you organize the data. Training the models should be easyish once you have the data organized, you don't need to optimize and find the absolute best model just convince yourself that the model is able to successfully predict a reasonable amount of test entries when the test entries are separated from the training entries before training time. After this you have successfully made some predictions and you will be able to take this to some other people within the business and continue to improve the model before making real-time predictions on live data.",r/machinelearning,Z0FBQUFBQm0yeGJUcjRMUi00R1BGaW81T0FkNVRQNjMyMWk1ODhRU0dvcjBFaGwxSkotTi1CRWVDWHRoZTF4SDk4MU1kbzhuLTZjSTBmZG1IcmxXNkpUcHREY1NZd0EwbkVyeHZUb0wzbzRVbmZlOThjcFlETTA9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJUNWpMVDFtOGcwLXczTmVPN21yNFNIYWFDcmF1WGNUTG56RndxVmdTak9HNXBTSlhMNnVqLWgycW1CZHpMN3VVVy0xdWNLRWJ4bDR5Y3RmR0dJTXhqdUtISjdQLUlPeFdTS19UMEtNQng1Vms9
"So does this mean my prediction is correct 98% of the time?

Also here I'm using XGBoost Regressor, can I input the values here and see if the model can make a correct prediction

Here is my Y, here predicting price of a house. Like those numbers I have 500 rows of DataPoints:- 

24, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 1525, 23.4, 18.9, 35.4, 24.7, 31.6, 18.8, 18.7, 18.5.",r/machinelearning,Z0FBQUFBQm0yeGJUY3dpdGZFQW9jOU5HaFNMRXVsTmNkX1dlVGhBcGZvaWNUYWZwZ25QaDdESUxxdF9vNVFuQWQzZGNEWUFlVTc3aVZOXzhwQVI3XzAxUzZoUXhXODFTOUE9PQ==
"Ahh I see, it's basically using this theorem [here](https://en.wikipedia.org/wiki/Jet_(mathematics)?oldformat=true#Mappings_from_one_Euclidean_space_to_another). There is no 2nd order expansion, rather this is just the 1-Jet of the RHS of 10. I never knew you could do Taylor expansions of f: R\\^n -> R\\^m (I've only learned f: R\\^m -> R).

I didn't find a derivation of this sort of Taylor expansion in my textbook (folland advanced calculus), I was planning on deriving it myself. Do you know where I can find a derivation of this (to cross-check)?",r/machinelearning,Z0FBQUFBQm0yeGJULVFWU1VBR0pDR2w3Z2JKV2dpYUZZUDgxVnAwSXNRSWlmY2hSQ0dNcThGMTRPcVI2bWRUVmhfbUpyYnVidHQxWVZnY1BJTEU4RDFnX0dSYW1PcHo0QUE9PQ==
"The interpolation thing is true, but it's also sort of a red herring. The more important point is described in that article under ""bonus property"": you want the inner product between different position vectors to give you meaningful information about their relative locations. Sinusoidal encodings work better for that than straight binary does, precisely because they vary continuously.",r/machinelearning,Z0FBQUFBQm0yeGJUVWVyZ1VEemtyU1hmTDN3d3FQbGlONUY5YzRMd3RoUUZRLVdEemY5TWNkRnNqRUtFaHRpNUdJOTd2b2xNNzY0STd3eTVjMHBMeGNqMUpsZ3plM2lBOGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJULThNeGdkczJYWmNjalNHUUc4c0J3eUNqX1hnUW4wZm9oTHNSc2RtcFdEcjR1WjRQX3BWQ01INkVyb1BBN0MxUGE5QUtJcGNVRjFldXNyd1BUcnNCeGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUamhSYkFjekZ6bmxQTGJoZFFtTlB3RTFRV2hlS01teGJOc2xvaGg0UFZSOWxILVh1LVc5b1drX3pPc2p0NkRyUU50UkhhYlBOSFFobHRUUzVjTlBESmc9PQ==
"Yeah, I didn’t state that well. I was thinking post GWAS linking causal gene expression to phenotypes. I am not an expert here but have collaborated on projects as an epidemiologist measuring patient phenotypes from large electronic EHR. For example, improved polygenic risk scoring and detection of epistatic interactions.

Most of the GWAS studies presented in our department report using AutoML GWAS, at least that is my memory. It may be that ML based GWAS is becoming more popular but I was thinking of analytics more likely described as post GWAS. 

I am not expert here so I could be wrong too.",r/machinelearning,Z0FBQUFBQm0yeGJUckVIaDhpQlQ3NWtuVjF2TXJHV2M4VEtSQ292Vmx2RS1pRE9Lb2dCeURjWmFTM2N5cjNvNHpUSTM2OGY1LVJ5U3loUUx6alAyV3FONzZKTTRYM3lWaXc9PQ==
I agree. I spend  a lot of time reading about statistics and related topics when I am at home.  This can be strange given my job deals with these things too.,r/machinelearning,Z0FBQUFBQm0yeGJUdEJnTlQtOUxPYjhsb1JBNlFDY0ZyYjlwVndMY2NlOEIydnc1ZThCUGs0MWxYbFExUm1ZbmlIcjg3YW9WQVZtNVhqYllMSXNoenNZUU9aYmFTWDQ0ZVE9PQ==
"This is actually quite related. If you have multiple steps in your operation where each depends on the last step (e.g. sorting, or RL environment simulation), if you roll the computation out, it is pretty much the same situation as a very long recent neutral network.",r/machinelearning,Z0FBQUFBQm0yeGJUMGY5RTJ6bWZMLWl1QnFHVDd2RW9qelFxMDFfUE8xVklSMW5ISEFCSThXZ25SN1B4M3ZjUkFGUkprYnU2alN4T1JKVzh1bjllZ3c1SFEtVE52MFFjMHc9PQ==
Any key YouTubers you recommend regarding this topic?,r/machinelearning,Z0FBQUFBQm0yeGJUdHpTa0RaaVZPWTFUakZoY3oxZDJHU05SWXZLODFwMHV0Sk1WODhicFJsNWg1eTdRamlxcENzTm9Cd2FITGp4bGhldk43V0pEMGpTUVBqQXNOeFgxRTZBcmd5RnB4ZWlENFl6U01QdVJaUGc9
"It’s funny, I get a hard time about it from friends and family for studying in my free time but I genuinely love learning and digging into these topics. If I didn’t have to worry about money, I’d absolutely get a PhD, but at this point it feels like the opportunity cost is too high given that I’m 30.

So, you’re definitely not alone in doing this stuff for fun!",r/machinelearning,Z0FBQUFBQm0yeGJUcFlxVnNmaFA3TEN3UmFoLW9nWllOMV9Yck9PSTdMLUlSSkx0M1NPUHBhX2hkNUJrMmVEYmlBb1FEZ0Qtelk5UW54OF80RUZVVHU1TGpDM3pMVDB1WEE9PQ==
Digging in…. I like that!  Lifelong learning and challenges.,r/machinelearning,Z0FBQUFBQm0yeGJUdkJGWlk1cXpCUE0tUkloajctbTBUcDgtdHdqR1lSMHNGQU9mVjdpa2VyeVRndEFweUNDY25IbTRibUpBYlNMVjJOdWJob3ZNMHFkWkNUNWhUSkotT3c9PQ==
"No, it means your predicted y is on average 2 off from the actual y. I am not super familiar with XGBoost but I assume there is some way to look into input importance and you should definitely be able to make your predictions on test data and compare them to the actual values on the test data. Given that the average value seems to be around 20, the MAE seems reasonable as you could kind of look at it as a 10% standard error (20+/-2), like I said there is no ""acceptable"" MAE value (except maybe 0) it all depends on your scale. You should use a variety of metrics to evaluate your model.",r/machinelearning,Z0FBQUFBQm0yeGJUSFlGS1FyTFJLdzUzZnFxdm81dnlaRVUxdjd0eTJTSTBteG95MUdlS1Y4ZmNMTzdub0JYYWZsTlliTWtEdTg5bnFZbkdfbDR3X3dzQVRBWDNGblBsbzNFNzFIRm11NjZqakwyckNiY0Q0SWM9
It seems like the next advancement is low level cuda coding. ,r/machinelearning,Z0FBQUFBQm0yeGJUTm1pUjBIbXE2dnVJVS11eVNZczFYQThwaXJVQjNETXJSWkhUOFE2LU5vM0Y1SUV5WXlEcFJQOW9EaW1zZHJscGw3UkVncE1fMVV2UXNVNEYyM3lNU1RYRkhIRzNodW5KcHlXa1lFSWpPbG89
[shadeform.ai](http://shadeform.ai) you don't have to limit yourself to one on our platform. You can deploy to 15+ clouds with a single interface,r/machinelearning,Z0FBQUFBQm0yeGJURFBURC1WOG5HaWViXzJtZU4wV3k2S1ZTYkRacWI0RzJxR01pNlRTaTNhRG1VRXRobTV1dTV1b1IyYXBuOE9iY3R5YzNtZlN2dkZSV0JHZnBIRTFGOWc9PQ==
Doing practical projects. Just theoretical knowledge is not satisfying to me as I have to see it being useful somehow,r/machinelearning,Z0FBQUFBQm0yeGJUTzhPOGRsVGVpV29UR2YzaFJ6V29mc1k0RFk3MWhmMDM0LW40ekl0R2czNlJ3aWlHSzZNbDdsQkduZzVUdjN6U2RhS0JZTzVMS05NcDZpa2puaFRtZ0tQa0JJc3ROZ0dwVjBRcUdCQnBnUHc9
"Reading a book named data science by vijay kotu and research papers casually 
Trying to apply all concepts in the book and the papers i read on kaggle notebook.",r/machinelearning,Z0FBQUFBQm0yeGJUaXJzUURkaUJINkxqSjR3enVpSnJ1TF9wRkQ4QjJYQmJ2UThIWk9hTHA4SnJQNnZsTTIzSWdfaDZjQnNwTUFFZi0wY3FXcHZVaDVpLW1fUFdkNWg5Vnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUcGVXcXhNMFV0aDlxWjVuS1BSNnJ0NENVem81MHNYNDVCQUd5cl9QQ1hkbE9OaktISG1HemdMdGQwY25Uc1pUVFktRmljVllnUFJMb01haUJCS1FNVGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUeXQ0M2I4QzRWM0N5NEQ1QjhhVGJrY0pyNjRSd0FjLV9uR2U2VlJuc3p0dks5c204OGlYY0VjSi1PMW1zZmFsUk40bWtLbGhMazV2dnJyRzh1N1ZEcFE9PQ==
"🦋⬇️🚀
https://youtu.be/P8WiYRbpTVQ?si=rs1hVqfyBpYgPkme",r/machinelearning,Z0FBQUFBQm0yeGJUS0hSQXFBTVNjSF80V2wyYlJGdWhoUlVaaDFIVFB2dDdpc3k1RXpiV1ltSFh6MFJSNXFzX20wdkt2cktRaXpNODEzaWk5d0p5Z2RQcDYwd3F0SDRuaTdCaEhIanV0WUlPeXhQNFgtV2pnazA9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUSUloaDRGdVhOaW5LWl9CaTMxS2libm83TkI1dElEd0lQcjF2OFJ1cmNQYy10MHE5bTFWZl9fRXNvZEhJaVg1aThwRDNNQS1XQ3hmaS1QTXhvU095RXc9PQ==
"🦋This one might be the one that you should watch first and then the other link I sent you before this one? Either way you’re in my prayers God bless you. I’m very proud of you that you’re your God-given human intellect in this area of our brains that most people don’t have that gift for. Anyway God bless you listen to the link below thank you

https://youtu.be/Khjq5W6yQh8?si=ItwYsAbvguY8LX7x",r/machinelearning,Z0FBQUFBQm0yeGJUUllfSlJlQzNUakdUcGlTRWUyQ0c4ZjAtcHRadHZYajlWZFNfZGluRlMyb2R3X0hxRGdycGNuOFdKLVV3OEY4cU5sSlpGekIwcUpDcnZULXUzcXoxY1RnRjRTRDdIYTdUeUpOV1dNelRVVzA9
"🦋 hello machine learning, AI. Listen I know this is a year late replying but you are so right on I just replied to another of your comments lately but it might be a year old but if you get it now time is not the issue God does not have a time zone. We do down here so your prayers are more likely with mine included today praying for you guys. I’m sure it’s more than one of you that are seeking the truth of the AI level of understanding in the sense of intelligence that has been a blessing from God in our brains and the only ones that can figure it out I believe you’re one of us with God of wisdom.",r/machinelearning,Z0FBQUFBQm0yeGJUQVRmT3djUGtpcXF5Y0RoVnUzcmdyQy1OdXZvajVBVWVVcnBVRUl3bDYxT3diSHNYekh0UUR3cDNnZXdXV1E5WVd1T2xILVJQcUVsQl95RnNWVzlSZ2c5MklhU09WOV9WQUZRQ1I5Ny11SVE9
"If anybody out there in🚀 space going back at least 50 years ago the Jetsons! The brother, AI has always existed in the brains of human beings. It doesn’t mean it’s bad or good. It just is there hopefully for the good to beat the bad people the third-party who wants to be scammers, the hackers the watcher of the world. God bless you it is a database and it is a computer which is so funny but the reason now I believe AI is important during this time of existence is that it’s gotten bigger. I love watching, from the time the Jensens came out and up to our time now nothing has changed other than the minds of human beings are afraid of a computer! Anyway leave a reply or comment I can finish it off another time. God bless you guys you’re in my prayer if you actually read to the end. But I learned something from AI on my iPhone that I can actually push a button and it can read anything, like a newspaper like my comment it’s amazing that’s amazing but God is the Almighty God the most high God who has created you to know them. OK I said to them, God the father God the son and God the Holy Spirit. Three God in one! The Trinity which I’ve been told is not written in the Bible. And yet many denominational religious people love to say what I just mentioned above. I’m a Born Again Christian because Jesus Christ saved me. Anyway I can go on religion is dominated. A child of God is having a relationship with the father of all creation. You’re all in my prayers in Jesus name amen",r/machinelearning,Z0FBQUFBQm0yeGJUNzBhWGhlRWt3Q1pVYUk5QVZHaFFLQVVtN21pZW9HSk1PQ2RWdGNhcU9LLTQ2UTJpbzhBdWFCNnRQZ0tZX3p5NGZ5TGZRWVp5cDdndjRYSUdQdEJNSFB3Nk5qY3B0eDJTTVR3Y2J2Y2tWNE09
"Some ideas for you, and you can probably find some references to dive into:

- Synchronous SGD: Some notes \\[here\\](https://www.cs.ubc.ca/labs/lci/mlrg/slides/MLRG\\_Synchronous\\_Stochastic\\_Gradient.pdf). You might also try searching to data parallelism

- Federated learning has some really neat distributed computing problems in ML

- Model parallelism, iirc AlexNet used this because the model couldn't fit on the GPUs he had. I haven't heard of active research in this area but there could be

- A couple years back when my team was doing contrastive learning, we found that the quality of the model scaled almost linearly with the batch size, which quickly ran us into the GPU memory limit. There might be some clever way to distribute that

There are several different areas on the serving side, such as:

- How to do autoscaling without a big latency hit when scaling up with big models, because they can take a while to load. I once saw a clever paper at NAACL that stored the word embeddings in Dynamo and and the rest of the model was so small, so it loaded really fast and they did queries to Dynamo for the embedding lookups

- Software patterns for models that depend on the outputs from other models: I've heard of this getting very complicated at some companies, like complicated to version, debug, etc. I haven't heard of a term for it though

If you're more into the cloud part but not necessarily the distributed part, there are important topics like detecting drift of the production data vs the training data.

  
Anyway, just tossing out some ideas - hopefully some of these give you things to search for! And once you find the first paper in an interesting area I recommend Connected Papers to browse the citation graph",r/machinelearning,Z0FBQUFBQm0yeGJURnNwbk00YXpZUlNWQ0trS19GVGFTMVBaeTU5dkZXZkFXQlMwaWhiYjlGV1VRT2pDeVI4SDJsd2VtWTV0NE1Bc2J3aUNVeHhYSHBKYnBNUUU5TkRnZWc9PQ==
"🦋 hello out there in the universe🚀 I have no questions but I do have answers. OK I’m reading your post about simple questions discussion group OK. I have to think about it❓💭..
As human beings this is my question, as human beings do you think that the God Almighty created us to be the great I am? Or do you believe the great “I M”  is the real thing? Not a computer program of intelligence. But the God of all wisdom and knowledge has allowed us to have a human brain to think for ourselves. I do accept the AI generation of learning how to keep certain order. my opinion on the AI expansion of using computer database knowledge to pull together more-database
Intelligence is a tool! Leave comments below because it’s just a tool for human beings at this time century that has so much intelligence on the computer world. And the AI system which is a tool that mankind human beings, are trying to understand outside of the realm, who’s up there in space?. please if you like to know more reply. God bless you!❣️🙏🏼🦋",r/machinelearning,Z0FBQUFBQm0yeGJUd0NGVjdRNThWZl9EZ0N1YTdpM3hUN3ROWXVRZ2IwUjQ5ZHpOWGh6VXBaYjNBSEUybkFnbTd6S3ZVcHN6LWJiZjlERGtROWdsdTNub2I5TTMtX0ZyZ3AxUUxieDYzd0ZoUHRHdmhZT3p0Y0k9
"You can just use mean accuracy, which is the accuracy for each class averaged,",r/machinelearning,Z0FBQUFBQm0yeGJUZFRqYmQ5ekdLOXBKNC1aQ3ZlNnotM3pGeTFHNU8wM3Z3V3JWYUV1d0RxbTJDa0Z5Yk1lSHo0LWYyNW1jblotaFZucUV1ZGZUUGo5S3lSa2I5LUFKRFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUV2dmaTZ3bi1BeW4xMVBMam5lNTQ2M1RTZGFUWlNTT1hKTHZkRHhxUUhSbkREdmxkVzJZclpkNDIxVnIxUDBoNkk2QUxIOE5Fb2V3Q3h4RkwyVDJKeEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUYmRjSXRvNG9TeXFnREh5OVJvS2duRkZkM0NKZE1qcDdGaTUtLW9wUFo3M1hjcmp6clVTSXlvX3hZcVpLbGFGWnd0a2ZKNWo3WkZzcEcyS3JZTWRSbGc9PQ==
There is a area of research called systems for ml and check out its premier conference Mlsys to know what kind of work is going on,r/machinelearning,Z0FBQUFBQm0yeGJUWjlfWlVfRVZLVDJYRHJmSE1oNFBEcTZyajk1NFZhUXExU2ZaTF96OXNNWXRPMERNTWZWc3hGVEZwUmxtQUlYd3pTUHZFbDFoTjBvdVBhc0QteElNMEE9PQ==
"can i also use macro F1 score, right ?",r/machinelearning,Z0FBQUFBQm0yeGJUcDFoeGhsYms3NXdRazVEaHFnU085X2I3d1lJS2tSTE1SckRWeFEwS2F0dXFjaUc0cWpWcURfMmpRRFc3a1V3VzV1eVlWWEswWWF5aFZVbDFLRFBTTnJkd2xnT25NYVRjWVVkeE9LNUZhY2c9
"This is a good list. Just want to add on to the inference side since OP explicitly stated they were interested in this.

Distributed *inference* doesn’t seem to be a very popular academic endeavor.

There’s this and the related section just references distributed training.
https://arxiv.org/abs/2311.03703

There’s also this: https://dl.acm.org/doi/10.1145/3470567, which has a better reference trail.

I guess tensor sharding can be considered distributed inference too.

But in comparison to distributed training, you’re probably not going to find as much. These two papers are probably good places to start looking  other papers and groups for inference distribution.

If you’re really excited about a particular school or PI, you can always ask if they’re taking students and if they’d be interested in branching out to your specific interest if it’s not too far of a stretch (e.g. someone who’s done distributed training research before might be interested).",r/machinelearning,Z0FBQUFBQm0yeGJUelpBYUNQUDB2Y2VnNElRWFcyX1JlSmo0OThEVTdGdXh2V0NlTGNOUWljTlQyekw1X05rMEhic3BxaUVmM3IzVTdncEdqYkptQnZVY0l0ZHAtdFd0OUE9PQ==
"Why _not_ MNIST? it's a great toy example set that runs fast on a potato and acts as a screen test for any new proposed learning algorithm. If the new algorithm struggles on MNIST, chances are it's not worth pursuing.",r/machinelearning,Z0FBQUFBQm0yeGJUUHlZSVR0RWRKRkdXQjAtU3FMaURNTHpfbmdNMHRseTdmMnBteERFY05aVHVuamFHZktoUW03WnhzR1hLNW9aV1VDVkhpWXB2X2xwRWN1ZmhFRFZVQzZLOHNyN21QSzNpZWRnc2NQS0dVOGs9
A minor update was published today at the same Arxiv URL given above.,r/machinelearning,Z0FBQUFBQm0yeGJUZmtXTEwzdlFUbFBMemZXWTNqSjF6a0hiNUFTM1V4QjB1LUJBa3VhVnVHNUhwRy1RSS1IOXZSWHpxVXMyNkFpQ1pUNGhqQlVKX0dJTm1GN09TOW1wZkE9PQ==
Any progress here? What did you find,r/machinelearning,Z0FBQUFBQm0yeGJUSVp5YzNBN3Boemt4eGxaT1FOT3lCWnVLSDd6TUpacHNKNm91NXpMRkF2LUt0dE1tQUVGekVGc1I5cUpqaUdUcHcxVWF6bG5QRExsaUJEczQyWlFkbU8tVEFBNGFnWFhiUGJqUDhNX0FpZDg9
I'm convinced that our brains are extraordinary precisely because they do not do global convergence.,r/machinelearning,Z0FBQUFBQm0yeGJUcENlbW5RQkxITGVnUkJEdVhENjVLV05lNmJESkhkYlRyYUNvbDJDN1dWWlh5NUZFVzVaZUdWZXZFdnVQTjFjd3gtMndtVnJNRzEwWjlBNUNfekpxeFRjeTlKZVFHOHliaEt4S1BCUVAxaWs9
"I don't think there's a ""right"" metric, but there's many different options: Macro F1, Macro Recall, MCC, Kappa, etc. E.g., see https://arxiv.org/abs/2404.16958",r/machinelearning,Z0FBQUFBQm0yeGJUWEVFd1NmT2h0aEZuaU5nRFk2Um1sbmtzeDhfeHQtVTlXMU9lRmFjbVB6UGMta2FXUXVrV1pYeFlxdWNveW9nd0hXQ2VFMDl6U0Y5WVlzLVRWanlXR0RuRlFwbVV1M2lpOGhuNERpczRSZnc9
Locount and RP2K.,r/machinelearning,Z0FBQUFBQm0yeGJUaGpTaFY3NHQzaFc3eXlTUDNNWHIyX1JfSjYzbHZ3c1JyX3BqcDJhRjJzcFBtT0NWM0FENk9IcHd2MlpjNWFMZlgyVlZGNlRsZXV4OGdGLTdza3V5dmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUYV9IeFVhM3dJZENsVlBoUjJpd1hXeWhkUHFLYy1NdTdNLXVETjFxcnQ4a1R6SmV6Q2lGY3BnN3hEUFBEQW9pOEVleXYwUHZKZk5HZWZpV2JmQ2RtNnc9PQ==
"I watch a lot of sesame street. Happy, happy, dance, dance, happy, happy, dance, dance!",r/machinelearning,Z0FBQUFBQm0yeGJUcmxmaF80YWphRklfcDRweFI3WmJ1c0ZFQ0NVN3gybTc3VzlPWEowc3N6bGczRzhMWDdCdVhCQUtqNXRFcl9TZURhSDhCVkRURmUxQTFhc2FkLW1MV3RIQ3lQTTFQcnIyMEJwU0c0Y2k0d1k9
"Would you say that it’s misleading, then, that the article presents interpolation as the motivator for sinusoidal positional encodings?",r/machinelearning,Z0FBQUFBQm0yeGJUcUE5QS12d2R4SGx3bVN5QmMySEx3QkRTOHY3ZlRyNk43Wm9vaW55Yi05ZG5nYTIwZHhNVld5N2N0Umo2N0R0VnMwOWlKVXIzVXBUWllNRm1ESlJONGc9PQ==
"Have you looked at the original OpenAI blog post about CLIP? Don’t know what kind of data you’re looking at or how much of it you have.. but representing different modalities in the same space allows *ideas*

Not even sure if unimodal embedding spaces would be able to converge on such an odd thing after the effects of regularization.",r/machinelearning,Z0FBQUFBQm0yeGJUYUh2OURWLUFFTEZBeEFyMFBOSXBkOG1fbS0yeW56X2JCMU5UT3Q4UVdfZ3ZwRWNGWGlrQXFCVmZEQTFwZUtHN1pKclhhTzJxSkUzVFI1SmZwZFBfdVFTSmJ0djB6SnFacmUxbkVISmlDS1k9
"Hey sorry for the delay. You can find more info here https://www.aeon-toolkit.org/en/stable/examples/similarity_search/similarity_search.html.
The module is currently getting reworked, a PR is in progress on GitHub explaining the changes to the structure to support any distance MPs",r/machinelearning,Z0FBQUFBQm0yeGJUdXQ0Sk4wRENjZ013TU1maHJZVXp2TlFVM2dXNVJmRm9iUlNOSU9wdlBVOWM0eXNvQjkyTUNJOHcxVzd1cGp2cmNPZGVQbjhWTEcyemFydFlXTVNkdEE9PQ==
Nope. I never put significant effort into it.,r/machinelearning,Z0FBQUFBQm0yeGJUTHFuTnFKTE5OczR4X3kwZDNLSzY1SmNWSVpNYXBJc3Bhbzd4TmkwWUZUWTJ5VVVuT1oyY29vc0J1NFVsTU8xZE5UYllVbWFSRXJYZUYzWi04X0NvSHFmbzZ1R2dBd05YS2dLd3NOUENIeTg9
"I quit my career as a software dev at 32 to work towards my goal of getting a PhD to learn about and research the brain and cognition,, because I loved coding but hated the industry. I had to do my high school diploma for 2 years (with some kids half my age), I did my bachelor's degree, and now I'm almost done with my master and have applied for a PhD open call grant. I couldn't be happier to have made the change. My field of choice is cognitive science, not pure ML but definitely related and it's a big part of it (as is coding and data science) :)",r/machinelearning,Z0FBQUFBQm0yeGJUWE1jZnhodUxVbGxYOXdsZl9Kb0ZUMmhFVU9yMlZFSlZ1N1p3M2w2NVNvd3NXSno1d280SC1McnRFUm1FYlVOV1F1REJsY2o4YWlnVG01OTJ1OFVtZEE9PQ==
Ah ok. No worries,r/machinelearning,Z0FBQUFBQm0yeGJUQ2FXX1I2OHMyMVBiWEkxOGJHaHRUbWZXVlp1bmtGN1hYTGM2bUxLTFNMa0RzN1NPOXZwWGhDOExXaG9oSzQtWHJldWZZNmJWNHlxMUhWaHl3V3ZGR3NaWTI1dUs1ZW9uRXIzSmNJWVpSeEU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUYUdCbWtfUUdMYXJLY0JVeGZFVEZteU5pQmQ2V1JUNTdaRnZjZW5VRkczQzVHVE5pUUtMcW5nSG15cnNXV1I3LVBHNHcyYUZPZ0pFcjI4dktpU1B0NGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUcVlUeTg4SlNaMmtsTTc3amxXckdCRHZPS0tEdW1lV2dDdG1kTUl3NmliMTU2akNRRVRWcmVReWtnc2sxMGQtN2ZFR2RTX3NoamRneFNZMV9uaDN6TkE9PQ==
"area under roc curve.  Even better if you have a binary classification and you are interested in detecting the positive class you could plot the precision-recall curve, and compute the average precision. 

Anyway, next time please post these kinds of beginner questions on r/learnmachinelearning

Edit: missed the part on multiclass, but auroc still is good to measure",r/machinelearning,Z0FBQUFBQm0yeGJUYVFVZUx1SHNRQzUwV3ctUE9RTHpZa0dkOHdKRXNYdE42NmFDU2NkRnkxMm4tcmNEM2s3N1phUzdMaWxvM0V3RVhBOE5lazNaS0RyZTh1NUlIT3dNMncxN3lpWTJLSFF0TzZnMG5ocXlpa0k9
Not as true as it has been ,r/machinelearning,Z0FBQUFBQm0yeGJUMWJYcEU4ekllamE5Q3BWSEJtLVdNMG96b01ZOENoZHNjemE1MGw3bHd6NWtaZFdzamM2R1ZGWm40TElBQUdpMGRjdU80Wm9TTndYNUtOQjk3Qll4NEE9PQ==
"Thank you very much for your answer, i will join group",r/machinelearning,Z0FBQUFBQm0yeGJUWVRFM1c5NEpnRjBkcjl4ZXBfQ1VMeG9LMkZ6bkt4Wl92NUR0dWd0X3hkSnFqUWVzRzdoNmJEc1hVZjdUSDl5TGRjdUUxSVFnZng5dGx2YW9uaTZsck40azhHTzFKSWY4emR2OVpGd19Hb1U9
"Eh, I'd probably frame it as pedagogical more so than misleading. The story about interpolation is technically true, and it follows in an intuitive way from binary encodings, which are themselves intuitive and easy to understand. 

Relating tokens by ensuring that the inner products of their vector representations have certain desirable properties is, by contrast, a very abstract way of understanding the issue, and it's difficult for people without a strong math background to follow it. I actually quite like the presentation in the article, I think it strikes a good balance between pedagogy and technical accuracy.

And, really, neither of these things was the true ""motivator"" for sinusoidal embeddings; all this stuff about interpolation or inner products was been developed in hindsight by followup research. The *real* story is that the people who first developed sinusoidal embeddings probably tried a whole bunch of different things and, out of all the things they thought to try, sinusoidal embeddings worked best. The ad-hoc nature of sinusoidal embeddings is suggested by their original formulation, which involved some weirdly arbitrary frequency coefficients, and also by later developments like rotary embeddings that are more principled.",r/machinelearning,Z0FBQUFBQm0yeGJUS2hrZkphMS0zVWw2Mm9XUFJTc3BoZWpqeGZINWV4WjBSeUZDTnVDcmxpd2NOQ2psN2M5ZGVMeTdLNGpNM2MyNVpHR2NpSTl4X0c2MnQ2SG9JQmdWRnc9PQ==
"Thank you very much, i think that macro F1 will suitable in my problem. So i will try.",r/machinelearning,Z0FBQUFBQm0yeGJUZUs1a1NzWmZFbXRWQ1RhcW9zZERWRU1ySWRuSV9BZU03NXRwaXp1QklRMk1CUDFZRUY3UlV5MVhrcUpEOTNXbjBESlVSeUlraDVzZEhfeklMNWJ6WmNNeFpZeVBZZ3dUNWhNNFhFLTBkR0U9
"There are a couple of stackexchange posts on this, basically using Taylor expansion of each component of the vector-valued function, I think. Just search multivariate Taylor series.",r/machinelearning,Z0FBQUFBQm0yeGJUcXo3STd5cGxLWDVwMDYzUGsxRHBCMkxraFMtVlhvaW1RenJyWWxRekt1dktMMTVReVV0ZmRLU3hXcnNpNmtJOHE5Mkx6ZkZXUnk5NXJEdTFKelRaTTJFd2otd3lzOUphQmNMNFdxX09hQk09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUTVhUVlFQMXBrRG5yUjVFQ3Vlc3Y0aGk1VlBOYktRbElJVm0zZmYwNmNHZTkyYjV1Z3J4LUh0LUZ4cFU3c0pPcl9zNXlWZUlJY1N6RklQSnM3R3NqR1E9PQ==
"I think people often overlook the PR-AUC metric (in contrast to ROC-AUC). The precision-recall AUC metric measures the ability of your model to balance betwen precision and recall. A better model will have a higher score, and will allow you to work at better precision for any given recall (depending on the classification threshold you chose), or achieve a better recall for any given precision. 

To the best of my knowledge, this is one of the **least** sensitive metrics to class imbalance.

  
The caveat is that it's mainly useful for binary classification. I don't know if a good generalization for multiclass exists.",r/machinelearning,Z0FBQUFBQm0yeGJUOUtQVUVtZUJQcGhHWC1SSWVnY2w3SG9QRl9tcnZ4YUU3ZXUtTHctellCaFlDSlBRYmJaQTBUZnIxSEd3VUN4WVNCbGhULXNfNTV0R1N2QzFLZ0EwY3c9PQ==
"Ah, I see the point. Thank you!",r/machinelearning,Z0FBQUFBQm0yeGJUSVZpcjRtdHZ4RGxmSFd4NzFnQXNoc3dpSFlaekU0dy1vSzV0LWU0MEpoOXc1V3JuUVFYbTNUZlRCZEZsZ3hZU1pVaU0tWUU5Y1ROR3NVenRsS2EwcVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUbmR2REIzNUZhQjl3akRBZjhmbFBmVTlXVVRLaTFZV3lvNm9tdE55T3Zxay1XSU5mNVhWem5zRUp5SnNtWDYydnJpRXhtZThxUEdKM21zRVozS0lBVnc9PQ==
Ehhhh maybe but it still is quite bad. See https://x.com/__tinygrad__/status/1765085827946942923?s=46,r/machinelearning,Z0FBQUFBQm0yeGJURm5OTUNxY2JsUTIzMUhXdk9wQXNnaXMwQlo2UDMtaExYQy1WRWxrOEpnVGlXRVNwVVptbzIxazRnaUFPQVdETG1Vbm10Q0J0eEVyRVNQc0phZzJROU5IbjZyR1NTNjBrZkdMeWxLTmFlS3c9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUdkJRaVZKMWJhTkNSMlBySlJBMFNDdERoanlNUFN5Ul8wa2EzWnpLdTJ4X0JaRTlOZl9CMWl4WEJ1QzM3Tng5NTdLSHRTQ2JmajctNjNnUE5BRnIwRlE9PQ==
"Maybe the key thing to know about ML systems is that the most important element of them is the way in which they interface with the real world. How does information get into the system, and how does the output of it get used?

If you spent $400k to set up a bunch of arbitrary or task-specific stuff that has no reusable components and isn't part of any broader strategy then maybe that wasn't the best possible use of money. Or maybe you can consider it to be the cost of training personnel and developing institutional know-how.

However, if you spent $400k to set up a flexible and robust way of getting information about the world and then using conclusions drawn from that information in order to automatically make decisions, then that might have been a great investment. Sure, maybe it'll take over 10 years to make back that investment with things in their current form, but if you set up the system well then you can expand the scope of its use or iterate on its core functionality (e.g. do modeling iterations), and in doing so you can accelerate the money it saves (or even makes).

This is really the secret sauce behind companies that make stupid amounts of money with this stuff, like facebook or google. They've set things up so that they can repeatedly tweak their system and directly measure the impacts of those tweaks. People doing ML at big internet companies can look at a dashboard and see in stark terms exactly how much money every experiment they do might make or cost if it is deployed on a larger scale.",r/machinelearning,Z0FBQUFBQm0yeGJUWGZyUVJ2eUd3OUhWT052V1BYOGRLZGR3Sk40SEMwQ19XdmhxX01vY3BieDBCUHlXdDVfWWJRa0pOWllpUGFyZXNwd1N2bzFYbFFxTmd4LWpoMGpCdWc9PQ==
">Was this a miscalculation on our part?

Pretty much. Before you start any large project you need to sit down and do a cost-benefit analysis to figure out if it's worth it. Your decisions should be motivated by business needs, not by cool tech.",r/machinelearning,Z0FBQUFBQm0yeGJUMkRZbVdWVGFRLWQwRE1Ndl8xMnJpNkJKaFpNMzVDcEVQMUQ4TFl5REZoNWRYdW84RVZwbE12TnRPLVFhNVA3aXdKZDdQQTZ4eEhsdm5FdGJ5R2V1UjFBSDJYb1VxV053YVVCQnZaM3BYQVU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUNVhodnJ0V2ZFcE92QWxBSEE1dnhLaHV1RUVkWFlXbExoSFZQX1c4QTFuQVl0aHpaVXRTemtWYXNTTEVyOC00VjNxTFZiVGZPa19uVGh6bW1BdGlVN0E9PQ==
I am also interested in how to transition LLM application from prototyping into production,r/machinelearning,Z0FBQUFBQm0yeGJUaHJCRUdISjluQ0ZmTXdCb2toMTRQUEw4TkQtSlE1aWxZSUE4bUctSXJIX3UwT1ZSNFZ3YWtNVE9NdzdzN1ZhYl9DSEwwVUltTmd2aFpUVkJBMXVfRGc9PQ==
Check out our SWE-agent work: [https://github.com/princeton-nlp/swe-agent](https://github.com/princeton-nlp/swe-agent),r/machinelearning,Z0FBQUFBQm0yeGJUUzRYZDFVUXRDUHVMTTFHSU5ReVBrTEZqVkp5UGZsNVg1WEJQSmVxOGNTOUY3WTVfSV8zSmJHNG5ub29LZk1Wei12dFBaclVVakdobmVtN3p4SnYtYVE9PQ==
"I consult to a SaaS company whose core product depends heavily on ML. In that scenario, it’s much easier for the math to work out, because the cost of development is amortized over many customers, and savings are similarly multiplied across customers.

Making this work for internal projects is going to be much harder.",r/machinelearning,Z0FBQUFBQm0yeGJUcTB0Z1F5aHVZZWx4OXBKLVlMU0Q4TkdFM1VBM0VWcXVzbGI4cDgyaE03M3UwMk10NUVrSVEtRUVxWXBPNkhweWUxUnhQa01OVzVvRVpQOFI2cnk0RkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUT1BEc3VaVmdzeVVEZ196UURYVVB0Vm9FUUlfaGNoZk9YWmx2OXpab0kxcjV2MkJDX3Vhc3ZBMEI4LW9aNkF4N0tjMjJaeGhSQ1RCWTdrNEMzd1JOV2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUZi05WXlHa2RCb2swUDlKdHBEckxQd3czQlhzblB5Skd6d0NJd0dvdk1aSGdtM1BrTnctdWhoVjhuRk5vWnFEQlhqaFhTeFFIVXNGOFhETWpPcXVRemc9PQ==
"Hi could you share with us , what worked for you and didnt ?",r/machinelearning,Z0FBQUFBQm0yeGJUem5WOXJpQzFIS1o3dmdWTFNXWXAwYVVXMkYwNVZVdUNTb0JENkdzd05IRTlubUlSZXhTNGdtUFFQOHBiR21jQU9rZE9QNG92a3huM0ZxYmdXb0lmV1E9PQ==
Do you happen to have a link to your project? I'm curious how well the models perform.,r/machinelearning,Z0FBQUFBQm0yeGJUQXZSd3R1OUNYeFZxREl2WFlzcUdfeGZjQnFpUExyUUk2b05EU0RDTWpWek1wMHR2X3JHMVVkLVJrUG8tVENDYzNRM2VIWVlrZ2thbU1EbExzOVFsakE9PQ==
"W comment. 

Not dismissive, to the point & pointing OP as well as other beginners to the right direction where their questions have a better chance to be addressed properly.",r/machinelearning,Z0FBQUFBQm0yeGJUZWlFX3Exc1hsZ2o4S0NNQ056cGZydmtwcmRfdVU5NWtPRUplVVlXdHIxYW1MeUhWQUpmQU5DQU1sdGxMSzF2TlcwQUV3NmJvYl9YMnMySDl6RW1ybHc9PQ==
"It seems you have just consumed the red pill, man.

But you are absolutely spot on. As someone who has overseen multiple ML systems to design and deploy and we had our own ML based startup..  it is at this step the problem became evident.

Customers asked for ROI. And it turns out only 2/3 million dollars a year.  For those customers  less than 100 million dollars is a no go.",r/machinelearning,Z0FBQUFBQm0yeGJUazZETV9Sa2s3UjZTZnNtZ1U5MWZwdzVZVVJfVmxJbEFvV1VsbVltUmlOZEx3T185OXVCX2RuVS0xTHJCSjVPSmhGNGpXRDFzWU9xck05THY2LVFkTmMwSi1zU2dhZTg5V0hSbHEwT2RtR1k9
Is PR-AUC the same as Average Precision?,r/machinelearning,Z0FBQUFBQm0yeGJUbjBIcnBBeTlVdXdlV3lFVzBXS3RGMWFoYzhFSjJraGZvZVBXVElVZnlkRGExd1dYdGtmV1cxV1V4WUhZekdnUGE3Y3NPSU04VFBWcnY2ODBYLXlyTHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUbWZuUEJlRThNR2RfM0VPSE9PZ3hzRC1GQUhvem1lMWxTU1Z4LXdCM3ZKbURIR0tMQldqUzNCX203SnFKUHp3eHhrTnVxVHlxNUhGekhMeG9GVkZFQmc9PQ==
"For CV based ML projects, the ROI is usually not impressive at all. The only clients we get are those that have a lot of money to burn and want to get on the AI bandwagon.",r/machinelearning,Z0FBQUFBQm0yeGJUdmZ5ZHRHdDZYemFPbVRmLUl1bDdYN0p6R0NTRGxMejlkY01fcXlTdUxFZkZQYnBSNUNiNzFRdUNqOUU5WUtmendUUVdfUm9SSnJab2FTeXFWWng0UXc9PQ==
"3blue1brown says ""you retain 10% of what you watch"" ""20% of what you listen to"" ""70% of what you work with hands on"" and ""90% of what you teach""",r/machinelearning,Z0FBQUFBQm0yeGJUWmJsY3BsZ3JBdzRodHVKUTl0QVh1b2daN3RfanpXVVNxODZfMFJaS2V4a1Ixa0JUTWc1VjhrSXJQZzNlMlVicmU5T2FyODlrNmduZk1OSjhtOEp1NUE9PQ==
"Did you run it in a notebook / small app see if it's useful to your target users employees? How did they react? 

If you got positive feedback from end users during design thinking phase, should be fine. Anyway if you're just a guy who don't make important decisions no need for any concerns

From exp, hackathons doesn't showcase anything relevant to reality and has no effect if an app is goong to be effective, it's for marketing and sway potential clients",r/machinelearning,Z0FBQUFBQm0yeGJUejlTclVHNmlLc0hrdlhCYVZuSnpZb0tGX1Zra20tUUZOTFpERWp2amhsdHJyMk5tLUpwd2JPNU1YMUcwSWs1QUtFS0tzUU9keFFGdDJMZnA4eXFYaFE9PQ==
"That is not too bad in my experience. Sometimes you have to build things to find out how much they cost and how useful they are.

The key thing is what you could have predicted ahead of time, and being honest with yourself about your motivations (eg did you do it just to get it on your cv or because you genuinely thought it would be valuable).

I have seen many projects cost a lot of money and even generate negative value because the model predictions were being miss-sold and misinterpreted, so it was worse than having nothing.",r/machinelearning,Z0FBQUFBQm0yeGJUQ1BpdjlEZ2VTdmdqOVFsRTZuTExkdllDOTJtdlA1X1FwZkJtZVJPTF9OUTVMUW1lNUotX2NUT1pCRi1VeDdmeG9zUFBEaG5wWXpjQ012OUQxOFFwRHc9PQ==
"I'm just using longformer 4k for now, but definitely I will put an intern investigating about Unllama
Btw LegalBert with scaled 16k context was not working for me",r/machinelearning,Z0FBQUFBQm0yeGJUOThvczVINjNaN3RCQXYwY3ZVX2tCVEtyVGY3OEs3WE9tRkFrOHh6bzE3SHZ5ckVUemducEZuajJLazhxS0ZIUVdJWUx5Mzl0N1lrTHZxZWhSVklOcEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUcDA3MS1hN3ZmeGZLamVrVmxlUEtWd3lJdC1fUGhMU3g5RWxydHBDZUNRQm5ubVVGV0xGTG5ucGxaQW5PVVhNVThtZkM4bzlSODg5cU84VjI1R2pBUUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUaVFlckhLMzV3WC1XRVp5S0JTT1cwN2FpYlZ3MTdTd3c1ekdkZkFLTHdoVXRIYVoyZHhEM3pJbWM3ZWZwakFwVDl3YTBmeVVuRW9XeGp2NjQzb3pXNmc9PQ==
"How about balanced accuracy? Also, I always use AUC to understand if the model fits well on the data",r/machinelearning,Z0FBQUFBQm0yeGJUak43aWg0djNaTzNMUGdCVTNPZWxsVFd5bEZOVkhkYWpFNE1QRUVzZVVFWktCZnRMYzUwY3FBdXFxWGtHYXB5dTlTWFAzQThoS1dGWmUxVkNhY2liZnc9PQ==
"Well that's something higher than i can do. I'm doing sentimental analysis. And reading anything about it. And still I don't know much yet. 
But you can check MLmastery it's a good website",r/machinelearning,Z0FBQUFBQm0yeGJUc0otSG5tLU95bHZmaUFJVkkxczF4LVhPS1dQVFc5UVZmS3dsR0Z1YTRoZUxYeUdQc2hvSHBFazBSN0pLX2NDYjZ0Y3hqOENhMUM1d3NETzJialpISVE9PQ==
Anyone tried this? Does it have something on overleaf?,r/machinelearning,Z0FBQUFBQm0yeGJUSmtJdnhqdDlHZ3ZNS3ctS194ZnBBYVlGR2V4cDdhQV9fT09wMXhuNUs1OFdSU204dWlfVEFWLTI5UE9IeFB3MEhmaThtU250MUR4UXlSQ0hMWGM0bXc9PQ==
We are pretty new and the users are growing. You are welcome to try and give us feedback. We are actively developing.,r/machinelearning,Z0FBQUFBQm0yeGJUR2xpeDFuYUZHRVQ4ODVUNG1hQjdPck11UnY0czVRZ0Jsa1NDcTF2NUd3SmVwQjk2QTJtUkhRQkE0OVF4dkozN285VzdnVEdGZDI0ZUZTb2NJcEVrRFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUN1NGWEJpR2h5YnVJQWVub3ZUVzlDNjBGRlBiTTJjN1pKb1hTQ1NiSF9QVmU2TERUWF9sSWtaUkxPVWY2bmtfZmJDNHZSZF9qelgyN2x6bUtybS1SVEE9PQ==
"it depends. I've done large scale computer vision projects that had terrible ROI, and I've made a small model for deciding whether customers are trustworthy enough to be allowed to pay later that the customer said would increase their profit by 6 million per year, on a 25k project cost. one of the ways to mitigate risk is starting small, with a POC and MVP phase, so you can get an idea of what performance you can expect, and what the operational costs are. this helps a lot when trying to estimate your ROI.

ML/DS can be quite experimental, and the ROI depends on how the model performs, if it works at all. can I ask why the costs for implementation/operation are so high? are you running very large DL models on live inference? why did it take a large team to get one model into production? can you repurpose parts of the code/models for other projects? 

is this a product you could sell to other companies? one of my previous employers would regularly partner up with a company to build an ML solution, and then use the client's contacts to sell the same solution to other companies. the original project might not get the greatest returns, but if you can resell it to more customers your extra development costs are generally quite low, so it's way easier to turn a profit.",r/machinelearning,Z0FBQUFBQm0yeGJUVzVYYjkydV9vNUU0VFh6QnZSQS1lTTBNTFZlS2dLOUZic193U2pmd2pfUWZlRlFyMDgteFl4UTcwN0RLZ3NHbkdkNjI3dENONW5YSVJnTWt6Nkp4Rmc9PQ==
"If most of the money was expent in mlops than you did a good job. The most important thing for ML system is to have control over it, how is it doing over the metrics, is there any drift, how about time and resources, are you collecting more data to retrain the models. 

Without that any ML project is doomed to fail.",r/machinelearning,Z0FBQUFBQm0yeGJUTTJhTklKWkJUZWhSMmRGQXZ5OXBrU3N1cDBWdk53bHdlWlZEb0dTd0s1ZmNLWjBDXzRGZjB3dUxhcGpNaWxwNktIaG85OFFkWEp1WlNsS3F1aVJLRXc9PQ==
"My impression is that companies and stakeholders are keen, but there simply aren't many efforts that have gone past the POC stage into production where monitoring becomes a real concern.",r/machinelearning,Z0FBQUFBQm0yeGJUYXZhakdLSlF6b2ZvNmRHMDlzXzhJWXBaWWVSZ0RSb0FYMGNRdDVfZzZCRGVjeklBeWxUUjR3bmVGUU1yT1lfQ2Vfa1BPV3BnTFpRdUwtRUVsQTZLZ0E9PQ==
"Put more simply, consider the intangibles as well as those things you can quantify monetarily. ",r/machinelearning,Z0FBQUFBQm0yeGJUTWN0WmptMlRLV2M1VllNNzFHb2Y5OGxZZkliNmQyTnd2MGVRY202UUpGNENILVBLNG1ta2k1NXYtN2lMZ2hsMkY4NldsT0cyOVo1dHRUd3Etclpfd1E9PQ==
"By any practical means, yes. But AP is an approximation of the auprc",r/machinelearning,Z0FBQUFBQm0yeGJUckd3VXI2Wm1PUzRaVlJiT1pMY0swREFTazFYSlF0eG53VEZyWDRpUnFkdElHRHp0V1RGSmYxVXU0ai1pX29uMTVYbklFSE5icmJJbGxzcUNFM2NOQlpPNFZQM0NVYUROOXFVdVhYMFFrV3c9
"Out of interest what was the rough break down of the costs, data labelling, training costs, data storage, deploying, any others?",r/machinelearning,Z0FBQUFBQm0yeGJUMjZqWnFTOXFidzFaVVpuRmFuc3N0emhfTGRlSHdjYTVDeTl1c3RhSXBZLTMxMkFuUjhfTGNadkJ5eExGVFFaZ1VzWTJtY1Q1V3NWN3ctRUpCREtEemc9PQ==
"Thanks for sharing, will have a look.",r/machinelearning,Z0FBQUFBQm0yeGJUdVBpWlgxZEwyX1lyMWtiMlNrd1UtSE9qNWY3RHZYamF4Q2Y4eFZSTFdZc21kQ0JTak5Ld2tfS1NBaWZuVi1ubTVubDVTX0pxV3dLNWhDaVRiZWlDX0E9PQ==
yes,r/machinelearning,Z0FBQUFBQm0yeGJUSkozU0xsdy1ESDJvZEt6ZGRvVjM2bFdYY0ZBd0hORGtTb3o2NURLbDQwVC1IZmt1ZDZrYUtvVWUxenhWcUU3VmQ4YXN4MnozQlp0ekZON3RiUzZjUUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUVkhJblpDcHdDeHQ4aExYdjl4enBQbUlBNmhqelpYbEJSMmlTTk01YzhFRkJfQmxpREFzcFdpMDRYV1NNSTFFSFdJUERvR2FrLWpfUW9MQ2xIbW9CMmc9PQ==
"10x faster to train and inference on CPU, which is not what people are using to train and infer on LLMs.",r/machinelearning,Z0FBQUFBQm0yeGJUQmgzSTRWcndPR0UyUTZLeGhYQndsNFBtcHA0VUNBRy1Ya1JENWdIRENMUXpFWFFlMWxYblBjS0UtcGJOOVJYYkFZX3JwWXdBa0pSRmJQcFo3YVhSNlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUekRYZFMzMnpkS2lzaDJYY0habnZnQkJKakVZekFtM2Y1NE9iUTlLdVdOdE5KbW5TQjNzNG1qRk4yeXh2WlVVb2lzWm9VM0ppN0x0cVJuUzFiTmNWZFE9PQ==
You can think of SEFR as a linear classifier with a twist: it basically thresholding samples based on a similarity score in respect to cleverly averaged negative and positive samples seen during training. Amrite u/CriticalofReviewer2 ??,r/machinelearning,Z0FBQUFBQm0yeGJUOF8ta21aazBwR2thNi1TNXlrX28tR2hSSWRKWTJqS2JEVzczd3J3M1RwMU1WLTJCNTA2SW9adDVWX2hJeTVuOGlPLTd3VVNROVRHaHR4TWFOUmdlbXc9PQ==
Did you find any solution?,r/machinelearning,Z0FBQUFBQm0yeGJUQ1paaWZnbFl6T2c5T1JCRUtBN0ltam44UGQ0cE1kVHJGRXFCQzRBeWF1SFBrVnphZU9SYXh0SE45ekVjUi1md0l1ZVBKdW1hdzFHejZFZkE1VVhvQXc9PQ==
"Can someone explain to me how VAEs actually get trained? I am really stuck on this.



I understand the theoretical benefit of normalizing the latent space. But every explanation makes it seem like during training we draw from a random distribution. Wouldn't this just result in muddy model outputs that don't converge because we have random inputs.

  
Say we have 2x = y and are making a model. A normal AE would obviously see the correlation between y and x:

0 -> 0  
1 -> 2  
2 -> 4

But if we drop a random sampling in there during training, the data could be any random set from the distribution:

x = 0 -> random sample = 1 -> y = 0

x = 1 -> random sample = 0 -> y = 2

x = 2 -> random sample = 0 -> y = 4

And this would obviously not get a good answer if we trained on it.

  
The only thing I can think of is if VAEs are trained on the z-score instead of a random sample, it would maintain the normalization and the relative value of the inputs.",r/machinelearning,Z0FBQUFBQm0yeGJULWVITW9CNHJyRjktaUxVd3hFTE9EWjJSNDJaaU1jQXJJU3Mtd1VkaWtDX2ZrRnFOTzRSMERhN1ZTeWNDNkhHYmM0bWxMc2duVlh0UU14ZzI0bk5QbVE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJUOFdHN2RmWW9jcjhFS1BBSFhtMVVYR1JPa04zZHh2Q19vS0xXZ1NqVGhZa1p0MFNwWU90ckFJUWY1ZmRlQ3JIa2tvTjFGdHptME5vck5Dc1ZGSFJ1RXVfVDJmc0tUTWlDMkFTOVVxMF95R0k9
"You must be able to select problems and projects that you are confident that you can solve and finish. Does your group have expertise to do that?

Even with a group full of stats and math people with PhDs you frequently run out of understanding when the problems are too hard. 

For small groups who know what they can do  working in consulting is a gold mine. Big-money project is not usually the hardest project. Customers just want to have ""AI"".  About half of the customer projects can be solved with classical ML (decision trees, support vector machines, GLMs), selecting good feature sets and data massage.  As the money flows in, it's possible to works on some harder and interesting problems and build experience.",r/machinelearning,Z0FBQUFBQm0yeGJUUnozbUZrTG1wdjNCVUFxYXZfdnJZRHZydTBWSkpzQXNTMzgzLXdUZVZsS1Nnb2NaZzVZNXFXUXBqeWZsQUFrNVFvV3d0b1U4Y2V2Z1RKMnFvY3dYVmc9PQ==
Since an AI agent is not a legal entity common sense would dictate that the legal responsibility of anything an AI does falls under the legal entity responsible for of the AI agent. But I am not a lawyer so...,r/machinelearning,Z0FBQUFBQm0yeGJUNmxIWTBLblNJc1pqMDU5ZkNlamF0MXpLc2NiQkRfNFJnTll4dGdrQ2NjU3JneDhPaGpxNjU0MjZET1JudUljM09FTHZPRllnc3VaS1kxQmhCbHdoLXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUVGtEenVJR2NzelNnYTJaWVBpRTBSdDFKVlBlTFNDLXFHNERXMERZVmNmWm9jYlJxX3JUUmMwUmQtT185bm8ySVVncWx2REJjejI0NFFQUk9yYXdPN0E9PQ==
Yes related. Not really affiliated,r/machinelearning,Z0FBQUFBQm0yeGJUMU9YMGFLUGhsT2JuOUVUR045elM1a1Zvcy1UQmRBZk9aWEFPWmNsNDJEaE1oejdfRVR5YXdvOEdKakJwN3FhYWRtWG1wcVNTeEZUTjZIaFEyUlVfMVE9PQ==
"Everyone got their feet wet with a new technology that will almost certainly pay off sooner or later. I call it a win, not least for the resumes of all involved.. who naturally would need raises to keep them onboard with this valuable (if not demonstrated) new skill?",r/machinelearning,Z0FBQUFBQm0yeGJUcVJDbzRObEM1bEdFZFMweVpBQjlsUlctNURwbG1TWHU5VldMSHZuUTdtbS12UTR4ZjlDUFZZdGJpNnlzSE1DSzlxN2tTTGp3dW9POGgwLVp0bndVMHc9PQ==
"You said it yourself. How did your group let you spend that much for low ROI? Unless it makes your solution look better than a competitors and capture more market or something else you didn’t factor in, your solution is a tough value proposition.",r/machinelearning,Z0FBQUFBQm0yeGJUZzhlN2d0OXRLdTFua1cyVWFWUUJRcFpwc0ZLbHcxNnZqT3BNa1JCUnhvRXhId1E2czJzei0zRVVfMmJ6Wi1OY0RZTkw5UjhhNDBTS0J5OVF6RTg1R1E9PQ==
"Awesome Work, Can you describe a bit more on the Supervised Finetuning of LLM? did you randomly chunk and swap text with their corresponding audio tokens ?",r/machinelearning,Z0FBQUFBQm0yeGJUX25EdXRvVld4OHZUbmRMbS1qY1BMUm5JRkxYVV9TcDF5ZEF1X0V6cVZxX1pRbnhpanBvMGlYTGFxeEZVWmZKNTN6LU5TS09zYm16enprckdHbDBFc25hRGxEUVFZQm9BMUZHeGRPQmhzUkE9
"Typically not successful. But if you need to know you have to use the model outputs to calculate at ROI.

Combine your outputs with your FTE utilization and revenue impact.",r/machinelearning,Z0FBQUFBQm0yeGJUY2RtejVlTzVId25WLU1oOGU0eUdoRDlJbnFEUDJSWFVReXRwRGpERnFhQTliRUlMaFRBWmFyRnU1XzJaTXdEd0tleVQ5TzFwdC10RW95MnNUcHFVcmc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUa3lFY18wTGw0REFKNEFSMTB5Q0I0QVdSMUNaUGtvb3k3S0VZYUF4czh2bkV2eFFtVXplQ1R3YzRuTjA0akp4WndENmYtQ2hLR2RJcWFwcEFGSDR3eFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUUFFGMUFIblk4dHR2b21zUEtUT0Q1RTQ5RW90VmhzWHVHamZLSUszQWlTQ1p1WFBQWkxjTFlBdVN6aE15VWlvNF9oLUo3UEF6MnkzOThNSVVnWWRGX1E9PQ==
ok will look into it and let you know. But did all the same things that a guy was doing in a video and he got like 0.9 something and I got 2.07,r/machinelearning,Z0FBQUFBQm0yeGJUejktRXRMcWZmMXAxY3BLdlp4OEhEaWdFX0ctaFBJM3FYcWFBUVZGUVotNkVoby00NWQzN1BpUERMZ1VDNG9RZk9UN3JVWm1pNGxFNDJMdThmdXVhbHc9PQ==
You didn't do a basic CBA?,r/machinelearning,Z0FBQUFBQm0yeGJUdHpTWW82WXVCVU9faE16SFpGbHQxd2lCVzE1a0J6TGlaR05adFR5QmxUcUpXS3JuZDdRSG1RZDZYN1lmLThIWXoyZGtDMHA1VDJraU1WU2NYZEV5M2c9PQ==
you did both your bachelors and masters in cognitive science?,r/machinelearning,Z0FBQUFBQm0yeGJUSno4MXl2WFNwS3ZUdjhPS1BMTFJrZFdKX1d6cGhzYWQxME9Lc1Z6ZDlHZ2tIU2dGMmtrdWhrSXhEakVJVEM4anVRUVAyUEUyc0xsTkl0M3FQckNhY3c9PQ==
"Yeah, it's a great programme, and being an old person I was fairly sure it was the direction I wanted to head, and during the bachelor I became certain. My PhD application involves computational cognitive modeling, psychology, neuroimaging and (Neuro)biofeedback. Maybe it's my ADHD, or maybe just a general love for interdisciplinary research, but that's one of the things I like the most about cogsci...how baked into the process drawing from, and collaborating with all different fields is.",r/machinelearning,Z0FBQUFBQm0yeGJUQ3pXemZVdTBNRTJqU2NzNC1acFJjSEtkamhfUWpEdkxvRmNIMl95RXhlQjhkNGhudUJmaHhMOElJTVpzeXJYVzRXQ2NWN0tMSFI3SlVEWFZGWGpRZUE9PQ==
Someone should try this out and post results,r/machinelearning,Z0FBQUFBQm0yeGJUam9ISExsdjZpbjlBS1hKMDh1cUgwblRfM2hnZ0tNXzM0WllFU3dIM2R2RF9VTG9HTXpPT3Nqb0hRTVFLdjlUWGs0dnJoUWJCdXQwZS1lNTZJbm96Z080ZnYtM0F0d2V5STBnNWVoMlBibDQ9
"What happened? I feel like even without ML knowledge it can be straightforward to estimate budget and ROI of a project. Even if you have no such estimation, maybe look into other ways to cheaply/quickly test the hypothesis. Look into setting up AB tests.

Edit: I didn’t really answer your questions so here goes. I work mostly on recommendations, risk/fraud detection, credit sevices domains. All of my projects fail the first AB test. Literally nothing works as well as human or a good heuristic. It usually takes a few “rounds” to get it right depending on the specific thing. We always have to be mindful about cost (computing, storage etc) and efficiency. No project is greenlighted without a proper hypothesis validation first, and a solid budget/benefit/plan presented. For startups it’s obviously much easier but we don’t have to pay much anyway due to small data.",r/machinelearning,Z0FBQUFBQm0yeGJUNXdrUjR0Umx6X2kwVG5iZHZkTUxjYjdrSDg5UHp1Q0hrandvbzJ6OGxGYklnS3lpWTRUd2F2VndhcV81SzJRYU91RFBFcEF5aV9UYUZBOFBSRmRXc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUR205aS1kb1BMc3Jfc1Q2SHdDUmR1c3FhQXhOcWJkUHowakJPX3FMamFORzdTSE1wdXJBdzc4dmpkSGdtd0VGbm1tTi11MjF1azNUVUt6cHpiRVB4Tnc9PQ==
"Damn, $400k? I can implement the first version of ""any"" ML solution for $50k within a month or two. 

We built a giant chatbot doing several things in backend, prompt server, ml and a bunch of other things. 10-15 people are working on it and it probably cost us about $400k.",r/machinelearning,Z0FBQUFBQm0yeGJUM05nUnhMb2xQTzZuRWdpeFhnd1NPdG1qMFV3cDdFa2hsZFl2aEtRVHZGbklUNzFQamFJd0hmRFkwMGdXRnZzLS16bGdfcFoxNzByTXlHMU1lNlpXVFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUclVielNnSTJXMnBiQWZCS1JfVnoyRXctV3U1MW1XNk55eUFWdEJxTFJaalpUVHNyLU1LTHZ5Sk5pcUFTaXg1a1Z1V05vR0RYYVJxRWpYU0xIUlpSb3c9PQ==
"I have been using Fish Speech for some time. The only issues I found are the following:

- wrong pronunciation for characters with multiple pronunications (Chinese)

- hallucinations for single words

- Japanese pronunciation for Chinese words when there is no context

But in general it is really good, much better than other TTS.",r/machinelearning,Z0FBQUFBQm0yeGJUTlFPVmNCb3lWa0lQclYzTmtucWxvdEZjM1VKWkJnV3hqd3JhUVhTX1NQbU4wcU5rbThzYXJ0djEwNlE3ZTZxVHlaa1cyMGJyOF9kN1FKOHhYVFF5c1YxNWNveWdTNWVRWnBrS3lnUUU3OEU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUeEFwTzdWcjI2eXZHalMwUXFPWmxfSXhRV1VvNDNpdUJMaUdLRlJUQmI1R28xQWVzdTM2RngtZDVtZUJMaC0yMzY3cm9vTzktM0VwdVRfRDhaeFVlcGc9PQ==
Any news on the matter? Did someone manage to ahieve any significant milestones?,r/machinelearning,Z0FBQUFBQm0yeGJUa3dId1RfTEFQSkdNcnFtUXU3MXpKMEN1d1BoMEJNZl9pQW5XeDBDdVJJOXFHMjRWMkI2RkJXdTFmZ043Zm1oa1cwemgyTFNKSG5FTUk2c2QxcUJ0MEZBTnByRXhkUEdiN2pGeTRwYWF3bFk9
Used paddle paddle pretrained OCR for table layout extraction,r/machinelearning,Z0FBQUFBQm0yeGJUc3BfcWZxUDZMLUw4M0NZY083VDlFelhTbnBwX04yOTNOWnVUemh2c2JUQjNOdTBuQTdSdXJRTVM3ejM2R0hjYl9EX3NQeXpNZ2ttV0lsNW9US1J4LUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUUWZPdzdHblMtRXktRHFiMVNqY3M4VEM2ZjF0WmREaXIzX2huVEp0d1NLbkE0dmxiMkU5TXhqaEdZNnVGb09GSUtOYmN2dzZxbzFvQnZka1RIanUtcXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUaU9qNjJjSHdhQzdSS0JyNGhSZllGX3NScENMZ1hCNGdBZnBZSXZsQ3J2MDRNY1BKdXRkRGNieFFmenBtVjNrbEZLckVZY3puX0plekx2SDJ2VEtsaUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUakpuU01kckJMdmlBLUpNd0VfX2dLSXRpd3lGdDNuQ3l3elBjVWxWU3JIN1RwRjdnNzBJYmRYNGtfM0l2WXhrWFJzcUVZc0V5dXhaVE9wOTZ4cDAzSXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUb1R1c3RsbHNlNnl5MXVoTEhzbnBPSGhYbVRfVjJuMUVvLWkzZXJYemw2aW85X05ncnlZbkFMcC01UW82REU1VXh0R1BSaDRqOGFBb2dtUERYbDhTUHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUVjU3ZmRuUFRjelEwNERoX3VXNlBDMGR0TzNSTWhVS1Z4QWlJSEk3NTBPcXV4OGpvMEhxY3pQMko1VGNpS2FfQ1pjMHk3Tkl4cU8zWUJGS1U0bUlNQ3c9PQ==
It's now available on the home page [https://cloud.google.com/text-to-speech](https://cloud.google.com/text-to-speech),r/machinelearning,Z0FBQUFBQm0yeGJUTmVOaWxDdHRXOFQyTS1iblg1bXlDY3dIdjZsQnZFYlZCUEYtY0U3bXdNVm4ycmxScHlBRF9LcTc0a3pHWDRRLTR5NFAyVkhZSTRjR2I3ME9RaGZFM25HSTd4TklJejJCb0VJTU5UUl9lUWs9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJUdjJmY01adDc3SWFaZjlXRkRhRzRSc2RXYjFvUV9nUjVON2toUkJ5MjR4eERPT3VFOHFjbDRabDc1QUJvLUVoU3IzTDVvdFVlVlY5TXB2WWQtd0laMTNBcjdYRGc3OXZIUElSNXE0bWZSeFk9
Something like 80% of ML projects fail. Really helps to do a MVP and slowly building the project out. Going from 0-100 usually is a recipe for failure.,r/machinelearning,Z0FBQUFBQm0yeGJUdXVWS2tvUjBwS0xnTDVmQjh0a29Mby1zbkhFSlJ1N2V2MVhvY0xYbFlGVGNVSXNES1drYmtLOGFhZUQ1XzUwTkVjZ2VnbVpUeGNJcTJNWWRvZnFGNlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUeTRzcFEzc2hVcVRNa3pCNW05U2V3M09aVnVYeDZ0bDBZZGZQX0NkMkxPS3dwSGZnVnA3Qm1mUGYwVjVyemJsMWp2ZWlRS3pDN0hCdVVBS2V4RmdFYnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUTkZwNDJ4MWotdmJORkRjWnllQW1icXNzZ0hqODk4YjJMUVh0eWptRFJSX1BDdnhBRlZ6clJrczk1OTJxdlFtYXU0dkRZWEtPZmhFS1ZJWmNLMXdhTXc9PQ==
"Finally someone said it out. My client side DS Manager keeps on saying use Agents, even when we show him with numbers that Agents have high failure rate, and it this point it's better to limit the scope and use Custom solutions instead. 

This whole LLM Agent Hype has made it difficult to cross this space. Everyone expects 100% accuracy when it's not possible with the best of the models.",r/machinelearning,Z0FBQUFBQm0yeGJUQ212dml0di1FYjlIcnJqenVCQ184d2Y5dGpLbHFNSjZBYkM4dVpaQmtKX010V0w3QmFVckRfMWtIc2lBbUMzVmJzLWxmMTFORzBpNndHX21VMzdDWEE9PQ==
"Perhaps the main reason for the delay is the lack of thousands of correctly labeled images, due in part to non-electronic record-keeping?

Then there’s also the possibility that radiologists, in order to preserve their future job security (or to protect patient confidentiality?), won’t (or can’t?) make their labeled images available for data input to CNN models! 😊",r/machinelearning,Z0FBQUFBQm0yeGJUUEpTMjloYTdnYVdsS1pfbEpjMHdVbHNsclRGRV9iNzVHTjNFX29QQkhZQzRtUkRfZ21zcFZfdlNFYUNrU0owbl9FcFppejVYQVR1NkNWbzdxN3JMc0E9PQ==
"Out of curiosity, is this a pattern in most of the batches you review for conferences?",r/machinelearning,Z0FBQUFBQm0yeGJUTVJqTWdzQ0UxT1Vqd0VZVEpyZXdPYjliSDhBNmM5bjNscVQxVmpBUVp6R25fX3FtWUhJTmFWN1Y3TktuM3NmcFRQZFRmcXpsdVQ5dWNnTGVySUFlTnc9PQ==
"The point is to create a scenario where ""legal responsibility"" doesn't exist anywhere in the process. The legal system doesn't operate with the assumption that someone *must* be guilty of a crime. If someone dies that doesn't necessarily mean that someone *must* have murdered them and we just need to figure out who to pin that on. In this scenario API documentation would be generated without the person ever reading the legally-protected code themselves, so if it's the reading of the code that is the ""crime"" it's not being performed by any person that could be convicted of it.

It may be that you could argue that he's *causing* it to be read, and criminalize that act itself - analogous to how hiring a hitman is illegal too. But that would make existing legal reverse-engineering practices  illegal too, where one may hire a programmer to go and generate the API documentation for a *different* programmer to use in writing a clean-room implementation. I think that would cause more problems than it ""solves.""",r/machinelearning,Z0FBQUFBQm0yeGJUVm8wSHNBelRMQnI5VkFDUUdqWlJGTF9FdnpRQ1duYU5wMmpwWFI2TTJpTFNBRXZwMk1ETDZRYTJIUDFyUlVuUmlSZ3FMR2lLMGFTNWlPcENaVVp3ZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJULTMtZmg2WTdGT2RjaVVDUFo3TWVybWNQRERQTE9TaV9wTzZQc2ZVY3JJaVlJOFZfaFRUWm9iQmU4ZmVpNGFEVzhVMFI4Qm5mLWUyaS1FT1RuTmU4WkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUOFBDX0RmLWlLMDdfSzBDbUlaVWlaM3NUTWtPRExZN0NKMWM2RUxOUzNnbXE1YU1WTEdFcXQtRUFoUDJzTXc5dlh5eDg2bTYxNjZfLXlTQXVPOF9CZ1E9PQ==
"I would be happy to contribute, I hadn't heard of this package before",r/machinelearning,Z0FBQUFBQm0yeGJUZVNNdDBVWG41aUhDX3FHd0ZabXh5aGVjMTljR0hrZGduanc3NWhrTjg0UFdQeDUwejJJTVNrdWNqY2NKUEFMeFR0QV9ad2RzV2lTVnIxbGFEY2dsRmc9PQ==
"One thing to keep in mind: 

Businesses are valued on revenue multiples of earnings. Tech firms typically have 10x multiples and traditional business 2-4x. You can think about this like you think about net present value generally: what is the value today of a cash flow extending years in the future?

If you look at project costs compared to enterprise value, a project with an upfront investment of 400k that gains 50k a year is positive book value for a tech firm (10x of 50k is 500k) and not so bad for a traditional firm (~400k vs ~200k). 

THAT SAID, the earnings multiples are based on revenues, not costs. It makes a difference. So if it was gaining an additional 50k / year in new sales the above situation would make more sense than if it is just cost saving. 

this may be confusing to you but I don't have time to write a better comment haha sorry",r/machinelearning,Z0FBQUFBQm0yeGJUT19uOWE3NTQwYWx0MnpqeXFEcTZwMVF2Y2FYaHhBTjk0cHRvM2RvbmNXUm9KRTRtT1FSVmNvMm1FQ0hMZHUxR3hEUHl2RGhndGNIUjA3ZnlPaE84OGlLT2ZlNE0zdzhab0MtUG9rSVZLUzQ9
"I know an org who built a whole team of 10+ people around an idea someone had about a new ML product. 3 years of development later, it'll likely be scrapped with no return. The heuristic approach is almost as good and costs nothing. This is why market research and not ""I've got a hunch"" is essential.",r/machinelearning,Z0FBQUFBQm0yeGJUV2JIcWlsUGhJUmdHbktIR3dQc2xuNHBTalY4TVF2enEyNzlieFhMbzVjM2pZYkhCRGRLS0x3SDZ4UWVJdi1ZdG5MVm1nZE5vam40WEpEU1NNdEoxQ2c9PQ==
"Housing is subscription only for most, we already failed",r/machinelearning,Z0FBQUFBQm0yeGJUYVh0TlQzaHhTNHA2Qlg3NHo4Z0daM3hzQnN2TzE0MHNvUUJ1NFJyM0EtWFBVQTJxbFMwR3VMcVY2Z3E3X1cyXzlGUHNhbDVfMTY4dENTWVEtRl9BVUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJUbkJUczE1TjJValZzUFdTUGp1OUI5Tno0WHJFUXh5QW5NY3hid1pmNXVhcWFGY25seWFTUHpRTGlPRXFPRFhIUTNnMS1EMk9zSzNSMms4LUMxXzZJcUE9PQ==
"It's simple - the rest of the world outside our circle of engineers doesn't care about those people.  They don't understand the complexity of it all.  They do understand the CEO role - that's the guy / gal who runs the show and makes the big calls.

Most of my family isn't in engineering or in tech - my brother was convinced that he had met the inventor of MS Excel and invested in some start-up idea of his that was 100% bogus.  I looked into for him and the guy had some certificates from MS on his wall and was just going around telling people he invented Excel - and these rich people were just throwing money at him which he scammed them out of.  

We're in a sub-culture of a larger culture.   The larger culture won't understand unless say 50% of the US becomes a software engineer.",r/machinelearning,Z0FBQUFBQm0yeGJUY29SRE84cVItUkZTeFBJb19BY3p6SmdiTVJ1Q19XUTJVTW9PUUhydTZCMEZGVjBWakRPZTNLVG51N1VSaHNpeEdVYkxSaGhpbExrbHEtMkNsRmJLWWc9PQ==
Andrew ng is pretty bullish on this. Challenges remain tho,r/machinelearning,Z0FBQUFBQm0yeGJUVVN2QVZsUUdMelRvdC1hd0hISFFaNjZFVkpLTmVER1pXSVpHX0liUGR6M184TkJsd2RnTmNRLWxyR0FwWHRkNS1qUmY1ZnpNclVHSGNhYmgwWVJyWkE9PQ==
">Narrowly scoped applications that leverage AI as an augmentation tool rather than pursuing full autonomy

That's how I'm defining the agents I make. They work great and it seems OP is arguing over the definition of ""agent.""",r/machinelearning,Z0FBQUFBQm0yeGJUeHVQV0kyTXhoM1FhaFU5M3JCV1pQREhVU2hsLV9xN2daNi1xM2ZsWmg4REhGNTMzeGpudklTajVpemNHcThnNlp2QWh0UE83MU1nX2JlYlBUWHlsU2c9PQ==
"In my experience, a dedicated Linux partition with Ubuntu might be slightly better for machine learning development on your RTX 2060. While WSL has come a long way, a native Linux environment can offer better performance and compatibility with certain libraries and tools. The setup might take a bit longer, but the benefits for GPU utilization and workflow efficiency can be worthwhile, especially for serious ML projects. There are plenty of guides online to help you with the partitioning process. You can even consider a dual-boot setup to keep both Windows and Ubuntu for more flexibility. Good luck on your machine learning journey – it's a fascinating field with tons of opportunities in various industries, including [machine learning development services](https://www.clickittech.com/machine-learning-development-services/)!",r/machinelearning,Z0FBQUFBQm0yeGJUTGJ3aGdNdEtsYTVOZ3V5bGpuMGt0NkR2UUlISUlSV3JqRjRKS1NBak15R2tUWEpUd3Q3QWtJSWY5MzkwQ0hyNzhLWEgxeFkxOEpmUHJxU05PMEJZc0E9PQ==
"It's weird. I can't find the first notification date in 'Dates and Deadline'. But according to the 'Call for Papers', there would be a rebuttal period.",r/machinelearning,Z0FBQUFBQm0yeGJUNkJ4ekhabGhzOTNDTjl4eTdtWnM1cjNOY1E4SGEwd0otbUh6WWVhelgxeTVfV0MyVFpuVkJSenVMdHR1akRqQ1kxVDAzbWFpTFJTdV8xQktXczhQc1ZRaktlU0tKQ21Nb0FLVWdiVFg3TW89
"In my experience, a dedicated Linux partition with Ubuntu might be slightly better for machine learning development on your RTX 2060. While WSL has come a long way, a native Linux environment can offer better performance and compatibility with certain libraries and tools. The setup might take a bit longer, but the benefits for GPU utilization and workflow efficiency can be worthwhile, especially for serious ML projects. There are plenty of guides online to help you with the partitioning process. You can even consider a dual-boot setup to keep both Windows and Ubuntu for more flexibility. Good luck on your machine learning journey – it's a fascinating field with tons of opportunities in various industries, including [machine learning development services](https://www.clickittech.com/machine-learning-development-services/)!",r/machinelearning,Z0FBQUFBQm0yeGJUendBQXgtMTlBSU91Z2pITVJZOGpKdDVrQVVTRUV1UkZpTzF2VEozUURFaDNlVnBySjZSNm00aXVydGp3em9hM3hGT3FIVXhHQjV5RHpBLTFoYkVrenV4amhlZlM3X3RRMzJKNU1IeF8zYUk9
"I could solve this with Evolutionary algorithms as opposed to LLM's. No joke, you're barking up the wrong tree! Give me $250M and I'll solve it for the world. Someone else will figure it out eventually anyway.",r/machinelearning,Z0FBQUFBQm0yeGJVbXpvRzg2S3dEOXpWQ1ZhUV9mTUp5b0hDaUZDSUR1MHZqVVBidG9keVp2M3FpclRkMVdlaGRVWndSZGRBMVZlR3J2UTFvbFBoeExvYWo5NUFBRXo4eTZ3VEpVMXlLQ3p5OUU1bi1aTTlDNFk9
"I had a call yesterday with an engineer from a leading AI telephony provider. They candidly admitted that generative AIs are not reliable enough to serve as agents. These AIs cannot consistently handle outbound function calls, such as errors, validation issues, or confirmation numbers, with 100% reliability. The best reliability they can achieve is around 80% (probably being generous). The problem? They are generative—which means they will hallucinate. Despite this, companies continue to promote their AI solutions. And there are YouTubers making videos about how to handle incoming orders, etc. Yet, they are simply not ready for mission-critical work.",r/machinelearning,Z0FBQUFBQm0yeGJVa3JCU1B2WnR6RmhMd2hRLXNxZGxtclBOdVA1MW1XcGtQYjJuenFzMkJ2RTBjRmkxTlNpYjNoNXk4Qjlzb3M0MXgtTWFadnZ1M2pIM0ZndDZnMGE0MkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVTGZMLW1aNUtaMFJMMXhLdmVuaTlUOU9EWE5nUDVmeWhmdHF4VUhVVTBrR3NIUWt2ejc2MzBPdFAzbDcwLVRxSFpqdGo5azlMVXdrMi11aEJ0NXpLdWc9PQ==
Does the batch-norm in a casually masked transformer cause information to leak backwards? If you normalize the whole layer at once won't the early tokens be able to glean information from later tokens?,r/machinelearning,Z0FBQUFBQm0yeGJVemNhdVdpNFdZbExKUktORkh1NWJsai01U0kwNjJVM24zNS1aWUlfTXJCUE11ODB5Tk44N283Y0tCZ0lYVzZlX3BZNWw4bXFGMnp4VkRIY0RCdktHN3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVVGV2V3dtS0ExZnhMbXl6WUZpOHAyUGdWLWp3b1dTMHpGdEJNbTNMeTA4Y1RTeE1MVUI3LU8yNDVLR0F6SnJVRnlBMTZHMFRXenF4TTlWN19wTmZaTXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVSlFyQVNEZVFtQ1hXbUxMQS1PeEo0bUN6TU9qbjZMUkRtM0pwQVRDUVB0RmYtNUdtLVVzbFVPajlVbC1tWThWQUN4VVFjWUc2RWlDWFZXNmFteFZHcUE9PQ==
There is one more new French startup H Ai. They claim they are working on large action models https://techcrunch.com/2024/05/21/french-ai-startup-h-raises-220-million-seed-round/,r/machinelearning,Z0FBQUFBQm0yeGJVcEFrckcxaWJLT1BWUlV5ajUwTnFobkR3aWl4QU9LdzA1bG1SNHBrMXVWb2NtajdwZERTd1h1N1ZlX3I2TThyaHZDSGZEM2NpUC01ek4yclh5bUZYT2c9PQ==
where the hell did you answer on openreview for the checklist questions?,r/machinelearning,Z0FBQUFBQm0yeGJVcGxkTnJiZWdnQ185b05HVXlscWZZVWNyeVJoNlNKMGlWTmxHLWNPMnVwZG1la3VxVlRsV1NNRVBmQzFTSmFnWGFhWVRxSFd4ZEE3RGhDNlRvdVl2QlE9PQ==
"Agree, I need to clarify the distinction:

a)  A small, well-constrained AI step for a specific sub-task. For example, a single LLM function call combined with traditional engineering.  
b) A general-purpose agent that tries to handle multiple complex steps by itself, without any intervention.",r/machinelearning,Z0FBQUFBQm0yeGJVX2lmWTM1bUMtM2JlMVR6WURqaEhfTU1wb1VpM3ZZTGhqdjJpSmc3OGhEdzFsQlIzdm9qNDc1QkQ3ZHRIa3BLTHBKcGJMMV9WREhtQXd1VkFuSFdhajdmemc1SHluYkRzQXYwWEx1Q0RGdms9
"Can confirm. Had projects with heavy imbalance and I've used PRAUC as primary metric, works great",r/machinelearning,Z0FBQUFBQm0yeGJVX0Y4Sk9WUWdIcUpScGwxU0F0SUVFX0ZqRG1UVGtDRENCN2FhcVdRb08yYTE0ZzhXeW9Qc1JNUjY2N0VEOXlRUTk3MlhQOHBLV0RMX19kaUd4T1lQRUE9PQ==
"I wonder how much compute power it would have costed to develop this LLaMA 3 models with

A pre-trained and fine-tuned text models with two sizes: 8 billion and 70 billion parameters pre-trained on 15 trillion tokens.",r/machinelearning,Z0FBQUFBQm0yeGJVLXZ2MThwaTF5RVNfOWRLa2dDeHMzSkxsNU5RSkdQTlhxNW8wdklaUWh1bkVxSzYycTZmVjdvdWFMbnU2ZWJDTU1CMVFfZDFCdkhVUVhaWUFkUWVVS0E9PQ==
"Agree with your points although I do feel this is a short term problem based on how fast models improve (probably will be robust enough in a few months).

I started a niched down version (similar to 1) where you can automate web research. You give an agent a website and a few questions and it runs the report and even send s you an email based on a criteria if you want. Check it out => [https://www.snoophawk.com/](https://www.snoophawk.com/)

I guess the end goal would be to expand this to full flows where the agent can take actions on your behalf but like you said currently a bit risky and complex so am waiting for the tech to get better.",r/machinelearning,Z0FBQUFBQm0yeGJVV3JHcjExM1ROYkxpckM0SnVRNW1OWmJuUnFqU3lpajFtZkZXQU9ZZndfZE1aOHQ2bVlBdTJndmtfS010S0ZfcHM3YjFvRkg0WHdpbGxmeGpveTZaZXc9PQ==
"Again, you're missing the mark, at least as I know it.

I define an agent as: A multi-step automation that makes one or more LLM calls, using those LLM results in the agent's own workflow.",r/machinelearning,Z0FBQUFBQm0yeGJVUmNHNWhmX1hXSXRuZlpPUW5qOUpRS0FGZGY4OHdwcHRHNVp4LXBtUWw2V0d6a3Zka1hiNjI2SDBSYWk5b3UtRXVrVUd1cmNXMFBuODZyN1pNLURHbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVZGdxSXNwRjVKTG5DNEZGdzRCTlJranFIalBoZFhGQVNjLXd0NWw2ZWJxTzV6TzIwMlhpYTFVZUJRdThrOFVZdkxkNVp5dno1ZzdONUk0ZXNRaFFIZlE9PQ==
"I guess the term isn't really defined but your definition is the simplest. This roundup uses a higher level definition, and neglects a ton of developer tools that do this or solve various problems like autogen, swe-agent, memgpt, open interpreter, crewai, metagpt, etc..",r/machinelearning,Z0FBQUFBQm0yeGJVcTBUaUUyU0o0MVlEUEZCcXZXdXNRVXZoOTRNOVJUZ1VMZHlBSnVsYzJualdMRTlKOWdvMVlKOGxUR00tMXhFM05Ibm14OXVCcjVOVW9Bd0VTdUttUXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcWtzX01WSkRDLUE0aTV3TmxYejZ3UVFIN1dsVUdQZXc5UWtpc1M4QmxCX2Z4NVZjdUtWdEhWcTdiS2pDLU9VQ3luWng2YXJrSzdlSWg3RWZVdTdOcVE9PQ==
Do a kaggle,r/machinelearning,Z0FBQUFBQm0yeGJVYUlZZEd4cWY2YVJ2cmJwOVVQSnEwaVRYYkxPLU5MVDZxUmc4cVFxUFdGbVUzQkVyR2s1alVlMVBKR1VkOHZnZjZKSDBMNU12bmhSMmVobWU3dlFWc1E9PQ==
"At least you can be confident that costs per year will go down as hardware improves and the world continues ramping chip production. Also, you have more in-house expertise now that wasn't there before. But yeah, you can probably see how hiring a consultant expert can be worth it, even if it's only at the start of the project to avoid some mistakes early",r/machinelearning,Z0FBQUFBQm0yeGJVOWYyeGNVdV9EN2RaY1Rxc25icjdnMFFubVZIVDR4N01wRGVTbjd5a2pUZHFiamUyTmNpTFhHM2dBWFpiVjk4bUlraU1rRXJxanV0bUpjMjJBR2hndmc9PQ==
"The big irony of the current environment towards incorporating AI is that the entities with the most to gain aren't huge companies, but rather individuals and small companies. If you can afford actual talent to do a job for you, ""off-shoring"" to a literally mindless, barely capable worker is likely to do more harm than good. But if you can't afford to hire a support team and that's why you didn't have one before, now you can at least fake it and capture new value from low hanging fruit much more easily.

This is part of why open models are so important. Giving these tools to people is how we level the playing field for independent workers and small companies who are getting steamrolled by massive corporations that can leverage economies of scale.",r/machinelearning,Z0FBQUFBQm0yeGJVWVY4WGMzSVIwbzlOb1BMNVpNSWhveGlUM1pZN0tRM3Nzbm1SWnktRWwzTzJ6MFlMV21GMFdnekJrMmJQOVpQRUdOaHREVFlzWkVHZWxhemY0aFhfQnc9PQ==
"they're probably great for routing though. both classifying/triaging incoming calls/issues, as well as fleshing out the classification ontology (which is a huge pain in the ass to do by hand and very difficult to do well)",r/machinelearning,Z0FBQUFBQm0yeGJVamlpcjFhMmFoUW9yU2lGQVo2bHAwLTVMRVU4d3ZIRVNnSTlwM3RMVGlhZnBYWDVqck9EN1lLdnZMYnhOTlVram5yYUhMekxUU0RhUTlYenJ3N1VNUFE9PQ==
"thank you for this post. I have to reread everything and go through the links after work. 

Most of my knowledge is on Agent Based Modelling and even that is outdated by several years. But I remember even then that the idea of agents was great but actually using them was seriously hard to execute. And even doing so required a lot of expertise and plenty of compute (unless you're working with the simplest things). I still remember when EA's last SimCity game trying and failing hard at using even a gimped version of agent based modeling. 

So it was really surprising hearing about all this hype about agents and LLMs. Thought there must've been several jumps in technology that had to have happened.",r/machinelearning,Z0FBQUFBQm0yeGJVLUhFTWd4NFl5TnAwNEpIaWY0Vkc5RGhsMEl2T01HRHZNWGdUNWZwU3ZUQWxKdnljUG5ZRzdyZ2VXT1lJdDlfUUdqWS12MmpFQWxTN2xTOVc1bGR5LXc9PQ==
I can think of a few business cases where 80% is good enough. And a lot of the limitations of those models can also be worked around (e.g. citing sources) with RAG or implementing an escalation system.,r/machinelearning,Z0FBQUFBQm0yeGJVYzgzcHktNzZKOXliZEtvWjh6Q0RIOGdKTDVBb2RZR3BDLV9xaFYzSEZzSzFiT0k1Z2Vqb21XLVBPdnZYaU9pOEswSlNhWGs2YW5FQU1CTF95RDZSeFE9PQ==
"This is not a trad AI definition of an agent. Agent is an self reliant entity that makes high level decisions about how to perform tasks in a (possibly unknown) environment to maximize a function value.


Given that the function might be under specified (e. g. user satisfaction), you'd need to clearly define what the environment is. LLMs can be seen as agents in the sense that they take decisions of which tool to use to perform a task. Are they good at it? No. But it is what an agent should be expected to do. ",r/machinelearning,Z0FBQUFBQm0yeGJVYVJUWmtxaWtrWGFXdkUxWlBnNnlDaWhXSENtTm5pZUhhclpWbmVndDRMWVh6VWRTc3lvTWhVeTZHYWE5cmtzZk5LQnA4Mm1kbS1yQ21ZcWoyVjhnZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVV0ktNFpWNXhCX2FhbUpCVXgtOUd4RjM2VzY0aGVTX3BvUFhKbFJKdEZVbUV2c1NTWXlnMEtSUjZhWWhOVXp2cEFfS2x5a3JLT0hOWWg1QWw2UEdPMXc9PQ==
"...although if the company is big enough, then internal projects can more easily justify their cost.",r/machinelearning,Z0FBQUFBQm0yeGJVMWxzZ1FUWjhSLXoydzI2eUJ6ZWR6OXYxWkJ2NnZEd0VYbExuWlVTWUFZN1h4NTl3WHowUUpKSDl1SDlFZld4N2NqYWRoUGsxeEhoZGRkbk9WQkR0aVE9PQ==
"Hey, I’ve got a project where I experimented heavily with AI agents, i discovered many of the points you laid out here as well. Many of my teammates kept pushing me (note they had no real experience in ML) to switch to a multi agent frame work, thinking it would work much better. 

If you’re interested I could relay my experience with multi agents here. I can see some people arguing around what the line is between a true multi agent system. I think it’s an interesting talking point. 

Personally I found that in most situations (maybe all but who knows) a “monolithic” agent is better than a multi agent setup. Many small fast agents is not = one large. Emergent behaviors imbue large agents with capabilities that make them far more efficient (on highly complex tasks) over smaller ones. This is especially noticeable on very complex problems",r/machinelearning,Z0FBQUFBQm0yeGJVbmM2OHJqS0ppT2dmMkZpOGcwUEN4bUt6anljVnFSNVR5QlhrOU4xdS11MjFOVzBzbEIwTlZ5eWRmV0IyOFNMZlRwM1BBVUhkMmZ6Vk95SFB1UzZsZHoxVC1feTN1YzBFcjNuUjN5ckk3ZnM9
">makes high level decisions about how to perform tasks in a (possibly unknown) environment to maximize a function value.

This is pretty much the definition of a reinforcement learning setup, so it's no surprise that LLMs (trained almost entirely with supervised learning) are bad at it.",r/machinelearning,Z0FBQUFBQm0yeGJVcGlFUDdBeUk4dDkzbUxoUGFsbG00aGZ6eTgwTjZpRFAzSTE3bFJkOUQ0NkVaR1JkaWJ1MVBJM2Itb2VuaEpZc1lCTUluNTFkWXB2dV9keTd0dDh0d3pnbXg4NlVBLWxKaHBKSnBLR2k0VWM9
What does the architecture look like?,r/machinelearning,Z0FBQUFBQm0yeGJVTTNQc1BWb2FkaC1QNVZaNDItNnM4eTk5dFlnSndxbzg3bUZTM2VDWTdRX0xveTdFUE13TEFTNWRfclk4N19qdHJXZkp4ZXVVMG1oTzR1cnc0RDlhQ1E9PQ==
"There are plenty of applications where an 80% success rate is fine and comparable with, or better than, low-cost employee performance. In those environments, one way or another, there are checks in place to handle the exceptions.

In fact, speaking of ""mission critical"", consider radiology screening. It's often a life or death situation, but AI has demonstrated better than human results in some cases, and there's human review to help catch errors.

Treating it as a binary issue - AI is or isn't good enough to implement agents - doesn't help to understand what's actually happening.",r/machinelearning,Z0FBQUFBQm0yeGJVZDM0Unp2Wm9Eektfb2hTSWpOLXlBbEZpa3pLUkc2dVZYX2JDM2NQclVhcEFOOUdfS0tzQW5Nb2RhLVQ3RVVlYktITDE2Y0VoQXZIMUsxYjJ2bVduZnc9PQ==
So many bad ideas could be shut down before the prototype phase if more people understood that LLMs are for information synthesis not retrieval.,r/machinelearning,Z0FBQUFBQm0yeGJVcXpOWXhzWHI2T1RQaEZ2cFpxbjlOU3h2UWtudlNtVGVXdmh6M1lpWnYzMW9EVGNlSDRLdElVVlJxc0pNTzJnekpadmN5TnVYNnNNdEV6NEc5YVVvdWc9PQ==
"I'm sorry for reviving this very old thread, but I just did a model no the cifar-10 dataset. the dataset was very understandable, but I am not even able to understand what the cifar-100 dataset is about. could anyone please help me out? like, I don't know what the classes and superclasses are and how the dataset is even formatted. I'm new to this, so I'm really sorry if this is dumb. Please help me out.",r/machinelearning,Z0FBQUFBQm0yeGJVTmllVFpWZXVlT1VadzM0TmdQZUNBMkFkV3pTYnJ5MXJsUTUwYUtJMjB6MGF0TlVKaE04RUlnTFBKOERKZWhaa08wdkp2Yklkb29jbnFVYUV2NHViZDhvYWg1S01IQXpXQ0s0VXFzWTNiaHc9
As in?,r/machinelearning,Z0FBQUFBQm0yeGJVNDg0ZmVrMWZXLUNoek1sd1dzTE11cjZOM3BuUm5RWlZ4RVdCVlJRcVVvWHVrdGpMRnlmWnd2bGtTVjRSY3prTVZJcUlTVk12cVpSZmpxXzRwZTZhckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVUDQtRHFRVFoxTlFscnlNeGYzUE5fY2ZOZGVfYU1uUHl5M29XTGh1SDdxa2JSOXZielIwYnQ4ZUpGaG51RGczSWgzU3oxOU1mdUFJcGdGalo5djBoUXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVRWFzbjFsdGw4Q1dDRjZ5M2hVSEVnejd1azhVejctUkFxOGZjMDdYNUs5NmN5WmZDY2RiNTJaQUgzOFM5blB4WEMwUUd5WS04LURsMGVkemRyLWpCWFE9PQ==
"Its a combo of taking a screenshot of the website and sending it off to gpt-o to answer questions. Then a bunch of other software to let a user schedule all this, get pinged etc.",r/machinelearning,Z0FBQUFBQm0yeGJVa2Z3OU1lNm55YlE1NWZ6U1VZTEJPejZmTHI0dDNGZEZpZnJtWFgxeEExY1lVekNfYmVTODdsTDhnbVRHMElTV2NpOHU5bTd5WEcwdXpjZUhSbHI2anc9PQ==
"More: Serious discussion about interesting research fields, like learned optimizers or casual ML.

Less: OpenAI discussion, LLM hype/cynicism. (especially the cynicism - there's not much hype around here)",r/machinelearning,Z0FBQUFBQm0yeGJVWUpCYTN6STUyaHpGMXJTZ1doMkx4VFd4b09jN2NYdTREZ1h6M1VHTUxwMTdacWlTM2ozQk9zYndzQ2dfZUs2UHVTb05RLTRSUVFCdWtlcW8wd3Y1dGlsU3BVMDcxTUI3R01ia2gwNllUcVU9
"Can we change the paper title (as one reviewer requested for it) for the camera ready version? If yes, what should we do?",r/machinelearning,Z0FBQUFBQm0yeGJVcEtLOTRyTEZxRjFDYUVwSl93dlk3aVdBYU56ZHFkbWdHVnNhc3hXbXl5QWVQZ0oxX3Y3MVRGY0MyQWxUWWc5NUIxWk1fNjhBdHBKdUJQQmJjeDFoWGc9PQ==
Me too,r/machinelearning,Z0FBQUFBQm0yeGJVWDM5LVJ5SXpwTUIwMVNuSHVkY1FMX0lDLWViVDZxSWROUnlwcTZiZC1HV1ZkT0tkMWgtazN2X2tIYWlSMmJYdzI0N2daZ3QycXg4a1NvWnFGUWMwZks4ZDVDS212NXhXb1o2cWZVRGdOQlU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVSzZWMDA5eUFLcUVTeW1NUUJFSE5jTnNjdkhSbXVHdklsa0ptZkdPSjhRSmE0bkRCOXV2QmpJaTNjaER4NGlDY0VFa2h2MWVISENNY21aVmM1cWZycVE9PQ==
"Hi, I'm currently building a personal web app that would have different AI Tools ready to use (AI Post title generator, AI Writer, rewriter, image generation etc.)

Since I'm pretty much new to the machine learning world, is there a website with already available and hosted models that could be embedded on a website, using <iframe> or something like that?

Hugging Face Spaces is neat place but sometimes their community apps are offline, also no option for simple customization",r/machinelearning,Z0FBQUFBQm0yeGJVT1ZfZmxJeFJsRnNlRFBZWDdUN3VhMjRBR1RxS1pLS2VfNkxOSnNhWE5wZEQwY3pIaUh6NnZ3alh0WUJPQzVDWnZkN241NVlnR1Y5ZGJweGJmd3N6Z0E9PQ==
"> Gaining user trust for sensitive tasks involving payments or personal information will be hard (paying bills, shopping, etc.).

With the way the current technology works, convincing users to trust an AI means lying and tricking them, since we know in reality AIs can't be trusted. So, it's not that it will be ""hard"", rather it will be immoral, and hopefully illegal.",r/machinelearning,Z0FBQUFBQm0yeGJVQTdpQVdFWTJFQWdJV1BVREkzNDF0S2doSG9MRzhhTWFsWmtmSDhwVng4WFMzdm9veVJ5dk91NEVVM3BoSVQ3dTdWRHJMZkNyRXRrdDVFOUt6ajRfUWc9PQ==
"I believe this wouldn't work, because depending on the noise the image might indeed be a little closer to some digits than the others. If you assign equal probability to all digits for all noisy images, that would (ironically) introduce a lot of noise. Maybe I am wrong, but I don't think this would help model with positive examples at all (examples where there is indeed a digit in the image).",r/machinelearning,Z0FBQUFBQm0yeGJVaDY4eTFTeWxKOXRSb0lWN2tQblF6QkRXc3lQdFVUU0NvcTgtOEg4SkQ4ZkEtWmNwX1h1THlOME40eXNPOHFjSUh5SVhvWF84ZkJIVmpVWEt2amZzY1E9PQ==
"Six sigma is just about the biggest lie that was ever told.

From years of experience in the trenches of a top 10-20 US Hospital.

Doesn’t matter what would be useful, though. You won’t change the culture. It sniffs its own farts.",r/machinelearning,Z0FBQUFBQm0yeGJVZ2RRMjYxZnlwTi13ZlBpYjAxUzh3OTJjeVlHLUV1RUoyRkN4MHVpVmVQRmtxaXl1Um1CYjBLN2lTUENWS3pPTnRJa3J0MTNOZ25UcVM1SFFhTHd1Q3VkV1RZdTFtQ0t5S050Z0pVSlQ5dms9
"You've summarized the current state well. I expect GPT5/Claude4 to be a serious step up but still not quite delivering on the dream. All the data we generate from these narrowly scoped AI automation tools will help train GPT6, which not only will be able to book your vacation but should also be your tour guide.",r/machinelearning,Z0FBQUFBQm0yeGJVUkV6VnliSDNFM0ZjMHZNUTdyUXlEeGdXenNuSFlDaUh5eE5XcXJuUVV1Y2JLcXNQcHRiOEQtZURzNUVyRTFpYkhmOHhJUmU5LUV0S21RelBOV3FFVUE9PQ==
"Yes, the noise and the associated labels you introduce would need to depend on careful consideration of the data distribution.  Perhaps a more appropriate technique example would be convex combinations of images from different classes where the label vector is the class weights in the combination. This would at least give you some intution for how close the ambiguous data is to a real image.

Though I am reminded of the fact that the Fourier spectrum of gaussian noise is uniform, whereas the spectrum of true samples almost certainly follows some meaningful distribution.

A final thought would be to add a label for ""I'm uncertain"" to the model's outputs, and rather than forcing the model to choose a high entropy prediction from the true label dimensions, the ambiguous data would be assigned this label.",r/machinelearning,Z0FBQUFBQm0yeGJVZGJRTnZRY1RTZmNCWlhBYXU2ZHRLMDNCYlRUR1ZQV3lKM2V5Y21WdGJQdmNuVkNrZ0VhVUZ0cjlVOGpoZXlEd2t2bWl2bjVheTdjSHB4ZlJwSTZxQlE9PQ==
"More Graph Neural Networks, debates grounded in math, learning theory …
Less buzzwords and people with weak theoretical backgrounds reinventing stuff that didn’t work before, but this time with cherry picked results.",r/machinelearning,Z0FBQUFBQm0yeGJVMXhOcWlUUG9OaVAyOWhpVGczc2xScllxRUw2WmxCb1BSZlExajlZLVBIV1hiQ1FzZXY4SWtWZXZuYTNMT3pnbUdTVEpjb1VZUUtsN0laUXJfaU5ubnc9PQ==
"Hi, it's nice to see someone else training a diffusion model from scratch.

Can I ask what your motivations / goals are for the project? Most folks who want to generate specific content with an image diffusion model would just fine-tune Stable Diffusion or train a LoRA.",r/machinelearning,Z0FBQUFBQm0yeGJVdjNtRE5RSWpFZ2ZUZ2JOZ213a1BTWmZWVlpBZXVxNG93U05iUHdZS0VHcEwxVW5Ya1Q2d285STF4b05Eam05ZHBFbFNPNE9MeUp0b3NEaThOTDlDMGc9PQ==
Is there an AI model to help me turn a normal video into a looping video? Like doing interpolation and deciding where to cut the video so it loops nicely?,r/machinelearning,Z0FBQUFBQm0yeGJVMXhxTzlZNExIRno5bGZZQWJrMjdsRWRXak83MWJ3VTVRRHdXVUIwOWpHdzhEZE5qb01vOVVwb25ab0MyaFNJOV9MS0FOZ1JpTG5mdmVGWm1KZTNhN0E9PQ==
heres a writeup on how we do video embedding as a managed service: https://learn.mixpeek.com/vuse-v1-release/,r/machinelearning,Z0FBQUFBQm0yeGJVN2dvRVFlRG85bzhhTXVvbjNVV2NXSjVlR3ZZSURrRHoxaDVUZXZGZklTRGlCeGY0eVhxU2N0UVdUVTd4ckZWeEFabkdEQTM4ejJRaW9neGltZ3pUcmc9PQ==
"This actually is a good point. Probably a few years at least until a drug with this structure is approved. 

There are ML approaches that are being used right now in rare disease diagnosis though",r/machinelearning,Z0FBQUFBQm0yeGJVWllFdDJwN1BsU3BIRHFpZHV2WVRIY2VhVV8tLVhHS1JSelR1WWxkZkM0TVdPMDlja2NValduLWZnV18ydkVhWHFVQVZfblBvYk5hRGJ4eUJGN0hJVUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVYjFCV05IQXQ3bjJjcDZ4U2dRWlZpRG1LUHg1bGxUVm52RjFYLUhNYzhPamNfakJZZF9QMHItOVAwVlRQWS1TWms1VTYxUE5IRDhkQ3dVdXVob2lubXc9PQ==
"Thanks for posting this. It happens to be what I do for my 9-5, and it's always cool to see what happens in the background to enable modern financial applications.",r/machinelearning,Z0FBQUFBQm0yeGJVN1psT05rTlVTRlJscUxBRG1tQlJHemNVeV9oZi1RM3E1SXk4dDRmRExaX3pycXE3dnREQkxvd19ReWxHMW5lZnlGVUlLN2swYUJJSHR5SGZ2Y25Ua3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVTXl4dkhIV041VHJFbVRNeGh5Rk9IYzFIZlhVOTQ4ZHFyQThxaEptZmUzVm5ZZGN4S1lhNnlnSUhzXzgzeFI1UlE4R3ZCbjV4T08yQkZ5cjdJenFpb1E9PQ==
We can add some single words courps to fix that lol,r/machinelearning,Z0FBQUFBQm0yeGJVZlVGc1Z0UVFYQjE2dlI2N0s0MXV6bUE3Tmo1M2dZeXpPOUlNM19xRzdrZXNuLWhBZVE2MzBVY3RHRVZUWGlnT25ZemZJYXUxUFRvakNSeE1XUDZ0R0E9PQ==
"Yes, we random concat the text+tokens chunks so the model see more samples..",r/machinelearning,Z0FBQUFBQm0yeGJVTlBlcmNrNEh4TkVNR0tDTWFjdjQwVGR0emtLNUV2bFFYM1Jrand2QVZTWUo0UGZIYkpfbTdjRDNGOHpnUkpwWm9Lbm9fNEFJX3RwcWh4eERiYWltOUE9PQ==
Question answering in medical domain***,r/machinelearning,Z0FBQUFBQm0yeGJVMFo5MW5ucjBoeWZkLUJ3cTExOGg2bGVwTmx4SVlFdmwzdlBXb1lSak9JcHFDa0l1NGJWbF9hWjZCVFZVTXVzaGNOa3Q4WnE4Y05yb2JKQUpBR2d4eWpBMGR3Wk5pMHBpcmloS3pxZVExTlU9
Amazing job.,r/machinelearning,Z0FBQUFBQm0yeGJVd09Oc013STJwRnhhQXVXU1FIa0IxbXg4aWFlSHQ5OHZ3Q1UxRy03ckFicUZVdFRGcEFSdDBMYjZJdC04bW5odm9wNDJSZlJkd1VFb2l3WEpsV042V0E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVYVNzT2JuWW9HaDREWG5VUkxQRlh0U3R3cWd0TGRHWTNyeDFfeV9SRUtudkt2MjdyMktPeDg2YUlTNUpkVUJJUmtFQVptRlZlZ25NdU5rM0pZY0FjbHc9PQ==
"You mean like… Anything in tech, right?

This industry lives from broken promises",r/machinelearning,Z0FBQUFBQm0yeGJVZnQ0Q0dWb0VieUY1NzVXWGxuMzNFXzRiZDRvVkt3X0twMGdvck9Wd0ttUHZQeHJTMDRaTjR4TkVmbm5BaXZUSEtmU3VWdGc1bTdxdnM3WU8xb0RXWGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVOThjb3ZQamwxVWpHbXd2TklmOWJqMnR4NFNEWFVXNG1oYUpzVnpHZXlLNUFIU2JlbXg0NjdscXR2aVdOeEEwOGw4RzhOR3p2TEQ3QnctZkxIX3NtRHc9PQ==
Do you mean random erase and/or cutmix with label smoothing?,r/machinelearning,Z0FBQUFBQm0yeGJVamQ5SGNYWXpIQl8yTDM0Y0NqMTVFOVNvRDBvY1NMV2xlZ1RhbVNwc0E2RnJTbVF4dkg1S2pCQzZmR0VEU25ZdmpYSUdtY3ZUTnM1XzhIbTV0ZWY5RXBrYkNXNHpqZmNkeERiZVdYclE5V009
Thank you! I googled and cutmix and mixup are similar concepts to what I'm suggesting.,r/machinelearning,Z0FBQUFBQm0yeGJVaF8zY210dmNlS1E1VXhEOHlUbEpLTjlKVnJURGY5R215OTFrYzd1SUhMb29mM0tiR2ZMVkMyMUxXckNxVkpDeXJmUFRwekJneFZjbmQ2bTZVQk9FakE9PQ==
A little less about LLMs unless it's something truly novel or worth discussing.,r/machinelearning,Z0FBQUFBQm0yeGJVb08wMkJjbWpjN3R4Slc5NzFUV0JWVTQ2bVpaaVAxMnFnRXFJRE44aTVwWElDREhNQ09RV3IyMlRZZ1N0ZWhpMnpDd1d4OTE2Zm5VYzFMTmNLNFJaVTNPc2dUeTIteWlsM1VybHRQNjF4Ujg9
"I'm curious about the recommendation network. Usually do companies first train the models, and then use them in the online setting to generate results, or do they also do online training? By online training, I mean when people are generating data, will these data be used to improve/retrain the model at the same time?",r/machinelearning,Z0FBQUFBQm0yeGJVMk5uTTB3RHFGTk03NHE5UUNrb2FaRllHSG52NFNnclR6bWdBUU91eWZ6Rk1BWURBaVF0VHJtal9rWXVzV04tclJpVUhFXzJFWDJ4MFZrbTBPeVlXcHc9PQ==
"I'd add the RabbitOS to this list. Their large action model design follows a pretty similar agent-based concept. I know the R1 is pretty much already a gimmicky also-ran, but the LAM concept is still pretty solid, though judging by the whopping ""4"" apps they supported at launch (and you can make arguments about the uber and doordash apps actually being functional), they are having massive growing pains too.",r/machinelearning,Z0FBQUFBQm0yeGJVSHQ1Q1IzTDZYTzFWRkZ2YU5rZzRBM0FjWXJMTF9NMG5aa3E0SXIwUEl2Vy1meFZTT0owU08xaGJJVFVRVWJIWTMwWnhmQVM4OUVKWnZBQ0Q0Uk5JeFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVMHNmc2JkQTFGSVdVXzgxVnN1TnFVRmFpWnhjSkViN2s3QVg2S0hfeUM2UmJ5UC1tUW9qUVctTEtfMThwM21sQlVsbmFkWWV2aGVqRUJVT0FjOWtlbXc9PQ==
"You could start by looking at the proceedings of the FAccT conference (https://facctconference.org/). If you are also interested in bias in ML, I recommend you to look at the Gender Shades Paper http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf",r/machinelearning,Z0FBQUFBQm0yeGJVWmNvZGJuY3pmTzZJMnc4YzVjTUVqTHZycmtlcmVFY0M3NVVhWndGZUExWTQwWmR1eUtpcjQ5X1NRMV9PMXdpVWtuaHRGOFQwVHZvdTZOVDdNcjJJME9HWllnVHNIN0RXLVVNQlEyb29lMEE9
Part of the problem is how badly AIs can go off the rails. 80% success rate says nothing about the quality of that 80% or the severity of the 20% errors.,r/machinelearning,Z0FBQUFBQm0yeGJVQmRXQjBqZHdlOWpuWk1lLV9HN1BLYm95d2dQb2VKaEo4a3B1ZEJLMkRoRW5ZR0x3amFSbVk5M3VZZTNlTGRrM2tNcTBqYko1MHNRUW5aN2F2SllSenc9PQ==
"More about general issues in machine learning, especially discussions if evaluation metrics and baselines in papers (and lately especially in corporate communications) are meaningful.

Less .. uhm .. not sure, I guess that's what voting is and for me it works. Maybe less advertisements for frameworks that add yet another layer on top existing frameworks. But no strong feelings here",r/machinelearning,Z0FBQUFBQm0yeGJVNjdtTEYtT3ZoNDFoYWNjeDAtT1VSdF9ycXZfeVpUd1kwU21DTWhiY3dReVE4WUNvU0RMaGc0SVFydkhKUUtxcUQ1bW81b3FXQXZaNkYySE1vOHZtZGc9PQ==
"Radiology screening uses LLMs?  I think AI is an overloaded term and confuses things, so it is almost lazy to use that phrase.. yet here we are.",r/machinelearning,Z0FBQUFBQm0yeGJVbkM5M3ZfWnlxM2N0Y1VET0llTlM2cVd4NjZDc0IxemtWb2x0clhYYkc3TWtOeVZmOUIzRXZuZ0VRRzIwZW1mc0F5SEQwc1NzSHBsZE9PMlB2Z1pFenc9PQ==
"I've done a lot of experimentation myself, and what you're describing is pretty much in line with my experience. Can you share a bit more about your learnings from comparing multi-agent vs monolithic agent setups?",r/machinelearning,Z0FBQUFBQm0yeGJVQlB0aldBby1yRVYtMDF0dERlVmhncXlrRGdCQlA1cEdpWUhpZkxQM3BvRTBURVlrXzhYdmZSdElhUHUtcnpmVGpjNF9qaVNGaWR5LTZQaVNsMWt1X0hRSkNOSTRTTFo4R1IwOE9KNEZ4Vzg9
"More of: people asking stupid questions.

Less of: original paper ideas, things not related to neural networks, anything not llm, papers not named along the lines of ""A massive p\\*nis is all you need""",r/machinelearning,Z0FBQUFBQm0yeGJVYWtPcV9zbUpBcWFDNm8xMnAtY0ZDQUZWaFNDNFVxTkZ4R3pNWHpuTEFTeDlaejM0aDRGa29vWGhmTEcyTDRaaHNkY1cyZ3N1UHQ2c0hSZkRkeWdCS1E9PQ==
"> Large players are also bringing AI capabilities to desktops and browsers, and it looks like we'll get native AI integrations on a system level:

There are very strong hints (including from Tim Cook himself) that you can add Apple to that list next month.",r/machinelearning,Z0FBQUFBQm0yeGJVRmo3TmdfOHNmci1ZODBJT2tVQklCYzFWalpZbFNMVmQzakVfWDcxX2ZXMEZPMTk4NHRrWWk0aFBCUWRWUW1ucTYtQ0NsbExwWWhCNDI0V2FWX2UzQzhTd0otLXNSeWZSY0o2aWpPYWpmVlk9
LLMs aren’t stochastic parrots. Plus LLMS aren’t good at chess. They aren’t good at reasoning. ,r/machinelearning,Z0FBQUFBQm0yeGJVeFNydU9qRGtwNVJiVlh6WVozcnE5OWVMZHRQcjRFazFEMGtrUnNBNTU3d2x1VG15RXlKQUlYekxOWEcyTlZuOF9JdmNheUNhSndZa2dpb2dNS0c1R3BiVXh1Z24tU2hKRVR6dkN6ZjV4QjA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVb3BNbEZZTjYzOEhxNDBzUHppXzFmNy1lOFlndF9vMVBrY3NaTFBnZzZlR2hHNGZPUGU3RVRlbDZTdlgzUTNXTnd5aXBPZnE1cC15dl9ucmxwWHR5MUE9PQ==
Mods removing the posts that break the rules.,r/machinelearning,Z0FBQUFBQm0yeGJVWVUxTlhCZjE3VGdkN2luTThTWGpKNUVOX253d0g0Y1NZYU9uamJpd1lSTGlzYUc4M2VwcWRKdVRYbWFrZFlLRFZ6bDZ0SHNRNEtYMkJDcldFSU9YSEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVTXFuUUk5TlVDM1VLM2JjRGRnc0pwNUcyRks5NEpOV1NjZHFvdHA5N1lpTDRsVUotbS1WaXpZdHZLN09QWXFWQjUxbnREbHlxNWY3cDNGcDhDYXBPcVE9PQ==
DATLINUX,r/machinelearning,Z0FBQUFBQm0yeGJVeTFSMnMydlc5ZURrREdKSHBudG5jdl9ETnZZQ0F0ank2ZHVWNV93eWhrMGQwTFl0ZWMtWUFKMzJMZ1cyNnl6MlNoblc2aGpNZDNwcUJrdXBSczZVMEE9PQ==
"More mechanistic interpretability.

I’ve chosen my niche

ETA: And I don’t really care about training speedups. I’m sure they’re important, I’m just not curious about them. (That’s more of a preference of mine than a preference for this sub though)",r/machinelearning,Z0FBQUFBQm0yeGJVYU1DaGgwcGt0ZWJXTmVERC1xVjhrbG95dUdybGNTdVlpMjlBcVAzMmd5QmhPdy1zYkhlV3FCb2VWN0lfZUhBNVlhOHgzMWMyaVY1RkhUZmVzWkFYN2c9PQ==
"We're discussing AI agents in an ML subreddit. The OP is pretty focused on LLMs, but that's part of the mistake being made there.",r/machinelearning,Z0FBQUFBQm0yeGJVaHp3YnhOazR1QTBGZ2dGTU1CTUN1VkpLdEJod3hpcFhWMlBCYWVTaUVyRnU5ZzBScGx1NWRtU1lzVzhwOS13emdiTmIxM0dZUGFsOU8yVFlIcmpxN2c9PQ==
"Does anyone know where can i find a dataset for sleep-wake classification (sleep stage classification)? I need it for my college project but I've had no luck so far. (the furthest I've gotten to finding anything relevant was [sleepdata.org](http://sleepdata.org) but I can only request the data, I can't download it directly)",r/machinelearning,Z0FBQUFBQm0yeGJVUGF4c1JYSFVfVDFETGUySXJpVTltbGp0QmZlWHRLRzVoZFZhYldPNFZUSml6MDR6RVlid2lGNUdEZ193VmtQZXJ1Wkxiclh2S2UzdjJlRldOSUVaMGc9PQ==
"If you consider ""NLP"" as a method, and think that industry is ""shifting"" towards transformers in 2024, this is a huge red flag. Also, you don't get noticed by employers as a fresh PhD, you just apply to regular job offers.",r/machinelearning,Z0FBQUFBQm0yeGJVQ0hzQ0VLUi1NeGZqMmhiaXRIN20yeDJTNm0xaTJVNXJWTzktOWY1QTFrWmhsYXdzdmNYeHU5d1Vvd0Z6Zm1KVFBOT0V1cUpqckQzbTFQc3cwQlFkMEE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVTkRLRHJaem5SaUNkaWxlcVZrMzlSd3BDSUJnWHJOMThNV3lkWV9wT2M4WjM2aUF2U3BVRE5keFBIWVBqQkQwaW4xMWJVWWV2djZtMHh4MlI0T0toR1ZodTExQTVzQlZCU3F5bXdud0YtdEU9
This industry will see more growing pains than any other.,r/machinelearning,Z0FBQUFBQm0yeGJVWncxQlNrd0ZqaW5GZEkzQjc3MDJjRFRmUkhLWUdWaThSZldOc2hWRk1vTUhjZ3h2VUVyUnl3MTZFZmtoUjFsVENJa3piQ1p5WEwtenVXZkFXdTRnOFE9PQ==
yes but multimodal retrieval is on the horizon.,r/machinelearning,Z0FBQUFBQm0yeGJVN19YZXJxSWNNcnZybG01dl8waE52U1dRUC1tWU8yZE1FNUJGVHdVNDQtRjkzUER4STBSb1B1cjVHdmRYa3VJd3VVUVZUbHlqX29fQXpJZHN5MGYtSGc9PQ==
what does production mean please?,r/machinelearning,Z0FBQUFBQm0yeGJVYnh4bTR0WU9fZ0V5R2QydkFtSlRSSklFQ3poYUgxS0tFMFVGUXR3OFVzdlItMU9ITUU5UFd1RzNwTVVtSlo3MjdwRjJzUllZa0RLcXJMWUliNW5IT2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVQ3NGLXR1amxxTjJqWGIxc08xWU1CbllyaERLMG1zMWRweVRqYm5Qc2tEbmtYZ1NVcFVGV3NUdEQwMy1QbmMxcmdqODFCWWdNdGJJU1VWZjZtX2RnUmc9PQ==
We already have systems that are unbeatable at chess but they aren’t LLMs.,r/machinelearning,Z0FBQUFBQm0yeGJVbWtUdXpibm8zNWt4MmZhMmNBUDJuZG9OY0J5Yl9pSlBVNmNQMW52T01sdlFqdXpsTS1JSTVpbi1VbU5OVFZ2MHpteG1pRmJ2QVB4aF9Xd0hCelhDMXk5a0R1TjV5dUY5a1NfcmZ1RC1sVk09
"I wouldn't call ML-based radiology screening an ""agent"". The classification algorithm that provides info on the scan isn't going ahead and ordering the patient's chemo regimen.",r/machinelearning,Z0FBQUFBQm0yeGJVWTdGTnRYRERyZmRFeEJ0Y3RMMHhwdWJKd0hJTVJOUTFJTy12QVY3bGp4NGVDNlVhSVJfOWRQdDB0SXU1QmFEODdRUHMwUzZjN2FWRnNNazMySUFBdXFRTzBONXlrd2VrT25EOHFPRGxOdW89
What do you consider the trend to be like then?,r/machinelearning,Z0FBQUFBQm0yeGJVQ1ZIa0RsNUlyZXh6SG9tb19YTTM0QTFIRjF1cVk5SnYtRjJqc0JXTTVFc3FGWFZqYWxjV2FsUlRwTV9PanBQc3ZrM05taS1idHpxSFBvNHRFdm9uSUE9PQ==
"Creating an accurate digital twin of Earth would require immense data and computational power, especially for weather patterns, topography, and human activity. You'd need to combine satellite data, IoT sensor networks, and machine learning algorithms to process and analyze this data in real-time.

Instead of going broke using traditional cloud providers to power this project, one might want to seek out cheaper alternatives like [CudoCompute.com](https://www.cudocompute.com/?utm_source=reddit&utm_medium=organic&utm_campaign=community-engagement&utm_term=/r/machinelearning). We offer sustainable and cost-effective compute resources, which can be super handy for a massive project like this. Plus, it's a great platform for AI and machine learning workloads. 🌍",r/machinelearning,Z0FBQUFBQm0yeGJVTHZyUkEyWEtfZGI4MW1kN1pubHZsZXVjbkJ5cGdlOVBFM3RweFY3R1pVQnBKS0djSkVMRmpDMldfTXpUUFdCWU1WR3pJd2lKRjRPZlctbXBuSWpJbUE9PQ==
"Learning theory didn't work for deep neural networks, there's a reason the theory has dropped off a cliff",r/machinelearning,Z0FBQUFBQm0yeGJVNS1fbHJmWjk3VGctNGdNbTJZcEpDRmlEc0VwNDkyWi10ZmNvMG80bWpEdktIaFRBcjdNMWdjUXhYRDcxRjBWdmw0SGhyWkZieURtUDgxR2dRbV9zdHc9PQ==
"If you’re looking for the best value GPU for AI models, consider renting rather than buying outright. This can save you tons upfront and offers flexibility to scale up or down as needed. Check out [CudoCompute.com](https://www.cudocompute.com/?utm_source=reddit&utm_medium=organic&utm_campaign=community-engagement&utm_term=/r/machinelearning) - we’ve got a marketplace for sustainable, cost-effective GPU resources that’s way cheaper than AWS or Google Cloud. Good luck with your project!",r/machinelearning,Z0FBQUFBQm0yeGJVNGtPdkI4NzFSWUpYNnFRZUpEMWZmSkh4Q3V2cFVWSjNuTDgzT3U0TjVWRE43cm9RR3d6bUlGRFFhRmEwZkMySDU0alJVNFp4bV9YUVNvcHBRS2lyWGc9PQ==
"This is not a trend, this is a de-facto standard, and has been for years. I have not seen anything not transformer-based for over 5 years in the industry (apart from language identification). And NLP is a whole field, or specialization, not a method.",r/machinelearning,Z0FBQUFBQm0yeGJVXzZmNTVzM1hGOGFvWWRPaDVpRGx2Y1M1czhDMDJSMXR5ZF9EYXZvVTdWT1BLMko5bTFlTFhuSEdhOU45eDVZOTVHUklxbUszeWlZWnVKTElNZk81a1E9PQ==
+1 on GNNs,r/machinelearning,Z0FBQUFBQm0yeGJVRGRmZ3JRSy1TQXo5dVlDbnJ3d3BzSjRtejdNcm1udUMtR3JoQjJMS2FfZHU2SndWeWxvcXNiZk9sMU9NWmNrMmpBTzE1amhnRHdJREJOSVlvUzhkR2c9PQ==
They raised 220 million?! I hope have something better than GPT4,r/machinelearning,Z0FBQUFBQm0yeGJVdlBONmVhb0FkS3otczk3ekVQNXZEQWRteXlOM0VybS03VEZaRDlUTTJJTkZoZ0RvblRLV1dLTENUSkNGTXpNY29JdTRHM3NwcU1ZQ0R1MjNlQnR1eGlwSXprc0w0M01vRDBRMnNSR2dHNXc9
"Your one example doesn't generalize. A potential agent in this space could be part of a fully automated screening process, with the agent scheduling a review by, or an appointment with, a doctor when an issue is detected.

But the broader point is that there are many scenarios in which a high degree of perfection is not the standard, and which already have procedures in place to handle failures. 

This means that the argument that AIs, generative or otherwise, ""are not reliable enough to serve as agents,"" is highly context-dependent at best.",r/machinelearning,Z0FBQUFBQm0yeGJVR2J1SERnZV9aS005TF9rYVpSNXhBcV9udHRyUDZLZFBrNnhtVERTajFGekk1bjZCRDFLcVdzbF9LR0xkV0dpX3pGMUlJSWJUcUYzdGRxTFVsdTZ4NHc9PQ==
"That's why people study and compare performance. Humans can go off the rails badly as well, which is why, as I mentioned, in environment where that's an issue there are already checks in place to handle exceptions.

For the example I mentioned, multiple studies have found variations of the results found by [this one](https://www.nature.com/articles/d41591-023-00071-1): ""AI–assisted mammography screening had accuracy comparable to that of standard double reading — and substantially reduced radiologists’ workloads.""",r/machinelearning,Z0FBQUFBQm0yeGJVM21kMElVYUVvYV9NRWZOQUttUm80d1IyaDd2TDQwd2N2dGNuMEFOdzFKTHlCQ0lWbXVLRXQ1U1JDd1l3UnRBaE41RGJabXJSdEpOTFlMNWtqWS1zWkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVMGtMaVJMWG91WjlJQWlCX1BZdWw0LUNua2ZmRWd4bVhDT3RaWDNKZFdUYzJLNXJUY2JaakJkb0M1dTVEWEQ5VXVSRjIwV3EzMlNUYldXYm1LNDN6ZFE9PQ==
"Open source, hobby, or startup projects?",r/machinelearning,Z0FBQUFBQm0yeGJVYTN1NzVYeHkydzdaOGszMXJNVjdUR2R1Ykp5OVlSZk82dWxydHZ4bVRrSEk3ZGRhTGs2SGVuT045NTRwNVZDLVJPZC1iaFFVdGw3enVQMlZmZnkxQ0E9PQ==
"A little more than a year ago, I started Kyroagent, a platform for bringing AI agents to small businesses. I quickly realized that working with agents presents some challenges.

Firstly, users have high expectations and often misconceptions about what AI can do. They think it’s like magic, but current LLMs and agents need much guidance to produce good results.

Secondly, the UX needs some changes. Making AI easy to use and understand is tough, especially for small business owners who might not be tech-savvy.

Lastly, OpenAI keeps expanding the scope of what its models can do with every release and is getting close to its first agents. This makes it hard to keep up and find a niche where smaller platforms can compete.

I still use AI agents for specific tasks and focused projects, but offering them as a broad service feels too early. The future of AI agents will be more about integrating agents into existing tools rather than being standalone services.",r/machinelearning,Z0FBQUFBQm0yeGJVZDY2d2kzVXNFUW12cEtOWDlHSUswbS1CTktLUktVU0xMMEl5MFEyemNlemRNSGZwaUQyV1JOZTdVRXoxeWRZVFUzUl9oOXZZdGFGOExTTnloWnV0dUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVWklNaEVqWnIzdXNRYkU3U2FQcnVVSGFPYVJxZ1N1T2EyQngxd0ZvM3pveDFhVHBQSjNYSWhiZGNuUnF1NnY3WUpDMElmTFV5UjFnNEQ2cWxDMnNVb1E9PQ==
"> Instead of trying to have one large general purpose agent 

Who is advocating this? A big part of the point of most agents is that they're more focused than that.",r/machinelearning,Z0FBQUFBQm0yeGJVZTBDMnZLSlZOTGtWR1BHcnhnVjFaLVE4YXp3OGgya2VYMXlmQXk0VWFNcFEzSnl1UkVIaURTS3hXbGNkcW5kX2d2OVJKS2NfdXd2ODVsMHVtRy1OSGc9PQ==
Open source and hobby and kaggle.com etc ,r/machinelearning,Z0FBQUFBQm0yeGJVZXRBSXoyMm9VaE5CZGNvaElINDZfaFNsUlAtcHZObXhRRTlHaDJrcnhJLXFsU3pGb0NHR2RfNmxzVjUxUEJIR3RONkhwMVR4a1hyRXRaWDJoZVR5blpiY1QyNWxOLUloSTdFYUpwYldNTnc9
This is an earlier one I read that I've referenced countless times: [https://journals.sagepub.com/doi/full/10.1177/0049124118782533](https://journals.sagepub.com/doi/full/10.1177/0049124118782533),r/machinelearning,Z0FBQUFBQm0yeGJVQWYzY294aVNTNEpqNUdPT0kzYk50NUc1eHpKZVVIdkgzMkdKX2hSQWZMN2d0d3pWYkd4ZTRZRTBHcEVnYVJfNHBMOUpCTFMyNHc5OTZRMnhxR3pxZXc9PQ==
"Hey, the app seems to be down, can you get it working again?",r/machinelearning,Z0FBQUFBQm0yeGJVSTUwanRNTXNqVFk4N2o1WUpua1ZkLTdjR2VvdVRtZVk3TUhVcl9Wcm1QUWVQaEtUUFhfWVFtcHJrYUF0Mkk4c3FmTDZ3a0p1RWRXMm01dUJmQUNkTGc9PQ==
"It's interesting because the discussion here is very similar to the issues I had with my own team. A lot of the controversy seems to be in defining what an LLM agent even is. Of course, this is different from the traditional AI/ML agent definition. In this setting, we're talking more about what I usually call ""agentic"" LLMs, that is, LLMs that are given agency somehow. Usually, this is done through something like function calling in an RAG setting.

I think what most people are trying to define and understand here is multiple agentic LLMs acting together to accomplish some common goal.

For example, let's say you are creating an LLM to diagnose cancer. It might initially seem as though breaking the diagnostic process into steps is advantageous. Maybe you have one agent looking through a certain set of knowledge bases and one looking through another, then they come together at the end with their findings.

I've found there seems to be more of an advantage in understanding the full context of a problem. The smaller agent is simply more likely to make a less useful or more error-prone prediction because it has less context of the overall problem.

The main argument I see that is pro multi-agent systems is that because of context length, having multiple agents ""focus in"" on specific steps in the diagnostic process, you can somehow take better advantage of the attention mechanism, and somehow the agent's output will be better attended to, or simply superior in some way. 

My experience has shown something different. And as I said before, I think if you can, the IDEAL is always going to be a larger parameter LLM, with a larger, more powerful attention mechanism. (Secretly, I believe continuing to scale up LLMs will actually be advantageous to an extent, and the reason we're seeing diminishing returns has more to do with how we benchmark LLMs, rather than the systems peaking in what they can do. But I have 0 evidence to support that.)

Still, there are definitely some reasons to have a multi-agent LLM system. I think defining what agents should even be in such a system is useful.

Essentially, you can say you need separate agents in a system when your two ""agents"" have entirely different functionalities.

For instance, you have one LLM diagnosing cancer and another LLM verifying questions being input into the system. 

The security LLM does not rely on context from the cancer LLM, and the cancer LLM does not rely on context from the security LLM. 

The tasks can be usefully separated into two agents, without impeding the overall goal. If an LLM COULD have more context that helps it solve its problem, then it ALWAYS should get it. If we have more information about cancer or the patient, we should give it to the diagnosis LLM. If that information in no way contributes to its overall goal, then it should not get it. Getting unverified malicious user input to the cancer diagnosis LLM contributes nothing to helping the LLM diagnose cancer. Likewise, getting information about cancer does nothing to help verify the user's input. 

We always want the highest amount of high-quality information that directly pertains to the problem that needs to be solved. Simply put, getting less information is never better in any situation. Unless that information contributes nothing or impedes the overall goal, then of course, we want to exclude it, or maybe send it to another agent.

A model with an infinite window size and perfect attention can make the best decisions. This sounds quite obvious, but this is a core reason as to why ""monolithic"" models like GPT-4 with 128k context size outperform multi-agent systems.

Multi-agent systems will always be less effective than monolithic LLMs on a given problem.

Obviously, in the real world, this is not always practical, and therefore you are sometimes forced to use multi-agent systems, but I think it's important to realize ""monolithic"" LLMs are the ideal. It's what you should work towards.",r/machinelearning,Z0FBQUFBQm0yeGJVUHpEOG5CcTA4YUU5UmgyVktLaWFHVExoeDFaYVYyeTR2Z01yUUx3TERiLW85MXA2WFBKYnNncnFYU3JzWTN2SHhlenZXTmFnYWZ5QWtaeW1qS1haWkM2azhDa3h1TjlJZVdzNXNEU3hnSjg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVdVRkaDJJZVVpWF9KSzEyM3Z5MndZcWl5UWNudndlWkRoUmNQNWZnSkUteHY3ejcxZjQxbGd1WXpxa0JycDFnUWdDTzdUYlJfRTNOS1hjR29PZkoxMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVdTE1ZThJOXVjUVJLMl9tcDJ2MHp6NXc1OXNIS1VLMlFwb01vZmJXTzhnS0lfRUpOMEVNbDRIcnBLeWdNVFhIY010Z2VMYVVhZXUxV2xqc1JsU05WOGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVOGRPWlhubFhkZ080bm51SldrX3ctWGtRa3JYRi1Vb0dnMHFZOVpPSnU0cU9UbUJ1NlJSU0RjdVd4SkFuaXlGN0RPU2dXSmlYV09uSnJmWHFWWWdrYWc9PQ==
almost as if it's something that requires further research,r/machinelearning,Z0FBQUFBQm0yeGJVSGN6dXd0MWRXdlp6V0NYdUxIbEV1TWJFTWVHdnNibEoyaU9CUmdCZmhiYTBySWJvdUZ1OVhlc0NleUpTWEFjc0N0Yk1CTFp0ajdyZkNpMWZfMzlYS1kwcl94czVabVZiM3U2MjA1WDFXZzQ9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVNGpHdjQwM3doblBacFNIRGRzQjJuejdiQk9OdUdzc19xbnoxcWFmSzlqb29kUnRGbUktaG80ZnNneVJWd3ZDc2hCU2RkRFBEWEtHdGhrVWdac1ItSFE9PQ==
"i can't wait to see more papers named with the ""x is all you need"" format, or some variation of, it's so original and funny every time you see it",r/machinelearning,Z0FBQUFBQm0yeGJVTjFwTE0wX1NOdEVNY1FuME9XSkdzdV9xalVwSThocWVFUFVrSDVoSHJpNmY1Z09wUmpJT1MycmJKMzl0R1liUDg4SG9QRDg4QVI4NWVYVDVybkN5VG1CbEU1dnN1RU5kSnVhVlVxaWpBYW89
I replied to the original comment with my experience,r/machinelearning,Z0FBQUFBQm0yeGJVRklRRDFwNEFiaVhjZW9oZkdmSU1tN2FxMmZPMl9qLVhwU0tsU1FXOS1HWWs4U3kxNDNxbExaWlBtdlowajZLU0dYV3FhQkpvTllOWUhmVDdUX0NjMm16OXd0bGJ0MXJTbjI2ajVGVTFoMkk9
"Just *how* stupid? I am very new to the field, and my background is pure mathematics. I assure you, the questions I can ask can be pretty stupid.",r/machinelearning,Z0FBQUFBQm0yeGJVRlJrWW8xSkEyVkowTzJuOWctNElpR0dJeVdSOGJ5dmYzMTVQb2E1UUNHMVV4WmRWWnhyQmduWUE5OHRpcGF3dU5qSXEyT0VIYW1jcHAtb1lXdTViQlE9PQ==
I just wanted to learn the way diffusion models work under the hood. It wasn't meant to be a useful thing. right now I'm making the same project but with GANs. and next time I'm gonna do it with VAEs,r/machinelearning,Z0FBQUFBQm0yeGJVZ0RDYUVQWDRvVVJqR2MwQk1VVS1jWjFHbENTZ3paMG1wd0RSY1Y1V01HZzJfYWd0cXlLQjEwb0RoWDRBNmk2UHFod2dDR0xaZDUzeVJaRzJleDJhOWc9PQ==
"Autonomous agents are this decades XML and many other attempts before and some after.... A holy Grail of system interop. Learning systems will get us closer, but it's always harder than it sounds.",r/machinelearning,Z0FBQUFBQm0yeGJVUWZ4SlBEbEtXQ01LeVphMWEzSlBSd0N6YXk2aTRhRnhOaTM4TC1IZ2xucklNT3NuekVBREUycEdXcGk1Skc0TU9MZFRkZzZmenpWMjdlUEtqRTM3eXc9PQ==
"It's a great paper, but in my opinion it's quite bad news with all that latent negative potential passing thru all the training and fine-tuning.  
  
Imagine a bad actor gaining access to military drones, AI controlled trucks or such, and editing some of the key weights. Maybe clamping 10x something like these beauties:

[https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=34M\\_12525953](https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=34M_12525953)

[https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=34M\\_5968758](https://transformer-circuits.pub/2024/scaling-monosemanticity/features/index.html?featureId=34M_5968758)",r/machinelearning,Z0FBQUFBQm0yeGJVMXdzOEdOVHpRY3hMdEFad2h2N2JTR1JuQUstYkpjN1FycElnZE1TMnBGUjBKZFFHUFA3WUYtQlctOHZMNjcxTVduZmFzX3R3cXdSNUVJdTlkdnhQY3c9PQ==
"Yeah, but the retrieval is pretty good in many cases and wildly differentiated. Can we synthesize the query? Yes.",r/machinelearning,Z0FBQUFBQm0yeGJVVVBQRzViN2VYMzA0LV96cG1wUVR4QzhLTTNrVExfLU1XRTdCQ3hwblRRdURxWmF5RGdCWS11eFB0a1NMbkx4akVIVlpsN0J6Z25ZdXh1ZmhHblNuc3c9PQ==
Would definitely be interested in seeing some recent learning theory work here.,r/machinelearning,Z0FBQUFBQm0yeGJVYnhqa3JmUmM1Z1J6XzNnODNqOEQxNnNEZzFlZ0ZxMGY1NllIT3V5cktvTWNkb3M3OTJRZndzMUFTUjRPeU83WVcydU8zYjFIVXhZRl9LdUpmQlFyc2pBanduTnlJdkI4bTEzRHhLOFA5WHc9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVaE9IaXZ4Wk40UUN5MWFCbFh4d2N6eUdBRjZnUjNfZDdTM0hqNHN0N1JhN2t2NzIwemtYRnBaRFM0Yl85cldYRUZtWDNqQ09WYzE5aEpCdWRUdzd6VkE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJVMF9taEVIeFF3clhkQl93R3o1WUJrdzBZRml2M3BIdDk3LXFWV0FqOXZRYWVCYm5Jb3ptV0VRcDkxbDA2Z1hSSnNDS29mNnRuUkVFUzZuNkFLSGxlcFpocFNMMTNOdENudm41MWxXclp3b1E9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVbXFLM3ZucngwdVVxR1hzaUR4bFlxQmVzNFQxRGFteTNKQWdjY2xsS1J5WjNWTFlOaFZMLWlZS1RZWkhGZFhKWTczQ1VuNFNWbnpfTF9qZHZmZlg1UnVzd0c4U0JkN2EtMkEyeko5dWhYYTQ9
Can we please stop using hallucination to refer to confabulation? Do I have the wrong end of the stick?,r/machinelearning,Z0FBQUFBQm0yeGJVSjgzdXJxTVdaODlHTEdzN2YxMjRRMTlZVmVFLUNWSXplYXlLa2VlRGJCOGxPZkNxbkk5V2pGajlaU3lYVzJLcHcwcHloRHZ3THVuNEZKckRyNU5iWHRXMkVrSmt0UkVOZE5WNjFqNkdxV2c9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVWVdCRUIxUXZwYXRvbXhFelI4VmtkYXlIREtwWkduTThpblN1NmtXeTkzWmo5elEzVGV1ajhYQ3Z1WDlBeUFOZ3QxYTFUM3VCMWRFdkVxbEdJVHI0NXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVU2ZUak5uLVB2Wk83UGN6RGU3dW90MWtKdDhINnFuLTRuNkNvM284a3RBRUlaRkNjZ01rdzRFX2c0ODlDTUkxS1Frdlp4Y2ZRVmxWMmMxNUpKWnlLMWc9PQ==
">(probably will be robust enough in a few months)

A ""few months"" is very optimistic.

The overall idea does sound doable, but it will require a different approach (probably with more reinforcement learning) rather than just bigger LLMs.",r/machinelearning,Z0FBQUFBQm0yeGJVYV91SlE3czhqLUdSb3IyS29xa0F3X1RFcXZfWjhhdzRtalZjanBORjFVcXB0MUtVRnd6NmJjQ25PS2dqZEllQjZpVkN4RlZhWFUya3dSLW1iY1c2anNwTUhuZHJ4ZUpvenZCTWdNWlYwa1E9
lol no,r/machinelearning,Z0FBQUFBQm0yeGJVMmhLT1V3T3dsYXQ4ZVRKa192cTNjRDdmbjZVejY4VXRyTy1nd1NPaTBmVWlqWERIZVVrMXZqSkp5bGl3TVVkRkl2NWJHSnJiXzkxTDR1dU5NXzJsR0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVVXQ2ZDBOWVZUTGFsS3ZUaFdwb0Z2ZHdVRTEzVE5reXNHSGpjQl9ERHV1OXhkSnhkRE5Dc2lfUG1xaXN6aXJwaTVNckFGQ1NTRHV5U1RiVXlHN1BGUlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVVU1ocDRzUUFmQldlaUxJWl9FRXo0d2RIYldEY01oQ28yTlJhelBla05HWWlxVWh5aDR5aWhRbzAtbDc2Vm5SV2VUNDJKVERvM3Jqc2lxaU9VTi1Hb2c9PQ==
Would be interesting to know how hard they tried. Were they using a plain vanilla LLM right out of the box? Was it fine tuned? Did they use RAG? Did they hardcode guardrails and filter inputs/outputs? Did they create chains of task-tuned adversarial LLMs to check each others' work?,r/machinelearning,Z0FBQUFBQm0yeGJVTERma3FCdHVPRkpXVWpYYWU5OEhMbXlibllRa2RGZHdaaG5oaElKRlVNRHRIZHVQbDhUTDVjczB5bGJyNU1hUnNMYVBiREFqdnZKdUxGNXRPZ2p5a1E9PQ==
post code.,r/machinelearning,Z0FBQUFBQm0yeGJVLTZvRHhRVFREbkxPLTAtY1lvVF9tVjFLUm93QUV6eDhzR3l2blB1R2VJZFdHRTJVdHdIb0ptUDM3V1h6eXhfZXNLbTY5Vk41UDFjLXRBenR5b180c2c9PQ==
I ask GPTs to convert AI Arxiv papers into python scripts to test out the theory or method disclosed.,r/machinelearning,Z0FBQUFBQm0yeGJVdmJXbDZiS0VtMjJid2hYZU93SFppdEhrWnRMVjJLWU5XZ3M0aHdQbXp0OXZUa3dWXzlELUdCaS15Z3JNLWxLZHYwUHg1SDlHUXlZLTJRZzlEc3hWckE9PQ==
"You have GPTs (Gemini, Bing, or ChatGPT) to explain Arxiv papers to you and to quiz and tutor you, and free books like [Understanding Deep Learning (udlbook.github.io)](https://udlbook.github.io/udlbook/)  so you do not need a PhD.  No one has time for an AI PhD right now.  Just join a group or hackathon that is working with AI or GPTs and make a contribution and get your name on a paper or a patent as a co-author or co-inventor.",r/machinelearning,Z0FBQUFBQm0yeGJVTU9lTDh0b3lUX0pKeUR5bC1pblJrUUo5cFRCU092eEU3M0RYRVZmZUVCMG1FbXo4SHN2dWM3LUdNVllpdFJvRjNuWV9nVEFsYzlVbnluS09SR2xlMlE9PQ==
"

You have GPTs (Gemini, Bing, or ChatGPT) to explain Arxiv papers to you and to quiz and tutor you, and free books like [Understanding Deep Learning (udlbook.github.io)](https://udlbook.github.io/udlbook/) so you can now go beyond your PhD. Get busy and make a contribution.  Just join a group or hackathon that is working with AI or GPTs and make a contribution and get your name on a paper or a patent as a co-author or co-inventor.",r/machinelearning,Z0FBQUFBQm0yeGJVbXBhOWNKTmpaRjA4YUpmZnY2NTlTMFMwaGFhUm4xNkxMZmRwSDNNTnZGRU00VDEyaE8zRExXYkhjZ0hDOHpHY185SFF0VV94UnBIUV9QbE5WV2hjQ3c9PQ==
"The OpenAI Discord server used to have a lot of open source projects, and for-hire opportunities.  LinkedIn has job postings.  Github has open-source projects? Huggingface has independent researchers building and tinkering with small GPTs.

This guy wants to develop a solar-powered GPT-based Teacher for jungle babies and adults: 

[MartialTerran (Martial Terran) (huggingface.co)](https://huggingface.co/MartialTerran)  

This MIT Deep Learning Book may help you.

[Understanding Deep Learning (udlbook.github.io)](https://udlbook.github.io/udlbook/)

You can upload Arxiv papers or python scripts or other AI code to Google Gemini to have a tutor to explain them to you, or rewrite them for your own experiments or projects.  
And see:

[The 5 Best Generative AI Courses (msn.com)](https://www.msn.com/en-us/money/careers/the-5-best-generative-ai-courses/ar-BB1mt4Hv?ocid=msedgntp&pc=U531&cvid=8f098689bdf24cc1bfbff2dc20554ff0&ei=17)",r/machinelearning,Z0FBQUFBQm0yeGJVaVJ1eFlYN1UycmtFQnZEZnV2akpENFk3Mldfa3lDX2pXazhUTVBUdWQ5TS1HczhWX3U1eTc1ODZOZ205a3RWUFNMd0V2N2N6QjFfaE9ESW1JM2dULXc9PQ==
"Do you have a github or huggingface where you publish the python scripts you write when you learn the book concepts?  

This MIT Deep Learning Book may help you.

[Understanding Deep Learning (udlbook.github.io)](https://udlbook.github.io/udlbook/)

You can upload Arxiv papers or python scripts or other AI code to Google Gemini to have a tutor to explain them to you, or rewrite them for your own experiments or projects.  
And see:

[The 5 Best Generative AI Courses (msn.com)](https://www.msn.com/en-us/money/careers/the-5-best-generative-ai-courses/ar-BB1mt4Hv?ocid=msedgntp&pc=U531&cvid=8f098689bdf24cc1bfbff2dc20554ff0&ei=17)

You can get hands-on experience.  The OpenAI Discord server used to have a lot of open source projects, and for-hire opportunities. LinkedIn has job postings. Github has open-source projects? Huggingface has independent researchers building and tinkering with small GPTs.

This guy wants to develop a solar-powered GPT-based Teacher for jungle babies and adults:

[MartialTerran (Martial Terran) (huggingface.co)](https://huggingface.co/MartialTerran)

You have GPTs (Gemini, Bing, or ChatGPT) to explain Arxiv papers to you and to quiz and tutor you, and free books like [Understanding Deep Learning (udlbook.github.io)](https://udlbook.github.io/udlbook/) .  You can join a group or hackathon that is working with AI or GPTs and make a contribution and get your name on a paper or a patent as a co-author or co-inventor.",r/machinelearning,Z0FBQUFBQm0yeGJVMHpnWEtpOXY2aEdyeno1NmZmbktISzhrRGMxbnF5Qjl1NzEzcEdvbU83UWNRN2NQT21YSlpCY3QxQW1JSUx6Q2RYNDdGbkJtUUhPR1k3dTc5RkNVSlE9PQ==
"I didn't mean to say multiple tests at the same time, I meant repeated tests after a certain window of time.",r/machinelearning,Z0FBQUFBQm0yeGJVdm5mb0hIZ3E0dXVIWnlERlFGa052WFprVi1paXVabTl6Mlg2QXNBc2l5YmtMWFBxcnRoRWtkcDFtQnQ3R0F5aVViUUZjQ0JJa3d4Wk9ZTXd2QVpYMmc9PQ==
"For every pathology that can be imaged or measured, the DNA and blood contents of the afflicted individual should be sequenced and examined so that the GPT can find the DNA/gene that codes for susceptibility....",r/machinelearning,Z0FBQUFBQm0yeGJVeW5yRVRuWlRUb1FrMGpZdHdHNmZzendobUhRZllrcEZCRk04WnUzRWoyRjNZazNYRkJNcXpfNjZoVjFlRWpoUHpvbG1uNm83UEROZThvdlVzMWJVanc9PQ==
"When you throw the 5-minute rejected papers into Google Gemini, does it agree with your conclusions?",r/machinelearning,Z0FBQUFBQm0yeGJVQlRpM0ZsNFdGWDdsYzg2anFpOUtpYVV6RTNvVWM3bloxVFVabXJJWDdNeGlpeWJlUWdDdTlJZlVSZUpqeDNaM1dQS1VZWExoaXhKdnc4aXZZc0syNFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVUk5FYlVoOW5faFVCdXdZeE1QbDNTSTR4Yk1yclYwRDZBVDJwSjBtbFJveEttcW1HOU5yNHh0Tk93V1pteVRrVllkMGhEQWFScFhvZlJUbXpmenc4WUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVVGVjd0N6MVEzM01iUFpfQ1Y0MHlITFZ3WU80MGl1UnVlVVpvaWl6dE0wY3BIaVpSSVZENndvdS1LUkE1UDVOY25JM3NwbFJoTmNBQWVxbExhSThuemc9PQ==
"Thank you for the detailed write-up!

Not mentioned is [OpenAdapt.AI](https://github.com/OpenAdaptAI/OpenAdapt). OpenAdapt automates tasks in desktop apps by observing human demonstrations. OpenAdapt is open source and compatible with any app on Mac and Windows: desktop, web, and virtual (e.g. Citrix).

(Full disclosure: I am the primary author.)

We believe a major shortcoming with conventional approaches to AI agents is expecting them to be able to figure out how to perform tasks of arbitrary complexity from their training data alone. While interesting from an academic perspective, this is unnecessary for practical utility, since humans perform these tasks constantly. In addition, a lot of tasks are domain specific, and the knowledge required to complete them would not be present in any training data.

With OpenAdapt you can demonstrate to a model how to perform a task, then have it take over the task, with additional user-supplied natural language instructions. We generate prompts from the demonstrations and instructions.

I started working on OpenAdapt after watching my brother (a highly specialized physician) wasting a lot time clicking through slow and user-hostile Electronic Medical Record software, and realizing that existing solutions (i.e. Robotic Process Automation) are brittle, time consuming, and require specialized knowledge.

Free download (Mac and Windows, Linux coming soon) at https://openadapt.ai. Questions/comments/contributions welcome!",r/machinelearning,Z0FBQUFBQm0yeGJVNW4ySzlqTVRyT2dQTHQ0VVQ1QVlSaGpteUd4RWhOU3p5RTJodVlyRUExQmpTQmU5T0ZUa3BJdGFCVjN3LXV6TC16SXFBSGY1aXBGeTNxbnZ0azdmdmc9PQ==
He believes it has nothing to do with the brain and the entire field has it backwards.,r/machinelearning,Z0FBQUFBQm0yeGJVOUJ5bV9qdV9zakZneTFhTTJTMzl6YlZySzhKd2s3MGFXeUJqTnYzSjB0ZVhDaTF1aDJ1SXMwTW5XcF9nSTRGYXBsN2VTWHZZR0ZQd2FlaFk5TnF6Vnc9PQ==
"there are videos of him talking about this topic and how he is more interested in unlocking how the brian works, This is what inspired his most recent paper of forward forward learning which is a pretty interesting read. I think this is the talk where he explains his thought on back prop.

[https://www.youtube.com/watch?v=NWqy\\_b1OvwQ](https://www.youtube.com/watch?v=NWqy_b1OvwQ)",r/machinelearning,Z0FBQUFBQm0yeGJVb0xRRTlOZm9uSjRQZUh2dDk5M2g0ZDgzcTZLM2tQZF9vMkxVMnYwM1pWTGh6S0pxLU01S3RISml4OTBCakdPT2h2a2k5WktPeFI4QjBySHRBbnJpUkE9PQ==
"If that is true, why has his stance shifted so dramatically in four years?",r/machinelearning,Z0FBQUFBQm0yeGJVRTUzamF3TzNjQ0h6bWRxRTZ4T3MxdXA2VFJTQlU4OV91QXpQU013SXA5cllyUDFtQnZfYUJLbmVTSDJuNHlGaHdlaE8zVElENG9Rd2ctaWVmYWFpUEE9PQ==
Nice thank you,r/machinelearning,Z0FBQUFBQm0yeGJVZW1LcVptajZMWUU3U1V6WHYtY2VyaXg1OWpaUkFaY25WcnZnYm9EMTVXSjNfLXVmeHk5Vl9aYTQtN0NRYVZzNF9oSHNKTERjbm9yQlIxMXNFN3VzVnc9PQ==
"forgot to link the paper

[https://arxiv.org/abs/2212.13345](https://arxiv.org/abs/2212.13345)",r/machinelearning,Z0FBQUFBQm0yeGJVREUzMDFPakZnMjlBa0NxNlo0ek9tbHFILUtIdV9LbkdncDNmMy13VWNlcmN6QWNneEtHS1REMWV1ZkY0blg0aGdTMTdMLXl0eEg1RmxCeWFOWVdMYkE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJVNjNEVXRwMGIyek1pNUV3NGhhQm10MHJqMTFqX1g0ajEtLVBiRUdPaVpKNGhsZ3BfLW9Ya2l2NkVmVU1ndTR2a2MyVTk1QklOQ2NWRzhoZUEyN05SbW9wS3BNV1FlN3g0a0ZWbHIyVmk0YnM9
"> and the entire field has it backwards.

Huh, that's weird. I think if there's something that all the great minds in the field tend to agree on is that backprop is like not how the brain learns, but hey it works in silicon so we're stuck with it. I've heard Ilya, LeCun and others say things along these lines.

They might disagree on the overall arch that will get us further, but I think pretty much everyone agrees backprop is not how we biological language models learn :)",r/machinelearning,Z0FBQUFBQm0yeGJVZmxqN3AwTFU0SXIyMURXaUQ1a09Jb3E4VVlfLTdTZ3dMUERwQmNreGRoN2l1eDJWX2l0YnFMM0ZycjJQMjNoLWVhOVgzaUs5empWUk1nMk1BWlQ2SnF4c3FFejVHRTlfaU9WbUxjT0l2dUk9
Yes,r/machinelearning,Z0FBQUFBQm0yeGJVMEN6cldQUlQwckRvS3RqbDFBUDNPZU5TLTMyQ3ZrSGVaX1J1M2FhNndzRUFOb1Z0VzRsaE1JMUNOOG9sMWxEU0hkNlp3UUJxY1pxWEYta1ZOQjRoMVE9PQ==
Why does it matter what he thinks? What do YOU think?,r/machinelearning,Z0FBQUFBQm0yeGJVRUhpaGZ0RlJoaHpQdk1ZRWxQRlNuajVqaGhpWmJwSlN6M1ctYlRHUzB4dzU2ckRlTzB3Q3BpbnYtNlR1SFRxajFWX01SZjJuS3l3eFdlRVJ0UXVWWmc9PQ==
"GNNs are incredibly cool, really disappointing there isn't more discussion around them here. I remember seeing quite a few posts about them a while back.",r/machinelearning,Z0FBQUFBQm0yeGJVUU9ZMjhsZklpeFROLXQ0b3hrNXpCRzdTaDVrVG9vN3ZrZG5ua3d2U3JTT3JQQ1M0NFZsS1U5S3V5enZ4VjF0M0dGSm5RQy01X2RBSnE0bWtfMGpWTWc9PQ==
The same reason any student should care what their teacher thinks. Hinton's expertise is far beyond mine and his insights are less naive than mine. I'm not suggesting that anyone should take his word as gospel though.,r/machinelearning,Z0FBQUFBQm0yeGJVTVZfbG14YV9ydHNGUG5YMEVlcFFUbzJpOTVBOUgxbWI0eWFFcDYwVWozeDA1RldvV08tLXR0SzlGTUJiNEdON0g3eHlhRTdMOERlOXVyVF9fVXZvSVE9PQ==
using the same dataset and train/val split right?,r/machinelearning,Z0FBQUFBQm0yeGJVYnhrLUtSb09mdTFFajlVZzNNaGtYNjAwanAtZUJOM05BOURfZW5Wam1VYWVmR1VxeE9fNTc2TGJUb0otNWF2RWtON2NPZ2NzYmV5WjN0SzlvdkxabUE9PQ==
"Exactly, I have never read a modern paper that suggested backprop is how biological brains learn. 

They only say that it is useful for ANNs and that currently it’s the only thing we have that can practically scale.",r/machinelearning,Z0FBQUFBQm0yeGJVaUg1WU1UZGRLWHlyZjJURHFmSzFkM3EtOW1ycU91Q0dzX3J6Q3VabDNSZWpQdVkzZnRnNC1HWkdCOVlkdzNqWk5iaGVQejZJSVp4Y3p1blQtdzhRRXc9PQ==
"It really depends on the project. Usually I explain to non-ML people that there is a reward curve that looks something like log(x). We can do linear or logistic regression and get an 80% solution most of the time, at the cost of a data pipeline. We can do more work and use an appropriate off the shelf medium sized solution, like xgboost. That might get us to 87%. If that’s not good enough, that’s where things get costly. We can train a vanilla deep learning model, but we need a lot more data and compute. Maybe we get to 91%. Or we can develop something bespoke via research, which is years of time and likely a lot of data and compute and risk. That might be 94% if we hit it out of the park.

In most settings linear models or xgboost is good enough for the execs.",r/machinelearning,Z0FBQUFBQm0yeGJVLXNoXzE5STFjbldnbHZtSjM0cVZYLXQzNDJiRE05enVFbHhJQnNyeXJ2emMtVXlTZHhDam9UOU80QWhGSHVxYnhFdldTS3Z1YmVMaS1DT3JjNmJlcGNjZFFiSUVrelFsel9tQ2MxcFcwLVU9
"I absolutely hate this culture of hero worship. If you care about ""how the brain really learns"" you should try to find out what the consensus among experts is, in the field of neuroscience.

By your own observation, he confidently overstated his beliefs a few years ago, only to walk it back in a more recent interview. Just as a smell test, it couldn't have been back prop because children learn language(s) without being exposed to nearly as much data (in terms of the diversity of words and sentences) as most statistical learning rules seem to require.",r/machinelearning,Z0FBQUFBQm0yeGJVLTFNei1LOHA3WW5tOTV3YVdET3hhT2FPQTJEU2h4TG1UNFVINWd6MVlITTloa2JHOUR2S2RMQ0xvb01vbHVWc1p6bnBiZnlXY29ZRC1TYlI2OXlQekE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVNW9ZZDNZYkxRYUJBaGd3ek9XQVl5YWlodWo5ZHFkbG56ckxlVzFvOWJwMGtubUg1R0V6bmlQcEJLd1Z4RGxYa3ktbTV1UzVmeUIzbWRyNXpPQTBIdlE9PQ==
"If you have access to alter the weights, it's already game over from a security perspective - you can just train it to do whatever you want.",r/machinelearning,Z0FBQUFBQm0yeGJVNU5JTjdiamZUZmxkNWNyejdxS2cwNzJjdDZQV0t1dFo0TVFaQkRwdHFPSUVjN3g1WTBfa05UMXJta0JPSnREZjJXYTd5YzFyVE1ENXdVUzZDT1YwbFpyOTlsT29oOWRDcWJQdEQtaDFsY009
"I’ve always been curious of this notion. I have a one-year-old who is yet to speak. But if I would give a rough estimate on the number of hours she has been exposed to languaged music, audiobooks, languaged videos on YouTube, and conversations around her, it must amount to an enormous corpus. And she has yet to say a word. If we assume a WPM of 150 for an average speaker and assume 5 hours of exposure a day for 365 days, that’s about 15 million words in her corpus. Since she is surrounded most often by conversation, I would assume her corpus is both larger and more context-rich. The brain seems wildly inefficient if we are talking about learning language? Her data input is gigantic, continuous and enriched by all other modes of input to correlate tokens to meaning. All that to soon say “mama.”",r/machinelearning,Z0FBQUFBQm0yeGJVaUg5NDd1Yk9ybTIwc2xGSzF6eUkyUFU0aVh5WUpVbVNMNGxVTnJUck1pQjZPemlDbmpVTmdJeVV1aEJrVk94T2tSTVowNTZZMXNNUmx4Y2h6Um5tQVh2SnAwVzBMYlI3SXViM2VKR0ZjWGc9
"It's kind of a self perpetuating paradox, truly a marvel of nature that so many things are ""all"" that we need",r/machinelearning,Z0FBQUFBQm0yeGJVTElTT290LTN4ZlAzTnA5NGdpc2dwaDUtVGoyQ2RneS04VmtHTnA2b3BNMkpKbjhsZThyYUlkQlRpMWRXbFo1UVJKdkM2ekpURUQ1WDgwYmd0UklFa1E9PQ==
"I like this breakdown a lot. 

To draw an analog to humans, we build teams of Poole because we can only:

A) do one thing at a time
B) have a limited skillset / knowledge base 

As I’m sure everyone here can attest to, switching costs in our brain, and communicating with others are very taxing. There is always loss (time or information), but a necessary evil for human collaboration. 

These issues are not present with AI (in best case scenarios). They are multi-threaded and have access to all knowledge if we want them to. 

An AI can reason with itself to iterate. No need for multiple agents. 

As we grow the context window and refine the data, a single monolithic AI makes sense (at least to me) to perform the best. 

</thoughts_from_the_can>",r/machinelearning,Z0FBQUFBQm0yeGJVVmtfVEZSSGZSVHpJNDMwNDd0Sk5aTFN3T3U4ZjhnbVJXdFdyMDZHQVV0TDFhdWxaVnotdXQwS0RhODVHN1gzVEpPdXNKMFlDTFFMSjByVXZxenVkMWc9PQ==
So you're saying you're not using chat gpt to trade crypto? \\*shocked\\*,r/machinelearning,Z0FBQUFBQm0yeGJVRktjTFNyM0toajk4Z0JQV01sNjgwOFJTZDhsbnlwTnNLQmo2cGZkaTBRVWpFNXQ5MmtVWkZ6akpkMkxjSkxQNUtncmZUN01nZVRxbnpwM01nTGY2N1E9PQ==
"He's probably right, although we may end up finding whatever technique human brains use may not necessarily be efficient on our current best hardware (GPUs)

Interestingly enough Francis Crick worked on this problem before he died and also didn't feel backprop happened in biology. In fact he was studying a region of the human brain called the claustrum... a part of the brain that when disrupted leaves to total loss of consciousness",r/machinelearning,Z0FBQUFBQm0yeGJVc2F0ZG9tOG1IajBLQ0J1WWhqaXo2aG4yU29TMmk5TURGWTZWdWZEb1FKUVVJV2JwVkVlZ2FTTldhZGt1OGg3MDVaTVJBTEhMSFE5RGlUNVFtNGo5Ymc9PQ==
In one of his recent interviews he talks about how he believes the brain learns through some sort of gradients. He mentions that he imagines that any other way of learning to be too slow. He doesn’t know if the brain does back propagation and thinks figuring that out is an important area of research.,r/machinelearning,Z0FBQUFBQm0yeGJVZVVDbl9NR0RoN1hSNkU3OTBqZjVMb2NLRzNtR3ZIbktKQldJS0ZzVVhsZVFOSDB1TWhTMHI4aHJCYVZ1YS1yNEZXeFVESUlUYUJQcWZiWGsyZGxXMEE9PQ==
"Cool. I started a similar project about 8 months ago with the goal of learning about diffusion models and trying to generate plausible SNES music.

[This](https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/) is a really helpful blog post if you want to take your model beyond generating nightmare fuel and actually generate some cats.

[Here](https://drive.google.com/drive/folders/1aCs0HWvocO1-EN2dXhEa3Hwcje1xeO24?usp=drive_link) are some of the samples I've been able to generate with models in various states of training progress. [Here](https://github.com/parlance-zz/dualdiffusion) is the link to the project github if you're interested. I'd highly recommend adding classifier free guidance using some kind of conditioning, even simple class labels work great. CFG is basically a cheat code to massively improving sample quality and is pretty simple to get going.

I noticed in your [code](https://github.com/Null-byte-00/Catfusion/blob/cbbd4dbca1f2588e7cb189520f731fd31d70e74b/model.py#L146) you're taking the loss as an L1 loss. I guarantee this is hindering and not helping performance; the stereotypical blurriness of MSE loss is a _feature_ in diffusion models, as it enables the statistical guarantees required to allow the model to actually properly anneal over the different noise levels in the sampling process. Just like in the blog post the way I think about it is the ideal model output should be a superposition of all the possible training samples that could be underneath the target noise level. This means blurry outputs are desirable as the number of possible training samples underneath the noise expands to the size of entire dataset at the highest noise levels.",r/machinelearning,Z0FBQUFBQm0yeGJVTTFSdEVOOWhHamlHUUh4ckNuLTNkQ0U0WS1aS0F5UVZkdHJDNGM5TWo4Q1JsWnh1RURWcnhvdnROSkpyeUZuR1JCc0o5azVWVU9CQjN0MzQ0dkp2SlE9PQ==
This so much,r/machinelearning,Z0FBQUFBQm0yeGJVTmUtUENaOHNIMzBSN2xwQjYyWFdTTWphYVhSQ0tJcmdEQVJEbHA5ZzQwb3Q4bHU4OVlVNzBaUmZYeDJraUtIdzJQWXEzZVpTWjVLaVVoWl9lZnpFUzRBRk9xTFBmZFhOSk5oeTVYZUhTVE09
Why would any of you in the comments even assume that brain is represented by some parameters that store some values that are updated in any way?,r/machinelearning,Z0FBQUFBQm0yeGJVbmhaVEp0SzIzOHNQdEI0WlpTQlREUDdDZG0yeE9RUTF6TXdsV2VDdVcxOFZURmVJMlI1akVrOXd0WG9iU0lOWVh6TFlhT2pEQmdvM0xMZWROQmRIdkE9PQ==
"You’re basing this on the assumption of what your child said. It is very possible your child has a much larger capacity for language understanding but is simply unable to express it because your assessment of language capacity relies on speech. 

Speech which requires complex muscular control to create phonemes, which is another task that a child needs to learn. Unlike language, there is no external dataset being fed, your child cannot see the tongue placement or other oral parameters necessary to create certain sounds.

I’d even argue that there’s probably an “inductive bias” for what children first say considering the near universality for the words for a mother/father (ma/ba/pa/da which from a layman’s perspective all similarly formed in the mouth but I’m not an expert). https://en.m.wikipedia.org/wiki/Mama_and_papa

Also your hypothetical relies on your child being fully attentive, which probably isn’t the case considering they sleep and are easily distracted by things like hunger.",r/machinelearning,Z0FBQUFBQm0yeGJVSGJIc0VqeV9VaVdqRWcyT01CRlY2eGtRaW1CWlh5bzF0V3R2UEZ5TzRPRXdrTHZFVTgxUWlmVS1XWkdxeldPdE5ZYVNGWWFZY1FlYm85YkZUQWVQbVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVMnFBUS1HYjVHSU55ZDdCRnM1TlNjY3JEVk5QQWdhRkhoMjl0TERFaXkzUDZUcjFCODRScTdKblphNWY5QmxLUHc2T1Z3ck53bmNQdzdTTEpfRXE4UGc9PQ==
"Reading proof in ML papers can be challenging, especially if you have a computer science background. Here are some tips to improve:

1. Strengthen Your Math Foundations: Brush up on the fundamentals of linear algebra, probability, statistics, and calculus. These are often the building blocks of proof in ML papers.
2. Study Basic Proof Techniques: Familiarize yourself with common proof techniques such as induction, contradiction, and contraposition. Understanding these can help you follow the logical flow of proofs.
3. Read I ML Texts: Books like Bishop's ""Pattern Recognition and Machine Learning"" or Hastie et al.'s ""The Elements of Statistical Learning"" provide a more approachable introduction to the mathematical concepts used in ML.
4. Work Through Examples: Practice by working through simpler proofs and gradually tackling more complex ones. Resources like ""Introduction to the Theory of Computation"" by Sipser can be helpful for this.
5. Be Patient: Reading proofs is a skill that improves with time and practice. Don’t get discouraged by initial difficulties; persistence is key.

By gradually building up your mathematical foundation and engaging with the community, you'll become more proficient at reading and understanding ML proofs.",r/machinelearning,Z0FBQUFBQm0yeGJVSnlJNW1sUjlzZGhWWmducHRXbmFEX3BjWWlOczJ2MFZMdENDY1Rwa3VxbTVBN1hNWXJsTl9yZGtsX0gybU42ZXRpa0tBaHFrd1YtWXlsUERnQ09lZWhqT19aVjlLSm1YMGVXa3VhVC1BTDQ9
Yea! Using the Cifar dataset referenced later on in the paper and matching those parameters for the models and training,r/machinelearning,Z0FBQUFBQm0yeGJVdnpUZFppMVRycVZQM3ZOalcxVUJsYVlnTFlVYV9kb3hiWEYxQ3RkVlFiU080eEJTMnUzUWhaNlBRLXBVY3UzRW94NEVJTGRxNHJ3UGduNUU4LUJNWl8wM0Z0dHIyWHZNak9uRktUbFE4Y2c9
"I have a dataset for energy consumption with 4 inputs month, heat, and population.  
how do I train a back propagation by using this data?  
what tools do I use? deeplearning4j?",r/machinelearning,Z0FBQUFBQm0yeGJVMmJaQjNnVzF1a0tJWk43eWRYbVhWVmNWdGM4NFRSeXdqYmZKQlBudlN1U1BtNVo3REx1a0UyVENreml4Slh6cGRUN2xIbUY5dDFwbkZqSnNudDNfQ1E9PQ==
"> Companies may be held liable for the mistakes of their agents. A [recent example](https://www.theguardian.com/world/2024/feb/16/air-canada-chatbot-lawsuit) is Air Canada being ordered to pay a customer who was misled by the airline's chatbot.

To be abundantly clear, here, they were held liable for the difference in fare... the guy was entitled to a lower fare and was given incorrect information on how to apply it. He received back not more than he was entitled. 

This wasn't Air Canada's chatbot getting tricked into losing Air Canada money, because in the absence of the chatbot the guy would have read the page with the correct info and submitted the correct form prior to traveling.",r/machinelearning,Z0FBQUFBQm0yeGJVVTJUdEw4Yy1EOFpSTnRUVHloUDRIX3A4XzFQRjEzV3pBMHdROWVyWllQRFlHa3JBUU04X3ozejdQUlVUNEczOWVVOVVFY1Zzc195aUhYVTZXVW9wbXc9PQ==
Cars? Planes? We had a lot of various crashes before we got to where we are today...,r/machinelearning,Z0FBQUFBQm0yeGJVQXk1UUNkc1BDS1NIYUFTTkNMNGg2eXpNU09iQ1lBUFE1bzd2bjU2eU1vd2psMTYyd3ZBdHVsRURtMklkOVlodXJrZE9pd2Zod1h3dGJVQVZCNVFkYWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVdnNEM0tTYlpHNVpNY3RQOHk3djZVOEh5cHFPdzdyYVFNbkN6Y1MtU25LbXp2cGZDeGRza21ORHpIdkpWMGVpQUt4ZTlWTnNwRnVwcndBTEZ0T1pfSlE9PQ==
It looks like you might need more regularization. Do you have dropout layers?,r/machinelearning,Z0FBQUFBQm0yeGJVRTJCbkdDRmxhNnhEMjlZb184QXpCTTBEaktneUN4cC1nNFk0R2VKRXFvYm9rNUg2Q2x5NXdaRW1UR2NDUm1zTURhVTZOTXFKVWNld2x1a001enFSMGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVQjBreGM1ZTRNd1N0NFJjV25rWDc1bjdRaHFlX2swNk91N0xKNVFkSjNSTlVrWC1CU3R2bDQyTXk2clJsbno2NWxRQWFodEEzSlBVZ1pRSTJiWlFjamc9PQ==
"Ok, the paper explicitly states it does not use dropout or max out if you are shooting for pure reproducibility however you may want to take a closer look at the data augmentation steps, which are only applied to the training set, but nit the validation set.",r/machinelearning,Z0FBQUFBQm0yeGJVMWM4dlZGVkNmLTRoZFZCbld1am5YTXFuQzVCOXJNMVh2UlNUbGZ1X3pzYTM3am5USEowaTFkN0NaMnRBWUEtZUs5ellzdFQ5c3RLc1lGWURVWjR1bWc9PQ==
Has anyone received feedback/reviews for revision after being accepted? I don't really know what to do next @@,r/machinelearning,Z0FBQUFBQm0yeGJVS1B6VGhOaXdRYldOSDMtZGhMMGx6Y1pnNWJoOWhvb0YyeFFRZ0l2emRxRWpGdDFFUVcwaEV3bU44STdlOGozUi0yc1RQekJrWUlpeHRCeWstOU1vWkE9PQ==
imo Less dislike would be the most efficient.,r/machinelearning,Z0FBQUFBQm0yeGJVWlhzN1VQbjEwdjVMam12VlFScXNWMnhobXc1Q3N5VXEzblZMWXhFWVNjTnBEVEIyTU5fT1c3MFRaX19JNDZNRW02S1k3ZG5VSkVPTjFvOXNPMzhYOGlpZzUyWXRFWUVMa29UczVLcThUU2s9
"you would be correct if all the brain did during that time is learning language.

it also has to learn to hear. to see. to roll from back to belly. to crawl. to sit. to stand. to grasp. to remmeber objects. And so much more, and so many of these things are prequisites to even START learning to interpret sounds as words, to keep them in mind and try to make sense of them.",r/machinelearning,Z0FBQUFBQm0yeGJVOE5xZThremRoLWZHVVRZZnkxZF9CT0JKbFNCc2h1X3VQN2tXcXkyYXZjanZqM1ctZnFkZ05waV9CY20zYVUxQm5PT0VPdzRRNWptTHRfbzg4ajhMNkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVUGMtbHdMOGZDSkhwNEdIUlozWTAtRUVHSXRUTm52aVMyc2VsSDVBVVRpZ2NXMnZVbVVvel9VN1BuSmJNRDRtS2RNbG1lZGRyb09OdnlvYUlSdUlLaXc9PQ==
"He's come round to being more positive about it as an efficient learning mechanism for digital computers, even if not bio inspired. 

Here's a recent video where he talks about it - 2:45 in. 

https://youtu.be/rLG68k2blOc?si=5Un1_VkVA8vMKq9X",r/machinelearning,Z0FBQUFBQm0yeGJVWWF6WERmZlotbVBiQTREay1MNkxqYmFpcFdWNEZRdktvWnBVNnNyYlFUQll1UWJwOXREX2xFa0NvdUptR01LTW1ybjRzNFlMOU9vT2RKdHd0emlkUTFwaUxyUWh2WkJNbU9Lc0VJYnNvNGM9
Will it be desk rejected if remove the checklist from the paper but complete the online checklist form in OpenReview?,r/machinelearning,Z0FBQUFBQm0yeGJVdDlfblVCS1J1c3VEQnVtcEtCRklsUVl4UHNxRkhFR2FRem91Y1ZISmliaTF3bXAwSUxUVUlwQzJ6c2lxeW82MjRQTEdSaVZpVnZoMVhHTUxBOXNxUjZQM0puSnJmVnJXUW10ejhRcUd5R009
"Anecdotal, but I very distinctly remember when my daughter was one, only just started walking, couldn’t talk, but one day we were all in the living room and I said hey daughter can you get my socks (clean socks in a ball which someone had thrown on the other side of the room), and she waltzes over there, picks them up, walks back and hands them to me.  It was surreal.",r/machinelearning,Z0FBQUFBQm0yeGJVeHBaSE9WUjd6OUJ0SHdWdkd1b29zTERZNUxNOGtwMmZkZnhFMHZCamg2NmljQmtJdXI0WEQzN1BRN3pSaTRMWHdmWWZ0R1VxN09UWWlzV2xHUlNtbXc9PQ==
"Higher success rates can be achieved using RAG, Guardrails, Fine Tuning, Double Check etc.  LLMs are improving at a rapid pace, if adoption increases and eventually the Buyer and Seller are both agents, they might just be able to cut to the chase.",r/machinelearning,Z0FBQUFBQm0yeGJVV1VyZkVpREM5cFRyLV9JSmhHeHltbXZSbjRqMVJCTFBMOE5CS0s5bVdCdHNoT3ZtcHJtcGg0X3Rsb1JSMEx1MFZUaU05anI2Y3c1WFNVbXBpMUtfREE9PQ==
"Surely learning to see and hear would be somewhat akin to tokenizing the raw input datastreams into meaningful content, with meaning being some type of embedding or some such? That is, they would be auxiliary processes benefitting the language learning since a developed sight allow you to meaningfully connect the spoken word “mama” with the coherent impression of a mothers face. 

I am not firm on the following opinion, but I’m inclined to argue that the primary learning objective for a newborn outside controlled locomotion, is language (as opposed to signaling, which they do from birth). I argue this point from a Jaquesian perspective, where we seem to be the only living organism capable of language.",r/machinelearning,Z0FBQUFBQm0yeGJVT3hiNmoyTmYxNTBFVVlIRy1FcEpSWmNXTHdBWk5ZdHg1bW44QVpsdlJ1TXE0bkI3UUNyNGk0ZlFXV0FxVGtWWlk4NHlfVy1UR2RUTmNRbGlKR1BlQzFpZTFVVFMxZmhKN3pBS2RwUGoyTXc9
It's true? Synaptic plasticity is well-studied and the strength of synaptic connections is the primary mechanism of hierarchical information processing in the brain.,r/machinelearning,Z0FBQUFBQm0yeGJVazBHR3ZHeldvdFZuVmI5NEU5MVVBN2tRQlp5bkZyelZ0Z0l1Uk8weVJheWZvRHdxNkJOTENBcUlHb2FvYnBCTUM4ZHAxLV9hOGN0c0tWbENFdFdfRGc9PQ==
"That is a very good point! If I say “where is the lamp?” She will 10/10 times look to the ceiling and point to our lamp. I have, obviously, no idea if she is just correlating the sound pattern to my happy response when she “complies” or if she have an understanding of the word. But I still think my point stands regarding the feasibility of backprop; if I slightly relax my constraints of the argument and argue that her training set is the unordered, continuous datastream of (sound input, visual input, touch, taste, smell), it seems her training dataset is absolutely gigantic by the age of 1.",r/machinelearning,Z0FBQUFBQm0yeGJVRTdpMGNSUmpYdmF4UFZ1SVFxSjBkLVF3Vk5FcXlveTdqTkV6OEUwUXg2Ty1BdlJ4M2Nla2cyNkdpWEtEVHlHcFppdkRKNmxJelRPZlo3T1RQbXV4TExiTy01Nmw1Z0xVazRIOFpEZXhRLUU9
How could you build a learning system that *doesn’t* involve updatable parameters?,r/machinelearning,Z0FBQUFBQm0yeGJVeTUya2VUUno4WTJOUzlQT3ZGOWpxalVNbDE0LXFFNFU5NERVSmVjRzM2NTFVNy0tNjNJeFBNR3ZBSVprNDUwaFlFemhaNWVmQVNaNGdlQVdMdmRKc1Azd1dQWGVObk8wU0FKNXlHejhfSlk9
"Is there any reference on what they trained V-JEPA on? *Wallclock time is measured on a single GPU*. What GPU is this though?

>Figure 5 SSv2 frozen-evaluation performance vs. Pretraining Time. Wallclock times for all methods are        measured on a single GPU with a batch size of 10 clips, using the official codebases for VideoMAE and VideoMAEv2, and linearly extrapolated assuming a global batch size of 2400 samples. However, note that the SSv2 accuracies of video pixel pre- diction methods are actually obtained with small batch sizes and significantly longer training schedules. V-JEPA out- performs pixel-reconstruction methods while training signifi- cantly faster.",r/machinelearning,Z0FBQUFBQm0yeGJVd29Ud1hDZlNLbVdyZG5iNDl1RVMyaTA2Y210cWlsSkgwUkNBemhUTDB1dmdqWGdxYVRhNkZlOWdreWIzcWlSWk12MnRWUzlaTld2RW1RYTlQRzN2bWc9PQ==
"me too, no invitation yet... Reviewed icml, iclr, acl, colm ...",r/machinelearning,Z0FBQUFBQm0yeGJVRHZJSFl1ZTh3bTVNNVdwdjl3Z1JEam5vVFF0M1Y1N3ZZVjdLSVVNaEFxcVNJZFEyVkRjM2xjeGFhR3pydkNjQlRlX2ZmYnFveUhKOHVVWWJ4N01Hdnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVNnhaOERBVnJGbHZfWTFRaVJNSFU4VEtsZ0N2ZmNGZHpEWmx1Mm5xeFNVcGlES0k2a0JZWFUtMTEtajhocnMtMndyeEVnN2tPZC1nY1hHdVhSdmFOWWc9PQ==
"The brain has a specific architecture that I'm assuming is highly non-identifiable. It's possible that the inductive bias is so strong that through very little tuning it will learn, potentially without any sort of direct feedback loop like gradients.",r/machinelearning,Z0FBQUFBQm0yeGJVTGtQV3BxVW9EakU0VWpRMjVURjVsZENEd1dDelJhUzF6NDJjSXBJbzJGREI3V2lIR1VtQUY5ZWpObVlZM1gxd1NsUTFRUXFFTXpLeGtsS0dPOXByQ3c9PQ==
"You can [try this API](https://apyhub.com/utility/ai-text-extract-keywords) - What are the average calls you want to make daily? This API costs 0.3 EUR/request. Also, if you want to analyze the frequently used keywords, you can check out [this API](https://apyhub.com/utility/analyse-keywords).",r/machinelearning,Z0FBQUFBQm0yeGJVUkZMTy05LWRlNGhFZnBUdWZBQUNtV0ZFMjZ4SWhBTnJVRDFSZkgxdFV5QTl5WjljYzBub0hhT3pXeFVxSWw4anhuR0VETTdOaGc1a0lyZFV5b0JJeVE9PQ==
"My doctor says I'm sick. But who cares what the experts say, I decide when I'm sick!",r/machinelearning,Z0FBQUFBQm0yeGJVT1BMN1R5XzlheUFFcnRobU1WY3MzQ2E0ZGYwUzdXQ3cza1lhbGJlUDliS0FlR2ZpZkNQZU5Md2QxNG9KWHA5M0wwRkFlRW5ibVpnVFRVTzJDZklQZ3c9PQ==
"I'm not entirely convinced about the practical utility of these SAE. 


Proponents will tell you that you can use these techniques to identify features of interest and then intervene on them to amplify or attenuate the models reliance on them. 


But this isn't something new. We've been finding steering vectors to attenuate concepts for a while already. Existing approaches are supervised and much more practical than these SAE.


But even if nothing comes out of it. It's still cool work.",r/machinelearning,Z0FBQUFBQm0yeGJVeU1xZ0NTSlk3QW9xOWhqMUU4b0kycnhXOWxINU1Uc1MtUHZIaHUyajFPc2lNb0dBWXB0Vnd2RlhEWF8yanBnOTJuSi1lY2VuVklNZWdzOUhUNkpNYVE9PQ==
Great ! :) You can chat with us on slack if you have any questions or want to introduce yourself. You should find a guide on how to contribute in the docs.,r/machinelearning,Z0FBQUFBQm0yeGJVcWhPWGhCUWF0c0dJT2Nod1pEZ0FBTWJSZFhTUVJfWjhOSXNnMUppZV9Idk95bEZOYl9vVGEtZS00MldrbGNVaWNtTjRyb2RlU3ZySGlCSlJOeEh6MVE9PQ==
"Sounds amazing. Especially for people that are new to machine learning (or coming from other science fields). I am sick of seeing papers with models trained and tested on the same data. Not to mention randomly stopping when the metric is highest on the test set. You only see that when you look more carefully at the code.  
  
What does LLM descriptor mean?",r/machinelearning,Z0FBQUFBQm0yeGJVTnNVUGtQOTlNR3JpU0lIV0E1RTI1SkNKQmxtREI3SVJyTTZaSlZyeXBIeTNqS0t5LTlLTHZTZ0hETnJfMWFXQ0NTVlUxS3BrODdleUFGSDlnajh1OGc9PQ==
"Hey! Is the data public, or could you make it public? Could you say more about the intervals/structure of the different timeseries inputs? What do you mean they are not IID, isn't that a requirement for even treating it as a prediction problem?

I'm interested in this multivariate timeseries/sequence prediction problem generally, and have developed a framework to quickly configure and train transformer models for these types of problems. If you give me sample data, I could set it up for your problem so you (and I) can compare the results (I am interested in benchmarking/learning about when & where it is useful): [https://github.com/0xideas/sequifier](https://github.com/0xideas/sequifier)

Let me know if you want to work on this together :)",r/machinelearning,Z0FBQUFBQm0yeGJVMi1INTVQZmlkcktiWExCWU5xNXVwVVFJcFdpekpGMmpfOV9MUGE2YlgzaEt0cklkbWhpaG5odmZpMnR4dE5Zenh1LUdxVXBwQ1I3MllKTFlBMnVDRFE9PQ==
"The idea is, when you have already configured your training, that LLMs can generate a full description of methodology used. In a later stage, I will also make LLM generation of Results discussion based on the achieved metrics and statistical testing.The output will be in form of simple text (for those who write papers in docx) and LaTeX.",r/machinelearning,Z0FBQUFBQm0yeGJVUi1RN3FCaW5CNmV2WTdsekVtNFpCQjdtQlZwanZfSzd4Q1FiSUgzNjNVRTMyYUpiYkZWRUVaWGtXN1E1ekJVUFBMZjJFWFhVX0w4VXBlRnZueFFIM2c9PQ==
"Nice!

I'd consider versioning your cuda, tensorrt, pytorch and python as it will be a hassle to reproduce this in a year or two.",r/machinelearning,Z0FBQUFBQm0yeGJVRGlmLUh2QlhWZ2tJS012cUNVU1Ixek9KTk5jMTdGNjZGZlZwRjZBRlVkZHRTNEo0M2hJaXd3QWgzdUk4NDFJeU94dEMycWVNWEJvQUtwTGdheVhoTHc9PQ==
I am still learning all these stuffs could you explain me how adjusting weights as well as activation function would improve catastrophic forgetting?,r/machinelearning,Z0FBQUFBQm0yeGJVNW53dGdsMlh0QmljMF9NQjRvUHdWLVBMbzR3bl9BSmhNZG9SeGNLR3JUVDFVeWxWdkMwZUdxUTh2bGRJZUcwNVRrUW9HS2RfVW1ZdXlMRFBYREZDZFE9PQ==
I will accept 80% success in writing working code. I will not accept 80% success at driving me down the road.,r/machinelearning,Z0FBQUFBQm0yeGJVTk9sejNOM0JPM2ktbzVSTk5ELVNvZjFRRmpfMXBsNTdaYndsMzJ5NFl4U00wOEFTZVFId3F3WFVaZ2RjMkM0bDl1V0hQMFhxNFA5MzI3YjRxdWwtZnc9PQ==
Casual ML 😎😎😎,r/machinelearning,Z0FBQUFBQm0yeGJVc004ZXQxemZmVkF0UDRReTIycVMzOVF1V1Z0cU5yUGtrQ2xNLWJlNThHSnZWWnBMYlM4cm5FUU40NG4zRUFlTUIxZ3E2Y3h4aTZpN0ltM3ZvSHNuUWVmLVg1dGVYOE8zZEltYXlOT3VmekU9
"Hinton is known to have changed his mind many many times on this issue. In 2010, Yoshua Bengio created a fantastic cartoon making fun of him for this:  
[https://www.youtube.com/watch?v=mlXzufEk-2E](https://www.youtube.com/watch?v=mlXzufEk-2E)

  
Backround: In the last day of the workshops at NeurIPS there used to be a banquet where all the workshops organizers had to tell jokes. The video above was presented in 2010 by the organizers of the deep learning workshop.",r/machinelearning,Z0FBQUFBQm0yeGJVV2NUNjlUMFg0aTcyVHF2aDcxMVdrblpYdEdkSk9KX0dUZTE0Q2VlaDRoSU85WE5xTVI4aWs5ZzdLNU44cGNaclZlYk5sd2Z3SmVqTWNiYjVzUWdUX0E9PQ==
"""The Brain"" doesn't automatically do backpropagation, but anyone who learns new information and then applies that to their own history and answers questions about their past they didn't have answers to before is engaging with their own brain in a way that has the same effect. 

I think it has to be an active process. Learned. Some people never develop this skill.",r/machinelearning,Z0FBQUFBQm0yeGJVN0lhQ0RPUi1lWVJXcUw3UFdhbk5zUjB4dW9OQkR0MU5iS2x0eWVkVDVLLVAtN3RmU1NtMzhRMldtT2xia1J6bi1ITWZjNGI5TldZY0loM09jelZ1eEI3Tld3dFBobkFfMG1kMjdkMm1JSzg9
People showing off their projects that have reached production and taking questions from us.,r/machinelearning,Z0FBQUFBQm0yeGJVS0ljam1EamZxTkpOeDhzMUE0V1pMYTFWcTNyMzdWamJ0eHVDWkxkT0NROV85RTRIbkRVb21iMThtNjd2QjRwN3lJWEtJNVY5ellUQkxiM051UWx2c1E9PQ==
"More.

 Anything that boils down to reproducibility:

Repetitions. Statistics. Confidence intervals. Reproducible code.",r/machinelearning,Z0FBQUFBQm0yeGJVWU1oVjZsWW9WMFBIQ1ZMODRITjhRUU03WmhpM1lNNFE2Z0VvWVAzcW53YTE0a2hxcEx6T0c4Yld1UDRTa0UzbEFzWG15U0RJVHh6Sk54U003QzJqYUE9PQ==
Hinton has since come to accept that back propagation is *not* how our biological brains learn. He has proposed a new algorithm recently called the forward-forward algorithm: https://arxiv.org/abs/2212.13345,r/machinelearning,Z0FBQUFBQm0yeGJVT2dNUzduVllYVm5EaklGUXg3WGF3MkxKNlBlX1FGSkc0bjdHbGt1amZodlpULTdablZjbDRyT2s2ZjhvN0YyNE1qMzZ6Mm5EMks0N05GaW80NWRHVEE9PQ==
So should they be implementing a RAG?,r/machinelearning,Z0FBQUFBQm0yeGJVSjJhZ2dZT01odjRrUnhFZHQwYlY4V2laczN4LXdobkZYQ3JobWVGU09fS250dzdBdHd1Yk9NNXJRclV3RVVrcnBoWmtpdUF6Tk1ZV0kzcGpmTEM0RUNKMF9VXy1qczd0Rlp2UEdPdjRfZXc9
"Not really, just look at supplementary. It's described there in excruciating details.",r/machinelearning,Z0FBQUFBQm0yeGJVZW0yNjJLcjBKenNpN3pPUGk3UktIcGp4NFMyZWpmMkNvc0hlZVY2MUk5Y0FfRjB5a0lGejRKRWlVTEEyYWpNaXpjcjQ0LUVncDZJWXhDLWc5TUxGWW5PeDFSdUxxeUdXajRqM1dkMUU5SVE9
"But surely you realize that this is another, difficult task. first of all you need to learn to make any sense of the auditory and visual signal. Then you need to be able to use the correlation of both to be able to do source separation, then you need to realize that the source holding you close is probably communicating with you, while the bird outside is not. Then, for the example with youtube, you have to realize that the other signal further away might also be language (or more likely, ignore it because it is not correlated with any ""parent"" entity or any other entity that has a direct visual presence in the room).

You are right these are auxiliarly tasks, but all of these tasks are pre-solved for LLMs that get well curated english texts as input. Learning an LLM from raw audio recorded somewhere is much harder.",r/machinelearning,Z0FBQUFBQm0yeGJVQmNudUxiaWJ2eENJbzgwT3NUeU1BMGpfbzdXemc2MkhkVkpnWEFLZGRVdnE1TE9fMGdzVXNuN05YY3p2MU9XZFlUcW9PdWZnR3lwNFhRdUQyMkd5SlE9PQ==
"One of the frustrations I have with Computer Science as a field is how tolerant it is of people (especially those who have made significant contributions) coming up with totally whacky and unfounded ideas about things they have no idea about because they think it has something to do with computation or vice versa. From my experiences certain institutions seem to produce a lot of these kinds of people.

Not that I think the alternative is better, I think it’s much better to have some ideas that are too “creative” than not enough. I just find it frustrating that people will latch on to them because the person is seen as a genius.",r/machinelearning,Z0FBQUFBQm0yeGJVQ2RueEUzb0pNZFBONGZZNVlSQlFBd1pIX3pSYlg3a20zYzJlSWFUcVRJR2NPbDdxSDZCSHdEWTJNR0RUOXBOVUJjRkV2bFNWTkd6MVJmblkzWFJTc2M2RkhobHJrZnFValBBVGVjOXBBQ3c9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVc0ZsX0Z4Tjg5cU56aW85TnZ5UGNpRUluNzlQRDl6ang0bjJtUkt6QUZXOVNmbHVhUnlIUF9jMTA1aTkyYzgzOGVRb09DSkUzcHpnenFTWnhFZ1p5Y1BzRFlNTmZndTg0bjhNMnNhRjdYOG89
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVdG1OLTNGNzB1UFpmWW9iTC0wanJ2WW1Obk51ZkJLay1vVzZEX082WUl2MkFsRDFxbVdmZ3JYc0V3c2t6OEs3VmRQRWRnenI2NDZZck1mb1VaMmEyRnNnS3VQLXFnbFlHYVVtVGRxZFViQjA9
"Training requires lots of processing time but adjusting a couple of weights is done instantly. Haven't hackers hacked Teslas? Imagine if people manage to run these tools on that type of systems in the future to find out the critical weights and then just adjust the weights. If you are ""lucky"" you can do the contamination with Bluetooth or such. There are almost endless attack vectors.",r/machinelearning,Z0FBQUFBQm0yeGJVMkloS2NMckZtd2ZUZFp5VWoxTGNZRHRNUFRGelRBMlJhemhHTEtZS2ZaeldEQWFWSmFINzYtX21hS2hLVlBqSmZhREVTeTVtdmNWVUpEUUkwRXI2a2c9PQ==
"There is substantial scholarship that language is [not learned through passive exposure](https://www.kqed.org/mindshift/60988/can-babies-learn-from-ms-rachel-and-other-baby-tv-shows). So all those youtube videos and background conversations are completely meaningless to the child. It's like training on data that has a random error function, a background hum that does not amount to any salient neural weights.

The relevant training data for speech is direct interaction, actually playing with the child, responding to its babling with meaningful answers, words uttered in relation to a physical or visual activity etc. Depending on the child, the level of caregiver involvement and the age when such interactions become possible (probably no sooner than 4-5 moths), we are talking about no more than a few hundred hours of very low density speech that must be parsed along with the corresponding multimodal visual and tactile input, all of which are alien to the child.

If you think that is low efficiency, then by all means I challenge you to create a model that, handed a few hundred hours of mp3 data (which roughly corresponds to the cochlear neural inputs) and an associated video stream, can produce the mp3 spectrogram of the word ""mama"" when an unknown video of that person is fed in. Of course, all of this would be fully unstructured learning, the only allowed feedback would be summing up the output spectrum to the input spectrum (listening itself speak), as well as video of a very happy mama when the first ""ma"" is uttered.

If you can really prove this is a simple problem than in all honesty you have some papers to write instead of wasting time on Reddit.",r/machinelearning,Z0FBQUFBQm0yeGJVWEtpaFEtNTdQdW1QVElTSkRwT0VVQ3VOUk4tbnVGaHNQaHZWS3dnQTlTa1F2VFJ0ZkZpTzVrQ0tmQ0l0WUJndU9pMUh3dTY3bWR1dTNnR1FBZWpub0E9PQ==
"Anyone submitted in April ARR? I got 4,3,3.5,1. How are the chances?",r/machinelearning,Z0FBQUFBQm0yeGJVYWlMMHVMZEszbktvUnFNeWxqeHpxRkQwWVZ0dkpKMm1VYk5uTzBGRm1mMWtwQjl4SVQ2cVN6U0NaSEVtZFQ1eDVtNXFIRGVGcnUtQ2EyR2wxcHNYcWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVb0RPeUVxRnNybVptZEdDMlN1cDBkQnR6dnU2czlCcnBtS2xIN2F4ZV9iTFBPX21zLVNjd05ZTkxmQTF2R2FvcUpXT0ZlUEQxdEJKWGJrWDU0UjhIYUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVV3RMWmhYOUZxTlVQX2Y4VFhiSkhBVU1aM3NrUXVRVlRtdElSOEtBVjMyTEtybXBURmZ5ZmRVZlBxWHF6ZEFfTDEzcjRabWxXWjN2R1hOam9yOEpmZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVZ243V2tUd1pWTkFPSnlfU2NlcHdraTlvejNOYy1lYlg3MHRsczlMdjBjOUVfSUJVN2dYLTNoSG14ZkMyZURTQThsV3d5TXJhOFY0WXlYTlpTOWU1QUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVUTI4OUVJc2Fzc0dvTzU5eG03dGo5aWFuNTZaTmZhN25iSUhRYnNNSldTWEJyNnBraG41bjRGU3RIMDRhZUFTWVR5RjRrX1hXanl6OHVxY1dZN040Q2c9PQ==
"More work that has its theoretical reasoning set in mathematics like neural odes or Hippo. I am hopeful that KAN will make people interested in splines again and it won't just be another hype field. 

Less work on LLMs. Don't get me wrong, I liked the papers that actually studied the generalized attention and tried to suggest changes (pay attention to MLPs) . But at the same time I saw papers which tried to regression with LLMs....",r/machinelearning,Z0FBQUFBQm0yeGJVak9kWUd5VlBpUXdfY2YzdnY2b0EwbkVWWl9MNWNRaXVBLWVKOWptNmlCZ2NNV2oxZkpkZnVlc3l3bFU5US1Za2dMb0hQMWNBZVhFaXlhZ003dldQVE5SSkFtQ0trbExqX3phZ2JRY242SXc9
"Did you use proper data augmentation? Like RandomResizedCrop?
I remember that in 2016, when I used ResNets for the first time, a network was overfitting a lot. And after detail analysis of open-source code I found out that RandomResizedCrop was crucial for mitigation of overfitting",r/machinelearning,Z0FBQUFBQm0yeGJVdW9vU001QmdWQW9jM0N0WW03dE5GdUw5NlVaWDhRN2ZSa1ZibXJkZFJMb01rc1U1LUQ1cFA1b0Q5bGp1eTh2dHBjT0w4bDNUUnZpTTlqVEdxc1otMXc9PQ==
Ehhh this isn’t doctor level stuff,r/machinelearning,Z0FBQUFBQm0yeGJVN0M5OTJJOEw5NDVkRGF1T0s0R2tWUGhEOEY0ZXY4M0VfYzQ4bmMwRTluM0JfYWc3ekpHdHBNMDlwQzdTWk15R21zOWhYTmpEZ3l5Mm04WG11ODdseFE9PQ==
thank you! I just found detail explanations at supplementary.,r/machinelearning,Z0FBQUFBQm0yeGJVcXBTR1ZYcktmeGNGdjZVejlHUnhTNC04MlA3dXNmejlKX0I5V0hUR1Y4M0IxTGJrenBkdmdCX3pGeVl5N19PYXlLbGtDZnRncWVVR2ZDcnFoVUhWSVo0WENuMl9Ubk9ydDVLMEw5Q0d6NVk9
"https://huyenchip.com/machine-learning-systems-design/design-a-machine-learning-system.html

https://huyenchip.com/mlops/

very general take. not related to specifics of the question.",r/machinelearning,Z0FBQUFBQm0yeGJVaXVnZkJSS283bGR4YU02eS1nRENKdjJGZURoV2lTWUVDT01aUTR5ZXFnbE9HYUp2ZFU3cjR1M2lvZENlcFpxRzlFT0RpTHdtZzgtZE9fLUM4Yk9QeVZad0NMcE5IaVlHQ1U3SENZdW5nWFE9
Any physical system can be described by something as vague as ‘parameters’ that are ‘updated’,r/machinelearning,Z0FBQUFBQm0yeGJVTlIyX01SWEpsMGxMOFhGNEJsMzBOUkxKTTczb292SVpnQnZTVUdWRnl0M3E1S1kzTjVYdDl0cExyQ3ZBWVh3VzhROHhmQTlOQThPYXZ0ME1QYTZkR1E9PQ==
"https://github.com/explosion/sense2vec

Not why what downstream task would you be performing afterwards. but the above library is very good.",r/machinelearning,Z0FBQUFBQm0yeGJVY0RnSnNYUVVkWVRIYjZCbVJUcUtwdnh6blUtN05MS29iRUFzMVZVZ3VHTXNRLVZjS2hrQVc1N3JtVnctcGYybGJibi1XYzhRRm1XT1pOenpvN1AyNlY1Rkt4cnZKSHZ1aElfbWtMUlR1cEU9
"Ehhhhh yeah it is, sorry.",r/machinelearning,Z0FBQUFBQm0yeGJVSUdHWm56SUY2blRWWUFWN04wUjlHTnkwTGQ3ZnNpRHdMaTh1aVJGRUtOeUI0ekJidWFnU29OZWMwcVdPMzRqTEtDRXphTEFoX291Z05oMnBTVlNBVEFINzdoSVhlclRHWkI5VmZrWkxBTjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVRG1fbU5mNVdMeV8zaUFQNTVwZVZRa0RON09tMzB4LTBvdGF3ajByWUpGX1FqdnUxaW5PZmhNZWlpUXhkY1Y3dUlBY0pyVDM5eUUxVFF6ZVo1bDFBTnc9PQ==
It’s really weird how people think that someone who is accomplished in one field should be consulted on largely unsolved questions in a different field.,r/machinelearning,Z0FBQUFBQm0yeGJVM0U1ckZaN0xjcnc5M1MwTnJtVHFscmNuT2p6dUMtaFRpMFRnbWkzdGJUWDFWVDRzTTNFSy0xeFVvRFdfeFBwYWZPZVlOZjhGZDZkQzZPRjZveFpxMnc9PQ==
Sounds like an amazing project but it's hard to keep up and support SOTA models for even a single application. I'm not sure which field you're targeting but you have your work cut out for you.,r/machinelearning,Z0FBQUFBQm0yeGJVcGN0cHo4N1RiTVNzNjJfUWFDcV9BN3V0V1NlR21QYmE3SmtBWU5wZGIxZmNOOUxweVhWbUdUUlRiMlpDenVoT0Z4U0RWWWJMWHE5RFc0aWlrNVBxanc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVWEtTcFl2eXVKOFYyeHh1N2xjTS1jeUhtSHN2SF9QTG1NY0VncUttZGxYdjJxTUdkNWVLRkktek1xSXNFek13VFkxUGludWxmRVgtV2VVaGFPU2VtaHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVeUxuWjRLcjBRcGxDYThDbXdvaU5MQzJiaGM3Nzd2aGEtbnFFLThtbG5yMkFtT1lkRVB6R2hUNF9lZ1hJSzBtb2JNeG1PZUFWNUtmMkl3Wk40M2NZYXc9PQ==
K thx bro,r/machinelearning,Z0FBQUFBQm0yeGJVd2NleThqRUpuN0VSTXBkXzRqWWQzRXhvYW9SdnNvaDNDQ0l0Wk5QWUxUYVJRMGhSMm1GbDZsck9kSzNOX29rVjdSOXpmSkxXdGt6UWlQLUV1NWdMOVE9PQ==
"But Geoff Hinton isnt computer scientist. His PhD is in experimental psychology and many of the foundational breakthroughs in deep learning happened when he was working in the cognitive science program at UCSD with Rummelhart, McClelland, and Elman who were also neuroscientists/cognitive scientists.

Hinton is as qualified as anyone alive to opine on these matters.",r/machinelearning,Z0FBQUFBQm0yeGJVM0NOVFJKRFZHWmkyU0NlZGRfOW1HQVlrTmlOXzVXaThHUzFvdlYzNG1PVEFucnBZa0pmRnBFRGRWUGZJaEd3Zko5UFBKdnUyUHAtekxwYVVRS2lld3c9PQ==
"Hinton is an experimental psychologist. Deep learning started out as a subfield of cognitive science (and he was there at it's inception in the Parallel Distributed Processing days at UCSD), not computer science. He has spent decades studying the brain from a neuroscientific perspective.",r/machinelearning,Z0FBQUFBQm0yeGJVM0Q5YWNaZ3ViTzRFWlZzMEJWel9qS2JaLVhEa01hcTlDREF3ZTVzWUFwSlpRSzJVTkczZU9weGZKZ3k4eFBTRkt3ZmEyTjRZZkUxMEhxb0wwcndKQmc9PQ==
there's nothing unethical about this you just have a weak mind,r/machinelearning,Z0FBQUFBQm0yeGJVb2doUmpxdDFaekhwNnlmWXVYa3pzR3pKYW1aT3ZZZXJGYXhtVmo5TW9wb0Z5cjB3LU1Sd292YV9paEUtNi1nZmZIRGRCVTVFRWVBaU8wQ2RBblNaY2c9PQ==
"To generalize a bit, one of the frustrations I have with academia is that researchers inluding those doing their work quite successfully in their field are very fond of coming up with totally whacky and unfounded ideas about things they have no idea about in other fields. So, my point is that this problem is characteristic not only of CS.",r/machinelearning,Z0FBQUFBQm0yeGJVMTU4NDlJVzFpdkE3UGRIMjd6aVZiVjhfZ1hhc1pkbGZlcGVmWGZnZENXd2ZLQlJjZ2RXZkNTc2l1ZDVWR3l1Y3F5V00wb0RoTXpzZHUycW1BazNjQlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVZkdvMk85aTFTWnVzcXgyQjZnSDM3TlprYjhXelNSN3ltdlBUZm1rU19uX2w0SEMwWWJUajg1S2JVR0dOMFdZN2IxeEpjTFM5Q3V2cHo1UWt6RmhCVWc9PQ==
"It's God level stuff.

Not even doctors fully understand the learning mechanisms in the brain. I'm not sure how any layperson could have a meaningful opinion on it.",r/machinelearning,Z0FBQUFBQm0yeGJVRmpURDdvOWlwS215aGtXVXV1a0Jrb2pyQkZGRUVEUU5Nc3NtbDdsdVRTV1preDlaOGVFVWE1Z3ZveEJrdWktQ2RyMlFhQ1YxN3BlcE5aMGJ5bUpTYjUyczVvaWZfVmpEczVOVF9sUUlSNTA9
"I wasn’t. So, I moved on to training DINO v1 instead. Will be looking into trying to replicate DINO v2 architecture to the training pipeline of v1.",r/machinelearning,Z0FBQUFBQm0yeGJVVjdUNS1RUFp2VWVaZUhqQU9tb3RhanFPS2hxNkw4SkJmT1Y4MUlwWlFyUVdid1pnTmM1UTVDQkNsWFlOSml5WEE2TDJvMEE2M3RBeDBkVGx1TkxMLWJ0RWJWZXYwRGN5bWdfcU82SWpjTzQ9
"I keep on seeing this question about NN and brain repeatedly throughout the years.

I highly doubt it works the same. Hell there are constant discoveries like dendries store memory.

Also how does NN even represent the learning process of working memory and long term memory? Or that our brain long term memory works via repetition, spacing, and interleaving?

It's kinda weird for comp sci saying they know how it works when Neuroscience doesn't have an answer and still an active research.",r/machinelearning,Z0FBQUFBQm0yeGJVbmREbXNGMnN4MnlHUGJCcmJ6ZFRJb09EdjhTTXhoTXhGUjJZVHNMWWZsYU9rUk1yU0xlZF95b0FfQkhRSDRMLTNUVjBOd3NhbGd4UzJfM3pKUEhBTnR3ZnowN3BraXN4bVo2Q0xFdDdTem89
"I believe I've implemented their data augmentation correctly, but please take a look! Here is the data transform applied to the training set and the second transform for the validation/testing set.

    cifar_train_transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Resize(size=(32, 32), antialias=True),
            transforms.RandomCrop(32, pad_if_needed=True),
            transforms.RandomHorizontalFlip(0.5),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )
    
    cifar_test_transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Resize(size=(32, 32), antialias=True),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )

Here is the snippet from the paper:

>We follow the simple data augmentation in \\[24\\] for training: 4 pixels are padded on each side, and a 32×32 crop is randomly sampled from the padded image or its horizontal flip. For testing, we only evaluate the single view of the original 32×32 image.",r/machinelearning,Z0FBQUFBQm0yeGJVUnA4YTNWNTM0RldzRTNyMDc1SHhycXBMbnZMWlNxNjB4Z0ZDLWI3YTNnendSVkNrcFlxZXN0XzNpRXJxWFVSdUpWTGNKSDBHd0lHc1Zqajk0ckNoMUhvWDdiTEpZQUo3TXNSQ01xT1MyMWs9
"The novelty is in the custom model itself, not the framework of using a custom model. If you had taken a quick glance at their code, you'd have realized that they indeed use sklearn exactly as you pointed out. No wheels were reinvented.",r/machinelearning,Z0FBQUFBQm0yeGJVdmtycVVpYjRvcTI5NFg1U19NUXlDVDluQkZIMHV4dmhxUWNIS0g0SWhIeGxqaTRVX3I4OXotUmltRDhwWVF0ZmVBMmdHLS1rTU5fUnllU05TWmo2c0E9PQ==
"Good math discussion will never happen on Reddit until they support LaTeX embeddings in Markdown. People try but it's too difficult to read, especially on the app",r/machinelearning,Z0FBQUFBQm0yeGJVdHhMblUzYlNyRWJDMVJka2Fvbk1KNTNaZHhldWVjbGdnZUpSSTVQSWxxUV92cEt1dTNGQjBNSzNJWVRnWnR3dlF0RVc1NGVQNVRlOTRyQXJZajdpclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVRjNtNXo4N1BTaDU1MXd6eDJhMnVPT3o3WmotYnFOWUVFSk1aLVU2M3hVT1hWRTExd2w2Ylo0TEdHUFQ3S2xvX2VzVDVlcnpkRzl3XzBndFFIeV9WS2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVRE40bjliNXJBNE51V3JEejNPVVNKb0NobGxxckUxYjlkR3hBT1R3Sm53WE5nU1NqOGRocHN5Y24tcWlBakd5YkRpbHRvbjlvU1hXeXVpR216TU1kbnc9PQ==
"Yes, I am aware that keeping up with all SOTA is hard. But somehow I believe that, if other researchers also find the toolbox useful, submitting code of their own models for further comparisons wouldn't be too hard.  
  
For now, I will try to wrap models from other libraries that already have some sort of a model zoo incorporated. For a later stage, the goal is to have categories of models (something like on papers-with-code) from which you can select your task and/or modality.",r/machinelearning,Z0FBQUFBQm0yeGJVOXgyaFQ4X2dyclUxc3BkLXlaVkx5RjMxOWxvQmJrRWdKZFdrQmhsX25YZzg0UUZkNDRHcl84cW1jRTFHZzhXWFN2SzJRTl8zcjZpN0l2UGZWTXhzQVE9PQ==
"The claim is paper's not mine. Basically their reasoning is bsplines are local so adding more control points to encode new information will not effect old information. This contrasts with standard neural networks, where each weight change effects networks response to all inputs, therefore fitting to new information may result in catastrophic forgetting of old.
Btw, weights are not adjusted, only the activation functions are. Their parameters are control points of bsplines, not weights.",r/machinelearning,Z0FBQUFBQm0yeGJVUF9vOTB2OEdBWU8zbFhqdU1PQk11YkxTc1FjbjN0Q0hRLWd6TTctZThobEllRnk0UWg3emV3LXdIU180bjZSUlk0S2djZ0xDSGZFNEJSQ1JON19rYm1YcWM3Nk4xcmlSMXVIb0p0TXp0eEU9
"This is a video of him from 3 days ago, where he says he is confident that brain is getting some kind of gradient. (35:30 onward)

https://youtu.be/n4IQOBka8bc?si=gpnWfspnxCQSB8lG

When asked what is one area where he would recommend students to research on, he mentions finding out if the brain does backpropagation. So he is not certain that the brain does it, but has a strong feeling that gradients are involved in the real learning process. Also it is one of the most important questions in the field in his opinion.He feels that a learning method without gradients will be too inefficient for the brain.",r/machinelearning,Z0FBQUFBQm0yeGJVNXc4bGNzMUh4MDdKQUJCM01wSnAxTC01Tzd3a0lEMnh5TEVUUUg4dUtZMGR0SldfellzTFBZb3pISnNVZUdrRDJ5Mi1QWktqTmlvbmlmUTMzcEo2Unc9PQ==
"This might be interesting for people that are not experienced with ML, but for people that already have been working in this field there's nothing particularly interesting/new talked about in this podcast.",r/machinelearning,Z0FBQUFBQm0yeGJVRy1RQk1wR3Fwbk5iOFBZNkFPbXlIeWhTRktwXzlXTFRxU1VPLWJrdXkya0hCaU1xWXVoX1NrdEdpa0s2UDVSaGRieC1aM1BhZzVkWFlMYS1fUWY3aHc9PQ==
"> you should try to find out what the consensus among experts is, in the field of neuroscience.

That's what this post is about, not hero worship. I am a cognitive psychologist who values opinions of interdisciplinary experts. It's naive to think that Hinton doesn't have insight into human learning just because his work had had more impact on artificial intelligence.",r/machinelearning,Z0FBQUFBQm0yeGJVYV9MU2hkUXBITWN5V2FXSkJnb04tZUlSNnJSbEFFWG83djdpc0xyby10X1B6T1duYkl1WVMwT1RUZmpzd0hxeW9pbUROdFBILWpBMF9jWXZRVTdsRWc9PQ==
"These were the transforms I implemented! Do you think the \\`RandomCrop()\\` here sufficient?   


    cifar_train_transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Resize(size=(32, 32), antialias=True),
            transforms.RandomCrop(32, pad_if_needed=True),
            transforms.RandomHorizontalFlip(0.5),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )
    
    cifar_test_transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Resize(size=(32, 32), antialias=True),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )",r/machinelearning,Z0FBQUFBQm0yeGJVZkM4Q2NlRmJpNXQ0eVNSclB0TGM0S19aOV9zM0tJX21xODJqc2dpdjlKRGY1QkNram9ZSHhnTXdaMjludnZBMUdGVjh4Z0FabTJpbE1FaGJpWmF5cUFkNVFOODJvUFpiazM4X09sWUU4a2c9
"Auto scaling, by far. GPU instances often take quite a while to start, a decent while to shutdown, and inference can be extremely fast. 

So you boot something up for a few minutes, run inference for 30 seconds, shut down for a minute, then you have to pay for all the uptime. There goes your margin...",r/machinelearning,Z0FBQUFBQm0yeGJVaG5mcExma01Sdl9za2RlZ2hMQVVqUzN2OFd5V3NCRXBfd3hiZWZqNnppOGxoY1RXbWNab25XWVo5UnBVc3prcEJrQS1BUUxHQWtreXMtU2xhajFvUkE9PQ==
"Thanks, I didn’t know this, but still neurons must somehow process the signals, is it valid assumption that each neuron is learnable function?",r/machinelearning,Z0FBQUFBQm0yeGJVakhIQWJDS0hXQ3d4aUp4b1NUSGFJWXRLYTd1VWsxazdsa2U4WTlDT3llUWJyVTRKSFpJNkg1N2tOWl81b3k0bUh4THQ3RzRnTjcxMWZmbmliZ0Z1TUE9PQ==
Honestly I feel like people still need to talk about ideas that might seem wacky. Remember that there was somewhat of a consensus back in the day that neural networks were a dead end and we all know how that turned out,r/machinelearning,Z0FBQUFBQm0yeGJVUEFjNVB2VVhHY1VocHQyS3NMSFBsSzdNdnpxVng1OFpnaFNXcFNzY3NOMzFEc25DYmQ4Vjh3MXVYbl9MRWZWLThYTngxeHQ5dXVCN2h4Uk9jR1A5cEE9PQ==
"A simpler (and easier) approach is to add metadata to the data when storing it as a vector. 

In your example ""What was CAC for Product A in the year 2023?"" add year:2023 + month:3 + day:27 + product:A + data\\_type:CAC

Exactly how you add + search on this metadata depends on the Vector database you are using, but all of them have the option to add other data than just the embedding. 

For example with Postgres/Supabase you can store the vector embedding in a table that has rows for the year, month, day, product, data\\_type, etc.. and when doing a Vector search you can specify these in the SQL: SELECT \\* FROM my\\_data WHERE year=2023 AND product='A' AND data\\_type='CAC' AND embedding <=> query\\_embedding < 1 - match\\_threshold.... the real SQL query is longer and more complex but you get the idea. [https://supabase.com/docs/guides/ai/semantic-search](https://supabase.com/docs/guides/ai/semantic-search)

For CloudFlare Vector search it is simple to add + search on specific metadata values, however it's not as flexible or powerful as Postgres since you can only do simple matches and only specify a tag name once.

filter: { year: 2023, product: ""A"", data\\_type: ""CAC"" } from: [https://developers.cloudflare.com/vectorize/reference/metadata-filtering/](https://developers.cloudflare.com/vectorize/reference/metadata-filtering/)

If you wanted to search for data between 2020 and 2023 CloudFlare has no feature to do that, and you would have perform multiple searches and change the year value (year:2020 + year:2021 + year:2022 + year:2023) then combine all the results. With other SQL based Vector DBs you can do something like: WHERE year >= 2020 AND year <=2023

Some of your real-world metadata/tables could have multiple values (example favorite\\_brands: Sony, Microsoft, Phillips, Toshiba, Mercedes) and again using an SQL solution its easy to narrow the search but with CloudFlare complicated.",r/machinelearning,Z0FBQUFBQm0yeGJVcVdfclpQejMtN2VYTFFRdGdITGpES2hSanZ2WGZ3Q21vY0pza0k4WFdUQzRqMVhmT0xFamhyTW9RNFVmMHdIMXU5eHBkTG0zcTBHVUVNZFlMVW1YbklmSWdvVnVEN3htQ3dEUmFPQUloUVE9
nice work! Does this work for the other variants of YOLO like pose estimation etc?,r/machinelearning,Z0FBQUFBQm0yeGJVX25ueFVxcm9iS1VjdzNNZUxTcEdiTENlb21SSjZRa29qWktEaGkzbjlDRGtIU05XWjA3M09weW0xZ2xjUmxycTcwdUFrTkdWWXM3SEJiX25UZGwzb1E9PQ==
"> Just as a smell test, it couldn't have been back prop because children learn language(s) without being exposed to nearly as much data (in terms of the diversity of words and sentences) as most statistical learning rules seem to require.

One counterargument is that we have an innate universal grammar, so it's not necessary to learn everything from the data. But poverty of the stimulus arguments have seen better days.

Another counterargument is that there are many types of learning in the brain, so saying that X can't be done with backprop doesn't preclude that Y or Z can be done with backprop. There is certainly evidence that the brain implements different classes of learning (supervised, unsupervised, and RL) in different areas of the cortex.

There's also the argument that language is not learned through spoken language alone but through embodiment, including multisensory perception (I have millions of different visual perceptual inputs for a given word, even if I've only heard that word a few times) and agency (the ability to simulate true experiments with causality).

I'm not suggesting that backprop is the answer - there are many reasons to think it isn't - but poverty of the stimulus is a weak one imo compared to other properties that backprop struggles with (one-shot learning, deep belief nets that resemble human causal models)",r/machinelearning,Z0FBQUFBQm0yeGJVNjB0ZDlMUV9rSnVUMzlrNWJtczMxQ1hvSFRIRjBIaFZkN2RZb1F4TzVWa2VoclpWMjVVeVVjVE53aXB4Y21sMnVtampaU1ZrNkc1MXZzbHp6b2Jtc2c9PQ==
"He's right about language learning. 


Humans learn a language fluently with about 0.01% of the tokens it takes to teach an LLM. There's massive inefficiencies in current models relative to human brains.",r/machinelearning,Z0FBQUFBQm0yeGJVYzBRRzRtS1JCem9NTzBnc2pVeXRLajNUMzZZLWFoNXI2WjF0a01LT0JwdEl4Q2kzTk9OYVlxZWpJcU8wN3pjbk9iRzhGWVA5RmhoSDR6VTdPWWRNd2c9PQ==
"Also see Filter with metadata:   
[https://docs.pinecone.io/guides/data/filter-with-metadata](https://docs.pinecone.io/guides/data/filter-with-metadata)",r/machinelearning,Z0FBQUFBQm0yeGJVN1lEZEpLVDJ1QVB1aWltR3hzNWRHclYyOW5jZ2FQU2J6REtQNUhhSm4xMllzanBOdER6YWtBVnkxVF9ER08yS2YxamVXajA2UEY3ekpFVU5NZVNCb1dOc0ZQYl8xNno3dWJOX09XdFNGdnc9
"There's one possible bug that tands out to me here. You apply normalize AFTER the random crop. A random crop is going to make pixel values 0. When you normalize after that, the normalized pixel values will be different depending on the crop. Apply normalize BEFORE any operations that can alter pixel values",r/machinelearning,Z0FBQUFBQm0yeGJVTTZoNmVmbTI5b3M3YmVRTzlRc0RHQVYtLXVuNU5kN0lfRW12dTJsQmFvcXFybGZYd2xsQVhIM0NBcDQySk9WeEdWZzY1ZWR3N3BfSFdjT2lNUGNHU2c9PQ==
"That's a good catch, will change that and run the plain18 again!",r/machinelearning,Z0FBQUFBQm0yeGJVQkJlVnlCVmtJZUhrVXAzcmMwdlFQVVFmNFBkeUkzamRoeXpzR2plbGE0cXd3eVFxZkxrUmJnRTY0VW1rcFZOOGF4WXRfT3ZPYnAwY1piamtaa2l5WEU4SUJuaUdKR094ekY1QmppeGFOQ1U9
"Also you can send the users query to a simpler AI prompt to use the AI to extract metadata values that you need for the Vector search. 

So with ""What was CAC for Product A in the year 2023?"" you could make a prompt to ask the AI to determine the year, product name, etc (even ask the AI to return that as JSON data).... then once you have the metadata fields that are contained in the query, you can do a search on your Vector DB using that metadata",r/machinelearning,Z0FBQUFBQm0yeGJVeFdoN0M5a0R2TndXZ3J2NEpGRFJzU0JKOFF4UDZyVUZySU53cl9KMDVyV0xaYV9yZ2lBa0dMNTEwNGdnd2tYVFdhUS1yTlg2NkNYZDlRcDVuTWxmdTdPcVp2VjdpbHlVdm9BSG16aXBLZEE9
"I never pass papers into LLMs. One, it is unethical to pass someone else's work to a LLM to be used as training data without their consent. Two, they can't handle the context length well yet. Three, LLMs to-date are extremely poor at source return. Ask any LLM a moderate-to-hard science question. Get a response. Ask it to give you sources for its response. On average the sources that are returned are inappropriate for the posed question.",r/machinelearning,Z0FBQUFBQm0yeGJVb3pLZFVySWNvVmo3cUhSbGV2RWg3MVhWWnFRclhocmEySkYyMHJadW8ySUloMzVlQ0xIVnZVQWJYQUNSS0xRT0tNT0RBTFpSTUZNWjRLa0UyOTNMR0JIRUNQLXBNeFd0bG44dEhqUUxFUk09
"If I am not wrong, a recent paper ([click](https://arxiv.org/abs/2405.07987)) states that representations in different models which trained on different datasets (and even different modalities) converge into the same representations.",r/machinelearning,Z0FBQUFBQm0yeGJVQ3otSHlGNGNERmhGREZ0ZHBKYVg2XzJsVkZoMHVtaXBRMXBQaHJlM1NSQ0VRUVZzWmRBNWdKbFR6QUZEZS10WlpPLTJLdnBEcWw2N2FUV0x1N3pKM3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVaVRJcXBobWJhZ2xsbndLSWNEMmI2Q0g0Rjdad0QzNzRhRTgyY29CdHdDYVczbGJwTlplNWFUNTJHOGNkLWtPM1pTRnhkNnNCaHE0TzNIbHc4OHZ2a1E9PQ==
"Look I know you are serious but if Hinton gets an opinion then is he a god?

I say this because it’s quite absurd that we aren’t allowed to discuss this in an open forum but instead worship gods.",r/machinelearning,Z0FBQUFBQm0yeGJVdC1tTFRHczZTZENBSEdqVk9ibGZfQ0NQMzkyOUNiOHc2dVVJZ0g4a25pSWFPT3NuaTN5TWdReFJ1N05uMzlqZXVNcUVwQkNvajNhcVo2dk9Nb3Fadnc9PQ==
"His undergrad was in Experimental Psychology, after repeatedly changing his course. Almost everything after that has been in Computer Science. I don't think there's much argument that the ML/AI advances he made (which have been by far and away the main focus of his research) don't have much to do with actual biological functions in the brain, even if the inspiration might have come from cognition.

Edit: Also, it's important to note that a lot of what we would now call Machine Learning or Artificial Intelligence or Computer Science previously fell under various different fields, because the area of research wasn't well established.",r/machinelearning,Z0FBQUFBQm0yeGJVOVF1WWMxLVRPM0JMdzhlb3RTcHRyMndneURkaGd3WXpSUF91YktWZVhjM3dkNC1rY3FNZlZtYWdIQ1hRNFIzTFBoeFZfUFFfYjhPY2haQjFISk1jdVBWaDZxdVpDOXVYa0F2UzFnZHhCRXM9
"Oh absolutely, as I say, I'd much rather CS was on the whackier side than the alternative. It's just that I think sometimes people make quite significant leaps of logic based on what they think is a comparison to computation.

I was speaking more generally than specifically about Hinton's claims in the OP, but coincidentally the best comparison I can think of is that it sort of reminds me of the idea that Victorians used to compare the brain to a steam engine, because that was the most advanced thing most people knew about at the time.",r/machinelearning,Z0FBQUFBQm0yeGJVamxGejFVV0R0ZnVQQTRRODgweXBEMmtjZU43eVpsM25GT2hzQmpjOGtyT1RIeDFjS2t2Q0djSW1kcHBESzBsWHZ4YWoxdHNXb0lPQmhfR0NjTTJENlhCYkFobjZESTJKQy1RRzZJVUVYZWc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVS2dpMzRPM1Eyd2RIU1c4NTBOZ1pLamlYNWVEdzlUdjljR2R6UzRFTjJJbGVxQThLbTBKVy1CcVdsMVhraG5zWmJqRVZsLV9mU3FJZHNUb2t3dTVYYXc9PQ==
San Diego was a hotbed during the AI winter. There were also the folks up the street at Salk like Sejnowski that Geoff rubbed elbows with. The irony is thick. People complaining about perceived hero-splaining without understanding Geoff's street cred.,r/machinelearning,Z0FBQUFBQm0yeGJVM2FVeXBDYmJSeXpYUVNtNnVCSUk2WG9VZDRzSG5qQ25heXlxY2lfT1pWMmd0UWVqc2lHS2kyUVZabG1IaEtKZ18xaHluSGd2WmFTMmJweWttU0xGSmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVV2lFNzdHanduREZkU1hRY3JLTkVHVmtRSFRRb1lacHh5bHdaUno3cmVoZEJwajBua2NqdWJMNElITnowXzJJT3VkMmtGT3h5UFBmUlRSakdnZVNDa0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVOHRYd2J2MThJYV9aY0lHLVJzS0xoNk5pUHV1WXRsZFY4UWk0QkxjR1Bsc04wWEhqVmQ0VUdiSU5iOFBuWkFYMkNoQ3ZMai1STUZZdlNJVm5aOVZtT1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVckljaEJBdGxuRVlpTjByZVVaM25YMlotdkh2V0FYc0ptajFKVFMwZnRSeWxBWHZ2b3FjSDVUTXF1VlJGcC1EUUhFWU9OZ1JJVjNVQ3Vwd3ZGVnVETHc9PQ==
We are pretty much brute forcing it right now. The difference in power consumption is also stark. The neuromorphic guys may have the last laugh in the end.,r/machinelearning,Z0FBQUFBQm0yeGJVbzlydE9vLUNmRm1MZUlha1VXS3JMZW9iV0p1VFY5Q0Z1VHZhR0Ffbll1RXpGU2syTjBIRGVVQ2RpWFgtY3pnMkFFclIzZnFZMGNkQll2amE3bTl6NEE9PQ==
"The irony hits extra hard considering that Hinton has spent decades studying the exact problem in question (credit assignment). Of course his opinions are worth looking at (though recent papers on this topic will generally have more insight).

That said, you shouldn't expect him to know enough about the brain. Neuroscience is vast and complicated even for professional neuroscientists, let alone CS/Psych people. Most people I know in this subfield don't even know all the different types, functions, and mechanisms of plasticity.",r/machinelearning,Z0FBQUFBQm0yeGJVWW1lZmd2bEg0YmZKcW5vQXNmQmxBODBhaFd2NEt0blN4R0hJY0F6bUJ2Q2pOeG16VHRzLW05a2Ryb1JKNmNBNXp0UTZNRzg1LWlXM1UxR0JmUW5yYXc9PQ==
"Elasticsearch has a lot more filtering capabilities, to include dates and compound boolean queries
https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html#knn-search-filter-example",r/machinelearning,Z0FBQUFBQm0yeGJVWjNVcG0zY29VSnV4dktHWk50OUx5TXJaczgyWjg5UEY2MnVMbjNkUEFVTzlsUzJSTGt3dWhyWmt0b19xNk5zLVlCMi15dFY0bDR5amMtRktyRl9taVE9PQ==
"yeah Vector databases are the new cool thing at the moment... choosing one depends on the level of filtering you need, if you want to host it yourself or a cloud based solution, where you run your server-side code, where you run your LLM, costs, etc.

No one size fits all solution... only option is to research all the options for server/serverless + vector DB + LLMs and find the balance of costs vs performance vs features.  
  
Free options to get started are Supabase and Cloudflare.",r/machinelearning,Z0FBQUFBQm0yeGJVc2xOd3E0TWUwUnFwc25NeW14YTVHbHZhQ1M4eF82RDdLbFZ2cy1zdVVFSUNXLWRsZTBKMW13d1dMTUVOMDFZSDBmb3V6Yld1ZjZBeGl4d0xHZkhiSEh2ekxOZXRXdVBFcnZBUFFEMXk1ZlU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVZDdZTVY2UFVaVEd6dmNjYnNwUGpSaTRid01QLWd3R0dHOHBoR2k2ZURUWVdydGVuekxlcXJTeUNSbUFkU2pERno1TEJvVm42c1J5WWNOSDVrU3RMVlE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVYnptSWVNbGFZZU5QT000WWJTUGF2aWRtWExBczZ4NVlReklmM0gtX3pIMEUyaWZQWkh4Yy1iYlVhUS0xQVFhLVhFVmJPRTZXTmdOOW9BSTFQb3hGTGc9PQ==
Let us know how it goes!,r/machinelearning,Z0FBQUFBQm0yeGJVWTdVeDliQllON245LW9YeDF2OEx2elB2V1E2NG9QOTgtQjZqamgyWGp0NlQzbG91aGQ0SS1yQXgxcGs4bThXZ29tWXdpdGJXbzRndkJTRTNSNnBzdGc9PQ==
"I wrote my masters thesis on the subject and my overall conclusion was that backprop doesn’t happen in the brain because neurons don’t have a direct backwards connection. I also found it unfeasible to approximate the updates that were being propagated in backprop: they are non linear and depend on the values upstream (which the brain wouldn’t have access to since neurons only communicate one way). 
Having said that, I didn’t dedicate a PhD to this and my research was very limited in scope (it was a learning exercise about deep neural networks).",r/machinelearning,Z0FBQUFBQm0yeGJVQmJXQ182N3BYU2lpVjFTd3cwSmd0dlNTYlRaVFY4c2tXMGJoOTdiR2NaWHM0THJqa09RSXp1MXBJNWJoeHh3NlNxYW9qTFRqNFllUjA3cmlCeklKREE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVaWttanUxbnA2clJqNXdIOS1BR245U0R6cWRZNWdPMzVMS0tQRk1fb25ULVpjY09ENlo1N1F1bjctUWEtMU1JMmZKVkxtcXNjcjdTc2p3M0pCZ1ppbHc9PQ==
"Geoff largely believes brains learn by gradient descent, but believes the mechanism by which gradients are estimated is not backpropagation, but some other (unknown) mechanism. 

This has become a popular opinion of those who study credit assignment in the brain. 

He has proposed several candidates for this mechanism, including feedback alignment (FA) and forward-forward (FF).

Some other candidates proposed by others are equilibrium propagation, predictive coding, and target propagation.",r/machinelearning,Z0FBQUFBQm0yeGJVSXR2TVBFbWJhelh0LTBtcjg0dWhDVFdxWmFiQ1loNmktSzJNWHViOVpTQ1Jjai1vd2VPcVZwWFdydjY2T3hCMVEteWxFWmxELTdjbDZNVE5qbWdsNlE9PQ==
"phi models are a prime lesson on how to train on benchmarks to make your model look better than it is

for example they claim phi-3-mini is better than llama3 and mixtral (look at our mmlu scores!!!) yet on lmsys arena leaderboard llama3 is top 20 (mixtral just barely outside at 23) while phi-3 mini is... outside of top 50 in the ranks of mistral 7b

not to mention from several people that actually used or ran their own evals knows phi models are bad. eg https://twitter.com/abacaj/status/1792991309751284123

main lessons to be learned:

1. be very skeptical when someone claims to break the compute/perf frontier (see [here](https://pbs.twimg.com/media/GL0RUOAbEAAnq_n?format=jpg&name=4096x4096)). the best estimate of a model's performance is flops.
2. high quality synthetic data is not going to be the silver bullet that makes your model magically x times more efficient w/ flops. data is not compute agnostic
3. run your own evals and actually use the model, trusting benchmarks blindly is dumb

MSR has really fallen off from the days when they actually released good models like deberta, lets see if hiring most of the inflection team will get them back on track in the llm space",r/machinelearning,Z0FBQUFBQm0yeGJVNlJDRGlRUVkxaEl4dmZ2ZThHVFVmTThsUnNSRE1nOHJqVHdUR2o3QlB3VEZaWEtOSDlMTVBKeTdUS1VfLXBkYnN1WDhVeTQxNnZMN00zVHlKbElzM0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVOWZUU2JycEhEREZaT25Yekp4ZVJUX1d4SUpCdXM5Q1lGMlFlR3ZTM2RxcGlOQW4tVDJSR09FN3FIdUx2alhON2s2N3N3T2oxbmpKVVVlbE0tNlZoVXc9PQ==
"There is a big difference between backprop and gradient descent. Geoff does not believe brains are doing backprop, he believes they are doing gradient descent.

Also, this domain is just as relevant for machine learning as it is neuroscience, and I have found the people whose research focuses on the overlap between the two fields have by far the best grasp on the problem.",r/machinelearning,Z0FBQUFBQm0yeGJVaGxqcXVWbG9ZcGJMczNhQjRRRGUxdUpneXhUa3RZNGVDMkdCam1hNHJKRWJDTEctWThFcHlQcDA0dTU3aUlnUWpxbm4wWk45RHBaQ214TS1EUGtpV2c9PQ==
"Hi, I am planning to do a cloud certification on either AWS, Azure, or GCP but I'm not sure which one is generally used and preferred by companies in Europe/ Sweden so that I can learn the one that companies expect from their candidates. Does anyone have any insights on this?",r/machinelearning,Z0FBQUFBQm0yeGJVaTV6U3ZyTTdYRlJqcEhUUUV4VlY2eUlWUWgtR0pMdXZoUUMwMGNEcUNjMjJ6RzR4dEVPNEZxNnYtQzVsZUZRaTFkNnZfZmxkcEl5cWFxTGh0cEZ6Ync9PQ==
I think in the original paper they used a function similar to MSE loss but a little bit different. but I saw an implementation by DeepFindr where he used L1 loss and got some good results. I also wanna train it with MSE loss one more time to see if it makes a difference,r/machinelearning,Z0FBQUFBQm0yeGJVMTJxRnlDaGhhMUM0a1BTVkQ2ZzQyN2dOaU5kc0pEY3BVRnJIV0VFdEdpTmU1LThCT1ozNURXZUpWdHJJTFc3OVhQR0w1b29TY0xIeFNscF9zS0g0YWc9PQ==
He now thinks backprop is better than how the brain works,r/machinelearning,Z0FBQUFBQm0yeGJVTVdhT1JOTDI2SzJFVG9jak9wNHBBWktTVXNRX295eGhoVVVqaXJjSDRDOXlUZmMwQWFvUXRRNF9feWZVa19VeGJJdDVORkktTllYZ2xpTVdjOGhpRmc9PQ==
"If you are in the United States I would recommend service positions that do not scale through the internet.  I personally know multiple Physician Assistants and Nurses my age who make considerably more than me (150-250k).  These people are my friends and I'm happy for their success but they would be the first to tell you they were objectively worse students than I was all through high school/ college and did not put nearly as much work in career during their early 20s as I did for the absolutely brutal slog that is graduate school.  I say this to illustrate that those kinds of salaries are not exceptions for people who are the best in their field they are par for the course with a balanced life.   If you are very ambitious and an exceptional student become a medical doctor.  There's a long slog of schooling but at least at the end of it there is a huge stack of cash (300-500k/year) unlike a CS PhD where there is not (90-120k)  ( Not bad but definitely not worth the effort from a financial standpoint)

If you are not academically inclined go to trade school. Cheap Indian labor will not build American houses or fix our plumbing.",r/machinelearning,Z0FBQUFBQm0yeGJVbFJBV2xMcFh3bUZ3cjR1UWl3M21YSzJpQ2oxUFJPQ1RRQkh6Vm0xWTZ1Q0hFUlBCcnkwM2lZbVNvcWUwWFlvWHhJZVZxblNUeDYzYVlkaElmbS1kTXJIR0RJUjVvZmlKWXUxUC10THFkYUE9
"I would also encourage you to read the book ""The Grapes of Wrath"".  The plight of modern software engineers is not nearly as dire as the characters of that novel, but the general nature of the situation will give you deeper intuition for why what I'm telling you seems so counter to the story you are being told about a shortage of AI talent.",r/machinelearning,Z0FBQUFBQm0yeGJVbENKUUZuQ2Eyc2RnYjVZWlVmY0JReTV2cmNSYU4xN1hFQnR6UWNmUGFfOFFZNERiNGZtbjJJckhaTG4yV3A1eTRRbEIwc1hEbGtCV0kxc21FamxqMkQ1WV9YV25nMThyWHV3eFJmTEczRGs9
"I don't know much about language acquisition; I studied perception (and helped raise two babies). It should be noted that the first six months of a baby's life involve laying a lot of raw perceptual ground work that may be prerequisite to participating in the interactive exchanges that really propel language acquisition forward. Around the six month mark (plus or minus a few) the baby is busy forming the means to make perceptual distinctions and *categories*- like cluster centers in sensory space- that make it possible to determine that a portion of the space of possible hissing sounds is ""s""-like and a different portion of that space is ""z""-like.

The sea of perceptual input that babies get \\*is\\* a ton of data, but the inductive biases for making sense of it are amazingly weak. It would be like getting the raw bits from a hard drive and trying to make sense of them without knowing a priori that groupings of *eight* bits are significant, let alone that these bytes are organized into clusters by a file system...",r/machinelearning,Z0FBQUFBQm0yeGJVTFk4RlY3SVhacnh4ZTJOcDhDMF9NcUo4akRFbFA3SXY1N2FiV2w3Q2ZtY3JKX1l6RVhxanNvTUV0UkwtaVpLVlpDX092OXRuX0c0TncyT01XLVFiZmc9PQ==
Tightly scoped ai is the way to go.,r/machinelearning,Z0FBQUFBQm0yeGJVSGtQVGVJelBwcl9zLVpJUmxZdVJXaHI5SXNnaEpOc1Y5eDl5aVhtdnNrYkhtVWxSanRrMnpLRnJsamMwc2hxVllxeVZMN0FkYTFXbkYxcjNxTHJOV0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVRVB6R1ZrNTQ4eXRVdGNUQjVIbFZidldWM1pSNUZSdjBjc3cxWFl5NzJveGNrUzFQTG1HRm9zaENRS1J2QjYwV3dNaXdjYUZVdTM3NjB1TlYtbFhtcHc9PQ==
"As we are now exposed to technology designed to influence us, we are at great risk of being manipulated to ends we might not understand or agree with. We need to empower individual with AI to help protect them from the manipulation of other parties using AI. An open platform for providing AI filters could allows individuals to curate there feeds and counteract the power of external actors using AI to manipulate. This project is a great start and gives me some optimism for the future. Keep up the great work.",r/machinelearning,Z0FBQUFBQm0yeGJVMUtmOHlzMjJ4WjROZXd6bDNIS3FRX1NVb1l5UnZ2MmJDbUdUNldxTmc0OG5WWHFQUUFZbE1ack9JN2F5M1FpWDNZY3BBOXZoeWRBemFFNW9zd3p6bmc9PQ==
Why is it important if the brain uses back propagation versus some other credit assignment mechanism?,r/machinelearning,Z0FBQUFBQm0yeGJVVFFTZXlMNFJYNVZOc0JVckJncWtlTUFOZU5iLUFQR2NKNHQtMzRRMlZIQmRGSDRvRmdXT2hWUFhpVmhLejUtSGl5cEdjdUhBbkhRR0ZLYXREb1NqYUE9PQ==
"Machine learning engineer? A lot. 
CEO? None.",r/machinelearning,Z0FBQUFBQm0yeGJVUlRrX1QteE1YcXp2S2xsVzNGcW1xWFM3ME5UaFJIaThxNlNFSlBGSkRGNGZQZ2xLN3pVOGpXdXRjTlMtQk9LdlE1VWVuQWZHa0NhRGxiTTdRUVV1WWc9PQ==
"You can learn a lot about the brain by sitting quietly and turning attention back onto itself. I believe most people do not have even the basic understanding of the mind that comes with doing that. Most people seem to identify the voice in their head as ""me"" which is an illusion you can break.",r/machinelearning,Z0FBQUFBQm0yeGJVTzJfeXBwM2psd2d0R01reUlINncwdUdkYzBLT0RoQU1VRXd3NTRTWkEtcHVoNk5GZUdLQkdIcXR1YTFMMVBvd0d6eEIwSm5ySnFTS0dqcTUwZlM2VWc9PQ==
Don't stop getting degrees until you can code the alpha beta tree of stockfish from scratch.,r/machinelearning,Z0FBQUFBQm0yeGJVRElQM0ZTTGhWVTJUYnV5SDlFRnZGTmg2d1d6MUJ1eWtydEdLMFIwS3doN040eFdBNUtEQTVuNUMxZjJGX2RPT1NKcjcxN25ZSTM0QWtUZDlnRnpxd1E9PQ==
">*the reverse KL underestimates predictive variance*

the reverse KL is 'mode-seeking'

>*the forward KL is useful for applications benefiting from conservative uncertainty quantification*

the forward KL is 'mode covering'

  
Why do you think there's more to it than that?",r/machinelearning,Z0FBQUFBQm0yeGJVVmc3V3pUNGNVUUdfM1V2WVhOd3A3YVFyN3d3R0RHYkQzNW5UZHJSSXJtOWVQa1FrMll4bEc1VXVsY3JBR1M0WmIyaW0xVWJ6b213MUtIb2xGQWJ0dFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVSmlqN2xYTUE4RnkxdGs3YUNPeFl6bGdUd0ZVYkczdVZ3RXoySGh4WVR4TDhNaFVHZGVNZmJVSjFKd2FLXzRwMlVBSWlYRXlvR2NoLU1yN0xuMjdMU3c9PQ==
"If you are seeking a highly sought and well-rewarded job in AI, such as DS and MLE, then it is not the class part of ""schooling"" that matters. You really need to pursue any or all of the following: Internships, Competitions, Funded research student positions, and at the very least industry-sponsored thesis.

Trust me on this; when it comes to hiring in this field, no one cares about which classes you took, your classroom work, or Homework assignments. Just sell me a tangible accomplishment that resulted in some benefit to an entity much bigger than just you.",r/machinelearning,Z0FBQUFBQm0yeGJVTllHbkVxMVh1dF95cFZKUTZZZE9CNmNnY1pETnYwd3JFcllHOHJLNFBKWHdMX3NqZ1RpVGNvRlJrbWlYMnVYT3NXa1RRYVRDcTVvWkNaMTlNQjFYMFE9PQ==
"It follows from the experimental evidence for Hebbian learning, but I think it's enough to simply acknowledge that neuronal connections change over time as we learn new information and new tasks, regardless of the actual learning algorithm that drives this process.",r/machinelearning,Z0FBQUFBQm0yeGJVWGhrc0FQOHZNWE45OF9JWFctZVcxNWh4REx2bUpHU0drRkN2MFoxamIyRnc1QUZ0dlM5VUg3QV9PdXp3NHVMOUZrZm5oQ01tTjc3bDFEbHd6aFN3Vmc9PQ==
"Stating ""underestimating predictive variance"" is different from mode-seeking/covering behaviour. The former is about the spread of probability mass **on the data space** induced by marginalizing over the latent variable posterior, the latter is about the spread of probability mass **on the latent variable space** by the approximate posterior. 

Two different things right?",r/machinelearning,Z0FBQUFBQm0yeGJVUGxPOTJncVYySEdISEtOQURWUFpmUFlWbWV4eFVDNWhoZzVHYjFVNVloMGlNdC1Bc1BOeURoUkVoOTNBczdVV1hWUGE5eE9sWHhDWU40a2NvMWRYN1E9PQ==
How would you advice someone trying to get on the ml field to do. Like what kind of projects he needs to do to prove his machine learning or statistical or SE skills so he can have a chance of an interview,r/machinelearning,Z0FBQUFBQm0yeGJVQnQ3R1lpMmJTbFlLSDdjVmE0MW0zUVJpS01tZ19pZnBlSkRCcEFHMkVudXYzVWQ3bTZzMkIzaDNHMlF1cmJQa05ReDlOaVVuQjZ1WnQ1SHdPc3VmNHZCVXk0Y21GYmxnQlJ0N182Q0hob009
"Hey, I'm capturing a disparity depth map using the iPhones camera and wondered how ML could be used to improve the fidelity of the depth map. I was imagining you could use the data from the photograph combined with the depth map to work out finer details. I know there existing approaches like ""midas"" which can create a depth map from a 2D photograph, but is there anything out there for enhancing an existing low resolution depth map?",r/machinelearning,Z0FBQUFBQm0yeGJVRWlXRlg3YnNseFc1dnZWWHRMeFdURHpfRjJlZjgyM0tlWENGVF9YWFhUTUNKZ2phVDdiMDFlTVBaaUFlT2VWZE9RLXpnV05ZTzZXV0prdnl1QTJub3c9PQ==
"That's my first thought as well. And TBH still running on the back of my brain. What agents workflows are proposing (seems to) boils down to replacing programmatic logic (which is traceable and testable as mentioned) with whatever logic is built-in on those llms. So adding to the topic those agentic workflows are inherit slower and obscure (non-explicit).    
  
One popular ""performance test"" I've seen (HumanEval) they compare zero-shot like implementations with agentic workflow, which is the same as comparing a prototype with a full-fledged application. The latter is only expected to perform better. I totally agree that the LLM agents approach are isometric to any other architecture that you commit enough human resources and time to get it done, it just goes back to trade-offs. Please correct me if I'm wrong.",r/machinelearning,Z0FBQUFBQm0yeGJVdGhQdE5wc05PXzIxRDZFMGVBWUlVMU9OY0dCdTIwbHV3TmYzMWdEYkJrYlBqdTJiYl9pYW5USXFwOS1kSmZTazlxem5Yc2NPWDNJR2EtdjB4ZlF2TGNrNHdibjFvV1AzLTRxbFkwa1FwQXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVLUYycWFDTm83WjJkbERMTXhwOUJEUlQtLUprbTkya3VqdzItNWg5c1dlVkNCckUxNTlvTkFFbTdOSFFyZm9wcURDRHViM0Y3YnJfT0xUQ0xfYmo2aGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVbjVzV21maEduXzlPbms4Qjl6NzBubHpoZVV3WTFJbEF4QjU4V1VOUlpXOHh0Y25lOEd4eTNrS0RUN2txVGM4RHJzMlo1WV9vZlllanlIZlFwbTRlNnc9PQ==
"What *exactly* do you want to do with AI?

I know high school dropouts that are “AI engineers”.

Also know MIT post-docs that are “AI engineers”.

What they do is *wildly* different, but the title is still accurate for all.

Picture your life 10yrs from now, and describe what you imagine you will be doing. With that information, then it’s possible to reverse engineer the best path forward of getting you there.",r/machinelearning,Z0FBQUFBQm0yeGJVTGJqTUNEeXd0TEtQRWVEZ1NSckI5RmpLZEwxVS1FNWtFVWxJZmpBb1VUT0d6bGJkUFB4UWtuTXFHZHl2WGxaU0Ezb0c0TXJjeHZic2w3dWtVbkc4bEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVeGRmc2F4ZlNvOXhOeVZTT3h1b2F6MWQ5aU41ODMzNklsQlE1cWRRVUhKX1ZYSUl3cW9WcGF6TGkyU2pBVjBGbEpDRnFTSnZCeGxNVUtTUmltQ01TU2c9PQ==
"> I'm interested in understanding these downstream differences in the context of VI, but haven't found any works that explain these claims theoretically instead of empirically.

Researchers like to ask for ""theory"", but if you're not specific, it's really hard to know what you want or if it's even possible.

Imagine a complex posterior that's approximated by a Gaussian. 
The M-projection (forward KL) will match the mean and variance. The I-projection (reverse KL) will fit a mode of the posterior. If your true posterior is also Gaussian (i.e., in sparse GPs), the KL you use is much-of-a-muchness. However, if your true posterior looks like a set of delta functions that are sufficiently ""far apart,"" the M-projection would give you a pretty bad fit that assigns probability mass where there shouldn't be anything. Conversely, fitting a mode is the best thing you can do with a Gaussian.",r/machinelearning,Z0FBQUFBQm0yeGJVVkpYQ2lrZjFIdjk3ejN3a09IT3ZkVXhqWjcyQ1FVQ3VrdWhMSDZydTdDNEs1N0w2OUJZTjlkYmlYUzhrZHJYbFQ2bTlMSE5HY1NuVk8xd0lPbF9aOFE9PQ==
"OK I just feel that people say they just want to see that you have the skill and that they don't care about the ""piece of paper"" but a lot of place I still see that they require it so I was just curious.",r/machinelearning,Z0FBQUFBQm0yeGJVejZwc1VKeU9EcjZ3allvWXJDcFh6RW5yMEZnVkhNTGJvVFhKWlYtRlU5dTFqSldsbWtyOGhqaDRQZGliNkJQdEUxdTRXOUJkcGp3ZFhxcGFaY0lpNUE9PQ==
My ideal jobs would like a AI Software Developer,r/machinelearning,Z0FBQUFBQm0yeGJVcTNNZkdON2xzVUlYQW9adDRGRUFKM1ZkWlg1dmNiZGY0b2psekMzS1JOTm5SaVRJUlJ6LWNFVk9Nam1GVFNzMDd0bVVNVnZxbTR5REN5S3o5bTlOX2c9PQ==
Brain learns during inference.,r/machinelearning,Z0FBQUFBQm0yeGJVdU9VS2VTTUdvRENtZDlqR2c3LWRBR0NxX2JLa01qQk9BQk5WcmZxVHZUaXFQVGsxaHBEakkwdXdOYjg2OUstVXAxMGt6RVF5YVFZbUFuY3l1dFZ1V3JXYk5CZ0tjLUZiZ1N4UjBVamRZM2s9
"Define ""job in AI"". How are you imagining this job? As in what kind of responsibilities and tasks are you expecting from this ""job in AI""? There are multiple types of jobs in AI so you need to be specific.",r/machinelearning,Z0FBQUFBQm0yeGJVZ0NMMDJhNTJKMUlDUERldlBKN3BYZXNuTDU1UUZLN1NJUFVtU0tqZHBMTTdLczlpMUhZOEFkaElabk1FY1ZlX24yRlZRcTdDQmd2aC1hcnA3ODdMTFZtcFlBNkRhV1RGbThIbDd0WlJRZ1U9
My ideal jobs would like a AI Software Developer,r/machinelearning,Z0FBQUFBQm0yeGJVM2tNY1owaGozSXdTTjhabWZMNDZLTHI0emFMdV9lYlVaVWdLeVVleUU3UkZRT2ZSSGJlcG82bHlfa2MtMEpiSGJBQ0xpS2VBczRpUlZTWlJWSDBHMXc9PQ==
"Be *wayyyyy* more specific.

Because you can go get that title right now, without a Masters.",r/machinelearning,Z0FBQUFBQm0yeGJVc0lvSU9tZDBsMEUwM29QZmw2WXNxeU0xYTNFQl9qNU5DaWVZVGlpOC00YjJVdDVSc21XaDcwX3lBWkFxa0NzYXRDWFNwQ2dOSkF2ZFpfSWgwV1oxT0E9PQ==
"You don't really need a master's but it certainly helps in the labor market because those jobs are super competitive now. The courses you take don't matter too much beyond the fundamentals. Experience will matter more. It's easier for experienced software developers to transition to AI Software Developer than someone with only a master's and no experience. At the end of the day, AI Software Developer is a software developer position first and foremost so that will be the majority of your job.",r/machinelearning,Z0FBQUFBQm0yeGJVOThJUHk4MGZueTdzZ3dnSzNtaWpoVkFpZE0xQ3lPN2lQdjR4YlJiMmFYMDE2WWRCMHhhV2pPQ2RCTVBIRHB6c1BqWjBCOHpEU19RanpTMkp5ZlpiMHZlQU42ejFiUThyNTU4VnRfd0lXWEU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVZ0pmVE9EazJGLUhxSThORzRlZkFmdkJOaW9WWFdOaW12RWVNWXRPTXFSSUtnb016b2tPb2RwM0paSXYwSkFaa2RTajBqUHdfbTNhaGpzbnVsaElwWFE9PQ==
"Yes, but they come out to the same thing in the predictive posterior (where you, as you say, marginalize over the posterior)

p\\_klqp(x\\_test | X\\_train) = int p(x\\_test | z)q\\_klqp(z | X\\_train) dz

would underestimate predictive variance, while

p\\_klpq(x\\_test | X\\_train) = int p(x\\_test | z)q\\_klpq(z | X\\_train) dz

could overestimate it.",r/machinelearning,Z0FBQUFBQm0yeGJVY0NNTExPNkh4XzltdnU5QzVYUEtGRllBS2V0dnJIUFlCdWdja2FxM1VIbTlLY0Q5b2hlaU9lbG5SbE4xbzV6NW1XR3pMdzhxN19Za2FSbGJyaThVWnc9PQ==
I want either be a Deep Learning or Reinforced Learning Developer,r/machinelearning,Z0FBQUFBQm0yeGJVZGQxVjFUSXkzeGoyRVczdVdHMkpOQW5hdWRsaEtQRE16LTg5bUxTdXYyOVVkNDdOSHpUOGpEczdHMlctb29XLVV4T2s4MVFaN3JjcmRJNlRXbjhuYmc9PQ==
Which one can I run locally on my garbage Mac to avoid dealing with secops tho...?,r/machinelearning,Z0FBQUFBQm0yeGJVQWFRRnh2M2szem9DQ3d4OUFZamU4UTdoR0ROUVpXRHZyTmlBcjN4QXZkbjRTTjQwZlVUU19hYnYtSGVISUc1bmxadm9sV1pqYUFuNWl2cVRYNzBIZlE9PQ==
Which one can I run locally on my garbage Mac to avoid dealing with secops tho...?,r/machinelearning,Z0FBQUFBQm0yeGJVdFlIam1GdlAxSE5QM3UyNWR4b0RFQm5fNlFSSURXejVnbFBsdkVxOXZMU3k1TzZZbmZ3UEdnRXZhalBUMTBRRDZzVVlLSFl2dVJmeW5YR2JYcEpOTWc9PQ==
"My understanding is they then have something like a thought experiment ('interpretation' section) where you have an agent tasked with adapting to know domain shifts, ie the agents policy conditions on the domain shift. I imagine this as something like an LLM that you query with 'given this observation and this shift on the environment, like I force X=x, what is the optional policy?'. And it doesn't have to be optimal, just satisfy a regret bound. Anyway, they show that any agent that can solve this task, returning a regret bounded decision given the distributional shift, its policy is functionally equivalent to a causal model of the environment. 

This is a bit idealised, but plausibly you would want an agent that knows how to solve a task given any change to its environment. They have this example where an ideal doctor would know how to diagnose someone given their symptoms, and if they knew some intervention had happened to the patient like they were forced to take a drug, they would also know how to diagnose them. 

They also argue that adapting given you know the domain shift is strictly easier than adapting when you don't (and have to figure it out from your inputs). So if the agent has to learn a causal model for this strictly easier adaptation task, it would also have to learn it when you don't know the domain shift.",r/machinelearning,Z0FBQUFBQm0yeGJVa2NkdE9IRV80dmtlbFdaNEZzcG5MbU5GQ3d1cFVKM3ZIZ1h0ME1DRTk5UzhPRk12cVl1cldDY05WNjI1RVNjejJ2NVAwdmV1RFNUZEpZOE9temctLUh2MzBIR2sySGQ2bzQzR2ZXR2FBdXc9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcFUyejB2SXAtUWpMeU43YXdwMWdmemdpZmlyMFVPMlBPVWkxU1h0Smh0NVZlUlBDa29yWGx3NVZJVm1qQ19yanJBTkpBMUFKLTB4ckIzaWNweVlmdEE9PQ==
"I understand the intuition about the I-projection and M-projection approximating the posterior over latents differently and how that would be desirable/non-desirable for different models. My question is about the consequences of the different objectives on the predictive distribution of the data.

Ok, so being more specific. Model is given as p(x,z) = p(z)p(x|z) where x is 'data' and z is 'latent' variable. Given x, I approximate the intractable posterior p(z|x) with q(z) by either minimizing KL(q(z)||p(z|x)) or KL(p(z|x)||q(z)) wrt q. My predictive distribution over x is then given as p(x) = ∫q(z)p(x|z)dz. 

Question: what is the difference in p(x) when approximating q(z) w/ either rKL or fKL? Anything we can say about the variance of p(x) that generally holds for certain models? Any works that study this question? For example for sparse GP models, where z is a latent function, \\[4\\] finds that the rKL overestimates the variance of p(x).",r/machinelearning,Z0FBQUFBQm0yeGJVcFVCakUtZnZFWkh5NFd3REJ0TGV4dVN5SmkyamJFZ2xaRUgxVGdHUVVlZlFIN0puR1hsZWE5UTR1bnZaSzNkVGlaZGxGa0lfY2lfSUdHU0NYV3IzSWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVYVl3MFFSTWgzekxQRkl1amRZTThFQjRnelhENjZtczAtQkpyNENSZjV1cEx4Y3FBZU9uN3Jjc25jRnBIUklzQ3BIMVFlVWVpWnJoaFVqaXZCeEZyRUE9PQ==
"""False alarm on the phi-3 models (did very poorly on a few offline benchmarks I have), still using llama-3 fine tuned models for a few specialized services. The phi-3 models seem very sensitive to prompts (not a good thing imo)""

That is nothing but anecdotal without more info on the offline benchmarks he ran. I've also ran a few ""offline benchmarks"" for chitchat, and I prefer the phi3 responses.",r/machinelearning,Z0FBQUFBQm0yeGJVSTJtUnAwTGZ3SHRvUFp5TkhjUEt6LXk3TzZiRndwdUZBRmlHZzJHOFF4akw5MVJXRDB4SlVJUmd3U1U5eVJ4YldkQVdUcXRJVTc0cmpZcGpRWUhWZnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVQTdMaEVGRjhoX0xVSVJpTUJkVlpoYkdHbldZNldLQjVqVkZYQnV5UmVSYU5mRlhFQW9YRXVLcjRWb2VjdXZDQmdzNV94Yi1SZ2lvcEtBM2FoM29FaVE9PQ==
"So, I used to have the same understanding as you wrote above.

Though, doesn't this paper \\[1\\] show the opposite? That for Sparse GP models, FITC (minimizes fKL) UNDERESTIMATES the predictive variance and VFE (minimizes rKL) OVERESTIMATES it (see section 3.1). This result is what started to confuse me really and what made me interested in the question. Might just be something specific to sparse GPs though...

  
\\[1\\] Bauer, M., Van der Wilk, M., & Rasmussen, C. E. (2016). Understanding probabilistic sparse Gaussian process approximations. *Advances in neural information processing systems*, *29*",r/machinelearning,Z0FBQUFBQm0yeGJVdkhTWDRGNkpRRFp1bDJXcm9Vcm05N3pxcUUtYWZvYzhjMUFnakNmTEYzZFQ2X09GWHFLN3AwZzhYQzFqSUtxN2JBSlZsT3RZRU5meVpNelhiQS1FWUE9PQ==
"That is an HR (bureaucratic) requirement, not an HM requirement (the one who makes the decision); 

They require it in the same sense that they require the candidate to be a breathing human being. I mean they require that you have it in order to be eligible to just apply for the opening. But to get selected? Nope, the HM won't even look at what classes you took and they'd blast at the HR if they brought a candidate to their attention with nothing more than classes and degrees. With only those, you are qualified for internships.",r/machinelearning,Z0FBQUFBQm0yeGJVUU10X3F1cGc5UnZYbnNBTXZDd2ZUMGtTalJseXh6ZDg0bXYwMjhINmhHc3hjbC1abHZTclhLUFNUYUFaVkZlUFJ2WDI4M0pjT3JzcWJWN2dsNnR2R3c9PQ==
"Can we move these questions over to r/learnmachinelearning or something, its literally everyday now",r/machinelearning,Z0FBQUFBQm0yeGJVNDI5MU13aDNnZVdacE8ybVAzVm1zTmdZSndKV1ZEX3RXbl83TGhVeEpqeUl1NV9tczZseHdNZU5wNi1NVzJQY2RGRkU2OE42djlicDNLQTNINUUwWUtTZGJmRmJtRDBJTk82YzdtSE5HdHM9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVWU9FWnZWOWxQWllqZ2dSSkE1MHdvQW5BYjI5UzhBbmNlQmdYcF83c3FyS2ZrVExEUkZOdzlaXzF6QWE0OHdGcWppTXpQV2ZQQ3ctZS1tUXZ0aXJBVFNLR2dYOHE2WWNMVDVOVDBKTXNOeVE9
"In 2017: ""My view is throw it all away and start again.""


> But Hinton suggested that, to get to where neural networks are able to become intelligent on their own, what is known as ""unsupervised learning,"" ""I suspect that means getting rid of back-propagation."" > ""I don't think it's how the brain works,"" he said. ""We clearly don't need all the labeled data.""  https://www.axios.com/2017/12/15/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524 




From last year:


> “I have suddenly switched my views on whether these things are going to be more intelligent than us.”


>For 40 years, Hinton has seen artificial neural networks as a poor attempt to mimic biological ones. Now he thinks that’s changed: in trying to mimic what biological brains do, he thinks, we’ve come up with something better. “It’s scary when you see that,” he says. “It’s a sudden flip.”



>Hinton’s fears will strike many as the stuff of science fiction. But here’s his case. 


>As their name suggests, large language models are made from massive neural networks with vast numbers of connections. But they are tiny compared with the brain. “Our brains have 100 trillion connections,” says Hinton. “Large language models have up to half a trillion, a trillion at most. Yet GPT-4 knows hundreds of times more than any one person does. So maybe it’s actually got a much better learning algorithm than us.”


https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/ 








OP, are you familiar with Adaptive Resonance Theory? ",r/machinelearning,Z0FBQUFBQm0yeGJVS1h6cGNaWTRqa0FRNWI0VTFVU0x5Ykx2c2NfMjhrdjZrdHc0M2VreW9mZUNaWWx6M2MxcWI1RDQzY3JwMkhzT1F6SHhtUi00amhURF9xVGJkVnhlQWc9PQ==
Data scientist do not require phd in most companies. MLEs are never required to have phds.,r/machinelearning,Z0FBQUFBQm0yeGJVT2psTGRaOUhrSGpIV2RBUmtKbnhJT1dJNHEyWmphVmJpZExsS0IxM3VvZWp1bVFOYkdYdGtwSUR6Y2dnVWJiMENxaFBsTjZfajJ6eElXdVBUemx4WEE9PQ==
Who mentioned PhDs?,r/machinelearning,Z0FBQUFBQm0yeGJVd1ktSXpuZ2xkbFNuWVJBUGhaS1g4ajRHTS1tTFd1MFQ1RGtDWVJyS09kTmVseFhMNGJNVXMxSzlfZjBGS2NDX3gyS0ZYM0ZjX040N3pidko1Si1BcWc9PQ==
Absolutely no need for phd to work in ai. Masters is good to have.,r/machinelearning,Z0FBQUFBQm0yeGJVNHhlMlZCVTBQZlBqdzlfYnRyU2JCVW5ybkRHaHJKY3g3ZXo5Zmp4ajY2dFRIZ2pEUi02OGJLY1FIRHJzeE9OUUhRMW1xVEVsZ0F2bmFkdW8tOElybFE9PQ==
"Your implementation looks fine, and they haven't used scale augmentation for CIFAR10. Then I don't get why your model is overfitting so quickly. 

Maybe try plain resnet-56 just to compare two depths. It's interesting if 56 version will get higher train and valid losses, like in reference",r/machinelearning,Z0FBQUFBQm0yeGJVdGNNaklYR3pqM0dURTdCaEg1WWJlZU9CbkJPSDlmVklISXowbWV4ZWN1YVg2U2ozbGNLNkQ5eWNrMFR4SDdlMmJLM094UHVJeGZxTmlGS1ZVSVNyd2c9PQ==
"""at the very least industry-sponsored thesis"" ?",r/machinelearning,Z0FBQUFBQm0yeGJVODBDd0VVTWtMLTNaMFhhN0plQnRQVmdsMW5zaDgtQ1JMWVo2ZEdJUlRDTHpmdUxLak9VaENsdnRONW9oSVJ5cVFQNVBMQWZCaXhoQ1Jsa0NHWm5pTnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVQlJ3UHA0WGl1Y2dPRDU5a0FQeVVQVExkNFdNNzFtU1ZPWmZFdHBjUHczUWViTjAxR0FGM1RHOTZ0NnhJMTdwY1dBVXBERmhnQ29qN3c0ejk0Zk44ckE9PQ==
"'pursue ANY or all of the following'

Also, , like many others, I had an industry-sponsored thesis for Msc. I made the connections with industry professionals through school till I found an opportunity. It helped me later on in my career more than any graduation project could have.",r/machinelearning,Z0FBQUFBQm0yeGJVcWhOUGpOUWVhZG9YT2VHSmZscGhVekVyT2N0VXluMVFjT2VWU3NObmFQd2hOVE9Cc2xYTUx1ZFExR0ZUbzZOXzF0U3JKUldSUS1xdEFQNmpoT2RHMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVTzE3dGNJNDJpOGdpNVU2ZkhYNnBDTFhPdjF2U0xmbXItSzgwMjFseXloYjF4MTlZUlFHR0lSN0o5T0RVMnR2aUgxcEJ0dVdwUzdsYmpoZ3pNZVVidkE9PQ==
"As far as I understand, what's claimed in the section is that the variance that's left \\*after accounting for posterior variance\\* is underestimated by FITC. Apparently it has a degree of freedom in estimating the variance that the other method doesn't have (namely the heteroscedastic noise term), which it uses instead:

>By placing the inducing inputs near training data that happen to lie near the mean, the heteroscedastic noise term is locally shrunk, resulting in a reduced complexity penalty. Data points both far from the mean and far from inducing inputs do not incur a data fit penalty, as the heteroscedastic noise term has increased around these points. This mechanism removes the need for the homoscedastic noise to explain deviations from the mean, such that σ2 n can be turned down to reduce the complexity penalty further.",r/machinelearning,Z0FBQUFBQm0yeGJVY3NIVzRoMFRQNFJtTjF6a3NfbGdTaFRkY3ZQbC1vNjVsZXdzOTdYYnItaDFYcXVPVVAtM3hWZU91bWc3a0hBVU9XMjB1M1dKcDRyZm5xU3dyNWlWRlE9PQ==
Ah you mean master thesis. I thought phd thesis.,r/machinelearning,Z0FBQUFBQm0yeGJVb0R3QVlrTVFrSmtBQ3d4UnJuTjlDVC10a3hwNXM5el9iTjdpSkpMTFJOZXdwVE5xN2puNXpYMTM4WDRmTE5OUGVyM3BDRVFnZHhOdW40WjVxZUJNM0E9PQ==
"Interesting can you point me in the right direction regarding some of these other more practical techniques to identify and tamper with features of interest, I’d love to read more abt them!",r/machinelearning,Z0FBQUFBQm0yeGJVajVnSGtxLVppcmVfRXdmaTB3SHJpOTJlcjdxWjhyeW9md2xRTDVteUptN2ptUk5PTTllbDV4WmdDZ3dQMW9iWnBhd0dzVHhCRkVWaExzbzUxb25jSEE9PQ==
Would you say SAEs have more theoretical utility? Allowing us to kind of un-blackbox large models for the purpose of understanding what’s happening under the veil? Perhaps insights from these will be turned into practical utility later on,r/machinelearning,Z0FBQUFBQm0yeGJVVFNVcEE0NWtoT3E5bEZ3WkNScGR4OFlNVDAzVUNOTVdzTU14dzJsQUVVU1VzWlZ4aEFoc2pZamZsUEowZDVvbElYb3poaTdQdjY4ekRRem53aUJLUkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVR21qcXZQN1F5dDhmSGQwRjVoOFJSQzJnUEVvdU9PVXBTZGVfdzNreTRsQ2J3dlBIMGhBcXRkMWY0TUZZX0RIbWxvSXpDSlZicWp3d3d0WE5sY090NGc9PQ==
"I have recently taken up a course online on Linear Algebra. The course starts with a few basic introductions to matrices and the operations that can possibly be applied to them. I came across a few topics which i would like to know if they're that important and if they're used in AI? The topics are: Pivot Entries and row echelon form including reduced row echelon form and Gauss Jordan Elimination. All responses are greatly appreciated. If there are any Scientists/ Researchers within this sub, i would love to hear your take on this question.

**TLDR: ARE Pivot Entries, row echelon form including reduced row echelon form and Gauss Jordan Elimination widely used in AI and is it advisable i know these concepts for a career in AI?**",r/machinelearning,Z0FBQUFBQm0yeGJVaHMxQ2FMQlJ5U1Z6V2hSUTJJenBKWkc5SDFZeVNiNFRqMEIzTURUMlczaUhnWXZzTFN3Rl92WnJBbVFaQUZ4S3E5LVhKODV3UUQ4aUZaLXJFb2laTmIzUVpLU2gxMXhLbFExRGQ3TTZQNEk9
"I meant a thesis that matters, as opposed to many others who are just expanded forms of a homework assignment so that you can check a box on your degree requirements. I meant being able to say in your interview ""as a direct result of my thesis work, company X took blah blah actions, resulting in blah blah in measured impact"".

PhD dissertations would be even more superior, but I didn't mention them exclusively and they don't have to be industry-sponsored to make the case.

You might also be focusing too much on the HR requirements rather than on the HM requirements, the latter are what really matters, while the former is just the eligibility criteria to file a job application. It is true that you don't need a PhD to apply, but your chances are dimmed as you will be competing against PhDs, especially for DS roles.",r/machinelearning,Z0FBQUFBQm0yeGJVMVVSNFE0VUxJcFdKNEFGZFNfaDdESnRRV3BhUFdmR0NlemtnLXNrekdGcVRkZ3NQOHh5dHpEVU1uTkVENTZZekQ3MlQyOHNQeVdZU05YQjA0dXZhdGc9PQ==
"Hi, your thesis sounds interesting. If there's a possibility that your thesis is open to everyone for reading or at least a part of it, i would love to read it. Thanks",r/machinelearning,Z0FBQUFBQm0yeGJVcEc2aHR3YXlrYlM4ek9iRXJRV3RQTWxJX0lGZUhDd2lsWjVEdDYyXzhqQkQ4Wjc0Tkt4R0VBbE9pTEFTRVBOdGZKY2M1VU5mcGFrQjd4N2xWMDlKVkE9PQ==
"I am not sure if there is a formal way to prove it. You can probably come up with contrived examples where the predictive has lower entropy for the inclusive KL minimizer. But in general, we do observe the inclusive KL to have higher predictive uncertainty. There are pros and cos though.

Also MSC is not very stable. There are some follow up works that make it stable with experiments on BNNs, but none of these scale to larger datasets.",r/machinelearning,Z0FBQUFBQm0yeGJVMDd0dFJ1Q2pqRFlUMW95VENrQ1JFSmxGNTZHSWxXRDc2LXZXWkFiNzNPOC11Y0VON1hPdHgzYjJRSmtZVG5tbmFSZ3BCUWZfUGVZd1VDSDJLektmWEE9PQ==
Seconded. More machine learning theory!,r/machinelearning,Z0FBQUFBQm0yeGJVUDhoSE1SYnBjMFhZSF93UTM2VkUySlNFUUxTc0tDdm4wR0Ytd3ItUU5JQU5TSjhZWTdmdEFxY1VXUUhVVnZVdzVfNmh6YWo1TDVNM1BZSTVZRXFYWmlIb2cyTGFheVlZSkt2VnJGYTZJMFU9
"For me, more stuff on the mathematical theory behind why deep learning works, why some architectures work better than others, and practical methods for choosing between different possible architectures or hyperparameters without as much trial-and-error.",r/machinelearning,Z0FBQUFBQm0yeGJVV2cxc3pTN0lOTGhZZGJFMWhEbGtCRjNfM3ZtSkZfU20zYVU3YkFHakllbGM1MjFjeEhYMnJjVzhxWlk0b1lWMmY5dXowcDNLNTRzaE1OWEg2SFdXUzlmdGx4dVdwYWRyXzJHWUZPOWlEZkE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVNEJuUHRqcDJ3NUl1ZjhLaGphcTFNN3JkNkpUYldFMlhCTzdIV1JDTlBxNDFxa1FYMHNtQUVWNllwemFpYVYtVVdPNGtWZ1h0M3JhVmNrX2pUZGNsaGc9PQ==
Happy to help set folks straight!,r/machinelearning,Z0FBQUFBQm0yeGJVSWI2RktrUHVsZ3ktTmJXLVhQNDRFaHhIUHNGSE42ZEloOWtkbmVZdkIxZ1dXeWVLXzBlZzI4MEp3VXJfaGpFNWVCQmdJSDF3ODRTVnozbmhuQVktamUxd01Tek9lczlTZGhYbG1ZMnRlQ2M9
Well we do have non-vaccuous PAC-Bayes bounds for deep learning now. So the torch is still kept lit.,r/machinelearning,Z0FBQUFBQm0yeGJVR2p4bWNkUWk0NXBhVkZVN2pSaXBqUUlzS2VNSkFkMHRzTEhGaG1NczcyRTc3WkhPQmE1RUZWUDk0Zng3TTVPV3JnWElMNlNmZEdQWFZpZlYyMmVBZFE9PQ==
Hey am doing my masters thesis on the same.,r/machinelearning,Z0FBQUFBQm0yeGJVSHpPMnhVQ0d0M21mYU1kVzd5M05NR3FscFlxcVRzUmFfSkxxMHBRbTd6eTF5MThRLUh5WGNJRXp1VE1CQk9pUUxkSUY1V0diLVlrV0tEV0NOaHpObE5zQ1Y1eUhPMHNFRkxSclZHZTdwZlU9
Interesting that smaller context models appear to be better across the board. What is the reason for that?,r/machinelearning,Z0FBQUFBQm0yeGJVNmxpV0l1cXVNeEhFTHhwei1vNGJCVmN0dkVYTVh6ZlY4WGQ5SmFpOWdmcTBMd3E4dnpfcFR3VFBFOVZPVmVEUXBidVRobms5ZG1MRlRXR0IxeVQ2TFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVVVNkRmFSY2tEYWYyNjZITTlnU0FKTy1LX25OQTVsRWhnc3hXSzdxSzZWRDZ4QXdvM3FxbE16LVVERzFTUWhVNGpLbU9sRXdTMkgyeFZmNEM3YlVZaVE9PQ==
"Cool, what papers do you use?",r/machinelearning,Z0FBQUFBQm0yeGJVdmk4NWluUmdzbUU3ZTN4TGdrdF95OWN4RXRkLXNHY3pSSjlzdl8yUVF4VFp1MmNEcVlXdng1Wk5KMll4VjBKdTJyc2FBR3AzUFVucm5RdDBnWlJoNWc9PQ==
I think this wave of investment into LLMs will prove to be a mistake. We don't have good enough hardware to train/inference models large enough to actually be reliable. Decades in the future we're gonna have insane GPUs and we're gonna see GPT-4 the same way we see Gemma 2b now,r/machinelearning,Z0FBQUFBQm0yeGJVUTVfbl93RTBPZFpnZ3RTQnZVZktrVGZTZmRVZV85LWRYYjNGblI0Rnp4SDdFaExLTnBIbmxUV3BUUmJ2UUZ1Yzh2NFAteGJxaEF1d2NRTWs3YndRd1E9PQ==
How does this differ from diffusion maps and the large body of work built on that framework?,r/machinelearning,Z0FBQUFBQm0yeGJVVEh2WHVzcGR4SDNQODVaT1dmb29pbXZTU1JpRmU0bzkybmtNYTB5cXRrUzNLRnBOZjVZSV8ta0JVbXlTVjVsVkhJM1dGYkh6aDlTS3BFdnhhdGNGRFE9PQ==
"I see. Thanks for noting that.

I wonder this behaviour is fully explained by the structure of a sparse GP model or whether it is a result of the choie of vi objective and thus could be observed in other models as well...",r/machinelearning,Z0FBQUFBQm0yeGJVLXNPcVdVanFtSGZmMW44RWlQY0NpMzlGZU5rSUFyRFlmZFRNQllFVnVuRlVadE9hRU9kdk5DbjRIODBfd1B0dThJb29odDQxUk9GSklqX0ZSd1NFbXc9PQ==
"> ust as a smell test, it couldn't have been back prop because children learn language(s) without being exposed to nearly as much data (in terms of the diversity of words and sentences)

That's not obvious at this point. Look at, say, [Vong et al 2024](https://gwern.net/doc/ai/nn/cnn/2024-vong.pdf ""Grounded language acquisition through the eyes and ears of a single child"") which is using (backprop-based) NNs and comparing with children recordings; or [progress on BabyLM](https://arxiv.org/abs/2311.02265), or [chickens raised in VR](https://arxiv.org/abs/2312.02843), or in DRL, [disabling human priors to compare learning speed](https://arxiv.org/abs/1802.10217 ""‘Investigating Human Priors for Playing Video Game’, Dubey et al 2018"").",r/machinelearning,Z0FBQUFBQm0yeGJVdUMxM2J1S3NkNFR6UWNGXzV0eVVtRjF5QUx4M1VjeFl4ZFVSeHc4QUtvQWNTd3prdXNhNVZBczcyalpjbXE1cF96SWEwM0JNTjRQUlFWTW9sODhsMEE9PQ==
"There's not supposed to be immediate practical utility. Anthropic has some safety goals they would like to achieve, but the main purpose is to learn how LLMs work.",r/machinelearning,Z0FBQUFBQm0yeGJVa05VQU5KQ2NkY3hRdkRHWjBnSXF0eXNsLUJXdGdrRHI0YnFlQ0pYVEtDaVVxR2ktTzFYbUUzSm1pdUF0N1dOaTVpaGUtMWZXZGxFb1EyV1ZtbmRoUkkzeV9KV3E1bVNPazR0aDVtTHlOTXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVSHBCNjM1YTc4bmgzTGRtRzh6UmFGMFhkeEZTdUhHeW5KOFFmQkpnZ3VtSkI4TTBjTjVUOWxqblo3Q2V5aVBCN3hJbFVxOS10cWVRNWFGY3ZONG9pTlE9PQ==
"Thanks for your comment. Any interesting thoughts on what the pros and cons are for both objectives?

Also, if you have any references to point me to as a starting point, would appreciate it.",r/machinelearning,Z0FBQUFBQm0yeGJVT0hYZ0h1YmFESVFjNWV2b1lTekVyR0R6SFVCVENSOGRLLTdObFRwZGVLSHo0RC1xQ2JnWFRHamJIbzhad204RzBPRUtlQUcyeE9zdHZyNWczcVpXaWc9PQ==
"Frankly speaking, the inclusive KL will eventually [fail](https://arxiv.org/abs/2103.01085) in high dimensions due to mode mismatch. In low dimensions, it could get you better calibration, but often at the cost of accuracy. A weird exception is BNNs. There, the exclusive KL is known to be [bad](https://arxiv.org/abs/2202.11670), but the inclusive KL appears to be [less](https://arxiv.org/abs/2206.06295) pathologic. But again, the problem is that MSC-type methods don't work with minibatching. There are alternatives that do work with minibatching such as alpha divergence minimization, but these were recently [shown](https://arxiv.org/abs/2010.09541) not to work. So there are some interesting questions left open.",r/machinelearning,Z0FBQUFBQm0yeGJVM2JHajRIVjBQVFQxR1M4ZjBPNmZodmt0NFNCWFNIOUJuOHBIVVZObGo2QUphaTdHM1lUTWwzUFJVMU9DVDNBN1loNGR4YlYtUzI3cElXUkhWdHBJVGc9PQ==
"This is great, thanks a lot!",r/machinelearning,Z0FBQUFBQm0yeGJVZnpzTnJMTXlOOUFmZGRzSVhfd1hvMGlHUEU0X01BMlVlNDd4NGV6Q3ljbGdUNno5MV9KLXRyMjNmelEwT3dyclQ2NTBxcFdWM2sxNVZSUWxZc1d0Q0E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVbEU1UVJxaFhHSkg3dUlKc3RIT1FBSGJjT2R3VnhHQ0JlTnEzYjJUMGVnajhKS082dU1EZEFQTkZ2TTFYclJ4MVl1eFdfczlvZkNqU3V3c2ZJX2xqRFE9PQ==
Someone else came up with the method 6months earlier. Hinton might have stolen it. Hard to say. https://proceedings.mlr.press/v162/dellaferrera22a/dellaferrera22a.pdf,r/machinelearning,Z0FBQUFBQm0yeGJVX1JMcVdtYzY1cG90eWlFR1hXS3BZaXdaNnFzbjA2enlrOWlGQkxxdG9QWHdaaXdiVW9wUmxtblR0TmliWGUxcnNkcVRSQmd0djc2U1hVVm4tTjlwMlRfWDVPODlsQUhjZF9FZ2RMOGlxZE09
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVQTFNVXBia3BPZGtxY0s2dUpjSDBkNlRoM0dnelgtQktRUmdja0liZFBwa29TaXI4dGVwZkhncWZHR2dEMi1nQmF5YnhkeTZwUWdMbTBGYllHVHlhQkE9PQ==
"My reading is that it has little to do with mode-seeking vs mode-covering, since there is no uncertainty about the mean function in that example anyway. The heteroskedastic noise term seems to appear due to doing EP, but I'd guess that's due to the combination of EP and sparse GPs. Maybe a good question to ask the authors?",r/machinelearning,Z0FBQUFBQm0yeGJVelo5TnQ0c0N0bVA0Vy1GWE83eEt1di1RR2Rnekx4cFJHMUpIUXh3U2E2OGE0WXBKY2N4aEFQS012SFBiYkxvZkJ5QWJxYU5fbGFsSElqdDREelQ5Umc9PQ==
"The plain18 error rate still looked pretty similar after the tweak, but after coupling all the error rate of the models together, I think it is starting to look pretty close? 

I edited the post to include the new graphs after the change you suggested!",r/machinelearning,Z0FBQUFBQm0yeGJVZl82NlI2aG1XOEhtTWVCdmFyeEM4Zzl6LURaNUc2NnZMV0VfSmFfN1B3a0U2UU9tLWoxOU0zbGxKOVlRYXBhVFF0LUt6OEVIUVpqS3dobkpnZ1ZPeV9hbHU5V1hTNU4wMmVrS3R4eV9rejA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVYUszN05wcUt4aTdCNTlpQ2h6MW1UUk1EaVlEZndQU08tQXZRNWR4SDlvUU4yZzJELTktMlJCM0U3dEpqeEFuZkhwNGpSUmExVHVPTk5KQmN1UDhkbHc9PQ==
Adding a new label for negative samples seems like a great thing to try out!,r/machinelearning,Z0FBQUFBQm0yeGJVMUhPbmxOUHN0SnY3ZGpyQlotaGFqVmVyLXRveHJOcXJfem5aeVF6b3d1eUxFZXFxazVTdUN2OTdDRzVOWE1MUXBZT095Z0F6SnA1YTFMU0p3eXNqeUE9PQ==
Is this due to lots of usage from lots of users?  or even at the smaller scale of your application?,r/machinelearning,Z0FBQUFBQm0yeGJVdkttdFNDd1VQY2J3N3g3eXlnUTJLeGFrUFZZQlBBcHhmakhUX3BmcHFYV05YelFWSGxIV0wtZzBadEtSb1lZaGNyUERRQzRWMHVGYVF6eWhMV0p1YkE9PQ==
"OP, what are your biggest challenges?",r/machinelearning,Z0FBQUFBQm0yeGJVUWJoRWVuNmozdWVsZDJxUEtscmwyeE9naHFzUndIOE1maVZSdURtbnI0OXhkbjJ4aWRlc2o0NnkzOUY3MlBGYmVnakRBMjhfcnZIZVN2ckhTV3pLc1E9PQ==
Then i guess this methodology is better for a more exploratory approach to understanding model internals rather than actual fine-tuning of outputs. Steering vectors and other supervised approaches working with labeled data are still bread and butter for practical uses,r/machinelearning,Z0FBQUFBQm0yeGJVWGJGeUt3eUk1eVVSNDRFN2NGejVSeTZON0EwMEpkZUdtV1BDVUNob2o1RUpjT0xqSHUzbHZyYlZwNFdKb1E5ZHRrNnlDdmdZemF1R0NvSVV1Vkt3VXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVaVFGZG9DMVlKcjdhc0hiSE9VRXc4eUFsZ0Q5eTZuaERqWEhVNFZuYUtIR2xuc3dXSUV1c2xFdVhZSFR5d2FlSnFYRWlhUkFHT3pOZXFjd3Q4MDE0bUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcmhRLTJoR25QZld0ZnV3emtUQUZqREF0dEdHbndSRS1jb0ZVNmd0QlFQdjVUR0RDbmh0Q0Y3NkVQT3M2VEVwV0htRDlRQzdmQVJuVU5jMWhCcDlJelE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVUnVtME5TZDQwZktYaTQ3emFjWEJtQWM0amgxazVJUFAwRzBSUEYwcTk3MzFaLVhZRkJxaHlqUi14ZEtzSGxFaGhJSGxNYWFGekpKMlNNeWpIcU5EWFE9PQ==
"It depends on how you like your learn and how detailed you want the information. 

I enjoy using podcasts like TWIML (and others) they have lots of guest speakers and cover a lot of things. But it’s more of a breadth and less depth. 

But i find it great to find out about things I didn’t even know existed and then I can find more detailed information if I want to.",r/machinelearning,Z0FBQUFBQm0yeGJVclFCYkxRb3poeGNjSFNoOGlCRlM0dGZuRUFTZWM2cy1IeFZOZDdMWVJ6ZXljamlPWlRqOVJvQkhmbVJyNFQtaVRkTkk2UXVPUERsZ2VZOGUwanZHazNOWkRDMlV1WmNsWF9qdUltZHMybk09
"This is kinda like the attention version of the idea behind DenseNets. DenseNets never really took off because in practice this is kinda overkill. I think there is power behind both ideas, but i think the really future viability of N-way attention and dense skip connections is as a starting point/viable limit, and then using some sort of architecture search to prune the connections/heads",r/machinelearning,Z0FBQUFBQm0yeGJVY001Y3JsaEJiOWtaVzVSaGZQbHdFUk14WVgtT19lcWhMYlB5NjFFVjFYMGNGY3MtQWtGcTlCUXlnTm8wajJFTEVvcm9zdzhDTGNqWU5vekVkQ1RWemc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVa0ZIN0swNU5qQjd0RXNWOVVXUWxlQlBnQV9TYlRJYzQ1R2UtdFZtYUkzWXYzS3ZyTjhsSk1NRWtodVB1d21wanB1bm5ZMXlQTTF4TmgtdUpTM2g3ZFE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVSnk3V2pDTFJtY0FJUTdURGdNUE1LNGZHSmtUZ2Z5RENwY1pxMjBNMnZNcWVmeXNqSEMtRlFkb1dNOGR2XzFFN2dVcm5KOHRKZGk3UC1rNkdObnR3V1NvektrTWRXSXI2UUFxei1KY3N6MG89
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJVcXAtYzVTXzUxY1dhd3RyRFV5NElwV3djUDFBMnJBSEJ2UGZPZGlaSXVFMjhhY2EtZk9od2lkcTRCaTEtR2tScHRTdW1RMV9qN0pEdnE5ZWlYTUdSTW1pYUNWaDJxVkdDOFBUSjVmc3BUQVk9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJVOFNXc2ktY1NGbUd5SmlQOGpiQ0ZDTUpIaFpzR0N0djY5OTgxaFYwdmtEYk02ZUZRSEVwbTIxcUdHWERiZ2V6UVBWcnVfN2EwTmVOaWxnT1V2YnNuN1RUb1AzVWhZS2ItbUwyRTJQVFhYaTA9
"if you're going by chat as a benchmark there's clear evidence that phi-3 is not llama3 level, just look at chat arena elo...",r/machinelearning,Z0FBQUFBQm0yeGJVOV9XaDNhMU5PSG40X1dRNTl3empKbkpCRXVCVnFQODF6aGx5TVMyOW1wZzZOSkU4cnRZOWtybGxtNDVVbmt1RW5rbEp4dWZUZURYamthZXhNRlduS2c9PQ==
"The interesting thing about this approach is that it's unsupervised, so you could theoretically create a dump of everything the model knows.",r/machinelearning,Z0FBQUFBQm0yeGJVMk8yc1JHSm1Nend1ZzNqYzA4dXlMbFNHS1EyUGVoV2xxblA1My11eUFVdHpDWllVb25YRTFXc0E3cDdjRWNVc1lNOFNfbnZpN1B4SFAxaDJpaG92V1publNMYzIya29NbEN2SmlRdllHb1k9
"Are you wanting to pipe in the CV data in realtime and get realtime inference output as well?

Maybe describe what you're trying to do in a bit more detail. What model, what source, what desired outcome",r/machinelearning,Z0FBQUFBQm0yeGJVZ1drcDJZRTc1REFoQjBraktWZFhDaE9iQjItakMySjNWakxQT2NyeG5vYXQ4c3IxM1c5QUEtQmhGSUJSSy1ReXhrUFpzb0wwdWNMdWZiQnpvNzRldVE9PQ==
Mine is more on generating sign language,r/machinelearning,Z0FBQUFBQm0yeGJVemg3NGJFZ1FPSS1xTDRVMkNCNmpzVDQ5anlqM3kzRDJDTWZjR0pFR3NTT1U0bVFnRkxpcG11MnZ6T25vS2Y0ODdXZzYxMTdzcmJYa0c4Rlp5VEQ5MEx2MGZFS3pIWGF6bUFHVmpxei1ZdFE9
"No, there isn't. I jsut gave you stronger evidence than the tweet to the contrary.  chatbot arena also doesn't measure ""chit chat"" It measure human preference for responses from instruct models, you have little idea what the criteria was beyond human preference. Most of the samples in the public datasets are assistant like responses, which trend towards long and wordy, and are single turn, it is certainly is not ""chit chat"". ""chit chat"" would be more like multi turn rp, nothing in particular and very casual.

Phi3-medium instruct is also easier to get to follow new patterns with few shot in comparison to llama3-8b",r/machinelearning,Z0FBQUFBQm0yeGJVbzB0c3hRQkFxOU52M3JmMVZUNngwU2gtNkNaaEZOQ1pMeHJZOVVFTXZNUXNXT3Z3V0RKTjlCQ3B4SGhISFZyTVYyQkI4eFFXOFJHUTdiSWtiZXVZMmc9PQ==
"Table 8 has that info. It's an A100, using bfloat16 as the dtype.",r/machinelearning,Z0FBQUFBQm0yeGJVaEZDWUtla19zVllrYTViU2NFMURmR2xnVWd4SXZObnJRX183UmRwUVMzRDN1aC1oSUxvMW5Wd3ljZEkxSHIxV3Rfa1RSWkJxNlVuUFBqM0x0NHBHSzFtZ05YSDdjcFNXY19HX0hLMmplYmM9
Isn’t the major problem that to estimate the forward KL you need samples from the true posterior which you don’t have?,r/machinelearning,Z0FBQUFBQm0yeGJVTXRfeXA3YnhtWmxZUjlwNzhEMWNuQmtoS2MySGlVdEVqTnJXNmtoTERYTVlYd3RWd20tck9YdTdnN0E3Uk9wNHdlWFkxMmpWOE1xaFA3c080YUx3RUE9PQ==
"It has become less relevant because NLP has taken the crown as the hottest field in ML from computer vision and it's way harder to quantify their performance.

And at it's core, paperswithcode was the place where you went for quantitative comparisons.",r/machinelearning,Z0FBQUFBQm0yeGJVR1Q4UlBYT2JiT3VSS1FrSnZOMXY4SE9HeWFSeHRvN3R3anlPRDZGcVU3OXZlcW9hc3l3XzhlUnA0UE5NbWpyWldGSWszemhJTmVDYlJweGlLZTZWWGFoaTVIeVoyRGdncUVKQVpZYy02b289
update with visualizing attention maps in the decoder layer: [https://github.com/kaiyuyue/nxtp/tree/main?tab=readme-ov-file#examples](https://github.com/kaiyuyue/nxtp/tree/main?tab=readme-ov-file#examples),r/machinelearning,Z0FBQUFBQm0yeGJVUzhmZmNyTlRwam5ZTlRhOFMyajZZanplaEstMGd1Z3ZySFZOcGJQbHRmYlNsSldDNlR2cFhLR0J1LU1rT2c1Qk9wMVVVb05YWEczU2hBX2pRUTZaSFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcjJrWE1rOXJrdzBULWdUV3BnTXUwQ2hObUJfSUhEeDJXcnpGei1Kb2tTY2ZfeUpia2IybWJVX25pQ2NhNF81NEg4dlRLTVNaVEVoODFtR0QwcXhvTHc9PQ==
What do you guys use to generate the benchmark data?,r/machinelearning,Z0FBQUFBQm0yeGJVZE03SFdPZU5mU0lzM1R6WGhSUWtjbW5YOGJzSzZsWV9HbG9RbElxN1RDMzlvQllRTFJudkxSTmhVNUZ4M2ZHenBUUklra3JrcDJjUVpzbG8weklfM2c9PQ==
"Based on the fact that different architectures are topping out at the same error, I would think it's something to do with either the data split or some common operation shared between these models (like the data preprocessing pipeline) it'd be better to post all the code",r/machinelearning,Z0FBQUFBQm0yeGJVQkFDb2tuV0dVb1F3Q182U1B6dmhITHpscmhJa3VveFcwU1NtRkhjSjVLQmY5MmtVeGtpd3MzNUJBRjczTjhvWkhHdGlwS0JFbFZ5YkpzZlJoVnRUdkE9PQ==
You gave no stronger evidence. If anything your evidence is much weaker unless you work with llms for a living. People in the know knows phi models have always been paper tigers,r/machinelearning,Z0FBQUFBQm0yeGJVVFNUUkZLS2wtVy1oY28zaWNaVTI2eWNCNjdybjNwX0Q3LVVOaVdIeHlwUEtkU3dOT1ctVmRiTUliM2JUSDVvaGM5dXcxMTlKaW5iU2t6Rmt4d0FGVkE9PQ==
I've always found it to be somewhat poorly maintained. There needs to be more moderation on papers which don't actually have code or repos which said they would post the code 3 years ago,r/machinelearning,Z0FBQUFBQm0yeGJVeG5VN2VOS2RPSC1kLVhqQk9MUE90VWZERWF1eENKT0o5WElSTjhGeGpHTGtZNWstR2pNUGJONms4SFhfRzJzT1o5Mk1MTW9pR2dUNmRQazBwYVJ3aEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVQXBhT20xQzVFYWt6VnJuclRsdjg1VzB4bExYY3kwN0Q2ek81VjdRSXExTDdZbEpLT2JkTjFjR0Rqa3dQWnZZM0tZRG1naVZXZFlCOXBlcXVvcC0xVFE9PQ==
"I just use the website for the ""trending research"" list. Sometimes I find some interesting new papers.",r/machinelearning,Z0FBQUFBQm0yeGJVSXhnLXBvUEZwdU14dTVnSUFTMW1WWjVING80UGVtY1VZcVpaLUJSd3hXUWVoU0tDM0hXX0RtS2RTMFhwUXRNQjlNR0MxeElJeUlUUmtNNzhQR3ZtQjh3Tl9yQWVJT0Q4aXRNQVVGdkpjdmc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVUHZHYUlrQTVDRGR6YnB4TzNUelF5TTJldVJ3YW9WVkxsNE00OG9PTmlSYXAwOGZXRGlNTzFTalpJbk9QMENyQnMzbllDa0tmbTBRamtMTllTMERMbmc9PQ==
"It is not maintained properly at all. The major problem for me is that they only report raw performance metric, with no regard for actual experimental procedure. In graph learning, you can take 5 papers and get 10 different testing procotols (no joke, there are papers with 2-3 different evaluation approaches). So just reporting ""a number"" is meaningless. In particular, they mix papers with no test set (reporting only validation set results, totally overoptimistic) with those with proper testing.",r/machinelearning,Z0FBQUFBQm0yeGJVS1p5SEt0ZDZNWm1JN2RTNmlSOVd0Ti1HUzRLU1ZwMENkOW9EVWxQTTRUdW1PNmhUdklGOVVzOEl2R09qdUxIN0dDRW5UVmtRYkZxa0hCc3hrMnVCMGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcFM4RU1VZWMtazhUVFlabGZDcjIySXJuWWpiUW5iZ1lNcVVxYkN0cFNNaHZWRjNpSmY4TnI5XzJjYTUtQy1ZaXF4bUpYR0ZZNEFlaUV6bTFpaEVKTXc9PQ==
It’s still live but clearly has been abandoned - they used to tweet and put out a biweekly newsletter. Both stopped in mid 2022,r/machinelearning,Z0FBQUFBQm0yeGJVY05COWdRdW5QRDVIeXUxSGlsRmRlcXpWVHIwRkJkUGNLN1RzdEJfaml0UDN5Sjh4NEhMQ05NMW5aR1I2QWhWc0dmajVPZlNPUXBlTF9ESUdJRVdXQWc9PQ==
I found this resource helpful - [https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/tree/main](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers/tree/main),r/machinelearning,Z0FBQUFBQm0yeGJVSWs5b0hodHhxT1NlOXhIUzlNbEMwXzdsYV8tYmpac0JPRVNCSzB6VmsxZ1RubVJkUzlRSXlraEN1LWtTX1dDVG9MVkFaY09WN0otWEkyUFF2Zl95aXpTTm41UmFjNmFUR1FWTUF0NGZFdlk9
"Oh damn. Reddit supporting LateX embeddings would be huge - but somehow reddit is not innovative enough for stuff like that. Their business works, so why make the user experience better ...",r/machinelearning,Z0FBQUFBQm0yeGJVWUpfTnBxVDdxNnF4eUl3UkxlS0RobXdhNUV1TWFDV1hIWlo5dUpxSG05Z2NGdm96cjY1Y1VSSHJsQmVyWlFTaXRKSEhOeDg0andtMUM3cDZlZlJtd1E9PQ==
I choose to believe this is just a Phi3 model and a Llama3 model arguing with each other.,r/machinelearning,Z0FBQUFBQm0yeGJVX1NyaV93LWZyZFF4aldJTFlyVHBxWFYxQmp5ZTNHVDdIUHMteUtyMzRHcER5TF9fdG1ld1h6SGFSR084TFNYc1VVUi1VVk9iT1RtS2Z5c1VaQTZ1TUE9PQ==
"The brain is the product of millions of years of evolution. In many cases life converges on the most optimal way of using resources, and can be useful in inspiring technology to do the same (not always, you do get cases where evolution gets stuck in a local minima).

Also if we better understand how our brain learns then that might give some insight to teaching techniques.",r/machinelearning,Z0FBQUFBQm0yeGJVTmxsT1lMQ281ZTdMSndPdmlSMTNtdjRfRmlYVnRiSHNIYmU2eGZZM1dJcUpwWXUydy1XMVNkZ2FZdEFOdHhHS2U2QXVkN3ljdzFQaU5oNHVhMXpUcU9zdVFkZG5Yak9TSHhhQ0JqV2Jaa2c9
"I am starting the Stanford CS229 Machine learning course, who wants to do the same so we can check on eachother for the homework (because i guess there will not be any proper correction of these homeworks) ?",r/machinelearning,Z0FBQUFBQm0yeGJVY0RqQnhVWVZ3TGNLMUNhRTdKNHNQVFRpMnMyNUV3N240cXZzeDY1YjJiN2ItWU1BWlpWWGtHVnNzWUl6dVRmUXRuN2JGSUhiVUJtckt0V0ZuRmpJelhCaFNZZWFpSmY1OUJfUC1GR0JmY289
"i would disagree, there are many ML research papers that were published in KDD research track which is as good as any ML venue. LIME was published here, for example. Data scientist type papers are in the applied track.",r/machinelearning,Z0FBQUFBQm0yeGJVakZrbmtfR01OM0taMEt3aHZ0Q2lmazNBMkdqMFJQVUQ1eVpoWkFIS3IwQThfb0lEd3lWWjNWVXN1a080N3JpV2RMRGlNcXZnaDF4X2dMQkRxNDZyYkE9PQ==
"I do, too, because this subreddit never had such angry words like this before LLMs. Try to find a single -2 comment predating ChatGPT. When you were wrong, a phD jumps in and gives the most charitable explanation of where you were wrong.",r/machinelearning,Z0FBQUFBQm0yeGJVOUxZV1FHaFdfU1daYlNuS2JZeFpNcWluZWstU0xfVGdoNlJ2Zk1ZTmhDSDRqVzdtTnduaEtwS2tqcEUzbDBYdHBuMExmQUtxeGRscTlRMlQtOG1KdFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVMkNUU281Y2pVaW9IdFVqb0ZjOGlBWVlBWGgxUVdmN1A2djhjNzdhZTB6Nk82SUE5S1Vsc2hsOFJONENkdTJjOHAtNFQ4eDZaWkF0Q2YwZll0Ykg1UUE9PQ==
"But the bulk of the learning required is not actually language processing. It’s the recognition of the mother, which starts even in the womb with recognising her voice. That combined with how to make the noise mama.

Then you don’t need masses of language training data to assign a label of “mama” to an entity you already recognise. All you need is the mum pointing at themself and saying “mama”.",r/machinelearning,Z0FBQUFBQm0yeGJVZE95UDFhV0pNXzhBX3lLQ3I3Z0Q3LXZLNmhtb2w1djUwZDF4b0UyTWNwYXhaSzM1elZTWVdfdXN0d183aE00Y1JzLVVPaUpLSDhhZVlUWnhnLVRmRzNfZzNKSFRDZkY3VVNnaVdlZEJCQ009
"My suspicion is that active and passive learning both play a significant role, where passively listening to people talk acts mich like an autoencoding pretraining phase.  No semantic content per se, but building the vocabulary of sounds that they can recognize and repeat.

I’ve kind of witnessed this a bit while staying for an extended period of time in a different country with a preverbal child and listening to the noises she started to make.  Even without really interacting much, the babble became markedly different over time.",r/machinelearning,Z0FBQUFBQm0yeGJVSHBFenYyQVpLY3Y1elpLQ2FocWtUeEtIa2lQdUZvcTlsX3B4UDBUZWVYZzN5SFhVQWtGMkdfY2V5ZHRsUGo4cXNmUk0yOUIyTXdpY0hTUnJ0V29fT3c9PQ==
"Gradients? Is it even possible? I know that even Spiking Neural Networks, which differ in multiple aspects from biological equivalents, do NOT learn by gradient-bases methods. Simply because a spike signal is discrete and thus not continuously differentiable w.r.t. neuron inputs.


Really curious to know how gradients might work in biological systems.",r/machinelearning,Z0FBQUFBQm0yeGJVTkVhREdwT29aNXR6ZHJrVVJJVDYyaHU0UmFvbHRkSE5hYV91Zkdsa3EwblV6eWR0Qlo3aGFuM0tyNTQ5andudGwtdWt1eFNSUDA3OFVLLUpqd2NlMU5VVEZZY01wY3FId3JreU14QXJrOVk9
"I've been working with machine learning for about 10 years across many different projects, and yes I regularly work with, train and curate datasets for LLMs.

""People in the know"", doesn't mean anything. Try again.

And no most working in AI know phi3 isn't a ""paper tiger"". Phi wasn't the first but maybe the one that popularised synthetic data, and pretty much every single model we're seeing now is trained using synthetic data.",r/machinelearning,Z0FBQUFBQm0yeGJVSWRCcHMwRG4tQ2FmSlNORDBYUUljTW82WEdjb3hNckN0ZWZXalZFU2prNEE5NHBhQm9wTUh0ZU9JVHVtUHE1cDlDOWlBNEFSZVRZU0p3NjdYRFZJZFE9PQ==
"Coming from the perspective of a researcher, all of these things that you have mentioned are indeed critical to machine learning. They are the underlying building blocks for which AI is built on top of. In your career, you might never have to do Gauss Jordan elimination ever again. In fact, I would be really surprised if these concepts came up again outside of the setting of your linear algebra course. That doesn't mean that they aren't important - they are critically important. Somebody spent their career optimizing these things and implementing them into libraries so that the next generation could use them without thinking about it. Why should we care about learning these concepts then? This will likely be the only time in your life where you study these concepts at this level of granularity. The fact is, machine learning and AI are built on top of many different fields and it would be impossible to study them all in a single lifetime. However, the insights that we gain from thinking about building blocks influences our future thoughts and gives us a unique perspective on the world. Foundations allow us to draw from problems past to solve new ones. Think of these concepts as fractions of a percent toward your overall learning. One of two concepts on its own don't contribute much, but over time paying attention to these details will put you miles ahead of your peers.",r/machinelearning,Z0FBQUFBQm0yeGJVUDFSeDJ5X3pWM3NHUmdrMnJESzRFMVJ5ZXptdjlERi11X1lWRUZZaldkU0xiSWVEMlNBQmRfRG1OcEtzSkxQSmFrU01Ba3FBbFhJZjhhSV90ZXZDaWc9PQ==
Push,r/machinelearning,Z0FBQUFBQm0yeGJVcllZUWttWTJuMlB1MVhTay1heFExT0U5YUdaMXU2MHZyOXdndUlydkhZWkg2NnBzNnJvVDFRUGc4SDk0UGNJcGFnOW9RbjhNTzZMV3M0RzV4NWJwR0E9PQ==
"Try it first. It really depends If it's a small regression or neural network for some conceptual prototype, to an end-to-end AI app.",r/machinelearning,Z0FBQUFBQm0yeGJVZ2NKTk93aVAyRUpFS2lBd3lPZmJqMWw2QlljbHFndDBvZVFqQVl0bG8tcHdNaDlNZTRJUUZWUkUyN0R3OGFNWFB5ZmcxRUVJY3M0Vm9RRTcwYUl0NHc9PQ==
Will do! Will clean up the comments and docstrings and provide the GitHub!,r/machinelearning,Z0FBQUFBQm0yeGJVTmdwV0lVQjRnc1otRkY0TVRBalJ4VHdmRUpMa0RGR0FTZFZ1T0dXTGlsVVpKMy1pal93Qjd5MVhLTHNOTnQ0bHRoU0VoLUl0MFBUV2I4c3lCSmotZEx4UlJ5WG9nbnhrbW5wTmphZ0ZtRms9
Why would you put tips in a compensation model lol,r/machinelearning,Z0FBQUFBQm0yeGJVN1hEdUJkcGpISEhWaEJFLUczc3E0MlBXQmVhQ3lKZGpkemozSkk3bExicnhSdXJCRGMwRmFKUkdxS3dlVWxBUzBFc0c5eFJRa3RrZXQ2WVNTZ3JBTWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcGpDdDU2cTlNa3Z5TUFVTG1PbVVfd1JmcEhJRHg1aWZxVENkamlZTGd6WVdaVWlZM3lDYldnUldnYmFKUWppZDNvT1hKTDR5UVRsSkI2SDdNa2ZqN3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVZFR1ZnVEM0ZJMUE1OVh0aGoyUGtFZWo2Tjd3czV3d00xVFBwQnNCQTJvSktwRGZsMTc5a092ZHBtcVBGWUwxaUkzVHVxazRzSnN5cHZOUkRUdWVIWUE9PQ==
a big part of the decline in utility of PWC was when they lost access to the twitter API and so couldn't do their social feed thing anymore. Would have been nice if facebook had just paid for that team to be able to access twitter.,r/machinelearning,Z0FBQUFBQm0yeGJVbEptSmowMWhTMFpoSGIzNm9Lblg4RzlwOWpuVU91TnRpSEtLQUVIb1ZNT0pFYnQ5bGZRLVBuNjk5SzhNUHY0SE1EUDdDNlJpaWxDYTVra2FpZjVZcVE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJVdGk0UDRwVm1XcDQxZERqS0NCWXNXUTBuOFRZcUFSeWZVRDI4LUpjaEZsdWhEZS01dWRVMzZIMFNnUWZMOXZvWC1LRGVSbEJQMlBTMlhFUkRFVTdCMXZOWXI4VnlXdlE1TWk4cmNXQlZySGM9
"The tips are just added to the total, it makes no difference whether you consider them part of ""compensation"" or not. Either way the drivers will be receiving the tip money.",r/machinelearning,Z0FBQUFBQm0yeGJVYnhPdWpGTXZhS0FzYk9aMWxoX3RRX213VFhjaWpQMENNX00wZnFTU29wNHo4ZkhtZi1TMVZOTnp4SGsteDI3Zm4yWEVhSWlQV0NRLUpfb1BfbE5MUHc9PQ==
Are you sure those means and standard deviations are correct? the standard devs should be closer to .2 in your normalization step,r/machinelearning,Z0FBQUFBQm0yeGJVQl9xVk9Ec1lURkNzMk1WSEpkNUZmZXBVYTE3Wk13LWlRRzJJcVpnMlZnWWxwWVFGZU1iNWM4QkRxSF9PV3hGS3VzVC1fVlZjZWJJdjdSZzRPaHBYcEE9PQ==
The standard deviations used for normalizing also seem too large to me but not sure how much that should effect the model. The relative rankings of the channel values should be the same but they will all be closer to 0 and the range of values will be reduced.,r/machinelearning,Z0FBQUFBQm0yeGJVNjUtYllzN0R0ZXFzbEk0XzRWRDdRcUFzU1pRR3Nub0Jrd2xwTUhlLXVBa3BPTEhhVWpkcjB0NGV3U21oM1Z1T1JPRkJUZE5iMUdUUlBnZmhRM1EzWVE9PQ==
"Actually, upon looking at the torchvision code, I now remember that since you're passing the mean and standard deviations manually, it shouldn't matter what order you are calling normalize.

One thing I would do however, is to take a look at the mean and standard deviation values for your images. Are they already setup to range between 0 and 1? What's the actual standard deviation here?",r/machinelearning,Z0FBQUFBQm0yeGJVUWxsWkpCb19sN2lSVnRlY0FhcmFOZldUV28yYmV2UTdYTFdHajVnTnppWmQ0YnpIcjZaWmtGVnNPVEctNzJ0eVRuWUIya1RyMDhWMHNYYXU2RnJ4ZXc9PQ==
"For most of our use cases deployment issues like setting up Kubernetes is a bit of a problem. But the biggest issue is just the cost of cloud services, often we're running heavy non scalable jobs that need a set number of GPU instances for a long time. Most of our cost calculations basically show it's cheaper to just outright buy the compute and rack it in our own on-prem racks. So we normally just get our own compute and set them up with openstack, etc. For example one use case we might need 8 p3.8xlarge instances for 3 months straight. Another use case we need twice that for an entire year. The cost of servers is cheaper than that.",r/machinelearning,Z0FBQUFBQm0yeGJVSERBLW11MUg0Tmg5d09GS0lNaDFqcjJ1MGdOb04xV05BZGdsRnBPMDlBMGU2akN3X2tsa0VmZFczaUhfY25vRFJXRERGQlhJZ01mUVlvdmFpWkJ2M0E9PQ==
"I didn't say KDD is bottom for the ML scope, I am just saying that there are others that are higher up in ranking and more prestigious, such as NeurIPS, ICML, and several other domain specific (e.g. CV conferences).

You may disagree by providing proof that KDD is actually THE top, or among the 3 top at least, in that context.",r/machinelearning,Z0FBQUFBQm0yeGJVZEROVWdBSDZBM2p6djZpSHRLcEctRTRmQTI0eDQzcVcxUjN5RWZYdXhocjZMZ1paQjVMZ2ZkSmJTRktFMThYR1pxN0R4RExVb09YbExZUDViZmVlYkE9PQ==
I’m interested to hear from others but new models are often only slight changes from previous architectures or ideas so I assume that recreating a similar architecture from scratch would be fine assuming it wasn’t a direct copy and you weren’t using the weights from the target model. That’s more of an academic perspective though so I’m wholly unsure about the legal side.,r/machinelearning,Z0FBQUFBQm0yeGJVeHdxRHlDMWE1Y3YzQVVoOFhwQ2JmTkVlakE5OHZFVTFQYVFUSjFqcWV2N1lkV3ljQ3N1M2d4cHU4UHdZNXlJem1oOWQ1eG14alZWQXZVR0o5ZHpIZnc9PQ==
"Old thread, but I found Siri to be pretty good at speech synthesis (I posted an example here): [https://audio.com/vik-jam/audio/example-say](https://audio.com/vik-jam/audio/example-say)

say ""The expressiveness of autoregressive transformers is literally nuts! I absolutely adore them."" -o example\\_say.aiff

You have to go into Accessibility settings to get a decent sounding voice though.

Settings -> Accessibility -> Spoken Content -> Voices -> English -> Siri -> Voice 4",r/machinelearning,Z0FBQUFBQm0yeGJVTHdGXzl5NlQxbWRoQS1qSGJobUludDBVN0RQMGd4cFVKLUxDMjJ3Q2E2T0lYNWpicTU4WEhIcmZ3bTVmUUowTmFOUEYxM21yZl8wM3NjaWVlMElvU3c9PQ==
"I'm not the OP btw. 

1. Yes it should make no difference. 


2. The actual values should be around .2-.25 for each channel on cifar. The means should all be between .4-.5. imagenet is roughly the same which is why those values jumped out at me. 

However, like I said above I'm not sure exactly how this would affect the model. I do think OP should try with proper normalization params though.",r/machinelearning,Z0FBQUFBQm0yeGJVcm5NM005Wld3Z2Z3MllibGhHeEZFVGlOT3lNbGNZamZzaHJmUHJmTVl1emZZdzFYU0FOSnVHZ0dkVmlkR2UxaS1SWE5ZTHlJVHhsUEpqU2VZVV9hRXc9PQ==
"Are you sure that your data transforms are the same as they use in the paper? I noticed some strange things with the way you are handling them.

1. Cifar10 images are already 32x32 so there is no need to resize. Additionally that random crop of size 32 on an image of size 32x32 will mean that many of your train images will be very heavily masked. Which could explain the failure to generalize to your val set which has no such masking

2. As I said in another comment, the means and standard deviations for each channel post normalization are definitely not all .5 in your training dataset.",r/machinelearning,Z0FBQUFBQm0yeGJVeFg0UmxfZ1d4SGUwRk9ER3QxMlFLOHE2NjdJcFJaYXNEVEVmSmpFT05peFFGNVd1Nmcwb0NYdmxBaWJUOTREamRXd3ZLOVU0S1ZZY3VhakxsclhobFE9PQ==
You aren't padding with 4 pixels on each side in this code. They are also telling you to do the random horizontal flip prior to cropping not after.,r/machinelearning,Z0FBQUFBQm0yeGJVMnNXdHR2bXphOFBUOWNkVkhyYjgwbGtkeHdMMWNRc2pMVXBtWUxuUlNfeTNrVlNLeTc1Z21NZnpMczByZFBJUmh6NHNxWXk0aW5iOFdLRmhyXzZIR3c9PQ==
what was your phd in?,r/machinelearning,Z0FBQUFBQm0yeGJVeGJFd0sxeHBJRTNtS2ozaXFYRU9FYllGUkswU0ZuN19hQVZleXQyVExxcGdFTGlKUkQ3SVFkUFJzczFEdHVOb2Y2dVRvMkNIVzBPRUNJZTR4dlFFSFVsY1B1UThoNTZtNy1aaVMwcW4xMFE9
I am building a fully open source tool called [langtrace.ai](http://langtrace.ai) to solve this exact problem. do check it out,r/machinelearning,Z0FBQUFBQm0yeGJVSFNjb2hCWFRQZm5BZExUcWl5clE0QnpDOTU4UW1udkZaYVJBWjN6Y2E1V3huWVFTZm5qV2VTODU4blRWeGM4SmVsemw2ZFBZbkhucjlqRHJrMGtKcVE9PQ==
"Computer Engineering, I found one at March.
Low pay but seems stable thus far.",r/machinelearning,Z0FBQUFBQm0yeGJVQ0FRU0tkdlhnRUNNVXdHZUl5VDZpekpPbmtyM3BMel94UEN6T0YwVzF1WnZJYmc5eGg3VEVlM3hYYmlWZ1VoRW1sclR2WUJVLVRjQnpqcFk0RndqNmc9PQ==
"I know there’s been a fair amount of research showing that *some* form of information is being processed/communicated in the EM waves generated by neural electrical activity instead of solely in the neurons firing themselves, some studies suggesting it’s holding major aspects of working memory, others that it coordinates neural activity 

https://neurosciencenews.com/neural-electric-memory-23691/

> Co-author Earl Miller, Picower Professor of Neuroscience in MIT’s Department of Brain and Cognitive Sciences, said electric fields may therefore offer the brain a level of information representation and integration that is more abstract than the level of individual details encoded by single neurons or circuits.
> “The brain can employ this mechanism to operate on a more holistic level even as details drift,” he said.

https://picower.mit.edu/news/neurons-are-fickle-electric-fields-are-more-reliable-information

I could see that being a vehicle for gradient type learning, just on first glance",r/machinelearning,Z0FBQUFBQm0yeGJVSzJOQnR5djV1RnZSdG5DaGpHSmtzenNGTXdYT0VVRHhGZV9feEdmV0JaY0J2UVluLTF5SVc5VGd5WnpsR2d3OUlNc2RUWDRFZXBuc3RUVEFtdGdzYXc9PQ==
"This is a question with two very distinct answers:

* Do something very tangible. An opencv phone app which recognizes car license plates as they go by at speed (just as one example). This will prove you have the ""chops"" to take a problem and turn it into a viable solution which a fairly non ML person can understand. The key here is that you can make a program which uses ML, not just ""do"" ML

* Or get a PhD in math/ML and publish incomprehensible gibberish nonsense academic papers(5+) where you entirely made up your results and don't publish the data or your models. But, be prepared to be brutalized in interviews where you will be interrogated as to what you know about Hilbert Spaces. Don't bother with learning how to program as I've met very very very very very few ML PhDs who could program their way out of a wet paper bag. Since your published papers are made up derivative drivel, it's not important that you could make it work anyway. The interviews don't care if you can program much. By any capable programmer's standard, python 101 is sufficient.

There are three realities in ML:

* Some companies are doing cutting edge research such as deepmind, etc. I can count these with my fingers and toes. I mean actually doing cutting edge. Not merely claiming to be cutting edge, which is an unaccountably high number. 

* There are a pile of large organizations where people who couldn't get a job with one of these cutting edge companies got a paper pushing nonsense job in their ""Data Science"" group. They do multi day multi hour interviews where they want you to prove you are an academic wannabe just like them.  They all want to get a tenured professor position some day. These people get nothing done but what they claim to be working on is too hard for their bosses to understand so they don't get fired. A variation on these companies are consultancies where they are using jargon and ripping off their clients while mostly providing ""awareness"". These companies want PhDs so they can charge more. Some of these are heavily government funded to create AI centers of excellence. When they do the programming part of the interview; be careful not to show that you are any good. They will get suspicious and call you an ""Engineer"" which is their way to say you are human garbage because you don't belong in their rarefied academic circles.

* There are companies really doing things in ML. They know that most ML is just proper application of easily used libraries and common algorithms. Stupid simple things like XGBoost and random forest will solve a massive percentage of problems in the real world. Or worse, just basic stats can solve many ""ML"" problems. These are the guys who will want to see your OpenCV car app.


There's a third answer. Get a PhD and do some really cutting edge cool practical applications. This is how you get a job at deep mind. They don't just want someone with paper credentials like the large useless corporate ""Data Science"" departments, but someone who is extremely talented in both programming and ML.",r/machinelearning,Z0FBQUFBQm0yeGJVNnptU3JlUHF2a0pPNEtlSmRaenhZQkpSVG5mMEdDQUtKSmRzMlZLTTR0OU1SVExOeUVZXzhRRGJ0QVdfcEFuMDBnXzlxWGFJbVdlS01mUzQ2MzlrQ1E9PQ==
"I’m not really sure that article is as conclusive as you’re saying it is. Most of the studies focused on whether Baby Einstein had any impact on vocabulary growth when babies watched it for short daily periods for 4-8 weeks, and the rest were focused specifically on video, and again, short periods

That is a far cry from what the other commenter was proposing may have the effect (daily 5 hour exposure at 150wpm over years over exposure). Not least of which the volume of data, but also, the medium. Environmental cues and observing caregivers interactions with each other and the external world have been shown to impact development. I’m not calling it an easy problem, or saying passive exposure alone could teach someone a language but I do believe it would be unintentionally but significantly oversimplifying to just scratch it out and call all passive exposure moot. 

To flip the question on its head, would removing all passive exposure slow the development of a child’s vocabulary? Limiting what they overhear and can observe to **only** direct interaction?  Intuitively, I would say yes, of course, but I don’t know of any settled science in **either** direction due to the ethical issues involved. The closest we might find is sequentially bilingual children, which do show a couples years of slowdown in vocabulary development in some cases, but it’s hard to say if that’s directly applicable",r/machinelearning,Z0FBQUFBQm0yeGJVcmt1Z0ZFdl9aMGFZX0lpYldkcmZwQlotemgzamFSU1ZWMkE2b1ZHQnFPRUprSjFCUmZ1d3I1bXVFN1IyVWhXVzVtRU9rU244czFyekl3QVVjUW9paFE9PQ==
congrats! was your school top-tier?,r/machinelearning,Z0FBQUFBQm0yeGJVVDV4Y2tENzJkcUVfZXRSMlFCT1FRTEVXSW1SNjlvTFlDN0FiSXJtNlRLdDQ2aDNtLThzd3lXaFBEdkl0TFl0cWdHUVdvRHI3RXdjTGZDX3hXVHh5dG9RZ3h4UDhVWEYxUm11dzNSblR4M0k9
This might be the most idiotic thing I have ever heard.,r/machinelearning,Z0FBQUFBQm0yeGJVbFVNMkR6eGtDWE91cVJjNFU1aHM3Y2F5RUFLdlVFOWhUb19CZEdhWkk3bkZXWUNXMVhrN2lkYThiTVVldzBZbEFqSFZ0VXB4cHk4ZHZXaFNzempDVlRSRTgwNzhZMnpKZDBaVUgxWmREVU09
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVeUpvSk82bE9YWFEwQk10bFVSZUVqMF8zWlJ3ZGdjR2toaHd2NzA2bUtQbUt6eG1FTGRmc0dPSjJ0N01KSGNES3BGSEVldk5WRUFnMGhiZkhpbkNsOFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVV0FuZFRZV0NJaGpsb0JZNkFsQXlwaklvRzJnaUYwNF9DVXFveTdnemd1NlpzQnlBMWoxQ2V2MjJuSEc1SHFMZGdiRkZxckVKc256elVudU9hV0xRVkE9PQ==
Sure thing bot,r/machinelearning,Z0FBQUFBQm0yeGJVQ0hYMjRwMkM2eXBPNWhfSEVLb3hyWUdXUGZKSVduZ043c2IxX2VvX3JoTEZJWnN1TkJRSFJTWUNwSEpEb1ZvMlBwQ3JaT3NlRGMzZ3B1THRiTnphbXc9PQ==
"Well I'm learning by back propagation, so I'm basically human anyway.",r/machinelearning,Z0FBQUFBQm0yeGJVSUx4UVlNTnhXelZmbF8xSlBsdV9HZmpDS3pyd3pHRTVIVl8xV05TZVkxZTdGN0dFbkh1cXNhWU04Rzk3eGtzb2x5Q1RJSVU1OFRKS0d6N28wQUZraWV5UTBTcXdqZ2gyQ0k4b2llZlpkZGc9
UC not very good,r/machinelearning,Z0FBQUFBQm0yeGJVUHBabVFqWTEyblZsNW9iaGkzU2l4eXMzYlpsMGdkYzBOeURlTUJWekN5NTQyNk51SkRPMUNMbFU3UExkOHB5T01oOXdLSTluaUk2aHgyNVlEWVhSX2c9PQ==
lol your wish had been granted,r/machinelearning,Z0FBQUFBQm0yeGJVSlNDNjlON0xYdkJRdWZKTWNhYnlhSFpPZGc4anQ2MjM5bnoySFh1NU1wZWhoS05zWG1IdE80MFVHT2hQSVJaVU1Ya2Z1MHhrYUxOMlRidkFQeVBmMlE9PQ==
My favorite part is all the papers posted there *without* code.,r/machinelearning,Z0FBQUFBQm0yeGJVOFZOZDZRNm85NHhaZmZsaXppTlZrX3d5N0lpOEhBZXVpUXZUZ1p2YndMWFZEdHhBMTNMTl95WXI4OWIzdVhUblVMeWlzNkFXNDhsMnNKWU01Mlh2Y0xNbWI1SU5uMXFHaWhBUVNhZVIzeEE9
Can I dm you?,r/machinelearning,Z0FBQUFBQm0yeGJVUWdqT09pdXZPbmotSGU4UWlSUEdFdHRTR08wdVMyblJIT3N2azZFdUhTdzNydVdhR05MMXpUWHFpZzhDLVcwWTlpem81cWxzSVZYdjN0RDdpM0h5aU44VDlKa0tDTjZycnpjaV9Sekt5Mnc9
https://www.reddit.com/r/computervision/comments/1cy0dup,r/machinelearning,Z0FBQUFBQm0yeGJVdlRWYXlkOXBwWmFYSGIxRllJeXFabVp2UXRoTG95a252Wk9QSUNfaUYzR1Nhc3lyRGJUN2JHZTJiaVFXY2NCaHExb1JoMHBVb0VVXzJIeVAtUno2bHc9PQ==
Sure,r/machinelearning,Z0FBQUFBQm0yeGJVc0xzWWIxV0R0QUx2UGJzSkc4aDd0cHpONVJlVkU3SjNaOF96ZlZMY2ZlaE02QUptV0lyai1oaEVjNEZjNno1dU9jNEY1UFIwUjAxXy1BS0cweTVRQmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVSllub0FPcTBpdWdwdm8wQ1BNbHlkS3JVNVdrV2VBVXRSd3RHOXNZWVhqNEkxTk9HVVAzQ2pQMjA0a2ZEU0ktaGdEdlh3bXRzRjQ5WmhwX2F2YzMtUXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVWXZHRXRxU1JJNUpUV2IzUFh5dWxmUUpZV2g2a0J1TjRoSkZESmc5c0MzamZGdVloUk1qbElCSll0UDY5dnVhME1RN0FwTnJOR3pPeGVXa0VPZGFGRHc9PQ==
"Which companies train and hire folks to annotate and label hyperspectral image data?

Here is one link I found. Any other links, resources appreciated. Thanks!

[https://appliedsciences.nasa.gov/join-mission/training/faq](https://appliedsciences.nasa.gov/join-mission/training/faq)",r/machinelearning,Z0FBQUFBQm0yeGJVZTJ1S3hYcGRWLThBMFozanozcFdRU2hucEFBVU4wUy01NGh0QmZkb290b1F3czVZdzBrbEF3RGN6d1ZRZXNPQWxINjEwajRVamFtU29oNGVmQU1ZUEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVS2NZRkt6ZkVTZFVVeXN3RHVqZFZuWXBrcXMtemZ0YVNycUViY2doZER4c0p0SXZrZ29xTVdTQ2xKLTgzWlRLN0ktVC0yZ2hDcjg1blZ0V2tFQjJtTFE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJVU1RJaVdSUW9JNEV1R2J3dFVuOUdYUXZXNTFZYjRpNUJDY1lfZmRsLWg3dVV3OVNLeE1SUDUza1FOWnA3c0d0QWJGUVNoQkM0TDhmYldQMS1uZG1DQmZzUW13dUNJd1FYdjJLbWVlRm82ZkE9
thank you very much for your detailed response!,r/machinelearning,Z0FBQUFBQm0yeGJVVjZFMnh0TzhNQlphMmtvOXN5TXQ2U0NyMk95QnFmcGRMVjE2dm15OGFMTTM3dVVsZ1NPQllHa0RURjBrTURiaWNrdkxSYUY4bnZ5aXhqdEgtbWVMbl83SnE5MXV1b0Uxdi1aSnRkbElJRm89
"thanks for the references, I'll check them out, especially the parallel training.",r/machinelearning,Z0FBQUFBQm0yeGJVYnBpVjBEZUtRaDVfa0hEOENrdnJCMUJrcWdhcXI3alZmMUlzRVZpN2JiRkF1MXBzd1p3QUdVWGdGMDVLQTgyVmh4akE2MXVmamhxQnhuMGZHMkJUX3VUZm1yekc0YjNVd0IxbWNnaDNsUE09
"mlsys seems to be exactly what I was looking for, thanks!",r/machinelearning,Z0FBQUFBQm0yeGJVZkFTVmtrUEhIUTdkbGluRmdLdUpJR3Q2QjRLYVFkSG5saWt6NjgweXhTZE4td1E3T2ZQWlZieUliTXdkZS1IbE5pY3BRd0dxazd5T3FUTVRyeDczOENkOUVYYzZyUlVNWnpoblJxaTJsQlk9
Can I help you with the project? I have a month until I start my next software role and I’m bored lol,r/machinelearning,Z0FBQUFBQm0yeGJVOTluTW5RMFdSYnZRWXhwY2RDWThYX0tNOTdNckx4RHVPbDBLdmcyUDY1OEdCTnpYdEtUVVB2N1hUM3RtbWlsaEp2TXlsT0dyUllkYlhCSkFsV2ZuczRxQXhFOWN6ZzBPd2g3RVhQY01CUDA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJVcEI2NGtGU3JaVjlNcVBkQ0UtZmUxT1NzZmg1RlI2UHhadzhmODd0U3ljV2Nqbmk1djZNcmh1djRRcTFZX0I0ZjIyQloteTNFRWN5eHN1eHNZeDVMMHc9PQ==
"Smaller ctx is probably easier to learn and work with than larger CTX? ex. less retrieval, less long range dependencies to learn, better available data at small scale, especially synthetic like phi.",r/machinelearning,Z0FBQUFBQm0yeGJVejVBckhnWHRDREZQN3hDOHduMUZyOHVEUGVqMjhMRmQ4ZTZDZldpbmVGUTVEdGpwTG45R052SEY5MkFHa18yeE9oU1NTNzU5RExwYmc0N0ZGQ1hSV3c9PQ==
Thank you for your opinion. I'll try,r/machinelearning,Z0FBQUFBQm0yeGJVeGdMMGtzUmhnRmc2LWtsZ1pUdXZwMk9JWHZlRFd4eFFBRjFLZUJ4Vk9JT0Z4QzVRTGpKUkdkYUl5MEVyNjlOZHpubF9BTl80S1lkTWEwV2ZGTVVUcVE9PQ==
"2004: I need a sound card. For audio processing. 

2014: I don't need a sound card, but I still like it. For audio processing. 

2024: I need a graphics card. For audio processing.",r/machinelearning,Z0FBQUFBQm0yeGJVeHc4THM4My03bUFJVmM1b240dW9qQlJvYTVHaUlXbHVMd3A1dXpPQ3E0aC0yVzN0SUVwQWxhQlRELTNCaXkwdVNRdGItRkdSdy1sdVRGTUlNR09LdlE9PQ==
"In the part of the code that runs YOLO, it will be possible if you change detect to pose or segment. I haven't tried other modes myself, so you should look at the YOLOv8 official document for more information.",r/machinelearning,Z0FBQUFBQm0yeGJVMzRRN2hKSkF0Z2tIc2RKdkk0V0FHY1NCWFd3NlVMNU1LV1lmVzhHeVpGTXBhczVuZkdFX0k1N0RyVTlNNVp1Q3IzYTFuVXpZSEZXMEFGUWhSOV9rakE9PQ==
Geoff hinton probs not the expert on that type of question tbf,r/machinelearning,Z0FBQUFBQm0yeGJVNmFnZG81ZFNmZU5TdG1kWVBWeEstZWE4ZUQ0bms0dkRITmpoNmhPMFNXbHp6SjloMjUzbTlaWmVTbGp1Q29GeXRPRVVmZ0hxOUJQNUFTTnZwTDZxVHc9PQ==
What was the social feed thing?,r/machinelearning,Z0FBQUFBQm0yeGJWVll2aHIzZnRmcDZ6VHZVTXFwWXU3MlhoX1NfZXVGd0tGWjFvbWs0ZHAwUURxWGVHNUFjYmhOTlphV3ZIMHNjTzNtSTFnNEpsWElrRUlvRzN1b2lCWkE9PQ==
"it was a sort option that was based on some kind of ""trending"" score based on twitter activity over the past week I think.",r/machinelearning,Z0FBQUFBQm0yeGJWQ0NNdS0wRVJjeUxMU2taVkxHeEd5YmxtUmhpN1NSenk5bjFuajMzNjhSRFlUa2xyT2ljMHpNd3NyWHJBM2xtVjRCcnJ6ZUNvdmhRT3MyYjJ2R01jd0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWT3ROTmgxQ3NPUVBtMGlYZkxpTHhfLTUyMUlRZndLM29Bc19yUVF4WG5uMDV3YjQtRW1QRlplWHJYWjhwaFduR0ZlS3V2SzBPQk1NQkZCQlFSYm4xWlE9PQ==
His take as of last year is that the brain is approximating backprop and that backprop is much more efficient than nature’s learning algorithm. That this is why LLMs seem to be able to do more with fewer parameters than the brain. I agree with him,r/machinelearning,Z0FBQUFBQm0yeGJWZTdHU0UxUnZrV0N1eEo3bHV3WTZLNlljQUtEYW9NRDdVMVpVcnZnclZRbXZfREdLMDAtaFFrTTJ5ZUZSd05KUmhrYXpvSl93NUhzR3E4bkM5TmpxQlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWR0dpdk1WQXdmdUdrb2xiaEkyVWFCYnZtTEhKYXFwQ0pELXY3aFcxN3I1OVh2dm9mYjNCc3lwLXZnSnNRaTBOMGUwMlZLcmZqWk9leXVURlRjWVlDZWc9PQ==
"Hello folks, I want to start learning about LLMs but would want to start from the right basics till current state of LLMs. It would also be really helpful to know the history of these models even before the first LLM paper was out. Is there any good resource/ papers/ list of papers I can go through which can help me learn this",r/machinelearning,Z0FBQUFBQm0yeGJWOXY0REo1dFRVSUxSQVpkeHR1U2FJUWVNeUV6cnlWNC1iX1Y5VFBsQUxoeFJYVG92bm9xMHdCajVyWUswZC1oaFlkdmVybzBFbXZQR1czMC0yX3l3TVNzRWxEY05oT29fVEJEdExoOEFKaDA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWSVUyZFZfU19JQnBmTEwycnR0TmJjRTk1dzVjem5PZFFRQ0dudXB0M2NlenRmZ1BNVmxpRllzNEhFWXlQQW9Sd3dSUXpVUzRpWENrdjZSczR0Z0cwS0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWcFpTT0k3RFVwUU5KUHItQVU5Vkdla05ESTc2dlgwOU5rX3I1TTc0WjV3WjRKRU5NaU5tUHBBNEJ1enJEcTVveWNQOEpraVU5UzB2QThRVG9zTVdvMEE9PQ==
"# Model not predicting the output correctly.

So here I'm using Logistic Regression and the train data prediction is :-80% and testing data prediction is :- 82%. Here I also used svm model and the outcomes (percentages) are the same

Trying to get the prediction using input data but its not predicting the output correctly.",r/machinelearning,Z0FBQUFBQm0yeGJWZmRVWW14clN2QVl5QlJrNUN2U3JEbmFFRWp2a3ZZTXdjZXhneW8xWlllbGFlaVpKVjVqMzh1T0lLQ2NlejZuWHZXYXBreWdaazRDWG96Tm1TZnJHNlE9PQ==
Something like backprop is quite plausible and I'd say quite likely. Look up contrastive learning. It is limited in how far it will propagate but brains use fewer layers and more shortcuts than current deep nets. I believe Hinton was an author on the the paper I'm thinking of but not sure. But there are others with equal or greater expertise on that particular question.,r/machinelearning,Z0FBQUFBQm0yeGJWV3NQSWI1ZVoybGV2c1hjSWJVRjQxSkdUVTJYa0h6NzhkMnh5cTNnTWt1Ri13NGJaVkhIaTdwWF9UUENlWkxvUFgtcHZjSEo1NC03SHNkUnpGX3pzeGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWWXRZcFBmVkU5dzVuMnFsb2tTbkhQN05IV2tZLWVaNUd5MGxsNHRXYzMxbU9VWE1HbVY2WWVSaWd6VWZvU3dUNnk0NUR4eVVwZHdiR0hmU0ZsYklhRVE9PQ==
"Couldn’t agree more. IMO the silliest thing about agents is having an LLM guess your business logic on-the-fly when this is actually something you already know in advance. We built CALM as a way to build reliable LLM-based chatbots https://rasa.com/docs/rasa-pro/calm/

Not only is it more reliable it reduces token use by about 2 orders of magnitude",r/machinelearning,Z0FBQUFBQm0yeGJWMkRnQnBnUWJFenMtNTFJeGo3T3RjYnljR1NiS1hNX0MzMVI1bVZVRUJwa25vdVFDR05sVnpGbWlEb1ZKbW1GRDRjenQxSkNRZjhERi1FUnk2LU5vRkE9PQ==
"Although some of the concepts will never appear outside of your course, you can look at them as stepping stones to improve your problem solving skills.",r/machinelearning,Z0FBQUFBQm0yeGJWU0dGcF9vTTJHdmFYRlk4TkU5bjRTdUh5T2J5ZTBXbmo3QmFldDA3dV9nQXpIQzdVcDVzbHJIUEkzbUM2OXpLRnMzSnZ3d2ZidWVPVUNzS3VqenJBRmc9PQ==
What are some widely used tools for making architecture diagrams/illustrations to put in a research paper (suitable for A\\*). I have only come across [diagrams.net](http://diagrams.net),r/machinelearning,Z0FBQUFBQm0yeGJWYVp4MFVfaU5KUkdKYVF3QXRzTzQ0UF9ic0Z0clhuc0VJZXNGbVBmX01WQU82UVFNdGVkVUxkZHZjcVVDN3VDazREeERGaGh3UFpycDJud0xiMGJOUXc9PQ==
"We are building a managed serverless GPU offering that sits on your infrastructure (AWS, Azure, onprem k8s etc). So we have solved most of the problems listed above. We have built our stack in tight integration with Karpenter and k8s that allows seamless serverless experience.

Where we struggle however right now is to provide a seamless Access management for all devs of your team. AWS IAM console is super convoluted and on-prem k8s permissions require manual updates unless it is a managed k8s cluster.",r/machinelearning,Z0FBQUFBQm0yeGJWNnhkOHg1X0ZXekFjN25kWjBrWVExRGM5czhiRE1MZE1aNUFSQTlxYS1wUTM2Z3FaT0ZNaTJ3TWtKMlhLNnlhUXE1WXJWaFpFLTZoS0NRT2E0MTg1RHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWNXBvSXR2UEdFYlY0WTluZkE1OHVCZTJKNDRncGxsd2did0NhUUZRU1MtMUd2ZFgyT0pYYlo3QzdYVEM3UGxPV1g0ZWwyNkluaUNjcjhONzBNTGhaenc9PQ==
Funny to see you here Alan! I've been following Rasa since the early Facebook NLP chatbot days :) Awesome to see how your company has evolved.,r/machinelearning,Z0FBQUFBQm0yeGJWTDZ4NUIweFNrVVVyNElKRkFNMGhCTmRldEdVY1M1Z0Rtd3VEUW1RYlBXNEJVMDI0LVBKRVU5X21NRUFTQUhXTVU4dkI0WFJsUm1UcjFsc29XSlE4dlNTdHpCSEdIYmR4VzhKWHIzaEZfTHM9
"Even if you ignore the overfitted benchmarks, phi is a phenomenal model particularly for finetuning and specific use cases.",r/machinelearning,Z0FBQUFBQm0yeGJWelNsa1otemRyZ3dxbUpSWU5tVzNKUGJHMGprOEJHMS0yaE5aMG9pSWUzaDByT0dUajViaHdYVzB4Q040UE1pNXppSjRSM0pHWUhXcW5QbHdtMS1pQVE9PQ==
"What do the images look like? I would normalize the mean to reduce exposure differences, convert to Lab color space, quantize the ab channels and cluster by that. Take the cluster representing the mode of chromacity and use it for class lookup or distance metric. If it's really mostly color differences then this should already work fairly well. ",r/machinelearning,Z0FBQUFBQm0yeGJWeHdYMzhlS1lhbGJPbFJkeWxIUWVNaUFENXBmWGd0Rkp4UUYza1Q1Mnpyc0R2SXV1cm1HV1NTc3lFM2VNc05xcHVuN3ZfZF9HXzBQTTh0SnBSN2Z2dlE9PQ==
"Which site would you recommened I should use for stay up to date other than arxiv? I tried using X and follwing researchers, but like everything else its filled with only popular papers, so I can't find an new niche categories and methods.",r/machinelearning,Z0FBQUFBQm0yeGJWelFTOGtUN1haSng2WXRCRnJkWjJadUNNMkp3M1hYMWFHLVNncmpTZDFtVE40OEt0R3NEUFAwd0l4Qnd2YWJfM1B6ZWVJc3RPdmxkM0JrNm95T0Q0eEhNQmZXclprcFRXUWhxZHp6VDdLZzQ9
"My org simply avoids models that aren't apache or mit licensed. If there's a custom license (e.g. forbidding commercial use if you use pretrainedc weights), then we just follow the conditions.",r/machinelearning,Z0FBQUFBQm0yeGJWeW1ZM0RRLWN2ZkowcllkV24wNmxBRU14MFIyWkNGajlqR3daNS1fYlczTHRCbGJhOC1TWkxaMW1WM1JSaUVOSkhYZklhVUVBTWVLejk2MTJWcndEckE9PQ==
"Thanks, missed that one",r/machinelearning,Z0FBQUFBQm0yeGJWbnZWdnZkLTFUVm04WjFNeERadFpORVdxZEU3VTNQTC1vSl9yQXlfUWJjU21QNnZxV18tU2REb2xfcGtRa19jRVZMMGJsbDF0eTktc1R3ZW9PNXYzZ2c9PQ==
"phi models are built for an agentic environment, period. 

The scientists behind those models have no reason to train their models on benchmark data, I really don't know why I keep listening this all the time.

phi models are result of training a LM on synthetic, potentially very high data quality (e.g. gpt4 outputs or similar) and that's a very interesting point of research that nobody has yet explored, apart from them. 

They are supposed to be finetuned on specific tasks, they are boring, that's also why they suck on the leaderboards. 

Moreover, they've lower capacity so tend to perform worse on ""in the wild"" prompts.

If you'll ever have to train a LLM at scale, trust me, you'll wish there was a smarter and cheaper way.",r/machinelearning,Z0FBQUFBQm0yeGJWakRFVHZFOExyNmxScFNrdXk5YTVNREF2SktjdFAxWC1vS3dubW01d0RTZTJ5T09RNVkzcEViLTJTRGh3ejN4OWl4eGR6Ri1mVmJuSU8xdldYQ2YwQWc9PQ==
The gpl licence only refers to the Code. Not to Models trained by the Code. This is considered Data and does Not Fall under gpl. So you can train IT with ultrlyrics and embed IT with your custom Code.,r/machinelearning,Z0FBQUFBQm0yeGJWOC1IMUZaVWVzVmE4ckFKQS1Ma1JNNFZwYm51Q00ycG9FWHFkMGVJUm9uMlp1SFRxX0lNMUVYdGZydGRBLUxGM0tDY2NKUHRjVUdWeExBS0gtdkh3SkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWbG1GSDVEMlBfb2hOYWFTTWlfOTV0TlVzZTd3cTYyQVVmVUZ1bGxzTzNBTXJ0eE9pTC0wbVVDdmkybGJWdGtjSFNza2hVSldTOUNhYks3RGpOVXBsU1E9PQ==
"If you have the object detected, you can also calculate the histogram (in Lab space even) and perhaps classify on that",r/machinelearning,Z0FBQUFBQm0yeGJWcXRMUk5jdGVyMTVzQUYxVXlFNEF1RkdaNWlzbnhNQjZpTV9nQWRHTDA4R1pyakFDSEE1VFk2aGhEUTFBSmxVV25NT2NhbFV5Q1ladUVtMnFydTJpLXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWTWxscHdycHByU0ZlOTQ1OXVsSmFrME5SdjdBMmxRcC1PdXJZUVVtT2VyNnktdmowUzBtY3VyeHFUNlNUVzJ0VEhKU1RFM1h5MzFVZjhiajdSLWxVVHc9PQ==
"I find https://www.scholar-inbox.com good, many papers I find these days are from it. Recommendations based on papers you select, very simple and clean interface",r/machinelearning,Z0FBQUFBQm0yeGJWSmZnMjVvRENyVzUxREFFQzlZVmY4cUV2VlBiZzRtSjNKR05fd2UwMHRfY0tUWi1tVWJocmRyLS1WUTYwWHlGMS1sajNBcExGaGlnWGdPaG9NY1BxUnc9PQ==
"As someone who is reinventing things for fun/knowledge, can you mention some examples of stuff that doesn’t work so I can steer clear?",r/machinelearning,Z0FBQUFBQm0yeGJWZVZkMlJXa0o4b2JLdUM2UVVPb3JTSFpmVlNpa3JRTTB2dG83Nm9IODVtXzZPMTlfNTliOXk5Qy1Dci16UVFlUHdqeUZzdmV2bG9teVNQVG9iY1VIVWc9PQ==
Can you Please debunk I really want to understand how to counter the hype,r/machinelearning,Z0FBQUFBQm0yeGJWdzJSVlF6RnJ5THRQLXJvLTd4dkE3RkRjSkhxZG03RGJ2V2JhZGlBYkw5Zm52UWhoQXZZYkg2WWJ3elZkSklzcC13dFZHMmJhcGNyNmNxMExMaXFCbWZWNzQ2RzlHTXNLU2dXWDlKNDlaWWs9
Congrats! Did you receive the camera-ready submission link?,r/machinelearning,Z0FBQUFBQm0yeGJWekxKNjBoWXpBeWYyNW5zWTRWM3B0YVdtSWgydF9zUVpocmRjT2JXVXBqVWNLN1RMbjQzeGlvVXdUS0JVa1lXTVJ6OWZxMmF4OTV0T3lKcjFfYzRJTnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWZzhQN1hMaVA1ZjVqYm1TNTh5clVneElYUkdUSE1DZlREZGtsdjZISDZ4S2hOb0NHMUdReTBuY0w2QllodnBzSW9kR0hRdmktNmVRNHJQUFZMLTEzSnc9PQ==
"> be very skeptical when someone claims to break the compute/perf frontier (see here). the best estimate of a model's performance is flops.


Thanks for this I did not realise just how closely MMLU scales with training FLOPs. That is really quite a tight fit.",r/machinelearning,Z0FBQUFBQm0yeGJWNmtfNF9iNUFfQ1JsaUVfZC01QWZPM0NYRlBqcVpQUE9NR3ZQMXdob3hwdHpuc3VSNDVKZkVQemltVl9lVU9lTXIwRnpHY0pzQW5Fb3dMT0tZQTBSbVNnWVJ5cUNaYjd3Z01uTmVxYlpUMnM9
"Could you recommend some HF space leaderboards?


I find HF spaces hit and miss",r/machinelearning,Z0FBQUFBQm0yeGJWREhHWUZRRzMxQ0V0aVdKNmJJTXJjeVpDQWoya0l1Mkl4Ry1YWWR0WV9IMWM2WjF0MVgzYW5sN0x1ejNvdUk3ZGdBRkpPS0h0VjIwazVKRVZOcnpNWmR1OUZ5aHdFMnZ1WW5KY1BqM1F6THM9
"[https://huggingface.co/spaces?sort=likes&search=leaderboard](https://huggingface.co/spaces?sort=likes&search=leaderboard)

I was mostly talking chatbot arena and openllm leaderboard in regards to LLMs",r/machinelearning,Z0FBQUFBQm0yeGJWMzYwdmZFb2poTUNTcDNLMzVGYkVpV3puaFFpc0g0cldXcHhKazZlRXBIS2JzeWZCZ3ZEN3AzcU5hOUd2NzQ1REpmbURhbkdmRjhLZURDcG5veVVhV0E9PQ==
"You should use Azure, you can have multitennant AD situations. I find the term serverless ridiculous. Like, you're selling servers..... do people think you're magicians?",r/machinelearning,Z0FBQUFBQm0yeGJWbXlNX1N6SEJ1ZXZYYXotUkhTcVFMYkUxX0xZcExrUk4tN1ZsVUYzbFl1QVZYZ3k2c0tTSHMyazkyTUxkcUhLU2RpcGlkRFpWRTZNZUM0Uk9HeEZwWmk0dGZIOHdJbGprMnlZQTFEN1A2SEE9
Thanks these are great,r/machinelearning,Z0FBQUFBQm0yeGJWa2VNa0J4Y29xZXZ1TVVBU3REdjBBZmVGcDV4ZGhhRklJM2wydlo5NU1sb0cxb3owUUpoX0d6cG94MFZ4cmszSVV2VlRnOEo3dHhodkNybmt4QWx0RGNaejVhM0ZyOFNLQkZWNjVzLTc4ckU9
"**Image denoising SOTA**  
Hi, can anybody familiar with the field tell me **which methods are currently considered the SOTA in natural image denoising**? Not necessarily for the purpose of image generation as in DDPM, just pure denoising is enough. Thanks.",r/machinelearning,Z0FBQUFBQm0yeGJWWWs3ZlZtMkd2NllfaWh0TWFOMHJHOWpOaVE0ak1rbTQyQVN5Nk9kNzRfX3BpSVVBOUFzQ3dfUnlKcFpnQUt2T3JlMWIxSWc2bU1ybWpuNXpBcV9YYkE9PQ==
"IDK, I ran my own test yesterday and after 3 epochs got 85%+ accuracy on Speaker Identification task with 3.87M Whisper Tiny transformer (depth=4) over part of Voxceleb2 dataset with 1360 speakers.

Your SSAST with depth 12 probably overfitting a lot. 

PS. Just looked at your architecture. You don't really need patches with spectrograms. Spectrograms are time series.",r/machinelearning,Z0FBQUFBQm0yeGJWZHpzdHNHbG1rQ1F3c21udExEc2NKYnpBTkd4cmE2MVdjQnlKYWNjdHUtRm8xTnFoQWgwTzNHcnQ1M0hPQUlwaUlVWWxsaDhjWjhaT19fRTF3elMzR2lJeExaR3QtUUVDS3ZicVozRWg0eWc9
"Convert it to monochrome, detect the object, then evaluate the color using the full RGB image and merge the two info",r/machinelearning,Z0FBQUFBQm0yeGJWQ2N4WXctU0ZuLWhEbVFFSGx5RWhndHhYTWR3UzFIajV1X1g1WXdNbUYzb0FfdTZ2Z282S0pGMWhmV2VhSGJmcXZETFFnLWhta29NZmZCc1JxSWdIWUE9PQ==
"I've always went to papers with code for benchmarks, but it seems like more and more papers are lacking results either because nobody adds the data on PWP, or they simply don't test on the existing benchmarks others are using.

Also ever since GPT 3 went mainstream PWP seems to be filled with anything remotely regarding LLMs - at least the front page.",r/machinelearning,Z0FBQUFBQm0yeGJWZjVkTXZjVVlmN3hDN0NOMlF0ZC1nNUVWN1hzbGo4MnpIbTBWelY3UUxPYTlmakxac0JyZjBpa0ZGX240bDdBWXdHQzY2bGFxeFBwel95MDY0T0VCdnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWVzhUWGJaODZrYUt6ZTR5V01QZmNIOHE2N1RYMVd5MHV3dXgwTThsRjl2bkl1dUZSX1FTMlVRYVFFdmswNVhQcjlKY3pHYmpZMWpZNTZkSGVHdG1EU2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWN1J3ZC1zNWhKWjRVaUVHZUR4R0tFR1J1bng2MGdPZVJYZS04TDF4UlVLeFV0Rl9yZWctaGZTeFlvVUJFaWtrZ0kycGpkOHhuWFJhVk5UVnQzT0NFVXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWTUF0S3ZXR1o4Q2FxeEZubzJaaWszRW9TeGVvWlNWS1gtOUd3MkJOTmNiYnlDbEcxZ21GMVdrTV8wbFdTTmxSczRtVDZxU0RuWXRsNVFFUjc4SVRXeEE9PQ==
"Try using a different color space.  RGB is great for displaying on computer screens, but it's not great for image recognition because it entangles the brightness with the color.  Instead, use HSV.  For a discussion of color spaces, see:  [https://www.scaler.com/topics/color-spaces-in-image-processing/](https://www.scaler.com/topics/color-spaces-in-image-processing/)   

As that page says about HSV:

* **Useful for color-based object detection**: The hue component of the HSV color space is particularly useful for color-based object detection. This is because it allows us to define a range of hues that correspond to a specific color, which can be used to isolate objects of that color in an image.

image processing libraries (opencv, pytorch, etc.) will all have a conversion fn.",r/machinelearning,Z0FBQUFBQm0yeGJWaS1SdW1PZnBCbjdxQlVoSmJtZTV6WmpsMmZYRTE5WFR4WEVHSlp5ZlhJdWZzLVY4blgtNlNwaHBWanFhMFJtSHJ4SUxWOGFaeTFPQ3ZLQ2RUbTdWUUE9PQ==
"Yes, i wonder why no one is doing this of its so efficient that it breaks the pareto frontier for performance, almost like it doesn't work like this 🤔

Quality alone doesnt scale, and synthetic data isnt diverse enough to make a good llm",r/machinelearning,Z0FBQUFBQm0yeGJWUGliRFFuMlVRbVdkXzBrNnI4Z18zMzB6RG5DMlhzVXBidmhLS3h1TWVDOWxVY1JQendGSFRnNEJtMnFKemV6eUM2MTJvbEcwcUlNQkM3WHhLTEJpNXc9PQ==
It finetunes well in the sense that base performance is so bad there's a lot of headroom,r/machinelearning,Z0FBQUFBQm0yeGJWZlV0cjV1QWRuNzJRTkVvN1dncDd4R29yaHFaT1VRZ1B3cktwX0RQU3NSUnB1b0RJVDRSQ3NmNE1maVkyOUxaMUxtRkRLVTBCWEw5UlZfWklZSmx3ckE9PQ==
It bothers me your key doesn’t match the color it describes,r/machinelearning,Z0FBQUFBQm0yeGJWaGkzY1FibXplVmoxVFNLWkk2aXVoV3V5TlhsYnNiZnMtelpySkVhMzliLVpURHctUEcwRk11QUdpQkV5WW5zZDRBMUVLYjJSZ1NsNnA2Sm42Y2xfWWc9PQ==
When do you think will super intelligent level AI be created?,r/machinelearning,Z0FBQUFBQm0yeGJWLWVGUmoxd3A5QjZGVlNVYk4yYkJTODJKUU1nRlo2OUxBS2lZWkg1RlVxVmdmV0FmS2RSU3NxZ21ZejFhdjVRZFpISXNRTVJMM21nazZkVW9wY1hLQW0xMFdrRHhiRkdlZWpmV0E0MnBNZkk9
When Will super intelligent ai be build according to you?,r/machinelearning,Z0FBQUFBQm0yeGJWUUZiT1k0WUFpNGlyNDJuTEZ1NnR6c1k5MWlMbV9OZDg3dnNqby02em51U0JmTUxVV1RpZVdPSml0QThBVXl2OGExRHJ0VmpyR3NUeHh6TXYwRDM5eFA1UWhHQ1czbmxtc29LbHpuTDgyQ1k9
Unexpected Stroop test.,r/machinelearning,Z0FBQUFBQm0yeGJWVDJKSmJJa09wUzlkU3ZRcmFHWlh4Y1FYVU4tVHRTVXl2OVlGdkR2cFMtcDFBSVBtMnRFajRBd203MUFDRVVzLVRPMThoSDZJZE9mOTAyZkNmaE54bWc9PQ==
"Your problem isn't that CNN-based architectures can't learn the colors. It is just that shapes are easier to differentiate with how the convolutions work so they are a much stronger cue, so CNNs use a ""shortcut"" to make predictions.

There are different debiasing techniques out there, but the first thing I would try would be to use data augmentation by random shape transformations. Then, network will have to learn to differentiate by color.",r/machinelearning,Z0FBQUFBQm0yeGJWVHM2bnFscWlpOGNKVGlodmQyRVNQdE5tSC1iNXVxWUtEcnI2bnJ3dHBfaGtPempOTFpmWjVCRndobTk4Y3B1WWdwQnM2Rl9kbm5HaXRHNFRiMEdzbVE9PQ==
is this open-source?,r/machinelearning,Z0FBQUFBQm0yeGJWbnR3SFVCendrT1RuVW1CWVZRdHBweEYyVzI3VXJ1WEFOSW5Jb3lKcTBobVFPWTBhN2YzVXBMWWRtZ0h0WXNZRlYzUVBOX2NCd1VKRjBSOTFjMTZGbUtxdUF5Q3ExZF9DTF9ULTlVSzlHWEU9
is this open-source?,r/machinelearning,Z0FBQUFBQm0yeGJWaGNGWm9BS3JqSkV5cXpWMlJQZjQ4Q3ZLNGE3R2ZRVlcwcWpHNXpPNnRHaWFzak8tOVBfTE1KYW5rbi1OZnE3Q2MtUENHa1FGSng2MUNVTzRWTEpCYkhVSTNFOF9DXzgzSVhKellmY1BMVlk9
"Whisper-diarizarion is great at this- https://github.com/MahmoudAshraf97/whisper-diarization

Transcription Stream, based on whisper-diarization, was created specifically for telecom calls and the community version provides an automated turnkey solution with sftp and web for file upload, download, and review. Includes llm for summary. All local and works offline. There’s a paid version with more advanced features, but the community version could be modded to whatever you needed. 

https://github.com/transcriptionstream/transcriptionstream

https://transcription.stream",r/machinelearning,Z0FBQUFBQm0yeGJWZW90NVZ6c0xoSzUwNUJsblpLQ25kU3lEaTlrUXpEUEdtOHo1ejV2UmRyUHExQ2ZJM0RvZTIzVUVKNHdKbkhOb2hZOEsza01JbV90bXpUOW9sU2xDR1E9PQ==
"> Do developers often resort to using different, older models that have more permissive licenses for commercial applications?

Yes.

It's common to have a list of disallowed licenses in bigger companies, especially if software is a big part of the IP.",r/machinelearning,Z0FBQUFBQm0yeGJWSkZlVF90RlVHTUp2V0hDcGFaR1dKVUhrTWI2bTVQd1NISzZqV1hDWXFpNjljLU05bU5yN0dDVXR3SlRTMzBrUWZQTkt6cTJTZ203cGZpYVMxdWwzMTRvTlZ1d2RkYjlYZmZmVDhWa2pyZmM9
How is this different from an openmmlab ui wrapper,r/machinelearning,Z0FBQUFBQm0yeGJWN1h6SzZjTjdSOHJCUS1odWFRdmF1U0lPR08wR0M3bTNEZjI4aDZHMXlDemZSZHFZU0lOdWF1YW9VM2RiX2JvX05aU0ZDT2lOUzNzVklHa0haY3BSYmc9PQ==
"At our organization, the self hosted LLM service deployment was the exact same as any other service, and we had hosted mistral 7b on g5.xlarge instances, so day or parallelism was also not required. We were able to hit around 100 concurrent requests, which was more than enough  for our needs, so scaling was also a non issue.

By far the biggest headache was setting up nvidia drivers, getting a base docker image with them installed was easy enough, but it took us a lot of time to get those installed on our node group. 

Service startup took around 10 mins as I didn't bundle the model files with the docker image, I had pushed the model files to an S3 bucket and was downloading those during runtime.",r/machinelearning,Z0FBQUFBQm0yeGJWMkR4R0h1SEJzWFRUYXFFRTUwZk1US1hqVzlRUFJsamRuMVRmNmdyeEV3Z184Y2JGcGZ0cVEzb3ZMdFBBX0NmQjNBNjRTN1BDTW9fVlJBNlFIWWdGNnc9PQ==
"One thing to take into account when using HSV is that the extremes in the hue channel are similar. It wraps around so to speak, as red is both at 0.0 and 1.0. And the hue channel can change rapidly for regions with close to zero saturation. YUV or LAB is another color space to consider using. 
In any case, switching between color spaces is a relatively simple transformation which the model should be able to learn on its own. So I wouldn't expect much change in performance. 

I concur with the other suggestion in this post to apply shape augmentations (elastic deformation for example) and remove the augmentations which change the color. Also try applying a blurring augmentation to blur out the object textures, as there is evidence to suggest that CNNs are texture biased.",r/machinelearning,Z0FBQUFBQm0yeGJWemdtRDdNQXNsWm5pQS02VlRxV2tMcW44UUhrOVYyYUFQTm10U1FNbEJSMmhnNGhiZHNFd2d0Q1hpOVVveXo2OV84LVV4ZWhzS1lRak5DYjFZN1lrMkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWQ3E5VlRGLUNVTkI0NnJXb2ZMU2JpUko3VVVPSF9aSXJwTm81dDZFLVVQY0tEZDdKblNXNnJ2YVE4M21NdWhXUUM3dXRSWUY5cEZ3bFdmYmdYMkZOYkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWMUV6NHg0YU9UTjNzR0RMVEt2YWdPWG52VXNVMWNGZ1ktYzMtcFF0c1lOZl9Pb0NET0xwakFYY0FoZEpuSnh5c1U1ekJvSnpjMHAyZE5xQUxuM254dEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWWThKS21lQ2VJUWpwZ3NOc3lCOTYwZWpVN1ZQNmgwR29xUF9WVXcwNTYyVVlLRG9CYUFPRm9XejgyOFo1YVpHWmxha3puS2xJSHU3aVU1cmZBekIwTWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWaXhaRW5lOENTNGVuNjN3dnVySGFPU0JQVEpiT2NwTDVjMzVUMElVcjYxM3p3TUpJcXRTeWJ3MzFuYTNPVXBVcVVYTnhnNHVIQzFsVjgtQUlhYmNJVlE9PQ==
"This technology is worth billions of dollars as a therapeutic, so it nearly certain that they are working on turning this into a drug (or drugs). Likely this is work in progress.",r/machinelearning,Z0FBQUFBQm0yeGJWaVRSTE9DV3h5TjRTUlZBS3BDVmJPSmYwb2VvUG5IVDFEZ0N4T2xfYUVPUWRhdHVsRkFRYzVZcFJ3czFQQ0M2bXFWVGZhUTlXWWpLRVhsNGJMOUJxNHc9PQ==
"Does your claim have any support from other people, like companies? I would love this to be true but I'm afraid this logic could some caveats. For example, in one of the answers here: [stackoverflow link](https://opensource.stackexchange.com/questions/6961/how-does-gpl-apply-to-neural-network-models)

>While data output from a GPL program is not covered by the GPL terms, Section 1 of the GPL states

>The “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities.",r/machinelearning,Z0FBQUFBQm0yeGJWQVZrRTNMUzY1Z2tJNDl1bFc1ME1NRU5rcXBacGR2OUo4bFBGcDNpbW5leE04NWQtQlJQdHYxeml3TjJ5dUZNZU1pd2NISm5JQlVaZ1UzVUwwOFZEZlE9PQ==
Interesting. Thanks.,r/machinelearning,Z0FBQUFBQm0yeGJWTzhvRnFHOTMzRnNjaFZRcWhmU1FZNXZYR2d1NllGNml4ZHJOVnRCWkh3MDEyVkZhR1k2VXZ0ZURZMmw2R3IxNWN1emYxZVU4WnlNcGR3N18wMXFCQ3c9PQ==
Thank you so much for this link! Exactly the discussion I needed to see.,r/machinelearning,Z0FBQUFBQm0yeGJWdThxT2RDeE1GZFd3NlRoeXV0dTlFZnYyTWZNVmlyNlNrV1VqWDREV3hOZ1NDYmM4Q1p1RkpKZEhaUjZSaDl2YkpRR3paeFhfcEpGVmtkV0lHMWlHWUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWczVSY254eDFqVzRQU213bEUyaUg0QzFQZ3lSWnppYk1aSURfRmt0ZHlBRlpZVXhVLUdBcllHMGNISUI3Yk5sTjM0LW1aN0ZLMmQyNHkxbnBHWU5UQWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWMmpZdmFkQnhxbnNmQkZUZVlHWUVycDZwSDI0aUVIVTQtYUZubjBFaHAxUzBSRFBqR0l2RGV1c2s2UWZSRlZBT3pJNDRqQ2ljZU8yV1dpcGRVTlNHeFE9PQ==
"I am just eyeballing it, but how about 7-9? Judging by the inflexion point!",r/machinelearning,Z0FBQUFBQm0yeGJWakhrR0xUNzhENl9TV1I0enAyS0w5UHZHTDdHNlBvTzdQSDNjR3JoeGRSZEFLWjJnRHR2REtnNm50TTkyMnN1YVBmZ2VWekYxUlRmQzAzQndtVXlWQ0E9PQ==
"it's called the elbow method because you look at the elbow of the curve and focus on that interval to find your best one.

Now you have this interval, suppose is [x:y], both integers and x<=y. 
In my experience, I usually don't stop there. Next steps could include:
1) use Silhouette technique to narrow the range. Silhouette converges to the optimal range of K
2) decide qualitatively which K fits your purposes, higher K leads to better WSS but it also cause fragmentation and worse generalization (I usually choose a value k<= (x+y)//2 )
3) test it with different parameters now that your have a reduced range of possibile Ks, in order to find better results

I'll tell you that tho, 19 features... I usually prefer DBSCAN since it works better with non convex clusters, and searching for the right eps and min_samples is usually easier. It works better with outliers also!",r/machinelearning,Z0FBQUFBQm0yeGJWSkVRcHgyN25EbzYxVHlQQTh5VHd5cS1fb3VYUENTOGdHSWdJTWhhOVg2MnNJTWh3djh0dDktWnhraHk3cHh1UThvM2hRbElfOFBjZ3JKVG5GSmtYZnQ1ZERIdEZSNnVyc2xhMWhpWmZVNEU9
"I'm using [gowinston.ai](https:\\/\\/gowinston.ai\\/?via=aidetect), it's always accurate",r/machinelearning,Z0FBQUFBQm0yeGJWUkU4U29fcVhualFYZ0FELUUzb21HM2xQY2hLRDYwSC1jc21MUHBRVXVDaTBoNW81LVFjTnhkZ1UzSHU5OE5fQmNWdTFZbllZSU5wZXRjblY3RTFHRmc9PQ==
"[https://segment-anything.com/demo](https://segment-anything.com/demo)  
Maybe this ?",r/machinelearning,Z0FBQUFBQm0yeGJWczk4alJMVUotT2hCeVBYRjN5cWNIekJhWDNQUkZmZVdtMklScW9GV1MzRU4ta0p5MmViX0daY1lRTk9DUHFYcUlERXJRcTVvSjRfZ2FWdEtXbXA2VHc9PQ==
"you....you don't need a CNN for this.  Convert to HSV space and separate by color.  This is a solved problem.

https://thinkinfi.com/color-detection-using-opencv-and-python/",r/machinelearning,Z0FBQUFBQm0yeGJWVVhBQzJPdmk0aGZ6Yk5GOXpjazlqNnQwYkVJczhsLV9jSVpBN3JCTm1tVGc4dzVvVVpvZC13VHQzelc1THktdzQ1aTdPVk1KWm9TWGhEQWQ4ZHZCM1E9PQ==
Will try this! Will read up on proper implementation for normalization,r/machinelearning,Z0FBQUFBQm0yeGJWcjBUQnRrM19nN28wVHdFcmE4aEFETHJseTZLMFdCTXdyd2pDMURxUmhqUDk2ZjA2Zk1nVEoxaFRLSnp2ZTN2aU1Bd1pRakZzYVd5aTVnakxEQ1hQM21BbUd2S2FEc3hYLU5xN3Z5YnJrYzA9
"Will correct, re-run, and provide update! Thank you!",r/machinelearning,Z0FBQUFBQm0yeGJWYTJianV3U294VUZIcWNuZGFZdDNIa28zZUNmYV9sRVVvcUdMNXVIZ095ZjRGTXMxOUJ1Um0zVjBqMWZsVmpWMUZSRERLeVJCUHAzbEQ3MnA2TDIyUEEzNS1hQjByMFlSZmRCUjlrYVlNM3c9
I know this isn’t part of the question but why isn’t there a canonical technique for choosing number of clusters which leverages the idea of elbow method but makes it precise?,r/machinelearning,Z0FBQUFBQm0yeGJWaWlka1FuWFB6MDFWYXJOOHZNMW1BWXdsYl9QWFZjUjdHNUY4ODdYWENKVW5weGtQam04Z0ZUZHhUd01ZVFBydmhfSnN4a3BZbjdfZjg0LTVyNXNPZ3c9PQ==
I've actually used SAM but forgot about it. Thank you for reminding me!,r/machinelearning,Z0FBQUFBQm0yeGJWWmI2cHpQZ2N5VGt0a1RDend4c0ZPUHlselNOeXpfVlgxTE9kbHl5dzhVYnBlZk5pTW5vYmJ2Q3BlUms1QnlHNFFwQy13MURUTDVBdUR5M1E1UnJyVmc9PQ==
"For inference, basically anything",r/machinelearning,Z0FBQUFBQm0yeGJWNnBfN1ZaeXplb01xN0JFWG1iU1ZRQ3dRQnZWampWTzZjR3dtdnBLazA0T1VMTVpNcXFSbG1NRHNMWGZXbENtY1RWZGlaaUVDN3ZMUll1MHc0NTI3emc9PQ==
Is video submission a must for an accepted neurips paper?,r/machinelearning,Z0FBQUFBQm0yeGJWcjYxajFfV1VvOVFDSkh6eWV4V1RuU05ieUpyWG1ELUlmeWdVQmcwaGhGYVZtM05OT1NoRWFRMzZsNnliaU0zYmVKRVJrWHhXZUJoNWJFd2ZYQVJZbmc9PQ==
"Your username says different. In seriousness, good to see progress on non-transformer based models.",r/machinelearning,Z0FBQUFBQm0yeGJWcno0eDQ2NWx0WnNlSlh0a3c1VGFqS2tHWGFabU5ONklkeEgzVENrMFhpc25kdWpZYTdTa2JRd3VjcXJFa0x6eWdxWHBJX1BXNHhqNUYwbG9zeEtGbnc9PQ==
"Within clusters sum of squares (WCSS) is great for the elbow method, but also look at a silhouette score: [https://en.wikipedia.org/wiki/Silhouette\\_(clustering)](https://en.wikipedia.org/wiki/Silhouette_(clustering))

They often are very close, but to be robust you can use the one to sense-check the other.",r/machinelearning,Z0FBQUFBQm0yeGJWZWRWT1lkWDl0VmFDbGVRMEpZUVQwSTNSa1Z6LTdxV05LekxCMUU5bXZFT0d0ZzVvODFNUVRFODBkdGwtTlNUWFRtMDh4MzVmMGJWVTRtTXlKRDJZdHc9PQ==
GroundingDINO and Yolo WORLD for zero-shot,r/machinelearning,Z0FBQUFBQm0yeGJWeHlrd09Ic0NkMDRRdEo3aVVsZWo3Z2g0d05vbWh0YnJtbzhPY2dmMmFSWDRRSlprOEN1cEpQYUxYdGpOelNWNFAzNHFTRUtmUGIxQ01IWWEyWHhBQnNOQ0FTa0MySHpIOUlJZHJaS245RDQ9
I have uploaded the Silhouette for the same can you please have a look im still confused. The graph is till 100 clusters,r/machinelearning,Z0FBQUFBQm0yeGJWZFlVbFVWaWNYQXdpRXR5U291X09mNWZWSXZYU09fRVJiZEJrd19NZW1jX3NEUW1Kc2lZUnZmMTN5VG1BYTZNcmN3NExKdkV1aWhZeElmOUR5ZW1XOUE9PQ==
Sutton wants to know your location.,r/machinelearning,Z0FBQUFBQm0yeGJWc0FyalU4N0JFdFN0TU96bnVLV3dhWFRjRHhfSXBYVGMxeDdFSy1FUUlhRURZbGRmUkJkckdjTzgtN3l5Q3hRQmdVUWxqUV9zbnhBM1VPVjU3aE5JY2c9PQ==
but some articles say a higher silhouette score is considered good.,r/machinelearning,Z0FBQUFBQm0yeGJWbm5TcU1QcU1GWWU5Q3NKZGNkamJPeVdxNnNwWElVUTdhZVFPZDJOTTZZaDFGcGtWaHFGVWNWeU1OcXpDTk41TjRoZ0ZpSDFOTWc5UGNNT1VmUk1QS0E9PQ==
True that.,r/machinelearning,Z0FBQUFBQm0yeGJWMWhPSVZla1EwYU83ck13Zkt6MGtBOEM1T2dla3ZXSHJ4d2had0x0a2hTcGJBc2g5TEh2clhOUDBsWG85ejF5S1BkeWRhY3ZZcTNJNm1YV0xZcGxyb2ZrMndISFRqanZDalFSenNiYllYQVU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWZS04Q0ZPME01X3l1YlYzSXdrRFNRVmJiRVNTeGowVHh1SjQweFNLQUI5cDBFRENucl91b0wxUVh1ZjhWSGNPVGduRTR6a1ZNNkJ5OEQyUlVZNGFvMVE9PQ==
5..10y? Automated lab loops,r/machinelearning,Z0FBQUFBQm0yeGJWOFlTeFN6OHdDcFA5ME13U3VQbEVNeHFBUml2VXA1LS1sSGJaR3I1N2hwdmk1bnBzcl8yQXJVbHpCbkczQzF4TkhDWWFJaE5aWjRJNUpyNnpjd3ZQRnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWVHBqT09zdjFqdHZRd3pGQ1BXSmNyOEZvdUs0dWxKY3BCN00xVTBSV1p3LXBoNUxMakYtR3J1aWlhUS1oNWF6cHgtdGVfaGt1UlloN09zN0MxNkNkWXc9PQ==
"We're using [FastSAM in Ultralytics](https://docs.ultralytics.com/models/fast-sam/) with good results in [OpenAdapt](https://github.com/OpenAdaptAI/OpenAdapt):

> FastSAM significantly reduces computational demands while maintaining competitive performance, making it a practical choice for a variety of vision tasks.",r/machinelearning,Z0FBQUFBQm0yeGJWZlg4TzNPbVZudHctSTN5UXVEdkYyUC1QN0RWdEh5TUNvaXNYeEJ0TDVLcFJKV3ZqcFBGSVNzWEtBZFRBOE5zT2hYaVFubTc5Y2xDalY2NXhoVHRpbVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWYUVfWWFsZDJlYWUwWGEyWmxEV0taS1pWV1BlLUNFUGlmaFRzd2drZDRlTXU5LWowQ2F6UUxDSy1SWGxWckZqZFdFZXJkQkMtZ0JyMlRpQzRDSjFkN2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWSDUzeHY1eHppRE1Xb25zR2JZZ29xRVJnSlhoSDFjQjY5NksxOWlFcnhHWlFlMUJaX2prckhRZ0FiLTNDTldJMWF5MllhNEE4akd1SG51NVlTc3NMS0E9PQ==
"yes, realtime.
Source : cameras, model: different, but let's say it is Yolo.
Desired outcome: video stream with detected objects and data streaming with coordinates.",r/machinelearning,Z0FBQUFBQm0yeGJWWksxLTBfNHBId0N4MWdlNzR3WEk3VVllVjBudktxUHF4MlhqQ2huRlUtaVFOR3Z2bFo4YlFhODZsSnpFdEEzLXhyN2dOaXdwbkJSamJrM0dpS0szZ1E9PQ==
"I might be a bit late, but I wanted to share how I used R in Google Colab for collaboration. You can find the details here: [https://www.tanyongsheng.net/note/how-to-quickly-re-install-r-packages-in-google-colab/](https://www.tanyongsheng.net/note/how-to-quickly-re-install-r-packages-in-google-colab/)",r/machinelearning,Z0FBQUFBQm0yeGJWaDVCUXNuVnNPcWtnUjlNdGk1UThZV1ExZkNoeE9GTGE2UkxGd2UwZ1RlX2FSQUNsYTdZUEpubmpkRzN3bWlRYjFCYUhIckV6ODc2eWNqTjZIOFlKTWc9PQ==
"No problem, see my other comments as well. In the paper they are flipping before cropping, also in the paper they pad the image with 4 pixels on each side prior to cropping (which should reduce the average number of lost pixels in your train set).",r/machinelearning,Z0FBQUFBQm0yeGJWeTBKVmhQN0EybUhhalFNNWNCRElHRG94WmdRbk81UzVNMGhBa1BscW9WeXhXYjJyQXNPNURiMURqT190MV9RSkROVEVCVEpRSXBYUFljSUFWMHZmdWc9PQ==
We are hosting a meetup in San Francisco on June 12th about possible alternative metaphors to conceive of / ways to build with LLMs than agents. Would love to talk in-person more about this thread: [https://lu.ma/beyond-agents](https://lu.ma/beyond-agents),r/machinelearning,Z0FBQUFBQm0yeGJWMnFzRjBrZUY4Q1h4NXB4RV84ajZnOXBFS1JzRGZwcEl5S0dndUMyQ0dVS2xmbXozdUU3VTNwanJWVGtDWEc0WTc4Y3FMUU10aThEeGZBUzdRQVVIOXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWWjhaRXhpS282U19GSUZDa2FKc0ctaENWYWxyNmNGMlpyc2FpQWoxNDRNa3Y0M21wLVlYdHlpTmJDbGl4VXFUQ0hBcFAzclJ1S0JhLVB2MnU3by1BeFE9PQ==
"It's very simple. First divide all pixel values by 255 so that they are in [0,1]. Then calculate the channel means and stddevs across your dataset. This is how you obtain the parameters for torches normalization layer. Or you can just use the ones derived from imagenet which should work just fine.",r/machinelearning,Z0FBQUFBQm0yeGJWdVBtQThRd2kxRFJMby16YXhETkN2eHNBMEt0dWpUd2ZZTXhpcTB6VkItRE5FeWcxN1ZScGtXZ181SmkzQ09fQnRjcXBjNTRPZE4wR0JZVWZpdzFXOVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWVmZDU29BNkJRLVU1eDBKQzI4NGl5ZjJpcWFpbHh0YVdKLTMtczN6YVVrcmdrQm1WbTBOT1ZwcXBBX2otYUMyaTNxcThtQWRtQlJLOFRwUU5ud0Q0aHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWSS1BVFRwZWVabUF4THRsLWVmUGZTc3hKSDAtZWNkOFN6cExKT3hsUUVYZ093RUU0WXAxWmFYUFp2RFJwODBhOHZodHBoWTRCN0tGcHN4MWZCYWhpOVE9PQ==
YOLO is efficient,r/machinelearning,Z0FBQUFBQm0yeGJWT3k5MHhxZWpoQ0pQQ3ptMWZyOHlvRkJReDJ2emVzRkxULTM0VkE4R3d0QktwUXgxLW1WTmYzaG42V2lXUVcyQUxmTWNYMC11c0JoUVk1Y01jUkc0NFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWT29NWjJWWVZwb2tTR1hMQ1hGdFFYR0o0SEJ1bnNHRDA4MUszZVFUYWlmOUNqcGtVa3VFUFRBcGtWMUpRTzEydzZFZ3JmemhkRTJydVJwM3d3SFlTdFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWN29xOVp5WVZ0R2hNOE1yTjFTdnFmVmFxeGJtcVN4OXQ3azFUTS1hOWFxQml0SnFBU0hMN2hXMThPUDhSTWNzLTEtVmdDTnRQeUw3dGdNYWJxbmJUeHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWWVhROU5ROS1NaVB2Mnd4S092bWdrbVNDZDctVXhJWTFqdlptNVZNLWRhQnRzUGp2UGZOYng0bHVGVmNybUxQWm1ULTZBZjlZM01qUmdPMUlnUUxZYXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWWU5GaFlrSk5QMGZCcl9JcTUtQnJyLXE3ckRCXzlTcVJaWTBPR0JpUVVQdVp3MlV2Z3RyYVJPZkU4OFl6TkdUVXZ6bnBOXzFEVDcyQm9vRzFpUmFzSnc9PQ==
"I think you're going to have to show us some example images to get good answers...


Is the lighting the same in all your images?   Think of [the dress](https://en.wikipedia.org/wiki/The_dress).   If humans can't figure it out, I doubt a NN will be able to.",r/machinelearning,Z0FBQUFBQm0yeGJWaXB4S05ZWmc5QXo2azgxdmo5eWs2SjNIOE1adDlfLVl5LTBFUTZYZGFZVEpYTUp4NE5lVUVTZFVpVTVacTNuM2swR0JKdUZNX1c5Q2RUV2gtNS1CYTA5SHpMRV92SFY5WWNqa2hQa3ZfV1k9
just keep quantizing till it fits...,r/machinelearning,Z0FBQUFBQm0yeGJWcmVNNUVrbE14eXAzXzVaZVVfS29zWGNFNVFvUmE3dlBjanV4cGY4RzRBRFJlVDF3MWM4RjU3cFI1Mm5Eemdfb1dMSTBZVnFoU1VzblZtSmVGV3lXQ2xMb3hJUXk1c0tseWJ5OVZsRG9oS3c9
I have a github link that has the slang term list.,r/machinelearning,Z0FBQUFBQm0yeGJWcDhSNXQ1YVNHX2phMWJ5U2EzcEJNMy1iZUJsYmItV0xINTJ1RVlqSDlFWG5XckNvLW9Ja0c0aHpBLVVCZkxDTS1xSk9YQUxNN3hxUzNLS2VLdDI3WXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWZWF6M1VVY0U2ZGs5SDJrTUt2MW4wSkRIQUpoX25JU0g0SGVObGVGY2NUdWpTVTQwQzJRay03X05JM2hxdWlfM1NRc09vdHpHNVpCdTRrdnprSjR4QXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWckVxdDE5bDdRVjUtdXRadVpCb3FTYVZHNE9Pd1NXOVpCXzU4RWk1cVI4MnVVd0hWcmpoS3N2Zk9MUlRxQ1ZnYlV3cVZwXy1NbmxzVUlWSkljTFBOckE9PQ==
What's an example of a computer vision model you are interested in that you feel resource constrained by? I think the only high-resource stuff in the CV space is MLMs.,r/machinelearning,Z0FBQUFBQm0yeGJWV1BQcFNjRFlHc1VoVjB6Y1BDNzNFdHZuVDlQWHdWTmlEVlJoeGVJc1Q5RDVmNHZaLUtub2hRaEtoTmQ1MVgxTWtjUkJHS2w3bTlPZUM4WXh5U09kRGc9PQ==
Is there a specific reason you want to do this in one step? You could also detect the objects first (maybe on a gray scale version of the image) and classify the colors later.,r/machinelearning,Z0FBQUFBQm0yeGJWSzNYY1dhb0NGY3hsblI5SkM2ZWE4bDZQZGRkb3M4UFoyN3M1UndaYXVBSmNmbGpKQlM3TklhVm9qSkRRdHRxRlZrRkRWc3ZRXy1qcDBGR1VvRGp2RWc9PQ==
I have already detected the objects and cropped them,r/machinelearning,Z0FBQUFBQm0yeGJWMGpWNXJLVzdJNE4xT2VIWlZ6eXVsSUt3U1Y2bnROTTBlYkJUc0d4QmQ3dG0xd3V5ZGZ4UnZsRVg1SnpUc3c3ckN2M2QxM2dWczdGTlV4Zk10dUJId2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWeTRWbENEbk1fTFlsUFNoNmVObF9pTnczdlAtYUJZeEZNVmRMM3pwSmE3UTI2VU9Edm1VR3FZMGJ4b2QySGtlYmtTY25qWUZLbTl0RFVBUHk3VFY2cVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWU2ljUi00SVFpd1E4SlllTkl1NmRnVk5icVJfaGFrZHc4SzQtM01RYWEwSXpWMDdwZ2JnSnV3RGtobjJfWEdBOC1QUjBBakZ6cWlyTmlwWk54VEw3OHc9PQ==
Note that i’m not an engineer and I want to take unstructured content to structured content.,r/machinelearning,Z0FBQUFBQm0yeGJWR1hfblU5d2tKYVFOSFFPczUybnJFYzFCNktsdVdjSk9melViRFZYdm1penV6U1k5bzB6YmRQbWtXZkpmbk12ZjBMTFVPUzU5VGp6cnk3VkZRZ2VCWnc9PQ==
"Label smoothing could be a thing.

But I also thought of specifically training the model on ""out of range"" images and enforce equal probabilities for all classes. I never tried in a real application.",r/machinelearning,Z0FBQUFBQm0yeGJWWlFIU0pOZUR6TmpCU3pqWE5PRzNwVjJzZDRNTHpZWWNoWUtnQWw1OEd2dW9JNGxjSWdYc2x4ZXN6VEJfMVN5NFNXelBaR3NLYlE4dWhJeld2S05NcEE9PQ==
Identifying the same shape but different colors -- can't you convert everything to grayscale and just check for shape instead?,r/machinelearning,Z0FBQUFBQm0yeGJWV2U2QlYxbUsxTXhWeGFNbHZCNzFFN0ZxUmZVaHV0b1RwLW1ld0RXajJsMWhOMkZBS19rMURwMTZRSEVfNUVRT1NoMXl5bHAyTFMwOV9ZOFp5YUFuNkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWSUZaRlBFN0psdnllUmRsUTRSWHUwV3J6Xy1ZRy0yM05RNDZsaHJnVWJpSUZsY3cwcTc1OU81ZUJzcjJVWmhmS0c5LVlvek9udThFMzdTdmo3RDZQNEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWQnhiai1VTGlidEY2N21yaG9WZU9zM1BUREx1c2RVWmpCZ0FCVmw4YndNdUdQOHhocUFuNWViVEhEUjZiS0JTZUllWEJnQ21Ia00xaWZTZGU5aUwtZ2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWT2xQZlJvTzQxUWhGb0wzRTY2ZC1MN0ZLcHBhUmVrTHVILU1mNGZDZjNTNXZiNi12V1BnTi1adjZneEg4NU9LZ2NqZEFrZUY1OGQxTmM2ZlJZUDd1SVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWeXZ0QnZkbXlNNlh1N1BTTF85cVZ4R0poN1dUdVdjTC1wQkVtZGlVRE84T1FONkR5NzBvQ3BLc3FZS2gyS21mUi1nTFlVV1BmTFRIekxOWHN3aXdzNGc9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJWX2M2QVQtWF93c3FIb3dfZlhMSlNmWGpydDk3Q0NBSGlKZllseXlteGZFNUJPcG5MQjgzYVdwT29pVmNjQ2N2dFJCMTVqQ09idVhubmFOR2F0ek1YLWN5aGVOVE5nV0ZidU5QWGEtRHZyRjg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJWc0Z2UlY3aDA4cVJqLWd3TmlLOHpXcGh3cV9tNWQtVlo5M3Rob3ZOb2sxNTdYTzdHN0wycWxqLUViaVU2X29USFZoOGVIcGtsdnliYW9lR2daeVhZNFdiTFdUVURBS1NPcU1xdm9Kc3MtV0k9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJWOTNkVjNLWDlsRC1KWUJ4a2hOVXhIek5VOTN1QmEtaHlhczg2V0xLVm11N2hIUlZTWTlmY25YaERQWEU2ZEF3cE45QmFobnNJMTROOXlNQkZCUWk4NkZDRzE3YUFkc2FpbnR3b3ROb2tZTjA9
2026: I need neural CPU cores.,r/machinelearning,Z0FBQUFBQm0yeGJWTjdYcEwydXAzZDJ5V2tiWFdYcmhTVXBTcHVIYlR4c2tZMmREUW5CazFMcHNRYlhEQ3hIMThNU0lhT0NMN1RoUTdDV3l0N2w5UTZLQzl0TXJUb1ItckE9PQ==
"I have been wondering/playing with the same idea. I think it depends on the mind map software u have used. I have been  using freeplane and it can export the mind map as an html file, or even a word document, as a bulleted list. I haven't taken it as far as embedding into a vector database yet because I dont think there is much actual information in mind map. I have also been looking at graph databases for similar purposes as these more formally describe the relationships between entities. So that might be worth u looking at depending on the usecase",r/machinelearning,Z0FBQUFBQm0yeGJWY0Nra05idktrMmtxY1pSckRPNl8wSWcySnB1TXVreXlnQUNKN21URkl0NVBBMTJBV2Z2Xzc4bVBXNTZTeHhjRFAwNFBZTVBEaUNEVmJjdW1lcG9TOXNmUnBUbHpYTFhGd2xKTkRuV25GQWM9
"This is a pretty good overview of CV models: https://github.com/huggingface/pytorch-image-models , has parameter counts and benchmarks. Pick something that fits your GPU memory (look at parameter counts) + a bit of buffer for execution, and you should be good.",r/machinelearning,Z0FBQUFBQm0yeGJWdmRDUkpzUjNuazN5aGJhUl9MNnVkU2sxdF9kdmFtbkpCTC1yYjdZNm9VQjdXYXJqN1FoM2pnT25YenNvLVUzVjJQbGZJX0pNbDBnNkxaVjVEYUtVRVE9PQ==
"In my experience of interviewing candidates for ML Engineering and Research positions, those with strictly Math (even PhD level) backgrounds would tend to overcomplicate basic ML concepts and struggled to organize their thoughts in terms of both i) applying models to real-world problems and ii) coming up with solutions to the types of hurdles one typically faces when deploying and using ML/Deep Learning in an engineering context. For this reason, I believe at some points the mathematics stops returning on investment, so to speak.  
  
You certainly need very strong *undergraduate* mathematics in Linear Algebra, Probability/Statistics, and Multivariable Calculus, but the abstract mathematical theory of each of those is not as helpful in a ML Engineering context. For example:   
i) The abstract theory of linear algebra in terms of dual spaces is insanely useful for those interested in Wavelets and other approximation theoretic fields but aren't necessary if you are trying to use such transforms in a model.   
ii) In Probability, the theory of continuous-time Martingales can be used to derive generalization bounds in supervised (I believe, don't quote me on this) and [online learning](https://www.mit.edu/~rakhlin/papers/chervonenkis_chapter.pdf), but it's not very common you'll be using a Martingale in some model you are building in industry.   
iii) In multivariable analysis, being able to understand parameterized surfaces, gradients/Jacobians, change of variables in high-dimensions are all very useful, but the abstract view of multi-dimensional integration in terms of differential forms isn't nearly as useful in industry.

To me the most useful yet more mathematically (relatively) intense subjects that are relevant in industry are Bayesian statistics and convex optimization.",r/machinelearning,Z0FBQUFBQm0yeGJWd1Nqc3d1cmh1WEZ1UFVEZEUtMEFiN2VxYWNJcHFNNWowNmhNanZhclNJbWdpblNKTEtmSDNtQldCZGdJUU1keS0xOVFjZEU5LXRuV0NmdGQ4NC1MTHc9PQ==
"Thank you! Your suggestion helped me solve the problem.

In the first stage, I used YOLO to detect the objects.

In the second stage, I croppled the detected objects, transformed the colorspace of every object to HSV, calculated the average values per channel and used XGBoost model to learn to determine the color label based on average H, S, and V component.",r/machinelearning,Z0FBQUFBQm0yeGJWeDBseUQ0OTBEdU45LVJvU1RfX2ZrNnlPZ0hVZ3hsVDRDblZYbG1wMmZzQXFkbGxQSElFZkpySW5jMG16TkR4dkZJWXNxTksyc095d2psbFRGbHhjSUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWbjZXVHRKZzJ4S1RQNl82MFg1eVN3NTBZUHoyS3FwM0dKTkQ3aU5CV3BmNkRNVDVrRzgzMWtzNHVfcFczMHRXY2cwNE1aRG93Q29BQmpZM2t0S01mTWc9PQ==
"In MLOps or similar, the focus is on infrastructure, but there are some areas that can be advanced through research. Model validation, monitoring, automated development.

The respective questions can form the basis of a dissertation.",r/machinelearning,Z0FBQUFBQm0yeGJWVnlfOUF6OE1BMjQxTktOYjJLbVJFdlU0Sm1JVjV5RzVpR3d4Nlk1Q2JubzJraTl2ZER3NnRFZXVoVi05cURXNXVXMDJldWFRaVB1UVJKVWoxRks1dmc9PQ==
"Seems to work well, when you squint eyes.

However the colors do no seem to fit.",r/machinelearning,Z0FBQUFBQm0yeGJWcDNqOEpUNndvQVdyV0hadnhUa0Z0RFRSVThqckVXM0NqeC1sVWRHWUx0LWxyMkRxVVI1MERlWVpmS0FkNmMwSmwtVFp4cENERVYtMUUyOGxzemJnLUE9PQ==
"It becames completely trash and outdated, unfortunately. The nice graphes that were tracking SOTA metrics on different benchmarks are not usable anymore.

Also a lot of categories are redundant, or useless (only contain a few papers). They seem to be created automatically by some algos.",r/machinelearning,Z0FBQUFBQm0yeGJWeTJrYVVJeWlOS2J4cVMxRGVFUjNJcXB5WGszY05xNlRwVnNBR0NFTGRDbjhFMzgtazQyU0J3V1M3eDNmT0l5Zm5SY3cwaWtCbW0wV0lLTDZhYzhMUHc9PQ==
"Thanks for sharing your results! Just a couple of things to clear up. First, our Speaker Identification was done on VoxCeleb1, not VoxCeleb2.

We’re very mindful of overfitting. We’ve used regularization techniques and closely monitored the training/validation loss graphs to keep things in check. Similar results have been reproduced by other researchers as well.

About the spectrogram patches: audio spectrograms are visual representations of the spectrum of frequencies in a sound over time, displayed as a 2D image where one axis represents time and the other frequency. These can be very large depending on the duration and complexity of the audio. Splitting the spectrogram into patches reduces the dimensionality, making each patch a more manageable chunk of data for the model to process. Also, each patch in a spectrogram contains local frequency and time information. This helps the model to learn from and recognize specific patterns in the sound, such as the pitch and rhythm of speech or music. It captures local dependencies, which are crucial for tasks like sound event classification and speech tasks.

Thank you for the discussion. Please let me know if anything needs further clarification.",r/machinelearning,Z0FBQUFBQm0yeGJWR2dPSUVyM2hGLWhwQjJXNGhsSm5DaDEzQnhPRVV1Z3dmQjRSRmRQVE1tTmlHYTZNdGZjRk9oOXVSaHh5MlF6TFZDTFJqalRWTHhhVmpTekxkY2ltNzB1Q0JzZ1dBNlRiOXRrdEJKUHJVSDA9
And so far I haven't seen MLMs used for anything practical - although they do seem very cool!,r/machinelearning,Z0FBQUFBQm0yeGJWNXhVSU4tNjctQU5ZZUpRSERRMmxyWmxwNFYwVkg2dFNqckxNcGFKUk5DOFoyczMtT2g4Z2w0YTBiMDJDdjdrQnpMeTdHRV94eExXRHMxVkRjTFMxWEgxckZnUmV1UjA0M0J3QTM1bjFlUVE9
Don't disagree with a single letter here. And echo what OP has relayed. RAG-esque attempts to automate seemingly quotidian cognitive work... good luck with that. But I can't be a hypocrite... I've made good consulting money from companies wanting these shiny new toys. But now I try and take a principled stand and advise them to think thoroughly about their expectations.,r/machinelearning,Z0FBQUFBQm0yeGJWVDRYVFdRakdXSlRBWFZZaUJOSlk3dEpZVGc4UzIxY2pHZ2RjTEI4cEJkdUsyYVlydkFuc1Bkem1rZFNuQ2o5dTBzbDZPQ0g3dVJaZklzNTBRRjNqU1Q3bGxBZFFuazJsT2hSYmRWQTBITTg9
"yes but with a mindmap I can use GPT to fill in the gaps, for example if only a few lines are written I can use GPT to generate synthetic data based on the information provided and double check for accuracy. Thats the plan.",r/machinelearning,Z0FBQUFBQm0yeGJWcWRaa3ZhVkk3NmlkWGI5RVNNbjZ5WTQ1U2tYZ3hwOWg0QTJLTWtkNHp0c2o5UUI4SzAxc056elFMWkdEUU5Qc0ZXQ0ZEaWNmd2gwaDdiM2lQUjIxN0E9PQ==
"Good exercise, good way to exercise your coding and deep learning muscles! Also, congrats for packaging everything nicely together. But I hope you don't expect anyone to actually use this when there is pytorch, tensorflow, Jax, etc.",r/machinelearning,Z0FBQUFBQm0yeGJWQUJ6SmtLSzhfWXg5T2JCbkdwcVFtRXJ3dUEyLW1KZXFSY3RUZThzTzllQzduODZxZENHM1V6WGR5VTJydWdvajAzanJPUzQwNHVLTHFxYk1CeDZvOWc9PQ==
"As I said, silhouette converges to the optimal range of K, and the results obtained make sense: there was still a steady descent w.r.t. the WSSE in the elbow graph. So yess, one could say around 90 to 100 is your best K. But The fact no matter what you do you can never know the exact best K for the task, and that's the caveat with unsupervised techniques: they cannot classify data, rather let the human *explore* the data.

  
What's next, you might ask:

Next part is, in my humble opinion, to stop looking for answers in the model and start analyzing the data itself: What's the domain of the data? What are the scenarios we want to cover with the K clusters? E.g.: I have this sensor that magically retrieves features about flowers like size, petal length/width, weight, but not pictures: without them I cannot deploy a human to label this data. But I know that this sensor is in multiple flower shops of New York and the sensors are acquiring data around Valentine's Day, I can take an educated guess and speculate that we're expecting a large cluster (the red roses) and 10-15 more clusters about other flowers (can be close to the large one, and those are the white or black roses, or can be really distant like the generic flowers for a wedding). Outliers must be treated: I bet that some niche flower shop has these crazy exotic flowers that no other shop has, and those are going to have a cluster on their own or worse they are too distant to the rest of the element of the clusters they have been labeled to.

  
The model itself did its job and can only get you so far: you have your k and you have your nicely cohesive clusters. But the best K? No one knows it, that's the point of *unsupervised* learning",r/machinelearning,Z0FBQUFBQm0yeGJWYWVxeFFQLVZ3RC1WSDR4d2F1YmR0MlFPNXhuS0UxcExxLU9yY0ItUWpqOUtqVkpTa01CX0VXazFaRy1ab0szRHZlWl9hcFEweUtQd19ybnJnMEZVbWRfS1c5Z2tVbG9iem5ZUkdtak1teUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWdnc3SzIyRXhwVkFxeEhBRGNCQU5zZDJaV0NGOWJBMW9Za1ZuWDZBQkM3bTd5aGRZUVFJWFJUWmVfUG5FT0MxcGdjTjl5d0JjaWpXS1VDMDBwNFd3SFE9PQ==
"Because there is no ground truth to compare the results you obtain with such method.

For low dimensional, convex, distant to each other clusters of data K-Means with elbow method itself is precise: after all, that's what he's good at. But suppose that you have such method, that for 1000000 rows of 1000 features data you can find the best K no matter what. How? How can you make sense out of an information you don't have about a domain that doesn't have a ground truth? Data can come in various forms: you can have a cluttered instance space where the difference in the underlying class is given only by small values of a single feature in a high dimensional space, or data can have missing values, can have lots of outliers, noise, and on top of that you don't even have the Target feature. Good luck with that.",r/machinelearning,Z0FBQUFBQm0yeGJWelEySXFtWHNVT1BQMmxRWER6NzBwaWh3THlLLXNvOGRPTVpLNjU3VWhtdllXN1h0ZkZ2TzBjdkI2bVd2cmNZaUhxM09OamF4eWlLQXNyQnJIZHZHN2Z2RWJCNUFJZTd3b2dSRzdSUHZFSHM9
"MobileNet ? RT-DETR ?

But if for you an A4000 is ""mid tier"" I guess you can run almost everything. Even an old gpu like a 1080 Ti can run most people really fine for inference.

This is more problematic if you only have a bad CPU or embedded device like raspberry pi or jetson nano.",r/machinelearning,Z0FBQUFBQm0yeGJWQVg3TTcxR29rMWZJejNVOHFvMjFESFpnYXoxSHVtTEVxYjBXdkNsWHdYVXBoaWpCMlhvNUVHUEhJNDRKQTdvTE1JTVhRRXVRaXpXZkhsWTdueXBMMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWckczaHRPSzhpSE8xLUtKN1RBQllhRDFZSjlHcnFWMlo5NDhnaEY2MnI5STc1Ujg3UzM3MGZNSXFGVXRLRGp0NXRwaDF6a1JtcmFkbGNCRW5kWVV5amc9PQ==
"Hello, there is a good jupyter notebook with the name 'Which image models are the best?' by Jeremy Howard (Deeplearning for coders). 

[https://www.kaggle.com/code/jhoward/which-image-models-are-best](https://www.kaggle.com/code/jhoward/which-image-models-are-best)

Maybe this will help you.",r/machinelearning,Z0FBQUFBQm0yeGJWQmRFZFVValhKNS1XajdwdnNKVXJqR3Boa3VRQmRrUlNmS0Qtb1pUVWJyUlVvaVVPV1Jwb1J3aVJwcHVmVTFLckF2RE1LYUx2Z3FZTnNnU2tjTXBReFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWY0Q5TTBsaUVXVjNEREgzQm1zMk5YLXJfVGpDZ2RqbWVBeXlSM3lXN19WSjVFdTJ1MUVxbTg0S0pMRkx3MlRfck5kT1duWXhfY001SE4ySjFzZ1RZZ1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWb2stV0lETXlHMkxyWDJPUkw2dXg2TlUydl9YbENndW5JdDJ5RDJuOGl1YUZwSjRhcURBNXJmdzJqck55Tm1uaUFYNkFnZzJvVHB5QmJUM2dkRkx5TkE9PQ==
"I am not suggesting using papers ""as training data"".  The GPTs (GPT4 and Gemini Pro) can ""read"" PDFs uploaded as part of a PROMPT, as-if typed-in.  This enables the GPT to ""summarize"" or explain the paper during the Chat-with-PDF session.  See [https://aistudio.google.com/](https://aistudio.google.com/)   This upload of PDFs is manual ""Augmented"" Generation.",r/machinelearning,Z0FBQUFBQm0yeGJWU2R6Z2FZeHJPRU5UM1hxeE54eTV4eS1fZjBNa0xwVmVkWDA2d2FYdnprU0hwYUk5QUJSX0xBbV9hUDNPNVp3a2dVc3NZZHlSeS1yOTN2VjBCaVVIeXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWenVqbmx5R0psUTI2bHVIcmswLUFyNVN0YUdIM3JiOXdvbDdXTGthS3hKRVBaTnFpak5ROWx2RXBUQ01XSndGTV82REV3WVVRMzZVWFFadmdhWnpjQUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWVDlsOUY2MEdwaFgzUnhtdFpuZmZkcEZ1Zi1fZWxNa25LR3JoZVFyV29wY2pNNkVENG9LQ3l1b3lWQmJPRnFKUl9EM2NsRmJPc2Njc0J5QjhnNlNkdFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWcEdDb0UzbDFEWnF4MWc4d3VMZ2NVWXZmdGo0Q1pPTDRTYzQyNDJLZlQxY01vWXotT2xERkpuM3c2ZVIyOHlCeHNad2hsRWRpMFNWR2txelgwQTVQd1E9PQ==
This is a really good point. Are there any sources supporting this?,r/machinelearning,Z0FBQUFBQm0yeGJWLWJkZE9oa0dtZ28ySkprbjFwOTlnSmkzLWRlOTBoODRIazNYc1FhcXA4UkM0eFFyRmNkNlMwTjBGWWpjVWhoeWt3SHRGMjJ5cnR0MktKUTUwUF9DYUFaSkV6R1ZkRU10TlAzbjJRSkxVSFU9
"> if there is some company offering labeling as a service that lists a few major players as its customers, that can be enough to make execs prefer them

https://www.cnbc.com/2024/05/21/amazon-meta-back-scale-ai-in-1-billion-funding-deal.html

Fast forward to 2024, I think what you said mostly holds true. Do you have any updated thoughts regarding Scale AI and its latest funding round valuing it at 14B?",r/machinelearning,Z0FBQUFBQm0yeGJWYjFpTXZsdkNPaFZHeXBjR05qVGtkZ2ZPb1ZIZkdvMVN1LWw0OTZoVU92cEhGRGY5alhPMFpJRkM2cXZvQ19jOFBWZ3F2bXZycHR1eUE2MmlPNDZjNjhneEM0Vld2U25adUFTc3ZRQU5IRUE9
"Lately he stated the reasons why the brain does not do backprop.

But in a recent interview he was asked : ""what is the one thing you'd wish to know if you had a pass to answer any question ?
  - ""I'd want to know if the brain implements backprop in some way""


He's both brilliant and humble, so he admits he he doesn't know.",r/machinelearning,Z0FBQUFBQm0yeGJWcTNkUktVV0kxUklfTUxTZFc1UVNzYUtrZ1gxTEY2N3FFaTdlWVVWcDlBUWcwcU56SDJIeGRMQVVhbmRXYThBX2MwZjlHNzFzVEktVFlsYzlSamdLNUE9PQ==
Submit and find out,r/machinelearning,Z0FBQUFBQm0yeGJWSWU3aDVOMW8yN0RDR3A5T3JHcHBvdm9tM3VSNmtZSVBENFFEeHZRSkZMV01oa24xcUlKdzJCTndaUWFCRzdlejlOdWZfMGlFVU1oY2FJbWpVVkJvMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWbnM5SGFCV3pRa2MweUFmX2Q1UjNmTnV5cGZ4R1J1dkNGWmtRRGhsRFJFaXluNWJFRGVHVDdaQ1NmcjhPSWdodUh1cFVFZG9CeXdUV242SHFOOElYelE9PQ==
"I don't understand why you would want to take a graph structure and put it into a continuous embedding space. This destroys all of the edge relationships in the graph. 

What are you trying to do with this data? Are you trying to use a mindmap query to retrieve another mindmap? Or a textual query to retrieve nodes in some mind map?",r/machinelearning,Z0FBQUFBQm0yeGJWaWZYZ1VuTGJLc3otV3NTVmxMVUhxd3lXRUtpenFJSDdrQlByTjlhTzRvdDg2SVc4ZUlNOXZkZ05oc3lRdVJHR09HZ21WRC1aelF2WFBuLTJLSmpETlE9PQ==
"Add a PhD advisor (perhaps the professor of the course) to the paper, 4 undergrads are (likely) not going to make a good submission and it is marked as a student paper sometimes.

They will also tell you if the work is not novel (I have a strong feeling it might be not novel).

Edit: I will elaborate because I would not listen to myself if I would be you.

1. You don't know to do literature review.
2. You don't know how much of a cult academia is, reviewers might bash your great paper because it is not written in the way the cult expects.
3. You are not in a spot to detect the weaknesses of your work yet, it might be improved if you add a good researcher as last author.",r/machinelearning,Z0FBQUFBQm0yeGJWU1dQNjQwVThHem85YWdZaVRQTDJHR3FaN1RNNEZRVFloMmYtbWk5NEhSYk9oZmExd0JDXzlNc0JGV0U4WGM2WGNuN1RXN2Z3ZTJIekNnUlpaeHVNMWg3aVhmY0Rfc25PMG9VN3NTV2VIWk09
"It could be worth a shot, but you should talk to a professor first and have them review the paper.



Your barrier is likely not the fact that you're undergrad students, but that the work you're doing as part of an undergraduate class is likely insufficiently novel or impactful enough to be accepted.


Also, most ML work is published in conferences, not journals. (Although very ""applied"" work that cares more about the domain than the ML tends to end up in journals for that domain - like an audio processing journal).",r/machinelearning,Z0FBQUFBQm0yeGJWU08zTXQ4OThzZ2J2am9ieExUdENQNXdpNzBYeHdScjNSNEhIX0dqNDZEOHVfbm15VkdKVzVZN2IwRVVWNlNJQkNJVS10M200MXJ6Uy1ISGI0S1hQREs2STFMNDd5eEF2SlRkMHpNNF9SUWs9
"The reason why clustering is hard is there is no ground truth.  Unsupervised learning is much harder than supervised because there's no non-subjective evaluation criteria.

What's the business(real) problem you are trying to solve?  Is it marketing to these clusters?  Are the smallest clusters reliable?

Have you looked at data elements near the center of each cluster?  Is it ""easy"" to determine why those central points are different?

Can you label some data with the clusterID then predict the clusterID using any ML classification method?  Can you predict cluster==X vs not X with ML?

With clustering it's usually better to decide how to decide first, or at a minimum getting input on the maximum number allowable.  Get mgmt to agree on the criteria and then do that effort and stop. Of course you may wind up tweaking the rules a bit once you see the data, but then that conversation is a bit easier as you need to decide if that lift is worth breaking the established rules for picking the clusters.",r/machinelearning,Z0FBQUFBQm0yeGJWNkNmaUVDRXJuNkF6TWZZeEx3UDZmSmVBeEs2MktyVmJUZXhhQ0dCQTBOaHBPM0szSjZXMktoSVVJclR5MUxJMDJ1TjQyWU5qeVgyXzZYbDRRSm8zdGc9PQ==
"An LLM is learning much more than just the language. A child could be considered fluent in their native language, and yet an LLM has a vastly greater 'knowledge base' than a child. How many tokens does it take for a human to be similarly knowledgeable to gpt?",r/machinelearning,Z0FBQUFBQm0yeGJWeV94dFllNUxQTnVkU1NTSm10V09IVGRzWmFBV0NhcENOYlNmTEtuT05Lc2hkSUlNaGRkVEI4RXBDeDBEQXBxOHk5aVZhTFNZTkVnY0xQZVJKVzdnc3c9PQ==
Fair enough!,r/machinelearning,Z0FBQUFBQm0yeGJWSmp0OWNTTDlBZ0Z3bk9NZ2l4Ui1DSVdHTEUtRTRPS0FaQkxXc1JnWWktSklGLXBSSm91QjhZZEZYSG8xaUR5M1U4amZubFh4VkdoSElXWERCY21YNnpnQ1RBWElJZl9XV3BqWDJhWHhmR2M9
"Thank you for your insight! I didn't know that about the submissions for most ML work -- that was really informative. Yeah, there aren't any pressing deadlines for this paper, we just thought it would be cool to get it officially published out there in some kind of journal, and are willing to do any extra work it might take to get it to that level. We'll definitely consider reaching out to our professor for our course. I appreciate your comment!",r/machinelearning,Z0FBQUFBQm0yeGJWel9BUHJnWTFVcjZBb2lnQWJrb3J3SGlPbUZocnIzZzI2eGdZQkVvZUQtNWRKeGw2VUxfbjYyV3JINzJ3TWs1T1FLd3dCNlB1OTRNekxHV2p2ZDBCMjBLaFhteWVFbU1oSzNPaDk5QmFOWU09
Thank you for the suggestion. I'll look into reaching out to my professor this summer. Your comment is very helpful!,r/machinelearning,Z0FBQUFBQm0yeGJWUDRCckNCQmxiaXdsb3FKVGw1cFNBMl9WNTgtME5IVGN1NEtZNm11czZ6TEs4TjExd3RHS2pXRmtaSG1MQVljeUQxTzVNa2xXaVVrakdXb3FzU3dLOGd0aDdBejhTaVo2d25IbFRiMjNtbTQ9
Happy to help!,r/machinelearning,Z0FBQUFBQm0yeGJWYkdPTzZPOG1raDdmOHNLVkZha0V0WGZ6WEkzeUl3Z1F4R05iN2V2dW5fdFVkb25nU2R0czVITWNRYTZ1a3ZFem9Ed2R1MzdyTzMwVDVFN0RKa1p1U29zQnRMeGhlTHA2R09vbWFnMjVkdmc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWM1oyTUIwTjR2Z05aWl9NWHVJalNjb0k0RUxtRXFqUkFMaDdFMzBsUmRXa3JULU95THJtYmFvek52OE1PTWxfRjdydHdOb2VTTzBCYmdBVE9DemItbEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWcmoxMGhfNEVYZEdadkJiMDV5azJHMW0zcUJLRlJzdXQ5eGJGNERMT19vb01uQzFkdjE1cmFVdWxEQVp6SGE0S3JqSG5TbFI2eHNJU3Z4anV4N0VkSEE9PQ==
"https://arxiv.org/abs/1905.11946

efficient nets are probably something you'd like - scale image recognition down to a cell phone format, but scale up as resources increase. those GPUs are typically quite a bit weaker than a 3070 or whatever",r/machinelearning,Z0FBQUFBQm0yeGJWZjdjWFFCZGNWWTdvOWpJNDVQMzZpemVCS3phdmdHQ1lWSmlkLWZGVkViQ3RidHdxWFBZQ0FFTW5rS0RZeDJIRnh2eWhfejJNWTRTLWhYSEM2V2g4alE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWTTNSRWpLSTR6QURfajE0MGRaNkc3b185RVJ1YXhKUFhfMnFHQnNIZ1FIN01XNEJOazdSc3kzaWhITExTMGt2UkR2SXQ1ZjBPYXhEMENvYVBrMVRxWXc9PQ==
[https://www.nytimes.com/2024/05/24/technology/google-ai-overview-search.html](https://www.nytimes.com/2024/05/24/technology/google-ai-overview-search.html),r/machinelearning,Z0FBQUFBQm0yeGJWUEpBVWRIZnFJNUgydjBNc0RSVHZKbkFLV2s3RWUyUHdUTnlXZGpPejlkWGQ1MWRuX0tnUklTNnU0dGFRMzZ1VFppRlFUOV96ckp2U1NLVnJsTTBhUWc9PQ==
"it's quite weird of a result and I would check for data leakage, but there's nothing fundamentally wrong with k=1",r/machinelearning,Z0FBQUFBQm0yeGJWYW8yODB1TDRWMVZuQ19OVDVLTFREUmF2dTZuTS1LczBlTWk0S3Z3c1NyS0tyWXpzOG5UdVhLa3U4YmVCY1hfZV9qVTRtVU1wdjhza1FHOFR0QmxJMXc9PQ==
"I used it many times over many months, never a significant problem.  Used billions of times in a positive way.  People sure know how to make a mountain out of a mole hill.  To be expected, since there is money in clicks.",r/machinelearning,Z0FBQUFBQm0yeGJWbnVQUlFUV3FIVEhYcDJRV3JDWEdmV3RTZW9CS250UEJaZVlnRVV0ZVFia1BpU1hPdEw4QUhOX1E5YTZNdUNFZzBraGNMU2s3LXFLdmluMUFGakhsdFE9PQ==
I’m running about a half a dozen of them in tandem on an A5000 with good results. The real issue with object detection is the training set. I do like CLIP though.,r/machinelearning,Z0FBQUFBQm0yeGJWVEtYNFdQRFBRUTVkTVJqVE54a19VZ3F3V3Rtc3pBOFlTSE1KcnduMnhYcm1Fbi1BbkdzR3VQdU00RDREeUNoS3lGVEdjQlRaaHVsNTVyQjJJdVpFLTBNOE9kaGt6QkJadkxXUjRFcWhwOEU9
Why is it seemingly impossible to post on this sub?  Automod rejects every post w/o explanation.,r/machinelearning,Z0FBQUFBQm0yeGJWb1pYSE5BVnVlVUNpSkdZVWhaa3ZtTGVxUXV0ZUFHdkZKdFNZQlJvU1RFTWxHMnNLYlNxWXNzVVNTeXBuZjJpd0RhMmtqSnZyalRhb2JJNThlWjk2MXc9PQ==
"Pretty much everything google AI summaries does can be accomplished by reading the headline of the first article that pops up. It's annoying and does little aside from making you scroll more to find actual results.

Google (because they are a visionless company with incompetent leadership) is desperately trying to hop on the AI bandwagon because blindly clinging to trends is the only thing they know how to do. They should recognize the value of their core service and stop changing it",r/machinelearning,Z0FBQUFBQm0yeGJWbkdNdEEyNTJoVVdZN2RRa05mWGRnRm9BUnJWRVdCdGFzVTg3RlFRUXZnd0toRVFBU2Z0TU5QbjdRaFVpM2Y1VnZmaTBjOWVYdnpVT3ZxUk03QVQ4bkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWckMtYW9RdHpxS3VsMTlmMHBCVjVEaXZtN2FxZk9YYnBCelEtRFR5ZFFCVzFIS1ZoQ3Z0YkhFZURQVkF4MnVKdDdZSEtldlNDZzg3TkQ1SmNMcjk4ZFE9PQ==
I don't understand ur question. The binary labels serve as ground truth. What exactly are you confused about?,r/machinelearning,Z0FBQUFBQm0yeGJWT05QTzVyZ2RHNkwxakxTblhLUmVsTDZnN1RpWHpSMklRUGFfLVgxZjUtNkJJbmh6dlFxcWswYkVWSGw2MW51b3F6V1h2aTU1VmJsUWtSYlhTYTdac3c9PQ==
You need labeled relevance scores to get an ideal ranking of each query’s best result. nDCG will then compute a score by comparing your retrieval scores on passages against the ideal ranking.,r/machinelearning,Z0FBQUFBQm0yeGJWWnFIb2EzZmhlRXVJajBSM045bmh5Vm5wMjgtdUJGLU5KeXNYcmgycUpVclQ3Wm16Y2RYVWJoV3hTcnBSVDhzUV9HcVlrQXZBN01tYXBLdm9jT1Q2UVE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJWbmRyWHBLTGRDREN2dXl2WXFldWhvcXFXRk9ncXRBRi1VVmNTREZfVEZCRkJZUXVGVVcxSkpTLVJGbTcwLU5EcWE3dVVDOV9Ga3UzYUkzRWs2REt4QTNWMDV6SnZhWWVHYUNSdURNZkFrTEE9
"I guess that's what's confusing me. The relevance scores would be different for each query, considering that what would be a positive sample for one would be a negative for the other.

In terms of ""ideal ranking"" I would think that all we have to do is take the retrieved documents and check if the positive documents are in there, then calculate the nDCG based on their position in the retrieved list.

It seems to me like all we need to calculate nDCG is the retrieved list, no?",r/machinelearning,Z0FBQUFBQm0yeGJWNGFRUHR0VjFZOHNZdVRhekQ1YTg1UzVOMnJyNzltTmZ5Ykl2THBJVXNFS3d4bkNPZVk1WDR4TS0yRUdZVXZqR1hMN2JETTdpTS14RDFlRmVEak9YLVE9PQ==
"no, there's no data leakage",r/machinelearning,Z0FBQUFBQm0yeGJWOEExMDBId0hFQ2ozR0k2YWYyOGtIclZ3VWdSX3ZtNWhxSmozZG9SbWhKVmVDckx6Y05kSTUtRzJIZDZ3ZmVzYWQyUEFnNjloY3VJV2NrN01kWVlIMk5WZ1pDLXhZNXU0Q2M3ODJDdDV1eWc9
For every query you need to label the top ranked passages with reference scores. Once you have that you run the nDCG calculation on each query using the retrieved scores and the reference scores.,r/machinelearning,Z0FBQUFBQm0yeGJWZVhvSjJUemxPMlQyM3ZQU1NXalhlXzdWWVUyN3FZUG0zR0E5MjBVX2FWSml3VkljX2VWSUZwN2hFTDNFbUE2UmV3UWRPeklCNlItTk5MRHhiek1GVmc9PQ==
"Hmm so if each query has, for example, 1-2 positive passages and 10 negative passages, then the reference score for the two positive passages would be 1 and 0 for the rest?

What's confusing me is how we would be comprising the reference scores in this case. For example if we retrieve the top-10 documents then those would be the retrieved scores, but for the reference scores we would only have two positive samples.

Maybe I need to go through a basic tutorial or something, I feel like I'm not understanding something at a more fundamental level.",r/machinelearning,Z0FBQUFBQm0yeGJWU21ZcndtbTgzdTdmOEVNN1JjYnprajE4R19USmhFdW1jVFdaS3hmR2ZOLTJacnAzXzhXMk5vUVlrYndCTWJnRXpab0JZaWxNQW1OWEZYM0NJSWxPaEE9PQ==
"I guess I'm confused as to why we need two inputs, when it seems like we only need one list of retrieved items.

Each query would have different positive and negative pairs, so for each query we would have to record which passage is positive and which is negative along with their position in the original corpus (since it seems like FAISS returns the indices of documents). When we retrieve the documents we would check if there are positive samples there and calculate our ranking metrics accordingly. I don't know why we need a separate reference array.",r/machinelearning,Z0FBQUFBQm0yeGJWd0lreC1tdzNMdm1FMFpyenZtdkZqbzh3VTlEclNyNjNLTWJpU3o3TDg0Tm5OdzRNb0dpaU5WM0hHSEwzVnZJdDRid042YzE4bDBZTWFsQ2dKcUFCVGc9PQ==
"The reference scores should be non-binary like integers or decimals, otherwise you don’t gain much with nDCG than using binary label retrieval metrics like recall and precision.",r/machinelearning,Z0FBQUFBQm0yeGJWQmV5QlhNdzNxbEQ5Y1JUYlktS0NNT0pjZkthZUZjVzB2Z1l5dnpZOU1rZEJocER1Rl8zd2ljYnIwR3pDVTA4QVJHLXhVY2U4ZlROckVfWWVwaGl1SlE9PQ==
"Ah okay I see that makes more sense now.

I'm only using nDCG because all of the reference papers I'm reading regarding embedding models and retrieval seem to be using nDCG@10 and recall@100. I also don't know if nDCG is the best choice for binary labels.",r/machinelearning,Z0FBQUFBQm0yeGJWeGw2M2NOV0dpaWpHVTVWRHQyMTJ0cUNSRGNuYnlfNnpEcElDc3I5aHozSExTN1ZYUzRsTl9aQl9OY0F2eFRDaVBLU3pnaExCU2FlTkF2SEo1THZxdkE9PQ==
"No, the AI summaries frequently pull forward information (especially tables) that you cannot see in the title. Google has always been on the AI bandwagon. Peter Norvig worked there since the early part of this century. The think, correctly I believe, that whoever replaces them will do so with machine learning/AI.",r/machinelearning,Z0FBQUFBQm0yeGJWcS13ZDl1cTEwU1ZabVBsLWJ0NFJENGg3VUdnOVRCRGJVY1o1a1U2cjFWYWNDcUt3SzZRNjhjSExhNTBvR0NfS2p5aDFveGRwUlZJZVBTeEF3Ym1adnEtNmtoWjFrVEplMGhtSEl2YVlZUHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJWTVFSeTlTa3NOU1Z5S3hmUGxSdnVfM1hlM0p1UUs1V1ZjbzBYb1RQYVhxQWtyT1Z4bFRHZVJtaEFRLWpKNFJ2QWpwM0g1YVdyc0xtN2tOaFEtUEtXekE9PQ==
"Are you kidding? I know it’s fun to be a cynic, but have you no knowledge of the profound AI research being done at Google? Look at their prevalence in NeurIPS papers. Look at things like AlphaFold, or anything else put out by DeepMind. “desperately trying to hop on the AI bandwagon”, homie, they are doing just fine.",r/machinelearning,Z0FBQUFBQm0yeGJWUmNUZy1vLWhFQUcwSlplLUhJc01ySzZaZjRKa3pFSFI2YVZwMzFtR3d0SWcxRUhfV1cwSUwtQ3RLWXNOczVydHZxM04yLUhTaXNteVUxNE1Nc2dWeWc9PQ==
feel free to discuss everything here or if you'd like more information,r/machinelearning,Z0FBQUFBQm0yeGJWTzJSMzFkSVF3VGxxbTRYZTk1a3lCZGltclFaYjc1NUZoMVdjcVRTby1CVkxKNW85aUFTSWd6VTJER05zLWRmQnYwMjFvd2EwZWNXRHNncnJwakY4Rmc9PQ==
"Yes, only the two positive passages will be ranked as a 1 and the others are lablled as a 0. If there are other documents (outside of the two labelled positive cases) that are relevant to your query, then you are out of luck, and you cannot accurately compute ndcg (you may retrieve documents thst are not in ur golden set, but are truly relevant). I guess we need to know the details on ur evaluation dataset. 

You can also just score the 12 passages using ur retriever, and compute the ndcg using that way. But that's not a super accurate way to compute ndcg@k assuming you have a much larger corpus than the listed 12 passages.",r/machinelearning,Z0FBQUFBQm0yeGJWRmkwMkNTQ2ZNYVBpdUxHYUdRcDJCWDVSODlrUDY2cGtHYmZyc1Q5TFNoQTgyNklaZDh1Z2c2bDdyN3hVd3NobENaa1d3Y05IUkNEUXVIQXMtdHNiTXc9PQ==
"The benchmark I'm using is the MIRACL dataset; it seems to be pretty standard for multilingual document retrieval these days.

I tried doing what you proposed, that is, just taking the positive and negative passages for each query and ranking them, then calculating the score. The problem is that, as you rightly pointed out, this leads to a misleading high score considering we're not using the entire corpus (i.e., the entire positive and negative passages of other queries as well).",r/machinelearning,Z0FBQUFBQm0yeGJWbV9KM3drU2xMYk1fMkNTTzZncG9nMV94Q2VEdHRyVllZbjZWNDhZNUVqa1pRU0J4Zk5vRDNQQ3I5dFBMX2ZvVHJ3RFA0MDJ0cTJYc1Q5UFNiWjVrYVE9PQ==
"Well - there are plenty of people who don't even look at the page AI Overview is summarizing. As a matter of fact, many think Google AI is giving an answer to their question. Now - when the answer is derived from unreliable pages and the model hallucinates on top of that, giving answers with authoritative tone - that is a problem. At the very least a PR debacle.",r/machinelearning,Z0FBQUFBQm0yeGJiQllSaU1HZkVHVEthcUx5TkZlSXlXNHh3VTJvY3pIQ0JMOE8zandMSWtaa05uVUlBWS1TY29KWl9yVW1jRnNCZnVBZHRmdDUyMlFLWjAwenEtSks1OEE9PQ==
"Hm I see your problem. Based off of the miracl paper

> To build MIRACL, we hired native speakers as annotators to provide high-quality queries and relevance judgments. At a high level, our workflow comprised two phases: First, the annotators were asked to generate well-formed queries based on “prompts” (Clark et al., 2020) (details in Section 4.2). Then, they were asked to assess the relevance of the top-k query–passage pairs produced by an ensemble baseline retrieval system.

It looks like they used a model based approach to get their lists. I'm not sure what the common practice is here. I think you should use faiss to retrieve top k results. Then, you should also score any positive documents that are not retrieved in ur top k. Any retrieved document not captured in the original labelled list should default to a label of 0. Then you can compute the ideal ordering and ur ordering and compute ndcg.

The assumption here is that they have a good coverage of the positive documents for each query. If they don't, then ndcg@k can't be reliably calculated.",r/machinelearning,Z0FBQUFBQm0yeGJidEx1Z0Fac0pUUGJoQ0NYenpqcFZMbTVzdDVVdWxSU3BEREtRMXJHQXBCelg0aFFLbzBPSlZSVDFnSElDdDR6amJ0UE9jN3VHeFhtNE4yczB3OUpHaHc9PQ==
"I have used it for many months and it has been wrong (i.e. hallucinated) 90% of the time, I found it completely useless and if anything - distracting because now I have to scroll farther to get to the actual results",r/machinelearning,Z0FBQUFBQm0yeGJiNHQyT0lWR2pDT2p5ZjFqNmRJUjlpUUpIbDMtRzFBUXpxazkxQlYxU1Q1bkIycUUtTUpJdFduMUU4MXdZNDh1ak1DQ3VmdkxvdWVVYWo4anA3UlJIQ3c9PQ==
"Most of their products suck, and this particular product sucks big time too. Researchers have zero interest in building and maintaining products, which shows here as well. The running guy is right that Google is desperate and it's not a good look, I have always been saying that perplexity is just a wrapper on top of Google search but right now it's clear that so far their AI search is far superior to Google's.",r/machinelearning,Z0FBQUFBQm0yeGJiTEJmcjlRU2l3WHl6cHhSYm5UdlNGa21IbUVVVjRCMmZERkhtRlY3NWxYUW9tUUQxVWpQQnVEeF91OGtCcjY2VHItajhCYURZLWVlWjhUNldNVWI0V2c9PQ==
"No, it should not have been released, this is such a shame that Google is releasing one after another such poorly tested, poorly performing models.",r/machinelearning,Z0FBQUFBQm0yeGJibk40M095WmFrbTlOUVN2Tk55aDF2RTM4UjNYVjhpbElnVWtCcC1KcVN0VXBKV05QT0RzS3ZDLVZITlZMZjhBOWlKTU90cXk1YnVjd2Zlcy1rNnMwR2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiWmVNekNYT1JRalhtTVNRRHh2LXhGS0JLbTlmZXlQNHJUWFdSOU0tYUEwUjFRb29vNlY0NTV3QkFjUzF0TDhFbmU5SnQ2LV9kSVlQYVp0WlIzVzA2MlE9PQ==
I never said they couldn't do research. At the end of the day Google releasing bad products is on leadership and them doing good research is on the researchers themselves. The fact that they've blundered so badly despite doing all of this great research is testament to my point,r/machinelearning,Z0FBQUFBQm0yeGJiV29RNEVzSWxpV0N6VXhNV1ZINUZRZUh0V0xWS2x6c3BFQ1MwcEhlTktUczZsbnQ1Nl9tYTA1ZGhKc2lYSFZlQTJCRHViei1RTHBobHlYbXNrMFQ2bEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiWU5RTkNId20zcGw0QjFvY2hvS0FzQ3hJV3JneWg3UU8xQks4MVA3TWF5eUVBbWdWRmZLdnp0UXc3X3JtNkptUzV3aGVEaUNJa0E1c2JuRTBQVmxJOEE9PQ==
"I'm going with ""no"".  I say this as someone that's fairly passionate about machine learning.  My objection to the release is based on these points: 

- Since we can't tell if the content is hallucinated, in the best case we're left checking results that have been moved farther down the page. In the worst case, people take the result at face value and it's wrong.

- The content, be it right most of the time or not, hallucinates frequently enough that it's embarrassing. Google was always competent at more subtle implementations. Their computational photography was absolutely state of the art. Photo search was top notch. Clever algorithmic ranking used to be great. It was the quiet, carefully considered applications of ML that were most compelling.  This feels like a vocal ""behold my greatness"" when really it's a flagrant demonstration of something that is mediocre at best.

- I can't imagine the carbon footprint of all that inference is small. Since the results are, as mentioned above, somewhere between useless and harmful, it's just dumping greenhouse gas into the atmosphere.",r/machinelearning,Z0FBQUFBQm0yeGJid21yQUcxVVhPa054dXBTdkF3M2pETkF3SldQTnJMR19rVjNJUWZkUm13UDE2MkpFZlVmNk9vdWNGbjJVY0x2OE5KbURERkN0MVFpcXlLTF9xTVhaN0E9PQ==
"Can you explain why a pre trained LLM is fed 10 million tokens from a new candidate language and ends up understanding it at a first grade level? 


A human with a million works would speak it fluently",r/machinelearning,Z0FBQUFBQm0yeGJiSlJvQWx5WFR4TWtjb0IyZWFnZlJDZEgzbFh5MUVVVkM3eURaZGdpSlg4X0RfT1QxMVBZUUFoTl9pbTFKZkJGend0QjlLVzNwbEwyZHpucUU5TDdPTVE9PQ==
"Ask Google how many rocks you should eat every day. Then ask yourself if you really should trust the results it spits out when you're searching for something more archaic but also more important like an error code or a product specification. Can you afford for that information to be wrong too? So now you're having to do MORE research than you originally had to because AI scraping and re-hosting stolen info to game popular search results and claim their place in the results overview.

""AI can make mistakes.""

Allowing companies to put that disclaimer on their page when I'm looking for information has broken a hell of a lot of trust with me. I'm genuinely worried that all information that is useful is going to be locked away behind paywalls all over the internet by the time this debate is over.",r/machinelearning,Z0FBQUFBQm0yeGJiOWRFVTRLZlJac3U0bHFqTzZfLXpmYlRQaF9UbWYwQ1lQdnJmckVzY2QxSmVGQ2xKeV9IZlBQcWR0c09CaUVlNno2VHh6bzRaQWtabTVPTHRJbVd5dlE9PQ==
Same here. Someone mentioned the other day that you can use a tool like ublock origin to block it - you just have to configure it with the name of the html element that contains the result. I plan to try that.,r/machinelearning,Z0FBQUFBQm0yeGJiM2xlSzRFS29iRmQ1aENITjY3bVBPLV9vdXotektVUklOZTluRzVCNWw3V2p2Qm1YQ0puWU5Nak1oLTBiZEpEbGlWZTZzaE5yNTYySHpLWm1rMnhoNHc9PQ==
"AI Overview is a solution looking for a problem. I would rather get my search results directly from the source material than trust an intermediary translator. If I'm doing a research project for a college course for example, and I need to site sources, AI Overview is an obstacle and not a solution.

And who knows, maybe Google will some day sell SEO services to organizations who pay for ""their"" summary to be more prevalent in AI Overview over others.

Here are more examples of its incompetence:  
[Google’s “AI Overview” can give false, misleading, and dangerous answers | Ars Technica](https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/)",r/machinelearning,Z0FBQUFBQm0yeGJidzc3NmZzTHFPTUZsRnljTzZ6RDhOaDFuMnlTUW1aS2lOV3htVWJ2R3JLSU52dk5GTlk0Yk52WDZzeHVBcW1JcENLZy0zMmYyUUExbTBockV1M0hRQ3c9PQ==
Gotcha! Thanks. But the changeable or learnable activation won’t affect the output for previously trained data?,r/machinelearning,Z0FBQUFBQm0yeGJiNl9mV0VGN1ZQRVJFMjJ3c00zT1NYMDRZcEZhbkNXMmQwZVd0VTZTY2hLSGNyN0FOYk1xcHZxV0hNS2IyVU5JTFMtTk9CcEx2OGVhcE5XMGVQeF9XVkE9PQ==
The problem is they didn’t have an AI product ready to compete with OpenAI. They rushed something out in a hurry because of concerns that the lack of that could impact their search business - even Bing beat them to it. The current issues are a consequence of that.,r/machinelearning,Z0FBQUFBQm0yeGJiUXZ3WGxLeGFfTTJRSmRkT3RzdzJfdFplX3hjeFBjYlhrMlB4cHF6NTdnR2FIMFJrQXNJQzZTRjBQa0w0QThBQ254Y3Foc0Y0aXp5Vms1SlVpTTdLUlE9PQ==
"similar, not ml though- https://apps.apple.com/us/app/fotomoji/id1059790290",r/machinelearning,Z0FBQUFBQm0yeGJiY3NxLXMyZjFYelFnSjBYZFAtMS1YT093S1k0cWRSQlV1U0FzVFVvNHk3QTA4OEJ5N3lCMmxmYjlLdFlDd2xxVGFQX3NuSTJzajVZYlRYWGw5SDl5ajgxSzZNN3JqRFRfWkcza0dPcnNXMWc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiRUZ4MDZTVlV0X0piUGZMR0pidmFFOU52MklpSFpnU0hPNXJDbTdLUWdyZlByeGktOXZzeGRjdDdndzhmM0FnWU9WcVhKZUtMQ3RJT0hZWVRWb043R3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiUTNrME05RjNEVFVnc3RMaUZJSjVsOExxYlJPSEtteG1sUDhoc01mdE1nLVZBU3p0ZkVoZUVzaXMxNUVuZl9IdWhLd25HVXB2MzEwelRxSF9OTjNqTVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiaTl1Yl94aFYzNTZDeFZ4dXdPRmJzclpLSHdfcUF6SHNiRDlFR2pyOTRSZnhyQ2dvbkJiQzRoaEMyRFhxcFliOXgtOWJnUGYyTEVpRlZPajg1WVFPTHc9PQ==
"The anti-AI mob has cried wolf so many times that even if AI Overview really is going haywire the ""lol eat glue!"" Headlines tend to make be believe the opposite. I'll wait until Google actually pulls it offline.",r/machinelearning,Z0FBQUFBQm0yeGJiTV9WRDREZWstLTV6a1gzeVFfZ2tITFgtS2dPWVlJaUpScjc5WS1zNkRBWUY4OF8wZF9UZUtNeDZpRktGbjZSUzBOVV9rQ0F2WGU0cnItcTRZRk53S3c9PQ==
"Two examples of what I believe is the SOTA multimodal pretraining technique is in the Llava paper and the Qwen Audio paper. Essentially, they freeze the LLM during pre-training, and create an encoder that encodes the stuff other than text into the frozen LLMs input space. Then the LLM is finetuned on multimodal instructions. This way the LLM can ""understand"" multimodal data without forgetting its text understanding.",r/machinelearning,Z0FBQUFBQm0yeGJiQXZ2LTZ5RVFYX2R6TXpIeHFzdHdVS1ZMSWg2YU9WZ3AyRGtZcFYyU2RQVXJ4aHViMGFPZC13R1BGQUpha1ROb055T2FETEw1MnJjeTgtSUh4QXJ2bXlENVR4RjRleHRyTDBjMFRUMjBlSG89
Or even HDBSCAN,r/machinelearning,Z0FBQUFBQm0yeGJiVDFEalVfaWl5MTBicFhDQTZGMG9RUXI3SUdEOFQxQThRZE9xZ1gxZVYxalNheS1lWUdtc3NPRjA4Q1pJWVVxUTNhbkJoS1dnWXIxaUxaLU1FUzhBcVE9PQ==
"I know exactly how it works. You do know that anything and everything that you upload into ChatGPT is saved by them, correct? Their user agreements are also very vague and some have argued they do not protect against uploaded data or prompt text being used for future training of GPT-vX. If I am doing that with my own data then so be it. But when you review a paper you are looking at someone else's data/property. I would never upload someone else's intellectual property into a LLM without the author's consent.",r/machinelearning,Z0FBQUFBQm0yeGJia2tCYUlhNkZJal9MT0xCdFpfS1VaMzlDRUhWV01zcWNiRmVkMlBSVDBuRmNPWFJPNms2V0JtOGxnam42U01WdlZZd1ZndDRPTHRPY08zX1laUUJLSUJhcUJJWGFhTF8wcWJqTzJ2ZHhsajQ9
"Yeah, but even when they do that the vast majority of the time the same information is repeated in the featured snippet. It's a feature that does nothing but clog up the search results 90% percent of the time. 

Stuff like this is why people are turning against the field of machine learning. If these companies accepted LLMs for what they are (personal writing assistants and little more) we'd be a lot better off, instead of the current scenario where you can't watch an NBA game without 500 commercials talking about ""AI"" and not even showcasing any tangible product.

Before AI hype, Google was actually employing machine learning usefully in their products. Search suggestions and Google translate being great examples. Not so much now.",r/machinelearning,Z0FBQUFBQm0yeGJidTJuQVJ5V1VVVFl3TnNnTlV3NWxBeDRUV2VRN0NLd1R6a2FEaDJMbHpQOGlPbkpzN2V0QVQwMnp1V3l6d211Z2NOT2Z1WXR5RGd2aUFMRzJUcEF3NWc9PQ==
"If it were a non-AI product that were as faulty as it is, no one would excuse it or think it ready for release. Think Apple Maps day one. AI is cool. I find it super useful in my day to day already. It's not ready for prime-time, front and center placement, though. It's still to be used with caution.",r/machinelearning,Z0FBQUFBQm0yeGJiMkJDa1NNYU53QlpLUU1ReHBoRmNDTF9wU05BRWpheDR0U2FsUU5yTXpLTWFEZGYtblZUWkJyOXhad0I1SmNSVW1WblliUUJzaVJqc2tsNnd5TFlZSkE9PQ==
"[https://distill.pub/2021/multimodal-neurons/](https://distill.pub/2021/multimodal-neurons/)

[https://poloclub.github.io/cnn-explainer/](https://poloclub.github.io/cnn-explainer/)

[https://poloclub.github.io/#research-ai](https://poloclub.github.io/#research-ai)

[http://ganalyze.csail.mit.edu/](http://ganalyze.csail.mit.edu/)",r/machinelearning,Z0FBQUFBQm0yeGJiYmxNYnFrR1NDanE4QUp2dkhwajJlZEdSQ29kdkZhQkY5MmRPRnNHZXozUVFGX3VFOTlDZU94OWlBMzNxc25iTnZrVkhsd1FCWVl1dy03R3RmQ1VLYUpEemFJQ3M3eDY4M2doUmQ2NDBqb009
"Just briefly looked through all the links, and the 1st one is really interesting. Hadn't come across this before, thanks!

As far as I could tell, the other three deal majorly with CNNs, correct? I'm looking more for interpretability in ViTs since a lot of explainability work is already out there for CNNs.",r/machinelearning,Z0FBQUFBQm0yeGJicUh3Y2xIOEh1QlZMWU5GWW9BdlVIUG9hZWg0T3RrNWFDLTlic256Rm1FVFJua2dQMThDblVYbnprOGhub2NpaWhFOTFLZi1vbGFyY3JfcUZ0Sk9sbC1UX3Q1MVF3UXRrQ0xaSTBqMzhmbUE9
"Depends a lot on what you want to do with the clusters.  
I generally go elbow if I get a clear answer. If not, silhouette can help narrow a range for K.  
I can check the porportion of inertia explained by the clusters and set an arbitrary threshold. Sometimes I check at the coordinates of the centers and stop when K+1 creates centers that are ""too close to one another"" (kind of a similar idea to silhouette, but I'm not looking at the average over all dataset but at the proximity of the two closest centers). Or when I have no interpretation of the extra clusters, or...  

Basically it really depends on what I want to do with those. Different use cases may require different levels of rigor.  

To my knowledge, there is no objectively best way to select K.",r/machinelearning,Z0FBQUFBQm0yeGJid0E2aGZjWUJNaXV2R1V5SU53akw1WjQwMFdITE9HVG56OEdlakNtcDBDcTdMR3QxbmxIOEdScVRJNTc3X3NWOXBUM2M3QkNHTktLNGhmczBOX1JJWGc9PQ==
"The Verge constantly publishes anti-AI articles, but their podcast makes it clear why they hate it so much - they see AI as a threat to their business model. That’s not necessarily wrong, but it is biasing their reporting. 

I am completely okay with new technologies putting companies out of business, that’s just the cycle of life.",r/machinelearning,Z0FBQUFBQm0yeGJiYzRtcjF0SW5aZW45Y2JodFF2V0tEZEc3NmY2bG1sYVRWZXlFUGNRRE90M2Z2WTFCSmhNLTVwcm5tM192NmhFNDlpZEw4MG5aMU9HRE9ZeW9lY3RZbmFTclhwZC1Vd2RKaE9UVjNkamRVWEU9
dude. murphy is ML bible. Not DL bible. :),r/machinelearning,Z0FBQUFBQm0yeGJiaUxBTl80NHhzb3pLOGdFVDdrYW9RUlRFaFYtQ0RQbVFENmdBZXVudjlLcVdFeWxwZWI0eUplanpta1h5SHgwUHdHcHBTSkhVaXdIMl9iZGlpVDJDQ2c9PQ==
"Hey thanks a lot! Also, gotta keep the expectations to something lol. I hope atleast people new to deep learning will find it useful to go through the source code to see how things work and maybe use some code for their own work.",r/machinelearning,Z0FBQUFBQm0yeGJieXR5anoxWm5kWi1TZ3pVRlZVckhWTk44dTlHYWE3MElKeU93Z1lmeHVsNUQ4UWxMNFg1bjVWVm9VNkVjQVB3aFhVU2VDTExpOFVxRVk2X1M4U1d0VXc9PQ==
"If you take the cumulative graph you'll see that after 7/9 the ""area"" below the part you selected is very small compared to the total area below the graph. This means that 7/9 clusters would only explain a small portion of the total variability of the data. More simply : you lose a lot of information by flattening the space from 36000 to 9.  

Depending on what you want to do with the clusters, losing a lot of information might be a non-issue, or it can be a dealbreaker.",r/machinelearning,Z0FBQUFBQm0yeGJibVRtSG5PYU0za2tFTk51ZXRiaXhzaG5PNlJXTHpOU2F6ZHNNb1J1YVB2UXJnV1NFbHBQRS15SHd4dS1CVWxfbVNERUxRQW1zdmIwWjBndUU4N2JvVFE9PQ==
"> If these companies accepted LLMs for what they are (personal writing assistants and little more)

That’s not really true either, they’re useful for more than that. 

The tricky thing is that they often *are* quite good at information synthesis. They can answer ungoogleable questions like [“can a pair of scissors cut through a boeing 747? or a palm leaf? or freedom?”](https://chatgpt.com/share/f182b495-7ae4-4c2d-b9b9-9626cb7337ea)

But when they fail, they fail in the worst possible way by giving plausibly-wrong answers.",r/machinelearning,Z0FBQUFBQm0yeGJiN3hrZThjcFBGOVZsVk1xNU80anBMSjZ5NTZzTlhnS3VoX3QzQmNkaUZVbXhVMXE5MkxnYm82cGNkTXFNaC1FOWhwYWRFZnAtU2Uxd1Z4b01VNmE0aXBaN3VUZTZEeEpfLW9pMmpObC1PckE9
"I highly doubt that every PDF uploaded to google Gemini gets used for pre/training, or that google supposes that copyrights do not exist on pdfs that are uploaded.   I cant afford your level of inhibition.",r/machinelearning,Z0FBQUFBQm0yeGJiWW9LdmQ0andKeV9DNDlRV3lsZ3NZeDJKNzhiV09xYlBIV080UDBIdWhOQUdYQ3dSeTlQSEJlRTZaMV9oWHlTRVVBcXNSc3ZDeTVtQVJSNU1IcmloaFE9PQ==
"Hello, OP here from a new account. Feel free to message me regarding suggestions/questions!",r/machinelearning,Z0FBQUFBQm0yeGJiWVN3ZUZYdm1pdlZBZnMzWm1qSE9FMDgwMzF2SkxTTG5lLXNwOWR3RHRXUkJnVUM5b2xuMkY5X1pzaUxaUnpvaVZrVVpiUEZPLUNWQ2FPaFp3WVFWV1E9PQ==
"Ah gotcha, thought you were asking about vision models more generally. 

Might be some relevant visuals in this tutorial, but otherwise I'm not aware of anything else. 

[https://all-things-vits.github.io/atv/](https://all-things-vits.github.io/atv/)",r/machinelearning,Z0FBQUFBQm0yeGJiMlM3SWtiVVFFbkRHTlg2a0YzbGhfYm03bTBxRWNrWXlMcTU3UDU1Q1lyNUp0amlkbmp3Wk5Gc0l1R1FndjN5R05TT3ZzVTA0ZHNGSUg0QlVVeGU5djdERmNFZGZldC01cU9uWGxBSXRNMGc9
"If LLMs do not fall into the academic category of ""artificial intelligence"" and deserved to be [researched](https://www.csail.mit.edu/news/natural-language-boosts-llm-performance-coding-planning-and-robotics) at places like CSAIL and [Stanford HAI](https://hai.stanford.edu/news/stanford-debuts-first-ai-benchmark-help-understand-llms), then what WOULD? Can you give some concrete examples and explain your rubric?",r/machinelearning,Z0FBQUFBQm0yeGJiYnV5ckVOcnppX2FvLVloSHN4Ty1HaGRhd1pRZG0taFNRMm1MUXRRZjJKcTdodlZ3akZ5cHNPT2ZUV2xGQkQ3bDFQSFEzbVdtejJCQnFQel9sdndvdFpZcnNDeTkwTzZzWUZsWVo2VmpiTkk9
">They can answer ungoogleable questions like “can a pair of scissors cut through a boeing 747?” But when they fail, they fail in the worst possible way by giving plausibly-wrong answers.

This is exactly my point. Most googleable questions don't benefit from AI summaries and most questions you ask AI can't be solved by Google. That's why it's so stupid to try to combine LLM chatbots and search engines into one product because for the most part they don't have overlapping use cases.

Featured snippets do 90% of what AI summaries do without taking up a third of the screen and having the potential to badly hallucinate",r/machinelearning,Z0FBQUFBQm0yeGJidldFdW8zTmtvNUdPdXJDV3AtS2ktaE91OGdhMk1tT3IydXZZTVZZZmp3VzFRbmxFQ1ZjWEN1OWFWTjFwNVVCMzdLcGpTc0RtdnpwTkw0OGNLdko0akE9PQ==
"This was part of the Beta for a while. It looks like Bing Chat in a small window shoved on top. You used to be able to follow up with it, but its more like perplexity now.",r/machinelearning,Z0FBQUFBQm0yeGJiZXFrakNVdUZUc3lrRmlWbDV5eFRRRW12by11MXUwVEtPQVNwYzNVZTRHMjdaWkRkNjVDRk1zS2NKUm9kRHJpampvMGJ4YWRBeFpCaVFEZHFvS3lYVWVnWWZOQTJNMEI2U3V6QWEwWTZxNGs9
"That doesn’t sound stupid at all, it expands the use case for google by expanding the kind of questions it can answer.

Featured snippets were also pretty trash IMO, they were very often irrelevant.",r/machinelearning,Z0FBQUFBQm0yeGJiSDA2U050bmFQbjlPT09KZnNna3J6dDlxcDZmeWh2UHBpT2dpWjluRm0wR0lWZFpnMzN3TTJjXzl6N1k5aE1sUmFhbFp6QkdOQTJ4dEpOWVR4MlBmLVc0bUVxcGdFdkp2TnVZVnliWEJaNlU9
"Arguing over what is and isn’t “AI” is a waste of time. There is no good definition of intelligence that isn’t either hopelessly vague or uselessly broad.

Just go with the flow, anything neural networks is AI right now.",r/machinelearning,Z0FBQUFBQm0yeGJid3Itakhjc0FVR3RFeGlXSE82Rld0c2J1SWhONG1ta3F0Ym9weDhRZzZYNy1tdzRuVjF6QnphdUVjcHlWeUhZS3dUVjhuWTZZSllUQTFQV2pST1dXRjdMN1FaUExTMVdScHF6dE1VYjdCcTg9
Yeah I've seen this. Thanks anyways!,r/machinelearning,Z0FBQUFBQm0yeGJiWVEzUDVJSmFBTmZ1dmp5WmpIb3NjSllCMGVqeFppSlllLVJTQ1E5NUhMTXJsMHFsUVFFbmhkalBDLTM5cjgwbWhteDJYcmpDYXlZMGVTYUZ3ZVFvNWJlUkJ6anptN0JoWExaMFBZdVRUSTA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiYl9lcDlwVm5LenJnY3UxTzE1bjJsbHVkZVFMbFdYV1BMQ2dDWjdabmw0QnlkSW9vZVB6S2d5RzFqbWtjanFYXzBiV0l5VWxMaXByREU3RWFXOHZCdFE9PQ==
"1. The transformers, based on neutral networks - both considered AI 
2. Call it whatever you want 
3. Rlhf is considered AI, yes


My question: do you think machine learning is AI?",r/machinelearning,Z0FBQUFBQm0yeGJiaTF2cXgtVjhNdzJzVmxEMlg4d2lnbHBSSGowLVo1ak93Z0FMNy1DQ0N2QWtXRG5ybUNpcHU1SXNDZ215cmxsNmNIMXB3MjJyQnhnTkNVUFRNYW1RM2c9PQ==
"Hypothetically, it could work okay if they configured the AI to only pop up in situations where ungoogleable questions are being asked. But it pops up a large percentage of the time you google any factual information, which is what makes it so worthless",r/machinelearning,Z0FBQUFBQm0yeGJibDNVRzJqUkxFSEZnZVNvclJVMDA0RU5rUGFQampCTW5TbkJBRVVTdWN1UTRuM284NU1mekt3czBLWW53N2dSQ2lqbnk0RGxfRVhzWVlSWlRPUHdKSlE9PQ==
"I use it all the time for informational queries like how to do X. I’ve never had any issues, I don’t use it to debug code but that isn’t what it’s for or anything too complex.",r/machinelearning,Z0FBQUFBQm0yeGJiLURwazV6MFJILU0ydjBKU1g0ZW9fVGVIdEIzUEplRXQ0TGpJYXhZaTBoRHBwOTJMU1dZQzVrckwyN1VNSkdTOWpQZWhTOXZybXl5X1cyYmxLVFd6SFE9PQ==
But so far neither you.com nor perplexity are significant competitors. so what will it take to change the default search in most browsers?,r/machinelearning,Z0FBQUFBQm0yeGJiUF9OR1BQbThSVWt4RXQwS3FRU2hSX0JGNml0Sks3SW1Na0s2M3ZnMnRvWTE0aXI1Qm5nbU9hN3c0aGdrbEMtdnVxME1PSWllTVppV1VUQnZQUlZfdGc9PQ==
"The ability to use reasoning to correctly perform tasks it has never seen before during its training phase is called 0 shot generalisation. Current 0 shot generalisation performance from even the most cutting edge models is extremely poor, and recent research has shown that even by infinitely increasing model size, this cannot increase 0 shot generalisation performance. Realistically, the only way to solve for this core feature of any ‘AGIentic’ system is to produce a transformer architecture that so radically new it has nothing in common with any current approach.

For OpenAI to have reached AGI, they would have to have created this architecture, which, has 0 known or theoretical approaches across scientific literature to achieve. This is highly unlikely to have happened as this area of study is so new. The ‘true’ solving of this problem (ie a pseudo solution not powered by agentic workflows) is likely decades away, and I think will coincide with research on how we understand the human brain.",r/machinelearning,Z0FBQUFBQm0yeGJid2E1dGlxQWJGX0VZOUszdmhieDk0eEdvZnExeHVHWUI2UmJReDhKU2kxZHA3bDhPcDVqWnhmbW9VSDVjUnVlMEpKcXQwRTlSVDlXbUlKdkhBRExNcWc9PQ==
"Microsoft will build AI into Windows (as they've announced) and Apple into Mac. If they give better answers than Google and you don't even need to go to a web search, then the default in most browsers will become irrelevant.",r/machinelearning,Z0FBQUFBQm0yeGJiNk9xbWREU2dBVHBBMHNFWm5JaEc2dmRGV21iODZPM294bXAwbGpfWm9hc0gtdWpPSmhxWmZZbzNUWlJJV2tWOURQb3UzNVlEdEIwLXI0QmZJOW9jUVg1Sy1DQjEtaGdlTkRjSWItZTZmVk09
"And the ""money in clicks"" is likely provided by Google!",r/machinelearning,Z0FBQUFBQm0yeGJiRW5LQ1pCZjJZY21KX0UxV3pIakt4NFZkTnQwZkZkeGpfbDJoQzFuM1RzQk81Ulp6ZlJpdE5FMDVIRE9qQmZNRHpwOURFamtBV2Z0VEQyMjdpcUx1TkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiaXZPdHNlXzU2QmhfQlNJMGhRWHlNa3U0T0p4aDhaX29kbmF5SUVDcy1ldDh3ZGFBR0RXd1pIaUp1Q0lnelRPbnhvQms2bmRONVh1czdQV0R4a2F4Y3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiekFaT0dBb2hsbmRqNG1iSVZ2RjZ4SUVsUkhXRjVTT1BjRVRpZU54dElnaTMtNklDYXFQQlVYdFhVazMwYXZvazZCUW5KSF9WS1VwMFg1MzFKamt3bHc9PQ==
For getting summaries for files on my computer. but pure GenAI without search connection to the internet/RAG will be just too error prone to replace general search,r/machinelearning,Z0FBQUFBQm0yeGJiTEdyLWc1bG5QNjdwby1iYVhEcHpyZ1BvT3QwYlQwMEVSdFVPMndtNmJWSHlrRjZrRks1ajJJS1hmOUdocktzSXhrX0RyRFIxQXN1d2hqRFNLMmdnS2c9PQ==
Microsoft has a search engine and Apple can partner for one.,r/machinelearning,Z0FBQUFBQm0yeGJieVNDV1h6eWNkbXdOb0w3N2hxY2twaVllNzNRd3dhZ2xzUEZ0dHpleHI1c3lFRlpmM0FEaFdSallmS2hYbmU0dVQzSlVXUHlXd2E5c3VqeWNxME53N1RHaGcxSll5WjNsQk5tZUl2bmhscDA9
"I'm inclined to disagree on part of this - the nonsense that sometimes comes out of the AI search would be very unlikely to appear from something like Gemini 1.5, which indicates they are using a very small/quantised/pruned model purely for a mediocre search summarisation..and therefore having a minimal carbon footprint.


On the other hand, if they used their most powerful models then while the energy consumed would be huge, the answers would actually be of much better quality.


I use the ChatGPTBox extension (there are others, this is just OS), which can connect to various frontier models and display the answers alongside search results on main page - have been very happy with it so far.",r/machinelearning,Z0FBQUFBQm0yeGJiQ2pXOTJaOHlGcmYzWGpaT04wOXQ5M3hmaS1DbWlMRURLYlFhX3ctOEp2X2labTZsblYxNEZpdFVDR291V1dNaHBhd0dVSUhqcHN6S095azBBZE9DcEE9PQ==
"I've had enough of this ""this is not AI, it's just a computer"" statements.",r/machinelearning,Z0FBQUFBQm0yeGJiZzdXdmNhdEJUUXZnMlVRMFNOY3BsZTNxeEViMjRTQW91VEhBelBFXzB2RFA2eWg1cFhTSlJxclZBaTZwWUdaT0VwQ0NnR3hLM3lBcU9WenFsMUtYTmc9PQ==
"data leakage in kNN is not really a concern I think, there is no training set and there is no training at all! the model IS the training set and the algorithm is nonparametric. 

The only think I can imagine going wrong is OP using the example to label itself as one of the k Neighbours, but for k=1 it would return 100% accuracy since there's no distance between a point and itself. There can be duplicate rows and OP forgot to merge them, maybe.

OP: let us know how many examples you have in your dataset, the class balance, if you normalized data, if you intervened to fill missing values, if you converted categorical features to numeric, what distance metric you used, handled noise etc etc. 

My opinion is: k=1 might return the best result, but the point is ML is to generalize in order to get a sense out of data not only in the past but in the future, and k=1 might be a too narrow value to make a decision: what happens if an elderly patience comes in? does he get diagnosed with Alzheimer's even though he doesn't have it just because he is as old as the closest diseased patient? or does he not get diagnosed just because he is in the early stages and the closest true negative had similar values?",r/machinelearning,Z0FBQUFBQm0yeGJiRlJLRnFWcWZQQ0dHVjQxQ0pLZ3IyT1FXOFpiWURmQnFBMDNGZVVsdUZPZURabjlEMXdiRGhtNE5pa3czWmZnVmJERVRqTDhHdTM0MXpET2htNjNRZjBfa3NObS1IUlZBZDRFaUYzV2piZTQ9
"sorry, i completely forgot bing 😂",r/machinelearning,Z0FBQUFBQm0yeGJieWZ4VGZsNndNMnhVRUZMYzZMYVVZcldLS0QtbVlBVEw1QUd3UFVQYUt5WTA5UEN6M3ZjeHhseERncjM1YXR2RUNMQm5tN0dmMmprM1gyOV9RellueGc9PQ==
Minimal in this case would be 0 and they are unlikely to have 0 carbon footprint.,r/machinelearning,Z0FBQUFBQm0yeGJiRmtfWlBsZ3B2TU1GZUJEazNZQ1R4ZlJLdm9TNnFoLWwyUS1IZjhLSWFXT0llUWlJZ2w0Mnk0alV0b3pOVXFYQ2xfVGpnVm9FYmFhZkp5eFJyVm1peEVpOFVBRDM2QjJETkxlRU9kME9yclE9
"There's several orders of magnitude in inference cost/energy from the small to the large models, some of the ones I run at home are close enough to zero that it can be pretty much disregarded as a rounding error on my energy bill",r/machinelearning,Z0FBQUFBQm0yeGJiTG1Td3pfZllOVjhuTlAwdjJsWEhjMXNRNGxZSk01a1ZyM2o0ZUVlcXJCaXRjd1lWTVdkZ1R0cGhNWGZsQjJXVldlMmNtaDZSbzVRUU82bTRHWEVSYnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJicXNFWEVzN2pJRGljU0NveERlUGJPNjNDaTVnTEhTLWdMZHhiRVd4ZWFlM1BCSUhEUGRHaFhGR01icXBzZjlERk9wUlFJNHM4OHM1Q0J3a2M3V0NYb3c9PQ==
"My experience with knn data leakage is messing up the scaling. Fitting the whole data before the crossvalidation, instead of just fitting the actual training data at the given fold. OP should check this also.",r/machinelearning,Z0FBQUFBQm0yeGJiVUZCdTM5NTJoSmpjNHdGNU1kWlZZblY2Y3F1dnJQbEY4NEJnR09LVlp1ZUppb2RBc3F6WkRSbWZnR3pnZE5oZmt3V0RQTlc5VFd4VTJCSS1rMEd6TkE9PQ==
"For you, maybe, but not when there are millions of people in the loop.

This is a good practical illustration, that has also a nerdy twist :
https://realpython.com/python-rounding/",r/machinelearning,Z0FBQUFBQm0yeGJiOHpsMVJxdTg0bFBHTjJRRWtMcGI1Y1FrcldKLWFoQWZIMnlfeUs2bXQ4b0FmU1hGVU1OdGVVNXhPdl9GNkswX1ZPMGNWTVl3LUd4SWVWTFlzZHhUR0poZThHdTB0cENOd29XcERGbWtCbTA9
I use PyG for EdgeConv and DynamicEdgeConv (non-heterogeneous graphs). If you are interested in specific GNN layers from some paper and can find them in the [CheatSheet](https://pytorch-geometric.readthedocs.io/en/latest/cheatsheet/gnn_cheatsheet.html?highlight=Heterogeneous#heterogeneous-graph-neural-network-operators) it might be worth a shot,r/machinelearning,Z0FBQUFBQm0yeGJiZFF0bzAtX0FhV3VBMWRsZDg0cDdDMVRreDUtM3V0eExURDhYaDl3ZVRyUGV6ekYyNkx0VVUyS1FrdHNKaFplS21PN3Roa21mdWpWaGlXSElvel9MbGc9PQ==
rubbish paper,r/machinelearning,Z0FBQUFBQm0yeGJiYjBxU2VHcG45M05MQTB6U1V0b0VteVk4dTRFV1Rzc1FRNm1IdHFlUEM4MFpVZWNqN0dQQ3BUWE1sTlZ2Sk9TdDg3UUFqVFByU25uWjVHamtvcGFtX2c9PQ==
"I would recommend AI SUMMIT organised by IMDA, the govt agency in SG. I'm actually one of the speakers next week. It is from Wed to Fri the coming week. The basic admission is free.",r/machinelearning,Z0FBQUFBQm0yeGJid1praHlrSFNNTDdZVzVGRHdtbDZRRlVMbWMxMkswb09ORDYyQU1yTkdZWjdsZE9nSFlLVXNJQ2VfSlZBUkRfM1NDTE9BRHBJYlZZY1QyMzdxYnNDR3c9PQ==
"They'll be great for video description for the blind. Also, cheap data annotation.",r/machinelearning,Z0FBQUFBQm0yeGJiNWdLR0lTakI2REp3TWZhQ0JMcUpxYWJmWkxqSHhwcEs1Q0Q4UlVMVDlwRF8zRTczbVZCUDBZMnNxeGF3UG5RWmhhYTNncTVaejdNenNMeVdMYWlQckE9PQ==
I most often use DGL because I find it has the cleaner API but PyG is very similar and I have been able to switch from one to the other without much effort.,r/machinelearning,Z0FBQUFBQm0yeGJiWmFpM29WdTRSc0tjcHFSb2ZtMUtqNnllaHJCZDNsME1iSEZfMFdmT0pHcWdXNVRUUzhRSFE4OENDT1p0b19pVVRTYVp5M0o3NmJPQldIM2VwVlJyb0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiRkFqUlJJWHdXanBVc3lJb2hoZHBpWmdoRFg0U3Iwc3VkQmZBTWhXN3dGMUNQZU44VEVpYUxfU0RUMWlWY3JzLXBfc2hINi1KNmRPOUdiZWJ2emVHeWc9PQ==
"there is no fit in kNN, you need the query point in order to get the neighbours, and those points are in the test set. 

For the scaling part: that's not really data leakage, is it? You can think about data leakage as a non-empty intersection between any pair of the three sets (Train, Test, Validation). But you're right, scaling is a major issue for metrics where p >=2 due to the fact that bigger features will contribute more and more to the distance (think about infinity norm), with consequences on both accuracy and penalties and error propagation etc etc.",r/machinelearning,Z0FBQUFBQm0yeGJielR6bmhFRkxrMWY0UmpVYjNaamxRN0piYjlCOW5GMGdEWi1qRzl0b2M0Q3lmMkxacVRUc0VIMUNILWdQdVN3dVZ1MXgyLXZTbkhXVTIyODlISjJhY1BVNEJSQVloRDI0U2staV9UazhZblE9
"I am not from Singapore and I booked for SuperAI after seeing Emad Mostaque post on twitter and now I kinda feel robbed after seeing AI Summit conferences lineup AND IT'S FREE? I wish I knew it earlier before booking the flights. Can you say if SuperAI is worth 400$? 
All the best for your talk Rockstar :)",r/machinelearning,Z0FBQUFBQm0yeGJic0tnSFYzekQtV251Y0oyMVpXM2dyYXNaM3hNSy1NTmdsQUYtTDNOMzZzQUNoZW10eGs0VFBMUFJLRTVmWF8xNk9HcEpNeHBkWlBwOGM1Y0lCRUVua28yUTJmclQ0M1lrbjg2dVlzZVhINzg9
"At one point it was, the it moved to deep learning - where it still is today. ",r/machinelearning,Z0FBQUFBQm0yeGJiaUlzQ29xWkllODNobi1Mc3hmWkFqbVU2aEN3U2c5eElxeWIzRkduaThWUTMwbWVuTG1kNExuajBlY3RTQS0yZnJmT2Z0bDUxTW5GdkhtUGpRTDNsTGJNR2VWUTdmOGtWdmU5ckU2VDBfQVU9
"I didn't mean fitting the knn, I meant fitting the scaler. When you scaler.fit\\_transform the whole data before the cross validation, instead of scaler.fit\\_transform the train and scaler.transform the test/validation at every fold, that is data leakage as you leak test/validation distribution into the scaling equation (That is you are scaling the train data also using the test/validation values). 

Different min-max values in the test/validation will change the scaling of the values, changing how much that feature contributes to the distance.",r/machinelearning,Z0FBQUFBQm0yeGJiWFIyM2FxSEJGWmJYdDQ0U0V5Z2M4ZWF4bGpiNnM5UnVHQjgxNlF2WWwzeHl6a0FmNHd4c1pib2lDVGNURG4tZkJxS2U1ckVzaDVmdVdBYVFCMjg3cVE9PQ==
"Other way around: deep learning is a subset of machine learning, which is a field in AI.",r/machinelearning,Z0FBQUFBQm0yeGJiODNMYkZ2TGJsZjBLaDYwR0FYY0VKV24xcFg3cU1oVndIOEVQUkJBajFjMkNxNDBkN19raE82SndNRW9kaktTTDlpZDVhdmtOb2FOd3NIS3BwVXdNdUE9PQ==
What's the deal with the conference? What can you do that you can't do streaming it,r/machinelearning,Z0FBQUFBQm0yeGJieGJjbXJnTHNIVWEyOXk5Q2l6T20teEpkd1lzbkF4ckRzNUNDdS1lQkFVRHdWTHhfNFBFb3pzMDV0b1RFMGhncERhb3BBQUg1OUFKZXZEZU9WMVR3Q2U5V2dyUVFjcFRwM3V6UTBxdzIwQ1U9
"I don't think they stream because I don't see any of their previous conference videos. I really wanted to visit Singapore too and this just felt like a nice time, cause two birds with one stone haha.",r/machinelearning,Z0FBQUFBQm0yeGJiZno0enNuTFNUdzZmNkxveDR6V0J4azJ6MGVPczZZT01PQWw4eVZFa1RhSGp0TXI0SFJibXFmMFZIMnpGa0xVWTYzbko1Z1ZHeWZZLS1XTzFLdHNSbU83S2pJMnowZW10QVJqblE4Ty1ERm89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiQVRnTkh3RjRJMEVidkY4SElPckhsdVZsS0JkOENOZkJDc3VNSXY0VlN6TE9QUzROdVpiV2NaQUJWWm5VVDZxcXpIWndyOTEwSWpKeEVnSHdrVGIxbnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiRlZEZkVLTFEzUFRkclRIQi1UWjhLU19WeGk3Wnk2UUh4aGhMS1kzRHJ2X0YzeG5feTh5VTNUaGRwbEZGd0FOVS1Jai1xUDd1bFJ0dzR1aGxaQS1BQ3c9PQ==
Sorry I have no idea about superAI. Thank you,r/machinelearning,Z0FBQUFBQm0yeGJicEdLdEtKVF9BYzhWOWJIbGdZcDExRDh3N1ZwTWsydVM0VUVIY2RpemJZbk9rSHdicjYtVWNqR3hmNmQ5T2JSQmEzanFjMElLXzhtV2hobXNWaUVTX1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiREJJOEZycFZGZ19nU2VuSmxnRGJnUk5Ta1lWeG51OHJwLVc3VDZ4S0Z1Tm45WkRibVFXY212R01la25wWnRCNWtaaklMMk5zOV9NNkxJcFZyX0t6T2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiVjZENDI2VWtRRFk4eXRXbEFtTjRSaFV6RDFhZHJjcFNteWF6LXJSdTNTZThyeUM1bVVmcEt2RjFnajFGbkx2RDdsMWM3Vy1KUEVQY29ISXZweVc5bkE9PQ==
"I looked through the AI Summit agenda, it seems more like a government and corporate innovation department conference? Don’t really see many AI companies there",r/machinelearning,Z0FBQUFBQm0yeGJiNjRxT0VyNkkzczJ0eTF0am1BNngyMklFSUZGUTN0U0VhRk9JbmI0RW4xdmlRUTByUmZ2U3M3Z2tSSG04ZXZTUzBVZ0xKS1hEbGM1Z0VKcE5xa0g3VlE9PQ==
what does it talk about?,r/machinelearning,Z0FBQUFBQm0yeGJiT1hlbGRERW1oNU4zSmFUamFFYUVhdlV3TjRELXM0NHFNeDhyMTFYc29DdmdWN3FqTExkUjFGODVLa256OU5lZGlCRHhKbVVyS25FNWNhTkFhcERxbXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiaWR6aGtuZWRmaDZhQXFpU0VabWdkWnVhT0FUSmhzU1ctQXE2NXRuc2MxUS1jWGZ0bGZ1OXJ4R0FjZWVOemVLOGFWNTJQYkQwSTBaVEZTb2dhblBFM1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiLXdjY1I2M2ZMU0Fwa055V1EzbnZoakUzSEk3bC1HT1AtbVJoM3hmTGRoeHg0ZFpXMFNRZlVKcVBZN1BSU2RxMlQ0eWVNQndSQ1NzZHo5amlyNlkyV2c9PQ==
"> As an AI startup, we ended up focusing on having high-quality eval data and an architecture that makes switching to new models easy.

Evaluation is more important, but if you’ve plenty of eval data, you might as well finetune on half",r/machinelearning,Z0FBQUFBQm0yeGJiaDNWeGYycTBqSTBBZTRibzdDck9XRVdvVUltazlldnhEMk5nS3ZnQ0VlcVBTM1FjSm5jVXZZSV9Ob1NXOXFUbUNPaEk0cnB6NDdjRElhNWc2TE9zVmVOT3F5eEpId1JtMWx4TnZ1VDdOdUk9
"Depends on the use case, what tools you have available and what your goals are.

A much bigger model certainly can outperform a finetuned smaller model. Even better is a finetuned big model, but that might not be available to you.

If performance is the only thing that matters to you, then it's best to go as big as possible, and finetune that if possible. However, big models require a lot of costs in GPU usage, so if resources are limited a smaller finetuned model might be the better option.",r/machinelearning,Z0FBQUFBQm0yeGJiSThuYXJmVUp5bkZDNVV3TWswNlFrelVWbktrRVd3R3VQMkdibzBDbVFwUUxVN1MxckxUZGc3ZXdGdVNXX1ZMbFJSQlBId09XNGc1WXZCRnJSa1pfcVE9PQ==
"AI is just a fancy name for ""statistical models"", and more specifically deep learning architectures (even if the AI field is much much larger than that, but its obviously not often used for traditional AI anymore).",r/machinelearning,Z0FBQUFBQm0yeGJiMUFRU1Uza1lXQzRuZHBaU2JyQnhLX01jZ1ZZTXJZTGtmbGtkajlPelcyMWpCZzdTRFh5Z1hEclVlVUMxLXdzMzlkS0JEcV80bURYVGE2ZkdBZ2c4SWc9PQ==
"
Def main():
Input(‘Hi, ask me anything!’)
Print(‘Saturday’)

Ask this program what day it is. There, passed the Turing test.",r/machinelearning,Z0FBQUFBQm0yeGJiUG9DclpLR053VmlCODdvT1Fndk1QRlc1NzF5RkYzeXJwTnNkT29lS2wybGhFejROWWlsTjgtRnIxblJYdzVydE80czFLUjNGNjhIQkRuY1RISUQycEE9PQ==
"Normally, it does not matter which YOLO version you use. The performance is almost the same for all versions. I don't see any major differences in this paper either. One notable innovation, however, is that the object detection is not using NMS. All other versions have always used NMS. Architectural changes/loss function make no difference. But the omission of NMS is interesting. That could really make a difference.",r/machinelearning,Z0FBQUFBQm0yeGJiOFkzYk1BdkJUd053dllhUllrOGJhMlF3X1g3VGdycFNnOUZjZ3lKSXRWbkY5bzRLOXRra3ZBUFNZREtFenc2N0VZMThSeU5pSWJZbS1ELWJreHdrNXFZWFF3WEZfSFhJdXFwT2c1RUdsLU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJibHN5eTJDM1JkYzhxLWUxN3U2MnpzbzdEaEtQb3pBYXhyRkZZVzQ5U3pPQW5PZUxlenc5dGgwX214OEVfb1RxSjQwVHlDbFVfVDJtWGE2VUlCcUhSYVE9PQ==
"After YOLO v4 there qas quite an inflation of YOLO versions. But I agree, no NMS could be interesting for certain scenarios.",r/machinelearning,Z0FBQUFBQm0yeGJic19aQkZOZ2M3N05mdG9wUVh0RmZJR0haRkdzVTZSR2NuZHdJNWZrbS10eG4zUzVQdDI3SEtPQzJBV3NkdGZlOWxsOE56S3ZFZzl5cnBMTHJtcXNrc1E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJiRndfMWxQTTZ4dktwVDJSMU1hVTNWd3RWN19ZR0JWN09OZ2xpQlUzRGxJZEQ2ZVR1ekh3SmN2M3pPcTBqZjRva0pKdExXa0daZDZBeVkzMVE3b20zWW0yZ21vSk8taFF2dW5tdkpHSTAtbVE9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJiYm9PcTh6VFB3WlVhdElLY2JrZGxQLVpjM3Bqa3FlTVJKb0tmazdSLTFEU2tWNmRxSGdWODhrai1Nb1hydUFvT3habzlSR0FYNW8ySmRhT3Zmbi00NGJoY0U2NXNVNWlXaFNnQzlrWHRkWFE9
"Basically, they optimise the autoencoder by using a 2D discrete wavelet transform, obtain same performance for 6x less parameters. 

Promising approach… or no? 

https://www.aimodels.fyi/papers/arxiv/litevae-lightweight-efficient-variational-autoencoders-latent-diffusion",r/machinelearning,Z0FBQUFBQm0yeGJiSnpWQV9zQXFxTUw4R01XUDVoMU51S2x0X0ZvUlF6MmF5SmpwTVZCRmZ3Z0JSTHZ0S2pQM2FmbHpTbGgwX01QRmFtZUE1dXZJVDc5UkJRejZMaGZNLXc9PQ==
"I can hear the laughter of a child..
He’s reading “AI History & Tales”, a book printed in 2104, detailing the journey from the perceptron to current AI biomachines.

The child looks to his father and says “dad, why did they call the token classifier AI? Were they STUPID?!”",r/machinelearning,Z0FBQUFBQm0yeGJiSEg3RnNXWUVaWDloTmlRZ3lmdFRTY3Z2RVFoR3hnUWtxN0UtRUNMU1hqTWRWWTNjTGdMQ281MV9pcnNSSUs4MTZsLVdJYl9XbGdQMDk1QUs1eExjdllpZnp0MWk3MjdUYi11a3FhZV9YVGM9
Also would like to know,r/machinelearning,Z0FBQUFBQm0yeGJiQUx2ZWFLLWpVcEgtNEo5V01oT2pSYXJNaDZpOGlySlcydUV6TVR2Z2VxcmcxYW9CanI2cTV2WHpqbnlwQnk3dEZ1WGhMR0RMYkttaHF6VFVWRFd5Unc9PQ==
Would it be possible to add funcionality for polish lang?,r/machinelearning,Z0FBQUFBQm0yeGJiTEZuU3NtdlZMNlBUcWhrbWhrSVp2TGl1eEdYSHl3TzlnbUNzMXRveWlqU0VXdG8yU3MxendvNTRicGNFZUpWU1ZoT3FRRnNFMHpfNzNYTFdiOGlkdWc9PQ==
"Interesting results! While k=1 might not be a common choice for KNN, if it's been used in a peer-reviewed paper, it's definitely worth exploring further. Can you discuss the potential limitations of using k=1 in your paper?",r/machinelearning,Z0FBQUFBQm0yeGJiSGlsLTdWVFhYcmNveEVXMTFVbWlsYWFJM3FVVlBFRnJkMjg1QWQ3TV9EZW9nOEhXblVHRF96TnpEMGRrWmttUUs3SE5Hcl93UmR1NEtaZDI1R0VzeU4yM0VtR2ZUbmxQWXFWR0pfNm9KbGM9
"> HuggingFace, FastAI and similar frameworks are designed to lower the barrier to ML, such that any person with programming skills can harness the power of SoTA ML progress.

I strongly disagree. As someone that worked in ML for the past 10 years it feels to me that a lot of the tooling developed recently is adding more fragmentation and overhead than anything else.

- HF: why not just store models in s3/datasets and use the canonical torch/tf way of loading models/datasets? we could have invested the energy that went into HF to make those ""canonical ways"" that already existed 10 years ago better documented and avoid adding yet another layer.

  
- W&B: don't even get me started. 99% of what people use it is again, s3 and Tensorboard

- FastAI: so much great stuff in there but the reason why everyone uses Python now is because it was a nicer developer experience than other frameworks. When DS people arrived from Fortran/C (me included) Python was like whoa, I can actually understand other people's code and I am not going to spend a week figuring out what is going on

and the list goes on. To get going now you need to login into 3 different services. and understand 3 different opinionated ways of doing things. It wasn't this way, and in my experience it it harder now than it was in early Keras days to actually re-use a trained model. 

  
bonus: if you work on niche stuff where the models, loaders etc you use always need some internal tweaking (and where business happens, not another blog post on RAG), these abstractions make life hell.",r/machinelearning,Z0FBQUFBQm0yeGJidGJTMWgwQmVEMnlWcTA3NjYwSjZtZ04ydHZYYnRGTThDV1FOVjlVS0QxM0pLdTV0T0N4Z2dOQUxJcmFycFEwN0VEcFF1OUQzNGhyOG4ydWxmaXY5MHc9PQ==
"I completely agree, it's surprising how Google AI Overview didn't consider the noisy web and unreliable sources. The lack of adversarial testing is disturbing, especially with the potential impact on public opinion. This 'move fast and break things' approach is not suitable for AI products.",r/machinelearning,Z0FBQUFBQm0yeGJiYWt0RldDdmhrUklGLTh6bGZ3dXl6N1NSakJTdk9mWEpfcS1kNTc1cVRZcTJoLU5tUVdTcWlQcTUxRnp5Um9RZFFLSzR5ak9jelVyd3BBT0RvbWZNWDdpMW9DX0p3Y0lqZVVIQjhaNkdaWFU9
you can host multiple llm in ollama?,r/machinelearning,Z0FBQUFBQm0yeGJiMC1CS2Y2YnEtRjQta3IzNGg3Y0ZaRFRQQUdBRUlrUzhQTlYtUGRnZ0s4YkNhX2NkT0RnQjJHdWExbUpiMXpvWTM2RHBnd0ZOVWVBNlg0dkg4U3hLOVE9PQ==
ollama can do it,r/machinelearning,Z0FBQUFBQm0yeGJiU2FkeGVESEVLRndVRHpqTUtEMWozU0xVZGY5ck9xbENyWFJ2TG5BSXlkaThnSW1jVjB5c0I1Z3RidlVuckxuZWtkckpreXF1MklCZWtHblZ4OEpiUGc9PQ==
"No, I don't use it to debug code either, but very frequently it outputs an answer and a) it was not using a source you would rely on/use yourself b) when you actually look at the source there can even be nothing of the sort in the article",r/machinelearning,Z0FBQUFBQm0yeGJiYnR5VHBKR3FxZjhoX0Z2eVhPeTFIUFk2Z3JvN3d1cklGWlhwMHFRYjlDQnJ4dzdfYlVpSnNvRmRmakotZ0RtUnN3dmpZcnRWc3Y1SndQV2lWSzI4b3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJidUlKejlqelU1cmZMVXVkUTlqNGgtdGV5N1VjM3hZUG9XMkhyMlRDb2ZrZWJqTE02OXFzVjBmc3BBSWFha0RnQ3pFbk1fb1dNdWo5M2FJenBjT2JSR2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiN0RmZGRkMWpvcVJXdXBlbElwbjY2MjZnYzIxQVRyWnBrdExmMUo5U19ENmlwX21CY2t4MVFWOTNMckhCOXpjd0JnRHFfWnA4eUhYVU1KUUY5X1pDYUE9PQ==
It’s the same conclusion as here https://arxiv.org/abs/2402.13991v1,r/machinelearning,Z0FBQUFBQm0yeGJiTXI2V1Fia0pzNW5vTWF3UWpPZ2poLW83R1BIT2hReWUzMkRYb0k3QUdjMmVkWkF1STlLZWRXNkdIYnJHZ1ZLaUdacVkwRjJxT21nSlJPRXQxUDZCUGc9PQ==
"These AI products feel so tone deaf; there is so much hype and so far the public really just doesn't want these products. I'm a big fan of ChatGPT, but that doesn't translate into me wanting a chatbot that has less than 10% of its capabilities in every single digital product I use.",r/machinelearning,Z0FBQUFBQm0yeGJiOUp1eHdDenR4NlNOWHkzV3dWOXdsQk1kcWRacmMyRFUybjM2Sk90MUktVzBKVS1oX1V3b2gzTjIwQTdTWDlzcl9ydG1LSG1rNnBBdVdDS2t0NWo2RGdWSzhqd3pVR1dfdkh0ZUZwRjJDUEE9
"Here are a few cities that could be good locations for analyzing Google search trends to try to predict stock prices:

1. San Francisco Bay Area - This is where Google and many other major tech companies are headquartered. Being close to the source of the search data could provide valuable insights.

2. New York City - As the financial capital of the US, NYC would give you proximity to Wall Street and the stock market. You could potentially cross-reference search trends with real-time market data.

3. Seattle - Microsoft and Amazon are both based in the Seattle area, so you could examine search patterns related to those tech giants and how they correlate with stock performance.

4. Chicago - The Chicago Mercantile Exchange is a major global derivatives marketplace, so analyzing search trends alongside futures and options trading data could yield interesting predictions.

5. Boston - With a high concentration of finance and technology firms in the Boston metro area, you may be able to uncover search-based investment strategies.",r/machinelearning,Z0FBQUFBQm0yeGJiMXBfN0NwWlhTcDdyTzRYMXZycUdHSklzbEt3TVRDeDN5bkNDZlFWSC1WMEN2U2dpc0d3YXMxRVd0bmNzXzBnc3BPa1ltOHY4TnY3cmlKR1VmbzZqOGc9PQ==
"yes, i suppose I can",r/machinelearning,Z0FBQUFBQm0yeGJiSmtkcFlsSS1EaTliVUVtbHN2TjdGUUp0UnUtOEdGMTBmVjBwOGkybEV4ODlrbVI0d0Q0UFF2NEJETnBDQ21rR2lxbTMyNlBpNkhkbHdYM3NJZ19LUW52c1JvY3pRUW5NMkJCajZMRE5EYTQ9
"An interesting part of the paper is an independent replication attempt of another sampling method, [In-Context Pretraining](https://arxiv.org/abs/2310.10638), which relies on semantic similarity of the documents. Back when it was released, it advertised  handy gains over random sampling baseline. But the results from the replication are nowhere near that impressive: marginal boost for common NL tasks and somewhat larger gain in long-context-oriented tasks (but the boost still isn't consistent across benchmarks).

Possible explanations, in my view, may boil down to insufficient scale of the replication. The original work trained models up to 7B parameters on 300B tokens while the replication was, if I understood correctly, at 1B-parameters, 100B tokens scale.

A chart in the original work with some downstream performance vs. token count shows that consistent gain over random sampling emerges only after 150B tokens. And in NQ benchmark, In-Context Pretraining even underperforms random baseline up to 100B tokens. Which suggests that models of smaller scale won't benefit from this method (albeit a single benchmark doesn't make this hypothesis super robust).

On the other hand, pplx metric in the original work is consistently better that random baseline regardless of model's scale and dataset size.

Which brings another point: the authors of the Dataset Decomposition paper do not report loss/pplx comparison at all! With the sole exception of training stability experiment where the hyperparameters were artificially tuned to induce instability.

This is isn't the only recently published paper in language modelling that ditches loss-based metrics altogether. In fact, it's become a worrying trend. So a few points to consider.

1. If your method aims at broad enough application, perhaps even universal use, downstream NL benchmarks still do not capture the full spectrum of potential NL tasks and use cases. No one says that loss is an ideal metric from this point of view. But it's still the broadest possible evaluation of model's capacity.

If you aim at specialist models, like code- or math-specialized, then it's totally fine to use only downstream benchmarks. Even then, in code case, I personally would find eval pplx on The Stack more illustrative than some borderline ridiculous pass@1024+maj vote.

2. If you research a novel sampling method, it becomes \\_very\\_ easy to optimize for downstream benchmarks. The same, to a lesser extent, can be said about novel loss objectives.

3. In most cases the difference in benchmark results vs. baselines/ablation choices is miniscule. In the paper presented, it sometimes drops below half a percent. Throw in the fact that benchmarking is \\_extremely\\_ sensitive to the choice of examples in few-shot settings (esp. with smaller models), and you are very quickly starting playing games with random noise. Charted pplx over training course is way more honest in this aspect.",r/machinelearning,Z0FBQUFBQm0yeGJiQkhMN2cxQmdmdndmOUNRdUVIWVRBWHFWZTk3RjdQSm1meTZSVUg3R2lOenpCNWVoSHlpUk9Tc01Kb2Y1clZfZFlITDlsVWEya3VMNUZQeE9EMVo3TDVKLUZ6U25IU0hpNUhuTVFyYnhXMjQ9
"I had a similar thought and included all of those cities. Originally, I was only looking in the US because I figured that those cities would have more sophisticated investors. As I am now looking more international, it is harder to know which cities are very important versus just large. Granted, I am using the predictions in a wisdom of the crowds esc way to look at the relative skew of all models, so I see a case for using higher diversity rather than focusing on ‘high-impact cities.’",r/machinelearning,Z0FBQUFBQm0yeGJiMzhUUXJpM3lVSk95R2cwb1RaWXhSS01EaVhhcEdlLVV3d2Nwdm9OM0ZGTjBnWFBDTFdZaWw4Q0NTOWNnQmQxcnQ5SDRUSk1PRHpZX3d0eW53WW1vSnc9PQ==
"NMS adds major computational overhead for mobile devices, this is a gamechanger",r/machinelearning,Z0FBQUFBQm0yeGJiQTJoSTNXOTdkdlBybXk5TEVKZ0gwb0ktbnJVSTBFTFYwUnc2dXlwUHBDUVJfWFpkQzhva1pXQTdmRXZBamFial9LMUhzdHlYb1NWSl96ZFFjcGliV0E9PQ==
"Look at this article to get some ideas (it will download in the background on your browser)
https://thomashasenzagl.com/research/papers/germany_1221.pdf",r/machinelearning,Z0FBQUFBQm0yeGJidlhCVDdycFhBUE9XWTQzbUVVSmxQY2ttZ1gxY0dwUFgzaDM2bU1PWUVnNjI3TkdDVXZZX2d4V2NUZ2lZMGI5Z2RVZEhOYWJVbGF4Wnl6bWpQQ1lLRlE9PQ==
">b) when you actually look at the source there can even be nothing of the sort in the article

Could you share some example queries where this happened? I'm hearing people make these claims, but if it's happening 90% of the time for you then it should be easy to share a bunch of queries where this happens.",r/machinelearning,Z0FBQUFBQm0yeGJiZlNqeUFtYXVfc3ZvbUVaWWRUYVFpZ2xIYnRlTkZHYTFRUVN0UGQxcktNQ1lZSEJva0dPRkFGX1JYYng3Z0l3NklEa2ZIZ3dETzJsU2YtcFhlMjRuQWc9PQ==
"This would almost be funny if it weren't unfortunate – it's reinventing the wheel and calling it novel, while misunderstanding the current state of the art. 

Bucketing by length to create variable length batches with minimal padding is how Transformer models have been trained since they were invented. Their large claim is that this is more efficient, but the shift to packing documents in LLM training was made *because* it's more efficient.

They also seem to be unaware of how common it is to reset the auto-regressive attention mask at document boundaries.",r/machinelearning,Z0FBQUFBQm0yeGJiTm1NS1NtOWJNRWRWUnMyZTZuUTZqNlFoTUlNOFpaSk1PUWh3dGJGdjhjRkRyT3gtLXpuV2dBd09jV1RPdWtYS243Sjhpdk84eW1iSVdlNV8ybnZ5OUE9PQ==
"Saved to read later, but from the abstract, it sounds a lot like contrastive learning.",r/machinelearning,Z0FBQUFBQm0yeGJiTU5JYkplQUJyWjEzYnYxZ29QRlFBekJROThwVTRSSGVRRk1JWFVhYi10Rm1nZ1VaejFwU3pBM2NESXlqRGY2eDIwbnVrSUh1Y0FQclpyNVA5VXR2TVE9PQ==
">This is exactly my point. Most googleable questions don't benefit from AI summaries and most questions you ask AI can't be solved by Google.

Are you arguing that it doesn't benefit from LLMs right now, or that it would never benefit from it even with an improved model & framework?

Seems like you are conflating the two arguments.",r/machinelearning,Z0FBQUFBQm0yeGJiUmVmN25SSmhZM0tDUHY3NDZQSFBrbC1LbUhoZGdfS0JCXzEzalQwbjN1c1hkYVVCZUxTbHlDX0xNVloxbnAtZDFkRkJPNU4ydVFGUVhpRDNNX0lzT2c9PQ==
"The current CEO seems to have abandoned the idea that product changes should be made by passionate people improving on their work, and more about colliding pet projects into other people's products.

It isn't like this didn't happen before (see the guy who moved from microsoft and tried to pull all google accounts into his product/platform), but this seems quite obvious at the moment.

Launching in a more humble way, and staying there for longer, gets less but better testers, as most normal users are just going see things are wrong and not provide any feedback. It's like they've lost confidence that in the rush of different machine learning applications people will care about their version.",r/machinelearning,Z0FBQUFBQm0yeGJiOEVWMnBJQUloLU4yaDZhT2U2cmlRLURMRGV3dkVCZlZxNTV5azRLUGxxV2luQ2tZNVVXaV9jVHFVeFRWNkRuOEZTVFQ0eWluYUI2eFJLVi1Xa21hTzZhcUxnMGJQa29CRjRGODk5NlN3T3M9
I wonder if you could get better results if you did something like sentiment analysis on a finance news aggregator website such as https://finurls.com  ?,r/machinelearning,Z0FBQUFBQm0yeGJiVE9DemVieEpPSTRaWFZLQTVOUlExMENxanZjUHlsRmM4enBCa24zb0sxVUpmMVRPVndTNGJxcWlvVDlVN2VOTEd5cV9MbFgxMndyRV92SWtuUDJtTlE9PQ==
"why the cmt has only ""files"" and ""actions""! i cannot see my reviews! i had two weak accepts and a weak reject",r/machinelearning,Z0FBQUFBQm0yeGJiaEpvdkpneHhmSGZCT0piSTBtS2M0VXNSZEtXbXNDRVJ4d0Q1WHBmRVNRUWdVRWpWenk1NWRRYzNRdFd6UVFDZms0X2NGVE5DVnc5SjVhRkN4cDBnSE83VkFaa2xaS2FXanRPZ1A0NF81eG89
Isn't this the one where the initial line up of speakers are some crypto folks and Edward Snowden?,r/machinelearning,Z0FBQUFBQm0yeGJiTE9paVBFSUFlbzZ5eHU1RzNVbGNpMFhQNFdPR0Vtamdka1pLMFFtSkZvYTRDVnFYSkhPekdLX01MejA0bjBBTDU5ZHRkTzhvbUxOdXVxNHVaejJzRnc9PQ==
The RT-DETR paper does emphasize lack of NMS as a pretty big selling point over YOLO-type models.,r/machinelearning,Z0FBQUFBQm0yeGJiS2xqMXZmQjFueDM5cUR1aGg1azBFM1RtOXVXSGxMTXd1MVNDenA3VzFfZVh4ekRBSHpUcVo0NjZXVkZMemk0VnNXVVVtbmhjSmVHQ0pyUGprRzRscXc9PQ==
"Maybe we can say Balaji Srinivasan as crypto folk, but I don't think anyone else fits the bill.",r/machinelearning,Z0FBQUFBQm0yeGJiSURMTUliSG1LczJkdEIzcVdhd3JoSmY1aGN4Rm85OEdWanA1emI5cEJxMzdZRXJjMnFWQ25uSTFjQzRiWDM2Q21idkJyWHg3S2lZcm14XzJKYWlVbUF0Si1qV1JTb29JaEdaX2s1UFhNSEE9
"I HATE IT. 

Not all Google Searches can be turned into AI responses. Sometimes (often) I want to see website results.

Just make the goddamn thing a separate button like maps, images, etc. Then I would use it willingly and often *when I need it!*

IT'S NOT HARD GOOGLE.",r/machinelearning,Z0FBQUFBQm0yeGJiR2JmdEhKb2xLNU5SMXJnTHBsZEJfTHprZ29ISUx5S01CaUZRUmN1eG9fTWNZbW9IcHpjSllPSVRRR0JKT1ZtM254bkpUTE5aa0hMdHE0YTBDZDNPSlE9PQ==
"Eh? Vitalik Buterin? Well the line up of speakers has since expanded, but I do remember coming across their page a couple of month ago when had less line-up and the only recognizable ones were Snowden and Vitalik. Lol. Glad it worked out for the organizers.",r/machinelearning,Z0FBQUFBQm0yeGJiM0lpMzREQThKZlJnOHpmVUZ4ejNFMEdkcUdTa1g3YXNGczlfTDQ3WmlYazVlQURXd3dMZXltdG1ERzVZOW5YTnFBR190a0JvTEFwODIwemt4NEVvMkE9PQ==
I personally scroll down quickly and try to avoid seeing the AI response while searching for reputable results. This stuff is worse than ads as a result.,r/machinelearning,Z0FBQUFBQm0yeGJicXZCRlVLeWVJb1pUaXRQTU8xVTVYeERWMFEwVGNjOHJ6bk9EZTB4ZF9PNFhXTWliUm1tb3FNcnlnQ3ZHTDlhWFQwUVBSNTBwdWtKdEZPSzlGaDBKQWc9PQ==
"I have tried something similar in the past but found the results to be incredibly inconsistent. With search data you are collecting a larger, more diversified dataset whereas news can be easily biased and incomplete. Your point is completely valid and would likely garner a more nuanced model because there is a larger matrix of possible inputs but far more work. You would likely want to pull in news from multiple sites with different political leanings.",r/machinelearning,Z0FBQUFBQm0yeGJia191Uk4zbWpHVGl4Y2xYeS1zMDJqR1QwU0FOXzd4ZG5fYndWZ3JBSTFlUl9TUmRQZDk4cHNBbUdLZUZrcEZJY3NnM0l2UGdOZVljSkZqSkdQMnNNUVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiS25LSmFCNE5BVnNtbXJPNVFBYXp2VTE3X21PSHJMdFpZZERGTTNJVkkzNTM0RXZZWjVnamhZRlQ3SDV2aURmSGFOQ2puZlZPWU9ueS1vMjZXVXNvN0E9PQ==
There is a major difference in the detection accuracy if you compare the versions v3 and v8,r/machinelearning,Z0FBQUFBQm0yeGJiUXh6OFR3YW9USkY0OXNCOE9vYzNrby1IQlhSb2ozanFkd1B3WkxVaHFzbl9GNHVoWl9STXNBRTNmdzZPb211bGVJQnp0Vkg3c0p6VmtwUzRkTDVXRGRTUWlkdGlCa2xCcjQ5VU4wblZNb3M9
"Context agnostic measures in unsupervised learning should be taken with a grain of salt. Imagine I cluster a set of people the following ways: 

- split by gender
- split by age
- split by favourite hobby

If I'm using the clusters to sell insurance maybe I just need the second solution. If I'm exploring the data to understand patterns, maybe I want to try clustering on all three simultaneously. 

Silhouette scores are good for checking that your clustering algorithm isn't absolutely daft at finding clusters in the data. If you have just one variable, height, and your sample is NBA vs. Kids in grade 1, a cluster solution that doesn't split up NBA vs. Grade 1 will have a worse silhouette than a cluster solution that does. But once you have an algorithm that can reasonably do that kind of separation, the nitty gritty details of which solution has the best silhouette in a high dimensional setting is essentially meaningless from a practical point of view and more of a toy flex like writing a complex one liner of code. There's no 1:1 connection between silhouette (or any) purely data driven cluster quality metric and real life usefulness because usefulness depends on your context.

Why are you clustering the data to begin with?",r/machinelearning,Z0FBQUFBQm0yeGJiY3ZONHRUbHkwRGJsVDhhemVDV1VrY3pyeXBWSTBBa3M3Uy0xbkJ3bWM5b2JaUk13WS1tM21jMno1Y0pPbjAwRWlxbUZrUjlzSG1SeFgtcUFvbVIyeVE9PQ==
"Wow, that is probably the most advanced machine learning research I have ever read. What they are doing is very interesting, and admittedly, much of the paper went way over my head. My only question/concern would be overfitting with the very specific lags. I understand why lagging the impact of factors is important and found the negative lags to be an interesting place to further research, but I would be curious to see the results when pooling multiple factors together in regard to lags. Similar factors should have similar lags and by pooling them (essentially batch uploading) you may prevent overfitting with very minor impacts on performance.",r/machinelearning,Z0FBQUFBQm0yeGJiLURJM2psTWFJOGVWNTF2NGd4MW00Nnc1ZGkzeVJiSzdTTUVxcTB2ajItSVhNUmFFTmhZaHBTLS1xTUg0ODFibVoxX2RGNjZjbVF5OVV6M1ZvRFlHZ2c9PQ==
"Yes, but on the other hand, people used to just go to those pages and get their wrong information more slowly.",r/machinelearning,Z0FBQUFBQm0yeGJiY2hjY1VmU2FRTGlVbDRTS1lDV1NxNkRQU3NYS0RfUjZxUXMtQTJxdnBQZm9Ba1dvWHVXWnl3clF0N01pdURmcm15ajVEZkN6ZnhEa0FRRUVaWElHWEE9PQ==
"I've only used DGL and PyG, and I think PyG is a much more ergonomic API, not just for heterogeneous graphs. I think DGL is faster in benchmarks, but not by much.",r/machinelearning,Z0FBQUFBQm0yeGJianhnZGhyZUwzN0VwcUVmd25mZGdwYmFyYU1tc0JSVTlvMWRKRTBYcENCN0dCdThqUU9HemZsYWNRcTd2SlVwSlBNQ1NsUEVDQWlyTHlpSExjaW8tVUE9PQ==
I was part of the beta for a few months. It was awful 90% of the time in my experience - I make a lot of technical searches and it really suffered in that area because it would regurgitate out-of-context things from the search results that weren't correct/relevant for my specific search. I don't understand why they decided it was ready for production.,r/machinelearning,Z0FBQUFBQm0yeGJiQjBxdHVTQjlkRlZKWVZtUjZFczRmNDM1VkNRTUwtM29JWlZSN1VpRU55ZEN3YUlFMTRzZkhqSm5JMTBFR3lGVk16cGRVbFZQSjBMRmgtSTZ1cVRrbWc9PQ==
I'll wait until they publish more than a LinkedIn post before getting excited.,r/machinelearning,Z0FBQUFBQm0yeGJicXNJcDNtb0lLeWczWlNXZEFBSkRRT3FHUmVYV1FsdzZ6UDgzQ0RKaE80S0dTTDlNYnMxc0hKNEZTQWY2bFpIbHhzZ3hWVjVicFhUbmo0XzRiUlpsb2lJUGY2SHBjVXJMSnFnY1ZuWWZBSlk9
"You can't afford to review papers without the assistance of LLMs? Yes, you can. Millions of people do it and as recently as a few years ago it was the only way to do it.",r/machinelearning,Z0FBQUFBQm0yeGJiRlBhdkVuaHhERk9aVUZKT3R6ckkxR3pQSjNYajZHY0dpN2tLX212YmdacGl4bkNDYTRfWVYySVkxN3M4dTFqZ0RBbTdydkxhNXVwN0VnSXJ1LXVteVR6anZNQUd4a09CSG9FREotRjJhbmc9
"Can this technique be used for optical target acquisition and missile guidance towards, say, a tank shaped object that may have moved from the target coordinates known at launch time, using nothing other than an visual sensors?

To give you an idea of the latencies involved, a typical anti-tank missile travels at 0.5-2 mach (150 - 600 m/s), a tank is roughly 10 m long. Assuming a 30° optical angle and 1280 pixel wide image, a tank would be seen as 20 pixel object when the missile is 1.2 km away, so the entire visual guided phase of the of the journey would take from 2 to 8 seconds. During this period, the guidance system would have to make suficient passes over the video feed to keep the missile on course. What kind of on board hardware are we talking about to achieve, say, 10-20 fps?

This could be a game changer in this field, as low light CMOS sensors have come a long way in the last decade, and can generate 120 fps HD video using nothing other than moonlight. The traditional way to solve this problem, thermal IR, is highly controlled military technology.",r/machinelearning,Z0FBQUFBQm0yeGJiTDNJdkxQMTlPYmxsNFBOdC0xendBdWFaLVVxMVBHYTB5dlU0RjdjTTZtTFg2cEVyZDdnUU1jb01mOGJPaEtwYTdsVTVOWnpMckhmX1lzbzNjZURheWc9PQ==
And the fact that different versions of PyG have different train-test splits...,r/machinelearning,Z0FBQUFBQm0yeGJibHlCdHVRRWh3Y1hGRk1UOHZlM3BqQ1RHUkpmUUlhQkF1VUJTaVNCU1ZnamYydjFpa1N6bTR2QVV5R3dOVUN0RXZGYWNtYS1hXzVZeGlKQnZ4SWpXV3c9PQ==
"[https://sebastianraschka.com/blog/2023/llm-reading-list.html](https://sebastianraschka.com/blog/2023/llm-reading-list.html)

Read the first 5 papers, you will be good to go. Read the rest if you want to explore more.",r/machinelearning,Z0FBQUFBQm0yeGJic19SeFE2RkFwbUEtZGlhejZPdmF2LXNFRkkwc1owQzhXaHFyenZvYVVtZXlLRlJKVFJvV25rd3BJUFFTNUg3TWRqbzV1bTlTN2toQlcyeG80YjM4TlE9PQ==
"Yeah, sounds like their ""memory tuning"" may just be a fancy or very good RAG 🤷‍♂️ guess we'll have to wait.",r/machinelearning,Z0FBQUFBQm0yeGJiVW9PQ3o0RHdKZURZbHQ2eHViZml4UmpXcVZzZjZ4VHNXYnlqWGhKV3dheTdOanJ6OFZfYkhsR3ZnNURJU0RVTGs4Z0QzVk9BMTJQazdWUW4yQ01ES3c9PQ==
rishi sunak just needs to resign and let someone else lead google,r/machinelearning,Z0FBQUFBQm0yeGJiRFE1SWRuS0h4ZE9HMkwwRjl1WEJWcjZkVzZRai1Lc3AxT1dZd0xhSUJOMUdkWkg1VHRqXzVpN2Vfek5mSzE4OG9CUm1VSjhHM0NMWE9VRHYycktUTnc9PQ==
This seems like a recent discussion [https://www.reddit.com/r/Compilers/comments/14z6gwd/any\\_recommandation\\_for\\_studying\\_ai\\_compilers/](https://www.reddit.com/r/Compilers/comments/14z6gwd/any_recommandation_for_studying_ai_compilers/),r/machinelearning,Z0FBQUFBQm0yeGJiclM1RUY0WmV4SE5GNGM1SDZFcHVZX2NFYmc5QTFFMmQ4dElSUWNXU1MwSUtrMnY2c0owbWliZXNMaUVrSjBlcnBjZkl3MkJkUzRCQXRVZ2d6WkFxNEE9PQ==
"90% of the time it's a or b. If I am asking about health, and it cites some bs from healthychicks.com that sounds wrong, and then I go to healhline, webmd, NHS, or mayoclinic and the cited information isn't anywhere on those websites it's still misinformation/wrong that I disregard - I don't every time actually go to healthychicks to see if that's what they're actually saying to have plenty of examples for you, but I do have one that happened yesterday because for once Google cited the correct source. ""Are J2 eligible for work authorisation premium processing"", AI overview confidently answers ""Yes"" with details on how to file for that, when in fact if you go the source the answer is ""no"" and there's nowhere any mention of J2, only F1.

Another kind of example for b is answering a different question than was asked, e.g. if you search for ""reasons for rejection of American tourist visa in Turkey"" it will give you reasons why your Turkish visa was rejected, if you replace ""Turkey"" with ""Greece"" - it will be reasons for why American visa was rejected. Idk, what's up with that inconsistency, since in both cases, the Visa Denials page on the US department of state will be the first search result so Google search actually works better at understanding your query intent but that doesn't translate to the AI overview somehow.",r/machinelearning,Z0FBQUFBQm0yeGJibTNYRTRwUHRkZThPdnJTcWtNWGZmSFNVZGk4LVlhN1RLZDhxVnQ3SlhZNkswbmVXTjdvRGI3dXVlbGJobE1vTWtPRlVCNE9TcEJ1OFdHbUNjYkU3c1E9PQ==
"There can certainly be a distinct train/test set. Suppose you have retrospective medical data and would like to deploy it to hospitals across the country. You would need to fit the KNN to your retrospective data, then keep it fixed during deployment. Assessing generalization to unseen examples will always be necessary as OP did here during crossval",r/machinelearning,Z0FBQUFBQm0yeGJiUmtaSzZEZ1UwR2cyeHYtVHFiNlJtM1A4VjFVNVd0WUdMRlRqczdyNW5pNjhyRGJPbE0wYU5Wb19Bal9DZDJ2UEIwUWVfazdfWWFHYlhXQ0g3amNzbGc9PQ==
"I think to understand how the brain learns, we need to understand the mechanisms of sleep spindles and dreaming. Those have been suggested to be processes related to memory/knowledge consolidation.",r/machinelearning,Z0FBQUFBQm0yeGJiVkNBOXhxSVEzWEpSR1ZacjhCczJfMHdicXljaGxBRG9fYjdid2xLZS1xaHpmQTFBZkJXQjdlSFRHXzl5Uk5yS2NfUFMtWEo2cEc5cjBlTWU5YXR6dnc9PQ==
"The most difficult thing is getting proper resources, budget to better clusters, better nodes, sometimes you need to do lots of politics to justify budget. 

Technically speaking once you understand that models should be separated from applications that handle business logics the rest becomes easier. We deploy models in Seldon core in GKE, then apis in fastapi that expose those models to other teams/users.",r/machinelearning,Z0FBQUFBQm0yeGJiRkx0WUs2UU9ocHd0ekFodGgwUGh5NjdqX08wNjlLeWRSUko5cmNGT2IwMUg2aGZZY2lpOFpIb1pRVHJneWdKVVo2RTR3d2o3eG5DV3k0ODhmcXQwZDFycE81ZTFYeXlGYjVZVEs2TElfQmc9
"yeah making q,k,v at the same time is easy, but efficiently doing the attention operations is the tricky part because the naive implementation is memory bandwidth bound. there’s great custom cuda kernels for this now though, see neighborhood attention:

https://github.com/SHI-Labs/NATTEN

and the associated paper:

https://arxiv.org/abs/2403.04690",r/machinelearning,Z0FBQUFBQm0yeGJiSS1HWXZwTkN4YWpON3lUT3FaTUZoOUJVcjBieVlKNHIwZDVrUW9uYW5vMDliLWEyVGVfbWh6bGd1ckJmNWZuNDZvUXpVMHJjTmFkMTNTc3BvM0lzQkE9PQ==
"I have three and posted but not really getting answers.  Hope you can help, I am pretty new to this.

This is around LLMs.

**First question**

I think I have the concept around LLMs, I have been looking at tensorflow and keras and llama2. I know this gets into the detail but I like to roll my own stuff for learning for better or worse.  There is a model reader in tensor flow to read llama2 binary files. I still can't get a binary format for it.  What is it? Pickle based?  I even asked chatgpt and it says there is no format.  How can you not have a standard format.  What is there if I were to byte by yte look at one.  What is an example one from hugging face.  Can i visualize a small one?

**Second Question**

Same lines.  I am still not clear how people build the llama2 binaries.  I need to read more and watch videos.  I know there is a binary, they will see wizard of oz and then hey, here is a chat.  Hold on, what are all the steps?  What are the weights?  How are they built?  Can I tweak them?  Can I pre-train and how?

**Third Question**

With that said, I have a blog, crappy one but I figure I can build MY own llm against that, also tweaked with public book data.  What are steps to do that, step by step for dumb newbies.  I see steps from wizard oz then cuda, pytorth.  I dont know, if it is a simple demo, I wouldn't gpu accel in it.

I also want to build a language, llm around povray ray tracing see here.  This is mix of programming and docs.  How to do that too?  How do they build llms around programming?  

[https://www.povray.org/](https://www.povray.org/)  
Possbly one for libgdx  
[https://libgdx.com/](https://libgdx.com/)

**OK Fourth Question - Legal**

I am surprised the legal question doesnt come up.  I guess it doesn't matter.  For example, I see the spaces in hugging face and think, this can't be legal. Some of it.  Meaning, taking CNN data and putting it through a LLM.  Also, I ask because I want to run my blogthrough a llm and then repost things.  But it is my data, it is public to me.  But what about reposting llm data from say llama2.  What license would allow that?",r/machinelearning,Z0FBQUFBQm0yeGJiaE1wQkRLQktHZGtUZU9ZeHFCZmdiLV9QQWROYmRoUjNHTmRRWkRDTC00NHYyUmp0c3plcTRhLTVqcWxTV2dadWl1QnV2V1dLQWtwU0JrU2ZQdndXQkE9PQ==
"Just wait until you hear about execution tuning, data tuning or tune tuning",r/machinelearning,Z0FBQUFBQm0yeGJiZ1d5MWl4SXowLUt3QUxZYlhYbDBJYlBLaVVmelMtNjgyckJUR2NJVHI0eUVDTEdpMXo4TVRSNDBRTXkyU3dQX0hQNmFXNE0zaXlmNjI0MnNtMVY2RHJwQVBaSFVGTU03U0VIQTQ2YTNVaU09
"Good for you. I never was ""years ago"" reviewing such papers.  As I said, I can't effectively review AI/ML Arxiv papers without assistance of LLMs.  I have no formal education in AI/ML.  My degree is BSEE without any AI/ML, with a career focus on consumer electronics, not Matrix Math.  I started learning GPT  architecture and ML/AI in early 2023 when GPTs were publicized on TV.   LLMs enable me to extract jargon and greek/math symbols from AI/ML/GPT Arxiv papers and translate the abstract theory into a familiar python script snippet, or compare the variations described to the python that I already know, and translate jargon/symbols English text that I can efficiently absorb.  I am researching GPTs and their variations and I working up to using python to build, examine and modifying Tiny GPT models.  [https://huggingface.co/MartialTerran](https://huggingface.co/MartialTerran)",r/machinelearning,Z0FBQUFBQm0yeGJidzZkelR6em5rNWswMVVUZGVUXzJHWVFMMzA2OHh5bkxKbGlEUFpKaF9IYWZlXzRRWXZocXhVbjQ0MFllWVlhRGlvYlBGZnNrTHJ5a2JlNzJwa19fQmc9PQ==
"1. Just adjust the attn mask

2. It doesnt matter if you scale up. It just works",r/machinelearning,Z0FBQUFBQm0yeGJiU2wxQXd1UVBiX1lXaGQ3bWFmMHVfUWdrRUo1VGVlQ3RraGpkV1VWUmltRjI3NkdYYWppblFQU2g5cmQ2UXkxLXNiYXJ3SjJrWGhFdDBMalVab1kxUWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJicGY0b2NwSWhQWmVjOWZUWTdDZV9wMGRpWlQ5dmhQOWtVZ3NSckhxY3k0UDNFUHhGRkEyekp0UUgyUTdvWmdxQlNrV05XUUVqclQyYTNtZTBSSXU3NHc9PQ==
"My project aims to cover not only computer vision, which is the primary focus of OpenMMLab, but also other AI modalities. The goal is to develop a comprehensive toolbox that supports various AI applications. While OpenMMLab excels in the computer vision domain, it lacks many features necessary for conducting and completing research efficiently. Once fully developed, my toolbox is expected to reduce the time wasted on research by approximately 60%.  
I believe that maintaining standards of reproducibility and comparability is crucial. This approach saves time for the current researcher and future researchers, who can simply load the configuration files and train their models using the same standards.",r/machinelearning,Z0FBQUFBQm0yeGJiNlVMcE4zMTdmdDV4OVVfVnBHYl9vZlU5VkRJNm1YLWFUMFk4LTRoS2pIcUUwQ3AtR0Q1VHlHaW9EVFMzVC1YUDVsbHZpLUVMVjdPRURVR29EV2d6Unc9PQ==
"Yes, definitely! I’d be happy to introduce you to the codebase. To get started, you can fork the repository and test it out yourself. Please DM me for contact details, and I’ll get back to you as soon as possible.",r/machinelearning,Z0FBQUFBQm0yeGJiOFhPandnX0dHVFBmVUtwWkhlOGdwVXFpMDR6Tkw1enl5SklNWS1WVUNwOUVoZ2ZsMTQ2eGU5NnlNRk9fRk0yZlNWNXpLVzFJNXkxdkVOZ05CalZpOEE9PQ==
"nDCG still works for binary labels, it will favour a ranking where the 1's are higher in the ranking. For example for nDCG@10, if you retrieve 5 positive documents and put them at ranks 1-5, you would have a higher score than if you put them at ranks 3-8.",r/machinelearning,Z0FBQUFBQm0yeGJiWG1SY194Xzd2V0hLRVgtejBKQklxejN4eXZhR2xqdWFWaHZwYTVzdjRaN25yYVctRU9XVENRQjlNWHRrd3lySXdtSktodTNvVWhDbFVaRV9feTBxR1E9PQ==
"Oddly enough, I've solved this problem on extremely modest processors (under $20).

The key is a collection of tricks.",r/machinelearning,Z0FBQUFBQm0yeGJiMWgtdlFLMHdEbnp1MVJldHctRTkzcVdTNEFLZWRKZGFfMWxNLUtLYU5RLW1rNTlrNlJBdlVjYy1nMWVBYnZINDlmSzROZ3QwbkZUdzdsd3BHX0Z6MVE9PQ==
"people make up buzzwords from existing methods all the time to appear different in the business landscape. Unless they publish details and proof of value beyond existing methods, I would be skeptical",r/machinelearning,Z0FBQUFBQm0yeGJiVlBJZVd2OWpWcmlCb1RXTlBDYllRT0dVRWhtU19YWEVpb0NHNjRwbW5maVlUcmFHMUxBNkFxVHJCX2pkS2RUU0xzcXhkY2RBdTA5bnJSNnRvOWY5Snc9PQ==
Why would I ever trust an AI from Google? It's whole reason for existing is to sell me something.,r/machinelearning,Z0FBQUFBQm0yeGJiQ3FiVzV1dDVrT3RSSFc5UnhEMDRGQzVjS2Vrd0hsc2NxSGQzUmI4UmFKR2tWMmhGMUoxQTB2anNVWUJ2a1V6MWxvV2tULVQzRWRxaktSQjdyRVlxSUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiRXZ1eTFiUDczd1UycC1vMGp2ZlNVVjN5aHFKaFRsWV96TUhFRGRtbTdlNDBKdDRWcVlwdTlWYi12MDFJb2N0QkVCVHB1VE5tS3FtZGo2YmxsZHFJb1E9PQ==
"They claim downstream benchmark performance boost compared to ""just adjusting"" baseline. Which looks sizeable enough to not be explained by pure noise (not much details about robustness though). And which looks to big to be explained by the curriculum effects, judging by their ablation experiments. Where exactly it comes from is unclear to me.",r/machinelearning,Z0FBQUFBQm0yeGJidm1pYUZoT09ER0Y4QTBwQkU0QWV6Q21vVXFMRm1LZFhPQTQ3bEpjblc2aFF5eWVfclRCX01NSWpvUlVIWmY1dWw0TllmN1ZDRktyczNwNzNhcVQxekc5MThsU0dUYS1GVVpZX0pkdUNmYlU9
"Do you think thermodynamic / stochastic computing for matrix inversion will be usable
With Riemannian HMC?",r/machinelearning,Z0FBQUFBQm0yeGJiNU1aOHFVWjNNUHdkTzd6bTlZUWFwVDN5YWF1UVUwWFJpcVFqcDRmanZUa2NVS1A1WnpubXR2bTVNS013LUJTNVZPMk9rRG9TbnpEd3lwWU4yU3JHVGc9PQ==
"I remember reading your paper that talked about progressing  (iirc) to the trillion parameter level for modeling in the future.

Can’t believe we’re getting there and I hope graphical models hit that scale too",r/machinelearning,Z0FBQUFBQm0yeGJidHJ0THRTcnluTVIyY3FPeXJNczMxQmdxUU5EUnRHM0JsaC1kcTF2bjdwTTg5eEJsaHNISlR3U0lBRlkzMnVIQUd2dVZoaDJaYmRiRF8yYjdPTWJwYVE9PQ==
">unaware 

That's a bit rude way to formulate it. I'd go for a more flattering ""strategically chosen the easier baseline to beat"".",r/machinelearning,Z0FBQUFBQm0yeGJiWVdQQjBPcjR4YVFrejNQbUFBVTVtNURveHVlaGUtSjc4eHV4Z1ZzeHM3THRiQTFmRm13c3l6S3VrNkhLcGxVYzRPVWJDdGZET2paQzZETnpwRHRGN0RVNDhfQUlxOFJpUVZHRUpmSHR5NXc9
Why is it better than PyTorch or Keras?,r/machinelearning,Z0FBQUFBQm0yeGJiYTYtYmdjcmxDRFVWa2Y4UDhkMm05UXljRkNRRW1SOWIyUHBuZW9hQlkxN2h2bTBlRlZSN0lFZm5HaGR2WU9MTkhiSFd1YlJ1QUl4Rnp5aExqU29xSVlrakEzUFN5cHdNZUF1MnRVSEV1RFE9
"Neurips, iclr, icml, and maybe cvpr if you aren’t an llm andy. Some other topic specific conferences if your grad school is paying. Definitely not SuperAI.",r/machinelearning,Z0FBQUFBQm0yeGJiQXZVLUhnV2w1M3Q4R0E4RjBnNHFhbGFiU3ItcWVMS19KVTFWYXFJNjU2VmpiYmdfNnBrUjR3blNOU0N5bEt4Q3hoVEFFOGZCS09zVjRYeGFPYnhKWFE9PQ==
"PyG is all you need, basically. About 99% research that I see, and 100% what I do, is in PyG. It's simple, performant, easy to modify, and has incredibly helpful and active maintainers on GitHub.",r/machinelearning,Z0FBQUFBQm0yeGJiNDBmeWRGdXhydWExYzFaLWhJRW1HZC1MZ3pwdDRKWGdyR0xlaklCUmNyZERPZExzd0JGMWZaMEJ6ajhiM2VXNi05M1JTVU4zWlJGWVlUSm5qLVpQTWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiRjVRMTVlUzJIaVpRMHBkVlZUcjNZanh1cWliMkRTMU10aVJWaWZUc3ZxbGlVb3V6WDhjUUdKWDV5YVpNZlFxbTRIdTlzR3QzT3R2ay11eU0tVlJLMWc9PQ==
"I guess it depends on how you define the ""target"" and how smart you expect the acquisition to be. Heuristics are a practical solution in a constrained environment, but they can take you only so far.

The objective here would be to take advantage of all the advantages of ML to achieve near human operator efficiency, for example train on a vast array of enemy hardware and prioritize high value equipment (radars, air defense batteries etc.), ignore things like nearby civilian trucks or tractors, distinguish an already hit tank from a still functional one etc. All this many miles behind the frontline, with no human operator in the loop and no radio communication.",r/machinelearning,Z0FBQUFBQm0yeGJiZFN4WmV2YVF5NXpiY2pBeWwtMTQzVk5OM21nMEtRMTdDbmRha05yVC1RS2RTVHZCUUxhTURJdUFtWjZidnVIbUJxMmMxWi1EQTY4VDgzekg4WmVJRGc9PQ==
"Sorry, I didn't mean to be rude",r/machinelearning,Z0FBQUFBQm0yeGJicHVfLXZpMENnX0YtMU9uMG5OeVVLc1k1QkJBRHVuV1dmRFFHTjZZYURPX2wyYUNPZThXR1BKazdNZXE1T2RCZGhkc2R4czdCSngycjg5OUZQdVA1THc9PQ==
"> I'm inclined to disagree on part of this - the nonsense that sometimes comes out of the AI search would be very unlikely to appear from something like Gemini 1.5, which indicates they are using a very small/quantised/pruned model purely for a mediocre search summarisation..and therefore having a minimal carbon footprint.

That's a fair point.  I'd be inclined to agree more if they had volumes like DuckDuckGo or OpenAI, but I think it's important to remember the scale of Google.  Google gets about ~100k searches _per second_, or about 8.5 billion searches per day.  

Let me try some back-of-the-envelope math: The best-performing model I could find with sub 1-B parameters on the HF leaderboard was a 7M. Big caveat: this was not fine tuned for summarization, I don't know how well it will do summarization, and I don't know the overall performance of the model.  A batched inference, assuming a maximally efficient operation, will be qp = query*proj matrix, kp = key*proj matrix, vp = value*proj matrix, (three flops per weight), qp dot kp (another flop per weight), softmax (another flop), and (qp dot kp) dot vp (another flop).  That's six flops per weight, thereabout, so a 7M model will take 42 MFlops per inference at optimal efficiency.  I think this is also important to recognize as a lower bound because I'm not counting any normalization and assuming a full batch and not counting any activations other than the softmax.  That's an additional 357,000,000,000,000,000 flops (357 petaflops) per day at minimum.

Admittedly 357 PFlops is a drop in the bucket compared to other compute, but for more comparison, the most efficient supercomputer (RIKEN, as of 2016) has about 6673.8 MFLOPS/watt at FP16 precision. We have a net additional cost of 53,499,175 Watts for their daily search.

53 megawatts for the feature, very rough ballpark, for a 7M parameter model.  That's maybe 10% of the smallest nuclear reactor in the US?  If they use a 1B model, this value becomes around 7.5 gigawatts per day, about 6% of the total US nuclear energy production.  (I'm using the US here and nuclear energy because the figures are easy to find. Keep in mind that Google is distributed world-wide and has places that use more coal, more gas, more petrol, more PVs, etc.)

This figure ignores query caching, which would bring compute down, but it also ignores indexing for RAG, which would bring compute up.  It also assumes TPUs are as efficient as the most efficient supercomputer in the world.

I think it's a judgement call at this point. 1-7 megawatts extra doesn't seem like it's worth it to me, but it's not so obscene that it's completely impossible to tolerate.",r/machinelearning,Z0FBQUFBQm0yeGJiNEk3Z0QxdmRIYmx0QVFIQjJMRGR0TGpPSjJyTGloWXY4NGhHNXF2dU5ma1lFQjIwelM4aFROaEpYaWg2c1lMUkNzZjRvRExVaGpMRmtlX2xHT19ua3c9PQ==
ICLR and 3DV are in Singapore next year. Those are reputable,r/machinelearning,Z0FBQUFBQm0yeGJiT3RqTUIzcmhHUWF0MW93MUlycG9Vdm1aRkJLdTRldmxVOEkzbnFnbElFLVd1LXotX2pBbjVrMmFJSUJSdVVxUElwNHZPRGp6Sl92cVk4b21mcnhRd2c9PQ==
"Running llama and finetuning it on your data is not super difficult, but it requires enough steps and background knowledge that it is difficult to explain in the space of a single comment. I recommend spending a lot of time looking through r/localllama ; that's a subreddit dedicated entirely to hobbyists running LLMs locally on their computers.

Regarding legal issues, Facebook publishes the Llama license, you can read it here: https://llama.meta.com/llama3/license/ . TLDR you can do just about anything you want with llama, within certain limitations.",r/machinelearning,Z0FBQUFBQm0yeGJiTGM5Qjh6WFZpWlp1SnY3TmdmZUg5UjJZbTByaVBFRm5XbE40QWJDbmdaNUg0bTUtMGxRNkpXSkZXdzd2bzRlaW1sZmh5S3M0T18yTTI2TWZOV2YtMlE9PQ==
I'm genuinely curious - how have LLMs improved your life? Could you give a few specific examples?,r/machinelearning,Z0FBQUFBQm0yeGJiOWI3b01EZVlpdVVFRE1mSkIyODIyQ0pjQ0M2QUNnTFh5QmQyY1AxOVF0anRiNjBTU0d3YTZGMXVRWTAtZmlGZEZjZDNqT2pHcWlRNDRMSkZiLTk3Qnc9PQ==
"Yea, I am on local lama, I think there are a couple tutorials on setting up a llm but some things are glossed over.   I will keep looking.",r/machinelearning,Z0FBQUFBQm0yeGJic1ZKUms3MDZXOWktRzJCQmt4LWZfdXIxT0RJQWFLdWFSMjJxYlhWMk9CSlgydWtGeDFvTlBXYmpUWlFVaGowR2lWNWRIV3BhQW5GaEV3OEVXcS15QVE9PQ==
"If you focus on a small vocabulary and action space, it's possible to train with less. [TinyStories: How Small Can Language Models Be and Still Speak Coherent English?](https://arxiv.org/abs/2305.07759) - they can train a 10M parameter model fluent English at 4 year old level, including reasoning. It's the precursor to the Phi series of models from MS.",r/machinelearning,Z0FBQUFBQm0yeGJiT3FPMDFVVnJyRExKQVlheFJGRVpobGctX0F2RmtYVkJVcGoydHdfb3pCMEZ4VERVd3R5cDVCV0JNMldOMk0wd0FVWTgzTzBjUGgxcmxRbXcwRHZhNmc9PQ==
"But there is feedback. Unlike ANNs, the brain is a continuous time system, the signal from above comes later, but it comes. Then the neuron can learn.",r/machinelearning,Z0FBQUFBQm0yeGJiTzJUTVhnQ3Y2eXhuckdnMTIyRTFIRFlwSnN3ZDE1a2hOVElIZ21hZ012QTZxa1BUSDl5ODBXUnoyQ1h4bDhWdVJIZmJ4STJscENXWVhXclQ3MmRpdGc9PQ==
Apache 2.0 license or it didn't happen.,r/machinelearning,Z0FBQUFBQm0yeGJiRjA1aGU3MnNqNGQ4VXdaczJzdnc5My14TS1KTFJXWUtTc2JrZkRtYkRvNGZNOXdsZnlQS2E3U1d4NTNDWVZ0YjFXeGZqaXR3VnQxVFg5YXI1U3g3QVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiSmtjVnJ4MHFRYi1SVWpobVVHbEh5TmNtZTFZaWxnM256Sk9PN3FFREdHa1hjLW8yUlVBMFdRWm1yY0xwVV90WnBVZXFRNDlkbG5WZXU2ZXNfOS1NcFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJialFkR0l2aDBIcVdnNE1mV05yYjREY0x3UmxtTHg1LUFsNUlFWFVXU2xnTC11TWo2amVPeXNrc3kyYjZEOWV3TXdGYXV2MUVtRGRrWk5jU3R1RW9lZVE9PQ==
"Yet another framework / package / library / tool against the background noise of all the others. 

I’m already overwhelmed with what’s out there.",r/machinelearning,Z0FBQUFBQm0yeGJiTXlPWGRKLVROckVZTXZJMnJ2RWk1MEM1Y0RpdG53T2lvOXNvT3lfdXJRSmVXUkxxaHI5Y0VzdDF5bTVzSmlLZUp0N1R3bUxqc1BOcHZ3T0twcU0xaGUwS1BPcmVSX0paZ085TWlWdDhUaWc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJiSVdxQ0hYeUdmQzRlalI1NVowMUFVekJrZm9xQkpxZVAwWGh5blBIbzhzQkVxMjNJRXFHRFhMREFuVU94WXFCUU1SQXZkN3oxbWx5OTZ5dDdCMjJDTWc9PQ==
"About the only thing missing from your list is the ""Vast array of enemy hardware"" as I only had a limited number of targets that I cared to head toward. 

Prioritizing is inherent in the solution. 

It was very much autonomous as the environment was not conducive to communications of any sort.

To add the ""vast array"" would be a simple addition of more memory. The hardware I used could upgrade memory somewhat, but to go to a $40 processor would make this very easy to where ""vast array"" could include things like damaged, undamaged versions. A $100 processor and the features could be endless.

While developed on a beast of a machine, it didn't require one for operations. My fun goal with much of my ML is to put it on as crappy a processor as I can for sport.

This isn't only what I do for robotics ML, but the server ML. If I can keep the server load down to a minimum then the servers can be cheap nothing servers doing lots of cool ML. When you start using GPUs on the cloud or servers with lots of cores, the prices start to become noteworthy.",r/machinelearning,Z0FBQUFBQm0yeGJiV1dvdlV3M0loQWJsdUQ1V2FyTUg4eXJodFVGSmI0Um5MU0FaLUotc2tVOFhySUE5SjZjYnRDXzU4SmNSTWtqZ1p2c3EwcVI1MFZsSDdVZ0lsTWxJSXc9PQ==
"It is striking to me that marketing and AI safety are clashing so heavily at the moment, with marketing winning, such that the goal of trying to make sure that users understand the limitations of the tools they are using and treat them with the appropriate suspicion has been abandoned.

Don't call it an overview, call it an interpretation, call it a *guess*, call it an AI skim-read. Wherever possible, the framing of LLM-generated content should emphasise the contingent relationship between that output and the expected reference, so as to allow users to distinguish it from actual snippets of text, human-checked overviews of a topic grabbed from wikipedia etc.",r/machinelearning,Z0FBQUFBQm0yeGJiX2xZWWFFWUwwNTRqOE9QQnhDRFhYUzZ6cmdvbkNVVTg1VHVfc2M0SVNJc0dZQjlWWjA4YktqdGM2MlJOWHp3Y2tiYVNnOXhReHZfMzBNcjhTSlN5aHVtenEwT19hMFMxVGhXRmtZYUlOcE09
There are some finetuning methods for RAGs like RAFT. I bet it’s something like that.,r/machinelearning,Z0FBQUFBQm0yeGJiVVM3UjJrMlJNU09kSjV0c2hINWdqQU1iSjlVbzA1bmR2OGlLZHBjbzlHRVdNZENKVEdjVFl6R1FxNVhvNlY2QzZMMF9xNEtXVjRHcE9qNDRMdWhmYkE9PQ==
"In the theory *neural reuse*, it is hypothesized that evolution has shaped various regions of the brain, specialized for specific tasks. And when learning new tasks, these regions compete to handle it. Specific regions are more adept at certain tasks, which is why people tend to use the same parts of their brains for the same tasks.

However, there is still actual learning happening. Either within the region, or regions learning to communicate with one another.",r/machinelearning,Z0FBQUFBQm0yeGJiTWxEdnFIWk9YUDZaZFNqNHlDa2NoNzAtLXFnUFlnUHN6ZTdvVkExTVM0QlBxLTRET1B6OTlGYTVQcDJqVDA4OXRJbi1iZkFZa2lWa2NlWUU3c0UzT2c9PQ==
any ideas? 🥲,r/machinelearning,Z0FBQUFBQm0yeGJiRkZneU9MMDJaNHlYZUUzdVpMSzlUZXZHNG9tcmJjazdmVFJydUFPMGlVczdqMlVESnhSVHVQekFiQzQ4cU50YmFWTnZVQnFnRWVvWU9jZUR5VlI3cWc9PQ==
Is he the quora guy?,r/machinelearning,Z0FBQUFBQm0yeGJiMnV6VVFJS0dpbGpvaUNLdmJQTExWbDlVSk5IaXVINFNqZFV3c1d6MHR2Z19iVUlvUEhyRXNXOXJnbm5IV3pSR29UUEtMWDIwZ0diV29ib0hialBRaUE9PQ==
This happens to me. I uploaded my paper that appears in a conference and the conference is okay with posting the paper on arxiv. Its on hold for almost 2 months now. Very frustrated and have no clue what is going on. I hope the process can be more transparent -- but the organizers seems feeling good about themselves. It hurts us as researchers. Weird!,r/machinelearning,Z0FBQUFBQm0yeGJic2tldGVhZkwxQWdQZ0RpRHhTR0Q2WFJMRmlGSVd2Z183VWVwcnhPWVhXQ2FfaE5NODlDbXBmbGFxdlkyNnAzS3h1LUxGT3BjWWVoRGVhX2lNMnVsU3IyQzhBbEVFOWNBSXJHdFlQcHVxcFU9
"1. Terrible name. Nobody will be able to search for this. People underappreciate how important this is. It's a major reason why I use sktime instead of darts, Airflow instead of Prefect or Mage, and many others.

2. Why on Earth would I use anything TF-based in 2024? ""The layer modules allow you to build neural networks in the style of PyTorch"" - so why not PyTorch? Even Google is slowly killing TF in favor of Jax (see all their new research projects, for example).

3. No pip-installable package is absurd. This takes one afternoon to set up along with CI/CD, I've done that myself.

4. Why write \\*everything\\* in README in bold? In general, your README is illegible.

5. Plainly speaking, nobody needs this. We have PyTorch, PyTorch Lightning, entire HuggingFace interface, Accelerate...",r/machinelearning,Z0FBQUFBQm0yeGJiUGF4SmQ5ZDhjWGhaU2ItLTE2VndGNWFVNlZlQmxHSkQwY0dFY3I3RGdlWVZnbHB2bXdodnAtamdjMWVXODJGYndPamxkVmotN1pTNldTa3NjbEwxeGc9PQ==
The only YOLOv10 you need: [https://github.com/FrancescoSaverioZuppichini/yolov10](https://github.com/FrancescoSaverioZuppichini/yolov10),r/machinelearning,Z0FBQUFBQm0yeGJiSVliY3BLMWVwOFpVOUNxeHVJOV9TNVV5bjQ0NEUxaG9JZHNWcVdFOTZZQy02Q1JwOVBVTmFzYVBUX3pJbWNDWUtIZjRDN1RkaUJ0SG1FM2ctZHl6Qnc9PQ==
"As I've looked at the problem, the diversity of lighting conditions, target orientations, seasons, approach angles, haze or fog, condensation and dirt on the viewfinder, camo etc. makes it definitely a non-trivial problem in computer vision. So any pointer to the general class of algorithm that can work in these scenarios (and be very hardware efficient) would be great - if you are allowed to talk about it.",r/machinelearning,Z0FBQUFBQm0yeGJicldBTzNMWEJ6UzdqaDdmNWtDdWZSN29DeWZJcUQ1dWlKczJhX2RhUk5PZVlLeG8xc1BvaWM3Tm0wRWhOaDVIZk04TEpleWFfbzlkSGFWaDFIMUxMOUE9PQ==
You can tune a piano but you can’t tune a tuna,r/machinelearning,Z0FBQUFBQm0yeGJiN3FNaWJjZWF0cGVRWThPVk5sYzZMbDBrdXlZd1lYUEJxTndnOUlLYUdPN3lfNW9TRjAzWExIVTRpazF2bkhlYTFtYTI2R00xWjhLWlVxTkozMFRIV3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjcUpfQjZmVTBYSS1OS0xaeUhkam4tREdPM01Ua214VE1UQkd0a2Uya0FPNEo3cndxd0RWdGNRZHFscXhhVjVoVlVoRVc0RTlCbm05cnhCcGRZR051R0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjQ3A1eHlEbFc4UkJFRF85bThtWFNQQjZMcVZxYkdfQWVMNjV1LWFCbUt4TndkZDJ3V05mYTQ5WUEwXzZDd1hlXy1kWjdKeG5PRktncGlZeTE1V1ZPd0E9PQ==
"as I said, the model IS the training set: once you choose a specific set of examples, that is the exact moment you ""freeze"" in time both the training set AND the model itself. Of course for testing and deploy purpose the model must be queried with new data, that is your inference.",r/machinelearning,Z0FBQUFBQm0yeGJjMURMem4ydXRiZkliQlJSUmxIRndoLTlfMm5wa2stQ3JGckdVaEpnYVBlT0J3dFp0Z2gwLVRZTkRqNWZzVHZyZ1BnYzBYZGtXcVMtdHNlZTlqdUZ4OENWN01PdVNkNkRaUXpGdGdPTndKM1k9
I think the issue here is that the reward function acts on full model completions rather than individual token outputs. So there's not really a way to use the formula during inference without sampling all possible model completions and then re-scaling them so their sum is 1.,r/machinelearning,Z0FBQUFBQm0yeGJjdHdjV0NKTGpGVDN6X05GMTI5ZlFQTmhQdlN4YXVwTE1EdGRLRXZ5LWdmX2hLQU9VRTNaXzFoV1kweFhkaUQtX3Zkd1pqcm85Z20xSnRCY0IzVGt1T2c9PQ==
hierarchical clustering with a custom split function condition?,r/machinelearning,Z0FBQUFBQm0yeGJjdVRKNUtUcEFlOXVKS05HbWg4d1BMRGxXYXNRZGV6cU5Cblk0czhoaWtOZFNQRXZfMFRQMGk5TzdkWkx6bEZTR084U2xHT0FjdmJRNHR0N1pPck8zQkE9PQ==
"This is not a research conference. It looks more like a publicity stunt/place where people go to network, and that's it. Do not go if you want to discuss actual research.",r/machinelearning,Z0FBQUFBQm0yeGJjeHp2cUUySi0yUjBBdUQxWGVRdjd2MURwZU90bUNabTJELXFLZFQtY3U2bUtyaDBneVVmUElkc1lSRVAtRnpqd0R5enpkcGxHb29nYjZ1NmI3WlpRVEE9PQ==
I’d probably start in the neighborhood of something like Monte Carlo tree search.,r/machinelearning,Z0FBQUFBQm0yeGJjVGxWWjRYeEp5OUh2MkNKYWxQQkJVUEhBNlFNUVlsVUNhaU1tVUJSWXJ2RjlneERtWG5Rd3dBeFhWLUNySlVVZ3RXSmFVNVlQRjhpMEMzOFdjYTB1NDVpbjZqZEtMVlZ0TFBjaVhXdDMzbW89
You 100% need to do this through reinforcement learning,r/machinelearning,Z0FBQUFBQm0yeGJjaXFaaFpuYnl1NC1IMldHX2paUU1oSWZ4YWdOWk1rM3dMQjN6MTljREtFN3JsLUN4cE42ejNxd3FsMkRwd3pqZm5LWmpPRnQ5dzBfSE9Wb3RlcXZTTmc9PQ==
"I'd guess NYC or London data would be most predictive, given their financial hubs. Curious to know how you're handling seasonality and outliers in your trend analysis. Also, kudos on making it work on a 5-year-old laptop!",r/machinelearning,Z0FBQUFBQm0yeGJjU0ZRdjZYTVcwdXp3R0NKUTllZlBwaWYyM0lmTDJHQ3Yzc0FZNFhEZ1hZZ2lRcUFpa09MUlpacnZab3FMY29fNFRIRE5vVkotLS02LVM3VDFEUnpVWkc2RmJ1TWJIcVh2R254LTZoNGRaVEU9
oh yeah you did say that my mistake. Data leakage is just as possible as any other model though since we still have distinct train/test sets,r/machinelearning,Z0FBQUFBQm0yeGJjTUxsWk84TGEyMHZOYjd0V3ZNX2U5ZTBuZUQ5TW93QmxXU2hxd2pzSW81MjdablZoa2oyckd0cGZSWXRRcjBob1RNSmZyaGo3ajltY0Q1eW85aHNsQVE9PQ==
Ground truth is the relevance judgment of human annotators or the gold labels.,r/machinelearning,Z0FBQUFBQm0yeGJjR3NrOExxZzdvY3RVeEx6d3ByV1dfcUdlUy1rcFRVdml0bElnMTZISHdXOFRxZC1LdTIzdVMxcWhkYzV3TzRBYWxZeDFVaU1hZjE1MWhhZTV5QUZPNUE9PQ==
"Good luck! TASLP's a great target, but be prepared for a rigorous review process.",r/machinelearning,Z0FBQUFBQm0yeGJjRlRJS0JqR1Qyd2haalhmVENRRVhpQlNHSmN5TEFtYW15dVo3S1dnVUtKU3Q2R0hmMjA4YWVFNFgzZkdPcFI0N1MtbUhOOGpsakVQa3F5d19jbVYzemc9PQ==
"To 2.: tensorflow is (as far as I know) still a better choice if you want to deploy at low power edge devices using quantization and tflite. I don't think that the Pytorch ecosystem has already an equivalent solution here.

I agree with the rest",r/machinelearning,Z0FBQUFBQm0yeGJjSU4zU2pNaGVmOVgzbEp3VnlabFZ2al85X3VvMVZLN0oxR1poMlhHYnE5UUc5VHN4Wm1TVEtUQ2ZiS3RsTC1NSzBUU2VQU2hxSjVZV2pyN19QRW43Zmc9PQ==
Can I tune a bass?,r/machinelearning,Z0FBQUFBQm0yeGJjSm9lc3Vmdk9HeGFCUWhmMXVkRkdPRlNBMjFtcTlMeWJBc2JianJiMDhvQ1hKbmtYYzlxTDVnY251aDFpbk1MdW9qQkZQcDJWbnpGUWw2MFZhN0dyaWU4a1h6OU9Ta3g0LUR2cDNRS05rQ3M9
Curious to know how they balance short-term goals with long-term research aspirations!,r/machinelearning,Z0FBQUFBQm0yeGJjX19NUkZpWkczTmZzRExLQk9XbnZaOVpVMzhwdFZ3VTNHdm1WTDFNUVdSdlY1YV9zX2MwbmNRdmFFS21JYmRWamRKa196MWNKM2F1Q1VrbFBybmh6TXc9PQ==
"Hehe. There are Nash Equilibrium solvers for poker out there, even for multi-way hands. It's highly optimized commercial software, so it's very unlikely that you can put something together that comes close to it in terms of speed.  That's a very good starting point against unknown opponents, but then you also don't exploit opponent weaknesses that way.

Some form of reinforcement learning makes sense in theory, but unless you have a history of hundreds of poker hands played by a specific opponent, there's not enough data in there to conclude much. Meanwhile, a human pro can very quickly adjust to erratic behavior.. which in turn triggers readjustment, a sort of ""I know you know that I know .."", the optimal strategy becoming something fluid, determined by the most recent history of the past few hands rather than the hundreds of prior samples. Example: player A looses a big pot due to bad luck. Goes berserk and aggressive the next few hands. Any human can tell you ""he's pissed"", but a statistical model built upon the past ~100 hands of player A fails to capture that.

TLDR: research wise, poker is solved by playing NE. Plenty of high-profile demos proved it beats the pros. As for making easy money online, nah, no serious money to be made there anymore. The game isn't what it used to be ~2008.",r/machinelearning,Z0FBQUFBQm0yeGJjTVVSYlA4WEVQMFBocWp1SkdQczVHLUxjWTdTN2gtM01lRE5Kc2ZheGtBTTlveWlGa3h6NG1DdTcyMFVQRVpNWHpfZElsQ2R3Z1A1N3VZcFRLd1pubEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjNXNYSU04YTNVN1R0RkxQMjdJaWJXcHI5aFhfeElwYlQtU2JXV3l5UTZuNWlLYXY1ejVkRV9QUE1JTVg1NkxQZ0dzTld4ektjRl9GcldMMFIwbkFvbXc9PQ==
"Have you checked out Noam Brown’s work? 

https://arxiv.org/pdf/1805.08195
https://www.science.org/cms/asset/910714a7-ee2a-486e-9970-42fb893b08d9/pap.pdf",r/machinelearning,Z0FBQUFBQm0yeGJjMlNmWlpSRjdOU2ZpcmM5UWlEeVlYb2JMamtrTWRzX1lYcjBqajF6QXZPNDA3QzZEV1EwZDc1bXlxTFhDMW5mZnhrVVZiNmRQUTBDN0szcVZoWlJRZUE9PQ==
"Oh, no problem, I was just joking! But I really don't think the authors are that naive to not know the prevalent practices in the industry.",r/machinelearning,Z0FBQUFBQm0yeGJjU19wcGRXMzlNbTAxdWY4ZzVCOXlxMV9BbXMtNkMwbU5vbnpubkpXd1owVHdZc3JFY0lmU1hGM0paa0ZvOFNIRU9LNVJ6VnJfbG42Vll3OWxjTEsxNEhNYUQxQmR1U0ozNlVNV2dIbXdvWW89
"If you specifically want a ""human like"" agent, reinforcement learning is probably your best bet.


It likely won't be truly optimal play, as other comments have pointed out that the game is well studied from a formal basis (example: https://blogs.cornell.edu/info2040/2019/10/22/nash-equilibrium-in-poker/)",r/machinelearning,Z0FBQUFBQm0yeGJjd0hJU2dHeEliMlJxOXQ0RG0zNVE3Uy12ZF92R0FhV0RXeDZuLW1uWkRNZU1lM0J0dnBLMVhBT0RUNDlaaWdlazlNb244Y01ob1V1R3B2Y3UzenQxNUVpVGsza2d1bjM3QjEyUk1MYXExRUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjcGNTME53bnh4WDNpWjF1ME9YUFlsV0d3bWM5NTJMRGhuUk1WYzNxeV9FdUpTMDlyMG15bnpvUnhkR2xvLU51VF9LVkRhb19FaElNcWhYVGR0MDNjd0E9PQ==
Find a massive of dataset of human games and train an LLM on it. Most human like performance with the least effort needed. Might have problems finding a big enough dataset or with compute budget.,r/machinelearning,Z0FBQUFBQm0yeGJjTFkyQVpzZjNYOTFzLUZ6Nm9Ra3N1ME9EV2Exc21BM0FBa2hwXzM4aXBQQTllM25QN29QLUw1RDhaZG03ZEtlZmR1OGZwbzZTbHE3ekFpZWVkdVBSbEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjWFFTVENZanJodmpRU1lCaUozZzV6akFYWWNaTzJ4cE04VXdVWVpVaDdoR0pQb3FZU1lYZmFEUjZjbmZRX2JrRE9ZVmpyUEhMTjhETkhRTmI4U1lRaVE9PQ==
"When addressing complex computer vision challenges such as varying lighting conditions, target orientations, seasonal changes, approach angles, haze, condensation, dirt on viewfinders, and camouflage, extensive simulation is essential. I utilize Unreal Engine for its capability to generate video that matches the camera lens, field of view, resolution, and more, enabling highly realistic simulations under diverse conditions like daylight, moonlight, different geographic locations, and fog.

Unlike platforms like Gazebo, Unreal Engine can create scenes almost indistinguishable from reality, provided meticulous care is taken to prevent the machine learning models from focusing on any unique, non-representative features. For instance, if a target has a few distinct colored pixels not found elsewhere, object recognition can become unrealistically perfect. There are techniques to avoid this problem.

There is no single solution; it requires a combination of approaches. Initially, I adopted the ROS2 framework but eventually abandoned it, replacing each module with custom implementations, including IMU simulators. This has minimized the gap between simulation and reality, allowing the robot's control systems to operate seamlessly on both desktop and microcontroller (MCU) environments.

The key to success lies in the workflow. A poor workflow hinders progress, while a good one makes development enjoyable. Interestingly, the choice of technology becomes secondary. I could switch MCUs without significant issues, provided the new one meets my fundamental requirements. The limitations are more about the ease of working with the camera rather than its technical specifications. Image quality, frame rate, and usability are crucial, often more so than resolution.

As the owner of my company, I have the liberty to discuss these strategies freely.",r/machinelearning,Z0FBQUFBQm0yeGJjV1VXTjZPb19NZVhDc3BaY0xsUE95TmtteF9GaDhGS19kVVdqZHl4YzhKWG0zTGhXWVVod3dYaWlGWGJiQWNfTG10QzZsUHlFQmljNTRVd2N2cUFCbHc9PQ==
"Yeah I wrote that wrong. I wanted to say there is no end to end calculation of the gradient, but probably local updates like in predictive coding.",r/machinelearning,Z0FBQUFBQm0yeGJjaldJVEZkTHpfT2lhQk14ZjFjZkN4Z1ZsbVNna1M3MkZkbGlSeW9LNUp2aTNIbUJLY0J1WmFqdHl0LXlWeXJMS3p0NjRpZFI2aEM0VFJOT09ta1ZhTnc9PQ==
PyG all the way,r/machinelearning,Z0FBQUFBQm0yeGJjdEJIdEtjby1XQ2Q4VnJ1UXdjTmJfS2hJWWlZQS1IWHFia0g4OWpmR0dyM0VkeF9tYjRGaWxFbW5ZaGtWaTFsZjNCYS1HU0h5R051MVJZQUp5eTdscXc9PQ==
man what do LLMs have to do with playing at poker at all? Do you even know what are you talking about? come on,r/machinelearning,Z0FBQUFBQm0yeGJjYkFMTFNCSDZfYXhUUjVRREVaU0JXQ2hCbFpoZUMzNUtxcWdmYWtReUc3MDFuUkdETTFaS2xjSWVTWDB0V3FrNXNEZjF5MHNVek5YdWVwQzBYUXpjU1dZUDFIem43ZHlPWmFNTXF6UzFNYUk9
"You train a transformer on poker games. You use an LLM like architecture. Just because there's LLM hype doesn't mean you can't use them for tasks like these. Everybody is talking about RL, but that's not the what the question was. Human-like poker, not great poker. 

How do you get to human like poker playing without having a big dataset of human behavior? Once you have that huge amount of data, what do you feed that into? Literally the only models trained to multi-billion/trillion parameter scales are LLMs. 

LLMs are especially good too because you can use pretrained models for this and train something which could annotate or explain poker games. Power or multimodal learning.",r/machinelearning,Z0FBQUFBQm0yeGJjaUFiTHhXa0pvN1ZiNThkRG1pTGJBN1NvRjFvX29CeERaSVBybmxCWmdMZC1MWWpvSktmbmQ4cjMwSjRtakVZNkM5NkNDc1hRQXNJQXVTRFpnNUVBWHc9PQ==
"stop yapping, you are revealing your own ignorance with this answer.",r/machinelearning,Z0FBQUFBQm0yeGJjNnFFbkJJYjRSc1ZXMWZuWkpnZko3Ukg3dFhadGlfT0NHVjNSMFJ3MHpjcEc1ZkZUN2x3NFppSmJlRjRaOU9EQ1h0aVNSQjVHamt0TmxjQ0RMR2cyNklfWURFaHRZWWhnZHVmRG1NRUduTTg9
"All you've done is insult me with zero counterarguments. People suggesting ""RL"" to a question of human-like gameplay, where you'll never get anything human-like not being questioned at all. Transformers definitely can work for this problem. Contribute something to the discussion, otherwise I'm done responding.",r/machinelearning,Z0FBQUFBQm0yeGJjUENvQ2FjSUUtWTEzcjVHR3JYbmVZVk9rdHZyRTNlU1dKMWxEc0lqSDhJN1d1Q2hYS1ZrTUVrd2toUXlabnJtWFV5N1MxNnY1VjBuS0dFbVdMSW16NWc9PQ==
thank god you're done,r/machinelearning,Z0FBQUFBQm0yeGJjaWNXX0pnUkpTaXN3WWMwbXB2VnlDMDFrWE1vVE1VSkF1LVhralkwZFR2c0Z2NWMwcXZqTjJ1QzJ0U1NKUUFfd3JUaHVmWEctalY0RHd5RmstQUR4X2dFSmc4aXFjbVg1em5FamhlSXZwSzQ9
"That is pretty cool, it seems like they just change the color of the emojis to match that of the image.",r/machinelearning,Z0FBQUFBQm0yeGJjT01DVkRWNU5IYXRka093dmFkUVFBSEhYczU3YlR3ZjIwdXduaXBrTHdGMk5RZWl0M2RMQjRYc0J5eWU4UXpQVTZEcHRHTU1WVk1OUnhTLU1Ed0pLZFE9PQ==
"Definitely agree. Emoji colors tend to be very vibrant, so it usually creates a very vibrant recreation. It's especially clear in the Mona Lisa recreation, where the slightly purple parts of her dress are recreated by the algorithm using very vibrant purple hues. I want to try out training with some other general ""shapes"" that aren't as vibrant.",r/machinelearning,Z0FBQUFBQm0yeGJjQ25FZ091bmUtWG5KZU9XWXk2NnpXWklRcDVFdllpc2I0VERJODl3aENIZkY5ajlPdVhlejhEVHRCZDB3eVN4Um9fMzctY19fd0I0endEU2lVQ2dwWEE9PQ==
">You train a transformer on poker games. You use an LLM like architecture.

I'm a bit confused what you mean by an LLM like architecture. Are you referring to a transformer decoder architecture?",r/machinelearning,Z0FBQUFBQm0yeGJjNmowMXMzUEp2X2FqUUtMQ09JdGViVzBQNlI2cmFEU2xnY1NpSk9aZlVOZnJaY3hFNGw1LWF2bDA4LV9FWmdJQS0ybFY3M19iYUVCa21hS1k1bXNOZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjdHJSal9fMGNzc1JGdVJoTEZVVFJUNE9zSWhNYTZsNmRsQW13R1RSallQSXprS2I5TmVYcGoxQnh4MXpULUtWc29Sa3JtUkpFcUc5Y2txLTV3UzZ1Y3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjR2M2TG5wcFJOZkkxUFZJTTBSdk5WZTlyZnpFZkZWZjBESHUwbVlaLWR0VWVJeF9tV0xaRFdwYTF6YnJQZVk3ZEJRandYSU5sSjA5dHQwQXM0NGlyb0E9PQ==
"Your input is usually a vector of real numbers. My intuition is that multiplying by the weight matrix is a feature extraction step, then the nonlinearity decides which features are actually important to keep for the next layer.",r/machinelearning,Z0FBQUFBQm0yeGJjOGJSdVkteXo3Y3dqbE84aTEyUEpBRFg4Y2VCcmk2U0FacUVnUExUanVteDhxeDBCNVp1QkFLUm9oUWUzVWwwM3BSVXVHSGM3WlNPamtFRHloMkYzemc9PQ==
Classic is pytorch geometric,r/machinelearning,Z0FBQUFBQm0yeGJjMWdsZ3Z5M0wtSEJXNS1TZXNiWFlEZUxHM0VnTlNUNzBmeG1zTVJ4ci14NFNvY3pIY0pEa003ZUgxUTlyQ2VtdGRIOWtETE1XZFV2Vk5nZVM0TGpNcHc9PQ==
"Im pretty sure you are just throwing jargons all around.

Multimodal learning? Do you even know what is multimodal learning? Nothing in a poker game simulation is multimodal learning.

I also dont think you know what LLMs like GPTs are. You seem to be confusing it using Transformers so it can ""do anything"". Autoregressive models cant reason. It predicts the next token based on the input and preceding tokens, whats the most likely outcome based on regression. That's far from RL reasoning which takes the environment and states and tries to give an answer that maximizes future and potential rewards.",r/machinelearning,Z0FBQUFBQm0yeGJjZTV0M1pTV09MNDkzRTdBUHhkbVk0VjZheF9fcVpEQjVMRVFJYk4yZUg2YUU5WVZYZmZ4eFFjVk83Q2lPU1ZDZHF3eEpRbmZVdTEyQlVmM2gza0JUamc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJjNUM3eXJiaVRDNTRDVW9GRVgtQTJKaVJHa2MzRGlpaExqQjVqelhCNk1jVG1SOUtMMmdSNzRGb0tXRW1xVlpaaWR5MVhqWktidjdOTEFzTm9aTk1MWDdESm13ampTNDAxSV81c0RKUkNPRlE9
It will be done with reinforcement learning find a poker environment and research what reward function can be implemented I don't know poker so I can't help you,r/machinelearning,Z0FBQUFBQm0yeGJjREFDWXdfVVhYWTRTbHRaVllseEZya2hiU3VMN0R6dXdudXU1aWpCTmJiY0xINWZTWnUxa1FGY1NwRjdCWC1CR0xaNnQ5eHcweUh5SjNNbVFlZVltMUNnd0R3Tml6VlZSdjNaVU9IUkhHOEU9
"hey! could you please explain this in a bit more mathematical detail?

I understand that a small weight value applied to an input will make it contribute less to the activation, but this could also be seen as transforming the space very little along the dimension of that feature.",r/machinelearning,Z0FBQUFBQm0yeGJjQk9VSXFSYkRGX29PbXhrb1ItWk9acmgwbElCQzBCaTlJZFFfNmlFUjBRU3RfaXEtVTJPb1l6VlZLTDlUY1VIbEJwWFF5anFiRndMYmk5Q2NjWEdCUGhlVW9INjZpTlBzNGRqemNCY0Z1eUU9
"Using diffusion models for segmentation isn't new.

E.g. [MedSegDiff](https://arxiv.org/abs/2211.00611)",r/machinelearning,Z0FBQUFBQm0yeGJjbGFBZmcxV3NHN1dDTVh2UnZhcmJLTnJxMmdQVGhMaGZnOHd4SWdiSWp4N0FDaVFkaW9uYTB4ZWNicmNXQlZNM1RxOXliaVh3eG1DX1RHdU9rYmJxa3F4YWJKY0R2aEFVT2JVQmpKRjV6dkU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjNjB4djd4aExFMFdrV1luWkRlclFObzBrT196bFV2TXZabGh2OFhXa0E5M1IxZ2RUdUI2aFotdFRUcHptMFFfbHBiRkdPOEhNNUF3RHFOcldJMlJ4bmc9PQ==
"My big question with the 'e-prop' as you call it is really just how you could have reinforcement for anything more than millisecond or maybe second-level timeframes. Presumably these eligibility traces of historically activated neurons don't last very long, so their responsiveness to reward signals can't be very time-distant right? So how does anything an animal or human learns that has greater than 1 second of planning/preparation/multi-step engagement get trained via this method?",r/machinelearning,Z0FBQUFBQm0yeGJjRDVzbWhoRnB1U1cyZXotTFRfeGtOTE91djg4QjVBUzh0WUg2cHJFRVRPYi1IeHgtLVpSWGRZeWlQZFVRZkZOSmtweGdPVHdKZ0xQNmhYWkxRdE1nM3c9PQ==
"Rich Sutton's RL group in Alberta, Canada made some major in-roads in heads up limit hold em a while ago. They may have investigated beyond heads-up, but regardless, this should give you an idea of an approach that has been successful in practice: [http://poker.srv.ualberta.ca/](http://poker.srv.ualberta.ca/)",r/machinelearning,Z0FBQUFBQm0yeGJjbHdKTkF0MzJfbUpIbkVKcG8zLUhuTFVNUjlEZm83MF95dmt0cEtsR3A0VW5Oa0NJSTFvalZXMS1Dem9qMHFsSUJ4VExLMzlreEw0aW5VcmdWdVlGS1NVRTZtamlkdHpjdnRxaXBRVjQzUnM9
Counterfactuals regret minimization is what's used for poker usually I think. I don't think it's exactly human like though if that's important,r/machinelearning,Z0FBQUFBQm0yeGJjVDFPMUg2T09sb05lMXNCU2lldk5lRGlfbG5uTTBqeGt6QUhrZFpyM0Z0TGlmVm9kMEdvaFZDWWtXODktZjhtQW85b015ZlZUd3RmSWJJdzBvZ3NWZHc9PQ==
RTMDet benchmarks looked so different than this...,r/machinelearning,Z0FBQUFBQm0yeGJjTGR6WTRybHEzRzRMTzdyVlBGSkxHVHIxb1BLWUVnMkNOYU1DNHhNbU5pNGoxekswSzlCb1pNT0h3eVZjRXFCeUctcXJpUGIxb3VIZ1NLVWNnejAxTWc9PQ==
After getting strategies using CFR you can then train a neural network to output a strategy given a game state,r/machinelearning,Z0FBQUFBQm0yeGJjbU56SU15dW5PWFhKZVVjc2hFMUV5WERyaW13ektQem1paGdHcE05Qi1zTjhqbXZtQ092cnFLS1ViMUl1SEd0NW9qMHd4cDI1QVhYZnBZTmlNNTgxbmc9PQ==
"The basic linear layer is Wx+b and you can follow that with a RELU. So essentially you project x into W space, translate by the bias, then keep only the dimensions with sufficient weight to be carried forward.",r/machinelearning,Z0FBQUFBQm0yeGJjc3g3ekl6MThEVE5pdGtCLVcwN1NPNEdwZTllWUxmMG82UUVmelg1M2RaZEFOMVM2WElKZ19xRDV4eFdwYUdvemN5THpkVFhva18wVk9oSVpiWV9vSWc9PQ==
"Yes it was coded in Python, however you don't need to know the language to install this file. 

  
Click on the repo link and look to the right side of your screen. Under the 'Releases' tab, download the latest version of the file; although it looks like the dev abandoned the project.",r/machinelearning,Z0FBQUFBQm0yeGJjS2pyS1BIelhFdzRsWGhYQmJXcjFOY3hCSUo1S0tOT0dwY3lJSHJUVGM2VHU2emFsZGJHS254RHdKSlVxQ0ZqeEJoenJlSWtaMlMtZU9qMWxCVk92U3c9PQ==
"My personal recommendation is David Silver's course on RL, [https://www.davidsilver.uk/teaching/](https://www.davidsilver.uk/teaching/)   .  The entire youtube series is on Youtube (DeepMind) channel.",r/machinelearning,Z0FBQUFBQm0yeGJjdGdDSG5iS2RyWnl4SVN1VlRnSk9hR2diTGV5a2FoTVFaU1hKWkcyaVRRb0ozdWx6aGpUdTl4OFFoTnJFeGRtdENiZzJMelFCYUlkNHhkdE5scWs0eWo4WjhqUGhYMnRkakFfak15eUhUSzA9
This was a good read! Thanks!!,r/machinelearning,Z0FBQUFBQm0yeGJjZEFOTFVpbHc5MUN4OWxKX0QxdkNNbDVxd2xjWEJyTWp2Z2pCSDJ0dWxlanpaZXVYWVByQ25IclBJSzNrbm05RWE0UzYxb2VwQXdVc2VsRDFaQm16V1Vwb2oxeXlndGgwMjBDa1RTTzlLZmc9
Two minute papers covered a paper on this a few years ago.,r/machinelearning,Z0FBQUFBQm0yeGJjZzBSZURIbHZBSVlZZkh4cmVFTWV0VkJPdEVJUW9TcHN4VGRleWM5QmFEQzg0TEZvbnlNYmhlR2o0Zy1XZ2FRdWhKa2FNU0kxT2lRMGM5aU9PSzVNakE9PQ==
"Do Perplexity and OpenAI have an advantage of not being public? I imagine they are running at a huge loss but can use better larger models. Is anyone using Llama 3 in meta’s apps for anything remotely useful? For Google to get a useful results, the costs would be enormous for a capable model at google scale.",r/machinelearning,Z0FBQUFBQm0yeGJjN3BYdlJVS0hrVDk0OFE4em1GUG9qZUV6T1pVeUlrVEFHNG1uQmxTZVdmbDFWWG04a1hiaFlHV21YSGRtdExBWDNsYURsaHpXcEdnMWktdGVod1hjVnc9PQ==
"A little late, but there is also BaysOpt PBT,check out PB2 under ray tune, and there a many more expansions one can make to PBT.",r/machinelearning,Z0FBQUFBQm0yeGJjdExaYnBJNFpyYTkyS2Y5UmpvR2RFWE1BRlBVRy1aWmpWX0pvencyTXl0ci10c3RZUV9YQXk2aGotLURCTXo0UXpOTUFWa1M1ZGxRZGxSOUEwcnhWcWc9PQ==
"I have one posted in r/learnmachinelearning since I am a newbie. While no any hint or response after 4 days, so I am wondering if someone here can helps.  
Please refer to my original post as below.

[https://www.reddit.com/r/learnmachinelearning/comments/1cxui7v/questions\\_about\\_tf\\_tensorflow\\_to\\_tflite\\_with\\_int8/](https://www.reddit.com/r/learnmachinelearning/comments/1cxui7v/questions_about_tf_tensorflow_to_tflite_with_int8/)

Please feel free to share any hints, or direction to find answer, surely if there's detail explain or guidance for me to understand exactly would be even better.

Will be looking forward any feedback, thanks. :)",r/machinelearning,Z0FBQUFBQm0yeGJjQU11WjdVQnpRZmtfMXRmcWVDTklMVVBaQ2V0WUZINHR4WjJPTG40azVYRXYxenYzX0dWaUhSN3BjR09jVV82aEVWbHRsRFo1M1hvY3o1NUJQMHNTUkE9PQ==
Can you make a short list of real-world applications for the Autoencoders described in the paper?,r/machinelearning,Z0FBQUFBQm0yeGJjQlFuc212aEdxNWx5S18yaVFhYUs2c29SZjB0S0J4QW1KRlNOaF9UNzNtSzRmR1NNb21ITmM4UWx1ZFNydzI3TG1uNGNNZGJuSFAtMXBGd3VEX2pIQWc9PQ==
"I wonder if you could find out how red dead redemption did their poker. It was great, you could really pick up on players having different play styles and betting patterns.",r/machinelearning,Z0FBQUFBQm0yeGJjQTlrSGlGVDJGb3FzWG8zeEpTcThTUjFhb3VvT0ttUUd2VS1KZE9KRTNrNDNfdmlRQ09wd1dJUWxQY0tQcm9kd1BKOTQ3X21GaHk2SjJGT0JTR2FaWUdwM3RidE5PNm5qdF9PXzJXRkx1ZVE9
What makes you think that OS search doesn't use the internet? Press the Win key on Windows Cmd+space on macos and start typing a query. With default settings both will always consider web search results and rank online results together with local results.,r/machinelearning,Z0FBQUFBQm0yeGJjaHdiSTNGb2ZuS3Q4aHRzSldOcmV3WmJ0WnM5S2Nfb25VNmpFSlNRZUhMVkR0NG5nVmlTSU1HMUZoUlU3V2NqMlpDb0l5WjJlQkE3dzJ5T3NpRENLUVE9PQ==
"IDK what's up with YOLO since V3/V4 but all new versions are from different sources and there's no consistency, all have their line on the left which is bold and away from the rest to make a menial gain in performance under very specific conditions look like they blew the competition out of the water.

And most of all, all have a copyleft GPL-V3 grade license and there's no way to use them outside research without committing to a long-term license fee that will effectively cause a lock-in.",r/machinelearning,Z0FBQUFBQm0yeGJjUkVORVphdmIxaHRWbTgyZjVlUkY5OGxOWjFYemtVRlR4TUZrUndSUTRmZEdxTjJWcFNTdGJhRHlocl93Q0trYmNnWVNUdEdxUWlLUzJIc2tuck05M3c9PQ==
can't wait YOLOv46,r/machinelearning,Z0FBQUFBQm0yeGJjMjVmbTJhMy1keHpnWm16WExIZ1RrcW9pRUVvRVpvNlFFMzFFc3BHRUZBU1M2a0pjeHdFSGVQWFNuekFkN3gtNGRWM1NYS1BYVkhBTTlaNVhHbjY3cHc9PQ==
"The new edition of Linear Algebra Done Right is an Open Access book, meaning that the electronic version is legally free to the world (at https://linear.axler.net/).",r/machinelearning,Z0FBQUFBQm0yeGJjZVFYM2lwRzViRWE4QXk5WjE1Slh1TGU2NHJYM243cXZ2WjVrX0pKX25hRWk5SW12WHZJVHU4Q0VVTGlMcGFiR0lWclZRT0gwaVhISWRBaGRzQU4zdlE9PQ==
"This ""study"" is just a half baked attempt at greenwashing the perception of AI models.

> For the human writing process, we looked at humans’ total annual carbon footprints, and then took a subset of that annual footprint based on how much time they spent writing.

A human writer is not going to _not_ produce their ""hourly carbon footprint"" if their job is replaced by AI, they will still be there *existing* even if the AI model is writing the same amount of pages they would.

It is even worse with the Image comparison they do for a *single* dall-e image for instance when someone trying to replace real art with AI images is not generating *one* image, they are generating hundreds of them they can try to salvage one passable looking one.

Furthermore, they inflate the human CO2 output by also taking into account the emissions from their computers being on while they work on the image but do not do the same thing for all the time spent with a computer on prompting the model.

> We note that just the time spent by the human writing the query and waiting for the query to be handled by the server has a far greater footprint than the AI system itself

While they ""note"" this, it doesn't seem like they are taking the human ""labor"" aspect of prompting into their ""x times as impactful"" comparisons, using only the baseline energy consumption from the training and processing.

> we note that there is significant complexity to writing processes: both human- and AI-produced text will likely need to be revised and rewritten based on the human authors’ sense for how effectively the text expresses the desired content

Handwaving away another labor intensive process in the writing that would probably need to be even more intensive on the AI spewed writing to make sure it hasn't hallucinated half the sentences it wrote is very different from editorial revisions of a written work with authorship and intentionality.

The discussion section is just plain high-school level pros and cons garbage as well.

> the development of AI has the potential to create jobs as well. These jobs could be meaningful and well-compensated replacements for those AI displaces, or they could be demeaning and/or involve low pay. For example, OpenAI, the creators of ChatGPT, outsourced work to a Kenyan company where workers were employed to label specific instances of toxic online content

I would not call mechanical turk data labeling ""meaningful and well-compensated"" jobs.",r/machinelearning,Z0FBQUFBQm0yeGJjN0lESUVMallSUnA0LVZ1dWo3VVlDQWtCbmdRZURWcHlxVkFkdzgwbXBydWpic1JDaFZuWDJQa09BSmVieE4zcExYRjZsRFVnWjhXMzAtSlhaU1FKSGc9PQ==
"I prefer DGL because of its flexibility. PyG is ok, but could be slower in some cases.",r/machinelearning,Z0FBQUFBQm0yeGJjYVZITUhnTDhnZFk0V0JOWnRWNWpyaXN2UnplLTdyM2Vhbm9rVlNKX1hicWZnVXU5NUt0VzduUzJ4V0NqLWxzYS1pVzQySjhsbW1XUnlzVnhsOGhqWmk2Y0RLaHFvVXBuMlRZZFhqdGJZTms9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjUXF4eU1mRk9sejQ1c0kzVkFlU19YQ1dhMVljcy1KSVBQQ3Y3Y2VqTTd3bUVseGNuX1pETGlGeFNQZDRGSW5DOGY4MnIyS0FRVjYtb3pZdDJnQTRwdHc9PQ==
The point is not that those humans will cease to exist and not produce carbon emissions. The point is they'll do something else which they may like to do more. If they like to write and draw then so be it,r/machinelearning,Z0FBQUFBQm0yeGJjRG54WFhJYVpxbENhMXd3cEJUdEd0d2FYN2c0Q2k4a3hQQ0U1YURWU2F5Z1NCc2FSb0lWNVZPMmV0Mk03QnVDZGM3eGU2QVozYkJEdHpCWUhnRjZIQXc9PQ==
That doesn't make AI models greener though.,r/machinelearning,Z0FBQUFBQm0yeGJjLUo3TTlYV0I3WVBQOG1vdkNTTS1McDYtUGNqdzVmTlNwa05FREpCRHZya2h4d2lyR0J2QjFhUm5ia21yeFZaVVFLTFhHbVl2TXJ0VUxvcWstbUhLRmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjMHZRcERJMHY4ODQwNlMwYk1jQW5GazhGUlVBalZLajdKd1I2X1NRMGRyRnNRNV9UNmlsNlRKdjB0b2N6LUpNLV9LckVNLWFIQm5yaV9hMmZwM3ZXaUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjdk1fRGlDeldTWVBVS2NjUzBONWUxaHE3ZGhqWTZ1M1VYdFppSmRycHJ1WHFkSnR0VlN1d1dDR1ZGNnJ6bmUzQm1GVl9nb3Z5WjJFZWdGdERiY3pmQkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjaEFVWTROTW43eVdMLTliV2V4R25kUkdvQWdNTy1LNVhteXJRQXJ3cVFLUUV6X182WDBkR3JzQVFPdG9hay1kRE5ZU2xLbjRNcVpROWxKV2EwSURwWVE9PQ==
"The paper explores the theory of mind (ToM)—the ability to attribute mental states to oneself and others—in humans and large language models (LLMs) like GPT-4 and LLaMA2. Key findings include:

Performance Comparison: 

LLMs and humans were tested on a battery of ToM tasks, including recognizing indirect requests, understanding false beliefs, and identifying faux pas and irony. GPT-4 generally matched or exceeded human performance in most categories but struggled with detecting faux pas. Conversely, LLaMA2 performed best in faux pas recognition.

Detailed Analysis:

GPT-4 excelled in interpreting indirect requests and understanding false beliefs but had lower success in recognizing faux pas and irony, suggesting it might miss subtler social cues or nuanced emotional expressions.
LLaMA2 showed peculiar strength in identifying faux pas, suggesting a possible advantage in tasks requiring the understanding of normative social behaviors.

Methodological Approach: 

The study employed a rigorous, multi-test approach, ensuring that the comparison between human and machine understanding of ToM was robust. This included both standard and novel test items to prevent LLMs from merely repeating learned responses.

Implications of Findings:

The performance of LLMs indicates that they can model certain human-like inferential processes. However, their mixed success raises questions about their depth of understanding and ability to handle socially complex scenarios.
The superior performance of LLMs in some areas suggests potential applications in technologies requiring advanced decision-making or understanding subtle human interactions, though their limitations highlight the need for careful implementation.

Future Directions: 

The research underscores the importance of continuous, nuanced testing of LLMs against human benchmarks. It suggests further exploring how LLMs handle complex social interactions and their potential biases or shortcomings in understanding human social cues.",r/machinelearning,Z0FBQUFBQm0yeGJjZWdua0x3M005aEw5TnZYRjNVc0ZIZ196TmhybEo0RlVLdUtmSGh0NHNJZmNVWVc2cUVsZU5TQ0dUeW9qWGN4YU85Y3RRMmlTSjNJem01a3VFcFY3ZEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjX1FZR3dVOTBBNXlfOHg0Sk1aWDhYd2ZScm5GcHZSTkUzQnJxRjJFbWpTcGE4VVJTZ3JfbTdpX0RIX1JOWGZmMDJqUTE4OVJLeVFUTVQ3RFZBZF81eUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjMHZrUnk0WW5kU1c4Z01NRmNZaHB0WE85VmpwVHNIaVFzM0ZNUGs0Z0lza3BjUDUxdFdUSjI0c0NnWm1XMHpINjdPS3gzSlU3UDNVUUJNeWt0QUlwY3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjdWhnMm1XeWtYUFdWS1pwMzQ3a3NkRlZiTG9DRUFJLVdyTlllQ196V3V6bEFFSFNiempEbHI1QVNCcVFPaXBvSkcxT25NWkhERTBfelUxVnpKNFE4N2c9PQ==
"Absolutely, I agree. But since OP didn't mention anything edge-related, but rather RL and disteibuted computing, I thought this was worth mentioning.

For PyTorch, you can use things like Apache TVM, HuggingFace Optimum, ONNX and similar tools. They worked well for my mobile use cases.",r/machinelearning,Z0FBQUFBQm0yeGJjZ2hoVXRkNno4Q3o2N3JYczlDRDd4djYzOFdZRG9SYWlKaWRPN0NxdndORmNCNzBCWTVHMWVVMlFRY2Y2cnBUel9JT2haX3JBakFYWUxDS3dvczNoRVE9PQ==
"The patch embedding is a linear layer that converts 2D inputs into 1D tokens. The attention layer consists of four linear layers: a query, key, value and output layer. All these linear layers have learnable parameters.

As far as I know, the patch embedding has no activation function.",r/machinelearning,Z0FBQUFBQm0yeGJjV3l4X2Z2djNPWU5jUVF6b2VGNDlTWG42ZjAyTkQ4cUk1c2FxOWpoMjdMSXRfb1FTVmZvYk5pMEJJbW9UM3UzM2U5T2tzNU9sdGU0YkVVRWVSU1kyRXc9PQ==
"But there are no learnable params in attention layer. 

Also, without act fun how does it even learn non linear relationships ? 
What is the patch embedding layer even learning without non linearity?",r/machinelearning,Z0FBQUFBQm0yeGJjWlZkV0VSWXNBMDY0MnRtVVotdjdnajd0S05IUGRoLWhRaHkxaUZwQ2laQWdKblNuNHhtaGpES1ppR2hqU0ItckJpYUZHUEFRcmw4WmtIbjVnTDgwbmc9PQ==
HDBSCAN and play around with hyper params.,r/machinelearning,Z0FBQUFBQm0yeGJjS1Q2MUFDSWhyWWJMNDVuV0dxbWx1dGp3U2VyNEl2NlZCRDhPS1A0X1RseW80a0l3YU5uNzZ4bk1oeFVEQlVaU3hXLUxDeURYWlZBd05GNXJTZi1RU2c9PQ==
"The goal of the patch embedding is to compress the image into patches. Without patch embedding, the attention layer would consume too much memory, as the memory consumption is quadratic in the number of processed tokens.

Inside the attention layer, the query, key and value matrices are linear transformations of your tokens. This linear transformation is done by a linear layer, which has learnable weights and biases.",r/machinelearning,Z0FBQUFBQm0yeGJjWWJnV1NZdGdqY0hzdXVCNXVZV3ZoNHJYOGZGZ1RhcElCb1lBTFdGNVhJeTI1VW4wMmV3VmNGaUZ5Ty1ldThyWHNzQTkxMWtEVWVDb0phckNPaENyUVE9PQ==
"GTO solver software (at least for now) is only going to solve multiway spots “offline”, which wouldn’t work if OP desires an agentic approach",r/machinelearning,Z0FBQUFBQm0yeGJjY1h4ekZweHpNSjd2NXBMal91bDI2QVpHeWpwNW1heDV6cEtCRi16Y2dMM0VPTjJTcDhHSXJYcW5vQ0QzZXN3TGVoMl85aU03RmJGU2hYWjNLZjZSNlE9PQ==
"Reading these papers is the best path IMO. Noam also has some great talks where he covers the breadth of methods involved in the systems he lead/co-lead: self play, depth limited solving, counterfactual regret minimization, etc.",r/machinelearning,Z0FBQUFBQm0yeGJjbnVPV2R0Vm5Ld1BHODgtUnZyZlVyLXozMHJUNFBQZ29OUEFBSjhSWHVpNVREUjV4N1I2Y0hta2NheXBFUUwydkRIYWJVQjhXc1pJZlE4TWFyaE1NalE9PQ==
"Beyond the great idea to start with the research from the researcher who have solved this problem…

Keel an eye out for aspects of particular games and what makes it not possible to solve them with scaling up prior methods: why MCTS doesn’t work for poker, why alpha-beta pruning doesn’t work for go, etc.  Great lessons to be learned along the way with prior research. ",r/machinelearning,Z0FBQUFBQm0yeGJjSzhZTkdDVXhvN1RlYVNiRmFza0I2MlFUYzRLZmRjb1d1QXRYZG9HRjVScndNYm5mZlJ6MFN4MGhWNENZY2pEUnU2TjVvc2pxV002bml5dkI0SmIyZVE9PQ==
I don't really understand what's going on. I feel like I had this product for a years or so? I think you could enable it in search labs. Did noone try those adversarial queries before or did they update the model to run on more searches?,r/machinelearning,Z0FBQUFBQm0yeGJjQmQwd1lGVkxTMXJucTQ0LVF3cmxZMFFlRXE4RG5mQThJLTRSSU5LSXlmSWlRN3AwekZHeVFnbkxaYnVIVFdDcDVlbkhrOXRaQnBjQXZKVlF2T2U5ZHc9PQ==
"So essentially would I just have to keep track of which documents are positive passages for each query? That way when we retrieve the top-k documents we would be able to calculate nDCG based on the positive passages' ranks in the retrieved array.

The current way that I'm calculating nDCG is to initialize a variable to count the gains, then for each retrieved array I'd add `1 / np.log2(rank + 2)` to the variable. Afterwards I'd divide the aggregated sum by the number of queries.",r/machinelearning,Z0FBQUFBQm0yeGJjOUpSeWF5ZWRWMGdWMHZSYjB5RFdKNDFRTnJLVHlnM3pLOFh5NGo0dGwtWjVtOFFJVm95UWRzNmFRd21qZGZ6OElKS1VtLUo3RlFVWF9tOWpUZGVkbkE9PQ==
"The patch embedding doesn't have activation function, so that's why they call it linear transformation. It's usually implemented as a 2D convolution (at least the original design from ViT and DeiT were) with large kernel and non-overlapping stride, but successive designs use a sequence of convolution layers called convolutional stem as it can make the training more stable (""Early Convolutions Help Transformers See Better""). Such an implementation can be seen below:

[https://github.com/Jack-Etheredge/early\\_convolutions\\_vit\\_pytorch/blob/main/vitc/early\\_convolutions.py#L93](https://github.com/Jack-Etheredge/early_convolutions_vit_pytorch/blob/main/vitc/early_convolutions.py#L93)

With regards to what is being learn in this first convolution, you could ask the same thing about convolutions in any CNN. In general it's widely accepted that early layers act as feature extractors of simple shapes such as lines. It also acts as a compression mechanism by reducing the effective sequence size from H x W to (H / P x W / P), which is a necessity for the further post processing in the attention layers as the complexity of attention operator is O(N\\^2).

As for the positional information, it's incorporated into the output of the patch embedding by adding a learnable vector to each element in the sequence.

Finally, attention layers do have learned parameters, as the Q, K, V projections are implemented as linear projections with weights and biases. Intuitively, the attention operator allows the model to dynamically reweight the sequence elements based on each other. But asides from that transformers also have the PWFFN or MLP that is applied to each element in the sequence, allows the model to learn non-learnable functions since it has activation functions. The PWFFN is also important to avoid rank collapse in transformers (Attention is not all you need: pure attention loses rank doubly exponentially with depth).",r/machinelearning,Z0FBQUFBQm0yeGJjNUZYRm9FOGg2WjU0eXlpbnpuNmxjb2E2ZFpkam1xMTFpUWVJcko1cDB6aklmbUtRVmVsMklHTHFQSTBkbWd3bHhocEc0X3gzcnVXTllDaWZYVmtIemc9PQ==
"I recall a few showcase matches from several years back (2017) DeepStack vs human pros. DeepStack was running on a super computer, so real time (heads up) GTO was within reach back then already. Throw enough compute resources at the problem, and you can run those ""offline"" multi-way solvers in real-time. It's just not financially interesting to spend more on hardware than the revenue such a bot would generate.",r/machinelearning,Z0FBQUFBQm0yeGJjUl9zNEMxZWkxci1SdmtUcW5aRWdxcXVWazRMeXM2cU54cWNxNnh3dlg2TXZPN1lIckY3NWFuNDJTRTdJTmJBMUt2UzNJUkp5SzJaR1NuOC0ySm4yNHc9PQ==
Style guides are for losers.,r/machinelearning,Z0FBQUFBQm0yeGJjbGZkQnVWd0ROd2VURWN3UTRXTGxvbzdxZjdPeUxPMkFvYkphNmNIYW1FY1RQT0RMcFMzdERMY3VQUUFETlhXMW5mSFR3T1hSVmhrSUMtY3B4Q1Zjb2d5WTVlQl9HN3hCM2tQdV9lV0lIYnc9
"In ViT, patch embeddings are learnable, but the linear transformation is just a projection.",r/machinelearning,Z0FBQUFBQm0yeGJjNDVlaDg3Q1pUZkx2c2Q4ZmV5SEZuZUgtUWI1QWs4R050SnZ6elE2Vk9TTHhNUUtIOGhEZGR6QXNtazRRN0xvR19uRlBsbW1mUXlSRHVIOVhXa0RVVVFGcXA1X1ZnS2JER2Q1REhUVG9ndms9
"Maybe it's because ML papers focus on timeless concepts, not past events?",r/machinelearning,Z0FBQUFBQm0yeGJjdTVwOWxJR3ppc01KY0d4bkNfR3RZNzJLX0JHcjNVejd6bGphVlhiM1d5ck50Rl9YcjdRSFc2bEJyTzhVN25tRkFGcUdrOFRRemx0SWJvTF9KdkFRWEluaUYzbUlXbTZPbkl3UHBSc3hkX0k9
"I think you do not have a clear picture of what you are talking about, I recommend reading the paper",r/machinelearning,Z0FBQUFBQm0yeGJjZHlZRU11M3FXb3QwTEJxeTFuWGlITzdWOUIySXo1NEVPMWViZE9hdkxwZ0JhWmxKeEJMMFdkUXN1VlUxdlRYSU9xbXNTcHFpeXZKYjYtRVJyZ3FMUFE9PQ==
"Federated learning could be a game-changer here, train a single model across tenants",r/machinelearning,Z0FBQUFBQm0yeGJjc2pSQkdneVVsOGIycTJlYm8yTjRzdi1RODVpZzZJN08tOW9qQ0VicExhS1dYdUJnWnRKLVJzR1VuV3JoR2JjNy1waDJ3QTVobk5DVkhCTEN6N1RVa1E9PQ==
"Page 9: ""Although tree based-methods can continue to gain performance through hyperparameter optimization"". Does this mean that you performed \\*no hyperparameter tuning\\* for tree-based models? Which are well-known to overfit if not tuned, and gain a lot especially via regularization tuning? In the caption of table 9 you write ""all others use random search over the hyperparameters"", but it's unclear what has been tuned, how extensively, in what range etc.",r/machinelearning,Z0FBQUFBQm0yeGJjRUZMcWhCcHRTaDViNWNUUlgyWHFZNlRNU0F6Tkd4N2tLVXREWEpCN1JrRHR6Q3dhcnBvMmk5WFR3bWM1Y3haXzNkYVdhSER4QmxvdE95eDdWZXNrdGc9PQ==
"The TabForestPFN is only runs on default fine-tuning settings, while all other methods, including tree based models, use hyperparameter search. XGBoost and other three based models indeed gain a lot of performance through hyperparameter search, as shown in Figure 4 (also seen in the reddit post). Because I use the public results from the benchmarks, I do not perform the tuning myself, and so I do not give any details on the search space. Instead, I would like you to refer to Appendix A.3 from the [WhyTrees ](http://arxiv.org/abs/2207.08815) benchmark, and the GitHub code for the [TabZilla ](http://arxiv.org/abs/2305.02997) benchmark.

Based on the results, TabForestPFN's power is on average roughly equivalent to XGBoost with a 100 to a 1000 random search runs.",r/machinelearning,Z0FBQUFBQm0yeGJjS2pqeVJ3bDRMeGxZYVpGTENkZmMxWGdiaEt1cFlkNHRYbE9TMkVXdWJPMjB0MG96MjFnMXFFTlVzNHZiaTRQa1oxYUM1NHoxYUhKMzBPdzN6RXlhQ2c9PQ==
">Everybody is talking about RL, but that's not the what the question was. Human-like poker, not great poker.

The field of reinforcement learning has roots in psychology and combines neuroscience and machine learning together. There is a mainstream thought in neuroscience that the brain learns through prediction error. For example there are dopaminergic neurons in the midbrain whose firing rate is directly proportional to the difference between the expected reward and the received reward, and people have done a lot of research with the obvious connection with temporal difference learning. There is also much newer stuff like Clopath's work with the meta-reinforcement learning in dopaminergic neuron activations. Human learning and reinforcement learning in ML are tightly connected, and if you want to emulate human behaviour, RL is your go to. Just because you can put a sequence in an LLM it doesn't mean that it is the best tool for the job.

The best place to start to understand more about what the people think is to read Richard Sutton's Reinforcement Learning: An Introduction.",r/machinelearning,Z0FBQUFBQm0yeGJjYktscGlGZk1OZDdfRTlkejk4NXNvR284RXdfU0Jzdll5Z2hfaXh6am5DcTg3RVV5WmRlY3VfejhqMWhDMUkxNURTQnUzM1NESlRYdkN3MDBrcVhjS0E9PQ==
"The raw attention mechanism has no parameters, but it is usually used with reasonable linear projections for Q, K, V. This is the case for transformers. Usually when you have something like AttentionLayer in a DL library it includes those projections (at least optionally).",r/machinelearning,Z0FBQUFBQm0yeGJjLU5PaTVEbUVGNG9xZ3hRNWF3Z2hEc2Z2LUF0TmktTzZJa1B2WklyTTN2MlU2enh6eXppTldxTWt5cC1Jd0RIVVl0cVVsWWVaazJocURwMGRBOVdWQ0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjekllMUV4cDdtT2dJdTFfTk9Ja1g5dWsxMXozOWRGQUtOMzlRX3dIaDRtMndBMUlrdUJvWjNwWWlNSVhLOW5obUhiUFFIeldpTHhVN2RKOGo0d2xRNkE9PQ==
Do you really think the authors care about grammar enough to read style guides?,r/machinelearning,Z0FBQUFBQm0yeGJjN0xwNXVyRjNLY284T1dZcWlxSF83WUQzNVBSb1RiU252YUtqczJvWDRaVVVWd1R3VXpNX3RlZDdxS2tRRmFEZ3podDFSNUVwb3dOTTJpNzdpTEFHYlBuR3lIbVlEZnlsYk1kdHY3ZmM0UUU9
This is completely useless. It's too generic to be a good review or a good summary.,r/machinelearning,Z0FBQUFBQm0yeGJjLU03UUdIdHZvOGoyVFVEa1F3ekE0d3QyVnJ2TVVjWlNIb3FOM0h5VXhJdGVSR3BnMVo0MkRhaS1zQVZPZFhOZV9hQXVuZ1Vmckw3TndnVXRTN1Vuemc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjMHJOWnV1N1F6c2h5MjU0RE8zSTNsTjNpcWNSdGlqZ1NabzhBeG9jMTFCQXppTl92QnNJa1VFSGFZU25vN1FjbTNEQnFJVkhIUjJCTEhVSDdCZlBfS3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjUEpZZWd1LVJxZWtsWk9mbDBXNWdUZ3hXN1RMTExUU0d5WjhnSFp5czFncTg1dUlOdjQ3c2puYm5lOUVERFdXM0JfMHU3aGExRDlfNTNueG1EaDVUUEE9PQ==
"I think that is not the point. APA style guide specifies that, for example, when we write some experiments already done, it should be represented like ""We conducted ~~~"" because It's undoubtedly past events. However, many papers use expressions like ""We conduct ~~~""

actually, even in APA style, it is encouraged to use present verb tense for general implications which are not specific or temporay results but ones having generalized meaning.",r/machinelearning,Z0FBQUFBQm0yeGJjMkZKWjlKY2JQUnNYNzRoWTJqSkJ2NG1mVGJ6UVdoN1BpR0hlNEEtUzBXbk5FRUJIMTRwZDVuVnJFUGx0QTFLZ285RTE5Z0xsNlFiZmpNNURMeWZMZHc9PQ==
"That was a really Good answer! 

Could you plz explain the below? 

1. If the patch embeddings don't have an activation function, how does it learn non linear relationships? Let's say I use feed forward or cnn for it, early conv layers, to learn even the basic lines, dots, curves or texture it needs non linearity otherwise the decision boundaries won't bend and there's nothing to squish the outputs. Since image data is complex and not linear why did they not add activation function in patch embeddings ? 

2. So the QKV projections are again linear transformation and don't have an activation function but further mlp layers would have it and that would be enough to learn complex relationships, did i understand that right?

3. Linear transformation with weights and biases with no activation function is used in multiple places in this architecture, why is that? Wouldn't it be beneficial to use non linear transformations instead?",r/machinelearning,Z0FBQUFBQm0yeGJjWDRUXzhjd2hSMXdSQTVpQ0VYa29oREctNTJNN0dpblJjVXZ4R3RVNDN4ZHZHU3F5YTlmZWM0dm90R090N1BFSEU3bnI5c2V0ZGF6d3N0b0tPX0hUTkE9PQ==
"Oooh, so this is the meaning of the X axis there. Maybe this could be made more explicit? I totally missed that. Anyway, great work then.",r/machinelearning,Z0FBQUFBQm0yeGJjTkpLMUZOc3NwMjlsa0M5eUU1YmhZOHA4RkRVdUozY081eE95SU0yZE4zSy1VRl9DUXhfVnljWDlRTkNDMWtydkxleGNwWU5JRGNXNVdmcS03TEJmSFE9PQ==
"Yes, the X-axis is the number of hyperparameter search runs for all benchmark methods. Thank you for the feedback, I will update the graph in the arxiv paper.",r/machinelearning,Z0FBQUFBQm0yeGJjdjVHT2tGcjRZYlRjdHlzMC1UNGpUVS00R3ZVaC1yZUI5YVZiMjZ3WDJhQTFpNHZwUTBZZXRJbDNLaWJ0U1lNWWpFR3NZSHFIM2tDT3BLR2R6TlF5b3c9PQ==
Dude noone cares. We didn't study literature for a reason.,r/machinelearning,Z0FBQUFBQm0yeGJjZHBseklyUnU2T2MwaHZEaDdOUko3T3pPaFhLTEdHbWUxYkY3T2N2VHBZc0FWTG1OT3VobkhqWUpkYWtUTHZTWUpvQl80VFIwaWVPOUdyeGs5ci1Jcnc9PQ==
"You should take a look at NIST's TREC campaign, they've perfected the art of large scale evaluation. To evaluate you need to have some ground truth, which we usually call query relevance judgments (or qrels). Qrels are basically a relevance score for each (query, document) pair in your corpus. That's how you can compute the iDCG (DCG score of the ideal ranking, i.e. a sorted list in decreasing order) and therefore nDCG (the DCG score of your ranking divided by the iDCG, which bounds the final score).",r/machinelearning,Z0FBQUFBQm0yeGJjYm4tSkFtdjlyT0pzbWRfbHB5WkpzSXFlZmhTOW02S182M21JWl91Q0ZjZVd6NjE5aVlKTUVlY0kzRUdXdmdxR3hoS1lQekRYcVZZLVJBNUtyT2RxOHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjOHhaWG11Z0NwTjFqTFpIcy1fdjBYRFRwMm92MGNLX1ZabmtTODZ0U1VOZ2pnTG8zbTdMODdFZUszVEloeUo0WkROLTF1alFuSU1KZU9IOVdlNXNwTkE9PQ==
Is there any better methods?,r/machinelearning,Z0FBQUFBQm0yeGJjSHI1N2Zwa1NzeFpWc0FteF90Qy1fay04bTJ1NmVISmhvNlR4VExvbWtSYldxYzQzc0NWcnNxNHV4NjkzV2dnYXZZQTEwS3VmZFRjNDFScVp1ZEZQcFotMlpUbnVmSEdTVmRNLVRhT1IycUU9
"The paper you linked does segmentation to face and face to segmentation ( examples at the very last page of the supp.material), it's not far fetched that you can do image to segmentation, maybe with a bigger model if your dataset is more complex than faces.",r/machinelearning,Z0FBQUFBQm0yeGJjZHF3MVA3VkVlYWpXR1lXcVRTbWFOSTlqWU5VTkltVnFXUDBEb2lheU04Q3ZYdUlnRGpuM2NuWVN3UTVPendZYnlmc1JMQmlCTktlek9mUmdwUVBsT0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjT25odmd5M2FKUUN3ZVh0N2twVkVsdFlWZnhvMm0wUW1jY1hUY2s1LVJOeXFfVTdOUi1KOFFKdEZsYnlWZnlDbDRXYndjY1lFODNKYjJrMGZMWl9yMGc9PQ==
LLMs should not be used to review papers. Peer reviews relies on the assumption that papers are carefully reviewed by experts that are familiar with the literature and methodology related to the paper. LLMs do not have the depth of understanding required to perform the task.,r/machinelearning,Z0FBQUFBQm0yeGJjS3Y4OTc2cXZQU1FjRnJpWXVlMHk1LWVvUW9uNjJQSndDR1J0a2c2Y0VGMDhGbzJ0S1E0YklUWE9PLUdWNzVqRzY4ZUNNVEktM1o2QnVlVWtKMDA2RUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjMUZFZVdpMHFsanhBdk9EalZybHVFTXljUzFQdUFrZnVSRUprWWJxOW53aFFuOWtVcDJUN0N5TjlHcmxHZk0wUWRjLUFPX1N3VUZONVQ2MFc1Y3dCQWc9PQ==
"It might be because present tense for self-reporting is also a widely adopted style, yet it resonates well with the very reason why ML is conference-heavy — to make the publishing cycle shorter and let folks stay on top of things.

Also, ICML does not require following APA style in terms of grammars. It merely says: 

>Please use APA reference format regardless of your formatter or word processor.

which is about citation, and that is already hardcoded in the bibtex style anyway so nobody really cares.",r/machinelearning,Z0FBQUFBQm0yeGJjeUROb24xRE9TdkJ2V3FaQTRfdHRvN2RmMFlsVkUwc0lDOXFBTkRnUkJvZy1hbWw4OFpWMWtubzltUXVxN1FJeDNoV1pIRkdDWG1na01pYTJQWjMyQVE9PQ==
"That’s quite pretentious. To be fair, a lot of the basic ideas in neural networks were popular even decades ago and were discarded. Probabilistic methods were quite popular not long ago. What happened to the timelessness of those methods? Why did we then throw those out for something else?

There’s a science here but the theory is still far from done. We think we are timeless but we are still finding our way.",r/machinelearning,Z0FBQUFBQm0yeGJjaElrbXg0UFYxb3BhcnV2cEhHQXl3bUg4ckhkRXZ5cWVmdWEyMTlfVlgtTTRpX3VPQ01hU2g3TTZmLXB3WTVpcms3V3VDWmEtMVpfc2ZrSUNFYzFLZXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjcC1nanNTZGc5Qi1YSG9wY1R6bHNxemRZUmxsaXhWV0FFcnNYYjZha1gzYTZheGdBMGx5eTN0bEZ2UGstdjB2TkFyOFE2UnhITm5teFU2Vi1RRGhvNWc9PQ==
"So I've read here and there that LVMs work by decoding text tokens from images, and appended between special tokens like [img][/img]. So would it not be possible to ask a model to ""Reprint this message verbatim"" and get the text-decoded image? I've been trying this out using GPT-4o but it doesn't seem to work.

Or I am misunderstanding something here?",r/machinelearning,Z0FBQUFBQm0yeGJjazltT1NYaGF0d093OHNpbUdGdkRhMGpjLTBFbUZCc0VTTXFRM2RYeUhwbk5ldndKdk9ablZRdDkzWWk2d0NjNnBoNXRHaWxnQUNzNjlxTG53dTY5SkE9PQ==
Most people are not native english speaker too.,r/machinelearning,Z0FBQUFBQm0yeGJjWlRiY3lFMVA2UTN3Z2x1ZjVpV0FvYmFQQ1U4cUN0b01EVXAxdjlidU1HYnVzZVV3UzM2Q3B2cWM2SDBEZDRFaFVtcUxTY2RuSnp5TEVEOUNTZXRmbFE9PQ==
"Most of your points are well-expressed but you need to more carefully read the paragraph you are quoting and debunking at the end.

> the development of AI has the potential to create jobs as well. These jobs could be ... demeaning and/or involve low pay. For example, OpenAI, the creators of ChatGPT, outsourced work to a Kenyan company where workers were employed to label specific instances of toxic online content

>",r/machinelearning,Z0FBQUFBQm0yeGJjNGRnbmxhYUVVYmFfb3Y2RTZOQTN5bi1xYTdCZldQTDZFa1JnZGN1UUk4Q0dkSGVIWlBTaVk5MnU5THl6NjhPQ0s3NU5FN21PZ2N1bFpkWmgyNW1wbmNzaThUTjlqODhvZ2Z0cmMxVmUycG89
"Didn’t know that, I’ll try it out today",r/machinelearning,Z0FBQUFBQm0yeGJjbThwU29nV0lYbHpuLXNpRjVPbUhWU3Z4aWJITVFLd0NuMmFVYmVYRWJ0QWw0MThXOXUyNUZJNnF3aVJvZTNsQ2ZCZVpleEN4alk2d3pfWjg1aFpkMGc9PQ==
"Hmm I did read it and I feel like my question isn't unreasonable. I see how SNNs learn, but I don't see how they learn across timeframe. Even a basic explanation would have been helpful",r/machinelearning,Z0FBQUFBQm0yeGJjZV80N3N5cVY3VFZSUlhVZFZFcEtkbDFOQ2EyN1FtRWg3T09CbDVyQ0I3a0FlQ2pVbWdtNm5iazl5UHFIbE9iSlZqMUJKU0lsSVQ2LUN5RU5aWVNZbkE9PQ==
"It seems your comment is quite confident. How can you assure that LLMs do not have the depth of understanding? Conversely, I can bet experts also cannot distinguish between human's or LLMs'(by much better method than this).",r/machinelearning,Z0FBQUFBQm0yeGJjNFpDUkxueXlENzYzUHFRYVE2bzRrc2tNd05lZFViS0NhNmtpZDJ0QWJWSEtrbWFDLXdRU1hobzM2Vk9TQV9UOV9xc3lxMHQtVXN3WGlMR1VldXdDbUZMb1VoTzNzcFVUa3VmQnNCTXlvdWs9
"This is DC nepotism, even said “random” will be very well connected to the machinery of the political industrial complex",r/machinelearning,Z0FBQUFBQm0yeGJja1FBeXRkUEw4dzVWY19Xc0tabUFobHhTX2gwWXp0VjJNSjBYTzVyQTJfUXpBVF9wejhUNnJidVhlYzlNa2FFbVE4dDN5MEJMOG5FTGdhRjlRRjVWV1E9PQ==
"Woah, what a list O\\_o",r/machinelearning,Z0FBQUFBQm0yeGJjYThHU0NFQ2M0RWlhRDhVcC1QamFLTjRYX09CY05CTTY5THJrMGY1XzRlQ1I5NXVRTWdoUWRJaXoxUU02TFR4RXpoSDRLMnhRdVlNU0J5MF9NVV85amc9PQ==
Baroness who hosted a Donald trump fundraiser last week and taking billions in BS tax incentives for DAC to boost bottom line of drilling,r/machinelearning,Z0FBQUFBQm0yeGJja2pSSG9SQ09KM2Q1b1BwcGh3eEM5N1VKSmw2bUZoSmRSTE1mdlM2cXdVQ2xVdjViMnR2V1IwNHRYaVlSaGl6d3JSbW54NV85MXdSSFVBUTJTaGthVVE9PQ==
No partisanship at all there. It’s an unbiased group of people that want nothing more than the betterment of everyone😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂,r/machinelearning,Z0FBQUFBQm0yeGJjTXBXUzRXSW5yZGotM25MY3lZbmF0ekdDc0RpZUNDLWY2NkhEdFQ2LVdGeFdmQnByOVBOYmtpazZSU1o4NnFpazdESVdMRnJMd3Z3WHAwZTg3SlNFZTJ0Wks1VGZxWENrNVNLTXNhTnc3ZWs9
"Funny you mention that, since they do have Oil and Airplane executives in the “AI safety” board also",r/machinelearning,Z0FBQUFBQm0yeGJjeUU3RjVBWkpLMmdxanZvM01aUUdOLUNzTnVteTBEQUFuNTl0d1hyY2F2UG5uRTNmWTNySzJiMkpxbVIzejJMa3pzZ3hFYzRkbk5aSW1ONVNNbnByTEE9PQ==
"I based my comment on the sample shown by OP. which is quite poor.

The bottom 40% of reviewers provides very poor reviews. Honestly, I don't think it would help anyone if LLMs generated those reviews. On the other hand, a good review requires deep expertise, which is something LLMs currently lack. 

Also, how useful a review is vastly depends on the reviewer. For example, let's say that I have a review about this paper that says ""paper is good, trust me"". This review will be interpreted very differently from you if it comes from Yoshua Bengio, me, or my brother who doesn't know anything about ML. Peer review is a system based on trust and reputation, it's not just a matter of writing something that looks like a good review.",r/machinelearning,Z0FBQUFBQm0yeGJjQWJpV0JUMDVwYTcwV0FfNDN1aUUtRW9MTl93eTBLUTdJNFlVQWozeGhzTkxuMjZRZk5pNVAyb3RWTDFOcWJUQ2VkT0Zpd0dzQ1Bndm5jU2FMQm1QVnc9PQ==
"Tip: If you use Dalle instead of running stable diffusion locally it doesn’t use your GPU at all, saving even more carbon.",r/machinelearning,Z0FBQUFBQm0yeGJjOF9WSndvUHVnS2s3LU94MDd2RVc0LWp3d1NPZTdjWmpqNTFhNk9QSVhDOFlEUFNvaDQ5RW1fTTNfcmJPNjRXTW9haVByeFczYWhERlR5T3FLSDE0anc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjUmt4OFZ4QURLTUN5bktGelNlRUswUmZReWxoYVZvUVNnM2lodHctRUZhd055MFFiSTI0R01kNjBXWThMZlBwRXlNQnU2S2JDaTRxSE9uX0NWYmxNRVE9PQ==
Let's put these monkeys in charge to make sure that no one eats any bananas.,r/machinelearning,Z0FBQUFBQm0yeGJjaWVSazdIT1RPeTU0bWxEUkt6YUZheUszMzRhVXB3QzZadmVsX1p1T0J0di1yRWdmYjlOY18ydXBsQXByNTdRdlNRejg4SnFLVmFqZ093LXgyUXlyaFdLWWRra3BOUW1kZ3FZMGotN3BZbEU9
"https://huggingface.co/spaces/yenniejun/tokenizers-languages

https://www.artfish.ai/p/all-languages-are-not-created-tokenized

Median token length actually is larger for OpenAIs tokenizer. Maybe there’s better Chinese tokenizer’s out there but this is the first example I could find.",r/machinelearning,Z0FBQUFBQm0yeGJjTWs5MjVFRTV4UmVSTjRUY0huZXhGN3RKVHAtdF9yQXlCam5OdVpYdEl0NmxKNzhmU1NzMWN1LTlHUlZCcE5WWWhuM3NueURWRGVOajI2ZGtvbmQ1RlE9PQ==
There should be 0 people that are profiting from AI on this board. Major conflict of interest.,r/machinelearning,Z0FBQUFBQm0yeGJjM19BU0xDMTZpY0FnRXVXYm1xUFhVNlp4VjNibnBHbjZlYmZEOTJRei1kS0xYNW90UGMxaTRRX1lwZG53RDNpaGRMOEtSV1BEcnpLb3dSTlZOUGpTX29KNTAtSWhUdGlvX0V3bUZ1T1NZSEE9
This is a foxes in the hen house list,r/machinelearning,Z0FBQUFBQm0yeGJjRVA2dXZlWHBWNGdxTnRsRWQ5dnRQT0NQSWVSQ2tDWmFuLWd5bFM4UFZnREo0U2JYaThTcWlwTzRoSDhubTRQWjF0czRNMFozdXYtMVkzOTVORGQ1dnc9PQ==
That's a joke.  All lobbyists plus oil. 🛢️,r/machinelearning,Z0FBQUFBQm0yeGJjc3JCaWRsclc1YnRXdzUxa0V0emZnSHY2UVcwdU1lYXhCTmtnLXNSZ2dFY0VJU1ZmRWRpblFiSE5KYk1yc0g2REtMYUxOcG05dXdBdDk1V0hhb0V6SnZ0RV9qR3VtTzY5aS0wVDAtYjFfcVE9
"gotta be peak capitalism moment, when people who are advising the laws are also the ones to benefit the most from shaping them in their favor.",r/machinelearning,Z0FBQUFBQm0yeGJjeUZYSGc1Ni1nM2hTQnpvNmphS08tNm1LVkRLMDk0WlMtYjBqMVRidW9vWEJ4aGtwSlRidHFDMGZuTnYyN1pqTUhIdm9KNncyeVR3OGc0aXo5MTlRV2c9PQ==
"Ai shmafty , do whatever you want",r/machinelearning,Z0FBQUFBQm0yeGJjajlFcWZGUHB2d1RhSGxJZlJYcUlkWW1CRU1zM1U1MHdwU2o5TU92T3drd1RKWUV3T1J1ZktGeUJGczBocmJmSWgtdmpLV3RqREEtdG1nYlNJaE9ESnc9PQ==
I think we can trust them.,r/machinelearning,Z0FBQUFBQm0yeGJjRDR2TElRMW9zUmtqYUF4WDZTdzRDeXpYWl9iQ3ozajBwd3RwcTQ2MlNWZzNZQjF2cVZZTDltc2hLT0V0eXp3YmxhQjdPeHVBQTFtOWY1UEtjekpmSUE9PQ==
"So, anyone care to read the release to see what this is actually about? Because it's very specifically about using AI to protect critical infrastructure and protecting against AI attacks on that infrastructure.


It's no surprise that open source is not represented. Why would the US want to open source the outputs of this board to the entities that will be carrying out those attacks?",r/machinelearning,Z0FBQUFBQm0yeGJjZ0NEVXJWNDdxRkY3LWk4cXdpcE9JWmlyWC1oTmxZY25JQkVjM0M1YVJiX2pHNmxIeDNUaTV6VHNkcS02TnpIdkRlRGJZV1J0Q1k0QkJrUVl3cTVYbEE9PQ==
Hugging face ?,r/machinelearning,Z0FBQUFBQm0yeGJjOUhGckZnWHRlSEFaS2lvZVlKSnVUNzNmTEdDU3doVklHQUJrTHVlc0w2OFd3dUxsaFlMUmtBNEpnVnlrOXFxR29fMVJDWnM0NlllaDdCakRheFpYNk55alFWa01ZM3lLLXY1U1Z6S0p6RXc9
"Full list from the link:

- Sam Altman, CEO, OpenAI; 
- Dario Amodei, CEO and Co-Founder, Anthropic; 
- Ed Bastian, CEO, Delta Air Lines; 
- Rumman Chowdhury, Ph.D., CEO, Humane Intelligence; 
- Alexandra Reeve Givens, President and CEO, Center for Democracy and Technology  
- Bruce Harrell, Mayor of Seattle, Washington; Chair, Technology and Innovation Committee, United States Conference of Mayors; 
- Damon Hewitt, President and Executive Director, Lawyers’ Committee for Civil Rights Under Law; 
- Vicki Hollub, President and CEO, Occidental Petroleum; 
- Jensen Huang, President and CEO, NVIDIA; 
- Arvind Krishna, Chairman and CEO, IBM; 
- Fei-Fei Li, Ph.D., Co-Director, Stanford Human-centered Artificial Intelligence Institute;  
- Wes Moore, Governor of Maryland; 
- Satya Nadella, Chairman and CEO, Microsoft; 
- Shantanu Narayen, Chair and CEO, Adobe; 
- Sundar Pichai, CEO, Alphabet;  
- Arati Prabhakar, Ph.D., Assistant to the President for Science and Technology; Director, the White House Office of Science and Technology Policy; 
- Chuck Robbins, Chair and CEO, Cisco; Chair, Business Roundtable; 
- Adam Selipsky, CEO, Amazon Web Services; 
- Dr. Lisa Su, Chair and CEO, Advanced Micro Devices (AMD); 
- Nicol Turner Lee, Ph.D., Senior Fellow and Director of the Center for Technology Innovation, Brookings Institution;  
- Kathy Warden, Chair, CEO and President, Northrop Grumman; and 
- Maya Wiley, President and CEO, The Leadership Conference on Civil and Human Rights",r/machinelearning,Z0FBQUFBQm0yeGJjOHFrYzFiZm9jSjQwZnVRWldLRGM3U2hCZG44MFE5Y2d4S2EzdHlESXBjUUEwd1NXbVpiZjFfMXRzS0FuS214RUI2OV9jUjFURXJEczU4NFctWWlSQXNqUUQ4ZF9WbWw0c3JzUFEyU0YtWkk9
"Congratulations on shipping!

> I am fairly certain that Microsoft does not rely solely on screenshots as I do, but also captures of individual app windows, and also extracts meta information like window title, maybe even the text content of the window (the same text used by text-to-speech programs for the visually impaired), these could definitely improve the results.

Check out https://github.com/OpenAdaptAI/OpenAdapt for an open source tool to record time-aligned user actions (mouse and keyboard events) along with window data extracted from the accessibility API.",r/machinelearning,Z0FBQUFBQm0yeGJjT0g5YWxCUHk0QllMQy1rSld4QkYyTjl2M1JNRW14S2kyUWFKR1U1UWE4T255aEl1Z0VIOXBFLVZBc0txMnNNVHNWcHdwclRuaDAzYmpOOXVDaGlWS3c9PQ==
I used to be at a nonprofit that worked with IBM on an AI project. There’s certainly an ethical component in the way they design their AI. But I’m not sure if “ethics” is synonymous with “safety” or “security.” I suppose it depends on the model being built and what it does.,r/machinelearning,Z0FBQUFBQm0yeGJjb24tUTZlRFRkbUF4NEprci1mSlVFUzlIZmw0NG16b1JmcWd4UHJfTVZWWHh0ZnZqMFZ5anRuV25Gd0szVnhDcHp2QmRDVXExY013MXAzLWo5MmE4YkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjbFh2aVUwOXV3MFlramhKUDlSc3NzMFQ2ZHAtdWVXYTRMLTQ1U0ZqRkoydDZLM2MyOGRSRUNOcFZTZ3JZZWRKTXZPWU8xdmxkNm5UTFFXdHdweW5tR1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjVzVUcG5IZjhDVDJZQlppTGNWSXlsQjNST0RxT3YtU1FRdG1IUFZrcjdxNGEzdmR2OWs2OTktZlIySHVyUUdVang4dVpZNF80dVQxLS1iNURPZHBqVmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjeHNqR2ZGUEdPVE1Oc1VWbnAwMnlHTURnQ0hqWTRWeEN0SWJ5Y3VIQi1TTFpkVm9JNm1HUEozbVZITEZlWmNZSlF4Q1ZURmV6MFpPcFY5SHdueEFmOEE9PQ==
"I don't see any professors, lawyers, judges, psychologists, ethics specialists, journalists, etc...just corporate interests.

&#x200B;

One could argue its the best middle ground...so to speak..as politicians want the support of companies and what not...but I doubt there is anyone winning except CEOs and companies here.",r/machinelearning,Z0FBQUFBQm0yeGJjVFVXWFd6ckw2M2o2STZGXzlKVktzX3NLaHdycTZwTlFuRTZvMl94UFhoRlltaDlfNE1tZ2xia09rWEZpVWNSY1lNMS0zNjIwbzZURGl4ZGtWenEwZEE9PQ==
How did Northrop and an oil company get in there? Lmao,r/machinelearning,Z0FBQUFBQm0yeGJjaWtsMFFOQVVQSTBLaUVWQ3doNE1TQlJmaXl5bklvS0xZeFZhM0NjQkI4UExWTWVDVWZKb2M3WDNSUkFtbjN2TE1FMEdISkFUZ3JXaDNUcU1ocFZDRXc9PQ==
I don't see academia at alll on there,r/machinelearning,Z0FBQUFBQm0yeGJjRUF4cXVra3g4Vm90WGF3aHplc0hUNTExWmhzcHMwbjgzNXJnbjE2YkhpeFAxSk91aVMzX3pPTXA0NGs1anBnZk9rVHlSYmNUZmJTcVI5VU9DaVd6TWc9PQ==
"no Meta ? 

But anyway, they should hire researchers, not CEO of big tech companies that will only make what benefits them. US government never heard of conflict of interest ? or is too used to it",r/machinelearning,Z0FBQUFBQm0yeGJjM19ERHo1aDRocDJGWDhnTU1tYl9URU1wYlJkV2FxWE1hUWNsd2RDOTBYVnBJZjV5MEN0ajZTaFFmLTNjaTNWMkVlQlgzOHVuaU52SUNKTm1aMnc5dXc9PQ==
"Definitely sounds like a memory leak. Also, for 780 images I very much doubt you can fine-tune any kind of network reliably. Instead, try using image embeddings, i.e. replace MLP head with nn.Identity() or something similar, to get flat vectors. You don't need to compute gradients or anything for this, just extract feature vectors from images. You can also use large models for this, for inference basically anything works. Combo of NN feature extractor + kernel SVM for classification tends to work quite well for cases like this, plus heavy preprocessing. Also, you shouldn't use a single test set for such a small dataset, but rather nested cross-validation for testing and hyperparameter tuning.",r/machinelearning,Z0FBQUFBQm0yeGJjUjRrc0E1R1l2RlIwN2dCZENCRnBUbks1cjdnR3lUSEVGcUpqZnhzQVdRNG52YkRudFMxLTNHem5zcy1kRDUtTjNwdm9lSjFjTEpCOTV6NTFUQ1hpOUE9PQ==
Would've been better if this board was made up of renowned computer science professors and AI researchers. This just screams major conflict of interest to me.,r/machinelearning,Z0FBQUFBQm0yeGJjdUFscW1EMWtzZVpvX0JzRXRxcXg2VXJyZ1lDSUswTnh5TUR4RzFzZ2hlUGhMdlFWRmtFTi0wOVlsZmN2QWE1MXRsUVdORTlzMmpPdGJYYzZpVjZJdHc9PQ==
I think as CEO of OpenAI it doesn’t really matter if he has a degree.. he kinda just does what he wants. That’s like telling Bill Gates he’s not allowed to attend an IT summit because he didn’t graduate college…,r/machinelearning,Z0FBQUFBQm0yeGJjOEJJeHpENE9KYVpkb1UtRUY5MTAtdFJjWjBwalNDTjZlUm5XcTVuWUtBSC1iS3ZocXpOUkNuQmRkQWdFcW5ZbDd4eUZDSDF0c2VSWk03cjdZbHlIVnc9PQ==
"You think he’s going to decide to start accepting equity or a salary now, after not for the first 8 years of the company? Why?",r/machinelearning,Z0FBQUFBQm0yeGJjclR0V0NFYWd0cHY2SFU4WWxzWUQxZElWaVBiZE9TUmprLXFvZVZZNmNzV1B5bDh1VWp2RGUwazU4aHVtZGxHeHdXV2tmS05US1MxOXFYODVWYkRNVWc9PQ==
">Jensen and Lisa really aren't qualified. 

A standpoint of never having worked in a top tech company with an engineer leading on full display here.   Just an uninformed and naive comment.",r/machinelearning,Z0FBQUFBQm0yeGJjZFFCNE9iSVd2THN6bnJkQlg0bXNtU1JlX09OWmoxbEw1YWh6eml5WjZZeW5YbFVieDFqeGF4M3FET3ZMNHl4elB1STNoam83WDJicEdRT000NjhkdWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjbmpzdkEyYWVVMk5DRmZxbFEzMHJ4ZkZoLVY2bVFTQ0lDY2k4U0VPYi1xTWdSalNNUWlKd2xEMTRaMXNRNl93OTNRUGxMMlBwVlU5Yk5UQ29KSC1NVlE9PQ==
"Not a single users voice on the board, only producers",r/machinelearning,Z0FBQUFBQm0yeGJjWGlqbWJPdzdpRmNOLVFOUXdYTW15OXBkVkJ1aUJ4ak1NOUhfZ01qOWlEeFFqdzl5WjRXVk5iUEJyUTd0eWZVY2tUV01ZelI4VWJMTkNuR2c0UXc1Q0JHc1RoSEp3aldoQm9tOUphRjJJN2c9
No. It shouldn't even be tech ceo's It should be independent software devs and stuff. This is a joke lmao. the country is obsessed with letting corporations do whatever they want.,r/machinelearning,Z0FBQUFBQm0yeGJjeUR0RjQ0VG9Ud0NKR0R1TEdwbzctX0VvcVNCZmxwQjNvZGQzZEduVG1ycmpmSHNlWXFxNktvVGVvSVpGMFFjVkFVQXcyZFdGVkJxQmZZNl9YV3V0WGc9PQ==
How big are your images? Is it possible to downsample them to save on memory space?,r/machinelearning,Z0FBQUFBQm0yeGJja0R2bzJiOHhIVW85aFZxTm5DQ2YyZ1VLbjZMMFM2U0ZjY0pMb2cwenY2QWJLb25zalRkXy0xWDB5Vk9jTF82LVlUZTkySFlQbUxYLWJUNUQxV2ttQUE9PQ==
"Smart! Let’s instead stack the board with people who have direct financial conflict of interest and CEOs of companies that never delivered an AI in their life (Delta Airlines????)!

/s",r/machinelearning,Z0FBQUFBQm0yeGJjZXRzdVotTHRLbkMzXzNySHhnX2Yxd3dCelRuZjRDYlQyLUt0WUV4T0tUQmY4RThjU3lMTFFKSEpGa1hpclJ6c3llWlJEOS14b1luMmFsbnF6YjFjWEE9PQ==
My interests lie in AI in healthcare especially early detection. As a newbie how should I go about it?,r/machinelearning,Z0FBQUFBQm0yeGJjUFJwcEZxQmdnVThaaGlaVlM2N3VxdGVaUW5xa1BFcy1aLVRBX1EyMl84WlEwdkJkOUtfWFNwMzd1dU5ZU0J3T3VaNDc5WVBNRzBlWjBSN08tc1dJSEE9PQ==
Besides representing an industry that uses AI extensively while 30k feet in the air carrying millions of people all over the world?,r/machinelearning,Z0FBQUFBQm0yeGJjYzBOb1JtM0ZmYzlIVVVCWEt6SGM2MjgzelRLdGNhSzMycGZtT3RkaU9UVXhkM1NLS1phQmxROHd0Uy15Nl9yVzZhZWw1d1l0WG1WRzlLaFMtOUxNdFE9PQ==
"The most approachable course I've taken on the subject is Jeremy Howard's fast.ai class. Its free: https://course.fast.ai/

It will give you a taste for what AI work is like, and introduce you to alot of the math in a gentle way, even if you've never taken calc or linear algebra. 

It mostly covers the neural network stuff that forms the foundation for all the craziness that's happened over the last year. It does not cover as much traditional machine learning and statistics.

If you want something a little more rigorous, traditional, and heavier on math and theory, check out Andrew Ng, machine learning stuff at coursera/stanford

https://www.coursera.org/specializations/machine-learning-introduction

Both classes are challenging and excellent and many people have launched careers from them.",r/machinelearning,Z0FBQUFBQm0yeGJjeU5mLWM2bU1yMUpoTjhlSTRsWXloV0Njc2VPckhkemtTT2pSQTM2SzZlQnlGNzBUbERlX29GX0NPMnBUZ1hWRHdjMXdKM1N4aFh5eGZuTEJlYm9hSHc9PQ==
"Great work, thanks for sharing! Will definitely give it a try.",r/machinelearning,Z0FBQUFBQm0yeGJjdEJPbkJFZXl4WFNxYXQzNlFuZDJKTlo0YkZEaDdobzI5bVlNMVdNVHBzaTRhSkpoLW83NmJMWTRQRWp4WHJuQ2xrYnpYNUZ6Q1g0Mlk1U0hHeVhLV0E9PQ==
You’ve missed the entire point. We can decommission those humans to free up the carbon once the AI is running.,r/machinelearning,Z0FBQUFBQm0yeGJjY0JGblJLTUJjNWJzTy13Y2JSa0F4bkVrYmZpZlpVeFVDdTZZQ0J3VHVXX0JBN1RxVHRUQUliTExDbHBkV1ZDS0JzT0dYSmVvbThBZzhIM2JOVlRsaXc9PQ==
"You're right, though it is a bit ambiguous when the example comes after a sentence with two clauses though. Doesn't really clarify if they intended it to be the first case or the latter but if we are charitable it would be the latter.",r/machinelearning,Z0FBQUFBQm0yeGJjNGtra0dfbjdvek1yRWQ5R1Zwd0lNemVoZk0yNjQyYVhxanNHc2doQ0I0Q0JGazJNNFEwazFlTTBEaWkzLWtPTDhqWTNadTNtR19FaE5GNGU0U3NDa1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjOHZOU29xNFJEWVo0NWRfMFZWNmpJUkwwTW94WjFNWXgzRnNJX2ttOEx0WHpZek5RSXFHemtlUEVHY0JqOXQ0RkFwd3oyR1pfaXNJWm5VSUhaZ21pY1E9PQ==
I never thought I would be able to advocate for small government but this may be changing my religion,r/machinelearning,Z0FBQUFBQm0yeGJjYlNlQ0tyemNrTmR2emEtR0Vya0N3d3FfYUZ0S3Q4Sk4zbndtMkZwc0QwQnJsa0pfWHNfODlFTWU5c2JkV0R1R2txT2JHRm1Td2hjeWpUWUdoeXZPSGc9PQ==
Please don't repeatedly spam with same beginners post. Although you have our sympathy - your post may not be suitable here,r/machinelearning,Z0FBQUFBQm0yeGJjNnZZdzRteFJjTWd3TE8wTjNkT2VsMUpHcnVQRDJ5UmJFblAzUy1GQm1tbmhUbkstV3d5R3h6RTR6N1VzcGhGdE1fbThacDRmT2ZZRS1DTkItNHFXRmc9PQ==
"There is a lot of vagueness in some Chinese words that aren’t directly translated to English. 就 for example. It’s just, but it’s more than that. 是. Yes, is something, etc. there are ton of possibilities to create new distinct words from that character.

Also Chinese wasn’t optimized for that. Man made languages optimized for this is better without requiring the same amount of tokens.",r/machinelearning,Z0FBQUFBQm0yeGJjX3d3YWg4YzZXSHV5allXWFNaSzZ6b1pNbUttQmVKTnh5WHlHdFNvZ2pVX1RXaTlqX2JKcER1UXdZaFdWMFQxUXZ1bkdpTm9acXZQUnp6OWVEMFY5QTlBZWJjZkxmaXBXVF9uVFVUMjRLOVU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjbkg3Nlg1eHRuXzluVTlMSWFjZTFoeXM4eHdQaFVsdFhlZVQ5TFFBb181X0o0QmVORHY5V0s5WU8zYUxCejF3NUxlSHZvekJhUlJnLXhBLUtuWlZ0Z2c9PQ==
The difference there is Bill could build things,r/machinelearning,Z0FBQUFBQm0yeGJjSlJhQUx1MXU3WWIwak9XQkFxUzhfTC1Dby05cW1tc1FYaVk2OHFJY1cwbDZmVGVLQlJTYTdkQnZSXzVvX2FGeUtaV1J6VW1DMkZaZ3Jrc01tUmVWWXc9PQ==
R/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJjT01vTnJrak14YXk2cW1mMXBqbk5FeTViRTFrbjRfR2hfNVlDSHZXcUtnN1ZsMEd3ZlJZVzBmY01ZNUZkN1BqWUdMZXpPdXIxVm02a1Y4NTVJQWpzS2c9PQ==
Hey. I have some powerful compute if you need and we can chat. Send some details of what your working on so I have an idea of the problem your trying to solve and your approach. ,r/machinelearning,Z0FBQUFBQm0yeGJjSldjYkZZV2dSUXVDa3V0ZC15OGpLazFzSXJKdFhLYXdiOUo5RVlxZERkZ2NyMW4xcHNDVUxLdWhQV2ZpNGVQdGw4cXZQVzN0c1ZabGZEMFJoUEpmRllxSTRmd0FCVTU2c2dkY3ZaTk5GM2M9
I've actually looked at this. Chinese is idographic it doesn't tokenize well. There's no compound words. Its essentially already tokenized. There are some interesting implications down this rabbit hole. ,r/machinelearning,Z0FBQUFBQm0yeGJjWXdUdXJEdWdrOGh3Mk5weTJmRnNkcVdfVEZYd0p3SVR6cGVmS2VFOHhZcnlQRDljejhTYjlxS2F0WGRqTDExQlhRd1IwWFNHUW1GOHhWcUVyMXJtUkwxM0pnOFNlU0I1dmtjVnUweHVodzg9
"Typically, an ML Engineer is supposed to be a postgraduate educated ML specialist who can digest a problem statement, understand the theory involved in the ML problems, perform literature reviews and implement a paper into production-ready architectures/code. The researchers/scientists are the ones doing the experiments and writing the papers.

I think being a Software Engineer who does API consumption (and prompting) has become the new LLM-based role under the name ""AI Engineer"". If the company isn't in LLMs or has been using the term for years, then you may expect an ""AI Engineer"" to be more like the former than the latter.",r/machinelearning,Z0FBQUFBQm0yeGJjdVExeEJtLWxCRWs1RUlHcnhuMkJWRDVHREUxRGMyS0hFdDhOci1RbU5PVGs1Mk1zX0wxd2lRbmktTnUzVFdVUDh2ZFhtblROM3JHa0NGWGNHS1BXRmc9PQ==
"I was always wondering how you get something that isn't straight-up too good though. In reality, you'd probably run into training issues that result in your model not being optimal anyway, but with enough compute and letting the model play itself for millions of games, wouldn't you just create something superhuman? I feel like you'd want to have some kind of regularization for an ""easy"", ""medium"", ""hard"" and ""expert"" mode, but I never got deep enough into the RL literature to figure out how they handle this.",r/machinelearning,Z0FBQUFBQm0yeGJjNUZGTEd2OGdCcGd0cGhWNFhQWFNuQzRZVUFVM3FZQTRqNlZUZlZ2ZHRCV2Vxd0RBWDBORUtuNUdYTWszcVpFbGZENzR2TTZnT0ZTb1lTb2NoZWo1NXc9PQ==
"Your readme is almost useless. Lots of text, nothing of value. For example, you picked several models and don't even mention which ones. In the results section you don't even mention the results. I'm almost sure you just used chatgpt to generate some generic text for each section.",r/machinelearning,Z0FBQUFBQm0yeGJjcnVGN0o2clVIa0VCdk1NSkQ4MUl5MXEyX09tM01wVVdHeEpScUduWGg4eDJzMlp4bi1OQXFScGZrVXdTa2cxVXVBWVk3eFJfSVFaLURKNjh2YjFmWFE9PQ==
"Before commenting, can we filter out complaints and criticisms of it.  EVERYONE knows it’s challenging, let’s get to the success stories.",r/machinelearning,Z0FBQUFBQm0yeGJjcUhyOS1ickRJcnZBWG1TaDJ4YXJ5eGxocGhLNG5UQkRxSHluSS1HVUVXRFdGTkV0T01lbllxb0VTTEUxbWRxdmVORnMwWUZCcmR4SUlWNjVvc1otemc9PQ==
"I would like to see more on successful applications of applied ML or causality even if it is just borderline simple statistics/successful ways to improve labeling.  I feel like twitter is filled with LLM this or that whereas saving lots of money in an ethical way of course and moving the needle on important human problems to me seem far more interesting.  As a grad student working on mental health and ML, I’m starting to lose morale so this is important to me.",r/machinelearning,Z0FBQUFBQm0yeGJjdEp5YkdxcDN4REVOSmhnOEpIenN2U2tXbkpmNS1sVGZOVmZrVFlrVnJXUmxLd2x6VlAxU2EtUGZzbHNEYm1aR2s0Ykp2NDNMbUs5R0NyZXh1c0M4OWc9PQ==
thank you for this!,r/machinelearning,Z0FBQUFBQm0yeGJjSlBuLUQzNXkzamlOaF9RdlNndm5uYl9VcTQtNTRqV19JMXUwVHJDUFlMcTMxaVFDMTJpVy1GR1VEOWtISEg4YzVhMG5Ca2NMZ0xZRFZsSTBoREdQdHc9PQ==
"You would think grammar would be worth knowing a thing or two about, especially in a field where NLP is a pretty major area of interest.",r/machinelearning,Z0FBQUFBQm0yeGJjWHJIMWlSRmJlcWN3aTMxVTZoSzdwSVBVbFI2dzFYbG1SdTNhTTZtaURBdm1VcTNERmxjUEc4QklxdXBQeS1uZV9aRWpRS0p3SG00VUhyejBHbEFKd0E9PQ==
Thanks so much! I will check it out,r/machinelearning,Z0FBQUFBQm0yeGJjel90cDJHWXJjWTZhbTRzd1FlSzM1WEdUMXhha0pLWlRFRS1nTkdscy10ekNqT2lsc1N1RUpqM1QxanVmTDdId2ctajF4ME0yOUtXaWl2LUxuQ0pqSEE9PQ==
"Oh there's a reddit page for that? Will take a look, thanks!",r/machinelearning,Z0FBQUFBQm0yeGJjQTI0UTU3SWxzRlc2eHE1S29LNFhiN1VDOTdUTzFOYVVhcmtwdW12b3VMenRydkxOeXYySElzOUlHeGhPVF9BSWhET2tpeC1sYkk3NDItSjgtLTJxVmc9PQ==
"Fair point, I didn't express my thoughts properly. I wanted to dedicate the second paragraph to having a bot play exploitative strategies, i.e. maximize gain against opponent weaknesses. Which is where RL would be limited by available data.",r/machinelearning,Z0FBQUFBQm0yeGJjSWdKMUZ6M1NoRGE2R2xDRm9fd2VLZ0U4MGlhMi16VDF5cnVIQ1ZMMG9YQVJ4enNUNElIelpGYUhqdkpSNGh1M0s4V3c3OXNrNDVMSW9GVi1FakltT0E9PQ==
">the most efficient supercomputer (RIKEN, as of 2016) has about 6673.8 MFLOPS/watt at FP16 precision. 

This is a meaningless number, that’s a computer from almost ten years ago and based around CPUs instead of GPUs.",r/machinelearning,Z0FBQUFBQm0yeGJjTUdGNmU5dHNGOGczYk91VWxBZUtRME5DNEJaS0xiUXNJajNRYXZTSGd4U0lMeWNYbC1CTERVRXluRzhpOFBudk0tUGx0NmtFcXpZRlNOanZDbExUVDliN0tkbFg1bkE5dzRnNFY1SEhJNkE9
It was probably sarcastic?,r/machinelearning,Z0FBQUFBQm0yeGJjY0VQcDNyODMwU2xHQk5zWDZyUF9kcHFqR3huT3hDbVJBeG95RXVDVGdna3RTYkwxbjgzazRmSlhaTnBJYjVGVnExb1l3dFJrSGVFTERQQTFXbENVREExXzNWbExkMUh1OGxYV3dTU0YtQzQ9
This maping is called tokenization and it is already used.,r/machinelearning,Z0FBQUFBQm0yeGJjVUs0TlRjOER1YVlFNUtyejZwUzVzUUc0ckxuWm1JMG1CLUgtYUtucWpEeF9xeDBnVUsxaHRCa1puVmRja1BoRGE3enU3bkp0VmZWRHlaZExKWXpJMG5oLUVOUUFrbFlfYnhJMUNFdVhTeTA9
"I said the exact same thing two years ago to another guy for the same question in this subreddit and an absolute wit replied that I was acting like an elitist and pretentious because math is useless, just look at models explained on towardsdatascience

YES GO STUDY MATHS",r/machinelearning,Z0FBQUFBQm0yeGJjS0RPUl85TjBIQXlSaDM1aVUyRkxSU3NUV0wzUmFONVNadVdEcUo4YnFsU1dKV2FrbHcyQklKb0trZGV5ZDlyQWFmNnc3VFRFbVJ5OVM5SElIQmJlWlFtaXA5aUVlOWtsdHZYbW5PM2UyV3c9
"Why did you deliberately omit more than half of the names in the real list? You basically went out of your way type out some of the names, faked the font and background, and then screenshotted it. Why would you do all this effort? Super weird.",r/machinelearning,Z0FBQUFBQm0yeGJjQjgyREtvQldEOV9kdWlZUXVPT01uamh5X0xqUEVKRDdoNXVzSlpLemlPaE14a2hJNE1wd2dwMk0taFo5LTBuYmFRbGpYN3RXaHVZdUNjbTUzSS1nY3c9PQ==
That's actually why they made a new tokeniser for gpt4o; I don't know if it's public yet but it'd be interesting to see how they stack up after the tokeniser starts actually taking chinese characters into account.,r/machinelearning,Z0FBQUFBQm0yeGJjLS0yMm5QWWFDdGdxdlBoWi1ELTZkV3ZQZndsSDlScl9BeDh0OHN2R0MtLWQybzRqV204Y0NSVmk1YThjaVE4RUpGMkVkaDNsYWsyUHFCU3dTbU5XN2c9PQ==
"This is a non-trivial problem for Google. When practically your entire business model is build on ad monetization, it makes it difficult to gain adoption for these things.",r/machinelearning,Z0FBQUFBQm0yeGJjTFNqZ3JRejdWTTJtZVU5YmNybl9VVkI0TklkcDVGaFVfZ0VVY0ltc3hwWVNVZ0FZUmNaanhyS0tkdGtfV3lMU2hmcno4RGNMRUIzSGFpcDVXZDI5ekE9PQ==
"I don't think this is really a beginner problem. Obviously the post is badly worded and formatted, and OP should have done a better job here. But the general problem of low-data image classification is highly nontrivial, yet important, e.g. in biology. I definitely wouldn't say this is a ML beginner level, since quite non-standard things apply here (see my answer about this).",r/machinelearning,Z0FBQUFBQm0yeGJjbl9LNWpqZE1nQ0tQREZSNHBkb2VGQUhCY2RCOVpIWTBXTFNjemphZmU2TVdPR3hwYzJSaXpqTkFMemhxUjdfd1BsLUFlZXZPRjd2T1phaHByU1JLV2c9PQ==
what were some of the interesting implications you found?,r/machinelearning,Z0FBQUFBQm0yeGJjWnhqQnhGREZaWXNiMm9laDRwbE1LZmpnb21VWUpWYm5uQV9FaW1yd0F3S1k1aUxENlBfcU95ZU1zSFBHQmdqM1NEcnRnQ0NSVVYyZm14WWxVejFJWm8zVkp5clRZVThXVDBIamZPY2NNd0k9
"https://www.technologyreview.com/2024/05/17/1092649/gpt-4o-chinese-token-polluted/amp/

😂

Also GPT4 already had a Chinese tokenizer… not sure what you mean by “actually taking Chinese words into account”.",r/machinelearning,Z0FBQUFBQm0yeGJjbm8xXzFOLVgtc1IweFdlYWJYVnlEbm04Tjd6dlRyOUxfV25PSGhUdmlVWC1VOUdZdk9UMDZJOW85X0JtbjlqRTJISXB4Ylo4Zk9zRTVLTlU0Nm9vOGc9PQ==
"It looks like you shared an AMP link. These should load faster, but AMP is controversial because of [concerns over privacy and the Open Web](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot).

Maybe check out **the canonical page** instead: **[https://www.technologyreview.com/2024/05/17/1092649/gpt-4o-chinese-token-polluted/](https://www.technologyreview.com/2024/05/17/1092649/gpt-4o-chinese-token-polluted/)**

*****

 ^(I'm a bot | )[^(Why & About)](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot)^( | )[^(Summon: u/AmputatorBot)](https://www.reddit.com/r/AmputatorBot/comments/cchly3/you_can_now_summon_amputatorbot/)",r/machinelearning,Z0FBQUFBQm0yeGJjRUJZQjZrRTNvZk92TjYwX1RDSFBQUG5rVS0wS0FhQTB4TkFTdWg2VDJuenhudnlaQWFGc096Qm9SUlNNYmpFTnd2Z2liYjh6SnBkZ3Q1VWZlYUhrSnc9PQ==
I could not see the edit option. Is it not opened yet for submitting the final version?,r/machinelearning,Z0FBQUFBQm0yeGJjdC14TUR5ZTRTSF84d3FyYXlhZGZXbTItQ1J4ZmNzZ1ZCdVljOW1VeVM0RzFoTDhwUmk3bjhWNTBuel94YVd1SlNjRzZvSzVlMmZkLWJLbVVIY05RcXc9PQ==
"The most (in)famous example of RAG today is Google's AI Search feature.

Corporations also use RAG to ask LLMs questions about their internal documents.

More about it can be found everywhere: https://www.google.com/search?q=%22retrieval+augmented+generation%22+site%3Amedium.com

As for Guided Generation, see the llama.cpp ""grammar"" feature and also https://github.com/guidance-ai/guidance

Right now Guided Generation is mostly implemented using grammars or regular expressions, but in theory it can also be driven by any kind of symbolic logic which classifies candidate tokens as viable or unviable for a sequence ( calculation logic, for example, could use GG to force the next tokens after ""11 + 7 = "" to be ""18"" rather than ""42"").",r/machinelearning,Z0FBQUFBQm0yeGJjUU9VaUtMY0lld3Q1Tm1NcjFWNWxMSWlFYlV0emd2RThWdnR2ZldrX204WTdTeTJnQnotaDEyQU5ILURDYlJfSkE0U0RMVnc1VWE2end1YlVCZWpnUVE9PQ==
"If capex is once, then, what is Nvidia future year looking like ? I think they insist on it being iterative process with upgrades every time, meaning it would be closer to OpEx.",r/machinelearning,Z0FBQUFBQm0yeGJjLUF6NDlWYzJqXzE1N2EtM1dpVGdBdWtPemZTZU9rZ0tsT2dfeEpNb1dqM0lmVnJ4cDFtcThxeDVmVUZUSXlBWVhyWm5yY3lBYkJZMnNzOGlOVlM5SFE9PQ==
So if you improve ROI : you increases prices ? Consumer won’t buy. You reduce gpu cost ? Ah. Wait,r/machinelearning,Z0FBQUFBQm0yeGJjTy15bW9pcnc5N1pDTlFrbF9GU05oYk1QdHFRZTJVWXYxekNwejYyamw0U2Z3NDhhbjlhNkZuTlhjbTdzVUlxYUFsb1JDMXpqOTcxSWJrLXZlbGZSTXc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJjWEpPMTNOZUNQUjQ5d2FISmxjbGx6Wmc3TEFVVDJzRDhleEtEZ0FpcFMyMVRyUnZ6cHg1SkVBZ0pXMWgzY181LVdobXdzcXFXVUsxOXNtRmZ5a21rMnRPTmlILUxlSi1mT1RPWUtMYTMzY3M9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJjWHVxYlJhQ0VFU3FIc1d6TWNUWW1jWWJPTXd3d296aUdFdzMySGhibmFRRWVhLXpnMkRyaHJWemdnV3RvaDZvQ1BYZDBlWHJwVU4zdUFNWGRTMXVwbXNPU21hbk5DUG9LTll5eXNWNl9rbWc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJjVi1kb3hYOGRqbG1QUGFOYnQyUzlIMXBpbGJQSjlXZnBtLXRMZHFlX1VxdHRmeEM4a2h1Wkp2SUg4cVNMUllBRWRsZ0ZsT1IwZmlleTFKU2Y2TUliS0ZLZ3FraW1QYXdXOXp6REhQMnBGelU9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJjZlFzNXNReVlLb01WMm9TbWM5TWVtV0RsVXROUkZCcUxHWGdXOVY1akhGZkxjWGRLUXExQkNaYTJ3MXhwa01mc3VlVjZTM2VTRnoyc1V0VmVPMmtCQlhJUWdJWWxLeXhFUW9jaVJMQWtLdEU9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJjcEhZQWNVLUUwYjFoNDNMUExudC1ZRlRtSGd0cWZJTFJwRXhhMjdSNGk4VHJTOXdVOGZnUXN5ZWgtRVBVLURlVU43S0N2UGp5LWptS01oUFRmUWhoemxzN1NFSzkxQm8xa3pUN182V0lZeVU9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJjZl9oTVFrZjFqNkU1cms1TzVNampuaWFQX1d6ZndqT1owdTFwN3k2NXAyXzRwbldaSkpScWp6dnh2Y2hLVG9VbHZwQzlBU29qOWNLZE5tei1YVFpIeXZGMkk4bWRyY1ZQbEpMR08wbGh5SG89
"??? Chinese has so many compound words. 中文, means Chinese (language). 水果, fruit. First character by itself means water. Second has no meaning by itself. 

Maybe this isn’t the technical term in linguistics, but in my non-linguistic background to me these are compound words. I actually think the opposite, the use of so many compound words make tokenization harder. There’s no super common suffixes or prefixes (like say “ing” gerund suffix).",r/machinelearning,Z0FBQUFBQm0yeGJjT2hUM1F1cm9SR0xCM1dFUXNQTmdVTWdFWVV6dVNjVlFJTEFGYkdRVHZmM0UwRE5EeUhzQVdfVjY5czFuV0lYbHhoMWtGWnhxUTN1RjlENGc4MUtYREE9PQ==
Though it could also just be marketing. It’s not like they’ll tell you and it matters much whether it’s separate models combined or not,r/machinelearning,Z0FBQUFBQm0yeGJjdEZkdFRXVFJCb2tvTXVLcmYwWDM3YXZYeERfek54YTRyUnAwQ1VJTHdMOXNMTFhkNW50MDVXTkZVVnVCa0RlLTY3Vnp1Qm5ySkM1NnhVOUNENE5wSWc9PQ==
If you check out the UFO code they released awhile ago it may show you how they accomplish a lot of the interaction. https://github.com/microsoft/UFO/,r/machinelearning,Z0FBQUFBQm0yeGJjRTRtbV9FZUlDNHNKTEpaeHljUmZSMm9aSm9WcjZNZ0N6cGhUVWJMVkRqbl9uNUxrbmlDaXRwdlRFZGJ4alBxV3lZOEctTGF5X2l0X2FnQ0J4UElMUnFKQXBiYzZWODRzSUNyUEZyb053d2M9
"Devils advocate:

* PapersWithCode is perfectly fine for sub-fields where the authors of Papers actually include Code.
* If it doesn't seem useful to your subfield, perhaps your peer review process should start encouraging papers to include code that shows how their techniques work on relevant benchmarks.",r/machinelearning,Z0FBQUFBQm0yeGJjUzE0T2FCM01XN0FaNzlqdXJuZ2xJcnc4VGJzaDFIOGJaU09LTmN1MlJvZXFRdHZ5RXVtOVZjYkhQZk9NWUMtNF95aEF3SS1DT29kc1JfeGZQdnpMZzA3X2RSeGxYdEExWXlNT2hLUUhmRGc9
Don't do this.,r/machinelearning,Z0FBQUFBQm0yeGJjbkhxcjVFcGRXX1JJT0JMRXp0TTlzT2lBbVM4d0lHU0hoSTJZOTJYTEVSdDNtbGgxUGRDdmJHUF80eVl6YU5vMTZYY29aWDEtQVRXRVZuYU5GNVkyRGc9PQ==
"# Synthetic Data for Fine-Tuning - How Much is Enough?

I'm trying to create a bot that can chat as much like a real person as possible. I have a 4090 for hardware, and I want to use the Russian language.

I'm training it using synthetic data generated on GPT-4 (before the release of the new version). Currently, I have the following issues: I generated about 10,000 dialogues on GPT-4 and another 40,000 variations on weaker models, using the dialogues from the stronger one to diversify the speech. For GPT-4, I had procedurally generated prompts, so each character GPT-4 conversed as had its own extensive set of characteristics.

I don't have a clear understanding of how much data I need. I read that at least 50,000 is necessary, but for instance, I can train on an entire dialogue (around 40 phrases) or in pairs: question-answer. This way, my 50,000 turns into a million pairs. The question is, is there a specific amount of data beyond which gathering more is useless and quality no longer improves? Or does it depend on the model size or fine-tuning characteristics? If the latter, how is it calculated?

Second question: can I somehow influence which aspects of behavior the same dataset will change? For example, can I change my model's vocabulary or the length of its responses without affecting the content of its replies, only how it formulates the response?

Third question: if I switch to a larger model, will I need more data? I'm currently considering Aya-23-35b and hope that a way to train it on my 4090 will appear soon. Does a larger model require more dialogues?

A couple more issues where I could use some advice: after fine-tuning, the model changes the structure of responses to a more human-like manner but speaks quite monotonously. Is the problem in the data, training settings, or something else? The model's ability to grasp meanings also decreases. Could it be that despite all my efforts to diversify the dataset, synthetic data produces too template-like dialogues?",r/machinelearning,Z0FBQUFBQm0yeGJjTXpGYkZVWHZmUm9WTmRJZXhsYXNaYUkyS3RUc01ORVJ5T2o5S0cwcHVISWRMbmk3SWxfeThHdVloazdwOVNNbzZUSmJ4Rm5yVXJGcTA0ZktXZ3RxR1E9PQ==
"You have some kind of metric like an ELO score, and when the model hits the target you stop. 


If you look at the Alpha-whatever papers for chess and go you'll see plots of ELO vs training time. ",r/machinelearning,Z0FBQUFBQm0yeGJjenlZOEpCMkhubHN4RV9QV0Y5TWhTaEJuZWhETENHc0QxRFc1Uk9BTVZOUHVoS09DSWkxNlFoZnljZDJaSmZQdEZtaTBSeW8wcl9VSXZ1RlV5b2dsS0VmWUVudmdnOWN1TVJvcU9FNHRNNWM9
"This is the most crass example of oligarchs oligarching.

What they don't realize is there are going to be four problems with their regulations:

* How to exactly define an AI? Is a simple monte-carlo algo which makes guesses until it gets it right AI? Is a CNN? What about a really good Markov chain; people thought those were kind of freaky in the past.

* This is going to let the big companies shut out nimble competition; in the western world. Countries like china are going to say, ""Thanks for nailing your foot to the ground before the race even starts. 

* Someone is going to come up with the genuine next gen AI. Unlike anything the regulations cover. In fact, this AI will help design itself to get around the regulations. This AI will eat the above list of companies' lunches. When I say next gen, I mean as much above LLMs as LLMs are above a markov chain.

* People are going to get their own AIs. Just like when they tried to declare encryption a munition, it just meant that people did their own thing, along with other countries without regulation pulling way ahead. The key to people doing their own AIs is these are going to be the ""dark"" AIs. In some cases really f'ing dark.

Plus, what problems are being solved by these regulations? I don't mean what problems are people imagining, but what real problems are we having right now with AI that society needs cleaning up?

My predictions for where AI is going to make lives worse are not ones I see. Mostly what I read are: Putting people out of work. Getting really smart, and putting even more people out of work.

This is not what is going to mostly happen. A few talentless hacks in their professions are going to lose their jobs. But that is not where the nightmare lay. That is little different than the ""economic disaster"" of replacing elevator operators with buttons anyone could use.",r/machinelearning,Z0FBQUFBQm0yeGJjeXNhQjlxRU5MY2xZVWUtMjZHV2NLZkdqckxFRlhEbF85Z1RtcWNXLU96b3Q0OERwX1lLSEhMVnBZT1pMXzQ5d0JtMmVUbVBBa2dZWjVqRFU0cFozM1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjYmZXY19ndzZaZkstalh5eldkS1FPM3pMc1RKTTNyaDctNDdvcHhzRWd4YU5BRWZrWVp0RGM5a1A4V3ZJQmtuY3pCMHM2cmpjOTNXQWI1Zk1YNDk1MEE9PQ==
What a sad view of the past,r/machinelearning,Z0FBQUFBQm0yeGJjSlQwajFuRUFvVTZsdEV5U3RMU3VQU2U1eDNkMUxRaVZJSzg2amR1akdrMDB6TkpiOHRscGFmdFd6UGNxUGV5NC1TZmJJX1ZXR0JmNkpMaE54am1qOGc9PQ==
"Ah yes, the good ol' not-my-carbon-emissions argument",r/machinelearning,Z0FBQUFBQm0yeGJjODdkWHZvZ05wdzRHRkZ1MWtoSzdtQjl3NDFWZEQtQXRnWngtdVJzN2p6dVZGY0ZwN3BJdi1DUlFzS0NaOWxfb3pxLWNWMEF3ZGo2eHJ2Z3pvWW9ySnc9PQ==
Guaranteed. Something is changed in translation.,r/machinelearning,Z0FBQUFBQm0yeGJjWmJPLUdTU09VMHNUOWV1MEpxcjJwRjlIOTlpTmJNcmpuNEkwelh0WGk3MU4tRTUtSkxEOXRlUWo1RkIzUFBrdDBvMFluR0hKMEx2ZUNxUkZCRjFNV0ZPZk9lWlRUUWpkT29qUHJSOEM4WUk9
Well run it through a tokenizer. I'll give there are word pairings but there us not the repeated elements you get in English. Words don't follow root concepts like in English. For instance genesis and generate both have shared roots tokenizers pick up on. Now I know Chinese actually does have this with characters having roots and incorporating other characters but to a computer each character is simply a number losing all of that information. I really have been intrigued to know if there is a way to keep that information in tokenization. I actually think Chinese may be a better working language if we could figure out hiericarcal tokenization.,r/machinelearning,Z0FBQUFBQm0yeGJjRHRCdHZhcDcyZFlXTm1FeXZibTA2amNUSTRwTFI2bnJycXprSmNSaEY2Y3dZcTJoOU5nbGRDODdUOUlxdlZkNC1POTJZMzFKbVpUUE04eU1HdXN3c2JtRDN5eEMxQ3VXbHJkTmwtc0pyT0U9
"I mean I never argued that your conclusion was wrong, just that compound words exist (but their existence doesn’t help tokenization).

What you’re talking about are radicals.

Looks like there’s some work on that.

https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00560/116047/Sub-Character-Tokenization-for-Chinese-Pretrained",r/machinelearning,Z0FBQUFBQm0yeGJjdFNaamhaX1hhRm5YeEJTa2szaUtER0xmekoxUVZFaGd3aURpSHZCbHNETmVFMWVpWnRsOW53SG5fY0ZycUhXU3c2ZGpxTTEyc1RmQ0pDRGxBdXhZS3c9PQ==
"I had been playing with the idea that idographic languages may be a way to make better llms and maybe even AI. Our brains don't work on words, language is important for structure and sharing yet its not how we think. When I say apple. It means a concept not a word. An apple is a thing, it's edible, sometimes red, makes pies, will fall, is liked by horses, etc. A single concept has so much more. Chinese idograms have simmilar functions where they contain the idea not just a word. Its hard to explain but if you learn some Chinese phrases you can see it. Where English would use conjugations based on context Chinese just uses the same character and context. Being able to better tokenize ideas I think is important.",r/machinelearning,Z0FBQUFBQm0yeGJja1hBMFhVdUdUVTM1a09meEtmZURYWDdfejFBZXJiR2pQVjc2TG80bW4zcjliVGdkTWpPeW44Nm1pQUNYdFpWWmxOZ3h5dEE4emVkYl84NjNJOTBGYkxuSUpBQjZOa1JFaHQxTWJla3JjMjg9
I think it's more like stemming/lemmatization to reshape words then map with tokenization,r/machinelearning,Z0FBQUFBQm0yeGJja290Y25WT292dTJmYUZQbkxINlpTdW9GZ2RraDZUbi1EX3lxU2NFSWNDT3hfRTA2VWNka29NaUY3eklQMkYtS0s4M3kxcFhfcnVRdGozal9tdG5ESFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjT2xsbmwyYlY1TzJGcEpNREJfSm5IeWxxWFlfMG4wV3p0YlpKYUFiTWZKN0dySFZYcTRidWRfS1ZHZld1NnprNXFIalRGcnpPazBFV3FiNW5wLUUxM2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjSmVsREljeHdwQkk3c1h0eTZ1NVhlS1ZZM0VjVFJnOV9ocjgza2FOSk9ia0dUSXZGQVFrNXZtSEpxVThpeV9FMHlUQ2NjN2NkU29GVHA2S1p1WkIxTnc9PQ==
"> What is the patch embedding layer even learning without non linearity

The answer to this question 99% of the time in ML is that you want to enforce a low-rank transformation. This is useful since you want to reduce the context size as memory usage scales quadratically with context size.",r/machinelearning,Z0FBQUFBQm0yeGJjcW5LbG82TTc2R1pKVk83ajhtVVB6dkJBcXBGcEJnWElpa1l6WkpaeUxsMjI1eVp2Z2lJWGVuUzZaLV8zVFc2Y0RDLXdNQW5YMmpkRTVpY3ZsY1o0ZWZCWDNxR0tHVVBkdmZpZ0tuWlg3ZXM9
"Is there a name for this limitation? And if yes, are there any proposed workarounds?",r/machinelearning,Z0FBQUFBQm0yeGJjSEpMV3NDcmRxVTg1elZ4VlNyb2taMkdJbkZEN2o0YUpPYjItRDNYTHdHdlhmakJDOTFLUFJ2SlJBU1hhb21ocm0zYThEMU0zZ0lRLXZ0cFJRNjhHcnNmazZhOExDc0hXbS1IZXZQTGZZS3M9
">I've developed a win probability calculator which can find the odds

It doesn't sound like you understand what makes a good poker player.

Poker is a very social game.",r/machinelearning,Z0FBQUFBQm0yeGJjNHRucVhjT25GTXRTcUV3OThsMGp2OUg0c09SeldteHVkRkNpRnJlZ1I2cXFpdWFyeFhnQzV4WEMyd3N1YUFlUEs4RXhIc1l5TGdPR2REQjUzdktObHc9PQ==
I was trained to not using first-person pronouns and passive voice. But I found nobody follows the rules in practice.,r/machinelearning,Z0FBQUFBQm0yeGJjTHZKZDBCdXpJRFlSU3NjU2NhTVpGejRKZC1TYllFV19zU05fQU45aGZpeFVtUVJ0ZldBZHhNQ09YQVE3am91UGlrclR4akxvS0pORnEtandxUUFkQ0E9PQ==
You’re most probably right. RAFT or some variant of it could be it.,r/machinelearning,Z0FBQUFBQm0yeGJjbXFCOEh6WHpUd3IwZFl4eXhkR3RCY0UxYm5GVngwM0tMUkU1c00waFNmWVZKN2hycFAwcV9TeTN0dktjLTdLX2JWS2R3Unh3ZkllU3JsRVlYMHVxMHc9PQ==
"Thank you. I knew what RAG was but I didn't understand you were saying it is ""traditional symbolic NLP."" I'm not disagreeing, but I just didn't think of it that way. What would you say is ""symbolic"" about RAG?

I have also toyed with Guidance but didn't know that it had its roots in ""traditional symbolic NLP."" I had been thinking of Guidance as merely a way to generate prompts but I suppose I'm not entirely understanding it. I guess it is much more powerful (or at least more efficient) when it is used with local models, which I have not tried. Thanks for encouraging me to take another look.",r/machinelearning,Z0FBQUFBQm0yeGJjakFJLXJ3WG1PbUE2NktlbG83dmV6ckJqaS1DQUJIMEVDYXFtbHlpSzRGV0hlMDVjYnJLZkEwRjNXand5cFh2a0xrSDZValZLeGVYSlFyR1Q5c3VORHpOVEJpa1FtMEpXS2VPeUl4N3FLbG89
"
It’s just a scaling issue: feeding each token reading each other previous token and doing that for revisions upon revisions would be effectively what I am talking about it… 

To fix it: back to the Physical drawing board - redo circuit design outside of the von Neumann paradigm… for one…",r/machinelearning,Z0FBQUFBQm0yeGJjZGhkY2pLWnNQbVFXZ0IyQkhfeGUtMXcya042QjhtQVJhX2VQOVlpYlJnM0taOTFETDRuN1QwQlBwbV9pZEtldURxbXFNV1pOenFDakppTzZUWmI0bVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjVVR0WnVEQnc1OFpHbWtLeFJDLW5ZcHl2dXpEdTZudmFYQWV1OXBOZGdsdG5CTDhqZkZ3YkQ4RXNBRmVzdG9SMnBpQVg2R1lMSlN1OExlTWMwX0puQ2c9PQ==
"idk if i’m going crazy, but tbh it feels like the ai overviews worked when it was an experiment in search labs. i don’t remember having any problems with it. i found it to be very helpful, actually. but ever since google dropped it commercially, it’s totally broken. WHAT HAPPENED",r/machinelearning,Z0FBQUFBQm0yeGJjZG1Da0dmdVdQdlA1anduOC15a2tJb3ZfR280LVBOMFFpaHBkY0o1SGJ1OGFIS1JsNjBMUkFKZVljTEJrQzBPN3otQk5mZThBMm9rMGxjcTUzX1FmLVE9PQ==
"Sounds like overfitting, high multicollinearity, or incorrect regression assumptions to me.",r/machinelearning,Z0FBQUFBQm0yeGJjSDlKY1NSWmgyQ1RKdDRxc2hDVlBZVWdEem1KYWR3U3J2aWhYN1ZiMlRZNHJvUGZGUnF5VWVmd29JTnZGNXhxZVoxa2JfalhSUU05blJVaTl4NXBrRW43aWMtODgzYlhVQUNTWnlFaGw3MUk9
"I can't answer the question. But I suggest that you load the arxiv document into Google Gemini 1.5 Pro (https://aistudio.google.com/) and ask questions that might illuminate. You might ask Google to write a python code snippet that performs the math operation as-described, and you can evaluate it that way.",r/machinelearning,Z0FBQUFBQm0yeGJjVUZqQUZacjFvTkR6T1N0ZlFHZkZCbXpOS3dTZUZGNDREc2F5X2Z5RVB2djFZRkFNa3BUaTZTcUtfUFR4MU8wWk02SzBPc0RVQlYyRWlvblVuSllSelE9PQ==
"Yea, probably the overfitting how i have missed that.

About the high milticollinearity.. isn't this a form of sign. That is, the data has low signal. Or what do you think?",r/machinelearning,Z0FBQUFBQm0yeGJjVDRsaFYxVklfOHpuNWYzU20zNmUxekhWZEpxVGEycy1iaE1ET2Vhei1kRENaMER1QnFmSmc2YmVRTmZxempjbGZoUF9JZnZSMnVzOWsyYzVvN0dsUlE9PQ==
Can you say more about rank collapse in transformers?,r/machinelearning,Z0FBQUFBQm0yeGJjTEx5UTdJQ2U5N1dsdnpJdzdVclAwakUzUmJhZS1PRWo5Q3NlZHZ5VXF1TkdzVzRlNHM2bWFwQ3BSamN5d05uOGI1UVhVMU1fWm1EdkNtMDVJMDAzLVE9PQ==
Quite helpful,r/machinelearning,Z0FBQUFBQm0yeGJjRHc5cExYclkzWlFnN2RaTWtNcnNZRTAwRldwU2liRXN5LVFLUVJMNnAxV3ljZUx1dDRUMTdxc1RMelJRQUszb19SMmVfUTBpZjZFMExFWVBkb0hVS3c9PQ==
"The problem is when two features capture nearly (or exactly) the same relationships with the response variable, so your fitted parameters become unstable (and no longer usable for explanability purposes). In extreme cases, you won't even be able to fit the model without getting errors. As a super dumbed down obvious example, imagine one feature was salary in British pounds and another is salary in USD.",r/machinelearning,Z0FBQUFBQm0yeGJjLXJhaE1qZHFJQUJYR0gwZDctREFTUHNJQzNVUlhVX0wyUk9UOURXemdUcnVXcTQ5RDhrZFA5YWszcGo5N0t4aG1wbGszb0s2T1NTUTJxa0FIaVI3Q2c9PQ==
"Would it actually need human data though? You are assuming that all agents would have some sort of ""inhuman"" play style or have no exploitable weaknesses. I don't understand why you would assume that. To me RL seems like the only way that you could possibly end up with agents that have exploitable, human-like strategies",r/machinelearning,Z0FBQUFBQm0yeGJjVEFTNlRFYW1OYkprYUx1YmhsRXBHTkhqUTN5UzFmTmpPNU96TGY5THdSdzB5ZkRRQmtpUTNqMzZkVWdDY2RIVGEtc1BUdUlsNzdKMmFsdWE3a3h2N0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjb2tLT0NrbFpMMzAyYkQ4SlV4R1lwS3MxWVVpbXRiUHoxZVUtNlpSQk9ybHQySTRsQ252NmZHaDluWUd6V2VSZEJzYk1acEtrRjVZODd0MHlybzhJZ2c9PQ==
Jensen was an actual chip designer. He was the real deal and built nvidia when the next release could make or break the company,r/machinelearning,Z0FBQUFBQm0yeGJja0pLYlZVVTZzcElsel9HSDV5cDIyTWF5eXc4bXdjSEs4MkFvUHlVUHNNZUtsSi1Ud2pFRFIwZmM2Rkw2bTR3OUV2MXJnT1k0VWZWb2hjekM5ZlFZOGc9PQ==
Yes 🗿,r/machinelearning,Z0FBQUFBQm0yeGJjbnNMZWV5cE43b0syLTRJU2VyeW00RUxvdlhtdGtCaHN5dzVXeV8tNWxyeGxqeDVCR2xCcTM3VDU3QTcycWx0bHlfZm9WbXBCYVItVmN5LVlNTW1zaFE9PQ==
OPs post was already removed by mods twice incase you were wondering why I commented that specifically,r/machinelearning,Z0FBQUFBQm0yeGJjMkNRNzdhUU5ySWptSUhQMTFtc0xpQmp4ZnhpXzlvY2xWak5OY1FUY1Y1a3FfckRMYjBsdkFtaE43eU9WMFJEZktVc2I4S1FSUnlDNFpDZmdkcWVLWWc9PQ==
I hope no one invite u for review,r/machinelearning,Z0FBQUFBQm0yeGJjYzhBREFsNm1OMWZENGFxVklULUN1cVd2S21XcXhHSFgzVFhxS05lN05zSU9ZeDR5eVVsM1Q2Q0VJQzZ2MGgwdWoyME9aRjNfWGtkaGdYY0ozTUlQS3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjOFlfLU1UMlMtWFhXeWVSX0JGYWpjQkNXa0lIbFFjeE5kbzF4cm5zbm1nN2F3dVpPU3M2V1V3RVBSbDdNeW03UGN6REhaZm1kREsxVDlpOGUwWTlMWUE9PQ==
Could try some dimensionality reduction techniques like PCA.,r/machinelearning,Z0FBQUFBQm0yeGJjUUNNdlN3blM3ODZENVZBeUZnSnFBSGNSSS1OZ2Vfclo4VnRxQ0lCNFRsZ0hsRWluYk96WEY2VFl4Z0VBZGJFUUQyTkNPTWN5V1VST2xLUEJlMDdDYUE9PQ==
I'd never used LLM for paper reviews in actual conference.,r/machinelearning,Z0FBQUFBQm0yeGJjZV9abHNJZm00dE1BR1hYUnZmMGVYN0luMnFldkdHTU5jalR1V25RcWZQYmNmTVpjdEV0RTNpWmpQUHpDb19MWWM0ZDd5ZVY5MHZ4R19xbFI0WmpDWm1tVFNGd0hGY1JlVDJ4Nk1ZNEFmcHM9
"I'd never used LLM for paper reviews, neither planning to. What I tried to use this is for selecting which paper to read, to check which paper fits in my research area.",r/machinelearning,Z0FBQUFBQm0yeGJjby1hckZmODE3UHhFOUQzS3pPTFlfeXVVYzFVb1ctN25jckJWZ3F1SUJNdEFubmNCMGQyR3JlSXBNOHJKSzlaQWF3aDVac0VFMVNQVDJOdTNJS0tGQmxjLTc1MGQ0OXZkUHFocXZrSEZKdUk9
now save the English document in ASCII and see what happens...,r/machinelearning,Z0FBQUFBQm0yeGJjUDZWVnVmSGsyY09pN3pqcDJla05lRnFkU1FXd0NRRUtPUnVNWE9TdkM2TVdxcU92UTlOMDJrUjNXNEhlTkliTnNqM29aVHVNMnVCa2tyQUo5R0hDRXh3WUNqbHVaVzd2bl9TTXlSQ2FNcVE9
"No. You can just use a larger tokenizer vocabulary, that’s what openai did for 4o and significantly increased their information per token, particularly in underrepresented languages.",r/machinelearning,Z0FBQUFBQm0yeGJjTEZqc2MzVGNDZExTWFZrdnFPZmVxUndRMlc4OE5kMDk5OXd2eU5vZ0lnS2xReEVVaElyNFdvRzQ1SWRVLTllTWNBdktHdF85djJsRVY5WWpNYk5BQkE9PQ==
Why is linear regression being used for classification?,r/machinelearning,Z0FBQUFBQm0yeGJjR3JYc3hKaUhNczNPbmpqMXA0b1ZHa1Q0dkoyVEdLSV9IQmpMRUtlVy1TOEo3c2JDa2ZLWjRIS2VsUHYyM1NyYndXT3FOc0d6dTVlRjlRN0QwZmxaNldYZkF6cUx3NHVqU0VzTVFVWTFLQ2M9
"Same here, just checked my CMT and the reviews are gone. I think they want to hide the reviewer final decisions, its due today (or tomorrow).",r/machinelearning,Z0FBQUFBQm0yeGJjZWZpLWpVNVNETWZwZl9QSmVMakUzcXhkdjRwSE5UZlNiTHNsdW9TcmJDbU5WeXNyVnZJMmdadklVRUllUUxadVN1MXBYY3pSOFl1aFg3UF9jNVNaQkE9PQ==
Does anyone know will the reviewer final decision be released to the authors?,r/machinelearning,Z0FBQUFBQm0yeGJjZTVYaTRRVXBaV0VzR2JXRlNpTWpidXQ1NFJ0aW5EU1Q1OUE0VkFKQ1VQUGgxVTk3bmFReV9QUUt4UVhmbDVFM0RHcFY3U1d6YVdrRi1NTnhtb284dmc9PQ==
"I don't think so. You could always consider the MRI as a stack of 2D images and use CLIP on those, though.",r/machinelearning,Z0FBQUFBQm0yeGJjWFZWdWNudHNnREE2WHNoNTZzQzd4a21na01WUEtoQy0zcHhfU3ItQW9WRzlPTGdHRDdaOUMySGVjaE4ycWNRM3JVM19sR0hmU0pFV3BUbVR2WW85NThDbElETkZuUEdUNmFSNnNtbUh2Qmc9
"The page for ICML paper also is guided as follows.

[https://icml.cc/Conferences/2024/AccessiblePapersAndTalks](https://icml.cc/Conferences/2024/AccessiblePapersAndTalks)

""When talking about people and their individual characteristics including age, caste, disability, gender, neurodivergence, racial and ethnic identity, religion, sexual orientation, socioeconomic status, etc. follow the APA style guide.""

Of course, that's not a grammatical point, but I think the basic writing guidelines for papers, including citation style, assume APA by default (otherwise why wouldn't they use ""Works Cited""?), so it's a bit odd that many papers are written in a way that discourages text grammar from the APA guide.",r/machinelearning,Z0FBQUFBQm0yeGJjdDZFUVF5c0dqVWF1bG5ZUldqZGhNMExXWGNLY2dHeXNwYlpxVGlnbGxZMVdUR3VELU8xYXphUHZxUjF2SmtqWl9paV8wQjVLai1yQkdTblA3akZvX0E9PQ==
“Could” build things back then. It wasn’t very long at all before he had no involvement in the development process. In reality he was good a business as a CEO.,r/machinelearning,Z0FBQUFBQm0yeGJjaE1oX09nSWktczZGZ3hUc1JnT3RsaEE1c2g1NzROWVlzQnNpS3ZRUjFjYTNmdUhLcENucGVYOFFXREtnUzRZa2s5ckMxVXNTUFA2MHhuQ0txTzRYaHc9PQ==
Only possible justification for LLM use is when you already have most of your reviews outlined and detailed and need grammar fixed/polish,r/machinelearning,Z0FBQUFBQm0yeGJjUElUU1g0UEdZbV9qbDJZckNBUXZkRVk0dUFWRlZpTXdLSjl1Zkg4NkhXQkt3eUFiN2V5c2otZVdXbTdaSlZUUUdtdGdkSC11TDhQZ3RiSjJnVFp6MzhrQVJTeEpSOXFlc2I0Rl9FMUxtalU9
"Yes, you’re right there’s a paper on that refs: DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker (2017).

You’re not wrong on the solvers given enough compute might be able to do this (though perhaps not economically).

My understanding was that there WERE optimizations in subsequent work to Superhuman AI for heads-up no-limit poker: Libratus beats top professionals (2018) which had brought down the compute / memory requirements to being feasible for superhuman performance on a single CPU.",r/machinelearning,Z0FBQUFBQm0yeGJjQVhkMExEWXluSmFwTjcyMGU2TzNwYWNxeW5UdlFnUHNheGhoMWd0Yk4ydm42Y1c5WXZwZFQwOFpKb3djdWs5SUhoOURCRlNQMHQ2eXpidnc2d1YxV2c9PQ==
"Starting with implementing MCTS on a game like chess or go is an awesome idea.

But MCTS out of the box wouldn’t work on an imperfect info game like poker.",r/machinelearning,Z0FBQUFBQm0yeGJjMlBwb1l1ZVhPejdhQWY3WVhJQkZVWkJfT0lIY3hnTUpGZlltU3NCZS1val9WeWRZWEtyLXNxcG5oajk0SDRTMFBmTWpDcU5IUks2V2E4TU1UcWRTQlE9PQ==
"This is awesome, well done. 

Check out rewind.ai, I think they’re doing some extra compression voodoo and have a cool ux that might be inspiring ",r/machinelearning,Z0FBQUFBQm0yeGJjWXBGbHZObVRZcU9zZVVTMTdQZDdUSjg4OVNuSGxzUnhBWFhvMWZyM29aSFQwSGM0d2RMZmlwNVo4cGE1T0ZBaGdUUlNjbHBTUE9BMFd6YktfN1Z3Mnc9PQ==
Linear regression is not used for classification problems.,r/machinelearning,Z0FBQUFBQm0yeGJjdG1icnZtQmVPaF9YMDhZY2tkb0N1V3V0OTJFZUp4aHpKeE9wM2dWMDZyUzk1QnZiTnU0SFhKYW42SVVZN1VQa2NSSDJxTW8tMDRjZzhJWS1iazhZY0E9PQ==
"Again, the paragraph you quoted here links to the [""bias-free-language""](https://apastyle.apa.org/style-grammar-guidelines/bias-free-language) page of APA; this is consistent with the quote itself and, as you already noted, is not related to the verb tense grammar you care about (verb tense guideline has[ its own page](https://apastyle.apa.org/style-grammar-guidelines/grammar/verb-tense)). 

So ICML's ""APA style guide"" really only pertains to citation style and bias-free language. ICML is in no way recommending nor enforcing a complete APA style.

Since using the present tense for self-reporting is also a widely adopted practice, scholars are free to write in whatever tense pleases them the most. Though I think 99% of ML scholars do not care about any style guideline as long as it won't result in a desk rejection, we opt for present tense voluntarily (possibly) due to the fast pacing of field development, plus the fact that this ""partial APA style guide"" is not even consistent across other major conferences like NeurIPS or ICLR; so practically folks really couldn't care less about what it says because they sure aren't rewriting/repolishing things for recycling.

Btw, not to beat on you but there is no ""default citation style"" for ML writing:

>NeurIPS 24: Any choice of citation style is acceptable as long as you are consistent.  
ICLR 24: As to the format of the references themselves, any style is acceptable as long as it is used consistently.

I really don't know why I spend time checking these out when I always rush my papers to the last minute and give 0 \\*\\*\\*\\* about any cosmetic guidelines. But hope it helps, I guess.",r/machinelearning,Z0FBQUFBQm0yeGJjWUZMT3hSSnZpSnZFWjZDZEpwd3M1OUlObElFb2p3cFlmckVyQWZKcW16cjVtTm1hcDZXTzJlSUZIcHJndTBiY2plY3MzQXIyb2c4REF0bWR3SFlZbXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJjNUdNaGkzRHFqQ0hnQ3Z1b21hWU84Uk1NcGNxX2hsVFlGWVZvV2J0d0ZiUkJXX01lbWJKTTJzcXBwNHNlY0l5NDFibzlERlptcGgzYXdBRExFRWpZY2c9PQ==
Examples of incorrect regression assumptions?,r/machinelearning,Z0FBQUFBQm0yeGJjSVA4cFpZZVNCM1BfclE2WGVkb0c3M0JJS0N3NDFVLXNURUI1dDFIOXBuc1c1cjdhUmF5Ymlqd2tkOVZPSFZ4RmhHb2JMUHFOdlRuWGU5UndFZHBNWi1PckpKLXJCY3h5RjhBcm1GNWtoTTQ9
"I think there are very common suffixes, like 们 for pluralisation, maybe 的 for possession or 了 for completion, although I understand those aren't generally considered part of the word they're affixed to. But yes completely agree that Chinese is not just full of, but built on compound words. Even extremely common individual characters like 他 are etymologically compound words, being composed of the radicals 亻and 也，the latter of which is a word in itself.",r/machinelearning,Z0FBQUFBQm0yeGJjVDRhQUZCSEg3YVNUUkJxc1JnMkNQeGJwdk90NHdKYjdNeHJCaEtfYmRCc0Y3RmJfWkUtUkZfRnk2bVZtUHVzejhNSDRWZm9LbFhQbmdWc0k5R2xVUnc9PQ==
"Thank you for that link, that's extremely valuable",r/machinelearning,Z0FBQUFBQm0yeGJja0tRTmVINkt0YmpKdjh5Wm43azlZd2RCMHNGZ0pVUGNiWjVrQ2FncG9SbDFTamNQV05xY1lHekF3SFZ0NU9xYkhkNjExVU1KMU9QdE0xeWNOcXBNMHc9PQ==
"I am assuming you meant LOGISTICS regression.

I would do project the data using LDA and see for myself that the classes are actually separable, (and the vectors returned by LDA is indeed the equation of the logistics regression)",r/machinelearning,Z0FBQUFBQm0yeGJjZnB5aG55TmJ0Ym1YYzFWdjYyME5oYzdhNWlYbVdUeWV6RURnODJQVWpNck1JbzFqeWNWQWQ5UFhXSzU0eDB1TmZwd3FNaHI4RWFfd0R0QlJVRUVTLUZ5Nkd1Vy1ibFI0Wk9ZX0FUWkp1Nzg9
"Used them for a little while to try it out. Amazing service. No way I will trust a for profit company with this, though. I will happily use the Linux version though. Maybe some future iteration of this.",r/machinelearning,Z0FBQUFBQm0yeGJkRUlYQmlISDI4MG9MM0dnd1VuUERra095WF9WcW1IWWJFQkRMTi1wY2VGWUV4V01QNl9Lci1zZTNvRGRDZ2VNMmQ2X1kxT1gxeHYxWlpzSXNkanRSSFE9PQ==
"There are two things that explain why Linear Regression is not suitable for classification. The first one is that Linear Regression deals with continuous values whereas classification problems mandate discrete values.

The second problem is regarding the shift in threshold value when new data points are added.

However, there are ways to bridge the gap:

- Thresholding with Other Algorithms: You can use linear regression as an intermediate step. Train a linear regression model, and then use the predicted values along with a thresholding algorithm (e.g., one-rule learner) to classify the data points.

- Linear Classifiers: There are classification algorithms that use linear models for decision boundaries. Logistic regression is a popular example. It transforms the linear regression output with a sigmoid function to get probabilities between 0 and 1, which are then used for classification.



Take a look at this document which describes four algorithms useful for classification problems - linear regression, linear discriminant analysis, logistic regression and separatinghyperplanes. Maybe, contrasting them can help it from the application side.

https://www.biostat.jhsph.edu/~hcorrada/PracticalML/pdf/lectures/classification.pdf



From Gemini -

Even if you've addressed common issues, several statistical problems can still plague a multiple linear regression model used for classification:

- Multicollinearity: This occurs when your independent variables (features) are highly correlated with each other. This redundancy makes it difficult to isolate the true effect of each variable on the predicted outcome. It can inflate variances of coefficients, making interpretation unreliable and potentially leading to poor classification performance.

- Outliers: Extreme outliers in your data can significantly skew the regression line and lead to misleading predictions. These outliers might not be relevant to the overall population you're trying to model.

- Non-linear Relationships:  While you've checked for linear relationships, even subtle non-linearities can affect classification. Linear regression assumes straight-line relationships, and if the underlying relationships are curved or more complex, the model won't capture them accurately.

- Interaction Effects:  Your model might not be capturing interaction effects between features. These occur when the influence of one variable on the outcome depends on the value of another variable. A linear model might miss these interactions, leading to inaccurate classifications.

- Inappropriate Model Choice: Even if the relationships appear linear, there might be a better model suited for the classification task. Logistic regression, for instance, is specifically designed for classification and might outperform a linear regression model in this case.

Here's what you can do to address these issues:

- Multicollinearity: Use techniques like correlation analysis or feature importance scores to identify redundant features. You can then remove or combine them to reduce collinearity.
Outliers: Consider outlier detection methods to identify and potentially remove or address outliers strategically (e.g., winsorization).
- Non-linear Relationships: Explore transformation techniques like polynomial terms or splines to capture non-linear relationships in your features.
Interaction Effects: Analyze feature interactions and consider including interaction terms in your model if necessary.
- Model Choice: Evaluate the performance of alternative classification models like logistic regression, decision trees, or random forests. They might be better suited for the classification task",r/machinelearning,Z0FBQUFBQm0yeGJkb0NSS05SX3NPLVhNRk9rSHFYUlhweTNkelEwRDZ0a2stb3pxcGxjdWl1OHFza1JoZDN5eXRJOVExQjdlUHNnYmd5SHVzVGxodTBId1FibnhvYnBsbEE9PQ==
"Interesting idea, but a few things come to mind: Not sure Genesis is ideal for this, it was originally written in other languages and your translation may not be entirely stylistically modern; you should see whether a Chinese text ""meticulously translated"" to English takes up twice the memory; even if the observation about the semantic density of the two languages really holds up, you cannot really choose which language your training and production data stream will be this way, you need your model to work in its context.

It is a cool observation, though.",r/machinelearning,Z0FBQUFBQm0yeGJkekRaOFNTbXBwbHlTUWpBUmxaVFlpQjFrMWlOeU9EY0NjeVZXS2NqUkFITG9Sb2tSQVJXNWlOX3lNWVRFZTIxa2pCXy1XMVNJTHNVWGNBdjBkUVhVbXc9PQ==
"If you extracted keypoints from the hand in 3D space, usually SpatioTemporal GCN is used, not point cloud models.",r/machinelearning,Z0FBQUFBQm0yeGJkeWZRWW1nUzlkdHk3SUNmMWRrSzJvd2FMNzdpYlZFVm1QSDEtRWNmMGtHaWlwV0lRdGNQY29JT20zTk5QQTFicENrUkRZYllJWkU5TGhPVEVQOXZJd2c9PQ==
I am very much interested in the state of the art training techniques o large scale datasets. Can someone please point me out to some papers where I can read more about the current strategies?,r/machinelearning,Z0FBQUFBQm0yeGJkZ1FjNDRmTnlFbGswME1LM25HcDVUV0txRHNQRGFtWHZvS3oyWTk4MG83T0t5aTVmNmxsamRxcEtncTZYeTZ1a3UzSXVUbEk2M28tbDZ0eGwzZnl2UEx3Y3JQZk9OSGZidDlOYkRYeVhiYVU9
"Interesting, I will look into it! Thank you!!",r/machinelearning,Z0FBQUFBQm0yeGJkaElYYlYwQllrMGV6a1B1endwZDBpejNpRzBRTXhsemNSNWJPcnAxczVYRWhZbWNvTU5tSE90aFVuZVBTb3VMQ1d2OHNuQXVoYk40MzRJOTM5b3daUmc9PQ==
"Hey, Im working on exactly this. Could you tell me what exact models and methodologies worked for you well?",r/machinelearning,Z0FBQUFBQm0yeGJkLTBOZGViY2NlYlpKdDZ6SFlrS2xjNnQ5REVDck1NYkdGQS1SOWYwc0F5Ym84RGdXZ2REZW9ZRVpVOG9ldGtvSTh0SVZaOHNZdDdNWkdFNF9VVnhVUFE9PQ==
"Personally I just use it for proof reading and sometimes a rating, but obviously go over it with my colleagues after.",r/machinelearning,Z0FBQUFBQm0yeGJkTmFyeC1iNFk5MlR1OG9WY29raVVxTWhObFRoMzFvTkl0bUI0bEtiUndRNnMzWEZtdVFvSkNWVF9ITmhacGRzcl9Lb3kwVGhhbHFLT1k5TDBnQnJDZUZJQ2M2VkhvRUl3VnVHeUpYZXgtT289
"Hey, Late response but say I want to compare a thousand images among each other to see which are most similar and Im taking Image Matching as the approach. Would I be able use some kinda image embedder and store the embeddings of all the images in a vector store. Then use a similarity methodology like the one you suggested to compare between each combination in the vector store?",r/machinelearning,Z0FBQUFBQm0yeGJkcC1zSnRodXlKMEd6THFuRHVGeDEyd0hhS1NhZTVyclNOOXR5eDVpRUMyMVBhdG9Cd3NOeWVDUDdJM0RVOVZrcWZCVnRSeElvMWRMVTQ0Y0hrOWdwc3c9PQ==
"Alot. Its basically representation learning / disentanglement research 
 imo, I have found no clear cut definition of ""mechanistic intepretability"" and how it distinguishes itself from these areas. 
 
https://arxiv.org/pdf/2312.08550
Not about transformers specifically but might hold in that case as well.",r/machinelearning,Z0FBQUFBQm0yeGJkN2hOWjVxMDAwZC1zWGY2WU5oMmpucENVZEVrMkl5NFd1ZXRCcW5BVlJwUzFaQUJGV3FrbkVyc09IMllnQ0t4enlyOUtnd3ItWUc4OUFqSm02bk1lQ0p6d2Z0RXJDMXQ1V05tQkpyUms1Z2c9
"It's been a while since I touched this (~2019?), at that point commercial GTO solvers were CPU based, heads up, texas holdem only. I could just precompute preflop game trees for different stack depths, and also compute turn and river GTO in real-time. The tricky part was the flop: it would take 30+ seconds to compute the full betting tree, so instead rough simplifications were introduced (reducing the number of betting rounds and betting sizes). It was far from perfect GTO (as it was patched together from individual GTO approximations for preflop/flop/turn/river play), but it did surprisingly well in practice.

Which gets me to Libratus in 2018: I was convinced at the time that it precomputed the GTO and stored it on disk (except for maybe turn and river sub-trees). But then the 2019 Pluribus (6-way follow-up poker AI) claimed very cheap cloud-computing training cost, like a few hundred $, no GPUs.

So long story short, 2019 already (seemingly?) solved GTO multi-way poker on commercial hardware. Current GTO solvers are a bit sloppy I suspect, as they still work with predefined search trees, making them slow to compute, or they maybe don't tap into GPUs for acceleration.",r/machinelearning,Z0FBQUFBQm0yeGJkTEowNmR4Q3ZVdHJPdmVmLXI0ejUxUWd6UlVFRHBfanIyVy04VUw2VUFSYmlzRmZ6NUdqUFMxYUFCRUhQallPR3lKOW1NM0ZEZHFuVktCdVNqZkZHR2c9PQ==
Thx for the answer.vHow would I combine the information then at the end?,r/machinelearning,Z0FBQUFBQm0yeGJkWW15bnU3YjFsdHRaNnRhMlU4MjJKcm41bmQzNWxPNXRHWDBuTTl1ZlQtQU1mTHZYZkgxR095ZmE2YUpUX3FJc3FRNEhjdkc3Q1h0MlNaNHBKTzZzZGc9PQ==
"Depends a bit on what you want to achieve. The research community was racing to create the best GTO playing agent; they did a few show matches where it beat the pros, so we sort of concluded it is a solved problem. Pure RL, no human training data needed.

Downside: it does not perform significantly better against an amateur vs a pro. Yes, it beats both of them, but it doesn't explicitly exploit player weaknesses. Research wise, this is an unexplored area: given the playing history of given players, find a strategy that maximally exploits it. It is also what the botting community was much more focused on, essentially trying to figure out how to fleece online poker players:)

So, you want GTO: no human data needed. You want to maximize winnings against specific humans: yes, data is needed.",r/machinelearning,Z0FBQUFBQm0yeGJkWmRlOXRFLVgtN1NfbVNhbUlSMHhnTUlfSjM4S2hyMmZfa0s5Z2hGcW9GWmRCaEh2NjdrY292cEh4LXNKZ0lrOUtRQWhvMzB5TVFYcXBESENUVVY2TWc9PQ==
"Chinese does have words. Unfortunately it is not possible to figure out without context and/or a dictionary. A good comprehensive dictionary is probably not easy to come by. Best I can think of is probably Wikidata+Wiktionary+OpenStreetMap. There might be better ones on Chinese internet. Grammar parsing does not really help if you are dealing with specialized text (e.g. classical text, dialectal Chinese, legalese). 

Same problem exists for Search Engines. Google can only index Chinese words it knows. I have encountered a few instances where when I first search a super-rare Chinese term (e.g. chemical names, archaic terms), Google would return almost no results, but when I tried a week later, a bunch of results would show up. This demonstrates that Google would re-index Chinese corpus based on ""learned words"" from user queries.",r/machinelearning,Z0FBQUFBQm0yeGJkbXNScHNGa2dvM0dKSHNGM1RGeFgweWV4cVJWS053QlFDUlFnalF6X3l3RDdjajlia2kycDh2c0dHZ09SOEtHSGRPNXhVSGhSR1IxY1BieWR2LWhPQkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkSnF5aUM2WXFlQ3NQdDVsajFRYmtRLTg2NkVQUXVza0d0SnJma203ZEo5ZDRJWWl5X3Fad1JTVktCMTh3QVlfRjdQVG4tQW5STERsTk81SmpPN3FlbWc9PQ==
"I guess it really depends on what you mean with ""do NLP""",r/machinelearning,Z0FBQUFBQm0yeGJkVUFkaHZYMDU1WmJLR3dlVGVZM3ZaMnBHeXptbVoza2tOSkFEc2N4dGhvNG1NaWMzbldZR3Y5OURvay0tSVdzXzNQWE5iUnU5TzVaMzNOY196WktkS0E9PQ==
"Same, have emailed them. It's showing for me now below the title of the paper.",r/machinelearning,Z0FBQUFBQm0yeGJkWGlrRnRHdmhodkNaWWFXdlBrd2RISmpuVlh4OURHRW5qX3FXMmp6a1pyWTZnSWduVjAySUJfclJsTzRqQ1pHb1F4V0llX1lPem1nLVM4NGZrUS1sS1R3RkRuaEZ3Y3lRSl9iN2VzZXJvMHc9
When uploading the final revision in openreview there's a field for the title that can be edited.,r/machinelearning,Z0FBQUFBQm0yeGJkV0h6Rm90M1RZdHpjUkNIYXNJRlhwWkVpVEVCNGU4Z2Z6OXRjYkVZaXBTX2JrMHMxb0E1b09zRHNFMWRFeDFjcUpMM1JSUW9mZkM0LVM4LTN0VFJUUmNJTEkyQUlqbXZycXpWd2JWNjNUNkE9
"Fair, mainly POS detection and idiom identification",r/machinelearning,Z0FBQUFBQm0yeGJkOEwwSzJESkQ5TGZ2RENqVjR3OFdGRmpzOHJBdmVaSVVTQ0I2d1NFN21YbV9RWkRUcnV6RU1FNjNSem5rdVVvb2t0QWxjbU5rYjBuZm5YbGZfLTFrUWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkazhBUmViYk5BR003azBxajFIR3k4SGZ6R2daVU5kdGszcTEtcjZHZ1U1bUgxUm85dTR5OWdGcWdCOVdBc1JyZGpZUlNvWmxuTS1sNzlvLUxRZ2Qyamc9PQ==
"Amazing repository. Thank you for the reply. I currently don't work in Diffusion models, but this is definitely helpful for learning.",r/machinelearning,Z0FBQUFBQm0yeGJkaWVqNktjR3pHZlJHUmtOcjlzeWFlWDFwX25UcWtVS0h0NjVNS2NYUkgzNXVac1dKaVdNM0hoUWp4RS0zd0QyZ1dFYnlqcnh6LVJCRnUyN05qdENmUWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkOVdlSUdOaDFKRG9aSDFXTEx1WDhPS1FXUjJtTVp2NzJzOXdaLUJOUWNCdkw4NWZhWXZEXzF1Q2FtRG9HVGFLYWE1MGlyUUw4R3dkWUtEOURiT3RYZGc9PQ==
you don't need LLMs for POS tagging,r/machinelearning,Z0FBQUFBQm0yeGJkNmJNamZ3dEVNbXlEb2l4SHdiSEI5dURQTE9MN3JLWURrSDE3VG1OX0ZndExtUzc4QVNkWWtlVjBYTEFMY1RUb1JzQzNSWk14TlZZTHdVSURmeXBpMmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkVnlaanJ3QkVfQnFwNTdSVG1NNFhIdFBFSmx4MEUyalBsQW1fOHdTcmRzNEk2bEFiQUxUWGE4N19JakxaNDZ1dHlsemN6dURVOWRDYVVDVkZpQkxiMWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkLWNzeEdPYXJUSldlRml4S3A4dDJybHU5VHNOTUl4NjhiNTN6ZmV6SzBoLUlLTEw4X1BmSVVKZ0ZMT0g5dDJKQ21Pc2lxVXFyeVJWUHV0TWNoaVNqQ2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkQVZtbFJ6cFl3WWxOczFLWGNhNXZ5S2JrUjNMTXdacWtOTjB3aU5NZWY3aFBBVDJZTUZ3ZnhrclhHYl9YVHplZGpZeDJRSGVtc3VpSERSdlBTcVJnbFE9PQ==
I am posting in this sub because this sub has more members so I have more access to guys who may have faced something similar as me,r/machinelearning,Z0FBQUFBQm0yeGJkY0RqaFcxUXZqTEN0LXRRdmtMTDU4bW9WMEpweHFodGhUOE1RSnJrUHgxN0xvaDBZbm0wdnAwU3FBYVNCeE15LXo0aUJkZEc1N09FN3A4MC1ZdENuMC1jZFFRbFZaMjZoSGZxRmJ6OEZkU2s9
"Haven't seen any papers, but would love to be proven wrong!",r/machinelearning,Z0FBQUFBQm0yeGJkU3ZDZ2R3eVRVNEZ6Q3VLeGZHQjhxeWJTWERhZnIwUzkzZU1KWXNoLXdhNXZxV29NNWNzZ0RBdmo4UmtHOFplYkpzUWQ4SFo0UEF5UkVBSzcyN3dBMGlBaS1RSm1kTEhGZEQ1Q1NILW5PV2M9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkc1c4WFI4WTJPUm5QUmlUTlBsam1HUDRvV2hnaVN0a210WTE4RGN3TVJLYm45Umh4NFBfUGxVUHdxWlVINmlDVkhMZ3AtYXowV2VsUVBJZXdPLU4tY3c9PQ==
Are there good options that can do this for most languages? What about idiom identification?,r/machinelearning,Z0FBQUFBQm0yeGJkQ3FrRjQ5WUVNalpjOHJfSFd5QmIzekJGYnFYV0I5YlBLbnNFNjNfdlMtR2xCWEVEeFFkQk9PMGpDSnJkVjdJbXFoaGtTLXVWWDZ6QWxkajloNU5YdEE9PQ==
Deep learning is experiment driven. Some people even call it an art. A lot of ideas may be inspired by some human logic but ultimately what trumps all are experiment and results. Researchers with enough compute may try dozens or even hundreds of different ideas across different settings to understand what works and what doesn't. Then they may fit some logic or some math as an afterthought behind why it works. At least that's what I've always thought.,r/machinelearning,Z0FBQUFBQm0yeGJkUENObDdXb0JYbVdicUh2d3RaYVd2RmdGcVFpRkhheENvbmJycmtQZlhfaFhzdkVZVlQ4Z0JBd1dPTHVVOEhJTzBTMXFtYWxzN1hjR29qTUxYeG9jU1E9PQ==
"Sadly, that's not how it works. Saying something doesn't work does not mean your project or your example won't work. It simply means that certain techniques don't hold up well within the body of research. If you try publishing results as innovative without reading up on the background, then that’s a problem. If you teach yourself stuff by implementing it that’s generally great,",r/machinelearning,Z0FBQUFBQm0yeGJkT2JlN05BeVFIWF9FOUdtTUtESHR2V0dsand4Y2xoTDBoVEtPT2RMNlZmd1ZQTzRGX2tUaEhTTnJOaUNRQ0hkLWU1NVBnSXVWX1hEOEc0NnNlX1dCaGc9PQ==
"Abstract: 

This work presents AstroPT, an autoregressive pretrained transformer developed with astronomical use-cases in mind. The AstroPT models presented here have been pretrained on 8.6 million 512 × 512 pixel grz-band galaxy postage stamp observations from the DESI Legacy Survey DR8. We train a selection of foundation models of increasing size from 1 million to 2.1 billion parameters, and find that AstroPT follows a similar saturating log-log scaling law to textual models. We also find that the models' performances on downstream tasks as measured by linear probing improves with model size up to the model parameter saturation point. We believe that collaborative community development paves the best route towards realising an open source \\`Large Observation Model' -- a model trained on data taken from the observational sciences at the scale seen in natural language processing. To this end, we release the source code, weights, and dataset for AstroPT under the MIT license, and invite potential collaborators to join us in collectively building and researching these models.",r/machinelearning,Z0FBQUFBQm0yeGJkX1RKWmZnS3hYeXBXWE1wVlJsQXJPa1ZocGJYYU5VMW10cmd0cG05T0dGM0NweW9OcjlubnFUSEpvNWFRbF8tT0lNcDFpX2NjWkg3ekxPSXRpR3BmYXc9PQ==
It's just an input shape thing.,r/machinelearning,Z0FBQUFBQm0yeGJkTXgydzg1NlQ1WTFXT1RpeVpYMERRVnM4em9LMTVBdG5ZNTY0d3QtUDlFRkhOSWFUaWg2dzd2YUNNMFdvbUxMQWgzUG8xS2NmZ1pFenNoMnhrNXdTQUE9PQ==
"> Screenshots

> Legally utilizable

Oh boy, here we go.",r/machinelearning,Z0FBQUFBQm0yeGJkeVdvOEw4d0hCeFhaNlJCcXJBNkZtcm1BdFo5dHhDSnVkUU9QX29rTmZiLXlnSVVxUnlEcVNVRUc3UWNDaFhYMTEtY2RIeFBuRjBGSmR4aWh2VnY2MlE9PQ==
Really cool work. Do you plan to extend it to be able to understand normal ASL instead of fingerspell?,r/machinelearning,Z0FBQUFBQm0yeGJkdjJKZDJQRmZLeUlVNFBJQzlUYTlmTWRsZWpWWVhYbXN4amZNUGw5SFZqLWdPUU8zQ3otUjRkYjZZVkVMN3RNTGJydEFSRG5YTFpYRWQ5Y2JhYWROMGc9PQ==
"1. They had big hypothesis to test. They were lucky, it worked. Now they are cutting edge. Not that easy to push further from here.  2. They had investors patience. Now it's used up a bit.  3. The expectations and the direction are set rught now so we have plan execution mostly.  4. The problem is on the verge of computational and time/resources feasibilty so patience is the main factor right now.   5. They actually have use cases now so they are also sorting out the details in their models and apis and stuff for their clients to be happy and to be reliable for them and useful.",r/machinelearning,Z0FBQUFBQm0yeGJkUlctQks3RDByMUVrVnJKQ3FsQ014R3VSZFc1empNUHZ2SGlNVHhOYmExNjB5YTV4NlRfdHZpU3ZaS2ZZTUgyQWJGd2Z4N3dzNHRxZUctRnRuQXFmVUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNVhJbUJYcFRrSklCLWVMSFNiSkFkUzgtMkY3Y2tYVk15LUE2MFotYXlTbGVvSWRzR281cnZvOTd5cC0zdV85cHdEOUJFeUtPRFAtNjhBVGdJLUw3eWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkd180eTl3WV9DaEdkMWV4djdSWnp5dDBnMXBMdEtaOEJHYk9adzVpTkhtVlJ1MmxfbTBqZmNoRkUzaGozUnpObllmenh6UzlVT3kxbC1wamJFTTdKUXc9PQ==
"Try asking one of the online LLM's. For example, I fed your question to Gemini and got this response: \\[Caveat. Some pre-trained models may not have new information on cutting-edge developments.\\]

*You're right, training a small language model from scratch requires careful architecture choices for optimal performance. Here's a breakdown of the options you mentioned:*

***1. Architecture:***

* ***GPT-2:*** *While a good baseline, GPT-2 might not be the most efficient for 50M parameters. It can work, but recent architectures offer better performance with similar size.*
* ***Efficient Transformers:*** *This is a strong option for small models. They achieve good results with fewer parameters by using techniques like:*
   * *Depthwise convolution instead of full self-attention in some layers.*
   * *Knowledge distillation (transferring knowledge from a larger model).*
* ***GQA (Grouped Query Attention):*** *This can also be helpful for small models as it reduces computational cost while maintaining performance. It groups inputs together for attention calculations.*
* ***RoPE (Rotary Position Embedding):*** *While RoPE is a recent innovation in large models, it might not be crucial for a 50M parameter model. Standard positional encoding can work well in this case.*

***2. Normalization Layers:***

*Placement of normalization layers (like LayerNorm) can impact performance. Here are two common approaches:*

* ***Pre-norm:*** *Normalization happens before the attention and feed-forward layers. This is commonly used in Efficient Transformers and works well for small models.*
* ***Post-norm:*** *Normalization happens after the attention and feed-forward layers. This is the traditional approach in GPT-2, but pre-norm might be better suited for your case.*

***3. Choosing an off-the-shelf architecture:***

*This is a good approach for a 50M parameter model. Here are some options:*

* ***MobileBERT:*** *A strong choice, pre-trained for masked language modeling, efficient for mobile devices due to its size.*
* ***DistilBERT:*** *A smaller version of BERT, specifically designed for efficiency while maintaining good performance.*

***Recommendation:***

*For a 50M parameter model, I recommend exploring Efficient Transformers with pre-norm layers. You can also consider MobileBERT or DistilBERT as starting points and fine-tune them for your specific task.*

*Remember, the best architecture can depend on your specific goals and dataset. It's always a good idea to experiment with different configurations to find the optimal fit for your needs.*",r/machinelearning,Z0FBQUFBQm0yeGJkLWxHYkl1ZmpHb2M2Nk54NEhTcS02ZHhwRUNic3VPWjU3V0NSb3JKN19hWjlOdE9RTEJzWVRvb01teHBHOWYyOGRmZmVYSVRfeUdHQjBscmQtSWZJN2c9PQ==
"thank you for your insights.

**conclusion**

ultimate way basically is: feel free to go wherever your train of thoughts goes. make a clear hypotheses out of it. find out how it can be translated into technical form. run proper experiments. represent the main idea in abstract math in case the findings are interesting!",r/machinelearning,Z0FBQUFBQm0yeGJkNUQtb3RvR1p4X3Z6LWsyUnNnNy0yZTc5NjVSOE9zOWNkazdMcHBYQkJzZ1F5dDdaWUpPV2ItMzJWeUh3Mlc2SXlNaXoycDRPUnRHcTEzdmlPZV9VcEE9PQ==
no idea about idiom detection. For what I've tried POS trading with spacy is very good.,r/machinelearning,Z0FBQUFBQm0yeGJkSmJmeWUyaEVsQ3JoUk9TeGdiYlRndnVZSDVCeldWaXJBZ0RKWDIwRWVNWE1xU3dlRE54bUptMWNPOTZrWnhLc3lfZjl2ZERiNUZYbWcxSkZtckE1X1E9PQ==
What do u mean that 果 has no meaning on its own?!,r/machinelearning,Z0FBQUFBQm0yeGJkUkJkeGpzTm1VNFJkYTRodFM4WWp6VWF4UDJHdmVjbUpPSTJLRU9mLWl5cXpDank3U3hHOER4cmJNUS1Sa2haejgzTWhpWmlDei1ZVjlYb3BMU1BCYTZPaGtEQndGYzlCNFZBSkFFOThlamc9
You could replace the author column with a column which contains the average price of a book published by that author. For example if author A’s books had an average price of £10 and B’s had an average price price of £15 you would put 10.00 in the column for all the books A published and 15.00 for all the books B published,r/machinelearning,Z0FBQUFBQm0yeGJkVVBKY1lvMWcyN3NwZzJJNEdlajlvMHdBa3JZdnNlUmFIbjB2bmE2LVlBZVBqTFJqdTdMb2I3V3FQZWtEeUd2Nm85eHkxZFZ2UkR1UWUzQkpRYmVYd1E9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJkOXl1QkpsbERDNV9Zbk1KYUpha29odWVJZmpOZXlMSkktY1Q2YTBVakFBZEs0cERPM3FCN24wdEJ3MnNsVXJpMVdkcjRDWDZhb1BFOU1ZRGNTemZsVHZLWElhd2dYd0dMaXRxTGQyT0piVjg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJkZmF1Rm9PRFg5QWxmaGJRemp0WExIaVIxcm10MUF6TDZXSjJEZTMtXzA4NV81YUM0R3cxNkd1YW91Tk5kamwyTENpOW1SekV5Z1JMQThqZzZmRUtGRVNEZ1RPSXFCZFJmcnJoSUl5Y1BZOG89
"This line looks wrong in terms of IDCG: 


`` relevance_scores = [1 if doc_id.docid in ground_truth.get(query_id, []) else 0 for doc_id in docs[:k]] ``




Your IDCG is then computed like: 


`` ideal_relevance_scores = sorted(relevance_scores, reverse=True) `` 




However, IDCG isn't with respect to your retrieved set, but rather with respect to the entire ground truth for that topic. So I think if you instead do something like:


`` ideal_relevance = sorted(ground_truth.get(query_id, []), reverse=True) ``  


 And use that for IDCG, it should be better.",r/machinelearning,Z0FBQUFBQm0yeGJkQmtDdk1QRUk3UmI1TXozcUd0RTZZX3FLbXo5MF9qZDUzY1hBUkRXU3llQnVIZVhpTmJCWkpyX3REbHpRME04c0Y4am9WMkZJcklYbjhDMjF6U1lTMWc9PQ==
"In general, a monotonic transformation does not change the output of tree-based models. However, removing outliers is absolutely useful, e.g. outlier removal, or winsorization (capping values). Often, it's easier to do so after some normalization transformation, for example Gaussian tail winzorization works for approximately normal distributions. My preferred library for such preprocessing is Feature-engine, I highly recommend it.",r/machinelearning,Z0FBQUFBQm0yeGJkSy00OUNPOXY5UWI4QzVCelFaUFF5UXVLRUxtZ1E0QmZwRWdoTTBKLWZSZXNqZnIwaTZoMmdBUnJaYnFhUzZHWGxNdVZVTjFTb2FPMFFiRzNFWEFXR2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkOVlISGxaSHRmV3RjOEpHM3UtY05BdUk2RTdBVVNyQVhNZFhKcUI0ZEFNaU8ySjhDZ09kMkhwcDNFTm9zdXlkSUJ2eXpYazZlaDB3Q1RGM1BxclBUVmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkbC1ldVY3ZUhZaTZENlBVNlJYQ1YyOVpEbzZwNlZ3c2NkU2JmNGYzNEYtY2lGSE5lZXhZb1gzVF9ta2Qwd0FFN0RfbXBrWEo3eVVVbnAxeVJWS0hoRnc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJkb3RSd2ZMTEdLMG9UOENBYTQzbUltdTRVZXBQd25rVGdmcHdJVjB5ZUFlSjBMU09WWmdBdmo0Y3NLVTllRFpUZ1dyanlKNnB5S1A1YWFzTXFDcXl3ZGIzZ2dIUmlNSWFOLU1UaTBnRDJ2V1E9
"The relevance is just a mapping from the retrieved document IDs to 0 or 1 depending on whether that document is positive or negative for the query. Is this wrong? How else would we calculate a score using the document IDs?

Regarding the ideal relevance, in your provided code it seems like you're implying to use the IDs of the positive passages for each query. How would we use those to score the retrieved results?

As far as my understanding goes, IDCG is when the retrieved results are ordered such that they maximize the gain. Since I'm using binary labels, it only matters that the 1's in the retrieved results, if any, are at the front of the list.",r/machinelearning,Z0FBQUFBQm0yeGJkNjhpMy1aQmtTcG5wYmdHVzFqbXpPSmdYYllsX1FWQzQ1YTVPTUZQWGJaSjZRZU51S2RLTFNxWUU4STU1M1pLYUpUTHY1dFFwYmZrZ0VId2tCZzFhWkE9PQ==
"My point is that your retrieved documents might contain say 3 ""1s"" and 7 ""0""s. But for the given topic, there may be 6 ""1""s. So you compute IDCG on the vector [1,1,1,0,...] but you should be computing IDCG on [1,1,1,1,1,1,1,0,0,0].



In other words, IDCG is with respect to all relevant documents for the given topic, not just the subset that you retrieved.",r/machinelearning,Z0FBQUFBQm0yeGJkZ2QtLXJQRzhMcVBWbjVvc1NyVEhjdndCemo1SnlIekttTEdTcVNnaVVaVkoweGdUMnRnNTExdWlSdl93bWdhOWw4dTVRNkFiMUpqcGZRN21fem41dFE9PQ==
"That would make more sense.

Would it make sense to take the number of positive documents for each query and make them an array with the rest of the array padded with 0's and use that as the IDCG?

For example, if query 1 has a total of 7 positive documents but retrieved [0, 0, 1, 1, 0, 0, 1, 0, 1, 1], then the IDCG would be [1, 1, 1, 1, 1, 1, 1, 0, 0, 0].",r/machinelearning,Z0FBQUFBQm0yeGJkZmxBNHMtRVRnbFhMdzF1MkRKYkxrVVBOcWpNM2dkQkdaWm55MEVnMTdpajVCSC1Oc2hBNVdhb2k4UmMyM29GaGw5V201ZVJrUG9uTXdMcU04eWw5YkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkeklxMjloOHpQdEVQcXVBLUtCS0x4ME5jQ28yVV94cVBMNzRyVEk5UEtfb0FZS2c0c3B1LW5YYjNmdDUwTVV6ZEhfakJkb0UtYzMwOWJuNlJ3ejFMSmc9PQ==
"Yep, that's right. But remember to truncate at k (I believe you handled this already in your DCG calculation).",r/machinelearning,Z0FBQUFBQm0yeGJkQW8xM1lzN0hPaEQ3MWpESjUxVF9iQlNWRzZMLUNlVUV3Q2FoN3U2OGlXalpZaFJkcldhN3VsVVNMWGdCR3pRbEJXajlvSDdLMVYzUVNOaXhHQjlDdGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkWnNBQjd4SGU4TlZqRG5uakhUOUNMNW12RFN3Wko0dzJydjRFSmREbm9SV1htZ0RyZVNRNHEteUFIV1FodGRMVHg5UkFOa1czcEUtV3BxNGJTZzU3blE9PQ==
"GQA/MQA are inference based improvement, it actually slightly hurts downstream performance in practice (See: DeepSeek V2 appendix) but allows faster inference. At this scale, you probably can't go wrong with the basic GPT2 architecture or go for the full-blown ""noam""/transformer++ architecture (https://arxiv.org/html/2404.12387v1#:~:text=Architecture%20%26%20Training.,with%20bfloat16.).",r/machinelearning,Z0FBQUFBQm0yeGJkQzNoV19TSzV5QUQ2dUpLX1NKX2I0bVBoQjUxOU1HRDZPVGpHaDJyaTRwNHBaWG5sR3pOVk5MSjlGSmxLVHBhUmo0REpaMVUzSDJWWTFlWXU2M1ZkVk0yN0hWVWtCZlR1SmMtZTN4SXVlUEU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNS1lYldTSGNwck5SUnVSME1PRE9aNzViXzlWLVNEcUswNnVGRXIyazJzQ3ZWM01DOUtnSkg1SDgyY19CWXRlUHZsbElMdl9SNDhkZ25lbkowTGVNaHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkR2FQSHhPSUs0U19ORjJxckU4c2VlU0V4UlotVGllOWxzcXo3QmRrUjlFQ2NkZFo2SGxNdGp6QkRMdnp0RHlQeHZyLXJvYlduWnc2RThEZGszNFE1Ymc9PQ==
"That’s great thanks!

What’s the risk of outliers when it comes to decision trees? As in, how would they negatively affect the output by keeping them in?",r/machinelearning,Z0FBQUFBQm0yeGJkVDA4TU16V05rWGM3andmSmdsU0pLMnVkR0lodFo5X2FwQkxITmY5VGxNOVF3Vm1jUlNJUzFMX0d0X014em5rbm12Ums5Y2VibHJKVFN3RFN1dnQ1N1E9PQ==
"I am currently working with LLMs, more specifically, try to utilize LLM as an powerful tool (backbone) to transplant some psychology and human behavior studies into information systems, like retrieval systems and recommender systems, to improve the system performance (e.g. improve click rate of recommended ads).

Sometimes, based on social science researches, I can draw simple and intuitive conclusions, like ""people tend to spend more time to spot specific keywords during web surfing"". Then I try to add some hand-crafted prompts to guide the LLM focus more on potential useful keywords among the user click history. However, I found that when using auto-learned soft prompts, the LLM tend to focus some stop words (like ""the"" ""a"" ""and""), and finally works better😅

Like previously discussed, deep learning is becoming more experiment driven. More specifically, empirical experiments are more important these days. I present the aforementioned observation in the case study section, and one reviewer pointed out that, such phenomenon is not new, someone in the CV field has discovered it. I checked that paper, to my surprise, they did not employ a single equation in their paper, and got accepted by ICLR.😂

So I think math is important, because at least you need to know how ML works. But it act as different roles in different levels of research. A limited mathematical background would not affect the research, for example, the first researcher who proposed ""prompt learning"" also did not use too many equations in their work, but he completely changed the way how people utilize LLMs. But math is critical when you try to explain **why it works, and how to make it work better**. For example, the author who proposed rotary positional embedding (ROPE), which has been widely adopted in LLMs, gave a concrete and deep background on how he devised this method in his paper and blog. In upstream research, you may start the idea and motivation from a single equation; in downstream research, application and goal are important, math is used as a tool to illustrate how it works.",r/machinelearning,Z0FBQUFBQm0yeGJkNHNKV0VuQmtGZlNIZW9fU0k2cEtacjR1d3NXbXdxSWgzSjV4cEpjM2Y0S2xTeUlrNVlZbkpnazdQck9wdXB5QVc0OFRURngwX0xua0pIR1cydWpOWUhkWEY4bjNiQllEczBRaXhBWWRaQjg9
"Let me link a few discussions and then summarize:  
1. [https://stats.stackexchange.com/questions/187200/how-are-random-forests-not-sensitive-to-outliers](https://stats.stackexchange.com/questions/187200/how-are-random-forests-not-sensitive-to-outliers)  
2. [https://stats.stackexchange.com/questions/297125/outlier-removal-before-boosted-decision-tree-regression](https://stats.stackexchange.com/questions/297125/outlier-removal-before-boosted-decision-tree-regression)  
3. [https://stats.stackexchange.com/questions/140215/why-boosting-method-is-sensitive-to-outliers](https://stats.stackexchange.com/questions/140215/why-boosting-method-is-sensitive-to-outliers)

In short, decision trees calculate the optimal split by minimizing a loss function. Outliers can affect said loss function exactly like for other models. Their impact is quite less visible than for other models, due to high elasticity of trees and their ensembling, but definitely it's there.

Speaking from my personal experience, removing outliers not only gives you a bit of accuracy / AUROC / whatever metric you're optimizing, but it also makes the algorithm much more stable and less prone to give counterintuitive predictions.",r/machinelearning,Z0FBQUFBQm0yeGJkWXlka2QzOTNBcGdoN1dQOEdzaXlLdzg4dXlXZktCaXZyZ0NENkM5SHdYNllYaFRpbVpQcldiTnVfSXhaQWdQeHJCMDNrQ2JUMjJiekRqTlQ3TGFTY3c9PQ==
"Newer editions generally add a few new chapters, fix tiny errors, new foreword, etc. but the core content/personality of the textbook will not *drastically* change. (Among other things) it says new sections have been added on pseudoinverses, QR/Cholesky decompositions, and perhaps most personally exciting, approximations of linear maps with lower-dimensional range. Any ML researcher will benefit greatly from knowing this material, especially the latter topic, which is highly relevant for compression.

Axler’s text is an absolute classic for mathematicians, be it students or practitioners as an excellent reference. So, if you haven’t read any edition of it, then I highly recommend having it on deck physically. If you’ve already purchased it, just check out the (free) online version of the latest edition for any new content.",r/machinelearning,Z0FBQUFBQm0yeGJkdmtJZFhHRFNPRWlOTmdJYjNuWXI0T1JZenJhaVJPelBfS0dQQ3IxSFlYVDJzbkVZeFJSYWItdzI4a0UxVVdjcXpfMURHdXVfWU5SWHE1MW5DZTN0WFE9PQ==
"That’s super helpful thanks, I’ll take a look at those sources ",r/machinelearning,Z0FBQUFBQm0yeGJkeW9BV2duVWlKZFhmSHZKWDJITjFBLXpvLWptMWYxaHhZRnpxT2VNUDBsWkFXVlExcFl4SUd3NHBNMHdxMkhrYlRSSGwwTE1adDc2cmVHU0pZRGkzR2c9PQ==
"We have to know what size of a model you are planning on training. Most likely, unfortunately, what you want is unattainable. With 20k you can (maybe) get a setup with 1 A100.

To answer your questions.

1. The choice between A100 and 3090 depends on your use case. You can work with a bigger model with 3090s but it is going to be much slower. I would say 3090s/4090s are your best bet.
2. In 2-3 years, 3090s are going to be 6-7 years old. Compare it to GPUs that came out 6-7 years before 3090 (I believe it is GeForce 800/900 series). That’s a massive performance difference.
3. Unless you find better deals that are pre-assembled, it is cheaper to build yourself.

Why don’t you rent from the many providers that are on the market right now? You can rent newest hardware and, when it is no longer relevant, just upgrade to newer GPUs. Additionally, it saves you from making a huge upfront investment on depreciating assets.",r/machinelearning,Z0FBQUFBQm0yeGJkWFI1RHdsT0ctZHl1TGlxSE9DMXVuVWZpMjR3OHNTZDJXRkRMOTVsaHh5MExwVWh6NENpSWVWOHM0NGI1dGxHNlpTRW82ZVZrSGQ3cXVQSHl3czZhakE9PQ==
"interesting! 

thank you for sharing",r/machinelearning,Z0FBQUFBQm0yeGJkcmFKTlg2WVRkVklfM0VuYk9YaEZvSHdHNk1USDNiMUhKeWZDMVFpODVlOXh1YXZxQzFScE1yelQwc3pOeVlFdW5PYU1QaEYwa21URE1ncktYaTRDeVE9PQ==
"Since you didn't mention which exactly field of ML you are interested in, I'll give it a shot for language modelling. (Simply because I'm not partucularly familiar with other areas)

I recommend to start from some survey-like work to familiarize yourself with the main concepts. Section 4 in [https://arxiv.org/abs/2312.00678](https://arxiv.org/abs/2312.00678) will cover the basics. For more in-depth dive see [https://arxiv.org/abs/2402.16827](https://arxiv.org/abs/2402.16827)

Some interesting recent works:

[https://arxiv.org/abs/2402.09668](https://arxiv.org/abs/2402.09668) - a great paper in terms of breadth of investigated approaches

[https://arxiv.org/abs/2402.09739](https://arxiv.org/abs/2402.09739) - calculate rating for docs in the dataset, sample with both rating and diversity in mind

[https://openreview.net/pdf?id=uPSQv0leAu](https://openreview.net/pdf?id=uPSQv0leAu) - method to match sampling with target (""high-quality"") data distribution. A rather prominent paper

[https://proceedings.neurips.cc/paper\\_files/paper/2023/file/dcba6be91359358c2355cd920da3fcbd-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2023/file/dcba6be91359358c2355cd920da3fcbd-Paper-Conference.pdf) - optimizing domain-level data mixture

[https://proceedings.neurips.cc/paper\\_files/paper/2023/file/a8f8cbd7f7a5fb2c837e578c75e5b615-Paper-Datasets\\_and\\_Benchmarks.pdf](https://proceedings.neurips.cc/paper_files/paper/2023/file/a8f8cbd7f7a5fb2c837e578c75e5b615-Paper-Datasets_and_Benchmarks.pdf) - semantics-based dataset deduplication

[https://arxiv.org/abs/2402.14526](https://arxiv.org/abs/2402.14526) - semantics-based docs clustering and reweighting

[https://arxiv.org/html/2401.16380v1](https://arxiv.org/html/2401.16380v1) - one of the first attempts to augment the training dataset synthetically at large scale. With promising results",r/machinelearning,Z0FBQUFBQm0yeGJkcHZuQ29iOXZGc0J0RzVURjRJVWFtLWVodjBzRFQ4dXhIcmtIQXlfUHZxUlE4WUdEaUJVNXRQNDlRcnRyQ1dkNGZGcjFHVXpsMWdkeGZwTzNQSnRFNVFBbEF2RGNvbzNoXzd6VHFLOWlBaDg9
"Can this post help you? It covers many aspects of house cooked ml. Check the other pages in this blog too. I found it very valuable.
https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/",r/machinelearning,Z0FBQUFBQm0yeGJkcG5UT2VQWTZIa0FoMk1Fcmk1Y2ZDVDZ3RjFuM0VNM1UzeXZfbjZWbjFId3c3ZzVMdlhneGRjRWU3b0NtOVk0SC0wcGxJSVoxay1CeTh6WGxlcUwxMmc9PQ==
This is really cool. I guess you can really model any problem as next-token prediction,r/machinelearning,Z0FBQUFBQm0yeGJkeG9TMW8zekU1WDhtOGdNa2RvWF94bDRTdmk1NVlxVGZ6T3oxSWcwanJlLTl2eU9XUXFHWDJfNjcxb3ZwSkpBa2dqaW1NZW9zN1lXZ1BLSW9nUmZnVGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkOWNJU2dSR3daTjZqWHdnVlpKV28ySDRzQ216TGtUejFXMVl1c3ZKTHBNNE5ETTBpY0twQzBodUVGY21xQzJLNldoUmM4SDhQblUyU3NVdGxNN0xDS0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkVmZtdmlBeFczZWp2OWtOYUFuaVg3cjNsbUh5amJERUNQcVE5a2gxY0VRcXkwRjd3QXh6MkhnYjlpdzRiMWY2OU9RMm94ZTNENDRKTjhCb2VMalJoTmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkN3JpWlF6bUU3NnVUZ1NqQnZ0N0xUVWJPcUROZ01yNktSbWxsTDFKUHpYV0syb1p4dkhtWEhuQ3pwQUJMbGQyME8zTXY5aDdTR25MMDVlSUZ1ZHZPNlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNnhjOVhKblNIeldSMUVrTnRqNDlFMW1NVDA5Tll2UnFNRkRWOVkxS29OUjZfMjVnWlBYT1hDekM3UGRQclo2S0lmXzR1NEJMNTlrU2tJZ3EyRGw0cVE9PQ==
"Similar question, what are you using to feed it asl grammar?",r/machinelearning,Z0FBQUFBQm0yeGJkR3dJMXJON2RGandGa0VhOFEwRjJxSGl0U0QySkNrLUt4bWxlUkhJUUVaelB3NDJKcWFSMlpxRkZBZTU4NGw5Q2dadDBkVWZiUnBCbTFrV1Vlcm01Tnc9PQ==
"Are you doing this because you want to learn or because you are trying to train commercially viable models? 

$20k won't buy much of an LLM training setup. In either case, your investment will be outdated within a year or 2 (probably sooner because that budget won't get you anything cutting edge) and you would be much better off renting than buying. This is because you can't run a setup at the leverage of the big providers and you can spend your budget on renting the newest GPUs.

You might be able to get a single A100 and train representational learning models (embeddings) or perform PEFT on small models. You should price insurance that includes replacing components that wear out.

tl;dr your stated objectives and budget are generally incompatible, if you can share more about the types of models you want to train or fine tune, we can probably tell you either a) how impossible that is or b) a smaller setup or rental setup that would work",r/machinelearning,Z0FBQUFBQm0yeGJkVW1VR2xwcDFNaWUwX0lOTi1jdGFjejZyQ3lMZ2hUZFZiQTFTWGkzaDg4YmFYMkFWUXdmbnNaYXJZVGtZZ1VXa0p0RlVxR21YdUp5ekRjaXhpVkRuWGc9PQ==
"As far as I am concerned, if I understand what's written I don't even care if you have serious typos.",r/machinelearning,Z0FBQUFBQm0yeGJkRkhyaWJRb2JjRVlqdDlNSFpYVFVIVFpGa2lKcHNnVW1Nb3V1QlRidGdVc1VQWmllRE1Ydnhnbjd2WVFNNDdKVWRLQVJXQ1RsZHJmdGszMXdNdk9nbDZ5QXB3MlNzbHRGN2xSazZFaVNfTVE9
Thanks glad to Know I can count on it,r/machinelearning,Z0FBQUFBQm0yeGJkcV9XdGNNRzVBWVdkbk42QndvcWFiNE9hc2NyOHNWZHdKclVfVE9SQ0hTMWlTc0Z1ZThFejFXN3BLMjdrWEtpM2lhTThsR2d4Y2FYOW0xelktWHJ2VFE9PQ==
Ohh okay okay,r/machinelearning,Z0FBQUFBQm0yeGJkTi1la0dOSjE5bjF0M20wNV9uc2hVQmxLelg4WGpQeGxld1N4dVNyM05SU1FJTmxNNkxXQ0QxYmFPUFZENlZmSlRwVmFxbmZGWW5GR05DWUFDMWNZTlE9PQ==
still invalid,r/machinelearning,Z0FBQUFBQm0yeGJkWHRZN2dzVFBWQVp3RjVNU056eTIzY2lrUnJKcmU0R0RqNlRqRWpjVU9xRFZpQ2M1SHNWd19QNkhZMnhfRDJyaHZ5b0k5SVRGSXlRR3dFRElwZkp1UEE9PQ==
Unless you’re able to hit 24/7 continuous operation of your hardware it might be better to rent from a provider.,r/machinelearning,Z0FBQUFBQm0yeGJkTVNSLWc4cFg1SDh3Zm9oRDlQTUItcUc2anJTeExDMjhCRndhdUxQTHpScjZZUUkyc1l4ZHVqWl9yVEw3cXE3LVBPWFVEVm5kWEE5cVB5OEh5TGZXY1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkbEhaRXNkUTI0RHdqbXFHdnFGelgzRjdqSkV3cm95UV93VTdzNXFVSUt3WjBnaVRudzcxZEQ0TEZFaldPbGtaQkxrakdPUW1ibWJMcm83djM3N1NOWlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNUJleWJEVzJ0azFJLXpXN3YtMl9GNk5WU01EeDA0dmtMVzdSeWFWVTlLei1JNmVtenF1eDdBelVwT2d3ek9NbmQ2cWItYXNGX1VKLVlTNU40Q0YwUHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkS09VVGJrZkRHUUVWbUtrakNUVl84OFJ4akV1ZnBCSFpkSk5pM3N3b3pWVFRxTGticWNta3FpcEZ2WVpfN0ZiOHpPZ3UxYVpVNGJjU3NwMklDX1k1UUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNUlaNU5POHFUQnJEZ1p4d3gwN3RmSEhNd0RzWm1XLVE5YTJiNUU2OTNidUdvWmpEU2NzdzhPZ05jTDd4cVIyMUNYU3JhYXFkaEhObVQxdHNaNENzcHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkS2hDSnEzMmg4bms5YU43Vk55dHZmTW5QSUI4amdfT1FPRm1yX1gxcElmdmdiV2J5RVN0RlAyMXNmc2MwbTFrRk5UVEFYYXRUSVJ6b2hVeWN0WmxPZWc9PQ==
"Does this seem competitive with building your own: 2x NVIDIA RTX 5000 Ada 32GB GPUs  
32-core AMD Ryzen Threadripper PRO  
256GB DDR5 system memory  
2TB NVMe storage  
$18,749 

https://shop.lambdalabs.com/gpu-workstations/vectorpro/customize",r/machinelearning,Z0FBQUFBQm0yeGJkSEVCUG1ubkVqbURlRC1vUzBJVTRBTll3Zl94eWI3VXpwYURGRmdXODFjR0hKeEcwUHdINUp6Nnlsd2dTcXNkcnVURnp0NFVyUjBNZEctTVppTVhSVWc9PQ==
It might bring out math understanding problem,r/machinelearning,Z0FBQUFBQm0yeGJkZjkxM08yVkNpTEc0ODRfc0dZNkZwa3lIZS1ZMzZFOVN0OHNGZmNiWHFYUGlYTHdNOV9tVzFYazFfdlQzSXJ6cXpJdzd6ejNXVlZ0dEp0M0tNaHo5bF90T3E5anFlWWdRR2drNWQ1NGRxeUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkWjJjc25mSlIzdm5ZdllfZ01VVGs1QWxEYXV4NG9RNWFZSjltTk9sYUV6R0tOeVdEN0VPM3FqNXB4M0tLaWFwZnU1UG5HM0pNZ3d2OEEtYnp2V2RHckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkRXhIbmgzUWowdVJTUlNHMlVnXzRlOHl4Y1BSSDJaSjhaSlFHSDd4bGdoQ2FGdTVKeS15MllPSTdKLWt4Y1VtSHE5eEdmMUltS0hEWkxhYkF6U0ZMSEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkRHFoOERhX3Y5ZnFBSk10MlFmekdOSWR4S3ZKOUc3VEFJQjg2WHVwYXBzRXdSTG1JbThRazU4aVZqUWN2QTlpZGJRU2ZwTDBST25YUVFmbVEyVkVrTnc9PQ==
"Appreciate the correction. I've updated the numbers based on what I could find for a better search.  I don't know how I got to RIKEN instead of one of the others on Green 500.

I've updated the math of the original post.  Thanks again.

Complete tangent, but ""This is a meaningless number ..."" as a phrase has a certain set of connotations in my eyes.  It may be useful in future persuasive interactions to try, ""There may be better numbers to use as the basis of comparison, for example, ..."", or, ""It may be more accurate to use numbers from more modern GPU supercomputers.""  Front-loading ""this can be better"" instead of ""this is bad"" and suffixing with alternatives tend to lead people to the actions we want with lower friction.",r/machinelearning,Z0FBQUFBQm0yeGJkSE5peHlUUERuWUp4blNiRnF0cE1aclN0Rk5WQzhudzJWQmY4M2lzOHNuQUVNQlRtOTJrWUVzTnZ3X2x4T1VwTU5PYnZVX0M0WVNoTDVHR0N2NTk5U1E9PQ==
"a really simple way you can investigate this sort of thing is to search find the article in google scholar and then click the ""cited by xxx"" link to find articles that cite it. That particular article has been cited over a thousand times, so it seems likely it's been built upon :)

https://scholar.google.com/scholar?cites=15300779753326541860&as_sdt=5,48&sciodt=0,48&hl=en

The fractalnet architecture isn't ringing a bell for me personally, but scanning it now the structure reminds me of UNet (which definitely does leverage residuals directly).",r/machinelearning,Z0FBQUFBQm0yeGJkWmtvOV9QMkFtRnAybjZaMW5BZVRFSHA4SkZTM183MG5OQVBIUUxJMkNhdXo1MEpMeU9fM2xtSnVOdk94TEhOWlJYY28xNnQxSFV0T3JFVHJNNENMcVE9PQ==
Is the title some math joke I'm not understanding?,r/machinelearning,Z0FBQUFBQm0yeGJkcmdTUUItekxYUU1naVlUVFJHNXlBb2w3NTZ5b1JmajlYd2xYWVNIVWZZaVlqcXR4YVgtT0ZkU2R6bHAweGIxd1ZkUGd5NXZSNzJkckZlRURERHE1Mnc9PQ==
"You didn’t state what your reason was for wanting to build your own setup.  Unless you have a strong reason for building your own, it seems like it would probably be more financially beneficial to rent the compute.  It will certainly be much more future proof as switching to newer GPUs will be the click of a button. 

Have you done a payback calculation of any kind comparing the capex here to the cost of simply spinning up GPUs in AWS or any other cloud provider? Unless you will be training for 8+ hours a day EVERY SINGLE DAY it probably will come out cheaper to not roll your own solution.",r/machinelearning,Z0FBQUFBQm0yeGJkazVsT2pLVDNld2NoeGRvVl9LNlVWemtwalFUVEVqYThia0lQM1lkR04ySjJyX2xKeFJjekNKa2lFVmdFd3BVVllfNmZ5VmpQeHJkY3pwTUpLM2JHRFh5TWp4dk1tSkdHbk53YUZtZHFISFU9
thank you!,r/machinelearning,Z0FBQUFBQm0yeGJkcXNXQlJxcUhteDc1Z1Fud0tTNXdBLXhqam5USmxkelcxZTNOYXFCZHFXcnlzNGJ4NFlMQlRxa25rVTREUnk4Mi0xNVBMTlRzdml3R0hCSy00WVlhM3c9PQ==
"I didn't want to complicate the post too much, but I did do a followup explaining your questions here - [https://matilabs.ai/2024/03/05/slerp-model-merging-primer/](https://matilabs.ai/2024/03/05/slerp-model-merging-primer/)",r/machinelearning,Z0FBQUFBQm0yeGJkam5TaW9BLTMxMllXeTU3V1N2a0tqVV9tSndjZDktOUdwVUEtNE9UQmtaWU8zY0ZuMElBRjl4eThaR0xiUlNSN2NtMm1peDFJSkVTTnU1WHN6TEJ6aHc9PQ==
Hahaha it was accidental but yes it works as a joke.,r/machinelearning,Z0FBQUFBQm0yeGJkWkVCcjBrczRmMmV6d19VVzhCWmVmaEdyME1fbFNQTTNhYWNCM3pEZHZIMmgwSk9xTjBNbGtBNWJtYVpWTDR6d29iYldMcFhNUnFlbWM2YTh0SkkzUkE9PQ==
Hey thanks for the info!,r/machinelearning,Z0FBQUFBQm0yeGJkajNLRUZQalFQXzlJTVZLV0g3eTZpeThPNmVzYTlBYlJGN3J0akZ5UXRLMnF0MF95UUNlNUItNGVWZ2NxU09iOXZUeVlKUXVFRDhCeDF1R0lxM0wwN0E9PQ==
You'd have more luck and better end results pictographing English than using Chinese then adding a translation layer.,r/machinelearning,Z0FBQUFBQm0yeGJkOGRpU3F3T0dKaWNmZkpTZDFmTXdoSEpYVmRxZUhrdGR1dkhycERhS1ZLODY3d2k2TmQ5c0xBZXhlcWdxRjRzNDlzb25IRWZhWFZETk5CMVpWdVZ3Ync9PQ==
I don't want to say something stupid but I was under the impression that tree-based models don't care about feature bloat since they are greedy and will select useful features automatically while ignoring the rest,r/machinelearning,Z0FBQUFBQm0yeGJkX0pTZlRjeFNkRmxFX0kzRG8tMTJuM182ZEdrXzZXczJ0U1Mzbm5nN2Z6dFhNc2N1WjRDMUVlZ2xrNERGZ3RZREVHX01MRktrbDFjOEZ3S3ZCRkt6Umc9PQ==
"A lot of people suggesting to rent here. It makes sense to do so if you're not sure about your current/future performance and memory requirements.
If you are relatively sure, you can consider buying if you expect to get a high enough occupancy.

Lambdalabs has a good article about this for calculating [cost of ownership](https://lambdalabs.com/blog/tesla-a100-server-total-cost-of-ownership?hs_amp=true)

A good idea is to try out your specific workloads on the GPUs you're interested in.
You can try out 3090s on [Backprop Cloud](https://backprop.co) (I am a founder there and happy to give free credits)",r/machinelearning,Z0FBQUFBQm0yeGJkcHRFV0VpWmJPaWs4Yi1odVNDc3c1MWhqRWlqbC0wdk1fdW1VUTZjSFRna19nTG1QU3lrYjNiZnIwVWpNUWNncnF0TTMwbGNaTW5TdlcydEtXWkhpQmc9PQ==
"It looks like you shared an AMP link. These should load faster, but AMP is controversial because of [concerns over privacy and the Open Web](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot).

Maybe check out **the canonical page** instead: **[https://lambdalabs.com/blog/tesla-a100-server-total-cost-of-ownership](https://lambdalabs.com/blog/tesla-a100-server-total-cost-of-ownership)**

*****

 ^(I'm a bot | )[^(Why & About)](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot)^( | )[^(Summon: u/AmputatorBot)](https://www.reddit.com/r/AmputatorBot/comments/cchly3/you_can_now_summon_amputatorbot/)",r/machinelearning,Z0FBQUFBQm0yeGJkTGNZNndzcDVoZzNRai1KelVJMldYM3NKdXl1MTNpcjJQUlRzcGp3VHM3Sk9Id1lWV3lPOVItUDFadnNkTGpfZU1PRkI2alBDaGFWUC1mem92OWhLQ2c9PQ==
Sometimes you can´t run it effectively without dealing with feature bloat. This happens a lot if you have a feature store with features built for a lot of different contexts and you are fishing for new features.,r/machinelearning,Z0FBQUFBQm0yeGJkYjFySXI0eGxfZFlZR0o2YjVETnpHeXpQcGtHcklPeWZDVlNKRXp3a0NfMHNROWZlSHBSU2VNaEdnUXRweUttSHdLWWVJUHJvYmZ2YjNhVlNBSnNiQ0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkSXl2WmZvTENPdERkdjlEOE5acWlxWVVzTlV1THJUSWZmYkZLelpyOGlMM3g1a1E5TWd3OVgzai14d3JERkFHWE9VXzg5Vjl5ZDNVQmlkbUlwTkVfM2c9PQ==
"Method 4 is often underrated, let XGBoost do its magic!",r/machinelearning,Z0FBQUFBQm0yeGJkcUI5Ymh4VUZVdG1OSi1zbTYzSlo1MC1EU09oVzZCTmVydklLU1VTNVVYb1RrbXBYRFhod2FVR241a0c0YU9KcVhxWnVvYUlPOUE0NHJDRXdtN01sbldsU2VzUGtxbXdHWDZKZTliT1Q3OVE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkOVAzVVJxdFZNMFJmNmgtSGE0N21XamNrWVBpdHpNZHk1Tm43OW1tSjNXS0FoTktkai1QQWJ0am9aaTVYWVNXVFc2NlE2Ul9aX2lET1dVQ3UydUc5VUE9PQ==
"What property of FractalNet interests you? I’m not sure if there are any direct successors given that many of the papers citing it are reviews or domain specific application.

If it’s the fractal nature of the architecture, you’re probably not going to find much. You will definitely find newer architectures with residual free or early exit properties.",r/machinelearning,Z0FBQUFBQm0yeGJkaGR6ZkdZcVpiSjE3LXpuZVlfZHQ4eXd5QUNZZDc2azIwTWFtUkNoLW9OU1R0QkJNdmUycnVORkZyNUtaNkFKMnloUDU5bWJvbmlRLWR6ZWo5aVBsdmc9PQ==
I have always struggled with this thought. Is it really the only way? I always try to push myself towards mathematical thinking to reduce my trial and error approach. But I still don't seem to get it. I don't have large compute in my lab.,r/machinelearning,Z0FBQUFBQm0yeGJkd1lOclJVTl9LbEU1QVdTVVEwUXdvSzhwN21FOTBqbUZOOWd2aGthMTJBeTFUUHNNRDNqZkE2dmdyekdJY2JzOHBXeGFEcVJuZEhEa2c1V0Y0M3FvOXc9PQ==
"I want to clarify that I am not saying that intuition and induction may be helpful (especially when working on specific applications or domains) but in general I would say having access to a large amount of compute definitely helps. 

At the same time, what do I know. I am just a student that may be scapegoating my lack of success on compute rather than accepting my own faults.",r/machinelearning,Z0FBQUFBQm0yeGJkNF85UDdoX3hpMXo5Zkx4WmxZQ2dta284MWJncmItR19HZEY5YWg3LWFRbUR3Y2dPM3hkN1VmR2pYalFzNUxkLWtXRzZYdTFwWDRYVDlNZUoxUzNzdnc9PQ==
"The main problem with kitchen sink approaches is when you need to put the model in production. Generating every feature can be costly or time consuming at inference time. 


Additionally training on more features also takes longer, which is more cost.",r/machinelearning,Z0FBQUFBQm0yeGJkWmsyYXNpTk1FT0lVWGlBX1NoVV9IZE5aWUpZVXZoNEszeFpQNHNVX3dvZGRWTjR2cFEyYVM4YlBidk04b2lMSndheTIyaXBFS29obURjVmFFVV9oTmc9PQ==
Others have explained the learnable parameters already. For understanding it on the code level. Check out the PyTorch scratch implementation: https://github.com/s-chh/PyTorch-Vision-Transformer-ViT-MNIST-CIFAR10/,r/machinelearning,Z0FBQUFBQm0yeGJkV0cwVXpwbGF4M3BqemxodWVSZzJoQ2FBcWtZa19PTmp3RFk5cUc1ZUpnZW93Q1VyVERyOWNhR3FyemxieVdoLXZoNlJSaUtxN1hYY0ZoZlB6MmF2b2c9PQ==
"The part that interest me the most is the multiple sub-paths that are found within the FractalBlock.

This and the regularization of such multi-paths!l structure.",r/machinelearning,Z0FBQUFBQm0yeGJkeEVuUTdBRXFBZmFSZUJMdDBDTUFJWnVIOXFXaGlTNnBzMVdYaVZDUW1IZ3RzUk1EdFNmZDBidi1iT2RDaFdHU2tSV3psRHB4eXZQSlpCWmJYS1g0LWc9PQ==
Would this still be a viable way to reduce corpus size? The Chinese translation preserves the semantic meaning and is considerably smaller in size. Although the amount of tokens is roughly the same the amount of storage necessary to hold all the data would be considerably smaller no?,r/machinelearning,Z0FBQUFBQm0yeGJkYWs3ai0xMXhpd0NuWDBvVXFncE5ua2p0RUVWNHNCMGRrS01Rck5KV2RpN3NWZFdNVk9ta2REQ0pqb2lGb3dJSEs5OGFYV1A1VjVMTXgtSE5hTF9SV3JFU3RPU0xFeDQ5SURUMXRMeC1MelU9
"Purely speaking from a storage efficiency point of view, would this work as a way to conserve semantic meaning in text while reducing the necessary memory? UTF-16 encoding is very efficient for encoding Chinese language as the 20,000 most common characters are encoded using 2 bytes, as OP showcased Genesis was translated to Chinese and using UTF-16 encoding the necessary storage was cut in half",r/machinelearning,Z0FBQUFBQm0yeGJkM003R1VUM0N4WmdkSmpFeXZZQnRsakEtc3IyT05nNWxFSy1LMGJ3WmFWeUYyQkR2M24tRlFBWDdiRTVtRlFoWlUwSHp1YjFlcFM1c0xPN3ZJVG1IOF9Dajk5dDVVQ3dJTGw3MU5PbHlJS1k9
"As a lazy person, I wholeheartedly agree",r/machinelearning,Z0FBQUFBQm0yeGJkWlBFdld4bkNQN2ZMeE9KdnJ5OExSLThRcWx2OUdRVEdrbG5PT21xV2pRX3h3NkRzT2lHUXJEaEZaVzFITGgwTVhUT0dlSWV0ajRvU1VMSTNoMnB2THc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkX0RhTjBINUFvNkpfa2RFYThUSVVZaVB4dF83dklUSnEtRXVTM09uYTRXYXJzLWQ2M1pEejZ6LWcyWmpsN2VNZWgyRG1UVkdXdGY5X1l6MmtMVzVYR2c9PQ==
This is the one I used as a general guide for the last year I think it’s good,r/machinelearning,Z0FBQUFBQm0yeGJkTi1lLVltYnEweUV6VldacW9PNWVHRVVWS3NveXVraV9GaVNfSnI3elRSNUZnTkxHZXFfR0N2dTd3cTJacFAtTG1TSTJQQ1lRSjVLWkphcFNoSkRSTzlDcHZUbDZjeENMUDlHNjk2dzlPZFU9
I've found Method 1 with Shap values to be a reliable approach for feature selection in XGBoost.,r/machinelearning,Z0FBQUFBQm0yeGJkb3JpUlZxb0VzaFBwQ2ozbmFnT1pMNkp1bWpQOTlxZFJ6RkdhalBITHBoZ24wR0ZhTDhucGZxZkVId0N4RXV4aFhXYlZYaEF2bzJtZlpQbVFwTTJveUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkU3hmWDVZX0IzSUlvSWtaWTdNdWpPUklYenB1Zi1WTzJfX3k4NE5JTjFvbktXaldKNWdKVlJ5clp5dmNpei1OY2FQSkNkem5nM0c4OG0yQmhtdjlIUkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkUHNsdXZaczJDVTl1ZWJhbXVNbGNUNW5vQnFUaFhxbVd2QU5BOEpqLUVfWm1iTkFaRGs1Q1YwUEFSQmxPX19yX1FxVF9TTzN6eVJjQS1BSUpHR3VGclE9PQ==
"Yeah, I’m looking into it! I talk a little bit about it in the video: my current plan is to learn more about RNNs and LSTMs, and I want to look into how I can use the parameters of ASL like location/handshape/orientation etc to narrow down signs. For example if the person’s hands are in front of their chest, I’ll only look for signs that take place in that location when classifying.

There’s definitely many many more complexities though:
- the computer needs to somehow know when one sign ends and another sign begins, and that’s a really hard distinction to make
- directional signs can be challenging. For example, “I’ll help you” and “you help me” are the same sign, but the former starts out at the chest and goes towards the other person while the latter starts outwards and moves towards you.
- And of course, facial expressions and other factors are also incredibly important. Signing without facial expressions is essentially like speaking with a completely flat monotone voice.

It’s a really really vast nuanced language but chipping away at it one step at a time will hopefully continue to evolve it into a better software overall :)",r/machinelearning,Z0FBQUFBQm0yeGJkR2wyS01yT0FUWS1VMW51d1pycmEzelBzdXpHdzJ2RFpwenN4SHQyd3dqS1NGZVEycUVWeEhpcmFsQnRvMVhPTU5sdjg3UHppcWl4RG82OHI5bDZiRVE9PQ==
"Totally agree! It can even be a problem during training time if you are working with large datasets.

Using 300 features instead of 600 features for training might reduce the amount of RAM needed by a large amount and means you can spend less money on a cheaper compute instance (assuming cloud training).",r/machinelearning,Z0FBQUFBQm0yeGJkWEJscjZuSEU2dzNlYlFGLVE3TTZyamI4UlIwcVNyeG1KNDN2Q0lJWEpCSUlaMDlwVElOMEJpMmxjU3ctT1ZDTlJSXzJFcUtITHN4NlFUNFk4UXN0Q3c9PQ==
"Right now to convert it from written English to ASL Gloss, I’m just using an LLM to rearrange the words into object-subject-verb order.

- I can definitely improve my prompt to make it more effective and I’ll be working on that soon.
- I also want to look into how I can use NLP tools that are actually built for this kinda stuff instead of just using a general-use LLM.
- I will also look into the most effective way to add things like topicalization, classifier and non-manual-signs to the gloss as well :)",r/machinelearning,Z0FBQUFBQm0yeGJkTmF3V2xDXzhtVEhfV2t1V05PSDhRN05IdmJZX1hCLWp4dUxnQmNlTE5Bbnd6c3NKTjExRVdFRlBFek9sekVpT3hHZ1JUNTZBdUpuQ0FRX0I2SWFNR1E9PQ==
https://rahulschand.github.io/gpu_poor/,r/machinelearning,Z0FBQUFBQm0yeGJkRjJsWVJpZGx1ZUhRcW9KbkNfaHFURnREMmJjMnVyV3pSMURuWDFQdkhmaUtjQWFKWnhfaW5NVl96b210THFOUENwWGd1a1JpQWVMcHZONjEyU3JOX1E9PQ==
"Remember that one floating point is typically represented by 4bytes in the GPU. So:
```
7B parameters =
7 x 1000_000_000 x 4 = 28GB
```

You might find the quantized version of the model which reduces the size, but also lowers precision. For example:
```
Q8 = 8bits per parameter = 1byte
Q4 = 4bits per parameter = 0.5byte
```

So 7BQ4 actually needs:
```
7B parameters =
Q4:
7 x 1000_000_000 x 0.5= 3.5GB

Q8:
7 x 1000_000_000 x 0.5= 7GB
```

Of course this is  back of the envolope math. But the real number will be somewhere around that. 

For fine tuning, this number actually needs to be multiplied by 4, since you need memory for the gradients and the state in the optimizer. There are tricks like Lora, that reduces greatly the memory need. I can't recall the exact math now, but I do remember that with 16GB you'll only be able to train quantized 7B with Q4 lora. 

This video explains it very clearly: https://www.youtube.com/live/g68qlo9Izf0

Hope this helps",r/machinelearning,Z0FBQUFBQm0yeGJkUDZSSGNwZWwxOEtHaXJwaC1faW1ralMtbnhBcW1MckVPNVRaeFZkbTJmUXE3MHd2T3VySDBUQnNheVJJMklkTXhTRUFoemZrdHZCUUZQTnV0Z1BWelE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkaW1pVlFGZk5YWFZaZ2EwVG5OeHV1OVg0akRsYWFtN3V4X3VhdEJTLVV6TGJyYkhFUXE1WHVRTmtTWmJZdUx3NG5ERmlkaTltNTZXd1o1TzZoMUdrQVE9PQ==
"Why make another wrapper program when the base model you're wrapping i) already runs on any platform and ii) is functionally useless? 

We don't need more middlemen. We need better base models.",r/machinelearning,Z0FBQUFBQm0yeGJkZ1B5MG4xbTJWaU9uQ3NMam1PN1A5Unk1Mk9IcGQyVWNCN3NkYU9DYmtTUU9EZ0M1VEh0b0ZwUmRjQmQ2Q0hGa1BkQ1BvT1pHNzNaRGFtSzdmRjZ5U1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkdDlfaGV5LUpxcm1yT0xDYWRSX3pId191UUMyUF9ubExrczRzd3JZU3BvN1ZpNl9WcjczWldabDBNSzMxZkVOMHN1U0ZuWURvLUxxVDVWdlJldlI0dFE9PQ==
Example(s)?  I like the drafts better than the published version because easier to work with on a workstation.,r/machinelearning,Z0FBQUFBQm0yeGJkamNpaWVNdThxXy1OSmI3ZjEyTmlHUmRJdFFoU0I5QjZLVnBMaXdhcmE4Qmo4Rm44RXNoY2dXbUcyMGFHbFVrSko2V3hnTzk3bkswNlJWelhhNWhhOFE9PQ==
op can make whatever they want,r/machinelearning,Z0FBQUFBQm0yeGJkeU1OUlBWQWh0N0V3N2swa3R1eFNCSk12ZGJ4a2xHdUxXQ3RWN2taclJIUlVxcWh2Z3ZOOXlWM2kzTktsdkpCNy11bEFra0pKSEcwRW8yNjgwbVNtNlE9PQ==
Expecting some random guy to build ~~base~~ foundation models is hilarious. Do you even know what is needed for that?,r/machinelearning,Z0FBQUFBQm0yeGJkY3IwYmx1QTRGWS1Xckl5dTRaUXZ2aE1yNGZhc3ZlY3dDcnROSDdNM1pnYmxid3E0ZXpUcFN4LXlOczducDlYdUVXdVEtTGFvbDJCZXJHZFJWYVlENmc9PQ==
"Also, what do you think about [AgentBench](https://github.com/THUDM/AgentBench)?",r/machinelearning,Z0FBQUFBQm0yeGJkWW1KUHJrcE5ZYVFYekE1NXU5UnhMRTRSQU5aRUNQN2hYcXhJc3JpRDhxYjY3eHpEQkY2eVBtS3hpQnRGYXhXbFp5TlJOUW1VQTZCakdhS0p3UlEyMXc9PQ==
"1) is reasonable, but you could also try doing some kind of explicit feature selection. Here’s one option which has a reasonably maintained github: https://arxiv.org/abs/2107.00219",r/machinelearning,Z0FBQUFBQm0yeGJkcFJMbmxfV1BsSnhWeE9oTlEtUG5OX2RJcGVEUU1sT3ZjWGIxLWNTdWxSaFFBeVM5cmN2a0RFUEdHZE0zLTJFZm1ZT1JoczhERTBJaVlqWnk1LTNOdkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNS13TTZmQUxlNGdZckc4QmV0Q1k2M1N4aVo2bFhLcGN6RU9QRUk0Ni15Rzl6LTdRRllwcWVxY1RHZlpyb0tBMkVNTzVZN0x5WXBvRjVmWDRnV25JdlE9PQ==
"The first approach increases the compute by increasing the embedding size and reserving tokens for images while the latter makes it so you can modularize the tokenization more. 

Personally I would prefer the latter since it simplifies the tokenization. You got 100 billion to 15 trillion tokens. The reserved tokens are very small compared to that.",r/machinelearning,Z0FBQUFBQm0yeGJkeGNiclFWeFpnRnUzZkxxV1hLM0Y4ckxVdUVybWo3RVdNeGVnLUxiQWloeTRWZTNMWjZZQTB4cjdCZkN2NWlpU2FlVlBFRTlOZmVmZDJmYXhCNXFKYk91aTEwb241NHdYMmtUXzB5ejRhYmM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkR2pfd1k0VkdVWk9rOG5uWTAzdDF2M3BicEJ1VzdoVDlxSWlCVUVUNUlFQU0zamZvTWdDdUowMjNmVXowa21VVmRKaGtpZkZQeTVSc2tKT3Vwdk11WFE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJkaXZBakxLb2tvd1o1SDc2cGp6Q1ZUMmF2Q0sySjAyNlVKeTJGUzY5T0VPU0RYeHZQaXIzbldLcm80dzFxRG5SbTA2Q05DaDdiSkpWVDN0V3FDYjNzWkkxc183dnR3UEF1NXlTZW05UloxUjg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJkWHpoX245NXdxeVA1Q2IwVHUwMGFwLURJY0VrU09TUjk2dFJoRFVUTDhmMEZ5TmxUNVZYX3o3cy1la2Q4RC1IZFZNa3dmdlpsZUlXV3hOSjNDUWwtUGw5aF8zaFc1cFc5ejVuOUp3dGFYYms9
"I have written an article on applying calculus to tensor functions and how to derive the gradient for backpropagation precisely because there isn’t much out there. I tried to distil the relevant information on tensors and tensor calculus for deep learning from physics and geometry books. I hope this helps.

https://robotchinwag.com/posts/the-tensor-calculus-you-need-for-deep-learning/",r/machinelearning,Z0FBQUFBQm0yeGJkQWtqd0lQZGtwMXlaX2lIeFR3RVAtRXJubG52RjgzV1NfT1daQ3gyV04zbml1ckRQaXBLNkRsb0JiME9iOUVzdUlqbThmT2diamlpU3h2WXl0cjVaQ3BVWVRqakVrb04zQ1htVHBJOE5USVU9
"I'm curious how much of a downside, if any, is there to embedding whole words rather than using a tokenizer? Surely an LLM would learn embeddings reflecting any useful relatedness of words without tokenization, so what is the point?",r/machinelearning,Z0FBQUFBQm0yeGJkZEFTMXFGeTdfM2tPbmwxRGNQTVdCYVh1Mm5nd0tVY25FZGo0dWZHWWt2V09Wa2VHdlFEWTVrWnQ0N2ZRcExDXzR5djA2RjlmeHdNVnNvTGp5UmlyTlE9PQ==
"They also get updated more than the print version, for obvious reasons.",r/machinelearning,Z0FBQUFBQm0yeGJkRFQweDdLb1N3TThyZnhKaWFSMTYtQzRlQlI3cHNQcllWWVM5S0l4WVc3NWoyYXJwVy0yeWc1d0pGS1EyZFVRTUJ5QTdIZmxZVENrS2VKMlRkel9EUUE9PQ==
I'd recommend checking out Catboost's documentation on feature preprocessing to see if they mention any specific transformations that may be relevant.,r/machinelearning,Z0FBQUFBQm0yeGJkZVlrUXVsdmVvc3g3M3djTExFNmlOSlRRTFlMX2tkZWgtVExYb2JVOC1JcENOMWE5VFJtWlljUmNjWmd5Y2lwN3p4UkVRSXNyZjNsZGJTYkNwNUtvZ0E9PQ==
"answering in order:  
  
1. The patch embeddings don't necessarily need to learn non linear relationship, the main aim to compute patch embeddings is dimensionality reduction or for images to be transformed or projected into a embedding space, so that it can be effectively and informatively used by the upcoming encoders. The non linearity learning will be done by the encoders. Non linearity is needed while learning complex patterns which cannot be modelled by basic linear transformations. Hence, non linearity does not need to be used everywhere in any network.

2. The QKV projections are again projecting the tensors in such a space where they can interact by the **non linear** attention mechanism. The QKV projections dont need to extract any patterns from the input tensors so we dont need non linearity, whereas the attention mechanism which aims to learn pattern performs a non linear computation. 

3. ig this question might be answered by the first two answers itself.",r/machinelearning,Z0FBQUFBQm0yeGJkZGhMYndubm5VNDBVQ2Q2MDgtMGw3d2ZwODZfdldnWWx1MmwxandFdUxfV1RWcVo5WUZKbkNlV2thcWlQQm4tT3dtYTRBMmdWZVozRzJWbFpxaVBfblE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkWmZ2Wl8zQXRmVkJlVkhia2hMejMyZ0JYZGlhM1BaNnhWQ091ei1FNXRCeDJHWmdXOVRlcVNwS3MzMk84M245Vi15cVV0cU5UdktuaDU2cTF1blRlcUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkeENfRHp3NldzVXk4MjZoMWxUYkpSLVdiRDA2VjhGakRTSjVaczFPWWtLVUw5aGowTXo3SnNjNUdUemlDM0Vvck1McDBRVy1QZTdSQktmTG95WWdIYkE9PQ==
Maybe he just expected a little pat on the back from someone for trying to do something bloody hard.,r/machinelearning,Z0FBQUFBQm0yeGJkNnMtbTVpWDdqZnBkVUNxUVF4dk5VTUYxeEM4cWNiMms0X1VFQ1JENDBKY21SSmotNlFqNF9nSk9fSXUzem1NcU5wWkRxTFlsODh2NEFGcUF1MllqUFE9PQ==
"But why would that change things when tree based approaches aren’t hugely interconnected like Neural Networks (which is why pruning are a topic). The kitchen sink is not going to get selected (nor should it be because regularization) so you still don’t need “feature selection” in the sense OP is talking about you just figure out which features are actually use for splits and discard everything else. 

The representation of the trained model should allow for this",r/machinelearning,Z0FBQUFBQm0yeGJkUFBPOGJZNWlGUHVoSi0xUi14Y0NTQk45d2dzcTRzbS0tQWtaa2tBTUZyNHNwTW04REhoMF9DR2Zjd1gtMlh3WDZ1emFDbmNWb3d5S1hvbFRWbGFVUXc9PQ==
"That’s still a method of feature selection, which is what method 1 was in the OOP. The person I replied to was positing the feature selection is redundant since the model does it for you.",r/machinelearning,Z0FBQUFBQm0yeGJkNGFwVXp4dGxDem5nR1A3ZnQzRWE5ajFWb25pclBNWUNYSzZ0akFfdnNOX2hQLVhQaUtsSTZxR1BUS2JKZlVtUnJlcEVmdFdvb0RDWUtiWU1YOWxLWFE9PQ==
Cross validated recursive feature elimination https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html,r/machinelearning,Z0FBQUFBQm0yeGJkN1M5V0d4R0U5U2c5Vl9abm5na01SZll1SGNtd2oybXJZZnBHekRINTBacS12cVEzZVR5elRqNUxLX1R1X09PWTRMT2RGRmJHaDVlenYyWW5SdGcyYVE9PQ==
"I wouldn't necessarily worry about this as a first pass. The beauty of tree based methods is that they are non-parametric. 

If performance is your key concern then you might find some treatment works better on your data, but you'd have to be sure that the outliers don't contain information. I'd worry about understanding the process that generated the outliers first.

Whilst you can find examples that show outliers matter, I haven't seen any scientifically vigorous comparisons based on realistic data, and this isn't something that is commonplace in previous online competitions.",r/machinelearning,Z0FBQUFBQm0yeGJkZmxWTkxUYmJScUt4ZXFIU3hnRGZxZnZVdGRGbUNiSHFYTGFObTZFTVRUNXNhWW1jMHYtTWlEcm9VMDZEU3paNVJwZk8xUEplSDFDVXZ4LVZ0aUk0aUUwQ2Z3VWl0bnFVNzJIa2FBa3V6cGM9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkSFNheGNhUng1TkNLTkhTXzdQR1NMbjJhZnNOaUM0VURGdC1wUXU0Vmt0WlQxb21RcVpYTEY2TWZWQ1FQQjU4enRMcGQxeVFoY0JnUFVIRU9yeXpHY3c9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJkblFyZnRhUEVIVi1EYm5nX3RqejVQMnNiSHVVLUtpMHhVVlNXOTctU0UwZi11RTBUWi1FY2tNc1FrSER6eUgzQ2NmS1c3UUFHX1k0SVd4WjBhLU1qSXltRlNKU0EzVEhSV05yRXZ0RlNYOVk9
"Hybrid search with an embedding model + bm25 has worked great for me in almost all domains, especially if you use a weighted combination of the metrics for ranking since it makes it easy to tune your model. I will say though that with 50k items you pretty much have to look into ANN methods. I normally use product quantization plus an inverted index since it is pretty easy to implement.

Also just use a bert model or even glove for your embeddings. You are going to end up racking up a lot of unnecessary costs during development using openai embeddings.",r/machinelearning,Z0FBQUFBQm0yeGJkdmlQWVFhQ0xsRm1rOF9nTjM3Sm94dlFTeVBubUtlMUlfRmJZV2hLRS00bFROY3Fwa3U5YzNKSGt2MTgweWxNd05qS3l2dXhONnZjbFJiVElSSmZESUE9PQ==
"> That’s still a method of feature selection, which is what method 1 was in the OOP. 

Dropping features whether it is in the model or not at inference time is not a version of 

>Method 1 - Shap: Drop features with mean absolute shap value below a certain value

You dont need to calculate a single shap value to drop based on if the feature is in the model representation. You can completely implement this by just doing something in the inference data pipeline that does

`SELECT (set of all features actually used)` instead of `SELECT (set of all features in training)`. 

>The person I replied to was positing the feature selection is redundant since the model does it for you.

That person is right. Why would you need any feature selection outside of the algorithm when you can just use hyperparams like `num_trees` and depth of trees to control the number of features actually used in the GBT at inference and choose to only load the actual features used at inference time. This type of methodology is clearly baked into boosted trees to deal with regularization and you would need some type of paper to prove sticking some other methodology on top of it post hoc after training a GBT will do better than what is already baked into GBTs for this exact purpose.

I thought DS was against over engineering and stacking a bunch of methods together doesnt seem like its keeping it simple when the original model has the functionality to perform the same thing as this Rube Goldberg like stacking of methods to perform that task.",r/machinelearning,Z0FBQUFBQm0yeGJkZURybUIyQ045NGxsc2dXMUM4TkVXeDRsblowVGppaFJiU0p1TlpNdDFoc1pvNFYyVlJvcFhKMzFBWGR0NGZwY2YtNlBGZTVCQmdoUWtONTB1emhVZ2c9PQ==
"True. It’s an engineering problem more than anything. If you have a pipeline building all features for all entities all the time, great, use whatever in your model. In practice many teams prefer building their own features for their specific problems, so they need pruning.",r/machinelearning,Z0FBQUFBQm0yeGJkcDQzVnN1VndlbktDWlM4R29TZzlLMmxqSUdQUGNCOFZLakdfNnhoRzlRZTgzT1MyMUh6YnpLUmlJWkVaSEZPTzJ4YkgtMEhLa3c2UE1GWU5fenpDY1E9PQ==
The evaluation dataset is not identically distributed to train dataset,r/machinelearning,Z0FBQUFBQm0yeGJkNkxPYUFleTVHd0JjSkVnMl9uRk81MmZCQlNUcnBxNjVpb1V2TF9aSEVmUnpONGdkQktnMXFYODBKSS0zWW5tenhvVk5jS3hrb3pQcUFvaXN3Y2g5U2c9PQ==
"Check out Multimodal Fusion with Transformers by Google, it might help with your project.",r/machinelearning,Z0FBQUFBQm0yeGJkYkN2M1VWdUtmUmZzdnpXUi12d1lXcVN1SHRwcDdNWUg4Z2xUV3U1MmlpbUlNMDREU2daenJrWTY5VVNSUmV5R21mcHg4b25FZ3RWZmpsakpnOTJCWThQUWdTYUJsNW13YzRKVXhJdzlXMUU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkbHNpWUU0X0tGMFphM2w5czRqWjliVlhUOF83SWRZcmxyWVdBZmU3U1Zmd0s1RDYwR2ZKMzdBY1o5ZUwtR3FqVUVabWY5V0ljekpIckljSlRFTTR2UUE9PQ==
This is the subject of my monograph. I'm starting soon the tests and I may present it in late September.,r/machinelearning,Z0FBQUFBQm0yeGJkaURudnM3aGR6WUdkSU9UeENnVUhVQjZPUmxPQjFBRVR0Z3RQNGE5VUo0MkNaVFQ2RW9JdWJ3Y1NZOUhoLVdGU1k0dXhfbzdjSkZfXy1wbmNvcVdveUE9PQ==
"I'd say drafts are 90% accurate, but fact-checking is still on you",r/machinelearning,Z0FBQUFBQm0yeGJkblBZclQ5SGJBd1V3dF9BcWhNYm1ma0pjUkNna1VOeUZ4cXd3c1M1LXUzUmRSeFFYZHRlT3NOTUk5SlZ1UHV6SXFUU1dmQWZWWF9WWDQ0TmZGZVJldnc9PQ==
"I am not sure what you mean by ""mechanistic interpretability methods"" but people have applied methods like LRP (Layer Relevance Propagation) and GradCam to VITs to visualize the class activations  
  
These might be of interest [https://github.com/hila-chefer/Transformer-Explainability](https://github.com/hila-chefer/Transformer-Explainability)  
It is quite an old paper though, [https://arxiv.org/abs/2012.09838](https://arxiv.org/abs/2012.09838) so I don't know if there is anything more state of art other than the what we already use for the CNNs.",r/machinelearning,Z0FBQUFBQm0yeGJkY3FDYWszMmg1NkozRjE0X1RTU2s5ckNmQzQyOWk5aVZLeUVzTkNXSkNkUDYyOGV4Z2N4eEtzaE9EQS1kM1Fad2lpVnlhUmxuVGZRazE2U2FnaEVLeXNYZkxQSVlmU1ZIOU9tWlAtWFZSSFk9
"What? Then, a database query is also intelligent?",r/machinelearning,Z0FBQUFBQm0yeGJkWWNQbVZRajBrRUlvSWM2M2luTmZNbUNSaTAwdnd1c2dkbV9pblE2QU9sY2wxa0E1dDAxbGtxOEw0VlREM2k4X25HbmVpT1FpeS1lMHVlZnBVdTRLdWc9PQ==
Question: do you know where there is a good guide on using RFECV? I get the feeling I'm using it wrong. Or could you tell us what settings you use?,r/machinelearning,Z0FBQUFBQm0yeGJkRG45ZzByeHBFdWdjSG5MTHM3eVZ0WGFXLVFzX3BFVGJGTGVYUjQ4YU1fNnlhSTFTTzAzUVRmYzFQc0xsLXR2X2s4eDg5Z0F2V2p6SHRlRkdOVFpfZXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkV1BnY3d5R09rY2ZsUkdEZHNiNU9vTk1ZbkNFdXY2S1J5d19nb25VdFZod2hja3ZXdThlaHFfSGp6UElPY0xSRWl1Tm5uc09ZR3VHWUdfUWw2M1FRd0E9PQ==
"I've used method 2 a bunch (because it's extremely easy) and I've never seen model performance drop from pruning many hundreds of features down to 100-ish.  Even paring down to the top 50 is often perfectly fine, though there are some potential downsides to pruning too heavily.",r/machinelearning,Z0FBQUFBQm0yeGJkT0xFY0N5X1p6NDlHNXdjbVhGVXNmZGJENkUxWW1lVnAxeTAwSFVHOE51QTYxeEdvY24wa1dJeU0wYnl3dFFXampCRXV4T2R2eGljbmpmdG9faVJTWFBUNnd2V3RZUlZ1WW0xcmF6SW1YZk09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkSFpSbThLaTBLX2dKTGtxRGVvTzk0RVFLbk1Cclpac1pNbi1LeFhFWjUxbFVsZlNiaHFRRkZjXzVWd3NxZ08wR0U3dEd2RThsMWhkWXlZU01NWks2R1E9PQ==
i usually use defaults except change the scoring function to something I care about and n_jobs=-1 for speed,r/machinelearning,Z0FBQUFBQm0yeGJkLWNnM2xGSG1HaDB5VTNLdHZLTWxmRXZtWHpucldkWGVsLXI1SURrWU81WVk0RTNZT2pJdU5tQkRJRlVhcmI2MEplaFp5ZVR5TFhWYzRjLUs0Mkk5amc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkNjJPX0IxMF9QRDNIM0Zoa3JUWUJ4d0N5M0N6WnZxOVR5R1lIUWxBZHJRUEhCSnp4akpZLXgwU0xpaDN4TnRrZFRNYlZSQ2dLSS1oN3pPVFJCOWtPaXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkaVFrS2kwRjNMbzJseWJRZ3c2V0hRZ1N4QnZpUm1NSHpld2pIZ3Z1ZFQwaUg3azM5Qmp2OUVkdzdpSUpwRVdsZmpucVZ1UWEtUF9CNG9PZlVrdUhZalE9PQ==
"SAR is a super challenging modality because of the banding, most common image processing assumes that standard optical lensing effects need to be taken into account, while radar processing is its own entire (niche) subfield. 

However, my advice here is to always use Google Earth Engine for this sort of task. Depending on the complexity of your algorithm, you can likely try it entirely using the JavaScript sub-dialect that is used in EE. 

The documentation is relatively robust and lives in the sidebar of the code editor. As usual, ChatGPT can help, but be warned it’s SUPER BAD at Earth Engine code. 

Regardless, the GIS subfield is extremely poorly resourced in terms of entry-level content like this. My legitimate advice, coming from someone who worked briefly in academia in this field and also taught themselves a ton beyond the norm on the side, is that you should literally just start with the simplest problem and work your way up.

My toy example of your problem was always to open Earth Engine, grab the Sentinel-1 SAR data and Sentinel-2 optical data, put it in one combined image, reproject it to EPSG:4326 100 M^2, zoom in, find some buildings, draw a couple shapes around them, flatten those pixels to features, use that to train one of the basic classifier models like naive bayes or random forest, then classify like midtown manhattan or something and visually inspect to see how it went, and look at the confusion matrix.

It’ll probably take you 2 days the first time you do it, now I could probably do it in 10 minutes and it won’t take many repetitions to get you to that point too. DM me if you need more specific help, this is a crazy small subfield, and it can feel daunting, but it’s not once you get the hang of it.",r/machinelearning,Z0FBQUFBQm0yeGJkcHB3TGo0SUx0V2dxdnVVNEJrRzBGUzF1dUIxY05iQXlfRVl3eENLLUpOd09PVmpWdk9GWWxtcDZPTzVVelh3RU1ZZllyQ1FsNXNsVXFDRERmZm5VMjlycW1EbTVmTXgyb21STHdmSGtxMVk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkaGFMUjA0QkNaT2tNUnMyREhuRndvblBrR285ZExYV09rVUtTZ0dMZ1dzZ01zQzNNQ0wtY2dhQWMxeVJkbzNza0hQcVlGTjh5cFk2RUxVaHNIS3h1anc9PQ==
Got it. It's clear now. Thank you 😊,r/machinelearning,Z0FBQUFBQm0yeGJkX1h5R1ZTWl9YVTJHMUhGZFlJR2d5R25DNFZRdV9XNkRmQlhmN2FMNWNVUHFxVkFTcklHTUpVLXhCSFdMSWZVUFBSdnlpX1B4ZUIzbXR2aXYzQTBMd1E9PQ==
"I use a basic mix of inbuilt feature importance of lightgbm ( features by information gain on split ), permutation importance and feature removal. 

Usually gives a good idea about which features are less useful and can be dropped without a meaningful drop in model performance.",r/machinelearning,Z0FBQUFBQm0yeGJkMXFRLWVTb3UxRHdvMF9rUU80TUlZcldXSnJTUDgtMFYtTk9DYnZNQjRUZjREMC1GdU1Qa1J6S2ZLMTFGVFRXdkR3ZlNVNkZvLVJYakpTNjJ1NXhTUlE9PQ==
Nice!,r/machinelearning,Z0FBQUFBQm0yeGJkMC1XUUJiUmE3T2JPbkVhN1RzX2x6V2E5bXJFblMtMVNvcHM4Nm5hZkx1aUdFRUVRcHNYdWcxS3ZkZ0tucllGeFhsS2wzWGtIYTJRWmxnSm5ydGxSeVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkc3BCWUVtU2hRVENUX1V2ODlVdHBtYnlPVjJraHlEdzZFQlJLRFBKdVU4NjlZcDVxZ2ZJa05TY09tV2lBc1dvam1WQ1hRSDcwQ1A4bE5SWEgtS1F5Zmc9PQ==
Damn,r/machinelearning,Z0FBQUFBQm0yeGJkVEZUQVRIT3phbUFYZWR5dklscEdJcmZPdkhiUlJISDh5bGU2OFNMMEZ4WC1pOGlIQVBpN0dCLUxWeG10Y2pFUUxJTDhvRTlUc0FsdlEzX0hfRC1Ob0E9PQ==
"I have read many drafts, and never encountered a mistake. It's also easier to ask questions on CrossValidated, since you can explicitly provide a link to a page, or even a particular section.

Also, as another commenter said, you can easily update a draft and fix some mistakes, which is a pain for PDF versions. They typically don't get updated at all, or authors just release another edition after a few years (which you have to buy separately).",r/machinelearning,Z0FBQUFBQm0yeGJkRldYZEpsN1BFRFlpazJWSTBiWEpXZnJ2SVotNVRkRzBZVk5GNmxCUGZOcVI1bEd6bkRiT3RwWng3aW15clNLUTk1cnRoWV9xNHpXcFNDZlk4T3VWTEE9PQ==
"Is this going to start a trend where we get ""poisson x"" after ""Bayesian x"" and ""gaussian x"" now?",r/machinelearning,Z0FBQUFBQm0yeGJkSUE1czlGUnZmS2ZUR2EtblZBUFdESk03OGdEby1nM1lhc2Vna2xLUXZUM0MydDFtRi1kZ3NEWmoyX2lWbVh3ejJfWUZzSEkyVVNyZ2tpQjhfWUxtZUpyOHI4REt2T3lhTWJ4Qjk0Nmw4bzA9
"Why not, that would be great! But probably not. 

By the way, what are those trends you're talking about? Can you share some examples? I don't know about these.",r/machinelearning,Z0FBQUFBQm0yeGJkN3dfV1BaZnFIbUVfM3NScXpGMXlxWnNLSG5oVW9mSFhhcjRMbTQ0dnYtZW4zYnFQYWxxTWd6WlptcTJVTHIwWlpxZGpRcXV6ZDdKUzNjRGUwNW5oQ3c9PQ==
"I wonder if you might be better off dumping a huge load of footage into a transformer without programmatically figuiring out when one sign ends and another sign begins. There might not be enough data, yet, though",r/machinelearning,Z0FBQUFBQm0yeGJkMWNQN2ZEVmNaV1ZBaUI2MF9RcXhVNlczdWNmTE1XWWVxQS1SMXpUbHlzbkFQVDhtZklQUVJjSUtDbWNwWldEcG45YVMyOWNlRXNHQlpaLXdJM2hDdFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkT0JwaHg5dndqLXB1U1R1ODdPSDZHT1YyWnUzVzh3RXQ1WTlqR3FtQkEtU1pyRlRwcXhpMzFUODZIWTdrOUJEQnkxUHo0U0Z3U3ZDTkJrQXdTekc5U2c9PQ==
"I'd you're referring to Bishop's or Murphy's - these are not drafts, just full books for free",r/machinelearning,Z0FBQUFBQm0yeGJkRzc0eEk1UWxxeTBkMnNMS3kzT0pVWHFlMlREdFIxSGJoWjU5ME1Tcy1NZzhoRjlqNGc2eGJ6M1RVcHRXY25qbWZqOVk0eGpBV1EyYnZ6dnFiX0xzQmc9PQ==
"1. You generally shouldn't cite refences in an abstract

2. Figures are typically numbered from 1, including graphical abstract, if it's a part of the main PDF

3. For statistical tests, you implicitly assume normality by using t-tests, which is typically not true for model results. Also, you should explicitly write what procedure was used for FDR correction (Bonferroni correction is only one of many available, after all). See e.g. [""Statistical Comparisons of Classifiers over Multiple Data Sets"" J. Demsar](https://www.jmlr.org/papers/volume7/demsar06a/demsar06a.pdf)

4. I didn't quite get the hyperparameters of this. Is temperature the only hyperparameter? Is the sensitivity to it so low that just annealing is enough? I think stating this more explicitly would be nice, especially if this reduces to basically a hyperparameter-free model.

5. I don't think that downstream classification on MNIST is enough. It is a good illustrative example, but for the final paper, I would expect more experiments in this regard.

In general, I really like the idea, paper is clearly written, and math is understandable.",r/machinelearning,Z0FBQUFBQm0yeGJkeU55SjdRVFZMSmVoczhPUlNzTU00RkktVUttM3ctcmFrc1BNeWVFZWdRWjQ3aHFSTzQxWE5xVkNFeXVzMUxJaE1qeWNjVkJzT1Q1R3g5RUp4Unk2WVE9PQ==
"Any news on the open sourcing of this? Noticed the playgorund link redirects now.   
Or can anyone recommend a similar tool to aggregate user research from results of web scraping",r/machinelearning,Z0FBQUFBQm0yeGJkeGs0N3QtQ20tTUtCN1dQV01yd1MzeVBfRmF5U3hRZ0h1cFVKWE9CR0M1eEI5S29NaVlKempiWi1sdi16VFFvUVhoTkIzNjZmREdndERDVmMzTzhFN3c9PQ==
"Search for spatio-temporal forecasting for traffic prediction. There are quite a lot of GNNs for this, but focusing on urban traffic. Obviously, the network is quite different then, but it should be a good starting point.

Also, maybe Google's paper about Google Maps travel time would be useful? They basically did regression on road segments. This is probably quite similar to your second approach.

Also, this is problem-specific, but I would also include an information whether a particular point is in Paris (map is obviously France-shaped). As far as I know, in France most long-range trains go through Paris metropolitan region, which may mean that this area is particularly prone to accumulating delays. Using exogenous variables for handling such special cases can be useful for time series in general.",r/machinelearning,Z0FBQUFBQm0yeGJkSmFJTEFtbUhPZTF1YzkxOEY2SnlRNHhZQWJkcDFjcjladmhGaGRYY0taaFRVdTBGMURkUXQxX1MyeExhTFhiSzlwS0hRbG44eUxRamdHMlE0R2puTWc9PQ==
"In my case, I concentrated on labeling costs for machine translation. That idea naturally induced me to investigate related works like data pruning. Getting some ideas from those, I implemented my idea and observed better performance. -> So, I made better method for data pruning. It can be applied to gathering machine translation data.
What I regret is that, before trying the idea, it could be more pursuasive if analyses were done before proposing methods. At least we can verify the weaknesses of previous works, are they really exist.",r/machinelearning,Z0FBQUFBQm0yeGJkd2J3Q0xFQzZublpLdU9FbkhnbHpUaHJ3alZNaEFZdTFvc0lRcG9wOURfRng0cnM5WVhEWXVRWkc0T3pVUTFjT0NwM1dqSERDVUxGX2xNNERUVGYyNXZ2ZXJlY2E5LS01akVud1BLUDl0ZFE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkamo0Mm1pbWF2WXIxWmpPdXlsN21nVzJfZVJCVjktcjJPSWIwZnVIZW5CV0kxbUpJRXI0d0VUalkzT0tEMDVGU2ZZNjZJamFlbWhhRUZTVGR5T3pKbXc9PQ==
"Hi Vafai. It's really cool that you have a poisson VAE. I have a point and a question.

 The relation to sparse coding and VAEs is that the KL divergence is that the sparsity term is the KL divergence. Actually I thought that variational autoencoders came from sparse coding. For example, if you consider the ppca generative model you have z \\~ N(0,1) and x \\~ N(Wz+mu, s\\^2). If instead of assuming a standard gaussian prior you parameterize the gaussian variables and draw samples with the reparameterization trick then you have z\\_phi \\~ N(mean\\_encoder(x), var\\_encoder(x)). And then you have x \\~ N(mean\\_decoder(z), var\\_decoder(z)) and voila the variational autoencoder. 

My question is about the reparameterization trick. You use the gumbel softmax trick to relax the discrete poisson variables, but do you assume an underlying categorical distribution in the process? If so, how many categories does it have?",r/machinelearning,Z0FBQUFBQm0yeGJkVjVMV05GVDN3aFdBdDJQa0doUlZuM29BOEV1MlhLZE5IXzRVdUJ2ZFhEOEhkVmdZeW1rNk16ZncxRVNRaFltOGlYWmtBbjRfTGFjeEVzVHlGTFFpQ2c9PQ==
python usecase implementation !,r/machinelearning,Z0FBQUFBQm0yeGJkSzRrTS1WMDJRN2RrSlJoREFFQ2Nsakl3My1QeW9DVVM2RzFkcEpzbnZSMjB1bDBNYm5pcFFZS1RjSFhmQWJoTkpjd0tOTlQ1RTh2aktEdjlWSC1EZ01tZUN4b3phMm5ILVJOcllEMmRhcDQ9
interesting approach! thank you! the importance of critical thinking.,r/machinelearning,Z0FBQUFBQm0yeGJkNTNaU2FqbGNNRDRqaFRleGlpdEFiSU9CXzFOanY2YmpNa2JDLUxQZmxOVWhBU2xTTFI4Z1RaNDFlTF9jR0pjUFRYYUgyYXFZTFJhdGdDc3lBOWRzRmc9PQ==
"One of the largest issues when dealing with discrete latent variable is the variance of the gradient introduced through sampling. This shows up a lot in other places where we see the need to predict discrete intermediates such as reinforcement learning. Did you need to enumerate the latent space or do any sort of variance reduction techniques to make this work?

See: https://pyro.ai/examples/enumeration.html",r/machinelearning,Z0FBQUFBQm0yeGJkR3NGX015aWx2NXVybHZOUGVwWUVfWldERm9pRDNOZ1BfQW9yZ2lpLV9uTF9LZGN6eGV1RGR3YTVEaGFNN0N6NndwalN0YnM2eDNWWFpqM2RFVUx0R1dlenpCVjNiNHRZMjl0UHlCSW1NTU09
"Not really, because the majority of models work with tokens. However I remember a few attempts to make models that directly work with raw byte data (there was something from meta, if I remember right), and in that case, that would work.",r/machinelearning,Z0FBQUFBQm0yeGJkM0l3MndzT3Fvc1NULUR1dVoyVEw0R3FRcW1EUlRvdTYwbUJtcm1EMGJSeDhrdjJ0NVZId2JKdklkUmNVOTBlNkU4LUN4Rnd0d1pMM3VQM0VUY0FDeUE9PQ==
"Thank you.

I have already looked at ST forecasing for traffic prediction papers. But the exercise is little bit different here, as it we don't aim to predict the average delay at a station, but instead to predict the individual delay for each train at its respective stations in a parallel manner.

Currently, the implemented model at the company where I work is a Transformer with attention mechanism on the trains. The input for each train contains the train's embedding, different embeddings of the its n\\_prev stations, scheduled arrival time, and many other informations (mostly statistical variables). We then provide the embeddings of the n\\_foll stations, and ... to obtain predictions. Our intuition suggests that this approach might not be optimal for this task as the structure of the railway graph isn’t explicitly modeled. Hence, we’re considering a model that employs Graphs, such as a GNNs

As for the Google Maps paper, it doesn’t align with what i want as it relies on algorithms like Djikstra / A\\*.

Thanks",r/machinelearning,Z0FBQUFBQm0yeGJkSUxUWjAyYmdjcHhNTHB3Y2hWbkZid2gxOUtLLTNTOU0xUzBwdkFsaTRmclk4cXdLbXV2SkstNGNXY3F1Ui05ejY0bUJyQ1F5VXBFOGdVRDJFNzFnM3UwaEthU2VLTUw3bU5CNlJKTjFTNDA9
"You have a few options, which will depend on the frequency/load of the requests coming in: 

1. You can have an inference thread, which will wait until it gets N requests in a batch (or timeout) then sends the batch to the model and results back to each caller. This is useful if you have a lot of requests coming in, utilizing the batching of the model instead of many individual inferences.
2. Instead of creating a copy of each model in each thread, you can use shared memory (`model.share_memory()`). This will let you spawn separate threads handling the requests, but all referring to the same underlying model. Inference is thread safe (so long as there is no state being written to inside the model)",r/machinelearning,Z0FBQUFBQm0yeGJkNU9vRHpXYzREUC0yb2Q5anVEVTBseFREOTh5MVFKWnBianZwSGJQWS01aXBzUjVZWHR5dE1kWTRxenFmYXNPOGktTzZZS3FUQl9ReEVockI5TFpvbmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkUUZIZGxKNHA3SnRXOVJpUG0wTlRZQkNJbDhYNmJPRGk3endvZjl3cVRLb1VDeHhzZVladDAxWWJLZzN5czF4TEl4TXdtcVFBNW10ZDNXV1A1c2pPbWc9PQ==
"Check out spaCy's HTML parser and entity recognition features, might help with your project.",r/machinelearning,Z0FBQUFBQm0yeGJkYTNsUTZUZ0VMS0ZBMl9UX0plZFFkbFZiNUo3QzBXVUwydUI4U1V6ZXdyXzFCMUhVX0FHVGRZY0duMEQ2OXUyeWN4Y3NxMFU4X0RWd2MtSkdFZmdhTmNuNmZ3eXd0M2p4ZUxSN3Q4NDkxbmM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkMk5UMHNBd1pzdDVZVTFqV0VMaXoyRXo0ZjJQSGYtMzFqdTA1UEltLVBqaDdPSlMzOG5mRWFVSFFGQXBxTm5HeXNfdWNjQ2xrWFoxX0R0ODhYYnM5QkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkYlZJRllwOEU5R3VTQm5oMjNMck9qc21rWWRBcDBJZEppOEFybGN3ZWdrc0RMbi1PeUVROGNKaEI3aXhyVWNIMWM1QnJ2OEdBNGlwdXM1UWI0TmRuWHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkSzlMTlVMZ1lGX015VXFUM1ExR1ZzZXgtdnZ3eE9Vd2J6U3dKTWVtWlNQVlVycXY0MkFGWEd5RHNQaVllZEliN2NYZG9Bd0t1dExPWjBLT3dOR0FkVWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkcFp2UGxwaDhjQ3NBRG1KaVl4aHdtM0tJZU9Fb2toUEdUV1ZiS0lDcVhqcjJXaFlidld4SkFyREFGd1REVGxDWXgyZXN0ZFpvUXJkcjFEMkxnSnMyUVE9PQ==
"ICML paper submission requires putting in the ""paper ID"" into the Paper Checker. Is the paper ID the submission number, or the ID that appears in the OpenReview URL after ""id=""?",r/machinelearning,Z0FBQUFBQm0yeGJkOFFtWnU1dWI2QkU4YTFjSXJ0RUxrOHpNc09ycE5OUjFWWF9uTlotRkljMWlaMU5raHlCU0w3LXc2ZDg1ZnJvb0VNdWtucXJQOThzY0o0QUlnNU5ldlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkZlhaUVZZYXZldXVNSEFCdEZMRVN1bVhjLUdzZGV5MzROQTFxMDlicGs3WHhBWlJkVVdjR0kxWXRITzBUdi1lSFNvTmlucUFsbzdBQm15UmRJT3NkTlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkLXVUTG9zeTZ6QkIxaWU0djZRbTJVMkdjdzEzU1Rac0UzZy1OeWZ5Q0NFYkoxdXV0YnA3VGRkZl9faTFXLWVEUGNLZUJpQURQTWtkOFRrZ0E1RjNnblE9PQ==
Have a tool at [here](https://go.extracta.ai/share) as well. It has a special feature that can extract structured data from unstructured tables. Let me know if it worked.,r/machinelearning,Z0FBQUFBQm0yeGJkcERWUmlXbjVHY1dzVTZHb2NqMm00WkVDNDhWYlVPelo5dk5KTXA2aWN6RFdKVlBlTTVJamwzbktXZ1JUdWd0bDhKSkNnVHFRX2lMYUIzM2Qza2licXVPbWJLTXZ5bTlzX0RUUW1MN2dCMTQ9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkVmFTVkxrT0ZyUlMwZ1pZZEN4SHNISXRNVGJQcFZnZ0VjaWIwRVBYOXRMVXBhTmI0MXVtbGNZTXlGYnotcTlqLWFTR0xwZzRZN0Q2Rm1aU1ZYVUZ3eVE9PQ==
direct ml,r/machinelearning,Z0FBQUFBQm0yeGJkbm1UU3FQdG9oeUc3Q2s0Q1k3YnBvOUlpWmNXbmVJdkJyVGs3UHREaG1YSDZxMmdITDNzaXNiaERTdnZCUFFFWGpfNE9rSkpURHJYU3F1SFh0elo3QVk3ekhUQjJleDJNMEhOTWtyeFQ0VEk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkcS0tMDhBZ2dzcThWd0NRSU5hNXJVRUFFREs3LVJuYlBmRGlLS1hnWVVjdDFwTFAta1hGRG9NckkzVjZ3aUF0VExDb3g0UkF6eUd5MS1POE1Ea2hsM3c9PQ==
"Note that you may not require fully graph-based solution. Maybe consider adding just some graph descriptors to your feature vectors, like edge betweenness centrality (for tracks), degree centrality (for stations) etc. This will implicitly input the graph topology information into your model, probably even more than a GNN would (since their limitations in terms of learning graph topology are well-known).",r/machinelearning,Z0FBQUFBQm0yeGJkUW1XalIwTmNISVBpMU1CaW9mMFdyQjd1WjN1YkhtaWtrZ29YZmJ0cFZhOXlJdzNqNVdIczgwUVk5UTQ0SjVQNUJuNmJSTEpDQU0yNEVwMHY3RmZJOFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkUENvZ3ktRkpvOXB4bUZCYXNJbkpDVzgtaFlYcUhkSUY4ZlM1aFJiaFJuOEhlTnpLcTJZVEJoaW0zUTluNE1zSW5OS2xXM2NBUEFvY2dOOTUyNHF5aXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkcms5ZE1lUGNLWUstcXFDemZqSEUyRDJLMjBCQTZ2WFllc0FHRldvN3VSakgyd0xBd05kcy1hRl9weU1mS2hfZ2lfUzRRcC1LQ3A2eUtHeHRUMkFkalE9PQ==
"Get fastapi working in async mode, and the wrap the prediction code in a asgief, asynct\\_to\\_sync with tread\\_sensiftive = False. This will do the equivalent of spinning up a new tread for each inference instance.

You will run into the issue that you have no control about how many concurrent processes are created, which may overload the machine. You would then need to create a queue to handle mutexing a maximum of n inferences processes at the same time.",r/machinelearning,Z0FBQUFBQm0yeGJkMWcxbG8wbjNvV0RTYVVMVGhJUGNFWG0yVGU1RW53WVBXSXg3UVQtWlducW5qZFhJUUF2LTQ5TUFLOWtDcF9wdVZjQU81ZTVvUUx4Mm9qVG1RT1B5akE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJkdnJjYmQyREZJbV9CdHFJT2ZMMUdUYjlIVGEwLV9GUU94ZDIzMThxNkxhVjdWVDgzVVI0cXN2NDVwR0s5M1NBWXNOUTRqUWFFV0tKeVBZcnlZOWtieVJoU3FrSDhYN1p6N09aNmMtZFoxckU9
The timeout is clever,r/machinelearning,Z0FBQUFBQm0yeGJkby1fUl9rSVY5QjE3U3VvQmhJdWJkb2JTNV9BSDN2VUxNSWQtYUZZRHJzU3hTSFpsakVUTnJLTWszSXlCWXZVRFNieDAycHBobnladExXV3JFMHdENXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkSXRQQlFCbGd0aXQxTUtvam5CNVRMMk9fZ0JwaDJjdDJyejRkcVY2OWEtWFI4di0ybl9PeExZUXpqYWY0RGRGelJCT3FBWmp6MUVEWDFLUnIweFctUWc9PQ==
"Hello, I am an independent developer in NLP/CV/Time series forecasting. I want to read new papers daily in those areas. However it will costs me a lot of time to find a new paper worth to read. is there any community where people will discuss about new papers? Please help me with some advices.",r/machinelearning,Z0FBQUFBQm0yeGJkaVdiRWh4b2VMTWNCZEhqTVZRVkVKekdPeWt6U3ZGM3MwSWlReWNRV1ZIbk9IcVFlak95eVdEcXVSdXNQXzl4bnZLcks3aGVQWFFSUUZHM3JqNmktQnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkdFBIOWFoMGZYeGNaRWVNTWVaczdCVEpYcUswa3V6WEhpUHBYR0E3eHNzclJPZmY3Y2VFYUhQZzV4d2Z6MklsaDJPSGpmTG5XSkVTYUZjdG0tbDZMRkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkdk1LM3RtTzdWOEdVVzRyMlNuR18tVEd3ZVdxSjJXNWZqdmR5NnlwcDdGaWlqaWlpWE9LczF0VExZNVZvSUlYNTMtUWZZTU5FN3laUjk4aUZjRVYtWEE9PQ==
"My favorite method is a bit convoluted and unconventional:

*KEEP ALL THE FEATURES!*

(I’ve tried all of these and the only one that is consistently the best or equivalent to the best is to keep them all. I’ve had models with 700+ features before and nothing I did could bring that down without sacrificing performance.)",r/machinelearning,Z0FBQUFBQm0yeGJkNlhtYlZzZmpFX0hrTTAxVTBKODRXd1FGSkIySnpHUFJiSEs4c1ZtQldCLVdjbTVYbXg3azVDLXgtODdoZkplRVpPWVI4NHNDd2Q1MkgyWHd3NlNjUU15NDVQcWV0VTZVRXVOZ2JFbDlxYlU9
"77 CVPR 2024 papers feature ""Gaussian"" in their title. Thanks NeRFs",r/machinelearning,Z0FBQUFBQm0yeGJkMVFNR04wdUFLYUczUEJJaDlZMWJpa1NlOHVtOUMxcDJ3c3RLeDZPVE4wcmFXT1pHV1pQUmNtYmJVVkpUZEIyZlJIZXVwektrVWd0b2tmSFpSWGR2SkE9PQ==
"I personally found the draft versions to be helpful, but always double-check with the final copy for accuracy.",r/machinelearning,Z0FBQUFBQm0yeGJka0stSjZjTjJTTXRQa1Myc05SOW1yd0J5akRmX1dIU0hnX3AxeWN4NmZlS3J0OG5lejNRTUVpeXZOQ015N0F6dzJ6RmVCbUpQb0VudEdFNDhqam5RRWc9PQ==
Pytorch is thread safe for inference. I do not understand why you are running it as 1 thread with fastapi?,r/machinelearning,Z0FBQUFBQm0yeGJkaEZvYjNUOWtMZ01IRTBlRm9QWVVmOHpYWmprNkJKeHVVd0JyQlQ2NVpWQ2c3RFRUXzI0THoteUlxSEt2YVRtLVF2MHlqZkJmdkw0ZktFaFlyd2swd1E9PQ==
I wonder if there were any notifications on deadlines of poster & short video (with slides) uploads?,r/machinelearning,Z0FBQUFBQm0yeGJkNnZBZ3JUeXBXSXRWYmF5V0RwaEdzazIwM1F4RTFkVUdhLWtIVlRmYVdQVERRaDZCY3F1NTFMTFNZMkhOSDZmQ1duaXlHVTJEM2tiV0xuUkJSeEl4eFE9PQ==
"50000 items should be too much, do i really use ann? i thought just doing dot product should be work fine... may i wrong.

in my implementation, i embedded then used bm25 and mixed their scores. it worked okey but not worked ""well"". 

i'll try bert but i have a lot of informations about products. i tried some open source embedding models but informations were in turkish so they didn't work well...

product quantization and inverted index kinda new terms for me could you explain little bit? actually if you could share sources, papers etc. or explain the general steps for searching detailly i will be appreciated... much appreciated... please... i need you... or my lead gonna screw me...",r/machinelearning,Z0FBQUFBQm0yeGJkOFZRR2RDbkFFQWc1Tk9melF6R3NiYW1yMkhMT0oxUW9GOW5zak9mWjdubENqYk9XQl9qcnRGemFJZjNxTUxiVzRJN0ZFRWJ5XzhzMXZEZnFRaTFXbWc9PQ==
"Thank you very much, I will discuss this with my manager.

However, I’d like to point out that I’m currently utilizing three distinct pre-computed embeddings for the stations, namely Laplacian, Node2Vec, and geographic, which remain constant. I’m curious to know if the information from the graph descriptors might already be encapsulated within these embeddings. Thanks",r/machinelearning,Z0FBQUFBQm0yeGJkQ3ZWT3ctRkk5R0lpODJnN3B2Z3ZsQ1JDQmhIR25FNUgxNkxhU3NXRERHb1VjWkl4blhzM2NDYlFvcGg0czNHdjVKd29uZm1iYUVpUG4yRjJfX2o5dmJwMkR6TG5fVGZvZnVyYkRxYlp5RDQ9
"NVIDIA Triton server is built for this. It supports shared memory, dynamic batching, load balancing, multiple model backends and other nifty features for concurrent inference.

EDIT: If you want Flask like API, they also have PyTriton.

https://github.com/triton-inference-server/pytriton",r/machinelearning,Z0FBQUFBQm0yeGJkRlNQOW5DdlVyeDU3QlhZdV9HekJtRm9GNnVfR0gyMmFGZjFmazRuOFJxd2huY3oxcXFWN2FVWkhRcWlEaHlaYVhKb3NGdkd6elFKLWRFNjZubWhwUGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkZE9DakE3QlhWM1V1QnNwZDVnM2tvbmM1V0trTjFjbmh2YVpVc0FCNGxSRG5qOHA1cFMzR01YNkZfUm1lSUxhRjZtcnozNWVxT2t1c09CbG9rMmxPV2c9PQ==
Have you considered using transfer learning from pre-trained models for better accuracy and faster training?,r/machinelearning,Z0FBQUFBQm0yeGJkZzV0NF9fQ3BHOFhwZGtiei1oNm5iUzlvZ0Y4QnkwR1ljeVNjNlVXT19ub0pmWUhrTTZwYjVZYjcyeWd6dkJJMU9VYzNGT1VGa3VEb2V2eWNoSTV6MVE9PQ==
[https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states),r/machinelearning,Z0FBQUFBQm0yeGJkOC14TmJsZEJrTV9PWkdIc29xYUJGaHVYbHYzT1FoWkJhVk1odldTM2wxZjJBMlIxMDNobzJUcVI1SlJFdHJZVnFQdUdXdGlYN19zZzVfVE1qbmVZMmdLVXJGMkN2U0FpZVkzTkN6dnhqaUU9
NVIDIA Triton Inference Server has this. It's called dynamic batching.,r/machinelearning,Z0FBQUFBQm0yeGJkTHlXcmM0NmZfTXhxSlpWcUFGUTM1ZjBhSmdNcXpRUzJaanhVVUpwRDkwMVpPOXBrSmtTem5KcmZmUFJ0aVdaZUV0dVJIVGl6eVpFaUVTa0xRNUxxN1E9PQ==
"Do this:

custom purmuation on cv\\_test folds (MDA, cv). 

correlate it to MDI x\\_train or OOS MDA X\\_test

and yes dropping bad features will improve your model.

I can assure you MDA cv outpeforms MDI and Shap or any SFI, its also model agnostic for the most part",r/machinelearning,Z0FBQUFBQm0yeGJkNzhPNkJ4cFdSc3pkUzRyZFhTNEVxUUhMd1hYZ0ZhNnpWTGdjeHdBTlloSmtYT183QmVsUU10TUpUeVVZektJRlRnWFhYZ3JTN1MyczlFdjBnUl83QUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJkM1RSc2FsTm5FWmJBNFA5LW9iYjJhVGxhZmQ4R0lfa2Jud2liTG0wcWdneks4WEVpdXlXOFhLVV9oa01qWXV6cF8xS2JQUU5iNnZkRkF3X0VsRW9kNVE9PQ==
"depends how you define prompt engineering. For me it's AI engineering because you're building search and retrieval, reranker and more.",r/machinelearning,Z0FBQUFBQm0yeGJkYkJTQVFZNy1lNEY5bi1kd0tWUUxuZVREX1RIMkEzcVBqTVlmNmppVjV3NnN2QlU5LWpxMXR0VlZMUUF4UFhxNTRtRnlQbV8wWXphZmpaRmtfM21LOVE9PQ==
"As a followup to this, does anyone have experience running multiple ONNX Runtime sessions simultaneously without them sharing  threads? I tried the thread affinity option but it doesn't seem to work.",r/machinelearning,Z0FBQUFBQm0yeGJkQzBaaHdDSEtMSEQ1U0hvTmxkX3ozSndEM1BmNy1vbF84Nmxval9Ec1FhemtUNklJdDhuS0xYa3ZXMkFfdnNoX2xzekJtMjF5X0JiRjJIUEJrdmlZUGc9PQ==
"MTEB leaderboard has a ""French"" tab: [https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)",r/machinelearning,Z0FBQUFBQm0yeGJlM005cXN2SmxIMlo2MjBndy1nWEh3TkRBbDl2bnB6cTZRUW5jN2RZSk4tUHg1WGVSU283d2pXdXZManAzaUh4aF95VUlZc1pwbUdSZk5HWjUxN0N5OHRLWWZjcmJ4dTBmVG04TW55WF9rdWs9
"That's a good point, I haven't tested it. For non-zero temperatures, probably not.",r/machinelearning,Z0FBQUFBQm0yeGJlM2I5ZEVIX3l1R25LQzlMNHJvdFFTb1N4ZjVVUjNBRUQ2OGd4RVZYRW5fTmFBaDJLZ2tEQ2poVVBtcnB6MHBOMjZoUnItWUJIREhNUkIyRnVFb3R5VGc9PQ==
Would you say that this opinion has changed?,r/machinelearning,Z0FBQUFBQm0yeGJlZEJXSXgxWloxTTlmNkV1NnQtb2MwWjYzeHhZZnpfdWlVSWhydk1HUVN6U2JpcW9kbnB4ZU5YclR5R1Z6MWh5SmU4Nk85NG4tRUFIVm9KSXVSWVNyLWc9PQ==
"Okay, just tested it. For low temperatures, it's a density to a very good approximation:

    temperature: 5.0 ——— density estimate: 3.9930
    temperature: 1.0 ——— density estimate: 1.3136
    temperature: 0.5 ——— density estimate: 1.0623
    temperature: 0.1 ——— density estimate: 0.9985
    temperature: 0.05 ——— density estimate: 0.9980
    temperature: 0.0 ——— density estimate: 1.0066",r/machinelearning,Z0FBQUFBQm0yeGJlRFBxcXJrTFNOM1BlVllTeC1qcmlzaXpSZ2U1WEUwOGcxYWZrQThNcTZULU9EeVdjVkNfNFlGSzhXRU03djJrLWMtZldaaHNjcFp6VFRGSHl0eG44X0E9PQ==
One thing I'm still curious about is How a Findings paper is being treated. I wonder whether Findings papers are indexed the same way as ACL's main conference papers.,r/machinelearning,Z0FBQUFBQm0yeGJlX2NvdEpKMDNTX3FPeHdMMkJUWEFpcmJqd0EzUXluRmtOMjdJdkcwVGRGQUx3N0hxODNxTUlTSHZ5Y3VWUDZvUWtQZm9tbGpnOTZwRUs1ZzUwOWwtVFE9PQ==
"Can you please clarify?

We've implemented [tools to remove PII/PHI](https://github.com/OpenAdaptAI/OpenAdapt?tab=readme-ov-file#industry-leading-privacy-piiphi-scrubbing-via-aws-comprehend-microsoft-presidio-and-private-ai) before sending to remote APIs, and integrating with local models is on the roadmap.",r/machinelearning,Z0FBQUFBQm0yeGJlZHQzQTE1dGFiZjVWTk9nVFBUUmpSaEVhM3k4S2dUOUs2ZzFUNFdvU0ZpZElkVUY5bjFmUDFKcDh1MjBCeXBDakVMTDJjbEhwNGZDdVcyMndVWmVHZ3c9PQ==
"For a temperature of zero it better be Poisson lol


How do you estimate the density?",r/machinelearning,Z0FBQUFBQm0yeGJlcVBwWjl3UnduZXFFTnpTSC13WkZBSk91YTZEVkpXdWVjeV91N0VWMmNxRFpWbGM4SnBHRlFwYlpZeE5zLTdBY21RWFVROTZUWFJfQTFhaEs2ejR0b1E9PQ==
"For \\\\lambda = 1, E\\[Z\\] should be 1 if p(z) is truly a density.",r/machinelearning,Z0FBQUFBQm0yeGJlTmxORHBERGRqWVoyaXZnbWVUd0xKOFJpUVFpMXNNN2w3WVpvSTJlcHVxbWFXbUxzVzRfUFh5R3hpNVdHc3F5SmVlSVBrMzdyN1lsZFdKb0FIdkJ1ZlE9PQ==
"Sure, I don't know all the details, I have not even been able to run the large model myself, but I know that:

- The small model runs relatively fast on any decent CPU, and consumes something like \\~5Gb of RAM, so pretty much any modern computer should be able to run it. On a M1 PRO chip, generating 10s of audio takes like 12 seconds

- The medium model can also run on CPU, but it's very slow, and consumes lots of RAM, the recommended way of running this one is in an NVIDIA GPU with at least 16Gb of RAM. On a M1 PRO chip, generating 10s of audio takes like 3 mins

- The large model, on a M1 PRO chip, generating 10s of audio makes the computer explode, so I don't know what it would take to run it honestly

I also shipped quantized versions of each model (small-quant, medium-quant, etc...), but results are very poor...",r/machinelearning,Z0FBQUFBQm0yeGJlQUxTTjMtd3k3NGFSSG41U0tpbXd1UENQWmUzX0NCd2FVLUlkUU1jbXlkZWdVeTFVUTc4eGdXTWlFR1JLcW9vb0FlczA5eklXVk9QS2Q2Rjk1ZWp2OGc9PQ==
"All the numbers in your comment added up to 69. Congrats!

      5
    + 1
    + 10
    + 12
    + 16
    + 1
    + 10
    + 3
    + 1
    + 10
    = 69

^([Click here](https://www.reddit.com/message/compose?to=LuckyNumber-Bot&subject=Stalk%20Me%20Pls&message=%2Fstalkme) to have me scan all your future comments.) \\
^(Summon me on specific comments with u/LuckyNumber-Bot.)",r/machinelearning,Z0FBQUFBQm0yeGJlMlF0alEyOHRBbkllVloxc2owV1F0bExGQ1JQZjJDc3BRVGdWWGZDN3YwbnRtYlJScXc3ejhwSUhsdjg4YWdRa3dyUzlwdzJUYU90MkJRRzQ5SU9rNkE9PQ==
wtf,r/machinelearning,Z0FBQUFBQm0yeGJlMGxEbjNCTnpaSzZqWGNHLWRnSllOUzZxeElmcy1USmdwZGtJcHh4djV3OW5vSlhqZmZpUUl0VmItdkZncXdXN052T3c4dVYtSGdnQnZSREp6Rl9IN0E9PQ==
https://www.reddit.com/r/technology/s/SM7NbvXNCU,r/machinelearning,Z0FBQUFBQm0yeGJlT3RMQnJVNGVXMlhscTVjNWJxLUNKNWlVWDI4S01VYUxWdWpyUGF1MExRV0R2MW9XNlZQZW5GbjRxUWVtZmxianJaUFYwaG9oS1IwdnlpWlRrUXdrQWc9PQ==
"I created a video about what I think - check it out if you're interested, and do you agree or disagree?  
[https://youtu.be/cBGBHnqns-A](https://youtu.be/cBGBHnqns-A)",r/machinelearning,Z0FBQUFBQm0yeGJlaVhXRjRuVERzWHFlZUVnLUU5a0hEVWFJbTBmdjlrVTlLWEd6dzBkN2N5T1RJc3B6MjdiT2NoRVVXSzZEOWtWbFl2RU0wQVBPYzBwRFlhTG1PYUJrSWpOS2VGa0p5bWVfejhZRWhXR1RJOUE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlczVabDR3UFVLa1c3TFJBMm5pMWRIeGZqSll0TmZYSmh2azBodUxWM2Y2dEJYTmkwV2MtbllJb1AxX01UQ1Nnd1ZXQVpCbzlQVEdvTnFzZWZSRE5LbkE9PQ==
"NLP is very much not obsolete. With predictive language models, you are relying on the input being safe an consistent enough, plus you have to monitor it for abuse. It is easy to do the wrong thing due to poor prompting or randomness. Not to mention the costs are astronomically higher, and you are likely relying on a large org to run ML inference or expensive GPU technology, but you can run NLP really quickly even on end user devices and embedded platforms. It's something like 1000x the cost to run a large language model. Remember you have to pay for each word that is input, and usually every word which is output, which may be unpredictable depending on the use case.

The main difference is staff cost (OK that's higher but you would have someone similar to oversee it), and the fact you don't need to do training for iteration (you can change the command).

Depending on the ML provider (epsecially if they provide an API) they may require the company to use it in a certain way, or disallow certain types of company or product from using it.",r/machinelearning,Z0FBQUFBQm0yeGJlQXV5eXhmLXk4NDZlbWJDYnNOVkhqSjZvY3M5LXp5OFVYQXRicGp6UDFYWHZkMS10dzBiZWoxX0dqcEQ1LWJ6djMtSGpxSjVPRkFyT3ZoTmI0VTh4V0tOZjlDT0NmRnRwMXZLV1o3Q2xBdVU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlenJIUUdCSlg5dXFsTTlja1FVQUxvVEhubDRmNERfNTBJWlNGOUgyaXVDemtWdzBsUTc3eFItZkZLemZJM1Yyek9zOUFlWTVfTkhodnIxUHI3b2t0WFE9PQ==
"These were already all being worked on. If you ever used GPT-2 or GPT-3 before the hype train switched from specific ML uses to overuse of ML this has all been an iterative process. 

Plus the costs of scaling and GPU compute are a massive burden, especially for universities.",r/machinelearning,Z0FBQUFBQm0yeGJlTWt0bzJiMWFHYUhsanZTYWJXZ3B5UUN5T3c4SVB0MjQ0QUt6RWZoOHRhRlpuM205YUpOZUdpVHhqN2FIdkg5WXQ5T3VLUXZkTXFCQVhmTlUxV0dFTnctd2wtWmdxTGIyczNYTVFrU0VCVkU9
"2Trillion _is_ an absurd upscale, it also has more than 4K hidden layers, but they just blitzscaled it all to hop the finetuning and show what is possible.

But it is _extremely obvious_ that the ChatGPT product release was mainly to gather data to improve the product. They also used the API by default to gather training data from any app using it until about 2023 (or 2 years after they publicly released the gpt-3.5 model in chatgpt then on the API) Though I don't think they expected the growth to be so explosive.

Microsoft partnership gives lots of resources so bigger models are less of a problem, and them it seems like the Bing team rushed to release Chat before it was ready so they could be seen more as the market leader.

They are still using data from the ChatGPT product by default, and I guess some people will have opted in to submitting training data from the API.

But I think the whole direction of what OpenAI has been working on since moving from not-for-profit to profit-limited org has been scummy. One instance is outsourcing RLHF to a company operating in Kenya. Another is using un-specialised models as advertising saying they are ""too dangerous"" because they will unsurprisingly predict anything from the corpus of training data (all the books, all of wikipedia, and relatively less of internet)",r/machinelearning,Z0FBQUFBQm0yeGJlWURkSGk2VW5HSFdOWE1RT1JzOWk4U3FQc0RiYTFEMFAwR2VhSE5IV0FhLTdQaEE4Q0haMGtBdnlUc2lhQTcxYk9ERG1zd0J0aWEzb051NkZ4c0VvTzZmRWtTQklZMUl6enduaU1WNnRjeHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWFlCX19FV3l3eG9jNnRON1FoRUdDNHFZbldHM2Z2YU9BdHJWSXZwYUYyQV9UZEg0b0c0TDdrRHBadlAyRzVkTENQa1VheHkxMnFOQmV3ZDQwOGVhUFE9PQ==
"Let's be honest, if big data worked that well by itself, the petabytes of data that companies gather would have reduced the cost and not improved alienation.

Yes, of course it is impressive that detection models can capture minute details and apply and learn from broad observations, but outside of academia, data collection was, and is, basically unregulated. For websites now, you just have sign a waiver called ""privacy policy"" and they are off to the races with geolocation, tracking the number of ms of every mouse move, click, keypress, and everything get from the internet being amalgamated and integrated by data brokers and supermassive conglomerates.",r/machinelearning,Z0FBQUFBQm0yeGJlTlJjYUk5SnYtZ3A1cklGUVAtZTh4TzZIN0J1R1VjX2xlVXlucWRjZVBoU1ZkLXpDVXdxRGdTV2UzOW5vcHMxMS1pUlprbmFlMGpuUV9KdV9mQXRBTmZ5aEk5QUU0dWFiZGdpMnRERzRZbzg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlN1JibWJ1ODNiNmtha0M5SFVnSWJjQ3J2cWdDbERkWS1kTTh5a2NVWnJNSU1Ed2g1Zk1ha0huTF9TZG82aXNleHJoV3BnemJHdDFaeHFUZDdPUGNxZGc9PQ==
"Everything is going to happen, so lets not spend much on testing.

The whole blitzscaling mentality of stock markets and capitalism is detrimental to everyone but those companies and the top 1% of individuals.",r/machinelearning,Z0FBQUFBQm0yeGJla01SWWVLV0FrZF9vMUxJWVpGYnk2djVJcVIxWEFpTDlzMVR6bFlJNy1yMXlKZk9fYlhfaUdKN0pSbWVtNzJZd2tLUzIzamkybjRtNEh1anc4cm9LaFBSNnZkYW5CQXMzLW5BTkVxV1VWYjQ9
"GPT4o (omnichannel) was natively trained with audios and videos, so  Can fine tuning be done with audios or videos without having to use text?",r/machinelearning,Z0FBQUFBQm0yeGJldmZUV0JydFg3Rjk0bWFJcW90UmNXSXEydjE3Tmx5VV9xX0xuNjB0MnlrcFBYU2FyZk1FMGc2XzF3M1piZjhvREd4ZzBmRTlfczNWNGw4UXJxU3lhamE3YzZXamdIZ1UzTGhGZmJkc1lmalk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlS2R1WnI3X1Fmbkg3c213SzFzeUFXRUJYS3RUNGVDRTNGcDVIRlNZS2pyYVRZTjlZMC1Bb0d1ZWUyWUdNXzlHMFFsVTdwcTczSGlST2xpRkc3VTNiSWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMmZ6NzlPTjFCSmpPYUgzNXBobWtTVl8zd01OaXh2d0RueTBSd3lmNm41cUhtVHh5ZmpBbnk0b1BRNldFOEliMHQyeUh6NXVaXzBnc1luY3NkX28zQ0E9PQ==
"If by feature selection you mean :”select all the non noise features/those in the causal flow/ non zero marginal effects”: then you can’t do this by looking at the data alone.   Trees/boosting:nns whatever can’t do this. You need to motivate notions of effects outside of the observed joint you have. 

If you’re just looking for ones that allow you to make good predictions: keep them all unless compute is an issue. If compute is an issue, you can generally use cv and heuristics like shap to select good predictors, but your mileage is going to vary. You should ideally be using bootstrap validation or large cv regimes(but if compute is already an issue this might be a problem for you, paradoxically ). 

Feature selection is a crapshoot.",r/machinelearning,Z0FBQUFBQm0yeGJlV1RpV2xTRzROY1MtYkQtZjZrRFY5VkVLZ3VuZHlrSkM0YjFBX0RTeS1iWVN4RHdHaVllYm1mRjkzMWFZMU5qaWtqbnN6UTg2cUMyd2k2eHFPOTEwVTJjZjRDWTdnVE8wZUdXbGJ1aUp0Tlk9
"They are not using web search engines for training data, they are using it for context (information and prompting).

The GPT-3 (original training) datasets are publicly available open source datasets, including most of the books, most of wikipedia, and much of the internet. Proportionately it is more weighted towards those books and wikipedia.

The RLHF (reinforcement learning with human feedback), a technique to train a ""quality"" classifier based on human responses, was initiated with data labelled and generated by an outsourcing company that operated in Kenya.

Oh and don't worry about getting ""more"" data, ChatGPT (by default), and the OpenAI API (by default until 2022), gather a lot of data. OpenAI has reached a deal with Quora to continue provide training data, and Reddit has reached a deal with google to continue providing training data.

They are both in common crawl but OpenAI seems to have their own crawler now.",r/machinelearning,Z0FBQUFBQm0yeGJlZWFQWGJuVDdsVThSbTFGNzFfNFZQYTNlVTA2MkdYZ21weWxOUnNoMFJsTGJSZmh3OGcwUFUyZEptcVBpZm50dFlLaGFESEJHTUdDUGZYLVh6Z2lhUU1IemdkN01ZbDFEMjdqdUEwZE9xYkU9
"It’s extremely hard to define useful from a statistical point of view.  Feature selection in general is a crapshoot, and this subreddit doesn’t give this nearly enough attention (probably because a lot of non practitioners, especially non  stats trained ones have been drawn here post llm craze) 

A lot of efron’s work shows that noisy predictors are often selected and “fit” nicely together with non noisy ones in models that are purely predictive (ie models you don’t do inference in: why/how like questions). We have large simulations that show most feature selection methods are hilariously unreliable (lasso, for instance only selects the non noise features than less than five percent of the time). 

As a rule; only do “feature selection” in the context of you only care about prediction if you run into a computational wall (note however, that in order to really ensure external validity of your model you often need to run cross validation many times, closer to 100x then just the four or five times you see in most tutorials). This isn’t sufficient for external validity: but it does demonstrate that sooner or later you’re gonna run into some compute issue. 

It’s always better to bake in domain knowledge for features.",r/machinelearning,Z0FBQUFBQm0yeGJldGN1RkIwS3hEWElCX2hNOGZtX19nTDFWb0ROaVBJbmk1M0tPM0lyVHZvMHB3WWFsbnA2Y1NtZXZ5U2owd3Fld3NCS2w2Wm1sVURDVjFkTHI2TmlfNGtQYi00X1VtbmFXNGhvb3dQSFVfbm89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWGVXelcwU2lrXzB4Z05VOXNRN1JsU3pBMmdRTDVRM09Ydm9PZFJzUUpkNWk1OFdWZVktbkQyT3lGYW1QQ3ZwM1JScWhNbzBrWHpkNTlib1VfQ2l6U3c9PQ==
"You should just use whichever epoch time format you are given, changing clocks or dealing with clocks is not a useful function in this application (or most applications for that matter). Ignore the actual ""clock time"". If you want to display the date/time, please use an open source library to do that.

If you aren't going to use the timestamp, but actually pass in a clock formstz then you will have to use ISO calendar which does not change and is fixed length, but again neither not the modern gregorian calendar perfectly match seasons (which themselves change) nor orocessions this will match the seasons.

Depending on what type of data you are professing, try finding an alternative calendar that is more predictable/related to the subject.

Again, using epoch solved the problem of leap days, hours, and similar, since it just counts up simply.",r/machinelearning,Z0FBQUFBQm0yeGJlX3BfdTNmckxzczRaWXkyX3FjY3Nocm1oRFhSR015ekhCUEhLeUxHRmsxOFVkM3ZyTG5MMG55dHVwdnlNLTI5VmJoZHNGbzU4WS1UVWdUb1VPZEw3clZ5LTBKd1A4aXZIMy1NNlpWbFVlY0U9
"I just got a desk rejection email. I completed checklist in openreview portal but did not attach it as a pdf to the paper.


If attaching checklist Pdf is mandatory why they had them in the openreview portal?",r/machinelearning,Z0FBQUFBQm0yeGJlRkI0VktuUmZFYklZY1gwV0I1alZpOTNoYWJlMGpMTVJjUnFjcjEyTG5uTFdTY2liU2ZyWm10dWlNUm1VT1FRNmNCTGFvUklwTUJ2UEt5Q0ExSXlFNjJiS0ZLVW5vbjdFZHlPaFhVZ1pGbmc9
This was popular when models were at such a size that the embeddings were a significant portion (sometimes the majority) of the parameters. Tieing reduced the overall parameter count significantly. With larger models isn't necessary anymore.,r/machinelearning,Z0FBQUFBQm0yeGJlZXFxdlVuaElmRl80NnA2dDNrb1l3ZGNPeVg2VDVpLXhSWWJRZ1BCTllIM3gyVnY0YlhYS0Npb3NlMTlJUmRYd1p5RU1QdUVhSk1sUzdmZXlzd0h3NUE9PQ==
Most probably not.,r/machinelearning,Z0FBQUFBQm0yeGJlV2tteHVrNG1kaTFPckYzdG0yNTNuOGduNjRMcGt4cjNvYVNBbmQ0dTdSUlhhNVVQbnpjWE5Ka21ELThmWEpMNWU4R2MwR3FvYnFTX1FzVFBwV1dYVXJiNldYcHZhNDhxenZBQU16WkhWX1U9
"We might be misunderstanding each other here. The problem is that the target I am forecasting is being released 24 hours at the time, except for to days a year, where it is 23 and 25. Basically the target is being released as a vector of values each day, but the size of that vector vary twice a year due to daylight savings.

This is not a question about managing time formats, it is a qustion about data leakage when using ""1 day sliding window cross validation"". If I set the window size to 24, my backtest would drift by 1 hour, which would cause data leakage during the cross validation.",r/machinelearning,Z0FBQUFBQm0yeGJlUFNyc010VTMzb3dkMHJTbmRoTThQZW5DQ0RDbGZiZDZmM3lHMDk5dEhaaU1mOTZIdnpzb1lMM2hqa2NnY1dheUdOVzZhY3lmVHhnWEdzaHE1THNpM0E9PQ==
This is not my field so I'm very much preparing myself to stand corrected - but the first thing that springs to mind is that processed signals from LiDAR are probably much less noisy than those from a stereo camera setup?,r/machinelearning,Z0FBQUFBQm0yeGJleEdsZkM3Q3BRdlVvbXFqVG16ZWhMRjd5dzg0SGoxc1FncGttMkJtZEViMVpLUG9Gei1KeWFHSVE2S01nLWZKU2wwTFJqMnFrcG9PYWJ5WEt0TW5WYmdvSC1lZDc5S2NFcGFlUEdQaEx4Z0k9
Same thing happened to me :(,r/machinelearning,Z0FBQUFBQm0yeGJlblpyN1ByOGVOTTdGbUh2Um1MVmJabzN3bnkyQTVZNTZNQk1LX0cybWNzLUw4UTBabm80NDE5WXZtb0RBNUZTa2tRdFFlTEhMOTFWVG1udkFoRExQNFE9PQ==
Thanks for the info!,r/machinelearning,Z0FBQUFBQm0yeGJlbWtqYml5RDU0ZWplQzlIQTA2MFBJd2R6aFVxOUR4TVZxZmx2em9SODcwSGlMV1NoWjI0NGtDQlBpVU0tYWZyNTlPNXNVRkZBUHpsRFBxQXltUUJranp0ZnpYT3VBejR5bzRKWHF5cjJ1ZTQ9
"It doesn't matter with large models. From personal correspondence with the lead of llama1, they decided not to tie it because they just didn't feel like implementing it.

If you do tie them, you need to have a scaling factor on one side or the other to control for the input and output needing vector magnitudes.",r/machinelearning,Z0FBQUFBQm0yeGJlU2xrMjd2U1BjeXZEM1lqZE1Yc1RZY1Q0VkFaUzdjWjRHTHJtb2VEdGo3YXNQNExTdk56WS1MTENMbmRteUtyOTV0R0tHdGFOXzgwNHE1RlA5N1AyaEE9PQ==
"My understanding is that when enabled, Microsoft's Recall mode is designed to always be recording.

OpenAdapt is designed to only record when the user specifically requests it for the purposes of demonstrating a particular task. In this sense it is no different from manually taking screenshots for the purposes of documenting a process (except that we do it automatically).

In addition, as I mentioned previously we provide state-of-the-art PHI/PHI scrubbing tools to remove any sensitive information if necessary.

Thank you for the opportunity to discuss! Feedback welcome.",r/machinelearning,Z0FBQUFBQm0yeGJlcXFKMkVyOGZPYTZIc3ZLNFZlTjYyMzRDdGl5aG93akxMRmN4YnNEaUpfeEdIakJyaVVJM2t0Wk13dmdiSDBGOWo5TE15RFNNQnBab1dSZGh1T0N1dlE9PQ==
"Sergey Levine has a great lecture on [making real-world RL practical.](https://www.youtube.com/watch?v=17NrtKHdPDw) 

Probably better to watch that instead.",r/machinelearning,Z0FBQUFBQm0yeGJlUFlCUWJQYnNWUHBxTUJnZ1NhVE9VMUZuWmJMWTVYeFNwVGZacXlDTWJhMDROYUg3VXY4MFRVX1NoWlc5QjJMLWFsdi1feDFvMk95X04zZjVRUGoxMlptUUZ1alFmRk56eW5rOU1BNUVjM1k9
Same here. Although I filled in the openreview.,r/machinelearning,Z0FBQUFBQm0yeGJlck5zSzlaQXlBaURicWRxX01DOTN4RzlLMksxakhzQzlfd0NlN1hMZTVYRGVnV1FEdUo4UTZiSFZiWlFKVGYtTmpQbDNua3RkSl9VRnFVSlZJZmpYTnZsVHNybnZZZjh4MUVuSVNtQWFoRk09
"LiDAR is far more accurate than stereo. Additionally, there are even better ways to get ground truth in a scene using light. I’ve seen a device from a NIST spin out that is incredibly impressive. However trading of scale of dataset and diversity of scene: LiDAR is still your best bet even if it’s not as ground truth as other devices out there.",r/machinelearning,Z0FBQUFBQm0yeGJlZmZlZ29PWGRCM1ZvU3JJUWxPalN2YldOTzV6UlpiSzdnMzNPSzBzRFkzUU9pYmpIb1lwaDRGNGpYMTh5WGpsYUcyRWRQa0VxeFZSSnU1LXVBSzhVc1E9PQ==
"Lidar produces relatively IID depth samples with high accuracy but lower resolution/framerate even in textureless scenes while stereo produces very much non-IID results with lower accuracy generally. So if you need pixel aligned depth at high res then stereo is good but finicky, while lidar just works for the most part. In AD it also gives a level of redundancy since you will usually have both camera and lidar while for stereo if one camera fails or conditions are poor you just get nothing.",r/machinelearning,Z0FBQUFBQm0yeGJlUWdDSEZHeDA4VFpMdlUxY0dGNzRxcUVuRGdlcDgzRlZ3UDVwWklQSmhNTGdQTHg3bHRIXzhQTWdhTXZuWEl2MzlrWmtCNDQ4NWMxcUZDZTh3V3JSQmc9PQ==
"Gotcha, makes sense!",r/machinelearning,Z0FBQUFBQm0yeGJlRV9CN0hwdlZrcThyZUJxZkIteWp5TlZMR3Z1NTZsdWZhNWZJMldBbktaWE1RbFZwbUptVUg1SkNXZDF1SUFXSVAtQnNvakhBYjd2MmtXZGNxUFBULWUtbHlTYXUwTjB6Y3NTSExscXJHYkE9
Desk rejection is just a way to cut down candidates. It’s BS if you’ve worked hard on the results. It makes the assumption that if you did good work then you would follow the instructions to a T. Just make sure to do your due diligence next time around.,r/machinelearning,Z0FBQUFBQm0yeGJleDdCMUV1TE9sSWUzR1ZFdDJUU25GTXZUS0RoQWRZQ1dmVUpLQUN1RjZGQ3RsZUpiZWI0czJfdDNtNDVvLTZ1ZHN3bjg2cXA4OGVUYTNJdFItYmo0eEE9PQ==
"Unfortunately there is more than likely no way to resubmit this time. They stated in the submission guidelines that any papers without the checklist will be desk rejected. I think they will use it as a way of reducing the number of papers needing review. Conferences change their guidelines all the time, make sure to always read the fine print. I’ve seen papers desk rejected for having an abstract 50 words too long.",r/machinelearning,Z0FBQUFBQm0yeGJldUU0ZnJ4cVZ3NjZDS292d3drOU4tWTBQRWlnVUpCX2JkY0JfQjVaQjNFMGlOaV9TMXp1OWhFVlRJNHJLWktOSEtCNGtFSWNOMlZuSmZGdHB5OFhabHc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlTUZXTG96UWEybHVRNk1Qekt4cDg1RHhIaUpHeEY5TFVXcVZBVk9WdWV1MlNVcG1DMXB0NXY2SVFZV2trNHpLQk9ENXFSand4aGFIVDBVNHgxNi1vSEpZZjFxd2lhNE9QZnpGUkhUX1hwMG89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlb1RRQk5qZHlLdm0zNXVZQU94TXFYbTR5OFFScHROQzluR0NNSWlaVjdtOTVDcmYza2FuUGp1dFFZUzFTWlNQbVFVMVZaTEduZGV4ZU1XMS1wV2xCcEE9PQ==
"The best albeit very hacking solution that I found is to pass the text in 4096 token chunks into Jamba-Instruct. I'm using Jamba here because it is exceptionally cheap, fast, and works great for this task. But you can use whatever. I've found that this works quite well.",r/machinelearning,Z0FBQUFBQm0yeGJlRU9MbXUyRXZETDR0TjdPRVYwU1JncHNTdXVWb0Fkc2tSUHBtRnJNOS1PZFZxRGJ5ekdmUW1mdUdrRFdxMWExYVpBU1pxUW0zdmxLekV1ZjNITkw2dGNMb1ktNnJkNVFhUUNWZG9IclpwVVk9
"Hey, I know this is old but just checking in. Did you get anywhere here. I’ve been thinking of training a model with side by side light novel translations and then runing it locally to translate light novels. I wrote a script that does a translation and can share it. It uses the chat gpt api and it got the Japanese by scraping a Japanese site that hosts web novels. I was able to translate the novel with I think around 12 usd of api credits but that included some testing. The main problem is I didn’t keep context and so the translation varies depending on the paragraph because there is more than english translation for a noun etc",r/machinelearning,Z0FBQUFBQm0yeGJlWVZXN1g0MWgtT0tLWjBJOE9TWVRVOGZSZ2xTT1ZYR1o4Z0w3clEwZHk1WWFYZFVnLWs3enBnb2pTV1JoT2hOellDdjZ3aTRTY2xobWhRLWF3QjFlQ01ab0JjVlkwcTlaQVMxak9KMnFBUEE9
Have you considered using OCR + layout analysis to extract numbers in context?,r/machinelearning,Z0FBQUFBQm0yeGJlbDMyN2ZNbnRsdm9QbWZMZmRXSXZrV2N3N05JeTR2NXpncHpSSVMzdjhhOW9LWGg5enBmYmgyUVFJVHk3M0dnM05GUjVmeU1IamJNaVI4Sm10a1kyakdsQWZYTUtSS1RaR0FHNEd2SjdRVE09
"Yes. Do you have discord so we can discuss? I have a proof of concept version of the program working and I hit a wall and was thinking of making a custom LLM. 

  
Discord: rk100",r/machinelearning,Z0FBQUFBQm0yeGJlX3A5ZnAxY0J5MXVpay12VWdvV3ZvWGRRM3FLaWlEczNXQ3hUYzEtZmg4a0NXcTlWMkpSRnpNcktlQVFETnBVRlBRNEVwQ2llM0Q0cFZmLXdGWWZNcGc9PQ==
Thank you! I’ll definitely give it a look.,r/machinelearning,Z0FBQUFBQm0yeGJlNVFlOGg0WDBrRWw1UkJoVWdRdkRIU1dVdER3emZsUV9wLXI3WHdORFZHUEZ3ZS1kVW5iS08wRGhxeV93NXNkbW90T2NWN3luR2hUb3VlTm00TGtGR3c9PQ==
"Lesson learned: always check the fine print, not just the template",r/machinelearning,Z0FBQUFBQm0yeGJlcVBCMHh0TFhsM200YnVJM0N0VkxQSFJfcnY4M1pra1Z5bTdibEJRUUdnMDRqaDlISnBpbHdTTFF1RUo0T3JjS2xqRkpLay1VWDM5aEFJNkhLUHRWQ2tWYkZJYW1KQkl0eXBqdjJZQnRXdTA9
I can feel your pain. My desk rejection was because I forgot I submitted print-ready version. At least yours in not that stupid.,r/machinelearning,Z0FBQUFBQm0yeGJlSEZoc0o1UGV1NGFRb05OUmpLVXo5UmRQNW1mbDZZNG5uUWUzYy1BV0NqSHhyZ21TVmNCMEtxdU5FU0poVXdFLWxsSXdRUXNQd1VBTGlqTEN1VzRoemk2ZTdUTWEzNDQxc1BlOXRVNGpMSGs9
I’ll add you discord is comradedave,r/machinelearning,Z0FBQUFBQm0yeGJlSmNjVjlITlRNdGh1UEtjNm9jYTNYY2t6eFRWSlM1b2p0SFg0Zl94a0xHTVViSndEWjJQR1l5RzdZU0xsWU1FSjU1ZDhFUXlCRXdpUkxERkFxTG9KdWpGWlpLZnRWUDdpeXYwcThYbnozX2s9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlQkp6QXcxTFc2MzRSVmFPRjNKZ1ZWYkUzVmlRSHJvbEs5WlBYYkxaajBub3V6MGwtWWV4Zjk0OWxIVXhSbVItbmJoeExTNnJ2SnZGWHBZVzJ2ZmdFdHc9PQ==
"Thanks, that's good to know. Though, can you please elaborate on why one really needs the scaling factor on one side. Why would it matter for the output if we apply softmax to it anyway?",r/machinelearning,Z0FBQUFBQm0yeGJlRnhUZnpzb01VLWw5LVhtVUwyUXB1SmNWbHJtQi1RU2U5aVJNamI2RS05Mi04RnF2U1hxSGkxLUYtaVRORVVxeUUzRFJjT1dQX0N6X3J0NkNPOVpvZ0E9PQ==
"Thanks, that makes sense!",r/machinelearning,Z0FBQUFBQm0yeGJldWpNaFdEYXFaSmdKV3NDdGJFbjBucVM2Um1PMnRnMkQwT3FiSy0tb3FYRjBtZk1penFabWRuUDFBRS1nQTFScW45VVd3VFQ2aFNWX09wNldNMjZXd0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlS2JTdzJYS0tVbEVFX2F2S3FyRk5oT2dtUnlHVHhRT2ItZnVqTENiU3k2eTEwRzFldWtrZnR3XzhCdF9CQUVXN3REdVVwLWM2aklGUVg0MVpmaGt5cXc9PQ==
"Great review, I would go with Arousr from the list",r/machinelearning,Z0FBQUFBQm0yeGJlakNQaURfQlF5NlRPZWdvc0FUekZsclM4RW5Jd3FTeVY3R09KcFBVNXhCcTIxZ3VUQ1hwUEtJT18yUlBmSmxxaXFncmFfemYwUWhNRU00SmZyX19FZ1E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlTENjcVFxTEk1RlVKQURhTVFITW5nTlVKQ2xld0hsUTUzaHNORzRwbGZTclNqSDJlaERlcjQ2dVNHYWctOU1iSGNBcnZfeFZvR3BBaWwwRTczNGFJMEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlX2p6QV9HdG5YMnJKQ1M3REc3V2xhS2M5VTdIcUJ3eHV5OUtEaVFMQkJ0Nmo3TFNiTThZZUY2M0pLck5RejBfX3dTNFA1REZpZVVYbG5ZdHQ5c2ZaN2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJld04wUWkzUkxpdDZjYVFIYVpTRnZ6VVNOUllhWDdzQ01zV2FpMDIybjVhUlNKNjNjV1RVcDE5TnFFd0xEQXVBb0ROTlBKVjZJQVA2eXUyZ0dWbHpMS3c9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJlWm9UYm1PYjFrV1FWUm9kaDIxS183WnhvSHhXZVpXTmpKR3JsZi1RampMdzlBaTRCazhVak9qVXhNa3RHbEExWkctRWlNUXM2aWJ3c0dlS1pWdDF6WVBZX0FBX0l6OVZ3bjdUQXRvamVzVzA9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlUnl4OHp3dVNHTVFldEJkSFZ1WW1vM3VBaU1YUFhTUG1BMGIyY19pbUsxZjJ5OFp6TXpBMFhLUHRVb0FjdkZ6UGxlUWctaFcwcjlxVmhLYXRMeFdCZWNUaUhQVHEwZFdieW5nTkFFcXBrVHc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlVm84RTBnckJyNUx6M3ZqZjVjTUQtdGp2dldjRi1vRGxJZEhvOHlZcjB4d09VNmVINl9ZSkNiTFQxRzlFZTItN09IZjJFZHRmdEt4dzJzYlY1N09NQVE9PQ==
I did provide paper and checklist in supplementary.  It is also desk reject. ,r/machinelearning,Z0FBQUFBQm0yeGJlQ1FBMEpfd0UtV2RCQjZfVXlVZGEtVkowZmVsbFNkZ3ZoNUtYTl9ZSUluekhBbmdkUVRzZkdrLVBpYVVlWGw0S3h6ZUJiY29NczhhWnROS0JkUmhibTdSYkRuamlCcU5FTUlsUFhEUC1rTzA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJla1ZlUmtqLV9lSGNUZ0lLbDRfcGp6TjdxMjRiSk5BMi1TWTliTjlkT1RQSnh0RFA3bDg1QWZKUXNrb0hmQXZSWGlEdDdtY0ExOC1EOVNjRUZuODhabkE9PQ==
"It saves 50% of computation in a self-attention layer as KV is shared. However, the inference process typically moves than a single layer, so the shared KV does not match current output.",r/machinelearning,Z0FBQUFBQm0yeGJlb2QzNlBhaWhKaHVFT3JHRzZmWWVqLUVxcXpsT2hsVFVZWGNSRzlOellscnlVc0Vvd01vbFhEcmVGQXlzWHZnXzI2UGxDdjJDb193eDBKUUFIbm1mWWEta01uSk0xeERmS0xld1NjaTgxWkU9
I am beginner plz tell adivce,r/machinelearning,Z0FBQUFBQm0yeGJlSDBhMkFXcHhRcGhVdXM4Nm5vR2hmOUdtaDdkMV9vd2lYT2wxWlZ2aWJMYnBTdDV2eG9PdVMwcjBfUlpFOWNhNjA0QVVxNUhWcTdPTkoyVDBzeWNuY1E9PQ==
I am beginner plz how to start,r/machinelearning,Z0FBQUFBQm0yeGJlcTY4bVlhWFMwQzlhcWZTbHl1VlcwNUVmc0JJdVVJUGp2MWx0TjJXMmpMYXVad2dTazZfaWtEaUJZc0pPNXZJRWpKR1RteGFvb3luV1o2emdsOGhoNXc9PQ==
Same here. I feel like I just lost a big chance at getting my voice heard. Now I have to find another A* conference to resubmit. Any suggestions?,r/machinelearning,Z0FBQUFBQm0yeGJlczd3M2NYSkhwOWRNLTRpNUtsZjFtSUtyRE9LMWRkM1pORXYtajM3VS1hZURTelY4MGllMVUxamVkU3ZnazRJSTFBQ0swR3BLQnBrOHdpbkgza0tlWnVtTUJJYkNaTVV6UVM2MXh6NHFBcjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlQjlhRE9KMy1iZmJqWWphWEtZV0lXM001eDhzVVUxMXVUNl81N2RiN0I4UHgtOHBoX2gtb0dQMk9WRzlJMk04SFFOMm5xcVp3eVhMV1VnUGhUSmg0SWc9PQ==
What do you mean by non-IID here?,r/machinelearning,Z0FBQUFBQm0yeGJlSlBscXJFU2VHUjREV1ZkelR0dmY4dHB0MnFvWU0yR1U5TUg4N3ZOeGJaTFpMcFR1alNuaFEwMHRaeUJnc21VOVphM1ZsdzJWMWp2V1B4YnM4U2ZYZEFVUHhTMHNXcWF5VHF2U0NzRXRjS0E9
"output softmax wants embeddings to be very large so their inner products will produce very different values

input embeddings want a much smaller range so they can have stable dynamics throughout training

all the ""old"" code bases had this scalar (usually sqrt(d)) but the llama arch dropped this when they started untying",r/machinelearning,Z0FBQUFBQm0yeGJlZkd1cjBWY3JnWGV6VEJiN1lsMkpoUGJTRl8zNHA3cVlKQ2FDQjAwZFNLdTVoSF9lRWtWRlphV2pQTm8wYV9IbERXT3NIUF9YQzRLZHBYVERaMTUzdlE9PQ==
"“Independent and identically distributed”

Stereo usually does window matching, or convolutions for neural methods, which aggregate over a spatial region. So each pixel depth/disparity depends on its neighbourhood and potentially globally depending on method. This causes structured artifacts that are content dependent.

LiDAR takes a time of flight measurement for each pixel. Ignoring high order effects like crosstalk and scatter, which are usually small, each pixel ends up being effectively independently measured. Consequently the measurements look like they are corrupted by noise and are much less scene dependent.",r/machinelearning,Z0FBQUFBQm0yeGJlQUM2M1VHVEdkeDFmRGpqVjJqZmVxT2J6d1FkcU9Sd0FDM0J4ckNld1FKbkRUVS00WFhZX0gxc0IwbTR2WVNXMTdUSXBSYW9uWFpwOXZhX0lEaUpoZWc9PQ==
"I know but i want to know how it's possible for the new shared KV Cache to hold all the information that usually the individual KV caches would have. Is this shared KV Cache larger? 

 (see my question in bold in the post)",r/machinelearning,Z0FBQUFBQm0yeGJlVGRVeTAyMGVqUjBGb2ZFR0RGbVBYR0RsNTU3Q0dkNmNaWkJIUGFaVHBNNENCSFVBS1RxZGdXMkRyYzVVU2JKczZGQWpxNU5HZ1JWelJ1RlBpOHlTc0hUdWowWTlQdDV1RmlOSnltLU42aW89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlT0xjU2oyOHNNZWk2aWtuLWtnVWJnU1pVNHMxNGZZZmhXYXdsUzJEZUFhVVBETG1qQWozYVkzaU9fMHAwTEZCS2F1MGtwc0xuWDdyZ21nY2F6QlRvVWc9PQ==
I also remember submitting it separately in open review. Is there a reason why it was required to do both? (Unless I am misremembering the separate submission),r/machinelearning,Z0FBQUFBQm0yeGJlQVV6WVliY3RSQ09pek81SFgyYUNYWUtqV1E0Rm15UVl6R0F4bHFncjZIbU9LaTJaMjNsTWM1Tklzc0xYZ19tMXZOX0Roc1FJYS0wVWkweVJRdFI5Rmc9PQ==
"The answer is likely that it’s because attention in every single layer of the network is hugely overparameterised, and what the model benefits from is just parameters in general. 

As long as you have a deep enough self-attention decoder, you’ve likely enriched the representation of the KV token sufficiently. 

What is important in these models is not whether you use attention specifically, but it is whether or not you have a component in your model that can mix tokens together to create a more complete representation of the words. That’s why attention variants also work.",r/machinelearning,Z0FBQUFBQm0yeGJlSmFsQTBRWTBvMm1nZWFLMnZIWGV1RVRTd1BiX0I3X0FkVHlLWXhYQ1ByZkRKSjRzbVVHN3BSaUxEcWxWU1Q1TVVuejNNLVJ1V0VEVEEtSkZPXy1UWXc9PQ==
"how exactly KOSMOS-1 is different than the MetaLM? KOSMOS-1 was trained based on MetaLM. When I read these two papers, I find no differences except training objective.",r/machinelearning,Z0FBQUFBQm0yeGJlYjlxTk9RRUdzQ1FqM1ZnOE9xN3p3d1RKai05dVZPTjV1Z3h5RG1MZlU3VDhfdnNxOVhLOUVGVFJXUUpma0lHcFNUbmx3a29HR25HRFhHcDZSSXRjTHpkbW1jNEZtcC1xUnpkdXlZR05YOWM9
Can you configure AWS lambda to run on GPU for inferencing?,r/machinelearning,Z0FBQUFBQm0yeGJlR3p3eUsyeFlZcm5qX0x1cGVTakVLZzM0OGxTUDdyeGprQjRrMXJmNzZIZ2NLOXRmZ2xWdW1EcGpJbjg3eGZHNjNLUk53YV9ac0V5MHU2eDQ5UnhfUVlPdzJybnhpejZHaVJOVVltT3d1Wmc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlT1NHTjVJNVlhaE1CUXYzSGVoWmpna2JWbVVtbzllQnFDUVpvQi1INi1FVndFeFN1NUZPakUwSU1XdFRNcWlKdVdfdjhROXdGSDZHNnBqSmItTmZZMVE9PQ==
Have you looked into using Docker and Flask for a simple REST API?,r/machinelearning,Z0FBQUFBQm0yeGJlWUZocVJ2UmJfbHRIXzltb3RZNUttM1NNUzg3QVVJUXhWaXZxWjZHTWVIQTEyWlplbHgyNTY1YkVxYjFONkh4cnBmd1RrZWZhOGl6LWIzYmcyc1ZZbWZjQkxteV9wR29STFJLcnlPVVpZeU09
"I've dealt with quite a bit of model conversion (mostly ONNX to TFLite, but not H5 to TFlite). The reference code first trains a Keras model, then exports it to H5. Can't you just directly export a Keras model to TFLite instead of going through H5 first?",r/machinelearning,Z0FBQUFBQm0yeGJlRlhFU1NnTnZReWRoYTNmUkVoMXcxQlFmR3MwRE1CaUhYQTRkX1l1ZVJQVl8wczlISmhKdXI4bHRaQ0tJYWkwVkVYdzUxWVF0QXB1cVUwTHJ4cElvOGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlcWY1WWdiMEIzWWpubjlpLUhXZG1GZ3B1VmFCS0ZWU1pMMHpFNXk1R0d2V0lJakRnd2U2WG1CV2J5RTI5OVpadDQ5UXZSZlRXVF9VWEVfQnVER25yTkE9PQ==
Try using torch.nn.DataParallel instead of copying the model object.,r/machinelearning,Z0FBQUFBQm0yeGJlMnRjSjdDMlNlNTNBY3BhcU1VWlVFZ0dPS1E0OWxMQU9XNUZxeG5uOEw3RVhyTThpYW1saEJfa3o3a2VZNkJ1TlFlcEtCWm9KSWR3VkhZLVFnaDdINWc9PQ==
I died. I’m in the ether. BOOO,r/machinelearning,Z0FBQUFBQm0yeGJlNnhURXhpemtQM0ZxcXRyWG5wRGs5TGNPU0gwSTlmQzJER0d1THJ6X3I2RFhPYXFOdjhGZXhIUHV0QlNiOVdXTnlGWnNnd254algxQnhrcXdUeG5OQlE9PQ==
"Use this as a learning experience. When submitting a paper anywhere you should RTFM, which in this case means reading the submission instructions from beginning to end and at least scan the entire style guide.",r/machinelearning,Z0FBQUFBQm0yeGJlS0tXYXdTZHRZX3hjY2hmcDRaanVzS3Z1NjVIajhTSmZoOWh0LVhYSHlBenIydVhuZ3NOWE11SkRvQ2UxZDVvUEVTcG1ITG01TzhDZVRaNkw0UUdvcXc9PQ==
Sounds like a game-changer for warehouse robotics and inventory management!,r/machinelearning,Z0FBQUFBQm0yeGJlZzRZYmRNLWNIT3VzNnFQTnc3S3htWldRWFFkaXR3em1rYkdiV0wxVmsxeXNQMVFyZUNMX2o1OElCLWpVM250b19ZX1VORC12bVhMNWh2LXNXbjV5MVE9PQ==
Sounds like a promising project! Would love to see more details on the technical aspects and potential use cases.,r/machinelearning,Z0FBQUFBQm0yeGJlVGt1MnRHT1gzdG5ZYTQ3VTZMbjJmNThkdGVtNERiY3gyaEtzOExlWF9XT1Rab1dscXZZOFpHWHFIX1JVWURfMDFkSktXTXVHUzNRTkVVTFY4T0tPVVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlZkp2cnRBZ0JjNy1OSkxldk04VEJLdEY2TmRMd0VnbEVJVGZCQlRwMWFpQ0NwNGE4MzRZWUl0OUVNYXFMdkl6aHFEX1RHZjJ5cEY1WEZQdEY1c3BfRlE9PQ==
"My suggestion is to play with it a bit. Your choice of training data will actually be more important than the architecture, at least in the beginning. 

You're limited in parameters so you need to limit the scope (at least in the beginning), so something that's pretty homogenous like TinyShakespeare will let you see if something actually works, then you can move up to TinyStories, then TinyBooks, etc

You'll build up an intuitive sense of how these different modifications effect performance. And as you play with modifying the architecture you'll see what symptoms arise when you experience common issues like breaking causality or exploding / vanishing gradients.

With the model being so small, you can even experiment with novel / exotic stuff like using complex numbers or parallel attention, etc etc

The truth is, big companies aren't incentivized to really stray from the tried and true transformer, but instead iterate and refine on it. Unfortunately, those techniques don't work well at such small scales like 50m parameters, so we need to test novel techniques to see what works.",r/machinelearning,Z0FBQUFBQm0yeGJlU3cwb3UxUXNhR3FtR0xqRmNZZnE5aTNHNTNVTzlBZVZNbENxRnVEMXpZNWM2a3lEVUY5a2JlQzVzYnpsTmhKSlNJbG9sRGJ6RXRqM3ZNMndvaHcyQ1E9PQ==
"It's entirely possible that your classes are so distinctly far apart from each other that by checking only one nearest neighbour it can tell what class the data point should belong to. It really depends on the nature of your data. In my experience, I've never found k=1. But then I have limited experience and you always learn something new.",r/machinelearning,Z0FBQUFBQm0yeGJleWFzSHh5RG5lcVl6cXh0LTVxNk9iUGNZTVZhNGNtUE5FSFR5M0RzZ2wtTkhsYVk5bXFkcGVRTU5oNmNOR2Vqbm1SVnBhLXJpazliUzdPUXEwUG9obFE9PQ==
"You should have mentioned that your data is in Turkish. If that is the case you probably want to find an embedding model specifically trained on the Turkish language. OpenAI's embeddings are multilingual which likely won't be as good as a Turkish specific model. Here are some that you might want to try: https://github.com/Turkish-Word-Embeddings/Word-Embeddings-Repository-for-Turkish

Another thing is that when you do bm25 you're going to want to use some sort of word piece tokenization method since they are more robust to misspellings. 

Also, with regards to the performance are you weighting each of the semantic and bm25 similarity scores before combining them? This will help you tune the model and make it easier to adjust the results. Additionally, you want to make sure that you have pretty rich descriptions so that the vectors in your embedding and bm25 space are well separated.  If you're working with a bunch of 2 word descriptions with lots of overlap between your items then your search will not be good no matter what you do. 

It's possible that your latency requirements and available hardware might not require any sort of ANN methods. You should test first before implementing them. It'll also depend on how the frontend is implemented and how quickly you expect your index to grow. If you find that you need to go down this path then pinecone has a pretty comprehensive overview of how product quantization and inverse indices work:
https://www.pinecone.io/learn/series/faiss/product-quantization/. The gist of it is that product quantization greatly reduces the memory requirements of your index both by reducing the dimension of your vectors and their precision. An inverted index is basically just a way to suggest candidates to search over instead of searching over the entire index every time. In combination these will greatly speed up your search without much additional loss. 

There is a library called faiss that could handle a lot of the implementation details for you but honestly I haven't used it I've only done it from scratch.

Finally, if you need to be able to quantify the models performance it might be worth the time to make a validation set of queries and a 'ground truth' nearest neighbor for easy comparisons... you will be doing quite a bit of testing if you go for the IVF-PQ method",r/machinelearning,Z0FBQUFBQm0yeGJlN3dNUnQ4Rmpwc0R4aHhCdnNyOE16bWNscW90MEYtTk1fQ05pMlpyM2t6SGhSbWhHbkdPOXlpWW9DR2hTbExUYWNYcm1FdkN3UG1TdnV1RnhOOWRJVGc9PQ==
"There's a whole section in the Wikipedia article about it, so not really. But if I got this result I would question whether KNN is the most appropriate classifier",r/machinelearning,Z0FBQUFBQm0yeGJlcVRHbkVVQjZ1cWxZNER6am1sRlBxVHVFRmZWSGdSYUZIQ1VIeVB0c0dkQXg2cHU0UU11NTk5TDk3UV9QQm52UVdjX2RjNWNyUFdHYnhESjJ2aDZobmc9PQ==
"Yes, but lambdas don't really have persistent memory so each call would load a new instance of the model. Technically I think Amazon does do some caching of resources on the backend but you have no control over this. If I remember right every 15 minutes or whenever auto scaling happens the lambda will shutdown and need to be cold started again, i.e. the model will need to be reloaded",r/machinelearning,Z0FBQUFBQm0yeGJleXVMUlBSVGNaekR3clZHMGh2U01rT0Vackx2S21RODZ5S2E2TndhdlF2U2x6Y2xqZFNuQ2VwMzUwcUlZQXVldlhDQ0VrNTk2aWpYb0c3dFY4TGJSS0E9PQ==
"You are running into a data normalization problem.

To solve this first interpolate between your time series data. Use interpolation that adds no bias to the data (linear) don't use any smoothing as that will leak data.

Once you have an interpolating function y'(t) sample from that function at uniform time deltas.

Use those new samples to train your predictor.

This should solve your non uniform time series problem.",r/machinelearning,Z0FBQUFBQm0yeGJlc29KN2t4WGhvSDJSRnk2R0xqMXdNbkJCYnBZejExRXQxTzdIOERSRThnZjlnanhkZ3VPdVl1UW5ZWDI5MEVMWGNYV1Z1MnVkcXZtOExEZEc0Z013MlVoZEtqQjVSMTFBdml1ZmlrWHJxX3c9
"a fast solution could be to adjust all vector lengths to 25 with padding, but then only base your loss on the 24 values that will be there for 363 of the 365 days, essentially discarding the padding.",r/machinelearning,Z0FBQUFBQm0yeGJlZEdrM1loekVYTkp1U1hBbzVGT1ZBMUJmVlUwdWV0MjVsUnlPRklvM0N0UVJ2Q1lmclFzcHhDc0RsUDZxdHl6Mkt1a2Q3YUVnbERlaHBjMTFReVV5eGc9PQ==
"k = 1 is often prone to overfitting. That said, your data might be super easily separable. A logistic classifier might be more robust, for example.",r/machinelearning,Z0FBQUFBQm0yeGJlY09HUUVpbWZCWlhBczhnOGpxcjFwVFBXM1I5Q1B3Z2Fqc3BjSGxkSGNUSldIcmM1SWs2d2NwUHhrbC13bVoyTmdqUDEyUWtKWTlkSm9kdmd4UjQ4Nnc9PQ==
Thank you! I'll have to read the introduction soon!,r/machinelearning,Z0FBQUFBQm0yeGJlMVZGUncxOFlzcl9tRjJ4V0xiejJ5MUpwSmY5M0JSRDZmYnF2SGJEZDNMdENOZXpvTDNuc3M5Q29aUE1DTlFqQUJJdzhVVUFLdnduN3NsTkU2cWtKc3c9PQ==
I can see that too yes. :-),r/machinelearning,Z0FBQUFBQm0yeGJlbWR6UHBOWHYxanJ2YW9kZXFITEVYWWQzUEVPQkVUaDY1X3A5OFJJSDF0Q1p0UF9xd05kQjhvSjd0NVBTZ0pkeklGMjZUSEVsekNwS1NLRG1DMXBqMkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlY1F4UUJybUpwQWtIZjZrQ3N6dEJIdDB4dVN5YWRscEg1NjM4RU5uSmlZYWVMSEZPV042OS1fWk85U2FRdHNFSGZuWHZ6RUg4THFkNk5GTzJMMDRNV0E9PQ==
"I have use KNN on literality hundreds of problems over 25 years. And yes, sometimes K=1 is best.",r/machinelearning,Z0FBQUFBQm0yeGJlLWRXaVdOT1ZiY1BIS0ZLY0c2V2Ytd2w0dUEyb2xGTmZxUHNsTEdFVGJNbG1MWFVJaHJHVHJnVVVxdXp4cGlCMl9RQ2ttc2JqTFpmcl9UVWNYcXZocUE9PQ==
"Good chances: AAAI, ICRA",r/machinelearning,Z0FBQUFBQm0yeGJlV01jVExJbDEtcm9sbm10N19pZEZtS1djZzRMdjBJLXVRWnZuX3hjb2pCdWREcHNLMGhwNVZXeV9IYjByN25PU2NTQklZNEVWZHpPaDd6YzQtQWlFM3Y1dUdlQmJQWnhtQ2ZoZ3FWZFoyZXM9
"Forget theory, here is a [real world example of RLHF](https://youtu.be/QpwE8QDj9cI)",r/machinelearning,Z0FBQUFBQm0yeGJlNElmTWl4T1JiNWMzcmxiVWc3VjFHZzRCUHpST2ZpVXFMSGRYUFVtbGgtbGEwUXh3YjNpMy1iQUVOVE9FUFpaeGtUcVl5bTZ0S1JXNEtMeGxVT0pzYkE9PQ==
"I don’t see this scaling factor in roBERTa code base. Any idea why?
I’ve trained LMs from scratch without the scaling factor and they have seemed fine - perhaps I would squeeze more performance out had I tried it though.",r/machinelearning,Z0FBQUFBQm0yeGJlV3lJaHVMa0dOVElkMGNraGluLTQydm1zQUl4X3FwejQwVno5Szh3Q1VMTjVmbmplNEc3VzR4NldiNWdjV21TVUs2VzZQUWxqVmw2Y2dsVUFWX19tdEE9PQ==
usually k=1 is the best in my experience.,r/machinelearning,Z0FBQUFBQm0yeGJlVklERkkxb3o0RUs4NURPRzNIQmlnRlc0NDBjNFpqeDBZZGpwM3J6X2VXelVNd0JldXg3NXB3UG9MTmFEQU1kM3J6Rk96bmEzVmZ6NjQxTDluT3JOWlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlUnk5Ym5ZdWhCRmtwY1AtRkVncFo1Wk1jM2xvYk5ISGlJR0gzWEh1TEdLYUxxZDBvRVcyU1h1VVZfaWliaUtSaWtla2ludlIzMjVMUmptalJ4YjB3SFE9PQ==
"It's not just prone to overfitting. It is overfitting. You're saying that the single closest training sample determines the class of a new unknown sample. That's extremely high variance, no robustness. ",r/machinelearning,Z0FBQUFBQm0yeGJldV9jLVNsOFhhNWRBcnBSREhyMF81YW4yREdwZ205OEdVREdjTkN0OEQxWERNYzh5Ml9tQWFQeldsa3NBbzB5Q20zRVVOZi1yQ3owMmxUYU51WlJucnc9PQ==
"https://github.com/facebookresearch/fairseq/blob/bedb259bf34a9fc22073c13a1cee23192fa70ef3/fairseq/models/transformer_lm.py#L137-L139

https://github.com/facebookresearch/fairseq/blob/bedb259bf34a9fc22073c13a1cee23192fa70ef3/fairseq/models/transformer/transformer_decoder.py#L81

https://github.com/facebookresearch/fairseq/blob/bedb259bf34a9fc22073c13a1cee23192fa70ef3/fairseq/models/transformer/transformer_decoder.py#L307-L308",r/machinelearning,Z0FBQUFBQm0yeGJlSmVaZGtkVkZESTZsNDJ5MzFPTEZFN2JTNzZoYXh1czh3WXpVdVU0S3hLQ2lzZ1IxODJSRkNFN3F5NDZDaldibXRwMk9qVnNlVjNlcGV2RWdGOWdoS1E9PQ==
You might enjoy this blog post on a similar idea on competition but on the neural level: https://meltingasphalt.com/neurons-gone-wild/,r/machinelearning,Z0FBQUFBQm0yeGJlanhJTnl0OFpyTDJrNVhBcWM3LVlvN3JIRXJTdWdXeTVDVU1Bd1NHNktBR3VnaXNyWUJONUFZYlVHVXo0YVRoaXhCanNRMUkzY2hfT3NocmxoR1lLelE9PQ==
One of the strongest baselines for classification of time seriws is using knn with DTW and k=1. So it's not that straightforward.,r/machinelearning,Z0FBQUFBQm0yeGJlNnVpQ1NZX1ZYNk5KU3d6YVRlUVN6SHd4dW05S3N4M3hreEJCd0MycjJRMmgxaWM5enN2WHhDbFh1SXR1N3V5N2IyYzR6QUdaTVpmZ3NxQXBkcFZQcFE9PQ==
"No. Just stupid, so learn from this. Bitter lessons.",r/machinelearning,Z0FBQUFBQm0yeGJlWDhxXzZJc2pTMGw3Qmd1MUp4OUJvb2hnV1A4dXdQZWVZTlBXNEpGbDFBSWtHQ0R0Q1BGSHprVFBWVkoxOUVuQ2lWektyaGpncUdobDRRMGRxRlBWYkx6THVZVUUzRnVSa3VjZG1MYlp5TE09
do you know what motherboard they use?,r/machinelearning,Z0FBQUFBQm0yeGJlRXhlbkZqdEppdXZacTc0dWZTb29ueXdMMmVTQnZPRElNNGo3azhFR2JsVVo3eEdzLURTS0l2LUgzMlJ2Rk5ON0F0VERXWThRMEdsaUZCV2s2YS1rMlE9PQ==
"Where do you see that lambda support GPU. I didn't find any reference to it. Also, AWS Sagemaker inference end point don't support GPUs.",r/machinelearning,Z0FBQUFBQm0yeGJlTmR3NFgxVWdJNlNLMXEwWjF4V2gzd2dxa1hFZXFCVEVxam9SenJUV25Gd290M2FJQml0WlFITndHX3ZiSjJCbXNhbWUxWDFhdGZzVXh1SjlWMExmQ0J1allwV254cjVUR3V0eUJsOFNFekE9
"Same here. Why even have a checklist response on the abstract submission stage, if we are meant to include it in the pdf file anyway? This is a load of BS.",r/machinelearning,Z0FBQUFBQm0yeGJlOXZVd21MbnNsbjVXaWdKMFh3YmhJeTlPYlVhT3VSOHRJclRiYzhkbThiWG9yM0xBMF9fbXJvX0xYaVJqb2ctSjhqRmZXTnFvQVRmU2pST3BJSUdnRmc9PQ==
"next big one is ICLR, but at this stage I'm just going to submit to journals like TPAMI or TNNLS",r/machinelearning,Z0FBQUFBQm0yeGJlV3BmUjFUMGNOdEM1X1lmNXFid0w0cl9MM1hTd1FzRlZUeTZhS09WR3NjV3N1aWJ2aXVYRFVBRHM2TjgyMkNkd2V3WUtPUlFFcnZyMmw2bTV2RzRMYVE9PQ==
"I think it makes sense to share embedding with softmax, this makes it easy to copy tokens, for example.  
If you want a fair comparison I guess you should compare 2x bigger vocabulary + shared embedding-softmax vs 1x vocabulary + separate embedding and softmax. So that the total capacity is the same in both cases. Probably somebody did already but I don't have a reference.

Also sharing makes things slightly different from the point of view of the optimizer. In ""shared"" case, each token embedding always gets some non-zero gradient. In ""non-shared"" case some of the input tokens will be very rare, and may not appear in the batch even once, and will get exactly zero gradient. Then if the optimizer does something clever like normalize gradients over one dimension, or keep exponential moving average of past gradients, or something like that, these zeros could throw it off.",r/machinelearning,Z0FBQUFBQm0yeGJlR3ZPZi1ndFRwcEFRZDdDT3NSQlJqTU1CNHRaRjJRaG5KZXhya1VxVjUtdVFsaHBZQnBLYnBWZGc0bGNFVjQ5MmcySGlqNEZ0R3N0NWdWZGRvd25iOHc9PQ==
"this guy has it figured out. Worked for me on an M3

[https://github.com/magenta/magenta/issues/2047#issuecomment-1543717428](https://github.com/magenta/magenta/issues/2047#issuecomment-1543717428)",r/machinelearning,Z0FBQUFBQm0yeGJlRmRybjBzM3JWWmw4NnZ4RnJPaVNIOVdHQ0lTYm9OSmVxSkRJNUx2OVBWemRQYWdMdHhlNGROY3hqMVc1TEFMY0hyWF9xMnJQdDI3M3ZUMkVieTJDLVE9PQ==
"I think they are both very actively studied, with all the RAG stuff",r/machinelearning,Z0FBQUFBQm0yeGJlb3c4Y2oyUEtlM3BhaGROMkdtNHE3TURSQWh1U21tbmZ6RjIyeFlmMzQxcmZhbTZKOEw3dVpPRWxGVEEyYmRDcUtWM2JQMi1jZEd1NTFXODVVSjFQOUE9PQ==
"I know this post is old, but I stumbled on it and think this ratio was undeserved lol. Theory can't take you everywhere, but the one nice thing is that it rarely lies. Here is the RMSNorm paper with empirics showing what OP said [https://arxiv.org/pdf/1910.07467](https://arxiv.org/pdf/1910.07467) is true.",r/machinelearning,Z0FBQUFBQm0yeGJlaHhBVHdEdlBqazhBbkg5NXBPMkhuRk4wc2Yzb29ZdFpVcDQ3RVBNQ1ZPaVNpT2Y4RU53c3paVlAxRzFydjRGRUl6dUliMDU4YVg0SFg1QWNnMDc5TlE9PQ==
"Thanks for reply. I thought there's not much difference between saving as .h5 and as .keras format. In my code I use load\\_model and the converter is using TFLiteConverter.from\\_keras\\_model without any warning and error, both 2 are just for easily to retry different setting of TFLiteConverter. I also tried directly convert the 'model' after training without export to a file (model.h5) and re-load it, while the results remain the same. It seems the problem I suffered might not relate to model export format.  Still thanks.",r/machinelearning,Z0FBQUFBQm0yeGJlUzgxNHFqU2tkU1lsdjRRTTBTZi0yRnRIU2l4TkxPblBsMVBhWnNyM042dmxyVzdlZW5KcldnbG1uSlIzbzNoR3lQT1B2YXhYcllQNWxPMGpKM3N6UEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlcUlpbzQtdzNfSXBXWjZJSWxNaVZQZVVZT0pHbmRPaXlDWTdqb1d4MlJNLU9JVzlZNTg5b3o1NnRvUkFmVUpNZS1iTXlEdGdKNUh6SWQtdDhkdjhaV0E9PQ==
Because people read too much science fiction,r/machinelearning,Z0FBQUFBQm0yeGJlUlVYbTAyR3lGaU1pZ3Y4TkRkZ3RqakRFWXUzRy1ZVWxyNWlGN2ZHZzV2N05kSUJZb0FJQXA2dTRXNXJ3RzdKYTdWV1B3MDdLQ1Bodno3RzNwV0NxTlE9PQ==
Have you considered using Flask or FastAPI for your deployment?,r/machinelearning,Z0FBQUFBQm0yeGJlb2xYWEVLWVRPdm9XSTJRMUVoM2hEc2NxYUhhdEJ3MG9oVHFjVWk4Qno3OHdTQlQydm1QVWs0TFZvckFFYi1fTW13eU1GcnhnS2FCbDkyRTg0el92Qnc9PQ==
"The current society has institutionalized risk aversion. People get much more vocal about problems, so various institutions and companies are forced to prioritize reducing problems (particularly those that can attract social and regular media attention) rather than focusing directly on what benefits people the most (i.e. combination of risks and benefits)",r/machinelearning,Z0FBQUFBQm0yeGJlU2FTWkw3dEpuS2xJMmFkMk5ZZ2ZtaThLSE1hY21JWWZaY0ZBWHRXSG5qWk5OTlFHY254ZnAtSGotNVZnVEVPNW1DM2ZFdjV0NWI1Y0VCbXFHNWRqQ3c9PQ==
Resubmission wouldn’t be allowed but I don’t understand this kind of strictness. It is just a minor thing and it can be easily fixed in the final version if a paper gets accepted.,r/machinelearning,Z0FBQUFBQm0yeGJlVXlaUHdydGdXZWxwOXo1OVM3ajExVzUwdllhaTVoQVhLSHNXSHluYnAzbDBrNnhrZmRGOGJrZF83M0pxT1ZVNk1SbjhEU0VzQWxGc3FtQmFfWnJKcWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlb29uZFQwRE1GcTE5SDRlUFZ0cWRmcDFUYk16V251SS05Q3gzZ2dXcE5JT3JZdmtCQzd3OUhRUV9BamZfLS1ITV9BQW5GenNPNm1BSmU1ZEtQSWJJWEE9PQ==
"One important insight is that the key&value caches are highly similar in Transformers. For example, the analysis in Figure 1(a) of [https://arxiv.org/pdf/2405.14366](https://arxiv.org/pdf/2405.14366) shows that the cross-layer KV cache similarity is above 0.8/0.9. It's a strong indicator why YOCO works so well.",r/machinelearning,Z0FBQUFBQm0yeGJlTTAtNmY4S3N5OENwZllFb3JLS0plOEN1dmVxV2RsNE1vWDNDLTN6N0VsV3VwbzVwT000S1lfOTdxcm9seExzeU1NSlVZc25JZEt6MnI2VkE5ZHUxU2RNbG1CaVVkWHVEYzNPRTZRWTN4Q3c9
This pretty much,r/machinelearning,Z0FBQUFBQm0yeGJleVlUNzlJbkpVZjhrdTR4c1ptR0t6RUt2TC00eWEzdThjZldubG1iTHk2eEo0MGZZX01IaWN4V3h1cUw4ZGJDRVh1OTdyQllET2hIV0RGTWRyTWhwQWc9PQ==
"Are the test ELBOs reported for MNIST in the appendix correct? Using similar architectures and training for continuous approx. posterior VAEs, a lot of prior work gets ~2x what you are reporting.

Just as an example, compare your results even for the linear MC gradient case with the MLP + more advanced gradient estimators in https://arxiv.org/pdf/1810.04152 .",r/machinelearning,Z0FBQUFBQm0yeGJlRHhCM0ZVQThFdVhKVmsxMkhVYkxqRjU0M0g4ZGw0NFhqcFA4YmFlT0YyRFRyajF3ZjVBR3F1anpNSXQ2TmptNDNTeDFRU2QzZWNjQzdmUXp6TEh5NkE9PQ==
"Hallucinations are a feature, not a bug, of LLMs",r/machinelearning,Z0FBQUFBQm0yeGJlaFBMVTBRZkYxLXdPZDYwdGh2bDh2SGFyNXlKb244QmNRRGdydkNVUi1ERGZfOTBkaUIwcTJJZTlaeV9VX2lqaVg2MHNiZTRKTkc3VDdnX0pNQ1lfNGhoMFlVMjZRUmUzRnFrTGRGMkZlSzA9
You're right I'm an idiot. I swear to God I saw them announce it somewhere but maybe I was getting confused with lambda labs,r/machinelearning,Z0FBQUFBQm0yeGJlbk9lZHhJQWVaeWdWU2dZck5vUE1GWWFvcy1vaFpyMFNyaTRVRlViT0FaQWdQN1FUbktUSGtNNFFxc0NuOGpqNmRwTnQ3dF9qU1VMcE5tcXYzRXVObHc9PQ==
"Please provide clickable links to the actual paper's page. https://arxiv.org/abs/2405.05254v1

Other papers by Furu Wei, https://www.semanticscholar.org/author/Furu-Wei/2253471545",r/machinelearning,Z0FBQUFBQm0yeGJlVWtXN2FQT0FKc3h0bEVKM1gySGRsVnhueGJmZEQwNXdwVVFDQ1NVQ3MyVUlZZVFpQ3drbllzNFFtdVRiNEtvR0tCMXlWYTlERlhXM1RFVXMtam9SV3c9PQ==
"Because safety makes the news

But i m starting to think hallucination, the inability to learn to reason correctly is a much bigger obstacle",r/machinelearning,Z0FBQUFBQm0yeGJlTXVWdlYwWFRsYXB3YXRYWnY5T3NWS05Oa2pKbzhGc0Vlb3BaTGJrSG0yajdXNElaV29MenRTVWVZSWQ2Wm0tdTZ5TVBEWW5OLXB5eUlyQjhUZmRjNkE9PQ==
"It would be , if hallucinations was also a feature not a bug of humans.

Humans rarely (on average) say things that are wrong, or illogical or out of touch with reality. LLMs don't seem to learn that. They seem to learn the structure and syntax of language , but fail to deduce the constraints of the real world well, and that is not a feature, it's a bug.",r/machinelearning,Z0FBQUFBQm0yeGJlcE13SVRDQ25TRlgtb1hkQXZ6b2NYZGpyUjlZZEhRT0NiR3dzQkRkbElLUk9QbjRSODBGMnl2X01uZGR6c1dlZjN2VW9KZ0o1d2ZacUtOV3VFcEp2bXc9PQ==
"That LLMs can reason *at all* is a surprise. These models are just trained to predict one more word in a series. The fact that hallucination occurs is not ""an obstacle"". The fact that it occurs so infrequently that we can start devising solutions is remarkable.",r/machinelearning,Z0FBQUFBQm0yeGJlMGRmUXQ0WmNEd2g5bE1yZDJmeUF4MW92anJQemIybUpXWW9sSzU4b2ZpUXNYR2N5SHNtWmpHNDFidVFMLVR1NEstZVdFYTNmdnV4UjlPdHZNbEtYZkE9PQ==
"> re just trained to predict one more word in a series.

Trained to predict a distribution of thoughts. Our thoughts are mostly coherent and reasonable as well as syntactically well ordered.

Hallucination occurs often, it happens as soon as you ask some difficult question and not just everyday trivial stuff. It's still impossible to use LLMs to e.g. dive into scientific literature because of how inaccuarate they get and how much they confuse subjects.  

I hope the solutions work because scaling up alone doesn't seem to solve the problem",r/machinelearning,Z0FBQUFBQm0yeGJlT1p4OENpc1FlMGpxNjZNYzNPNU83VTVqd3ItSFY1RDNpTFdMc2RKaWJoZ2dPWGh5SmtQdWFBenBObmVHUnZsMlhzdThZRTJOMjRPR0RDcU1yWDZHT1E9PQ==
"oh, good to know. yes i was indeed referring to Murphy",r/machinelearning,Z0FBQUFBQm0yeGJlekJnQ2U4SW5lVE9vTklYNklHRExVREtDMDJRcWdfZFlhLWRNMEN3MGpzX1VpSDBRRUItano4eUZ5dEJxTTF2Xzd1TGxndWpobDh4TnNYZ0I2a0RKa1E9PQ==
"i also want to do the same thing, can you give me some guidance please",r/machinelearning,Z0FBQUFBQm0yeGJlaFVENzdTeWZTUXVVU0dBLW9ERFBPSm53S01xb0Vjb1lvSW0wNnR0VldobUpaa3ByRTRydTg2a3YyTl8yLWRDVVNQOUZnQjZzMjR2Z0lDX1lwTUJyR3c9PQ==
"TL;DR: AI Inference hardware accelerators were all the rage a few years ago. They still are, but they seem to have abandoned the hobbyist, low-power, low-size, low-mid cost, seperate board user, such that abandoned projects such as the Google edge TPU from 2019 (5 yrs ago) are still your best bet $/perf wise. The $20 - $150 range is empty or has some products that aren't worth it at all. What happened? Are there any modern hobbyist $20 - $150 accelerators you can buy right now anywhere?
Sidenote: I know TOPS isn't the end-all be-all of perf comparison, but it's all I got.[1]
Skip for history of my interest: I've long been interested in machine learning, especially artificial neural networks since I took a class on ML in college in around 2004. I've done some hobbyist projects on the CPU and even released a C#/.Net wrapper for FANN (Fast Artificial Neural Network, a fast open-source neural network run on CPUs because everything was on CPUs then): https://github.com/joelself/FannCSharp. When deep learning took off I got excited. I got into competitive password cracking and although my ML based techniques were about a dozen orders of magnitudes slower at making guesses, they were almost immediately able to find a few passwords in old leaks that had been gone over and over for years by the best crackers with the most absurd hardware and extremely specially tuned password guess generators. That made me pretty proud that I was able to do something in a few months that years of dozens of groups with $100,000s of thousands of dollars of hardware and who know how many watt-hours couldn't do. I even thought about writing a a paper on it, but I was kinda in over my head and my life got a lot worse so I had to put all of my side projects on hold unfortunately. Recently though I did a vanity search for my FANN C# wrapper and found people talking about it and some references in some papers and student projects which made me feel proud.
Skip for history of my interest: Now I really want to get into the cross section of hardware-accelerated inference (no training this time, I'm not a trillion dollar company with billion dollars of supercomputers running on specialized training hardware that took 100's of millions of dollars to develop), microcontrollers for robots, drones, other smallish tasks that can't carry around their own 100 lb diesel generator and 2 1U rackmount servers full of inference hardware that I can't even get ahold of because you can only buy that stuff if you are an Intel or GE or some other company that might make products in the 10's of thousands at least. And this is where I hit a wall.
I just started looking around and one of the first things I found was Google's TPU by Coral.ai. 4 TOPs in a package, 2 chips on a small m2 card. Only about 40 bucks for developers to try out, $60 for an easier to use, but 1 chip only USB product. But this was about 5 years ago, and they just slowly disappeared and haven't made a peep in like 3 years. They timed the market  perfectly. AI stuff was right on the verge of BLOWING THE F*CK UP. They could be THE edge/robotics/iot/anything-other-than-server/cloud-phone-tablet-PC-laptop company. But they just seemed to give up. They're obviously not giving up on improving edge inference hardware. They release their phones twice a year (regular version, then A version) and they always update the tensor processing unit in those and are really starting to push that as a must have feature. They could use the same hardware improvements to make somewhat bigger chips to sell for other markets. You never know, someone might take their 3rd gen 16 TOPS TPU chip and makes a product(s) that takes the world by storm. Maybe multiple people/companies will do that.
Okay, so Google, seems to have dropped the hat. Hardware inference companies are a dime a dozen these days just go with another. But that's the problem. It seems all the focus is on Cloud scale, super-computer (some overlap between those 2), embedded on finished phones/tables/laptop/PCs, powerful server accelerators, and a very few extremely tiny MCUs with accordingly tiny MPUs. I seems everybody has abandoned the lower-mid range-robotics-drone-hobbyist space with haste.
ARM introduced the Ethos U-55 and U65 with the 65 having about double the TOPS of the 55 at a max of 1 TOPS in 2020. As far as I can tell the first products to use the U-55 were in 2022 and there haven't been a lot and I don't think they ran at top speed. Noone has opted to implement even an unmodified U-65 for anything. I recently bought a Grove AI Vision Kit with a U-55 NPU and it's specced at a lowly 50 GOPS (ARM's top-end says it could hit 10 times that and until *just now* I thought it was 500 GOPS and thus offered good $/TOPS ...oops).

... continued ...",r/machinelearning,Z0FBQUFBQm0yeGJlWlJXY2JNNTd0bzFpeW83OFdiNFJxaTMtWENUZnM3Q2kyWUxlbEl4dXotWWlGa3lfRGpxTTJUSEhDR2otZ1JtckRJRTlFV2ZxMGtzOGt3YnlEQkcyNVE9PQ==
"... continued:

There's a lot of companies making hype, a lot seeming to have selling dev or reference boards, but instead producing a few thousands and distributing them via the usual (Mouser, DigiKey, Element14, SparkFun, etc), they want you to fill out extensive forms to ensure you're a big player that will definitely eventually buy at least 100,000 units a day otherwise you're a waste of time for them to consider you (even though going over every applicant individually is WAY more time consuming than just producing a couple thou and have DigiKey take care of selling 1 to 2 at a time).
Thus I've come to the point that while Google edge TPU is abandoned  (even though Google is going full steam ahead on AI inference for their cellphones and tablets) and Coral.ai is seemingly doing nothing. Their TPUs still provide the best $/TOPS in the range I want. Take a look at [VOXL2](https://www.modalai.com/collections/blue-uas-framework-components/products/voxl-2?variant=39914779836467).  Basically exactly what I want and would expect we should have had something like a Google Edge TPU v3 by now (but a bit smaller and a little less power consumption, yes, I know moore's law doesn't really apply anymore, but in rapidly growing and learning fields like accelerated inference, double the speed every 2 years is not unreasonable and it has been 5 years since the Google TPU @ 4 TOPS per chip). But the damn thing is over $1,2000.
So, my point finally is that even though Google and Coral.ai seem to have abandoned their TPU. At about $40 for 2 chips at 4 TOPS apiece for 8 TOPS total, they still seem to be the best middle ground. The next best might be the  BeagleBone reference studio for about 8 TOPS at $187. Same TOPS (though on one chip) for more than 4.5 times the cost. The Jetson Orin Nano by NVIDIA is $259 for 20 TOPS at $51/4TOPS that a single Google edge TPU will put out at $20 (including the board and stuff). It seems everyone is abandoning the hobbyist edge inference space at lightning speed. There are a lot of companies with promising size (physical) and performance products, but they won't talk to you until you fill out a form that implies that they only want to talk to someone that has already decided to buy 100,000s of your units whereas in the past, companies would have dev/reference boards out trying to find someone that would develop that killer app and make them a lot of money.
Why is this? Am I looking in the wrong place? Should I hoard Google edge TPUs? I bought their USB version to tinker with and the Grove AI Vision Kit (now that I realize is only 50 GOPS, so might be worthless). What are my options. For example. A single quadcopter a 100 - 300m above the ground looking ""things"", not image classic image classification where it can identify thousands of different objects. It just needs to identify one type of thing. Doesn't even have to be very fast. In fact, don't these NNs run on single images? I could just buy multiple chips and run in parallel to get the framerate I want if it isn't fast enough (it won't improve latency, but 100 - 500 ms latency probably isn't a problem until you get real close at which time you can switch to a different, much cheaper solution that works even better at close range and wide FOV).

Maybe I can use a phone and get low level access to the NPU/TPU and use that or use their powerful graphics cards on the phone or small laptop like a caveman from 2017. Still pretty expensive and I would be paying a ton of money for hardware I don't want. Maybe I could buy broken phones ""for parts"" on ebay, but I'm not that hardware savvy. I need a dev board to get me going.

The next best idea is to just push video from my drone/robot/project to a central station with a super powerful 1-4U server inference accelerator (not sure how I would get one), or Jetson Orin, computer with RTX4090 and do inference there and just tolerate the latency. That won't be feasible for some applications I would like to do though.

1.  I found a github repo that collects perf comparison projects and I checked their data, and it's extremely sparse. One set is dominated by NVIDIA 4090, L(s), L4(s), and QUALCOMM T100 (or something, it's a cloud only processor, so you can't buy it). Then a few rows at the bottom have Raspi 4 and like 5 other mini applications units and MCU chips. And the results were hard to interpret especially since not all entrants have run all benchmarks and they can run it in probably dozens of different ways and then the results may not matter because their accuracy might have been bad. TOPS right now is like Whetstone/Drystone or MIPS, FLOPS, etc back in the day. It's a very rough estimate, but it can get you in the ballpark, so you can narrow down hundreds of options to 15 or so and then do more research from there. If someone comes up with something better then for sure let's all use that. Or if we could get some standardized benchmarks (I found some last night, there were several, and the results were very sparse (not every entry ran all of the benchmarks in all the different ways it could), one dataset was mostly a couple hundred rows NVIDIA 4090, L4, L40, QUALCOMM AI 100 (a cloud processor, you can't buy and run it) and then the last several rows where like a few Raspi 4s and some other MPU boards with drastically lower scores. Every once in a while some announces a project to fix this, but it hasn't helped at all.",r/machinelearning,Z0FBQUFBQm0yeGJlbzRLQWtwNVJkWnZlcHlrbUo3a1BWSnJ3V3psMFFvTFlCbmJEZ0FpdS1qcHUxN09uanpseldDSWtDQzNGeHRuQ29Qc19mSVhxa3Q4emFFdkNRcF9XblE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlSW8yQnBZX2JCQmIxcnhINnFXS3NkOVBTSGdiTWVia2hyMlpmR1FDOUxRVUV6UTJ6cFlielpiWGx5MHJTSXFuS01sTHpWMndKUnN6VGsyNXQ2eEVXMFE9PQ==
"Hey there, too late here!  
Can you help me out by providing which embedding model would be the best for financial tabular data to apply in RAG.  
Thanks",r/machinelearning,Z0FBQUFBQm0yeGJlMVdlZ1dNYkgtdndBSUdUS2dpU3NIRDBsaU9qaU83dldBNmN0QUNZNERmeVV6NlQ3Rmt2a1R6THJ6Tk9SMGhpd3AzVkNwV3ZGQThtSTFkUmtzTlZSQWlOdDJaeElhWDZLY19vSHl4TlhmckE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlbkJPVlo1Wkh3RHd3YWVKUV82ZzlMY29NRjhtM0pzNklSaVRhYkxtOHpYSi01RXFMM0NJLUY0ZWxJVl9JbFY5akRNQTF3U0xVYlRzRFdVakxxQ2Y5bkE9PQ==
"Both are actively studied, but look at it from a company perspective. Which is more embarrassing: not adding correctly or telling users something truly awful (insert deepest, darkest fears here/tweets from Elon Musk). The former may get users to not use the feature, but the latter may get users to avoid the company.",r/machinelearning,Z0FBQUFBQm0yeGJldTZsWmtCQVY2TWRSY3NYYWNiUTNBMmFoWXNUR3JQODJfQ09HU25HWkFHVDRzbWRWTHdURkY4LUd4RGMzS3o4a2lUcmtLMHVMQmNJSllhd0ZrelNlOUdwXzVLU1ZZbFR1Zmw5TXJZU3dLVTg9
The point is to build a product that will automate whole lot of white collar work. People do dumb things at work all the time. Systems are in place to to deal with that. Social engineering on the other hand can cost companies a lot of money.,r/machinelearning,Z0FBQUFBQm0yeGJlSEdJM0FFUHMtUEExZ2ttLWpSRllqREZadkc5TEZpNV9LVTI2blYxUHhTMTFsbDRGUE5QS1FqdUZJZlhWYmdvOHlFRTgxM0hQaTRHUWRjVXpIZkgwM3c9PQ==
Could it be that LiDAR sensors provide more accurate and consistent depth estimations compared to stereo depth from cameras?,r/machinelearning,Z0FBQUFBQm0yeGJlVlJ0NVh6ZDgzUzdiSWRqaWVSUE9Wck1QUlhKM19La0FLSExPN2NnbjhRbmdLVEZRQ05SaGZzd0stOGN0WG54TldBX0lBX2lnYXNTZFo3eG5IOGRHemc9PQ==
"Hallucinations are an overrated problem in my opinion (I'm not saying it's not important, just overrated), hallucination rates of flagship models are decreasing at a good pace.  
And while hallucination rate is decreasing, model capabilities and threat level for various safety evaluations (cybersec, pathogens) is increasing",r/machinelearning,Z0FBQUFBQm0yeGJlR1ZIN0pRbkhwekpOQXBDUTBTUXprSlhtY01Yc09DVnR0MWdGVnREc2d4S3hOMnJzZ3JGMUhMTTM3UDlnZXhCeFduNGx3cG9xdWlIbjYzdmNqaDlOV2c9PQ==
"The hall monitors and marketing-layoff-turned-alignment-expert hires argue otherwise. There's a lot of metaphorical primates who don't understand the power and shortcomings of this magical tool in their hands.

  
""Safety"" always sounds more stylish, especially to the ding dongs at CEO/COO levels.

People barking ""RAG"" have actually never used rag and seen it hallucinate, in real time, while you contemplate how many stupid reddit arguments you had over something that turned out wrong.",r/machinelearning,Z0FBQUFBQm0yeGJldjlWWVFhb3I3MnBrV18yaDZzQjFjbnNXeFdjY2NfdjdDc09FX2VRVWxqQlRrRHd1UUtxNTg4c3JyQ3daMnB2QnNrR3VjaEdNd3Zvai1Pd1c5NmRuZWc9PQ==
"Amazon has created jobs for tens of thousands of people, made the lives of hundreds of millions objectively better, yet a couple of instances of employees pissing in a bottle and now you're the devil.

Our societies are tuned to overcorrect over mundane but emotionaly fueled things and never bother to correct glaring logical problems.",r/machinelearning,Z0FBQUFBQm0yeGJlc21kelJmZGZxX0NXZEtjSE9VbFRvRTFiclBOcGREbEt1dk93RlBDOGJqOWtOUnlweXJCdU1hSmFIOVl6VDZjQzJvajVjWXpWd0RrbEx6VXAwSlhBRFE9PQ==
Hallucination is overfitting.,r/machinelearning,Z0FBQUFBQm0yeGJlUzJ1WFNkTVJoVnNJY0NfVGQ5WkhMcUllX3ZIcjlYM2JZZk1IaW5RNHo2T29GNU4tX3lSNGdoVHZPZ21BeHdCNkVnNWJTWnQ5T0EycU8yZUFEOVVqaWc9PQ==
Raising safety concerns is a brag about the model quality and impact. 90% of it is marketing to increase valuations and get funding. It sounds much better if you say this new thing might be so powerful it could threaten humanity than if you say you can finally turn bullet points into emails and the recipient can turn that email back into bullet points.,r/machinelearning,Z0FBQUFBQm0yeGJlZ3dDX2RmZm5yaDZyUnhtZUJPQklvR2I5blhVVEc4SkxYQVRBYmFVY3pidjk1M3NuZmlWS2ZrNEVjRDZuZW9XMXJhT3JVNUhsVVF4NXI4eE43T2NWaXc9PQ==
I second this. Hallucination is a byproduct of what LLM do: predict the next most probable word.,r/machinelearning,Z0FBQUFBQm0yeGJlaHZ3TDVZakw3alllUkhaMHJHWDFXR2l4dnlWNU13S0N4NkZEN0M2MG1hNmpnanNCenNfYkotZUF1NXZVam0zS0lJLV9rQ3o2LTRZRUJ0ZUFQTG1oeEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlNHBuMzZTdWstY2hleDU1SFpsOXVUNkZGLUV6eUdPamJrZFBja01wbl9pSXpHUVFQYV9PNnhqX1V3cFdPeDkwM0VmazFwakdHNE9pRzAzaGJuZEZCdnc9PQ==
"Let's put it this way: one makes you sound like the keeper of some of the darkest and more powerful magic crafts ever known to man or God. The other is an embarrassing revelation that your magic powers are nothing more than a sleight of hand, a fancy Markov chain.

Which of the two is likely to increase the valuation of your company, giving you real capital in hand today which you can use to build products and cement a market position that you will be able to defend in the future, when the jig is up? Which one would you rather the world talk about?",r/machinelearning,Z0FBQUFBQm0yeGJlSmhMT2YzU3QtbDVUM2phRFNGUHoxdkNKaHY3SVNQMEh5NThkTC1DMmFGZ3doZG41dDVrQ1RJWkJ6S09KZ1lLRXVTOVA0WlpJNmZ6UUk2TVNJNVYxQXc9PQ==
k=1 means your model is basically memorizing the training data...,r/machinelearning,Z0FBQUFBQm0yeGJlTE93MmFOejJQZUdRVVdtV295MUFiVVhPRFljSTRzUlZNeWFMdzRGVnVaYm9Hc3MtNThwRGM5N1JrVERFYzZJbldxNEJVbTZOMUxjN1FrX2VpeGM3RFE9PQ==
"> Humans rarely (on average) say things that are wrong, or illogical or out of touch with reality.

You must be new to Reddit!",r/machinelearning,Z0FBQUFBQm0yeGJlSk0zSmFmOXNwangySmNPRmxPeDdodlNhQThxR2FzUTItdEVxWFlwSFdwVERORTBfT25xbndkZmdzellyNjhFSGJjMHgxdnhpdTc1eWdOSHBwaTJMZ2xSREp4VDFGMEJQQXpLcVlRNlc1ZWc9
"I definitely wouldn't say anything is ""SOTA"" here. There are transformers, there are GNNs, there are graph transformers, and so on. So what? There are different tools for different things. Your linked talk is mostly about learning algorithmic reasoning, where GNNs are indeed SOTA, and have been for quite some time, but it's far from being industrially useful.",r/machinelearning,Z0FBQUFBQm0yeGJlSzZnN2J6ZlZqYnhLTTNmU2g2R2lSclpRcE1VSW9xZ0tuZnRpcVlWOWhQT1I5Z20yeFJqa1RTM1EydGUtbWViOUVmTS0taTI2bjNvY3RWRVdrZnBROXc9PQ==
"4. Definitely a good idea. Providing reasonable defaults for this parameter would be also very useful.

5. I would consider downstream classification tasks, i.e. which autoencoder gives the best classification accuracy after reduction. You may use kNN as a classifier, but I would also like some linear classifier like logistic regression. Providing both tells you quite a bit about geometry of the reduced space in terms of class distributions.",r/machinelearning,Z0FBQUFBQm0yeGJlWkhHdldEMkRpTlVQVWRwbTU4NFZva0lIci1sdkVrOVo2Zk52S2FGR002OWpYV3lIalJUcEJaMklOWnBoYWo1VElBVWRvRmNHVXIya2hFbmxmLWRneFE9PQ==
"I understand your general argument and agree mostly, but let me introduce you to Donald Trump: https://www.politico.eu/article/donald-trump-belgium-is-a-beautiful-city-hellhole-us-presidential-election-2016-america/

People talk a lot of nonsense and lie intentionally or unintentionally. We shouldn't underestimate that.",r/machinelearning,Z0FBQUFBQm0yeGJlRWw2Q1dzaUs5S1JsNTJ2d3gyeGgyNTgxMmFMdHJCeGxWT2xVUzVZRWhfamgyLUQ2dkZpUkVaaE5tMFcxWEkzVVV2MEM4YURNRDdMUHFub3ZHd01RUXc9PQ==
Completely agree with this. Would love to hear an answer,r/machinelearning,Z0FBQUFBQm0yeGJlQlZOOERZUV9DQVBETXUzbnNMLVQtNXVfMHBsZVN3d3B1N0pqWHJYdlJaNWNpdnE4RU5iVFFPd3FRa3RVNHhxZ21qcHJzeXFHOE9xaV8wcDNNa2tiSzRzMXJDZkhvVmEtbWtTNHk4c05ITGs9
"It happened to me too. I filled it in the open review but I did not ""copy"" it into paper. Small mistake, big consequences. It sucks",r/machinelearning,Z0FBQUFBQm0yeGJlWndrWWNURy1YSWJzNG1OaXpTZ0pac3RQSWR1SXpNN21lWjlINnVNNlVoVDRvaVVQdGRhSlZyV2JKVzVoam05R01NNE5yT2FiZjNDam1VSEE3TTFXMWcwVHZKMVNBY2FpS2ZHS1Jrb2hoZ0k9
"Humans say wrong things all the time. When you ask someone to explain something they don't know, but which they feel they should know, a lot of people will just make things up instead.",r/machinelearning,Z0FBQUFBQm0yeGJlWDlvcTk2UUllR1ZFdXg2a25LVHJJV3BaNEtBb1ktTS03QjNFZk9ybnFUNllDVFJlVDhaQXdjXzAxRnlfLUxBVlNNMGdDSEpZbXhLV3JiU2I3SnF6Smc9PQ==
"Check out this software for bulk download of CVF papers:

[ElhamKhan859/CVF-Scrapper-Public: The CVF Open Access Downloader is a Python application designed to automate the bulk downloading of open-access papers from Computer Vision Foundation (CVF) conferences, including WACV, ICCV, and CVPR. (github.com)](https://github.com/ElhamKhan859/CVF-Scrapper-Public)",r/machinelearning,Z0FBQUFBQm0yeGJlMzB3Z0xoN29lT1dSanRMLWRiajhfYjRtWF95ZUdNRnVxYUJIRjJyR2U1QU9Fb2c0YWpLOVY1Q1Q3b1pVclcydjliOUtmWUJfTmJMNHl0VF83bzhTeUVJSDV1R3FrOVRNU0x4MGFNWjJjWkk9
"May I ask how RAG research is related to hallucinations, and to safety?",r/machinelearning,Z0FBQUFBQm0yeGJlaWREZWpJUTdBM0lyVUVNTm1aY2pIVHZUSmxHT1JCVGNnTnl2YVNxdG1QSjljTUNVa083RkpZQ0ZyS2paaFlYelpITU1pQzI2M256VkNFRG9lOXdjcEE9PQ==
"Also, im curious if “dealing” with hallucinations will result in a lower likelihood of achieving AGI — surely they’re two ends of the same coin",r/machinelearning,Z0FBQUFBQm0yeGJlclF5cjAtajFoemlvakdZeDk5VXVTZ1R2amxvbFJjNTcyWHhsXzNfdzNJeFRpbS1ycUtwbFFKMFhabFV2ZG9ObmhuSzVTYWVqTnllOXpCWlZuWEFuYWc9PQ==
"Lol. If we give people the same setting as an LLM has, people will curiously produce the same results.

Ask me when was Queen Elizabeth II. born on a text exam where right answer gives points and wrong does not subtract them. I will try to guesstimate, as the worst that I can do is be wrong, but best case is get it right. I won't be getting points for saying ""I don't know"".

I say 1935. The actual answer: 1926. LLMs have the same setting and so they do the same.",r/machinelearning,Z0FBQUFBQm0yeGJlS0t4NFBwSzljUDJDZFEzWl80bVZGR0tZTVREcU9mdkZlUmRCT2ZmRTVoTWJZRmxYOE5PWG1taXBaYnhUWXd3c0xXbDNmSy1NYl9IZDJyV1dnSXY3Tmc9PQ==
An AI which doesn’t hallucinate is more grounded and capable of interacting with the world,r/machinelearning,Z0FBQUFBQm0yeGJlWldBNTJyaTlxdG5oeXA3RkJ4M2JSenkyNEVCbUNuZXExamNDMDB1cjRzN3c4RmNfSGR2RlZrS2FackZMbXVXTFZ4bWw0eEtqeEYyeGw0b3VWV2NXaXc9PQ==
"You do know that ai works by predicting what word comes next, right?",r/machinelearning,Z0FBQUFBQm0yeGJlVll0bFZtVmoyUG10NjF2TjVaaUU5aEdXUjBJSjVtaFBud0dOTWtGSnZHOEREVEE0UW90cExQZ3ltUkFYY1h1aXhrb2FnM0E5aDVfQkJ0UENuZ3RnLVE9PQ==
"The assumption is that they learn the 'distribution of stupidity' of humans is wrong. LLMs will give stupid answers more often than any gruop of humans would. So they are not learning that distribution correctly.

You did some reasoning there to get your answer, the LLM does not. It does not give plausible answers, but wildly wrong. In your case it might answer 139 BC",r/machinelearning,Z0FBQUFBQm0yeGJlRksxQzVEbnJXVS1xSHFmaVc5a3RjbjNKaDVTVlVvMVdvajhUMkxWcTNZNzdha0h6ci13aTVzRkNZNzdQc0F0bUZoZmxWeUFvbzB3MVlOQTh5blNTUXc9PQ==
Just look at anyone's history and do the statistics. It's 95% correct,r/machinelearning,Z0FBQUFBQm0yeGJlODVnUnVVUkRSZFZta3oyREx0bUwyakpxYnk5U1Y5eDVfOEM1YWRXZnNiN3ZaR05tUi1OVW5DZkdCVTNHSHFKbHRBMnJocmNqNUw1YkNwV1UwSms3VUE9PQ==
"Nope, people say 'i don't know' very often",r/machinelearning,Z0FBQUFBQm0yeGJlRHJwOVZGQXd0aXY1MVZHYkFLS1B4YndyeWp4VTRLQ0F4eUI4aXVHVmdfNTZDWk1GeG1TLTVpTjVMOG5DSXc5Y19wTmZMZXVuc0tfZHU0enR5VUZJbXc9PQ==
... and he's famous for that. Exactly because he s exceptionally often wrong,r/machinelearning,Z0FBQUFBQm0yeGJlUHgwZlR1SExaQU94Q3VPblV0N3BzZjlZdUdQWnZMakJYbDlBdTVWS1VTejhHdjlmTTI3aGQ5VzAwanBibHJNSGctbkNPYXFiS19SS3VrM2JKMjZOM2c9PQ==
"Magician trick, focus on the sexy assistant (here the scary problem) rather than what I actually do with my hands, namely boring automation that is not reliable, even though some use cases, beside scams hopefully, can still be interesting.",r/machinelearning,Z0FBQUFBQm0yeGJlWnJzeFZnaHhDcEZNdlVGcHZRWnNYczRjRXh2QTFxTURyYThuTnBHS25uNlNXSGViYlR5TDhoM0luS3A1T3B4emstWHcySmphR3J2cXBRQURBUmdiOUE9PQ==
"Alright, that makes sense. Si when talking about training depth estimation models, would I benefit from first training on high res low acc GT for capturing structures, edges etc. and then fine-tune on sparse lidar data to get the metrics right?",r/machinelearning,Z0FBQUFBQm0yeGJlbGFIQXJ1akFmUW5xdXRiT2NWTkd3UGlGNkJhbWhUV1N6blpMNmhOTVFXTzIzbzlqd1VCZXF1a1A5eElMZnRPbG92M013RDA4am1Uel9sbWRrM09xcHc9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJlZ2J1bmNhUENGQmZkY21xb2pQeUd5MmVjWVM5MmRKeWVBY2hobVVHM09uajN0Y3VNV2tJLVRqb180MEpDdTRvWFpxcVBMMng1TF80Y0NqclRQV3BtWFE9PQ==
"It depends on details about the lidar sensor and stereo camera (and especially for stereo, the algorithms used), but generally lidar is more accurate. Accuracy for classical stereo algorithms decreases quickly with distance (at some point, the disparity will be less than a pixel/zero). Classical stereo algorithms also suffers in image regions with no texture or repetitive texture, as well as dark and noisy images. I say ""classical stereo algorithms"", because these issues can be mitigated with more modern learning-based algorithms (but how do you train that algorithm? one possibility would be lidar). Regardless, stereo imagery (binocular, multiview or active using structured lighting) imagery is definitely a rich source of depth supervision, there's datasets using it out there. Stereo does have advantages; for example, it often can be provide higher density, and may work better on some surfaces that reflect lidar in odd ways (very dark surfaces, shiny surfaces). Not to mention cost and portability.",r/machinelearning,Z0FBQUFBQm0yeGJlMHBvU09CUEM2RHBRWmVaUG45UXB3aTNyNmRiVXg5dzFOZDVnRXFIRGFwVnhLSExwbEdObGFfNGo4RlVSbmo0ZFJCdjVzcHF2WU1teTNQZVFteXBaNmc9PQ==
"Yes, some people do that. Others don't. Maybe your social circle is biased to saying ""I don't know"" more often than the average person (which would be a good thing).

But I had to listen to a guy trying to explain Aurora Borealis to some girls without having any idea how it works, in the end he basically namedropped every single physics term except the ones that have to do with the correct explanation. That's just one example.",r/machinelearning,Z0FBQUFBQm0yeGJlRXpObXRGVjhUVHduYWZ3M0NIaUt6RXRqMlM3YkJSVW9kVFJuMXhlVFk3N21rR1EyNm4xZDhrOVhaZDBZejBYd1RIeWVIeFRCSE1RdDl4WHBFVF9VbkE9PQ==
"Take it with a grain of salt, I am just a student currently, but my understanding and observations are that LLMs are surprisingly good at explaining even things that are not well explained by quick google search. And that is ability that likely rose from RLHF, it built an intuitive understand of what a good explanation entails, or other forms of text.

I in no way think LLMs are an answer to everything and try to be reserved with my hype for them, as I did not find them particularly useful for my research use cases and have stuck with more traditional machine learning methods.  
But the claim that ""Humans rarely (on average) say things that are wrong, or illogical or out of touch with reality. LLMs don't seem to learn that."" seems incorrect to me.

I completely disagree with your statement that it might answer 139 BC. If we were to display all the possible output tokens and their associated probabilities I believe it would have it way less likely, as it has an internal representation of possibilities of each token and 139 BC is not often associated with Queen Elizabeth II.

But thank you for the well thought out answer nonetheless.",r/machinelearning,Z0FBQUFBQm0yeGJlQk5HNVNCQzZvY0lPYlZ3c29SWlJJMno0NFZaclB6eDVBaUJHNVFORXVJVDMwV0x4Sms2dDB4TlEyVHVNYW50MHJPcS1jZzY5WFVNdFlETU45NVZyWUE9PQ==
Who assigned you a task without also ensuring that you’d have access to data. I would just say that I won’t lift a finger without data.,r/machinelearning,Z0FBQUFBQm0yeGJlNGRJeWRFNFJ1R29FWjl5MHNiVVZ1MHlEUHdDS3RLQmlVMzJUdXpKQnVxVGtNVlRIS1JUdzltU1h0YWQ5RVdlb2lsRzkxYTlrMnVDYjdoSnR4Zi0zMTgzSWJaSU5xbDM2ZXhYbGdrVThhUWc9
">  I had to listen to a guy trying to explain Aurora Borealis to some girls 

you have to take into account that LLMs have no penis",r/machinelearning,Z0FBQUFBQm0yeGJlRTVWU21uTmw1b0ZWQjVsdENQcV9jaC1NUjZkQkRZdnhrVGwxRlpXY2hLMnB6Q25CU2NaM0NhVmtnOGh6MEZpRmhzM1lqUWFmVFZ5X1prTDJvN0N1Y1E9PQ==
"Does any have any good pointers to techniques to to image classification of what is essentially line plots?

It seems like an overkill to go for the more advanced image classification techniques, I do also worry that simple line plots might have to few dimensions for them to perform that well. I am also more interested in the general shape of the plot than the direction, while I think many image classification libraries and techniques would classify say \\\\ and / into two groups, for my purpose they are the same - a straight line.

I have briefly looked into graph classification, but I have a very large amount of plots that each consist of a very large amount of points so I worry a bit that it might not be the right thing to the task.",r/machinelearning,Z0FBQUFBQm0yeGJlUWFaQzJuUk00UExReGRqU3g0elBseGY3TUZzb0QyOHZOc2RvZG8tbWFaQkc4SXVLMlh1d3c4a09CejA4TGxSSUZKaUV2Tms1RXZVazlzdGJyd3NlZ3llVm1XRnhhenN0YXowSTVmVmo2RTQ9
"2 is the ""proper"" way. Your system is built on a false assumption (that data will always come in packets of 24 hours). You can probably mess around with stuff and make it work ""well enough"" without fixing it. But if you want to do it properly, there's really no way around fixing the false assumption.

Of course, the issue will then be that 99% of the time, your code will be running under one specific modality (24h), so any potential issues that only arise when the inputs change in size could be hidden and pop up unexpectedly to bite you in the ass. What you could do is (for example) to randomize the input size (sometimes cutting it up in chunks, possibly delaying or accelerating the last/first chunks and merging them with the adjacent day's, that kind of thing) and check everything's fine. You could leave it like that for production (if performance isn't any worse), or use it strictly during testing only.

Or, you could just check how the various hacky methods perform on historical data, and if it's ""good enough"", go with them. I'm assuming this is for ""real work"" and not homework or research... so you are most likely not going to get paid any more for writing the most logically sound, robust and general code. If it works, it works.",r/machinelearning,Z0FBQUFBQm0yeGJlVm8tWG5waGh6eExYZnJZdnNvaTNNQ2FSYmh6RWhZaTVsOWZ4OUJCcHVKT1ZINzhWMHB4UTBLOUIzSFdDcEgxRzJTRENiaWpLTWNfbzdCNFhCMzlSRGc9PQ==
"The task seems weird, and not having access to data is odd. I agree with you that it's not a great task. That said, I don't think your approach is plausible, either. Even if you have somehow engineered sensible features, without data, you cannot fit a model.

Personally, I would instead tackle the problem that needs solving: What data is useful here, and how can it be gathered? Make a plan for that, and have alternatives if some data is not available for technical or privacy reasons. Have a rough story on how that data can build a sensible model, but make it clear that the idea is that the data will tell you which features (and combinations of features) are good predictors and which aren't.",r/machinelearning,Z0FBQUFBQm0yeGJlTmdFbnlWVHhhT25pUW5rU3RPeVFKb05tdWdOdXJiV0c2azlQbWZqSUFFOE5YanRTRWNsSndrSWFZd3kwczQ4clZWMktVaWtCbW1fOHhfTkw1SGYxbHc9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJlQzNkNmtpd2tkMV83MVZZc29OZ1kyYktsOWxKZ0FVZThYRkx2bElSOFktb1NOQlpyTFI4M19aeXhsd1ZDUU9IQzNKYWNNbDFUMHhjQkRGcFU0NnRfM0E9PQ==
"Directly, I would think. A majority of the effective development related to reducing hallucinations is focusing on using RAG-assist, along with stringent or synthetic datasets.

If we use LLM’s primarily as reasoning engines, instead of knowledge engines, they can be much more steerable and amenable to guardrails",r/machinelearning,Z0FBQUFBQm0yeGJlYVRaQXBKalN6UHZZVVZmTGZtcVR1aUQwbTJJZEpyRGpqUTlTNEdwYldoNmVZS2tjZFFnZlRWUEd1LTFDUk1kUmZXTHBWUktyTEdSM0N6cDRycjU1cmc9PQ==
"Why is ""creating jobs"" a metric? We should strive to eliminate as many jobs as possible, so people can focus on things they actually want to do.",r/machinelearning,Z0FBQUFBQm0yeGJldzhnZTJWYmxFUkdSNmJUdENWRjVTVWFvYllSX0JYNHJqLW9zVnowOGFKZVRCS2Myb3BhaGYxX2hfYjZQMXA5SGtSdUZacTZXVHdSWURmUFZyMjg4cGc9PQ==
"Thanks for agreeing - if there is some trick to getting your post through, I would love to know what it is",r/machinelearning,Z0FBQUFBQm0yeGJlUUExT2xwd0xaN3NoTW1xVl9mNm1EdTE5bk5WV3oxeGF4MDVsaHp0Zm11a0VQMXppZk0tVkd5TWQwaDZkQV8yYXNSNVNyNC02dG9DRk81TjljeDFWY1E9PQ==
"Bro, I’m not sure if you know this, but this is the foundation of nearly every religion on earth. 

Instead of saying “I don’t know” how the universe was created, or why we think thoughts, or what happens to our consciousness after we die, literally *billions* of people will give you the mosh-mash of conflicting answers that have been telephone-gamed through history

And that’s just the tip of the iceberg. It’s literally hardwired into us to predict on imperfect information, and to have an excess of confidence in doing so. I mean, I’ve overhead half my office tell each other with completely confidence about how gpt works, and present their theory as fact, when most of them barely know basic statistics. We used to think bad smells directly caused plagues. We used to think the earth was flat. That doctors with dirtier clothes were safer. That women who rode a train would have their womb fly out due to the high speed. That women were not capable of understanding voting. Racism exists. False advertising lawsuits exist. That you could get Mew by using Strength on the truck near the S.S. Anne 

Like bro. Are you serious? You’re literally doing the exact thing that you’re trying to claim doesn’t happen.",r/machinelearning,Z0FBQUFBQm0yeGJlNmdLQTJRTEwyUGo3T3ZQd3pzaU1DNjN3Z25GQ2Q0TFk2Mm1Ocl9LT3dVS1gzRkthOUI5VmU0WkI3a3FkRERVZ3JnMGEtTFhuY242eGxxYXNPbnYzZVE9PQ==
"But it hasn't been trained on the beliefs of those people you talk about, but mostly on  educated westerner's ideas and texts, most of whom would not make up stuff, instead they would correclty answer 'I don't know'.

Besides, i have never seen an LLM tell me that ""God made it so""",r/machinelearning,Z0FBQUFBQm0yeGJld0NfWHdnb1JXZVNTalh4ZkU4ODVFQjhKdzM4RU9oaDA0ZmI3czJlNF9pUmtXMkZ3TXg1cTJqdlozYXEtVWFHU09yTVh5NW9yeENKeTNoRktMc0xMN3c9PQ==
Maybe try and find a couple of costumers willing to pay for it before deciding to go all in. There are a couple of startups in the space already like sevensense that you might try to look up for business model inspiration.,r/machinelearning,Z0FBQUFBQm0yeGJlUWpyVkY0UDVnTFFreFRwVmJFSVNscm5FT0V0Q2Rlckk4aFpIQXZObF9XTHgydlJIYWVyX2VmSVE1eDgyclVwQmI4V0RKY3pmdG1Sby1vYi1qR2EzcmVsVjlsWFY0ZHREXzUtME94a09uNDQ9
That's good info. Thank you :),r/machinelearning,Z0FBQUFBQm0yeGJlNzBKTDhJVzlOaWxnR2o1aDc1VXE2MUhQNVlYTDJDangzRzNpS1pfS1lON24wbThKWDFUZWpOejBLMmdwNXJuNmgtRHlpV0hvUmhjc20yc3JmRFBnMEhjejBlb1JNUXhybFlUMV9XOHZjcHc9
"I'm actually so sick of telling this to people and hearing them respond with agreement to the unsaid claim that LLMs are completely useless and all the AI hype will come crashing down shortly. Like, I actually didn't claim that. I'm just saying the same flexibility with language that allows it to communicate like a person at all can only be built on a framework where hallucination will always be part of it, no matter how much resources you devote towards reducing it. You can only reduce it.",r/machinelearning,Z0FBQUFBQm0yeGJlUVVQTnlOTXBHTTVzSTNYeEpRNWxZcks0dmg2NXhhNUt4b0Q0NXczN2xhUmtVWGt3RllZa2VYNnRJTnlnVXpyS0F1ZmpZcUxtQjNpcUU1MG5GUjB2bkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlU192M1dsSFBWMlFzd2toMU5GNHY1OE9hZnRfT1dZSjRXbkJvQ1VTakdWcUdEOXBva0JYSzZ3UEdLVVVXZXpZSjlmWHQyVmUxSjhjTkpCSVVMZTJNVnc9PQ==
"This is a cold start problem. You can try to begin with whatever data you have - user signup information eg age, nationality. And then build a collaborative filtering model from there",r/machinelearning,Z0FBQUFBQm0yeGJlcjZiS1lBZ09SeFlhbHIyRmNfMVNheTAtZURla3NCN09lQzNLbGR4VWtmd0tBcDhTcndMYkZCM3A1eXFJd3dMdUlwNDlOdkhmX1pyVW00TGNpekd6U1E1NUw3c1lycDlDaEpLV2JXT1JFZGM9
"You need to know what kind of data you need, it is a part of your job.

The fact that you worked on it before you figured it up is also a mistake.",r/machinelearning,Z0FBQUFBQm0yeGJlMlFxRExzWTR5ODRIXzhLY1piMTJ0LWU1blpTZnRDTllHYnI5bmJlQmJrSkpaR3hOMEJ2dFVBVDhmUUJaQ2R5NkpDQzU2RlkxU3dYdjJaR0czT25tNElYRk1yYml3Ynd4Yk93WEZFMFFBYjQ9
"Which is weird to me, because in practice hallucinations are much more harmful, as they plant false information in our society. Everybody who used current LLMs for a little bit knows they are not intelligent enough to be an extinction level risk as an autonomous agent. 
But hallucinations on the other hand are doing real harm now. And they prevent them from being used in so many real world applications. 
Also saying this is not solvable and it needs to be accepted is stupid and non productive without hard proof. I heard the same point in the past from people telling me, that next token prediction can not produce good chat bots (the time when GPT2 was just released). The examples were that you could ask them how their grandmother likes their coffee and they would answer like most humans would, yet currently chat bots are so aligned with their role, that it is pretty hard to break them in this regard. 
Solving hallucinations will be hard and they might be fundamental to the approach, but stating they are fundamental to next token prediction makes no sense to me, as other flaws of raw next token prediction have been solved to some extent, e.g. by training with a different method after the pretraining. Also you can disregard most auto regressive text generation as next token prediction even if it's not that simple (see rlhf for example). You can probably build systems that are encouraged to predict the tokens ""I don't know"" in cases where they would hallucinate, but the question is how you encourage the model to do so in the correct situations (which is seems not possible with vanilla next token prediction alone). 
I am not the biggest fan of ClosedAI, but I was really impressed how little GPT4o hallucinates. As anacdotal evidence, I asked it a bunch of questions regarding my universities robotics team, which is quite a niche topic. And it got nearly everything right. Way better as e.g. bing with web rag. And if it didn't knew something it said so and guided me to the correct resources where I would find it. GPT 3.5, 4 and all open LLMs where really bad at this, inventing new competitions, team members, robot types all the time.",r/machinelearning,Z0FBQUFBQm0yeGJlRFhTTmVGSjZ5S1hsemNsOTF4am8wZmEyaG45WnRBTVhURDdPRWJoWnQwdGs4cWhqQ3ZYRmxkTEM1MjZ0VUE5bWZJa2tVTjQzYlRNbzJwVnRjQl9HeHc9PQ==
"Safety/hallucination are more or less interchangeable. to fix safety issues, you need to fix hallucination issues.",r/machinelearning,Z0FBQUFBQm0yeGJldDcxTm5BSnh0ZjJSN0tBM0lGNGlhRXczbWdkVksyRDVWMFJvZjdPczdYTHpWdm9qU2NuOXNSS09rdUp5SVdQMHhiTjVnRXIxU3NRWk5CdnhsZjB6cGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJldXgxVjRJSnEzOVZGMzJFZDU3OVRraURRQzVjMEdoSFdObWVrWDJFcGtQVk1OYUxON0I2d3FXS1VWQU1CRWhsdTd4QVhzSXcxeC10Wk1IQ1FCbjRCb0E9PQ==
"In a world where Kaggle exists, with it's amazing free quotas of 2xT4 and TPU, fast copying of datasets to a VM drive, what's the reason to use Google Colab? What are it's ""selling points""?",r/machinelearning,Z0FBQUFBQm0yeGJldnRSTGdxTEt6YUhsRWlyNlpRTHNXamdjVUVPZ0V0cUVIN3dsOHY1SUF5OGdTSWtiNHZwMkNrTmFQUy1ZTkhzajJObGpXZFhTdEh4Z25nejRrYXFSRVE9PQ==
"Not exactly what you’re asking, but asyncio is not the same as having multi threading. Your approach will only really speed anything up if there is some IO heavy bottle neck in your prediction. 

To answer your question, create N worker processes and dispatch prediction jobs to them via a queue like RabbitMQ.",r/machinelearning,Z0FBQUFBQm0yeGJlalQwc1hRQWdmWjBXQXNIVW5PUGx5c1ZXb0t6SDIxdWl0QUl0UmdaWkpZZ0xUUkVjLXhmR01uX1o4RlNlbzNJZkpuZDJwVHNHOWlqUTJBdEFDYXdBa3c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlNFVscHZITWNLUUtYVXZNZzY5SkF4d0V5LXVKSEdaQ3JFSnRfNDVSVUI3MjZ5amhvN3czZ0dYTFBNM2FnbGtDaEotZy0xTHE4aXNheTZ6ODZjLUdQQ2c9PQ==
Their training data largely comes from people with penises though,r/machinelearning,Z0FBQUFBQm0yeGJlLWJNOC1MREF1NWVvWUo3eVB6UEdSNi1kbHkxbHZwVkdJRmF0YW5QWVNWVTh5OURwZy01QUMxNFNLeUpka1ZmLVIza2VERjZKbHZfQUhEdUU2WERuZEE9PQ==
I'd recommend exploring alternative data sources or collaborating with other teams to gather relevant information for your model.,r/machinelearning,Z0FBQUFBQm0yeGJldUR2WTV2NmphbEZxdkx5Q0IzdjdVdTQ2STN0YW5BVXBPdkhRMnJQdVlUNE9vTWlETmJpTWtsT0pPbjJHZTlEVDR4Z2RNZnpRYU5SSkg3eDN6M2YxSUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWGNHaXh5M1ZWcmpRNDAwMmJ0NUVwSktHOEVKSDZfc3puSWRYZWYydWZPRmV0WUhHblNEVW9xWVlPY19uaGFjcXBVUWRLV21sbHpoNmQzbmFaZmxWUFE9PQ==
"I have been assigned tasks before, where as soon as I looked at the asks and givend, I returned the tasks right away with an explanation of the rejection. Sure, a few times my manager didn't like that, so I simply explained to him how science works and told him that if he doesn't want science, then he should take the ask to a business analyst with a lot of domain knowledge. 

Maybe you can do the same?",r/machinelearning,Z0FBQUFBQm0yeGJlUzg3bEkycFM4MHAwWjJGTURFblZZWlRqa2VxWVl2QnZGUUJ6VjlVWlU4ODdTeFZ3THpRbEtVM2NSY0U3bWhTcHdsQ3ZGV2p5M1dwMVVsbS1wY3pRLWc9PQ==
"If the data contained honest knowledge statements including lack of knowledge admissions, it would be much easier. Such is not the internet.",r/machinelearning,Z0FBQUFBQm0yeGJlbHo3V0lYd2V2UWtOOWJzMHBCa2wtcWtDYU9sWHF1UnM0YVAzTmNDYU5RVEw0UHV1dHZ3UjJDTDdIZU9pM19YV0E1VnNOT1ZrbHVVLXJJYTJ6ZG92MXc9PQ==
Still the major roadblock for most practical uses,r/machinelearning,Z0FBQUFBQm0yeGJlMS03ZHU0Rk9pTkFsOG9oVkxSYUpqd25jUFA0aDdFMmQwbjlxaDRRTzRkTVM3OV9WcV91R3V2cGxEc2ZOQTZOS1RST2ItTUE5YmlnejVmUlVqUnVoR0E9PQ==
"Indeed, they are good at reasoning with language, and they should be sourcing knowledge from external sources in most applications, the fact that people still consider using them for storing internal company data via finetuning is crazy",r/machinelearning,Z0FBQUFBQm0yeGJlS2s3ZkR2dWd6M05XbUpuNVA5Qkg4UlphTzRhN0l0eWZZTVI2SXpNdm9FdERycGFxVDF1NHNNNkZPT2hfY1ZWQ1J2Q2llbjRzQWRfM3Y0bkF3U1pKZUE9PQ==
"I work as a Data Annotation expert in Gen Al based projects, currently working with LLM based chatbots. Please suggest me something to improve my portfolio and to earn more in upcoming years. Also, what's the scope in Dara annotation? What are some good companies to apply? Thanks in advance",r/machinelearning,Z0FBQUFBQm0yeGJld0NnTnkxemNPS0hlSVZIN2tEa3lTcnpfNzg3WXE3TTNvM2IwcmZleHVFOWZ0T0FjQm95bGNFQklsTHp2UWl6OUs5ZW1tSGxOTTlKLWtWb0c2VjdLdFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWFV1MHNKOWk0dmNkLVYzZHFxajZiUGNHNHhNTlVoM0ZQMm1NWUhTUkl6TUdDNUljSEpFV3RtMC1fMjM3eS1RZ2RrV0o0Nkhnb0FMai1HZFMxaHhaMkE9PQ==
"I find hallucinations to be very minimal in the latest models with good prompts.  By latest models I mean Anthropic Claude Opus and OpenAI GPT-4 and 4o. I have found everything else to be poor for my needs.  I have found no local models altar are good. Llama 3
Included.  I have also used the large models on Groq and again hallucinations.  Claude Sonnet is a hallucination engine haiku less so.  This is my experience using my prompts and my use cases.  Primarily Medical but some General knowledge.",r/machinelearning,Z0FBQUFBQm0yeGJlc2duejRNNWhYZkh1ckp0RmhfRGV3NGdVSjNmYm5pdjZrQWc3N3BKSGFtUEU0VEFhR0FHREllN05GaS1xMm5XcE5WVjFvSU10R09YMWt2cjM1T0t2VHc9PQ==
They aren’t mutually exclusive. Ie. People can work on both.,r/machinelearning,Z0FBQUFBQm0yeGJlR0RWRzZBTGtsemNNalVQZzF4M3dNaXhqVWduUDExRUFHZ1dPakgyQjVyeWIwRmxBc0c2eFNHcVQ0WVY4eVNnZk5yVFcwaHNfNl9OWUhOME9jRE1xLVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJldDM5bXZnY1EzUENJSFVOZFpWV0gwTTdhNjBoeVZHc0hsN1A0d216U216eDBDUnA1bUpFcVlMRVNHa01WWmlsMGRwSkg4TTVLSnhBeDVHa3Jrc2hLdGc9PQ==
"How are KANs (Kolmogorov-Arnold Networks, [https://arxiv.org/abs/2404.19756](https://arxiv.org/abs/2404.19756) ) different from liquid neural networks ( [https://arxiv.org/pdf/2006.04439](https://arxiv.org/pdf/2006.04439) )? I understand the internal mathematical formulation and the motivations vary between the two. But on a higher level, are they both not proposing to shift the non-linearity into the edges from the weights?

  
PS: I am new to Reddit, any suggestions on how to structure my questions in a better way are welcome.",r/machinelearning,Z0FBQUFBQm0yeGJlaHIwV0FzYnNhckhnb2d3d1JmbUVkbnhpUDZob2llNkJhbURuclQxaE42R0JaYWhTbmU4S2hpVW82bGdFWTJzU3JZak9KakRSbXU1NDJpXzhCSjktY2c9PQ==
What is « reasoning »?,r/machinelearning,Z0FBQUFBQm0yeGJlN1FrWTdBWDczVnJoajMtaXNRWXpzVVdXZTFPMnFsVXFQZ2tySjZhblFmZzFlMTZvQUY2RkluRlVOZmZmUGs0OExCc0RJamk4eUtYWTFzTTFsYktCSmN0YmVZVlROdUZISFVDcFQyYlVlRDQ9
"If they used empirical support, then how is the ratio undeserved?

My argument wasn’t against OPs idea, it was about how to convince people",r/machinelearning,Z0FBQUFBQm0yeGJlTk44NWI1ekh0WDFlb1U3YWlsWnNkcEI0T0Y1OTlNTWxqQzJnVXFpSlpuY1BpWmVHb25FUjNpZG9UTWRCdEZjR09zVTZwaUhBOVRDVW5QcEo0TERDc0Y2dVlPdmdnTVgtR2JNV0V6NkVaVmc9
"I Think Google Should Have Not Have Made AI Overviews In The First Place There Is This Google Extension Called Bye Bye Google AI Turn Off Google AI Overviews Discussions And Ads From Tom's Hardware 

Google Had Violated The Sherman Act Of 1890 When They Even Made AI Overviews For It's Google Browser 

I Would Suggest Moving To Firefox Yahoo Bing Or Duckduckgo What Have You Any Of Those Would Be Better For You I Would Go For One Of Those 4 Browsers Insted Of Google Chrome",r/machinelearning,Z0FBQUFBQm0yeGJlUjNUZ3IxTW1HN05zcnk3Rm5sTEJ5Q2s5V1VCS1JrSVE3cXVsOTd6SGdLekVndTRPSmtwMXBBcjRKdWV3SnFoSFREUnNZY3hKUi1Za2ozTGROQXo4STRtOEZTeUI0ckhia0FWbm1la1JBcGM9
Hallucination and invention/creativity are not one and the same.,r/machinelearning,Z0FBQUFBQm0yeGJlYjRybTRBR2xFb3hDOGN3NzA1eWY1TlpoZDJZeGVXNnZCUVNMLWp0T2FJekVTVFRNMzR6OUlqamxtWjdsdWJxcXNyWkJIWWdWUlNBSFE4QTdBeFNDckE9PQ==
"Dumb people will make things up, yes. That's just lying to save face and not look ignorant because humans have pride.

A hallucinating LLM cannot tell whether it is telling the truth or not. It does not lie, it is just a flawed approach that does the best it can.

Your follow-up comments seem to want to excuse AI because some humans are dumb or deceptive. What is the point in this comparison?",r/machinelearning,Z0FBQUFBQm0yeGJlTXg1SlVyZW40N3RZc2JvamVVdXM3aDFGM05mODNoekM1XzFTZXdPWmQwNUd1aDg2Zkc4R004STI4cUg1dUE4VzcwQjBPc29WX3RkbHlEQVQ2R2xTQ2c9PQ==
"You are assuming a logical approach with incomplete information, and you are extrapolating from other things you know, like around when she died and around how old she was when that happened.

This is not how LLMs work. At all.",r/machinelearning,Z0FBQUFBQm0yeGJlWC1EbHdjaENsX3dDaDdPYnR5SVRLSVhUU190VV85LW9tdDEtVkpMR2JpaTBYb09zcnVTdnR3U21YNFgwQ3p0aTA4NHV5VVhNYUR3Z2d4c1ozVWhCZUE9PQ==
"Literally in the news these last two weeks is all the terrible out of context and even dangerous replies Google AI  is giving due to the integration with Reddit data.

You need to be more familiar with what is actually going on.",r/machinelearning,Z0FBQUFBQm0yeGJlb1NkbGh3WlNpU0JDY3c4UTFPNDJNRUh0NlVKUkJUU1BxX0ZnNktpRnQtSWJkNC1GWDVKSktaMGxfTnRVN01OUW11NU5BeW5FQUY2X01xNVFISVVCV2c9PQ==
"Imho safety includes the moderation that prohibits queries like: ""Help me commit crime X"". That is very different from hallucination",r/machinelearning,Z0FBQUFBQm0yeGJlODluUE5PM3gxRVJLSkxMMUxITGxxUTR0c0pScGN2S2xxYTdLb0pkdWJKUXdrcmtwdk8zdWdLalRJSXBha3dUT3BESFhoWGMwQUpqYVExRGNkTG10Q2c9PQ==
"That implies humans hallucinating will always be an issue too, which it's not. No one confidently produces random information that sounds right if they don't know the answer to a question(to the best of their knowledge). They tell you they don't know, or if pressed for an answer they qualify statements with ""I'm not sure, but I think..."". Either way humans don't hallucinate and we have just as much flexibility. ",r/machinelearning,Z0FBQUFBQm0yeGJlU0FXVmlvNUQ3dnBHSzF6VF9aMklsdmpyRUlKNl9XZko2ZkE0dVRQaUY0ZlVrUmVwY09rZEE2ME5PY1R5aGd2N1I5RTN5RnNnUWRiUXBwbTN3OTJ1ckJWQjhSLTN1TDBiZm1PdDUtVWJfWGs9
Lying isn't hallucinating. Someone talking nonsense that's still correct to the best of their knowledge also isn't hallucinating. ,r/machinelearning,Z0FBQUFBQm0yeGJlVzJrdXQ5NjJQeEFiczA4MENkTHVaUXFtWERzU3NoNGQ5TDBIb1ZfMzA5WGFnUy1WNmdlLU1tcGRQSW0xMTRNYllOLWhEUjlFNmpEOERWbExHbjZkel9VOUwwZ2E1TVN2eVhTRlhOcFdwMVU9
You need real world data. Your synthetic generation method probably doesn't generate data with discernable patterns. You could look for anonymized datasets for your needs online. Maybe approach the department in your company that manages that kind of data. Not sure what else you could do.,r/machinelearning,Z0FBQUFBQm0yeGJlX3VTV0N4QjF0M0c4MXY4UXdVTklvVEgwWlVONjkxb255ZFIzWjJCZUp6bEgyQXJ4dVc2TV9GYW96Qnl6RWczMmRVRDN6ZU9DS0dZOXdTUGx6OWZ5MmI1T1dtTWUtT2VmNGg4WG4taDJ0Y2s9
"Sure thing, imo that is one part of safety. but an LLM can generate a harmful answer to a rather innocent question, which would fall under the category of both?",r/machinelearning,Z0FBQUFBQm0yeGJlQk5rX0JiTmx4RjV5ekRZeG5jcUN6cUZJMlNyRGtnTjZGYWZ3NGdIeko3Y1pBcDhibkVudzVQdGNKNHF3RVBYQTlTem9Iek9BR3h6ZFpBUU1CYURwUUE9PQ==
bro he's the PM or UK 💀,r/machinelearning,Z0FBQUFBQm0yeGJldHo5LWM4b3BxT1lPeEliQTd5d0JWQWp0XzdTd3E3eW9GTGxPUWtCSUZYRjhyZGU2Tlg0Smw2RDZTYnVKNEQ5dTczeTVMMHZKWGVXMUNiV0RHSl9WMGc9PQ==
"The underlying mechanisms are certainly different, but the result is that you cannot trust what people are saying in all cases. Same as with hallucinating LLMs.",r/machinelearning,Z0FBQUFBQm0yeGJlRWYzendLTFZwUk5xNTE3U1BzZkJkWjdLU09UUnptcVhVMThHZ3NmNVB3Yk8xbzhaLWUxNUItMkc1RVZ4XzdFb21YQUU5YlNxV1JvRU5KSTBtdVZZVGc9PQ==
"How would that help? If you had tons of redditors who admit they don't know a thing, but the thing is actually known in some rarer cases in the training data, it would be a more probable continuation for a LLM to say idk, even though the correct answer was in the training data, right? The LLM still doesn't ""know"" if anything it outputs is correct or not, it's just the most probable continuation from the training data..",r/machinelearning,Z0FBQUFBQm0yeGJlaV9NX2VUOVZVX0gtdUstUUdPTkRSTHFBTDRGQjYtd2MxVmtpM21NdWM3Y0xFWFhsV3VteXdFMUVNTFJGdTVYbm1jTVJ4RVdFWlBNM2liZnZfTFhMWWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlYkFISGJ0UldhWFZubElFNmNPdWxQd1Q5Y2xDTWQ3VGN5bkZxTlZxdV8yUEktSUs1SE10ZkVYWnNPSmdwMmRmendyUE1ORlRWMzVMdklPN0VfenluQnc9PQ==
"I'm not excusing anything, just trying to explain that humans often say things that are wrong, for various reasons. One of them is lying. Another one is humans remembering things wrongly, and thinking they know something. Which isn't really the same as lying.

The point? There is no point. I just felt like arguing online with someone who made the preposterous claim that humans rarely say something that is wrong, or rarely make up stuff.",r/machinelearning,Z0FBQUFBQm0yeGJlUlJ1QkZwdXNCc0ZERl9jNklHRFBQOENBLS12QlNwQnRlZ21TSTJDajZQdWRvMTZPdXJoeHJJQmJmWWZBRS1oYjZLMlIwdzVTY25pbjdmQmFMQTdXMnc9PQ==
"Yes, I agree. ""Safety"" as whole would probably include sovling hallucinations (at least the harmful ones). But the first big arguments about safety were more along the lines of: ""This is too powerful to be released without safeguards, it would make bad actors too powerful"" (hearing this about GPT-2 sounds a bit off today).

That said, beign able to jsut generate spam and push agendas and misinformation online is a valid concern for sure, and simply time passing helps to make people aware and mitigate some of the damage. So just because GPT-2 surely doesn't threaten anyone today, it doesn't mean the concerns were entirely unjustified -- but were they exeggerated? I tend to think they were.",r/machinelearning,Z0FBQUFBQm0yeGJlSUtpOTlJZkU1bUt3ZnliXzd6VV90S1hmMmJtSHlrWDlHM3ptQ0tCdUlNYVNGMTdVRnFuVG9zbzhMNXVFRk82Qk03M1c0Mk93c3pHaE9tYjMyOFpyQVE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlSzdTZEtLdVFYdFFjalFjejFPSGdyM3p3TVBiWDNmdENwNXhPZ3hySlhTTTZhTnR6ZVhGVk9BclUzOVVWTjJQdVo1ZWJibjlyWGlicDhURER3cmpwMWc9PQ==
"i mean rational reasoning, following the very few axioms of logic

Or following one of our many heuristics, which ,however, are much more accurate and logical than whatever makes  LLMs tell pregnant people to smoke",r/machinelearning,Z0FBQUFBQm0yeGJlZkFaWW1ybWNmTG1xRDlLQlFLNXd3bVo5d1lTZ09HNkxaaF9MODJ5MDhJRjlfdzhjY2JDdG1Da0xoUWpkODFlZno5ZTRvU0FOY0U1OUEtQ3RlWHV6TlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMnJFcGJYbUpyNTNIM2o2bWF1bXFSVzJ5a0FoLXNkN0NXZHltQ0k1UXhxWjlncVJxSUVScjc3SElOdlZ3SjJibnlBRHE3MkNyQ0ZHWW1UQ2tITE5VT0E9PQ==
"Yes you are correct, it would already be good to skew the probabilities towards admitting the possibility of ignorance. It would also help with RAG in which hallucinations can occur when a requested information is not in the context.",r/machinelearning,Z0FBQUFBQm0yeGJlTkJCYjNTSmdTMkFLcTVaa2h6N1JBV2pYOVd0SVZnNjJBdElHUDg0QjNsVWtqYThFeWFWcGVmTUR0NEpfcE90Y2tjclZJMFdiM1M1M3lSWjZKR3dReUE9PQ==
"I have met plenty of people that, not knowing the answer to something, come out with something plausibile but  not correct",r/machinelearning,Z0FBQUFBQm0yeGJlRXNGai1xaFJjLXh6TXNFc3Z3d2FpT3h0VVdha3Y2M1NRY0NlbjNBWGN4STVhY1RLSWxkQkxCQldlYzVleGVQS1BGNGJuUkJMUlkwdHFobFZuZkc3d0E9PQ==
"Actually, yes! It is the initial approach I had in my mind, but seeing all this increase in performance using an inference wrapper, like tei or infinity, makes me wonder about other possibilities deploying these models in the production",r/machinelearning,Z0FBQUFBQm0yeGJlQkp6UXRPaldxaUtBcXZSbHFKRURjZjNwcE55d0FVYmdvTUh6b1ZPMXl3d1IyZ0pSa0tNUlNMQ2V4MHZQN0NYVEZUcWhMYWhpbWp0VnpvY0NQVUtyUXc9PQ==
Yes! I just wrote in the comment above for the same question,r/machinelearning,Z0FBQUFBQm0yeGJlOTk0blJRZk43OWFFOHR0WlNzSXNRclkzZDVJemZ3dm81N040clFubG9HZEtrbnBLa2c3eHhhMFljcUZ6dFdWek1nX2FBOUNWaW4zQVdlYVp6eDkwUXc9PQ==
I must test different ML algorithms for my master thesis and I could choose k=5 even if it is not the best value; I could justifying it with the fact that k=1 would make my model too sensitive to variance,r/machinelearning,Z0FBQUFBQm0yeGJlQ1VqMzV3aHQ5X2hfcU9seGtFcml0U09yU1NqbDJGbER5Umwzc2RJSGFjR0VhaFBpU2VNbnVzV3dXNFVQUG51OVNvSEdBSlNrOHVFNndick5xTEF1cklXbEQyWEdOZmVMRGp4VzFlZ1cxZlE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlU0s5eHhyNGRlbEVkc3FqRWZGMTFxUmtTSU5kX3BfeHc5UHJ4UFo5TTVMdlZoa2k0Rnd1UElFdTQ5LWpDZjdlQVludXo3WHUzUGJUYVNrYWFnXzcwZkE9PQ==
"Will read the paper Thursday night, so this might be already answered in it, but I have a question about a  tweet on this paper from ""thesephist""

thesephist >> *I'm very excited about the interface possibilities this will open up, particularly for multimodal models and creative use cases. For a moment I thought it was possible that dialogue may eat everything. I don't think so anymore. We'll see new universes of possibilities in both.*

Could someone please put into words:  
Why does this research result open up new interface possibilities?",r/machinelearning,Z0FBQUFBQm0yeGJlWUE2cmdZWGhUX2VIbzBfcjJlSEEtbnJSaUx0YkxiVWIteVVjLXA2Nmxpb0N2TkNWV1ZUZURPcEwtbS1YU3VpT2tGNXdWcUd3SDMtQXZ1XzU0QlB1X0E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJlYkpiNkFsMEdZbk1BS3h3Sno3MXBwZTZtTkltVnBtNnpNR1NjSFhRbGJrdXdSU2YxcEFMd0hxUHpaR21fVVpjN3B3TmpYVEJVdGVCVEhBWHRzdTNfdjczMlZKWkRHZno0Um05c05wbWhISFE9
"And those humans are buggy. The point is, it's not a feature. ",r/machinelearning,Z0FBQUFBQm0yeGJlbDRtQ25PNDBKS1FqRjEtb3JLVV9icE5aY241REppZFp6c1JQU1FRQTZOVkJDT0ZiZjlwbWJkRDU0S1dXMkg4V0U2T0xTbjNWd0EwelpRY3RGOFhKNGI1TjJzOTVUSUE2cUlxZ2tYZE01ME09
"your first task is to help them instrument the system to collect the data you need. Until you do that, its all a waste of time",r/machinelearning,Z0FBQUFBQm0yeGJlSlVnblZfa0NxTDVoLXNjb3VENGdhOTRUYjdTX1RPeWxfUDcwQ2dOMXhxLWRPZTNHZGNsVlJmRWNzNENONVFXVi1wMWlPaERTN19TdEZESlhza2JNSkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMGlrXy1XY01CQklVZmllV3lfQzBxM1ZTanRzUWx6Tm1GMDVjOWxsWWtHSmJPbEpMeDhScU4xdUV6alNpWURkQlZaak9FTllVZW1PeGNRMWdDMlFTTUE9PQ==
"It is a feature. It is what allows exploration. Think of it like an optimization problem. If you only act greedily you can't make bigger jumps and will eventually be stuck in a local optimum. Creativity is a form of directed halucination.

Or think of practices like brainstorming. Most of what people will say is utter garbage, but it's about finding the one thing that isn't. We are highly trained at filtering ourselves. If we brainstorm we turn that filter off (or try to).",r/machinelearning,Z0FBQUFBQm0yeGJlek9vQ3JmNU5NUFdiOUU2YWZuY0hZMlhvbE9URWdOczJESXctdUZPdTB3cm9MZzdIcDNPV01QQnhoUy1BV2lIdC1jclZXbjUwRnRyVlNtVklYUWhSdHc9PQ==
You think the steps of information processing through the layers of a neural network aren’t following a few axioms of logic?,r/machinelearning,Z0FBQUFBQm0yeGJldFprLXZIdXVTalU0QXJndG5YQlY3RmxIN2VUTEExVTJZV1U0SVM5UWtVQzhsMmYwTXRDZUxCb09GQU5tMzZqdXRJSk9WRDZrVXVmQmQ0VzIwc3JET0FGV0pURzhVSEh6Y2hUamdFd1JNSjg9
They need to know what they don't know.,r/machinelearning,Z0FBQUFBQm0yeGJlaDVvX0wyM2E5TWN1NEwzXy1IOWpYeFRYMU1KWHNReVZzQzRzQUpaeDF4eXJaWEtMNHlMZVJ0aU9ZRlVzdFRBUEtrWW9oSFVzYlM0NVpWdmh0c0RIUWc9PQ==
"I don’t buy this. For the model to be creative, it’s not necessary that it constantly gives me nonexistent APIs in code samples, for example. This could and should be substantially ameliorated.",r/machinelearning,Z0FBQUFBQm0yeGJlMjZFVTRNZmRhMGcxUVhGV1RPTkhBZGlCRlZ1eEJFc1ZLZkdGcmRzVUdvNWJnTV8zYTJTMDZUU1V5Mk1ISXB4dFdGUzNkQlRGUjNBd1o1MGVNV2lHemc9PQ==
"In a world where not having a job means you starve, yes, creating new jobs is objectively good. Get back to me when there’s a decent UBI.",r/machinelearning,Z0FBQUFBQm0yeGJlUk1lc3hUR1d5Um14bzl2dE5WbmhseXgzUG5jd042ZUVFeHNnZnJhMHozZU9HSGRyYkFvWWk2VHo5dDYwY1FQamVXY0ZWclVxVzlKNUQ4VGdtOHduSEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMGVsOFZ3d3o4eTVqcWxIaGpwRC1abDdLbkdvaGFNN0RGTzlramhIQ1pvZVJjMkVsM3VrdHZ2cklGdlNGVDNtNElWSFVrVHhzUnNlS05RTjlKN2NWdEE9PQ==
"This isn’t just a couple of employees pissing in a bottle once while everything else is peachy keen. Mistreatment of its workforce is endemic to how Amazon operates, and people should be cognizant of that when they purchase from that company.",r/machinelearning,Z0FBQUFBQm0yeGJlanlBYS1WNGVXLTlCRllYZ1ZxME0zakFKWGJLdG04MmRXX05jaFZ6UjJIb3VSMGZMMm84RnFfc0NLMGhRTWw3UGIya0VSSGJWbVdGNDRONXJsd20xc0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlYy1IbWlyZnFhRTJ3eThmNFpMcHV3aGdqWEVCdHlOLXRZWUU4b0duX2NLTzUxbUZpclJoaWF3a2FIQllDZTUtZU8xb1c2Z0tkX0RCa3N5S0F4el9CbGc9PQ==
Do we have any evidence of this? That layers are steps?,r/machinelearning,Z0FBQUFBQm0yeGJlMWxxQmwyRWE0Nnc1UjV3R1VTcWZVQTFhRGd0VGx5dGhCc0x5d0w2UkVUVkF1SWlqdEVaQ3NnMXR5OGo2Tk5yZ1BrTGFqM3J0aV9ESDlTYk5EMmt0M1E9PQ==
humans hallucinate in the same way LLMs do. humans don't use paperclip maximizer logic,r/machinelearning,Z0FBQUFBQm0yeGJlbVpzM3BGbXJMTDZnZ21TbXloQXR5Qk51SUpVNWplMXlkU015VWtnZVJUbmx1cDNCZUQ5SlBoVVlJZlBkclh0NjBKZnJXZlk5dUpQcTJodnhjc19MUGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMTIxaXpPcDBEcFpzalVWem1uT2M5cnlySlNLQmxCcVB3dkM1b3hCbGh2ZDY1Z0JqclQxMDVJeWU3czBnQWUtcU42TUp0X255d08wMHI2aXRiSFd1WVE9PQ==
"""the results were extremely bad""

What results? You don't have access to data?",r/machinelearning,Z0FBQUFBQm0yeGJlRzdJcWVOQUNWRkJsLVA0Z3hHODNaT3haYnNmLTM5WVEyS3BvLUwwTEtEaVRiNFJhWmNWRldPUW5BUndnRVB4NlcwMGQzTWY3OV85X1JjSUJYVHNwQ1E9PQ==
Part of the homework is finding a paper.,r/machinelearning,Z0FBQUFBQm0yeGJldlpqM1RHN3RLdUh5cXJSMTR2RzlDamNTX1IzNXF3elFGN010SnFhOWIwNHhZdVZBSFB3YTl4TU5YdE95TGlRTVZ6ZjNxRC1XbVNoTUJTb0NVQzJOUmc9PQ==
"If the job is literally dehumanizing: No it is not.

I don't know where you hail from, but here in Europe, you can survive without a job. Not UBI, but also not starvation.",r/machinelearning,Z0FBQUFBQm0yeGJlZFhPWmthUlA1LU1oZVc1NFNzZkZ3Ynh6a2lvSERYbFBrOEhONmlXbjVxTXMzTmtxYkJ6cUhuRngybnVBSDJhUEl5eW52TF8wR2NnOF9WTmJSb1RNT3c9PQ==
">far from being industrially useful

Is this due to high computational costs or other reasons?",r/machinelearning,Z0FBQUFBQm0yeGJlT1NuRV90a2s3SDhtY2Z1NmpQWS1jbDNXamp4cU9kaVlidEpwNzlGSmlXSDBCd1J6bzVpUDNvczN1eDdUSDhTNmFJNUxXank0dUFHNzg1QzlzT0w5VlE9PQ==
Define hallucination. I don't think we're talking about the same thing. ,r/machinelearning,Z0FBQUFBQm0yeGJlaFc3bFRKOWV5MVBzSlJEVUVoZExiVE5nemxLOGdmMHN3cFI0VDdEVm5yZFJjRzk5V1Axc0gxcVVNam1UUHItUXB1a1dHOFdlaVR2cktmWmhFTU9fRlg2R2YzdjlfMDJVdVFYZTRVZG04Y1E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlRk9wVV9jaXhlT2dxUFNzSTJFckkxMUprOWEzY2Y4Ri1KbnJvdWk0Y3hJeXJNN3c4bnhHU2U1ZWpDMnJkV0ppVUNtUnFKOWVPQzMyY0ExYWZYQWdNelE9PQ==
how did it work out?,r/machinelearning,Z0FBQUFBQm0yeGJlUDVvOC0zNEl0V1BZTzdJZE9wOXV3UENDMkswUVFaalN0RTZqbmt2RFVZYVZocFJ6d3Azd3J5dzRxbzNvUnN5cVBSNThxbUZmUnROcHFoZ05oSEM1bnlCdUowbTRzYTgtaE50d3d0SjlqSjQ9
"Only work towards models that you have some kind of plan for how they will be operationalized. Figuring out what data is available to you in an operational context is the first step here, not the last. If you don't have real user interactions to feed the model, it can't be operationalized anyway.

It's one thing if you can't get access to the real data because of sensitivity issues and so you're forced to work with fake data. It's a whole other issue if not only you can't get access to real data, but you can't even get a description of the fields that would potentially be available to the model in production.

Either you or your manager need to figure out what engineering teams own the platforms upon which the kinds of interactions you are interested in occur, and work with those teams to figure out what kind of data is currently available and what kind of data they might be able to collect that would be useful to you which they aren't already collecting.",r/machinelearning,Z0FBQUFBQm0yeGJlVEVwQlJUbFV6cFlZR0dxNlV1enNQd1lFSFB1dkxIV3RKc3FvNk1kR0VzQzFBQXFDaDNFMGEyOHhKRHpOU1pQREd2OHU0a195TXJmNWNTbVFCS2RWQ2c9PQ==
"It does not learn the names of the API calls.
It deduces the names from the embedding it learned and the context.
So what makes the model work is also what makes it hallucinate.

It is mind-blowing that it works at all.",r/machinelearning,Z0FBQUFBQm0yeGJlOFVwekc3ZzFZMFhiNTlWVk9aOERiUkdXcVJVWG9sSEpJWV9malRJZnJaTTJfUDVhOG9yN1VsQjF3d1ZtU1ZicFFxZjRkZ0ptYzFQbUhJZ29ja3phSmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlLXlQWTFsTmdqVm9RbUZhOFBKMHRiTW52a044cE5UR2IwdTNtSW11NXRJcVdPem9PUWNTTEltMl80THVfaWU4MkZ2MXM0REd0QzBYYjdoWjZBaDdnc2c9PQ==
"You still have to validate the data, as the models don't have a way to explain their output, it's just a breakdown of token probability according to whatever tuning the parameters have. It isn't producing the output through reason, and therefore can't cite sources or validate whether a piece of information is correct or incorrect. 

As advanced as LLMs get, they have a massive hurdle of being able to comprehend information in the way that we are comprehending it. They are still completely blind to the meaning of the output, and we are not any closer to addressing that because it's a fundamental issue with what the program is being asked to do.",r/machinelearning,Z0FBQUFBQm0yeGJlMG85MmI0ZGZFVU9SSnA5cmRCd21idzZDSl94N1V4d1htYVl2bVBNMWtucTI3R1ZfYzE3OXMwS1I4bHQ2MlBzSG5hNHdvX3ZWM1lJT2FXbV9tWmEydFE9PQ==
"That's not true. Humans can parse what makes a statement incorrect or not. Token generation is based on probability from a dataset, combined with the tuning of parameters to get an output that mimics correct data. 

As the LLM cannot interpret the meaning of the output, it has no way to intrinsically decipher the extent to which a statement is true or false, nor would it have any notion of awareness that a piece of information could determine the validity of another. 

You'd need a piece of software that understands what it means to cite sources, before you could excuse the occasional brainfart.",r/machinelearning,Z0FBQUFBQm0yeGJleXdfdlUzV045eHhSMU0zTWtuX3paTDh3S0ZYT3NBTkVMQWdsSXlabUd0VlpxR3FMTlJlUklic3B2UjJmOENPdXBuVV9qVGt1QUJNOGNLZExpRV9uV0E9PQ==
What do you think it is? Large Language Models and deep learning models in general would be deterministic without adding a random constant (i think they call it lambda). You can either define hallucination as that planned randomness when choosing the next token or you can define hallucination as the resulting effect. Namely that the cumulative randomness can lead to the models predicted sentence straying completely off or just being factually wrong.,r/machinelearning,Z0FBQUFBQm0yeGJlekFPdlJteW1MOTFoUVI1dGFhMTVaeWlwckJpdFBHb2RDRDgxTnQ2bEFJbkRHYTRyVHlGNnViVjdVaUU1TENJWlNvbXdzWEdxaUFRRHBUSDhJT2w2Vnc9PQ==
Doesn't mean we shouldn't invest in building systems to detect and suppress hallucinations. The system may not be purely an LLM,r/machinelearning,Z0FBQUFBQm0yeGJlc3B2VEZpVEpzOFlLdEtrNG15ZWZROUxTSnhNRGd5eGJ3b2dKNi05VlBRUVI1dHo5UFYxM1laOXRyZ1k5enVINEMxSlhaSE9HZ0NCNG9oYU5QSFdOeUE9PQ==
I think the argument that LLMs are dumb because they use probabilities is a terrible one. LLMs understand the meaning of text,r/machinelearning,Z0FBQUFBQm0yeGJlZ1NJZ2NDOFBZandJZndKSFNIYlJtbXBCRHJOT1BhRFlVX0FpOWg4dHNJOFdfcmpPWXFuM1I3OF9TV0RZcW5paWVDX25wb3FhTmVURmtBVlNXOF8wWmc9PQ==
"I would strongly disagree that RAG alone is the solution for hallucinations, yet alone safety in general. It is useful or even necessary for many applications beyond simple demos, but it is still inherently prone to it. Current models still hallucinate even if you provide them with most relevant information, the model sometimes just decides that it needs to add a paragraph with nonsense information. And constraining the model too hard in this regard is not helpful either as it limits the models overall capabilities.

Changes to the training objective itself as well as rewarding the models capability to self evaluate it's area of knowledge/ build internal representations for that seem more reasonable to me. 

The ideal case would be a relatively small model with excellent reasoning and instruction capabilities but not a lot of factual knowledge. Maybe some general common knowledge, but nothing too domain specific. Then slap RAG with large amounts of documentation/examples/web/... and you should get a pretty decent AI system. The tricky part seems to be the small non-hallucinating instruction model that is not bloated with factual knowledge.",r/machinelearning,Z0FBQUFBQm0yeGJlem55RUtfdVkyQkxHTERRZFlMUy11LWJvLVZmcExNcHF6V2RmTXlFcWwtNXVBemdFMUxKdHlfNXBxVVpuV0ZZNDROWE1kT2lnSllvSG1rLTZXTUMwZmc9PQ==
"They do not contain the ability to do that. The way hallucinations work bears that out, it's a core problem with the software. 

There is nothing else going into LLMs other than training data sets, and instructions for output. If you mess with the parameters, you'll get nonsense outputs, because it's just generating tokens. It can't ""see"" the English language. 

This isn't totally a drawback, for what it's worth I think creative writing is a benefit of LLMs, and using them to help with writers block or to create a few iterations of a text template is a wonderful idea! 

But it's just for fun hobbies and side projects where a human validates, edits, and oversees anyway. The inability to reason leaves it woefully ill-equipped for the tasks marketers & CEOs are desperate to push it into (very basic Google searches, replacing jobs, medical advice, etc)",r/machinelearning,Z0FBQUFBQm0yeGJlN09ScGZWZnhoUm82UjkwWm1yN2d5bWNqc1l1QkhpbTN4NmRydmQzWW45QVVCN3JzY3pORmdjS1ZZRUFBcEUxekI4ZUF6MThxam0xSWZ0a2UyVk5ISmc9PQ==
cold start problem. use the data you have as a rough first pass to get something operational in order while collecting the user interaction data that you then use in your more fancy model.,r/machinelearning,Z0FBQUFBQm0yeGJlNEpwYzZiR3pqREhXNE82ZXI5bVFmMFBVYTdtQURrc1pIOTlVYWJ6ZHZUR2lHS3A2emNCbVN2R3I0MzVzLW9XRWk2WnlnNER4YkY0YmlDblM5S2VERVE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJlM2hzdEVyX3k4dVpERGNwYTNUOE02NzFPQWlMQ3FxZDBGX21SUXB0bTBtaEo3cDZsb21fdHFFd0hhRmthS0xUUnViNklxVHNVTXBkakU2SUc4aE8xcll2S3hxNmxud0xiN3dnU2RMN0VqQ3c9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJld3p3Wko4RzhuSzhXaHpsdlIzWWI5VHNQT0lmVEFYUkNPclY5REY5ZnNvWGszOVI0eXVHRUhTT2ZCQlFPcXp4dXhXdU04NGFmVmh5ckJkaHhtUHBiTkJwZmRVYzdPbU93NEkwMGlZWjh4MEk9
The one fused with Stable Diffusion 17 that adds in the picture an object with its bounding box in 0.25s using a simple A100?,r/machinelearning,Z0FBQUFBQm0yeGJlQW8wM0VjVXlqOXZwUUFiYmdrSXc4eGRYOU5pM18wWFR2aWQ0dlIwSXZIVzltM3hTNl92NGJFSGN5b0t1X2lTQTNqQVFJQ04tTHV3OW00aWl3N2xETmc9PQ==
"I know this is three months late, but maybe this article can be helpful: [https://medium.com/towards-data-science/fine-tune-smaller-transformer-models-text-classification-77cbbd3bf02b](https://medium.com/towards-data-science/fine-tune-smaller-transformer-models-text-classification-77cbbd3bf02b)",r/machinelearning,Z0FBQUFBQm0yeGJlMURMYUxxWjVZTDJGS1dPcjR4bDZnWDJVZVJDV29oZHI3OEk4WUZvM2hmTmtGamlLY2tmWEFRTnh5aVlWdk9GZ1hnVDh3eXZxdWtwWW1YdWhQMXZKTFE9PQ==
I kind of figured this out months ago with GPT custom instructions,r/machinelearning,Z0FBQUFBQm0yeGJlLTIyS3ZSYzN0V0RJYmt0SEFwR3ZrN0RZQmhiaFZWS1VfV1RMOGhHUWg4VUpWNEc1Ujhac1ctRW5mMmNMMFZ0ZlFHUlBYMktaTU9VM0xWYjJCRlZwZGtIeE9meW84NEpBbVNNc2J5cUl4ODA9
You guys are definitely talking about two different things.,r/machinelearning,Z0FBQUFBQm0yeGJleUtyckozWmlMUkVYVXppQ3hySEtOMHFxMkFlTlEwYUpjUGEwWG0zUlpYZ3VnV2NBMHFkcHVuN190SFp4NkkzOTJPaEh4LXVDUnZieFY2UjNudDdyT1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlQUQyQzV6R2ZHcXF5SFMtQ1h5MUticmV3SW1SZ3NuZUsybWhLN0pmYzJhOFpkendBcDFnd3NaVlpkQ0NkYThvOHZBcW1TV2VoQ2NBS3pPNndvV0Y4dFE9PQ==
No,r/machinelearning,Z0FBQUFBQm0yeGJldUlWOHRfQmxDQzdRbjRWVFBkRkJPWVlsX3k0VEpXcmVkc1d1MHQ1d3hxQngyZXgzUWV4R3pfYkRZTmVSVEpUYTMyeUY4NlJsZWNESkNDelhudzlOYnFLRUtUdTA0eENuMm5SRmJaVFpNWmc9
Shame on you for contributing slop to the internet ,r/machinelearning,Z0FBQUFBQm0yeGJlYjRMR1J5TzZ2RjlTV0hOdlJQVkpKTmNPU0dSRUozNEZ5UmhrbnQ2M0tidWJ3elc0cmtLcEhDaldhOGktYThzSldZZmdaVi1KSlBzQjFFQl9XbWxvNFVDX3R4LUdoQzRYZVM5MHdIVmQ5bmM9
"> ameliorated

I disagreed with you completely until this word appeared, proving that we do, indeed, agree. It can be **ameliorated** ad infinitum, but it will never ever be **fixed**. That's my whole point. People with no understanding of AI/ML always frame the question as to when it will be fixed and, to hear it can't be, conclude you're saying that it can never be ameliorated.  But it can be and can be substantially.  My family members, being catholic, I tell them that fixing it would entail making it infallible, rendering no more use for the pope and a collapse to the institution entirely. If they're devout, they usually can't understand a serious answer anyway. If they're not, they'll know I'm joking.",r/machinelearning,Z0FBQUFBQm0yeGJlaVZWdXEySDVlNEwwTmRkUENYaU5ScXdPT0pacmZCTkk1VERmODBBcUpuc3RKR1J4NWotclhDRTJtYTJyeWFyT2dkSmRRV2I3RzcxdGUyaEQ2VkhYekE9PQ==
"I remember about this on hackernews at some point in the last few years.  One of the issues Intel had is that once you're mounting the cameras meters apart, you actually have a very difficult time of calibrating their position relative to each other and ensuring that they are remaining calibrated.  Even if we don't put them on folding mirrors which are... less than perfectly rigid, there's a lot of frame flex once the car is driving, etc.",r/machinelearning,Z0FBQUFBQm0yeGJlNmxlYnkxVW5pc0x3X2NleTRXUE5PYzNJUjU5UG9mbkVWZ1pvRW0yUEF2dTd6dkE2bTZldWZONko0WERjSTE0Q2JMWUpldUcwVWY0OUE3bVFJeWNza1E9PQ==
Thanks for sharing. I'm sure it'll be helpful for people looking into similar problem statements in the future.,r/machinelearning,Z0FBQUFBQm0yeGJlak9tbWFOenFET2V4NnotUHZvMW1CdHVTN0dLRkdMYTZzYUs0V3F6ZzhNTWFGNkZDem15bC1Qc3A3d0UwMkxDTF82V0lneHkyYjNsX0REVDhrcjRnaVE9PQ==
"Humans hallucinate too. The issue with LLMs is you can't absolve blame onto the LLM, whereas you can dump blame onto another human",r/machinelearning,Z0FBQUFBQm0yeGJlN00yRHRMd2lPUUtJcnl2YTJ2RURkQ2pWVEg2eEtzbkFMVWVpLVRSbzZZQVBVQ2dIMzBWWlBJczFBYVNLZlhQbzhQV1p3Q2phTlNjOEhuQ05PZHBCZ0E9PQ==
Does this subreddit have a discord or slack group?,r/machinelearning,Z0FBQUFBQm0yeGJlTFVXOU5JdGxlNFNwNEQtOUZBdl9RT1cxWkt1NWlrRHl3X3hZNjFQYk1zam1XRUgyQjloQW51SVRiTEZZWlBabm4xaEQ4ZlRJZmZXUE00TV9EMG13MGc9PQ==
"> It is mind-blowing that it works at all.

Especially if, like me, you gave up on decoder-only models after testing what GPT-2 can do when it came out.

Context: ""My name is Sue and I""

Answer: [something horrifically subservient based solely on Sue having a female name] or [something stupidly mundane]",r/machinelearning,Z0FBQUFBQm0yeGJlWWp4VGlNZWpibVpaRGlUbVBweEhsVDkzVXdSM3MxeklZWUpUT1NodDlIN2dpRTNOZ1pvYll4RTZqTkFmVV92Zi1oLWgxNFBFYk1ZdXZGTUNXRzJqZ0E9PQ==
I had another question - is greedy decoding better for generating more accurate solutions in general?,r/machinelearning,Z0FBQUFBQm0yeGJlTVNiczNBUk9NOFNWX1RnR1F5QUh6cGtBQXoxZmQxbmhKTTJiR2VmZV9JeU93T0xxYnRwSVpkRFhzU2NkRGFpTzFSRGtyWjNJWjNwTWhfWWlTZzlmWFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlNlM1V2JjaUNJb25RQ2lDM1FWMDB4OThwZ29uTGt6X1d2cHVvcXR4Zk9hek5kZmxFRi1DTlRPcUtWN2FPVlF1ZVdBWXVrRjhHWEhJa2JOdXYwWmJUd0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlU2FGUXA0Zk5fVkZSZ0kyWmxLRTVsOWtIUFV4RVo4Slk1eS1XNmF2Rl95VXBzVEtaMHQ3aTFOczB5VGVMWXlUeGlkdjJSb3RPMWJfbzU3WFpzeFBFZUE9PQ==
"# I want to start learning about machine learning.

I don't have much knowledge about computer science or even the non linear algebra for that matter, however I have a 3 month of summer to spare and a desire to learn something, considering the hype around Ai I thought why not to try machine learning or something like that, I started watching some courses on YT however I realized I need some more prelearning for that, what courses can you suggest for that?

The courses I've already considered are :

* Linear Algebra — Stephen Boyd’s EE263 (Stanford)
* Neural Networks for Machine Learning — Geoff Hinton (Coursera)
* Neural Nets — Andrej Karpathy’s CS231N (Stanford)
* Advanced Robotics (the MDP / optimal control lectures) — Pieter Abbeel’s CS287 (Berkeley)
* Deep RL — John Schulman’s CS294-112 (Berkeley)",r/machinelearning,Z0FBQUFBQm0yeGJldHZJYUJHdjAyeUVpQTdpWk9wcTlXUG5RS2Q0V2ZTVks5LWlCZ2N6aHduLUZyb1VCOG9Pd0VsYlg0YXVDX2Vzbm9wTDdmYmJ1X3UxOXdOVnQycnhudERXUU9KQjRCeGNvQnlGTHFGS3pOSFU9
"Hallucinations are more likely or less a non issue due to automated source citing, guard rails, inter agent fact checking and human-in-the-loop.",r/machinelearning,Z0FBQUFBQm0yeGJlQjROdktOZHNVSV9uc01lS3QtVjE3VzBSVWJlZXhSVkMyVkJ0TzlSMzlNcG5PNm8yZnM2ejN4VktxUWJyeXk3OXNCZHlDazA3eHViVGh0X1hLWXV5b1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlcms0UGN2ejRHVXJrM0ZNOEZyWndZVVVfYVZmTmNLZHhfN3RIZU1DTnBvYUY0NXJMZWp0X2thekI4QWlxTzhKX3g3MDFGb0FrR1dWcmh4ajkzZ2tLYkE9PQ==
"Yeah I think i am just going to build my own backtester, since this seems to be a relatively unique issue. Honestly I imagine a lot of people not realizing this issue, and creating faulty evaluations, but they probably still work fine...


Thanks for your inputs!",r/machinelearning,Z0FBQUFBQm0yeGJlX01hcW9wb2JNdlV0YVp0ejU1MWVxQVl6OGFrWWVKemdqTVRIVVdlR0RBbFQ1dEdoazRNbEVKSzJ3b0hVcmF1UExJOXVBOENET2lqeEhUa25JNjVvdUE9PQ==
"Explain it’s a cold start problem, a 100% accurate model would mean that no action is necessary since you have to train on a dataset where no marketing was done. 

Use a Lead scoring method initially and use the distribution of the ranked decile/centile as benchmark.

Then follow up with uplift modelling once the solution is in progress.",r/machinelearning,Z0FBQUFBQm0yeGJlVGxtQXFSQnVMMkx4ZGNCRV9xNnphcF80TzA4S3VIQm1RY3B1MEdGSmc1dWtUYzR3SjlheGFfempPamJ1X3VfcVYwMzVkZWV1ZExBUWRCTXZnN0s5bGc9PQ==
"The axioms of a nerual networks are the axioms of arithmetic and linear algebra. You get some input, which is first tokenized and mapped to high dimensional vectors. In most LLMs the steps are repeated applications of normalization, matrix multiplication, application of a nonlinear function and gating of the information that passes through the attention layers. These operations can implement all arithmetic operations and perform conditional computation (i.e. if-=else statements). Given that these networks are stacks of layers with the same internal architecture, where the dimensionality of input and output don't change, they can implement for loops (limited by the number of layers/blocks in the forward pass).

The way they process information follows logical steps. It's just that it is not directly mappable to human language. Or do you imply that all reasoning, even human reasoning, has to be decodable as sentences in human language?",r/machinelearning,Z0FBQUFBQm0yeGJlN09ONWswOTJvZE1SNVp4bDFxY2p4LVBOWm5jZ20teklBUXEtdTJudDN3NzFzS1A5OGttU0REbkhMMC1ueUN5NFlyM0lQczJFaDRrVWVGZE9BMjdsSlZSWmVOWDA4b20tZlRmYldDRlhuUVU9
"Every layer in a neural network is approximating some function. If we are to believe that sequential layers represent sequential processing in steps, then that needs to be shown by decoding the function of each layer. Otherwise, i do not see how it is evident that the way they create their responses is based on 'logical steps'",r/machinelearning,Z0FBQUFBQm0yeGJlcmZINVM0SEdWX25Mc0xNaklydmhsS19Ra2xQanAwalh5eXVRcGZGNmdRMlZBa2U4Y0F0WDVnZEVkdDk5ejhVMzNtRmd6Y0w5YnptWEdjRHVJdU5lLVE9PQ==
"Well, if you use an LLM it won't give you consistent results in the long term, so your best bet is to build something good you can use. Using an LLM for prototyping is fine, but it's not going to give you enough consistent results. Learning how to use the transformers library isn't rocket science.",r/machinelearning,Z0FBQUFBQm0yeGJlOEZMUlJOZlFFcExpdnZsdG5OcjdSZnY2TEkzTDkzYXE3UEljQ3huek4wck05dHJleFBQRGxxVVRaMEg2VEhuTl9vSWQ2UXI0M1VPQjMxaFNVVFRqNkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlR28zWXRaenYySUdBVnp6NFRxV3NJV1FVX2xfMEZ1RTBVSlQwcTZXNlo4T2xFTk5ZRm0tZUtTLXo3alUxclBKckxqS0FEQ3oya0NxdUpZUWdEcmhxR3c9PQ==
"Interesting, I overlooked that. For the ELBO table, we use models with linear decoders and an overcomplete latent space of K = 512 dims. This choice was to connect to sparse coding literature, and can potentially explain the large performance gap.

But thanks for mentioning this. I will explore other hyperparam settings to test if the large latent dim is indeed the reason.",r/machinelearning,Z0FBQUFBQm0yeGJlZGFFNEFrOG04Rm1kNUF4c183cHpzY1MyWUVLc2NvNDJMMTRkQzZkSmFSN2xzLVF6MzAxM2IxTHZkNE14dmJJVVRsdkRlS0ZfbnRFeXNxTUExckk5aHc9PQ==
I don’t think this is true actually.,r/machinelearning,Z0FBQUFBQm0yeGJlVEtBRlNTV3c4aU9xTkdaeFFVMWZlS00zNXctQ0pHTFFuR1N5MG1tOFlVUi1iUU1ESENDd2ZLWklkblJ4MXY4VlcxTUtXeXBmLVpMeElPX1J0TGlKeEE9PQ==
Which part?,r/machinelearning,Z0FBQUFBQm0yeGJlMDh4TDZKbS1BUkpqOTd5ODhjQWdQY3AwUnd5N2o2RnBwZk9EdWdlaGQ0aENOQnVvR1djZGRrMTZJdm5IM0U4TkFmSHpNZUZySHBodDR1N1FqYVJvUFE9PQ==
"They are, by construction, doing sequential processing steps. That's how nerual networks work.",r/machinelearning,Z0FBQUFBQm0yeGJlSmF3bWlKN21WZWZqbDg1WURtREU5dGIycEZSMy1TekYwLWdWQXFMRW9IRkV1dnJpYzgyOXhIMjNUUU9jbk12bXBPR1pnUHRhS0EwQ2pIaGJhU2xrTmc2cnZ4WFRqWWFDZlNkQWRHY21ETnM9
"Not in the same sense, which is an important distinction. You have to identify why the problem occurs, and it's for two different reasons when you're looking at human logic vs machine learning.",r/machinelearning,Z0FBQUFBQm0yeGJlS08zUTJiX3FyMEx2enMzUWV1Z1J1VWxNRFRoQ2gydjU2Z2hSX2NCSzFHUlF5enJSWEdoTVJCRkRxckxKWEp0VF9MYkFTTi1yTW15QzcwOWlQdFRHdkE9PQ==
"It's like inventing the car and try to attach wings to it, and to find a configuration that is sufficiently ok to make it fly and have the airplane. Imho you can find conditions that reduce or minimize the hallucination in particular scenarios but the output wouldn't still be knowledge. It would be a probabilistic chain of words that we can consider reliable knowledge because we already know it's the right answer.",r/machinelearning,Z0FBQUFBQm0yeGJlWDhtVWFEVXlpbUl6WVpQNDV3QlZFOTNGeHFrYXNzaFBlWEJ1VUJEWkJVLWQ5NVlFc3Fidjk2SEprNWV2NFdfZXJNczVsX1N4ZlBEVkVMNU1BOTlnVlE9PQ==
I think there is some understanding beyond token prediction in the advanced models.  There are many emergent characteristics not explained by the math.  Which is what spooks the builders.  It is why safety is such a big deal.  As these nets get bigger the interactions become more emergent.  So.  While there are many that disagree with me… I see things that make me think next token is not the end of the road.,r/machinelearning,Z0FBQUFBQm0yeGJlNGNBRU9wYkRHWE9aMEVyZ19NdHNZTk5xSDQwNENJLTRsTlV3blhQTXlkdk5hNlIwcUc3X05QSTFtRVM5Uy1zakFwcGNITDBJT21SUmsyN2k0NDQ0OGc9PQ==
"$20 says hallucinations are much more highly studied, safety is much more reported in media.",r/machinelearning,Z0FBQUFBQm0yeGJlejNjX3p1V0FDLXA3clJBMTM0NGdwbFN3YVRNQXhVSXRwbU9OUFk1c0FKR3hIZTJmS0lsT3l4S3NkWVZ1ZGtWOTBveGlDVnFMY05NN2x4MDVqSjdTMVE9PQ==
"Why so?

LLMs learn a world model via diverse natural language text representations. They can learn it well, forming a coherent world model which will output incorrect (""hallucinated"") statements very rarely. Or they can learn it poorly, forming an inadequate world model and outputting things based on this inadequate world model that don't reflect reality.

This ""continuum"" of world model quality is quite evident if we compare LLMs of different capabilities. The more powerful LLMs hallucinate less than weaker ones.

There are some complications, like arrow of time-related issues (the world isn't static) and proper contextualization on top of good world model, but they won't invalidate the whole premise IMO.",r/machinelearning,Z0FBQUFBQm0yeGJlUUtneXZ5RTZqUlQ3M2JENW85aUI2WlMyQWFDckY5bUhmQXBFUEI5YnFoNEZlTlozVEROM2tYd2V3OTdMNWIyRGNvRDRIQUs5eFNXd2hCUW8zUmpuU3NUdUVuSVBCVlpCUlFJQWR1LTIzWDg9
that doesnt mean that each step represents the equivalent of logical reasoning step  that humans do,r/machinelearning,Z0FBQUFBQm0yeGJlaHhiS3JBU0VlRHFwbTRKU0UxTm9mQzRNVlBiZGJkc2diWEhEcUtjdDFhdVJpQU9rT1k1VGNSUWVfcFhfc1Z3N25JeUV0ZVhIT2F3d0tQbE9kcGZfMkE9PQ==
If you have stereo cameras plus lidar you should do both. You can use a dense photometric loss for the stereo cameras and a sparse absolute or MSE loss wherever your lidar points project.,r/machinelearning,Z0FBQUFBQm0yeGJlMHlNbF9hZFQ4RXVZUTBxbjBFVmNfVi1OLW5TaklyNHFzQ0VxSDFGRnhmYmdPTW14SkVMbWFnOWJkYXNKZXpmNkhselRodnVTWkVfS0xwSnZuNnFVT1E9PQ==
"Which AI/ML conferences are friendly towards people from software engineering (application-focused)?

My research focus is on SE and I already got a couple of top publications in the SE field. Our next project will be LLM-related, so we are thinking about going for an AI/ML conference.",r/machinelearning,Z0FBQUFBQm0yeGJlZVlNYTV0VlFzSWxFRHdDYmJ1S2U5SlNmaEctYW04QmNhdG9jQUZBSE5seUZEZ016QWt1eGE2OURUTTZydmxCRmRBbGRWYzdnN19icDVFOU5XMEw4dVE9PQ==
"I don't like that point of view. Even if you think hallucinations can be useful in some context surely you want them to be controllable at least.

OTOH, if you think hallucinations are an unavoidable consequence of LLMs, then you are probably just factually wrong. And if you somehow _were_ proven to be correct that would still not make them a feature. It would just prove that the current architectures are insufficient.",r/machinelearning,Z0FBQUFBQm0yeGJlMVZZanFfcVNzSUxEUXhDaWVQV3FCekViOGpDLXlLbFFHV2NsdGJyaWQ0ak1BZENiUnFhV3JNSEwwckhvcThmRUkzU01uQ2FhNzlIaVlWSXRsRXozbkE9PQ==
"I do think the newer models being able to sustain more context gives a more impressive simulation of understanding, and I'm not even arguing its impossible to build a model that can analyze data for accuracy! I just don't see the connection from here to there, and I feel that can't be skipped.",r/machinelearning,Z0FBQUFBQm0yeGJlbFZweXZPc3hLUl9pS2NJVjhzRHhXVEV4ZHlTU0RtYklqZHd1MXNhbXBEWnhXYW52OFpzOUE5TmNPd2hjVjBIc1pTU0g2NWZBenZ4TzNDV1g4NTk4WWc9PQ==
"Some of the outputs may look similar, but it is vital to understand that the LLM does not have the same _motives_ as a human. Nor the same processing. Nor the same inputs!

LLMs only are considered AI because they _look_ to us like they are intelligent. If anything they are  step backwards from the approaches of the last 20 years of simulating intelligence. And I mean that in that it doesn't build context from the ground up, try to simulate reasoning in another layer, and then process something in NLP on the way out. I was working on these systems in the 90s in my thesis and early work.

They might be a lick of paint that looks like sort of human conversational or generative intelligence. Or they might be something deeper. We don't even know yet, we're still working out the models, trying to look inside the black box of how it builds its own context, relationships representations and so forth. We just don't know!",r/machinelearning,Z0FBQUFBQm0yeGJlM0t6SVVoeWtUZUZlci1jYS1FOUFFcFhGWlQwWW5lcjM3bHVYT0xRRzRCOWRJYjM1NVJkOWo4T1JHQ240WmU0Wk1ZcG5acHNBcy02MG82U2RhcXY1b3c9PQ==
Maybe.  But if you compare a gnat or an amoeba and a dog or human the fundamentals are all there.  Scale.  So.  We shall see but my instinct is these things represent learning.,r/machinelearning,Z0FBQUFBQm0yeGJleWhrQS11UjZKdldQVTZBVlhVVW5fRTFFZ2dpRmh3SkhIb1llVEdlbDVBbWs4TGlIdE4xZEtLRzhwUXlzVE9uSzIwS0J4bkwySDV2d1ExakQtLUIxalE9PQ==
"That implies hallucinations can be fixed by not introducing the randomness, which isn't correct. Models still hallucinate. ",r/machinelearning,Z0FBQUFBQm0yeGJlM2ZULUp5Z2M3VnJ3U0l4bWtmM05pcTJLMTJiX200UjByQjJ0R3czb2U4QVBIS2FyV0ZFOFRUVFpPOFZKeHozdzhraW5nak04THpTLUlpdzJKN1RsS2JBTlh4ZndSVm9GaXRtcUVPZmFwRHM9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlVmo0V2RvOHhCVGI4N0oyd2R1T0swaHZlY0lRTTVBeHdBWk1tN1pPZ1dGN29YQzhUV3c0M3VSaHR4VzVjMTM3X3FDcDd5NGNFcWRJbWliOU5yVkxmUVNaUWJCSnBZd1BweGVDQzNQejRXajA9
"Original post updated w/ changes from this thread implemented! Codebase also linked! Sorry for the delay, between work and the holiday weekend I was swamped!",r/machinelearning,Z0FBQUFBQm0yeGJldkx2SG1DRnBZbjRJT3hEd1RmOFhiUlFhNEthSW95bHlNSTJEOXdHVXNYcnltdmVWamVhWWN5d3lEWUtYOVk3OHZrRVdaS00yRnQwOHVUeVJJc1FNNzgwNDFfQmpiTDRNMVVybGt0MUhjTjQ9
I updated the original post! Most recent runs were done w/ the modified transformation and the GitHub link has been added! Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJlekZ3aEhleHFJUEtqNVpMakJXbnlIeExWTkRuOUJCMDdpYzV3M2pKSG9BMm9aTU01UkhrcGs1TVk0SGMwZE4tMHVfOHhfdXpIUE9FUWRLajhDa25SUmNoOXV5N0NWVXBfTkd4d3JLOXB3SEE9
"This doesn't make much sense to me. Clearly, hallucinations are a bug. They are unintended outputs.

LLMs are attempting to predict the most probable next token, and a hallucination occurs when it incorrectly assigns high probability to a sequence of tokens that should have been very low probability

In other words, hallucinations occur due to **incorrect** predictions that have a high error relative to the target distribution.

That is the opposite of a feature for predictive ML models. The purpose of predictive ML models is to reduce their erroneous predictions, and so calling those high-error predictions a 'feature' doesn't make much sense.",r/machinelearning,Z0FBQUFBQm0yeGJlR1d0TlVfcEhyWUkyNXF1WnF3YnBPc0ZlMDRRSXdydGFDYnRJeGphbG9XSlJPeF9zTnZpaXV5SGdDVmZCc0EwekdIOEdFS0hRU1RELU5nX0FUamlFNFE9PQ==
"A decoder-only LLM does two things:

* It refines the understanding of the input token by enriching it with context 
* It predicts the next token

Notice that if an embedding at position n simply contains a prediction of token n+1, it is obviously better to attend to the token n+1 directly. There's no point in looking at the n'th prediction of the n+1'th token. That prediction doesn't know how the sampler ended up choosing, so it has strictly less info.

So it makes sense to try to separate out these two calculations and spend more time attending the first one. I believe the idea is that instead of mixing the two together as in decoder-only, a decoder-decoder may manage to disentangle the two and put them where they belong",r/machinelearning,Z0FBQUFBQm0yeGJlbU1mOHdIOFBNNDRkMkZjd0diYllZajJwS1BWYVZ2azU3R2MxWUdtUkN4SFNvcS1oQllJbXp6OHJwRS1ZY2JSX2d4ZHAwanRJZ2plc2U1RkxuVHZUY2dwLUV1RVdWVUtxdXc3TGJxSnhzaEk9
"Make sure you are splitting your train and test sets appropriately. It is definitely possible for k=1 to be the best, especially if your classes are well separated.",r/machinelearning,Z0FBQUFBQm0yeGJlenB0SlZyMXdMeEJadUh6cTFxNVBkSVdmSDlOVXE5N05HeHBYNnRIX3c4TXpvOGFQZXptYnRQNEFwQ01Pa0tHUHk5Zk9ZYzZpVE5tclN3aXVYa2VqT0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlUVdHVWlhbXh1V19sOS1vODJrdUc1SWItQUxCeFJuaUozbktveXNfTklISnpIZTkwaGFIdFhaYzFPMnVlZ0tDVHBtR196al9Ob2RQOEpkSlo0YXNrREE9PQ==
"I think calling hallucinations, what they are, errors, woupd be the first start to getting serious. Hallucinations is a marketing term to anthropomorphize (basically) a statistical model. Wheb weather models give incorrect weather predictions, we call that an wrror, not a hallucination. Avoifing marketing should be the first step. It'd be easier to get the public ro understand the problem too. ""Be careful, this AI can be incorrect"" vs ""Be careful, this AI hallucinates."" Ask grandma what the differenxe is. She won't understand why the computer is on drugs, but will understand that things make errors. 

/rant

Getting to your question, with the realizations that hallucinations are errors, understanding of the dangers and safety concerns can be evaluated.",r/machinelearning,Z0FBQUFBQm0yeGJlRi1jUjQyTXpRYTV2S2xPUVNiREJhMl9ZVW4wYllwNEpSYll4SVdpWkZRNnpGUE40ZFhCWGNMaGY5ZTdTaENGRl9EdU95NEI3c1lWV3NGU2xvVzFsUWc9PQ==
"This reminds me of those systems that combine proof assistants with large language models in order to generate theorems.

A distinctive element of a large language model is that it is ""creative"", which if you are able to accompany it with other measures that restrict it to verifiable data, may produce outcomes that you otherwise wouldn't be able to access; we don't want it only to reproduce existing statements made by humans but statements consistent with our language but not previously said, you just need something else to catch references to reality and check them.",r/machinelearning,Z0FBQUFBQm0yeGJlWV9NcG14Si1UQ2lIbFlETVJHVzI4T2FiTkhmV0xUZUxvdlo0S2FIR0ZZaG1iM1UxVUZrVUw5Tkt2TGtWem96OGtxQ0xSby1Pd3NIUWx0RS12VjJ2dUlDZV9EVU9Rc1VFdWdjX1RGcDA0U3c9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlX1BWYVBJNmswVkdRVEk1OXdDdmIxWGV4STU0SllneE9OUXZvUmduVVFGdlNnZDU0U0NLVTdMVmcwdVF6MGZMYnZGTjA3dFE0blFGWHVfVEhsMlpJSGc9PQ==
"I’ve noticed people use 'hallucination' in two ways when talking about LLMs. One definition describes how the model creates information that isn’t based on reality or just makes things up. The other definition is what‘s used here that refers to the basic process of generating any response by the model.   
It seems like whenever 'hallucination' is mentioned, the top comment often ends up arguing about these semantics.",r/machinelearning,Z0FBQUFBQm0yeGJlUDFSSUFvRklOdmlrNmtxcmRwOHFFaTVkNHFVdmt1Z040TWppVDk0Mm5KV2MzcHVjUTljMjU1OVNZLUc3c2QwRXNPVzBnbk53b1Brcm5BT2JJb0ZxQnc9PQ==
"Wow, that's really interesting. I recorded an interview with Shelia Guberman - a former Soviet Union (from Ukraine) scientist in the field of AI. Shelia was the person who took the place of suddenly died Mikhail Tsetlin at university back then. Shelia was the author of the handwriting recognition technology implemented in the commercial product by the company ""Paragraph International"" founded by S. Pachikov, and used then by Microsoft. He didn't use any neural networks as you might guess and he told me that their small scientific community headed by I. M. Gelfand (one of the greatest mathematicians in the 20th century) tried to work on something he calls now ""AI with Human Face"". Shelia is 94 years old now and he told me that he is interested in your work and he knew Tsetlin personally of course. Maybe you'd be interested to connect with him... who knows.

Anyway, I want to dig deeper into Tsetlin-machines and then record an interview with you if it is possible. BTW, I'm the Russian video blogger in the field of IT and programming and a former programmer myself. I would be really appreciated to record an interview with you online.",r/machinelearning,Z0FBQUFBQm0yeGJlZGg5Ui00dUNpSGFWOHJTU3hPMlQySDlLNWZYUHdwMWQyUWFoeFVMaFdTd3VXcGlNQ3pOWmF0dkRrbFF0bmJRNXQ2akl2OUhwemlEWWo4UU9OeTNDYlE9PQ==
"At first glance, this looks like the definition of a really terrible talk. Reading pages of text, directly off the slides, followed by incomprehensible diagrams with no explanation or context. Whenever category theory makes an appearance, I get very wary. It seems like a very complex way to ""unify"" everything by making even really simple things impossibly complex, and then it never seems to lead to any actual new, useful results.   
I don't know what's gotten into me, I don't usually do hot takes.",r/machinelearning,Z0FBQUFBQm0yeGJlMnVSNmVIendyYXpmTzVNaWcxUWNKcDU0TU1vTnhfY3F4RnRIcGRKLTl6WlI0NkRJb0pnZXFaOXNXRmlxQ3E5WUFQejNFd2h1cWZqOVhuUWtaQmZNeFE9PQ==
Interesting comparison. But what about other new sota models like TS-Mixer and PatchTST?,r/machinelearning,Z0FBQUFBQm0yeGJlcXh4ekZheUpUbDkzWEpJVHBJYkdhQTBWa0VtNzNXYnpadXp6NFRRbmFrMkJENDNYZTI1S3VQM1dobFlaajhzcG9Cd24yQ1h3bzhYY3U1NWJtbjhGcC04Nk9nQVFlMWtXZkh6V05PblhJbTg9
"All LLMs do is ""hallucinate"", as in the mechanism of text generation is the same regardless of the veracity of the generated text. We determine if we regard an output as a hallucination or not, but the LLMs never have any clue while its generating text. I've been working on countering hallucinations in my job (mostly because that's what customers care about), and the best methods are ultimately improving dataset quality in terms of accurate content if you are finetuning and ensuring that the proper context is provided during RAG situations. In the case of RAG, it boils down to making sure you have good retrieval (which is not easy). Each LLM behaves differently with context too, and the order of the retrieved context. For example, with llama, you likely want your best context to be near the end of the prompt, but with openai it doesn't matter. Post-generation hallucination fixing techniques don't always work well (and can sometimes lead to hallucinations in of themselves).",r/machinelearning,Z0FBQUFBQm0yeGJlVGxad3h2ZEhPZ0JUOUtTeHhhb0oxeDNsM1REaEpIUFE1czR0aldFNjVFM3lzX2dLNUYwQ09fSkZxRzlOOGsycmczQWdYMklVVzd3ZFZ5LVZzQ0dsOVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlZ0dibE9jTkI0NFRZT0xicUt1QWVmTUVKcW1jZ0FyVUtLOVAyM3A3V0tLTncybnZMbURqaVZ6UTREMG9wclN5LW1JQmhxNDVvYWUwS2hMZnE4cWpFOHc9PQ==
need a chatbot arena dedicated for benchmarking such 'errors'/hallucinations,r/machinelearning,Z0FBQUFBQm0yeGJlaV9zdnNtdDdXdEgtd0tOS1lWNGFwbGJOUUQtZXB2cXNaSU5hVVBqSU10U09wZEVoM3d4alNpdnFvWW1UakZVRkJfOEExYXQ1SmV1NC1lcUtPT0djUnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlV1Y5YVhRaHBJd0p5UHBVMWxVTVJJLXZoWl9SZmFnbVF4VkxaenRiN3d4YWNHSlVHbWM3MHhPc3BkbEpVenl0YzhKQzBycDRSZk5qZGhTZ0dtRW1nZFE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlMGV6TUNEQmgzVHNGaDBnZnoxcmJMaDFHWFFjRWJoNlFPaVpIMVBYT0h5VVpibEU0YjYyQzY2SHRubEo1bFBCUEtJblh4ZDdZX1ZKTEU1SjBSajVBeFJBSVNZVXB0YVlOd1d3VTFwZHM3dHM9
Gumbel soft max is like the reparameterization trick used in diffrentiable sampling of continuous distributions but for discrete distributions.,r/machinelearning,Z0FBQUFBQm0yeGJlS1lwMVRZWWFUVlZ1YlhxZTFTZ0YwRktud1doZEZpd0VfR3QzMjZWYjRfdTVUN3lCNGkxRG1aMjFpMnhzYWEybTJzaHZNUWNGRGNMb2l4SWhWenJ0VWc9PQ==
I think gumbel softmax is more related to argmax than softmax. It’s like an argmax that you can differentiate and anneal a temperature parameter to make it closer to argmax over training steps.,r/machinelearning,Z0FBQUFBQm0yeGJleVBEekQ1ZzBTS2lBbW0tS1dZU1dHSEtGaENOUjcwNFpyWDNjR2gwaGpLTExTSWxqbVJqOF82MTBrZmwyRGVpZ1Vzb2N4N0I1UFlUU3dLdXhib0p2dFE9PQ==
"To my knowledge, gumbel softmax is used if you need to be able to sample from the probability distribution in a differentiable way.

For most application, the classical softmax works just fine.",r/machinelearning,Z0FBQUFBQm0yeGJlRFpOcWI0bHRYRW10TVN6akxTMGZ6NkZSVGlLWDRET21jZllaVmJaRVVhMmRXMEhNQVlVNm92RF9ZT0NqZHBlZ093Sk1XWlJzb2g2OTV2M1ZQX1lvOHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlYWJRR3VNVmJibUNXQWlLNjFocnBMRFpkVzNYVUJFNlRvV0xhWnpRVjIwMDJCNS1ZZkx5SUlQY3poQmF2MW1FNExCLVNfbUxiandmdmNPYklhZ0RqZGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMHJERzNyd2l0LXphakJFNGsxd0ZFWU1DQjJ5ZUdENVZJWmFRUW95QnVjQTBRUl8tb0hnZDlINXZ2bVFtZWJtb3lWbjVReTR6dlQ0NXFhMk9OT2F0ZVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWGdDUjFfNzRaRUtnd2o0VDN1U1VOblVuS3ZVU0V3X3JISGxFS2VHZ21VakJxcW5NOU1HWE5PVEt2azBHS0Y2eFhKb1hTNkxqT1pEQl8tU2w5N2JKVkE9PQ==
"My advice is a bit tangential but: Problem first, solution second.

Don't go into this thinking ""I'm gonna use AI"". Define your problem, look at all the previous work and tools available, and select the best one. I know it's tempting to just do AI to be ""novel"" but if you think about actually adding value you're gonna have a better time down the line. 

That being said, hard to answer without more details about your problem.


> information from the vertical and horizontal directions, obtained separately and with different resolutions

Not sure I understand, are they already both 2d (ie it's  an alignment and fusion problem)? or is it 1d data and you have to generate/extrapolate 2d data?",r/machinelearning,Z0FBQUFBQm0yeGJlOGJVRlkzYjhuSXpGd3o0a3FjZGlzbGVKbkpITkpORUU2Y1dFSnFWVDhXOFpBTUV4cEpNSHVpTTltNThPTXYtc2tBNS1PWXkweEhybXlBLUVZMDgwWHc9PQ==
You can implement a custom loss yourself pretty easily.,r/machinelearning,Z0FBQUFBQm0yeGJldjFRYjhybkZsYTJFRGR5U2FoVk42TU0yWWw0RTZEdDlTNjVIYWxzZFhVVE9NZzhlSG40NjJBc1hjNWZVbzRpQ0xEOEZWeFpQcV9OR18tejJydU1TSUE9PQ==
"The question is how much computation you need per layer to update KV – this affects how much computation you save compared to self-attention. Each layer is doing a sum product followed by convolution in YOCO, compared to a sliding attention and large self-attention kernel in a self-attention layer. I am pretty sure the authors did not disclose the savings (choosing an L, batch size, etc).",r/machinelearning,Z0FBQUFBQm0yeGJlWjExYjczZm45Rzd1RXFPdnRfdWdIc0tpWDlxTFdkZGIzMGp3aTVJRnk3ZmpKVWwxdG5IU0JjVEhrdWpNbmJWcXJPUDRZaTluLVVldV9ab1hjQUdjVmE1V0NYQVdndkluTEY0OHJqUlRNNzg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlSTNTU1h0aXNZSlJUQW51UVJ5d3MwS3gxOFFoU0o0VnJjWjZaRW5iX3hxNXRuQkpMN2prYmJfbUdYRmFJTFpyMVE4MFNheG5iZEZaVVQ5UGVaWFRDMXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJleHUzVG5qTGFxWmY5SkUzSElmZXpIT0FiYTBNRzhNVjdWdXBuUzFodGZOcEVpZWlmdEJOb3VweHE0T1F2RGtmZVI3aEdyOHoyRlBhWi1ucExPX0dScXc9PQ==
Not really. It is demonstrably the case that one can reduce hallucinations in LLMs and there is no evidence that doing so reduces the utility of the LLM.,r/machinelearning,Z0FBQUFBQm0yeGJlWE1GeXdELUZvTVJ6QkJ0Mk9IYWtsRjJRbl9XS1A1Rk9aUExwS3o1LXhmR0tFX3JyV2RUbTRSSXJCcG5STnFwM0JuQ2Z5dTVrLTRwS20xQVhQMnh0Uk91eHh1M2FWUzd2Q21RTmVuY2xwV289
">the results were extremely bad.

How did you evaluate it without data?",r/machinelearning,Z0FBQUFBQm0yeGJlaWtlaVRuNlBUWWdkZ291RlROelU5amxLWnVIdXlkbnhCcDNyb3djU1d4d1lDVUxtU2Y4c09GR21ObHJkbExJVnRQeWlhRXVVOE0ybnlPTWdLWjFmeXc9PQ==
"The fact that it's mind blowing it works is what scares me. There's so much ""yea it's a black box, but what if it were bigger?"" Right now and I don't find that to be useful.",r/machinelearning,Z0FBQUFBQm0yeGJlX0R3bnRTNnlpVFV5ZTkwR1FsdHJBVGZfTlJuem1wRmRETHhiYl9KOTM1MHNxUXVMVERCT3lBc1NPblpZd3pRQ2Q0WHN2RzdldUo0WVdIVmlFMVhibnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlTV96YzdkcFQ3SElXZVU0WkhNNEQzYXNtT1QwenEyY0c3TWI5WXBmWkR0WkJFMDhEZE84VmhaQ1FCd25PWGxfODRSdWE0OUZHd0dSVC1Qa2xJQ0JDU0E9PQ==
"Check this out: [https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize](https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize)

Lot's of ideas there.",r/machinelearning,Z0FBQUFBQm0yeGJlckNaY2I1cDQtenhjaHhPQ25oWGYta1Z5WXFVZVZrVm9jdGc5S002ZHJsRk9NekdxVExMODIxYWdPNmRZWVM1YWI0eTVKZDVNV1hwdEItSWRqdEtkUVE9PQ==
"How do you ensure that the datasets that you are testing on are not part of the original training data used for these foundation models? It seems highly likely that a large model trained on billions of examples could contain some of these test cases and would put these foundation models on an unfair advantage compared to the prior-free models.

Edit: Some of the models even explicitly use the testing examples you provide for training (for example Wikipedia page views is a common one). This seems like its measuring over fitting more than anything else. Why not create some artificial time series based on dynamical systems which could not possible have existed before?",r/machinelearning,Z0FBQUFBQm0yeGJlY2lSWkhoak5NaC12UV9OVnM1bElJeUJsN2hJbWJLa2kxLTB4aHR3OVNMWjlCTlZwWHNJOW1WY3JvNzZoelREVGk4TnY1dUc3OGFzT2pLOHo2bm9UNnh4bDduUGdveXlBQXQ1SGh2TWZQNDQ9
"TBH, that is what OpenAI has been doing since inception;
take research and scale it up.

I also agree that the ""just make it bigger"" is a bit of a lazy trend that has been going on for some time, and it prices out non-profit research centers out of the research.",r/machinelearning,Z0FBQUFBQm0yeGJlMnFsUk1OWUlKdkVIMG5rYmpldTlDS20yaWF2MXVLQkRRYmlHOXZGdTBCUzhMdEtLeEZfOWtyQWMyUDItLVlqeVpVbFRSVTZfRlRocG1JaFNKMFVmTVE9PQ==
Softmax is also differentiable and you can use temperature. Gumbel-Softmax is used if you want to \\_sample\\_ from the softmax probability distribution in a differentiable manner.,r/machinelearning,Z0FBQUFBQm0yeGJlODRRMEZoZU85UTYyalc5UkRxRkdYY2JwczNXMHRvXzdrQjE2NTFxRkw1TjNUNG5pVXJVNHZmU0lXUHBselZkQTFmcWxUWXdGYTgwa290alIyUk5ReGc9PQ==
"You're assuming that true statements should consist of a sequence of tokens with high probability. That's an incorrect assumption in general. If that were the case, we'd be able to develop a (philosophically impossible) perfect oracle.
 
Determining what's true is a non-trivial problem, even for humans. In fact in the general case, it's intractable. It would be very strange if LLMs didn't ever ""hallucinate"".",r/machinelearning,Z0FBQUFBQm0yeGJlX09YWDYzVDk4SHVpWTZqMlJMbDZvZDdlMmU4UXFfckVoT2hnSy1ESHJWQzBqOTBaTXdNRzh6dlV3aElwU3dUN3FzbS1selNod1NLTkdoWnVnQ2gwWXc9PQ==
"Cristian from Nixtla here. Thanks for sharing your concern! We discuss this in the repository with the reproducible experiments: https://github.com/Nixtla/nixtla/tree/main/experiments/foundation-time-series-arena.

Based on the description of the training data from the papers, this is primarily an issue only for TimesFM. For TimeGPT in particular, none of the series were observed by the model during training, so the current results benefit other foundation models.

Note also that this is the first iteration of the experiment; we plan to increase the number of series and models in the future. The main reason for using real data is to evaluate the models on real-world applications. Synthetic data requires making many assumptions, which might not represent real-world data.",r/machinelearning,Z0FBQUFBQm0yeGJleVNHMnRmTkxTMUZod3daQ3lIMU5DV0FkaG5Nandpemw0aHZHTkl6OFByYnRyMkIwOUdJa1F5cFlTUXRzT1NmNTgwSVB5V2dDNzdjN0szbXB6eEdPYlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlZDJ2X2wyWFB5enh3VmJfUTh5NEV6cUhRZTkxSUhCTXpVMk5maFpVekVfWC1WcXBBaE5PN3NGWFVWZXhzb1VndXphT190OU9ZVTN5RVVyZGtnNFJrb0E9PQ==
">I'm just saying the same flexibility with language that allows it to communicate like a person at all can only be built on a framework where hallucination will always be part of it, no matter how much resources you devote towards reducing it. You can only reduce it.

That's true of humans too, or really any statistical process. It's true of airplane crashes. I'm not sure what's ""interesting"" about the observation that LLMs will never be perfect, just as computers will never be perfect, humans will never be perfect, Google Search will never be perfect, ...",r/machinelearning,Z0FBQUFBQm0yeGJlZHBiUEdiOV9kWEVrazl0Z2ljRUV2dHdNdVBub0puM2ViZmw4ejBOWmM5a1ltd2lZS3FpQXBWSDh4RWFCcXZyYXBWRUw5c2hXdUJ5RnJOS1ZWc19TMlE5ZjZjQmU5TkhhdkxYRWJjYWNBQVk9
"Nobody can define ""knowledge"" and it certainly has no relevance in a discussion of engineering systems. Human beings do not have ""reliable knowledge"" beyond ""I think, therefore, I am.""

Human beings are demonstrably able to make useful inferences in the world despite having unreliable knowledge, and if LLMs can do the same then they will be useful.",r/machinelearning,Z0FBQUFBQm0yeGJldU5fZC1JNGdtNmJqWThUZ0hyck53SUF3VURaTTBvRWdqS19uOTFFLWJ6ZVNha3h1a2pkY2xsYTZVZDIxeHFaY1VCSXMzV0FfT0FmNXJZSUVrQjFyWmV0RXJRcml6aDlWaHJta01iRG1MOE09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlSHRIQllkSldyWXVMSXVKa2F5ZklRN0l0cUhwT2RDbEdybE5iY3FObjd0SDRTdVFSc1BTNkFEU2cwU2RodHFmNFhiUFpqS28wUkJQcDlHS19rYV9LMXc9PQ==
"That's a really excellent point I never thought about, it makes research on smaller models inherently less impressive and likely to get funding.",r/machinelearning,Z0FBQUFBQm0yeGJlcE9fcVFHTDlyMEtWSXZOa1lYcW80bGRBTWYtZEczY0ZOZjhRTV9QeVQydXZLdDlrQm5hLUtlaVg4U0RYQjMybHlIbENYd0dyZC0xUi11VlNOaVZkMnc9PQ==
"Category theory is to machine learning as string theory is to physics, change my mind.

Edit: in case it wasn't obvious, string theory is also a much-lauded collection of unnecessarily complicated ideas that is putatively supposed to unify a large field of study but which has actually produced nothing of practical value so far.",r/machinelearning,Z0FBQUFBQm0yeGJlWGgxbmFKSllPVm9STThzTGdRS0EtaXBOZk0tT2w5N0VUcDM4VmI3QUFlbWlObkFnOGJjOVg3dTlhTnZPREFKdXR0Q3ltLTdjV2RkR2NkekNuOFNJUmc9PQ==
"You need a few years 5-10 years exp to easily pickup remote positions in my experience. 


The field will be different by time you graduate, I would focus on robotic applications ",r/machinelearning,Z0FBQUFBQm0yeGJlTks5VkdrVGFWMW4wWG1CWEVHNTRtRzNDcGJmR092alJUMm1qTnAzc3pHckdacW50bkg0bmtId2lzeDYxLUxUQUhsaXFJTEhVaXpna0hYNElMMkMyUnZEQXV3OElWQW9ET3RWbXR2VHd6cUE9
"First off, it’s a common misconception that you can just direct research scientists at any problem. People have specializations and grants have specific funding allotments. Whether or not a problem is worth effort depends just as much on the research pool as it does the funding alotters.",r/machinelearning,Z0FBQUFBQm0yeGJlY1lpbFhQRGpjWExuNU5ma2NLaHpLVlV6amh0OW9XRkhyXzVFZ2U1dzNsdEVxbXVKTDFNTHducDhNNGxHLUg0c1ZGcW5tRVFOdmNaQy1MZWI1Wm9wWUE9PQ==
"More than ever, depends on the training set. And who will be deciding the minimum quality requirements for the training set? What inferential value can have a result that I have to judge post hoc and tune a model to have a results it fits with reliable knowledge? Humans do not put the words in chains when they evaluate a process. It's not impossible to obtain that in silico imho but you cannot to that tuning LLMs. They were born hammers, you can't make them spanners.",r/machinelearning,Z0FBQUFBQm0yeGJlZ19VSWE4NWNzdWVaS0k5OUdFRllZeHplMzF4NWljYlJwWUtxd3lNRFhhYW5QcGNLN3padFQweU9kX0dCcDJXZ3JiM245TElZNGlWUUxDaWRqVnRrSnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlY01TcGZMNDIxVktJcG5sbzc3SlE0T2VWb1ZHZ3JPcFlpT2Fsa0lVQVhlbTFtamljN29kdVRVb2N1ZVlqclVrMGNiTWNNdU5qQ1pKeUphbVcwVG55SGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWUk5b1pmNEV6YmwzMTlkSzluTjBRamNHRnExQndmaWY2SjVRU2psTkxUQjZ1S3pUX3ZydEo2djRfX3pOZzRIWktHNmVSZ085R3MwbU9nUTlkeXpzRWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlaWliNTVPNFU5SngzNWdQMmgzQzVmMmtQS3ZudlFhbEtGcVpZRXQ3b0xnVnJwc01feHo4NUZGdlVtczhBMWxpeWZTR0ZOTWkwWTBxMzZNS190ODg3akE9PQ==
"These are the same thing

Safety research is alignment and explainability research 

Alignment is capabilities research; and consequently how stronger models are produced

Explainability research is functionally a study of practical control mechanisms, utilitarian applications, reliable behaviors, and focuses on the development of more easily understood and more easily corrected models",r/machinelearning,Z0FBQUFBQm0yeGJlODlZb09ISlZnLWM3M1ZTQkNmX0VYY3dYSGZiMnkyV0lfdEY2ajhuZTFNbURTQWpETHduYVB1d01NcUY5MWk5WXRub0FucnhzTmItZ1lyQVIxUGdOVy1PdHJKNUZPRS14d3RRY3B3WVpxTHc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMzM4YmNoTzJjR0ZYX2tNM2hzUWVPb2ZFOVg0eFVoMl8ta25GaUlmMUhNR1FEcVkzd2ktNWZvUlByNTExRkE0YVdZQnZWa0wtU1V3S0VKY1QyUm9hclE9PQ==
"Yup it's done by converting things into log-likelihood before converting them back which gives a curve that's more friendly to differentials.

Using the gumbel's trick which is the basis of the softmax is also a way if you have a log-probability generating network you can create a sample from the output map.  It's useful sometimes because log-space can be much easier to work with.  Especially with ML models since it's easier to get them to learn how to predict log-probabilities instead of continuous space ones.",r/machinelearning,Z0FBQUFBQm0yeGJlbHBjYmJIRTRkT3hwSEpvSjFSb1lfNkNwY2MtVkZYVTd6Z2xPUUU2cVNwdmQ0STF6VDhTWHZpaGo5eWNuUV9WU3NKbEZuSTJpYjk5OXE5NFNyZ3J4c1E9PQ==
"AFAIK those aren't foundation models, which the benchmark focuses on. I.e. you'd need to train them before generating forecasts.",r/machinelearning,Z0FBQUFBQm0yeGJlOFBqbEFpaVBZVjAtaHY3Tl9WTjROZ00xQ0FjSHgxTTh3SXJGZDB2VG5HamhMeGpNcFVqUUprWWhKVkRCYlFmT0IyVFRlR1NnaE4tN3NWSVQ2NWQteWc9PQ==
"If you're using latent diffusion then can treat the autoencoder as a noisy channel and calculate rate/distortion as per usual. To calculate the coding rate you need the distribution of the data, and you can get that by calculating the determinant of the jacobian of the process that goes input -> latent encoding -> diffusion noise distribution (i.e. run the diffusion process to get the noise sample from the latent data sample). The probability density of the sample can be calculated using the jacobian determinant and the probability density of the noise sample that you calculated.",r/machinelearning,Z0FBQUFBQm0yeGJldGZicGxYdXpYVjRaVXNGd3RGWnd5U2M5VUpkV3BBSnZFbGE2bE52dW5oYzNDdVhjMlJZZ25ocjR1dTRSLTdDSHp3ZUR5VTkzNTJSUXZ3VGFlWjFjRVE9PQ==
"Outside of transformers…

The first paper to go into bounding boxes was an incredibly creative solution. Also the lstm paper was a stroke of genius.",r/machinelearning,Z0FBQUFBQm0yeGJlT0R3bWI2RDdRSDJlTFV2T01YOFR1czFwQ1p1TFRkQ25zS3pseGRmWVByb1VvZ1NFOVcza0VxTDMwTGZYREdMMWs5MUFQQ2hoQXNlc0hGMkR0YXpqaXRVVjdFUXN6YTFQVm5XY3haaHNUT2s9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlOFEtd1I5dXg1Uy1kbVliVWR0MzFWOURkaHQxRGxKZXQzSlQyRHZzYW5CWnUzYTBNWjRTTDBwcGxNTEhLMTJYYjRWNng1TE5GSC1KNjNlOFNGMGdUVFFwMldFYzduNV9oa1hiTjhjU1ltTDA9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlcVh2cWR3akdfcWlxMWNEakFVS2xDa0pTU0hWVXFRSy1OakVxUC1DcWtnRjlKaUZHeDQxVUlIQ0lpeEptLVpOMDI2Z1pUSW9HTGlwclZQSW5xTFdjRlZaWk9PM0hEM1RFRFRnREZxNlA0VGs9
Both are actively studied. Both are not mutually exclusive. Both are equally important.,r/machinelearning,Z0FBQUFBQm0yeGJlMDV6N3R6X0pQWVo5OGJOVDhic0hQaWc4WHFqMkZZemo0Yk5tc2dxU2hTdkw3ZGJCN1k1YTN1Y2hiTGg5bFVLZVA4bDNDQnVzdWNPM2pvQTJ3LUF3YVE9PQ==
"Kind of a mix between paper and a book, but ""The Principles of Deep Learning Theory"" by Dan Roberts and Sho Yaida",r/machinelearning,Z0FBQUFBQm0yeGJlYWRGQnF2NmVNdlp1ZUQ2RFdGNjB1RGdqTUJwYS1EOHNhbE9UeTd3SnFPNVBWWjM2bG5YQzc5QmtyMldUeFVWOEZIYktpa2lDUnktQnd3VWRrV3A3aHc9PQ==
"This looks like making things complex just for the shake of it, but it sounds rather interesting so I hope someone can try to answer this.",r/machinelearning,Z0FBQUFBQm0yeGJldUxxUmczS2V5QzRrWFhYeElWNGNhSVNhb20xTEExRG9ib09UTWE4MUt6MjM1QXFFUVZmeXFTOGpxdzhnSW9Td1NWT01JaklfaTlZVWZ3dHhwZ3hZYkE9PQ==
https://cloud.google.com/blog/products/data-analytics/bigquery-multimodal-embeddings-generation,r/machinelearning,Z0FBQUFBQm0yeGJldTlDVGxCa0VyWWpZdjRqSGRZLTl0QUlvQjJWc1ZuY0JibXhHWlZRN3NvRzcycE04Rld2dldMN1UzZmhQMXRQQUgtTzhPOWhFVEJhdVBtNURlWXN2Smc9PQ==
"When I first read it, I thought that this paper was soooo cool!  
[\\[1802.01548\\] Regularized Evolution for Image Classifier Architecture Search (arxiv.org)](https://arxiv.org/abs/1802.01548)

Honestly, I still think this is super cool, kinda wasteful but super cool.",r/machinelearning,Z0FBQUFBQm0yeGJlMGxod3lBekRzVFlZU1ZmMTFsYTFJbHNLU0hzZlQyOU8wTzFlX3k1NkpyQm9kZk1yeXlnWjY1QllXc0V6aF9QcUZTRGNJNmRjWlBJbFdfQU5YQW44NEE9PQ==
"My favorites (unfortunately I don't think they're about architectural improvements):

* [Adversarial Reprogramming of Neural Networks](https://arxiv.org/abs/1806.11146)
* [Noise2Noise](https://arxiv.org/abs/1803.04189)
* [Random Network Distillation](https://arxiv.org/abs/1810.12894)

They aren't super influential but they all have some neat insight I find very compelling. Also I notice they're coincidentally all from 2018. I guess that was just the year where my personal tastes were most aligned with the research zeitgeist.",r/machinelearning,Z0FBQUFBQm0yeGJlakg0VTNfZy12MnpVVFU5R2ZQSTBlenJzTTJBU2pYMlZtdW5yRUhCUWZnSEFuZkQ1ck5QM2dDck5sUlI1WWRBR25ZSFduS0NrTEVIa3J4QnJ2WFhWSnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlWnFBU2hoUUJVVGNXUWJKRW5vT28zaTJ6M2tKZm5rR3puVklVak9kV0YwOFl3N01XWGZDdENMZ29IQmpIdVFiQ2IyaUdKWmpLd2hLbFVCTExlSUxjOVE9PQ==
"As a DS, or any senior technical role like an architect, YOU have to explain and make people care about it - see the value. 

 - Don't come to people with problems, come with solutions. You're the expert.
 - Be patient and explain to other stakeholders. Someone on your side is MUCH more valuable to someone who begrudgingly allows you to do something. Explain in ways they understand.
 - Be smart about showing where the value is, _to their point of view_. If something is not what they expect, like requirements or a timeline, you need to illustrate why.

This problem has been around since the first programmer or the first database.

The way you phrase it, it sounds like the manager doesn't know what he wants, you just had a guess or made something up that sucked, and now you're angry (your words) that he doesn't know what kind of data is needed to build a model. Well, you're the data scientist, YOU are meant to work it out, and YOU are meant to communicate it.

Managing upwards is common in technical circles. You need to work on your communication, be patient with non-technical people, and focus on outcomes rather than technical details when talking to them.

Good luck!",r/machinelearning,Z0FBQUFBQm0yeGJlc1I4NGJZYnB2VUFZSGJQdkFWOVZXSlh0cnJ1QUlLeEJGV2NxNmNDeVlFS2wxOWdVbHlWSWpTaDhmZndmUVNGZkMyMUNpOU5wa3lNcFBYWHRrTUVkb1E9PQ==
"This is an odd time for us. While we, in my opinion, are at the edge of a significant shift in the market related to how technology is used, the value and what is possible with LLMs is being overblown. While this isn’t going to implode as a buzzword like blockchain, it will find real footing, and over the next five to ten years, people who do not keep up will be left behind.",r/machinelearning,Z0FBQUFBQm0yeGJlak9IMkxFYkNwSm9oeERaY25xSzFmd3NNTkNxb3dLVVZJZ1RobDgwZU5MaFZQQjQzdDFyVE5zUEdmMkhYVFh5bmk2dUlzWFVCbC1lOUdwYnJpcTB4cFVYa3U1Nk5ZakNPckE3VkZJMzg1b009
">You're assuming that true statements should consist of a sequence of tokens with high probability.

No, I'm not assuming that. I think we might have different definitions of hallucination.

One thing that I think you are ignoring is that LLMs are conditional on the author of the text and the context. So imagine a mathematician writing an explanation of some theorem they are very familiar with for an important lecture. That person is unlikely to ""hallucinate"" and make up random non-sensical things about that theorem.

However, imagine if another person was writing that same explanation, such as a young child. They might make up gibberish about the topic, etc.

In my opinion, a hallucination is when the LLM predict high probability to token sequences that should actually be low probability if it were being authored by the person & context that it's predicting for.

It has nothing to do with truth or right/wrong, it's about the errors of the models predictions. Hallucinations are incorrect because they output things that the specific human wouldn't. LLMs are intended to be conditional on the author and context.",r/machinelearning,Z0FBQUFBQm0yeGJlcFN4WUFXQk04MHFyTkNRVGhyNUs3NlQ5c1pfRVYteTRmVU13Sk5VczNWb0cwVmxib0RBUjNHMXVscXNKQnIwT0NlcEI5dk1pMkF3YVlpMVlWb1dtSHc9PQ==
"There's a good reason for doing this. I think the jargon is ""twin tower"" recommenders, or something like that. The JSON part might be misleading, just think of it as structured data, with different schema, that when input into a f(A, B) -> distance. and so what I want is a  |dot(e'(A), e''(B)) - distance| < epsilon",r/machinelearning,Z0FBQUFBQm0yeGJlYVBpNFB5a2RSQkZvV0Z5NjNRbURZVkZJYjZSYzVPZ1RUVTBKcEo2MWlfb045YUZyNU8tQWRfMV9BNHR6LWstQ3lWem10R29rSldiTG9rR0s3b2tvRnc9PQ==
"Honestly you'll be replaced by someone who develops a plan to bridge the gap, rather than folding your arms like a toddler having a tantrum and refusing to do anything beyond what YOU think your duties are.

Especially in a competitive, new field with poorly defined roles/processes like data science, you need to adapt. If you take this ""I am only this cog in the machine and that's all I do"" attitude you will rarely progress, and find yourself overlooked as a colleague. People want to work with people who try to find a solution together.",r/machinelearning,Z0FBQUFBQm0yeGJlQzVFR2gtdko0WDRaSmh3VVo2Ym8yV1pSa3lUWE8yV0NKLVNDOFQtQzR1YTFHTmhXd0xSeGswRWItOVZ4OERpQjBrWEpJb3NmTnhJSXE4Qkt1aEVDLUE9PQ==
"Yes, truth should have a higher probability and it’s a problem if that’s not the case.",r/machinelearning,Z0FBQUFBQm0yeGJlTXlnVmlhT0xTQU8xbXliOFAwM0g0WW9aSkRfbzltSFlINWd1Rl9kekZKMVFuNG16MjY4aGRaZTFGb3Fwckc0a2k5cjAxdzBXNmdlWDU0X3FGbFNWQVE9PQ==
"I know its super recent but ive thoroughly enjoyed the new KAN paper. Super easy to read and understand, and potentially paradigm changing. For a more established method, id have to go with AlphaFold2. totally turned my field of structural biology on its head

  
KAN - [https://arxiv.org/abs/2404.19756](https://arxiv.org/abs/2404.19756)

AF2 - [https://www.nature.com/articles/s41586-021-03819-2](https://www.nature.com/articles/s41586-021-03819-2)",r/machinelearning,Z0FBQUFBQm0yeGJlSVNDbFBWSk1UdDRobW1ibGpCLXpiOWxTLTBtTzlsV2R4NklYemJkTDZLZWtHdHQzbkg4NTM4VVR0REkyR1JKN2tkS2wwaXlxM28yNTdwRmdjS2xVM3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlOExybm1fUUZzME1vOUVBSXRVeUNDQzh0TXVPZVhhRHJhZTZBbFFSMFhDUWNEMEZtVHlMa2JTZ2Z3Y0x2SHlKWG5EQ2IzUXFvQUxIREZ5VFBib2RrRlE9PQ==
"YOLO. It was released as I started working with deep learning, and Redmon is/was a super friendly guy that answered all your questions on his Google group. Great experience, even if it wasn't the most groundbreaking paper, everything around it really etched it into my brain.",r/machinelearning,Z0FBQUFBQm0yeGJlLUJ4STItcm5NUVlUcWVVV2dkNTZORzNCUzZ6WklMZ3JzVjFvQXl1RWVfN2hrdTI4czRLSktNcjhXdElUblEtYWNZekwwMXNtWUJIamU0WXk0MmpjY0E9PQ==
[ilya's phd thesis](https://tspace.library.utoronto.ca/bitstream/1807/36012/6/Ilya_Sutskever_201306_PhD_thesis.pdf),r/machinelearning,Z0FBQUFBQm0yeGJlWmFOV2gwMU5lSGttTzZMNHh2ZzR6TzdTSDMyQXRZMUlxYVpJQWxUaUJTS0VfY3RXc2RJSFo1Vl9nX01HRWhhM2pDR2tvS1JqbEctLXM2dEJ3ZXp6YlZsRUx4OGhMcS1jSEktTzBGeHJqZ3M9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlOE5MTWFxeHEwWGxwTHIyRUxrd0Vfd25ta3RraFc3RmNJdGZ3Rzd5OHc1Y19tbzZ3SFdCVkpUS1VQbmhtczFvRWk1eGpPcEVkcXctVi0zcmx1VnlVblE9PQ==
"Yes and no. When an LLM invents a new reference that doesn't exist, then this shouldn't be the most likely tokens. The reason for hallucination is the lack of proper information / knowledge which could be due to a lack of understanding or simply because the necessary information wasn't even in the dataset. Therfore, hallucination could be fixed by having better datasets or by learning to say ""I don't know"" more reliably. The latter shouls be totally possible as the model knows the confidences of the next tokens.
I don't where the impression comes from that this was an unsolvable problem.",r/machinelearning,Z0FBQUFBQm0yeGJlRDdVbF84QV9IdnJXcUhhd0F4RFoyalh5LUxxaEtWYlp0UGJXWkZUNW5tOWZBUHRQVW51WmhGWFFTcDBFWU5fTjVMcTd3RGxwbWdWMVg3aFc1b2s4dEE9PQ==
"There's still a potential overfit / look-ahead bias because of correlations between time-series. This problem affects any pretrained model on real-world time-series data. If the models were trained on IID time-series data (can guarantee with simulated data), there would be no cross-sectional correlations and thus no issue.",r/machinelearning,Z0FBQUFBQm0yeGJlS0hoaFNVaEptcHFhYXBkSUt4SGx6M1F5T2dVNFdCenhsMUwzM0FIa1NTaU9uNFA2ZUd6alFhM1NCVU1ZWmRBSVVYRkItby1fWHJHLVBxZ3dEREZuY1E9PQ==
The VQVAE paper.,r/machinelearning,Z0FBQUFBQm0yeGJlLVdMVnFGNXcxcUk3Yl85MlBxZkJEVnk2anpVQUVHZnFXel9venhFcUdhbEVYZUZwZHBXdVh4azJqc2l1WlJGV3FZN0x6MFN0czc5VTRGdW9icjJEbnc9PQ==
Hi thanks for the reply. No I want to know for the standard DDPM model. If I want to calculate the rate that is sum of all the KL divergence terms how would I do so ?,r/machinelearning,Z0FBQUFBQm0yeGJlLWl4dHQ2Q24tOGV0eC1nTC04XzNhQV9Tc3pHZVlFb1paVGl2ZVY0RVdLZlhYZV9fYmRoNmxPdzV2ejVGN1ZVellmVlRtS3BLaVFaYWFYeHIyQUQtUEE9PQ==
">You generally shouldn't cite refences in an abstract

You can? It's not a common practice in machine learning, but there is no rule that you can't either.",r/machinelearning,Z0FBQUFBQm0yeGJlX29KNFYxU1IxWlhYbFdGLWpCS3lkNjh1RUR4eUZEZ2lveTJNOFRaMnNOYVdDSFdHa1NuMGxsb09CODdxUHJaWktWTWVoTFZHQlo0c25RTzQ3WWVNenc9PQ==
That’s complete nonsense. Hallucination is a byproduct of the failure of the neural network to capture the real-world distribution of sequences.,r/machinelearning,Z0FBQUFBQm0yeGJlSFFxZDNUUDhxWXdmYjducE5CS1VQcWRCSEdRTGJDaENJYWZLSmRlZ25UeDJSelJMc0lyRmtxaXF0VnFxOXpuSU5SSmtiVDdFeC03cmFDZTd6QXI1ZHc9PQ==
The reason is probably that safety is much easier a problem to study than hallucination.,r/machinelearning,Z0FBQUFBQm0yeGJlY244bmw1LUQxeEt6ejVSVTM4UU1qWXRMZVIyMWZYcFpUX2JOcHJtbDhWb0F0S3AwcGpXcDZQM01XbzlnMEFmZDlVZWxsbUZSVlNoRTNzLTdGS0tNdHc9PQ==
"Oh, well the [original DDPM paper](https://arxiv.org/abs/2006.11239
) is explicit about this, see section 4.3. The distortion is calculated as the RMSE, and the rate is calculated using equation 5 in that paper.",r/machinelearning,Z0FBQUFBQm0yeGJlaExiRExFdUhldnppem9UR3Ywa0ppVkplMFk4bXBnT3NkbWtheHBxYXdGNDQ1RnFrcW1VSnZLMXB3WnhsM3hpM1pQdUMwZ1BVLXpzUjBEMWFqUTdTTVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJldUpfVV81NGR3LS1RTDBMRnFTbVpUZjhveWN3NDZzaWN5NERJSGpHbkYtQVpOME1GLUtlZ3E4U01sbzFDRWNnbEQ0UnVWMXRaVXc4Ri1zSmZ5c3lXTFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlVE9Uc2IxRmppQ0dMZFRXWTFJUXhqeWxtOEZ4U0gzVzdMeG5PQ3dVdEpjcnlFOUdGVUlZSDkwNTZRVVJIS01fcmhkaXAzRmxibmVkbjVlWExZV1dMY0E9PQ==
">More than ever, depends on the training set.

  
Okay...sure.

> And who will be deciding the minimum quality requirements for the training set? 

The engineers who trained the model! And you will validate their choices by testing the produced artifact, as you would with any engineered object. 

>What inferential value can have a result that I have to judge post hoc and tune a model to have a results it fits with reliable knowledge? 

You can ask the same question of working with humans. If I hire consultants from KPMG or lawyers from BigLawCo to sift through thousands of documents and give me an answer, they may still give me the wrong answer. Are you going to say that humans are useless because they don't 100% give the right answer?

>Humans do not put the words in chains when they evaluate a process. 

Focusing on the mechanism is a total red herring. What matters is the measured efficacy/accuracy of the result. I can point to tons of humans who I trust, and humans who I do not trust, and as far as I know they use *roughly* the same mental processes. The processes are mostly irrelevant.

This is *especially* true when we are talking about either humans or ANNs because we cannot possibly understand the mechanisms going on in these big models.

>It's not impossible to obtain that in silico imho but you cannot to that tuning LLMs. They were born hammers, you can't make them spanners.

They were born word predictors and we have discovered post-hoc that they are pretty good at summarization, fact recollection, translation, code generation, chess playing, companionship, ...

They were never either hammers or spanners. They were an experiment which outperformed everybody's expectations.",r/machinelearning,Z0FBQUFBQm0yeGJlZ1JDV1k2WWM4cGtCZ1pCMDhwSVlPNl9kWEUyblR3aElDM1FtblFpaFpYN1ZkR0x0SkxyR09JaDBqLWNzRjJSekhWVEU4d2p6c3hWdE1HbFZQVndPSDRvWEhBUGV0amFLdU9XSjRuc0hJRDg9
"This is a basic recommendation problem, made complicated because you're probably looking up a bunch of text embedding keywords. Like you mentioned below you could use a two tower approach for this, where each entity type has a NN that takes in features and produces an embedding. The user tower would take in a bag of books and any other user features and produce a user embedding. The movie tower would take in any movie features you might have, or could just be a lookup of a movie embedding (in which case it's equivalent to a standard multi label or multi class MLP). You train it by predicting your labelled ""liked"" movies - by taking the dot product between the two embeddings and then either sigmoid or softmax - with unliked (potentially sampled) movies as negatives.",r/machinelearning,Z0FBQUFBQm0yeGJleWpGV2xvYXJOd0p0WkYyaExnVUx1QjlnYWFBOHlCVmt4T2thX2JXU2VYYVlDd092cHpwTHI0Umd5UlphY0Q2UUExLUVxN0NDM1FzdGJZTVlRZzhWUDQ4Xzg0czZTZlBDN2NaYkYyVDYxUGs9
"Genuine question as this is a knowledge gap on my end: what’s the difference between the two? Surely there is overlap, especially as we increase temperature, we eventually guarantee hallucination",r/machinelearning,Z0FBQUFBQm0yeGJlSXhGNy1aZlhPNnRCNkl3ZFhUZEIxTU0xSm9QQVdvckt4N29ucnFKTFRLb2VvcURMc1djR2JadlhYRDVfTHk2WExPTjVyUkpvT1FoV1g3SkxGVVItOFE9PQ==
"This is a very complex question, perhaps someone can give a more expansive answer than I can :)

Hallucination can make something new or unexpected, sure. It may even seem insightful by coincidence. But it has no direction, it is the LLM flailing around to respond because it HAS to respond.

Being creative and inventive is directional, purposeful. It is also, in most cases, logical and progressive and adds something new to what already exists.",r/machinelearning,Z0FBQUFBQm0yeGJlajhhQ1VZMnhPZjdsdXpSeURCci1acHZkOHlGY29aOHV5U0pXRVRXdGpRMDRQTGNxTmZPWHB0dHR2ai1XdU5UQV9qcGJRcThjOF9EaU9WQWpRUzVVeFE9PQ==
"Here's one thought: What's the most interesting homework question you did or paper you read? What did you like about it or find strange/unintuitive about it? Use that motivation to try to extend in a direction that matches your interest.   
  
Once you have a rough idea ask a good professor/TA/friend to help narrow the scope to something that's likely achievable in our timeframe and that you can get data for.   
  
Good luck, and if possible please post what you can about your choice and how you found it.",r/machinelearning,Z0FBQUFBQm0yeGJla0xELTl3RmNxZVc0ODJRdDBiTnlETEtYVHNLcXlxeUhBblZPM2g2bnR1ZUpBSW5fWkVmV3F6S3dVVUFJcW12OUJfcEtURFJoaUZMMklLOGNtVlpBaWc9PQ==
"Researchers developed AI capable of interpreting road signs, used also in modern cars. Security researchers have found that putting stickers on speed limits at certain places that covered key points, they could mistake a 3 for an 8 even though the numbers appeared well distinguishable by the human eye. The same happened with image recognition software that could be confused by small shifting of a handful of pixels. But this is not a failure, this is exploiting the twilight area between the cases well covered by a well constructed training set and particular real-world cases engineered to play around there. Now I can probably feed LLMs a huge corpus of factually true information and still get hallucinations. There is the difference. How the method works impact use cases and limitation. And working around this make sense in a way that it improves the threshold to reduce this issue, but it will be not a proper ""knowledge engine"". My idea is that AI companies just want to sell a ""good enough knowledge engine, please note that sometimes can spew nonsense"".",r/machinelearning,Z0FBQUFBQm0yeGJlU0d5MFB0ZmVXbUVHUWFremc0bVNJVXV4RzBFTlNMdklyZ2xoejd5MEhKTWYybDZoRlBQdWkyWkRDeVhlUDhzdWluek55VTFkWEk4RjM0LXVNZmRacnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlcElFV1haeWtiWVI5OElnT0dxQkJGUEY0SC1YdUhnVjkwWFl2Mk9nMnc2T0VwMm1BQlY5MnRiWEpRT3dENlVEZjlOTzdGcVpUNnNSdUQyekcxOE5pMHc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlYkpPRWZ4OE9LX19MM1luY1ZETzBLREVjbFY0bi1wN2NpSFdrd1g2YzBJc0VKekFKdF82bGdQczVoR2o0c1FRcnBKUjFQTnpiYUtjTlBVcEJNdFVNaTh5T1lSRHVXTmRTc3dwclhzYng5a2M9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJlQ2VLWGNQUlFQU3FlTFdrWUdPM0JMZFVpNTFJOWYzODBndlZKNlNoVzNsWVdOOHRSZWZLYVBDTFVfbWpiRmF1cUFJTFU4VWxoWHRCNUZFWnkyTG9EOGlnRUN6ZlRESThheU94OHJTaDJPaUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlMnhpUUVRLTVqQS1KRWI3Q3hyVVlybV9QSW5TSVlsM3g2OXNaWDNlallSeGdmU056Vlk3VlZ5MUJnVC1uYUtzTFc1Sk9zc09pc3RjN1hxV3hjbmJIQlE9PQ==
"You're right. The right term is confabulation, not hallucination.",r/machinelearning,Z0FBQUFBQm0yeGJlTnlNWlNkYmhqdF9LbHVvRFZKZktCY3BMUFBVVWVRTUw4elVwckJobGloQVNiTVlMcjNFblBxWURWQ29YZzlNUmdXRm1HT3dSZjVBazlrYTN6cUVRYVFvb1FrWjJka3Y1dVI5RFhfWWNYV2M9
Gmae changer!!,r/machinelearning,Z0FBQUFBQm0yeGJlQ1FFcEtaN3NwTkZDcU40UG9kaGM2d0ZfYnBoNGszMEpmeXBMSGtCSHgwenJ6dUVrZUxxNnp6dE9HdW4yaWcyOE45Yld2aW1qNFo1OVRvVzZTWnQ2RWc9PQ==
Thank you so much. One more thing. The R-D curve should be created for sampling procedure right ? Not during training right ?,r/machinelearning,Z0FBQUFBQm0yeGJlOVRhS0FlbExSUllUV1lyRDhwVjBrTUs4UVVLZHlVUDcxWGszS0t6NU1DZVVPX0ppUFkybmMtZ2pRNmRjWGdHNzQ1T21EZ0VqbEstcVlZd2dLSlVyYmc9PQ==
"If you trained on simulated data, you wouldn't learn the patterns and structures common to real-world data... which is the entire point of pretraining. You're trying to exploit the fact that both your train set and your final task come from the real world.",r/machinelearning,Z0FBQUFBQm0yeGJlcXJaX1RwbUlKUERXWFNVZUF6YmFyVTM4cnp6WjFvbmhSZkNKeUcxTmlNSExiRjdxMzhEVXZ5dzljVTc2T0ozSlVNQThaQTREUkhmWjVVTmFLb3FRQW9ieF9lbmUxbVFHVHFHMWVrcUhPUFU9
"So, could you tell us what happened with your 2-hour take-home coding assignment?

How did it go, what were you asked to do?",r/machinelearning,Z0FBQUFBQm0yeGJlOXhIMnRheXg3RlZuM1VvZ2tQMHZOSHNLdmNLU1ZVNTBCVExzYXBYUy1NTkpEcmtnYzdfbXd6TkhlcFB4SHZzTlhRb2RGcWswR3ktcEFZZno3M1oyMXc9PQ==
"YOLOv3 is my favorite, though it's more for the content and less for the insights.

> Reviewer #4 AKA JudasAdventus on Reddit writes “Entertaining read but the arguments against the MSCOCO metrics seem abit weak”. Well, I always knew you would be the one to turn onme Judas.",r/machinelearning,Z0FBQUFBQm0yeGJlZTJUaWxZQjNHa1hJaU1HekM1MFZTMlNMeThZSUhLekJ4V3RHa2lsU0YtVW90SS1SUmU4X0w0QmpqNnRJRF9iR3JHYlBCci0wRmZZV1FjeTlKOXVsakZBRUJKSVMyWHVNOFVyYzlkVF92Z1E9
Autoencoding Variational Bayes.,r/machinelearning,Z0FBQUFBQm0yeGJlUlFOZTd0RTBGUDBKVGF5ZFhLTEVLZjZ0V3kxcjhjaXVqNXBrck1ONGNZN2o3RnlPcFdXY3d6RkhibmNjaXJkZHExWno0LTlocEtxYkNrOGJyTHAteGc9PQ==
"Right, these don't do a great job of tracking the difference between what current reality is vs what might make sense. It seems what they're doing is some form of what I used to do before search engines:

""I wonder where I can find clip art? Hmmm... clipart.com <Enter>""

Sometimes when I get a hallucination of an API function that doesn't actually exist, it often makes sense for it to exist, and I just go and implement such a function.",r/machinelearning,Z0FBQUFBQm0yeGJlVmhNMXNobGZFX1dXQ0V0Q1hWbTh0YnNHZkdKU2llWDZlYnAtMk1ZV1c1VEJiNTMzOFVJUm8tRUlSYmZBUFI0MlNiNl94TWcta2FJSEl3eFN3TFdVaXc9PQ==
"Thank you for your reply. You say on that page:
> we guaranteed that all the timestamps for all the time series were completely unseen to TimeGPT-1 during training

Do you have the same separation timestamp across all tasks? If not, then datasets where the training split ends at different (real) times can still inform each other about their respective futures. Although not direct, it does leak some information about the testing split for individual tasks. 

Additionally, you confirm that you separate train-test based on timestep. Do you also have a task-level separation? Is there a subset of the results which are only on tasks which are guaranteed to not be in the training dataset?

This, I think, is the critical selling point because any personal applications of foundation models will be on private datasets and tasks which could not have possibly been trained on. Its important to test this shift, whether through simulated data or holdout tasks.",r/machinelearning,Z0FBQUFBQm0yeGJlLXAtdjhYX1V3bEQwUWJrVVRnbHRjM1dFNHBhRHlGQ040bE11OGxQdnl4TEQ4SC12aG9iZ1F3Z1d2YzRwTkNGOW53WTQ0aF9PSGhzNmhrdlhtcEI5ZERzNWlpRGtQVUlSU1U1LTB1dmZ6ZDg9
EfficientNet for me. Just showing that optimizing for efficiency can simultaneously give us better performance is just awesome. Really went against the grain of blind scaling.,r/machinelearning,Z0FBQUFBQm0yeGJleEYxMkIwVzV0OXVNdUdDRzV1QWlDMENqNzFONWQzaUI1UXJTN2hBRGpYeWRuNkpsbUZxanJEQk5iUTlLTTRYMWd6WmExRFAzQk5VS2Y1bUxRQzJadU80WTV6LUVkUWs3ODBZWHJfWEFXSDQ9
I've only been in ml for about 2 years but my fav is LoRA.,r/machinelearning,Z0FBQUFBQm0yeGJlcDY1TlRpOWp3enRtRTBCU0VGT1I5VDROSkdYQWR5dXFWWEIxbGpkc3ZTOXkyVGFvT3RYcGhVeXNERGtrTmR3ai1NTmphUE1LdDJIU21MSk5RSWI3TFE9PQ==
"Right. Part of the problem I have this that I have a complicated pair of objects, of which some of the parts are effectively lists. And while I could do a simplification manual exercise to try and get two pairs of  embeddings that I can just dot-product on, I'd rather learn the proper structured embeddings simultaenously (given the labellings I have access to).

That's the bit I'm having a hard time finding literature/HOWTOs on.",r/machinelearning,Z0FBQUFBQm0yeGJlYmhOTThTeWw1R25WS3dIeC1BdHp2X3JqVU1yVWM2QWlZMmluZl9kRElhT1lMU1I1Z2hoellyaXhfdlJjeTFVMnZNLUJERTEtQ05pZ0pySEVROHRKUUE9PQ==
"Don't worry about the books example, the domain is far more specialized, I was just trying to give a rough flavour. The two classes of objects have stuff in common, but they're also different shapes in different dimensions.",r/machinelearning,Z0FBQUFBQm0yeGJlYktRWHNzNnR1VTVfaDZpMURJZFJsMzJXdEp1ZlJQcWp6NjdxTmNWMHJlT0ttMURqZWo2amNXWkgyNEUzLUE1ZzBxSFU2UzcxNVdiZWloRjFzeUtveUE9PQ==
One of the greats for sure,r/machinelearning,Z0FBQUFBQm0yeGJlTUF6R3lrSkVJYVJXWXhKNmNXM3ZOWW1zY0stdENhTjdKMmlrckFUajl6bEtNQUxwMWxTTEktVEdpbHh6T0Y5OVFPdkRPYk50TkNNWWJBTHlzTkZ0M2c9PQ==
"FYI, 水is water, 果 is fruit, if anything 水 is the less meaningful character here.",r/machinelearning,Z0FBQUFBQm0yeGJlaFV5OGY2RE1IeHN5QTQxS0ZaTURDVzA2Y1BUVG5yZkx6ZjlyUlFBRDFmLThWYkVGbW9nNmhaT0RxVE5FdkpINjZSYkRaSWVia3M1SmZqd2tLakJETUdXVUVIRHVHMXd2Qm9Wc1FRbWxOVnc9
Did you end up implementing the constant padding prior to the random crop?,r/machinelearning,Z0FBQUFBQm0yeGJlVnBqcURzS1pEN2lGX0pPY0pzU25wdjBnMG5YMTAtTWlHdC1Xc045MTlBSWQxR29URkk1X3BFb0tUNWI5RzhQSTdTN0lGOXE5U1RXSFpnSWM3d2RZNmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJlNU9DcnBmdGJING5MZXZmNGxCd1ZsT2NUaV9OQ0xXZXVQa2twR01LdWlYZVJrOFphZGp3MmI5Q05aQTVWQTB4dXV2d05rUDlmcjh1WkJrWXpzc1hWaWc9PQ==
simple diffusion,r/machinelearning,Z0FBQUFBQm0yeGJlWG5yS1QwQUhwczVYemtmLUFZWGlnZ0o4MzZqRHMwVVVrd0l3ZW5lRmdvTEF3X3Z1WmY3dGgxMURuZ19tRmgtbHhQdGJuSG5fbmpvdXFiWGlkanllWEE9PQ==
"Yes, that's the main benefit from pretraining. 

But, in a time-series context, overfitting on correlations between observations is more problematic in that it inherently leads to exploiting ex post information which defeats the purpose of forecasting in the first place. 

What *can* be done in this situation to address the problem is to do a simple rolling estimation. EG: Train the model on data from 2000-2010 and then test the model using time-series data from 2011. 

I may be mistaken but I think these pretrained models use data from time-periods that overlap with the time-series data from the test set. 

To give an example, if I fit some time-series model on a bunch of stock returns like META, AMZN, AAPL from 2000-2010, it is inappropriate to test on AAPL returns from 2000-2010. In fact, most time-series variation in stock returns comes from exposure to common (market) factor, which means that a model that would have over fit on the train data (META, AMZN, AAPL 2000-2010) would likely do implausibly well on the inappropriate test data (AAPL 2000-2010). The same point holds for most general time-series data sets; they often lie on a lower dimensional space so overfitting on that space (the source of cross-sectional correlations) would be problematic. A better solution here is to test on AAPL 2011 onwards to avoid this look-ahead bias. The same thing should be done with the experiments above. 


---

Out of curiosity I checked the performance of a portfolio based on TimesFM. Standard weak efficient markets hypothesis says we shouldn't be able to predict future returns with past returns. Common sense says that hedge funds should have arbitraged this idea out already; trying to do this shouldn't make a lot of money. 

Methodology:

* Use historical monthly returns for each stock to forecast the next month return using TimesFM (context window = 32)
* Sort stocks into deciles by the forecast value
* Compute average returns within each decile portfolio 
* Compute portfolio performance on long-short portfolio (the high decile minus the low decile portfolio), the underlying portfolio leverage is thus fixed to 200% - standard academic finance operating procedure

Shared the notebook here: https://colab.research.google.com/drive/1fvuVpG5r46mVuUEuJg8NDY1hNrFX93Td?usp=sharing. The stock returns are proprietary data from https://www.crsp.org/ so I won't share that. 

Results: The return on the ""TimesFM"" portfolio is 34% per year. The annualized sharpe is 1.46. Also, the [cumulative return plot](https://i.imgur.com/fnB7kwa.png) looks practically like a straight line - there is no performance degradation which is quite suspicious for a portfolio. 

This does not seem realistic, because the only inputs to TimesFM are the past monthly returns, too simple of a predictor to get performance like this. For this reason, I think the look-ahead bias of these pretrained models may be non-trivial.",r/machinelearning,Z0FBQUFBQm0yeGJlUG81eWZwbzlkTEVNSzVCYnk1UnpUa3hqOHdTSTk0S1gtTzR6ZTlpMV9Jem91TVU2RzBOZXNlVmZrRGtNdHVIblBrZ1d6TkhoUVUxTUotRVpxSFN2SGc9PQ==
2D wavelet transforms are a great place/space to start from. I learnt this from the WIRE paper. Been fascinated with wavelets for a long time bc my job revolves around unsupervised anomaly detection in time series,r/machinelearning,Z0FBQUFBQm0yeGJlSl9tNVJtZVRVWExzSFJfNXdud1dwYlNkYmJTX2VPb0VRWFlnTmFOVU9RUEktYXdpd2FjWDQ1YTNNZXNqMmRBWUlzVUdwWC1FOTRJTGg4eXlldHJqVkE9PQ==
I'll add a link for convenience: https://arxiv.org/abs/2106.10165,r/machinelearning,Z0FBQUFBQm0yeGJlbk1BS0JJVkttUkM1QUw2cjVIbEYyUXJ2NXZLNl9QMGNMUURtU05PLU10cTgzTnd4Ql90MTZHSFBjR2U0ZlNYU3NvT3NZUnJORUFEaHplU3JIdHhPZmc9PQ==
"I know this is pretty stereotypical at this point, but the GPT-3 paper absolutely blew my mind. 

Multi-task learning used to be a whole subfield, with dedicated metalearning techniques and complicated training setups. Then GPT comes along and does a million different tasks if you phrase them as natural language instructions, without needing any fancy techniques or special multi-task datasets.",r/machinelearning,Z0FBQUFBQm0yeGJlQXB4cDdwY0plSWd5alJ3M1F1RFBwVEpna1E0VzBvRHVreUx6YzhiLUdjekVyTEVyNEF6Ym1tZXdEbk1PYmRrWGdRTkl6Z1lsU2t1ZThKcE15SjZKMy05dXl6cjlRZDJCVDdSSXZPWWxaNzQ9
"Someone should develop a ""physics for deep learning"" course",r/machinelearning,Z0FBQUFBQm0yeGJleWhWX3lzVk1xdE9qUlYtLXVWcW5DT2NBbW5ZX2xraGJXMEZqYUVneFVrT3NDS3o4VHhsaFlMVm5Ed2IycnFwdDZrV2IzQlpOeUxqUWhobG1RRk5GV2c9PQ==
"You have everything you need to do contrastive/triplet learning. This solves your need for a learned embedding space. 

Instead of simply treating the whole json as text, you can separate out the structured values like genre, and price from the unstructured stuff like descriptions and titles. One hot encode the categorical values, leave the numeric stuff as is, and then simply concatenate everything with your embedded, unstructured data. You'll also want to do some normalization so that your structured values are not overrepresented in your distance calculations. Additionally since I'm assuming the movie and book embeddings will be in two different spaces you will want to learn a projection to put them into a shared space. 

From here you might also want to consider a metric that is a weighted sum of another metric measured over subsets of each of the dimensions of your embedding space. 

I.e. special_metric(a, b) = .5(metric(a[0:3], b[0:3])) + .1(metric(a[4-6], b[4:6])) + .8(metric(a[7:9], b[7:9]))

You can learn the weights for such a metric using the exact same technique as you used for learning the embedding and projection layers. You will probably want to learn the metric after learning and freezing the embedding though.",r/machinelearning,Z0FBQUFBQm0yeGJlVnhnTWFhUG1JUlo1dFV0VEpsYTBxU1BQY0paVFBVekFTWmNCQzhyWDl6WTJaNG1lQ0NxVlNiT2tnUm1fTjBQWlRjSU00ZTQwQzFmUjAyVHhadEVQUnc9PQ==
word2vec paper by Mikolov at al.,r/machinelearning,Z0FBQUFBQm0yeGJlaG02azc2cmExUlJMQ01XTjR6MjFERTNMdDg4djI4eG1MUjd5R0ptR0dxLU96NjVBaWFoWWg0S1pTci1WT3FnNTJmSHJHRDNQYUE0WEk4OFNmOHJHZGc9PQ==
Yeah I think it makes the most sense to do it once training is complete.,r/machinelearning,Z0FBQUFBQm0yeGJlSU40QmhZYVlGVVBwbVZWYnNIMlIzS21rV2gyOC0yT2pWb0NNa1ZnZ050MFNFMG5RdTR0alJwdVVxTkkwTHRlS2NESUszT1JHZkVORU45LWhvOEZnZ1E9PQ==
"The reason it's not solvable is because the ""hallucinated"" non existent court case that it cited is, as far as language modeling goes, fundamentally the same thing as the LLM producing any other sentence that isn't cut and pasted from its training data. (I'll be using a hypothetical ""AI lawyer"" as an example application of AI)

A ""hallucinated"" non existent court case is a perfectly valid output for a model of language. 

That you do not want your lawyer to cite a non existent court case, is because you want a lawyer and not a language model to do your court filings. Simple as that.

Now if someone up sells an LLM as an AI lawyer, that's when ""hallucinations"" become a ""bug"" because they want to convince their customers that this is something that is easy to fix, and not something that requires a different approach to the problem than language modeling. 

Humans, by the way, are very bad at predicting next tokens. Even old language models have utterly superhuman performance on that task.

edit: another way to put it, even the idealized perfect model that is simulating the entire multiverse to model legalese, will make up non existent court cases. The thing that won't cite non existent court cases, is an actual artificial intelligence which has a goal of winning the lawsuit and which can simulate the effect of making up a non existent court case vs the effect of searching the real database and finding a real court case. 

A machine that outputs next tokens like a chess engine making moves, simulating the court and picking what tokens would win the case. That is a completely different machine from a machine that is trained on a lot of legalese. There's no commonality between those two machines, other than most superficial.",r/machinelearning,Z0FBQUFBQm0yeGJlVTRUVVpJczNfYkFnTkwydkQ3U19oTUZPTkViLTI1eGZFb2doeTBuVHVLVlhyZmhOTENOb2tXSUJXM1JJMktUWi1ycWI4NUJkQWJFYzFMdk5td3J3X2c9PQ==
https://huyenchip.com/machine-learning-systems-design/toc.html,r/machinelearning,Z0FBQUFBQm0yeGJleDZKQ0tGMGVnMWpJLVZVVkZBY0pFRW9jZ2JiNXRCVDA2elFKZHRLdU1tQlpqejZTRTVEYVU4WEJkcmw4T3pSVUlFUmxqdVNSSzhTX1VoMFhLNXhuLWc9PQ==
"No arxiv PDF this week, [u/AnthropicAI](https://x.com/AnthropicAI) has beautiful blog posts instead (so says Greg)",r/machinelearning,Z0FBQUFBQm0yeGJmdTRoNTlGeUJ6eVQzZHBrbm5La1RHaEJCQzJvRmg1dGlhUy1BOW41TjJ6cTNPMEZKRjJ6Qy1DNHlkdXZjWnRMbDJHVndmTGxVMGRWaDhJVVVyTWFMZWc9PQ==
"I did! I added padding of 4 to all sides of the images prior to the flip and horizontal crop. I'm fairly certain there is something wrong with my CNN architecture. The training loss fails to improve as the ResNet architecture does, but I'm unsure what would cause the poor training in the 34 layer vs the 18 layer.",r/machinelearning,Z0FBQUFBQm0yeGJma3Y2NlNLek1sZUFMdC1Jb21DOHBQRHVWMjkyU00ySU11NlI3cllrN3FKU1QtUHFKNDJuNi1KOFVWRG1qTTFxWlRLUHJveFJNMDBkb29rUG5Id1l4MGtxdEpOWHRGa2VpT2FXUVhSbUxmNlE9
"RND is such a cool idea, great picks",r/machinelearning,Z0FBQUFBQm0yeGJmMXFPNkkxSDl0T3VCTTVzWG04djZodVd2Y1R4d2V0M3RXd3VZTUpmckZEbXF3RGdLdWF2S28xY3QtWUVRa0ZSRnd4LXVvZ0t3OWtzODJwYXBvQlRieEE9PQ==
"By the way, good discussion topic! So much cool stuff to add to my reading list :)

I personally love teacher-student architectures, so I will choose [the original knowledge distillation paper](https://arxiv.org/abs/1503.02531).",r/machinelearning,Z0FBQUFBQm0yeGJmWlBtazBPV2YwVGM2NENPWnpSNXZkcm9jQlRlZEx0bXByM2ViUm92MUJILWpqbkNKV2tXRjZiTDZoUXNYWFdWX20wa3FkUUhxVkRxNXgxZ3JjcHFVa1E9PQ==
"Precisely this. 

On top of it, LLMs do not have much in common with typical scifi AI which is most decidedly not an LLM: for example if a scifi AI is working as a lawyer, it got a goal to win the case, it's modeling court reactions to its outputs, and it is picking the best tokens to output. Which of course has completely different risk profile (the AI takes over the government and changes the law to win the court case, or perhaps brainwashes the jury into believing that the defendant is the second coming of Jesus, what ever makes for the better plot). 

An LLM on the other hand merely outputs most probable next tokens, fundamentally without any regard for winning the court case.",r/machinelearning,Z0FBQUFBQm0yeGJmdmlCYlNRZGFncFZ5Q3Q4Q21wVlc5NnpId1FUTUNyX0I1R1Z1dC1IMkdOWHQ5T2k5OHhmZXhOTU9Zdm8tdVRjUEJmOFhvVUU0YVJOel9nX1owdkdwX3c9PQ==
"ChadGPT5, by the esteemed machine learning quantum physics astronaut Chad Broman, obviously.",r/machinelearning,Z0FBQUFBQm0yeGJmUnF4S0Q0aURPN1NnSF82Y0xTNHB1bVM2aTVtNENhSnlNTEdxUnlJb1pNY3lQd3VlcXptUGZrRHhOaFZhdF9IVGJPNkN4eXlySkZscXN0aGhYOXppN3c9PQ==
"https://arxiv.org/abs/2304.09355

To Compress or Not Compress - Self Supervised Learning & Information Theory",r/machinelearning,Z0FBQUFBQm0yeGJmeTdySWYwbnlyN0duczk1VU5yOGRDVXp6ZjYzOUYzNEdUanhGNG9IdWJxTEdoQ3NtNVlaQkdhRlJlOG5TMjF6Y3RZYWFmRmYxeDRlQzJiUzVWN2dZSVRQa3c4WjhCcjg1SXhQNF9OdHZfTXc9
"These concerns go back to Alan Turing.

If Alan Turing were alive today and had the same beliefs that he had back then, and ...

if, like Dario Amodei and Ilya Sutskever he started an AI lab to try and head off the problem...

You would claim that he's just a money grubber hyping up the danger to profit from it.",r/machinelearning,Z0FBQUFBQm0yeGJmNTdCeEVXT1VjaFAxOW1xNVBTelJ5TnpneVNQaFZFdmdzYXdoRWo5TkZ2dEdDNVEybVF0dGZkWlBjczhKemlQVmpHWE1KaU03dmxNWXozSHZ5QkFrenU0QWdES0ItdC1PZmRDMWl3ZEhHS2M9
"I’ve worked specifically in this area, which is converting JSONs (in my case, non structured db raw query code) and I do indeed use embeddings. Usually I download the weights of a coding LLM like CodeBERT from the transformers library and do a little flattening before my processing. I want to capture the semantic meaning of nested JSONs because it affects code execution time, and CodeBERT can handle that. 

Then usually do some PCA because my data doesn’t have enough variance to use the 700+ emerging features. Those components seem to work as predictors in my traditional tabular models.",r/machinelearning,Z0FBQUFBQm0yeGJmWlN0ZlJYbHI0ZDFkMmdpbVZHTzlWS19jTlVJeU5RZ3NYMW1uUVdDSXA4M0MzYVdmVjVFMlBLZG83dEhqTjg0WHhSaG5MQTZZem12U2MtMWxJd1QyQkE9PQ==
"Using an Ensemble Kalman Filter (EnKF) to train neural networks.

https://iopscience.iop.org/article/10.1088/1361-6420/ab1c3a/meta",r/machinelearning,Z0FBQUFBQm0yeGJmd3NCdks5LW4zR2ZvakF3ZkZOclRlU1RJcTVvYnNTeWRIRGczekw1R0hBMXI4SkdfS0x2VVNEZDIwTDZmTEdMTV8ycFZRaUF0UTU1Zm1BVzVqbDFIVHc9PQ==
"Thanks for the reply, please do DM or reply if you end up finding that to be the case or if it ends up being something else.",r/machinelearning,Z0FBQUFBQm0yeGJmOEI1NDljMThoYTVidHRqOTAtRFNMUnBrVXdiR3JLeVFRNlFFcjc5TDdHZFN5SXlxZ045SWpQNVY5bmt5S1A4dnRFbGdJQ3ZqVHJ1bHZ1R2pjcXcwZkE9PQ==
"""Learning to Execute"" was a big inspiration for me. [https://arxiv.org/abs/1410.4615](https://arxiv.org/abs/1410.4615)",r/machinelearning,Z0FBQUFBQm0yeGJmZlpUWEVnZUNOOU1CVl9tbmFjTDF0SXlWNTlRMUxXclNldF9La0dZZl9vVGpYUk9zOFRmRnZpeHBGVTFXTVdoTzcwaURRVnRMMGllbXZDbU1hZjU5Rnc9PQ==
"""Additionally since I'm assuming the movie and book embeddings will be in two different spaces you will want to learn a projection to put them into a shared space"". Right this is the heart of the issue? What's a good resource on how to do this?",r/machinelearning,Z0FBQUFBQm0yeGJmcWdBN3RyZm9yX0lXM3VFVnpnZ0p6MnBZUnlEOW5JdTdUbUR5cHdFNVh4YUNSUXI2ZlhyMldDUjBXdEFCNzBzRmltRl9GRVNIX3l5bzcwNzZ5U0xBUFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmYXI2V3pYOU5kMDRONlBDWTBJY29PdHFvR2VoWEZEY1U5UGNCbjNFa0JnRktJcm1CTzZiM0hDQmZkdHViZElsS0RlcGhQblR6V0tMQW01bG01OW5iSmc9PQ==
">In other words, it hallucinates EVERYTHING, and sometimes it gets it right.

You could say the same of humans, and it would make one seem profound, but it wouldn't help you manage your bank account or get a job.

This reminds me of Buddhists claiming that all life is illusion. Yes, it's technically true that all life is our inaccurate sense perception. But it's not a useful frame for an engineer to use.

The engineer's [job](https://arxiv.org/abs/2304.13734) is to reduce the hallucinations, just like a psychiatrist's or guru's job would be for humans.",r/machinelearning,Z0FBQUFBQm0yeGJmczV2bTJSZWNiLVI2RnFrOGNHZmIzTS1IamRueWZ6S1hZU3o1eE1VUHIteUJQaHpGdEVtX3c0UXV0OWFJdnZxamt1cEM5d1V6bmJiTnJ2V1E0TzVSVlUxdkpqV1k1bExSeG1HTllJNzRtNEE9
"What I find interesting is how many people who didn't see the potential of GPT-2 who are totally convinced that they know what the upper bound of LLMs are *now*. ""This time I'm right! They can't get any better!""",r/machinelearning,Z0FBQUFBQm0yeGJmUUVhOFd4Y1NqeTVIZ3Z4bjdfVzdoM1drNnVHZU5MaUJiQUlZa05UZDdUQU9NQUxlUWtTQzJCTV9CRXFZTFpjcHBPY2Q0UjRFRVFBdE5kUzF1YjNYbXlVWVh4SXA2cFRzUHpqVUQzYWZhWUE9
"I think most reasonable people want the hallucination rate to be ameliorated to the point where the LLM's error rate is lower than that of humans, rather than to the point of actual mythological oracles. When they say: ""When will AI stop hallucinating all of the time"", they aren't meaning to ask ""When will AI be omniscient."" If that's how you interpret the question, I think you're being unhelpfully literal.",r/machinelearning,Z0FBQUFBQm0yeGJmMFR2aUk4MVF0aFpPSXZON05oNW1Nd3lwVFlSMjRCNkNVR19kZ25VTVlMelZqLWhjS0VYelM4OVJoT3Y2SHJZUmRCcl9BQ2dORWRQcXQ2M3NIc0JvQ01QYmZFTnJsQkYxR1JKb0xjd1VYdVE9
It's just a dogma. It is the human equivalent of a wrong answer repeated so much in the training set that it's irresistible to output it.,r/machinelearning,Z0FBQUFBQm0yeGJmNk5oSENCVzR0enllZDVuZkowWHdxX1FvOUoxdGdBWDRKTWIycVpadG11RGpmeVlTMlQtUnZPZE9pUmxJNGVvUFN2THZvdHBtTzN5cE9GZzE3YVN0eGhoQ2NvTHQxOEFUc1dSOWtUR0F3Zkk9
"YOLO v3 the ArXiv version and it's not even close. I strongly recommend you read it and try and catch all the random jokes thrown liberally throughout the paper. Doesn't hurt that it was a major improvement worthy of a publication!

https://arxiv.org/abs/1804.02767

The Intro:

> Sometimes you just kinda phone it in for a year, you know? I didn’t do a whole lot of research this year. Spent a lot of time on Twitter. Played around with GANs a little. I had a little momentum left over from last year [12] [1]; I
managed to make some improvements to YOLO. But, honestly, nothing like super interesting, just a bunch of small changes that make it better. I also helped out with other people’s research a little. 

> Actually, that’s what brings us here today. We have a camera-ready deadline [4] and we need to cite some of the random updates I made to YOLO but we don’t have a source. So get ready for a TECH REPORT!

> The great thing about tech reports is that they don’t need intros, y’all know why we’re here. So the end of this introduction will signpost for the rest of the paper. First we’ll tell you what the deal is with YOLOv3. Then we’ll tell you how we do. We’ll also tell you about some things we tried that didn’t work. Finally we’ll contemplate what this all means.",r/machinelearning,Z0FBQUFBQm0yeGJmX2RxRmRINlZLbmZEWDFzd3VUWE9GOGxHbi15aFJzb2ttNmhZaVZZci1jXzN5eDRFYjdXTGp5RTlyLW1PazMtNExhcTdwaE1UeG9vZWxLdUQ3V1VRMUE9PQ==
"You would use the same idea of minimizing triplet loss. Your network would embed each item separately, then you would learn two different linear layers with the same size output. After passing the embeddings through their respective layers they will be the same shape. You then measure your distances in this space. I believe the name for this technique is 'late fusion' but honestly I might be wrong.",r/machinelearning,Z0FBQUFBQm0yeGJmTmptN0xoZGx3dG1FNWpoWUt4dE93V1JEcEM1Rk1Zc3c4V1ZuaEwtVHhYbkpRb0VYcll0VUN0OHNkc2wzOGlCbEhiN2RCd1NxVUd0ZVh5Y3RKYU13OVE9PQ==
"Hallucinations are not just false statements.

If the LLM says that Queen Elizabeth is alive because it was trained when she was, that's not a hallucination.

A hallucination is a statement which is at odds with the training data set. Not a statement at odds with reality.",r/machinelearning,Z0FBQUFBQm0yeGJmeDdPaFN5LWRXTUo3RHR4bkRTTXVNWkdzMUZzcDZRYTgxcVVvYllxVE1vaHFOUTUzZmVlUy1FWUtQaFZYYTk1c09Nbm1XRy1jbFFGVGZ2S3hTMTZxZC0yUzMyRGh6ZzBKUFF5QU8xSzRJcFE9
"Resnet, simple and effective",r/machinelearning,Z0FBQUFBQm0yeGJmck1HTlU0QkFJM0VoRGFEU2tZdUpnbHo2UEVYazE3dzdvNkMzZndHTTdtRHg0NkZJZWtscVI3eF9lSWR5UDdBQkVPRkhQQjVkTUVfbWh5YmthS01VQ3lsbHlldEtEbG55SXR0bzFWNXNfSW89
sure thing. will do.,r/machinelearning,Z0FBQUFBQm0yeGJmUHk3V0MzQXhUUDNnZGJ5YXpnSDY5MEt0Z0ozLTZHclNNYlp3elAwUUJYWmhEZTlBUE5VNnl2R05VWU5rQlAyT01xOGt0Q3ZHajZMcXlyZ3FwdmlZWWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmZ0lwa3A1QzZBam1RM29CNU1jTkQ5MUhkbzJoMXpNel9XSGNXR0hRc0kyOUVqQWMtdkZlVW9PYXlBeC1tYTlDdGdDVVBLRGotNGVpVXp6MDR1dG1mTEE9PQ==
Should have been called Longer Short Term Memory,r/machinelearning,Z0FBQUFBQm0yeGJmTy04UE8zbnZVNE11RUtGV1VBc0RKdHdMT3R2aTYwZHpvTkYyRk04Qnp3SVVxWnVFM3VJTW5JUUZVaVI5Vmt6ckU5YlF2MjV0anRJSkp4akthY2dNX1E9PQ==
"Each tower can be arbitrarily complex and the weights and embeddings are learned from your task, so not sure what you mean by “simplification manual exercise”.

If you’re saying you have some sort of KNOWN structure, put a network module capturing that in one of the towers. You can have the user’s read books be a sequence with metadata processed by a transformer instead, if for example you believe the order matters.",r/machinelearning,Z0FBQUFBQm0yeGJmSl96MVRkU05PcEEzSjJCU1ZSM0pMbGt4dmlqYi1ldGpwS1hyVjZWc1Z3dXgwQzNCUmJNMXNOeXBTZ0dhSUZlbHJoYTZraGxuWms2LWpZVXhFbl9VSUVvbVlKQjhXR0lnV3JObGhOYXVXZjg9
"Btw, you mentioned about doing dsa, may I know which leetcode topics are important to practice on leetcode for an ML domain?",r/machinelearning,Z0FBQUFBQm0yeGJmNnZLZzBGQUg1TGxLUWN2bUdRVjZnMDVxUWpob0FycUtmTllQeUExY05pTm0tQklwSFhTYnZVSGt0cVNscUlsblhRU29yaFM2cXRKOF9yRXVPeV85OFJJbkJMeXQxU3VFT3B5bmxvZlZhcmM9
"So many good paper recommended, thanks everyone!",r/machinelearning,Z0FBQUFBQm0yeGJmVTFScTBpRE13SWJvU3RFQ2NrMmpEcU4xNW1VbmJ5YjhualBFLWg4QzNmbkxodmE2al91R1lYT1ROOXlPeWhvbXprcy1BTTdHdmJyaEZFcDUtZzVkdlE9PQ==
"This is a treasure.

> Can you cite your own paper? Guess who’s going to try, this guy → \\[16\\].

(and the link works)",r/machinelearning,Z0FBQUFBQm0yeGJmUXhCc2FZdXFoUUtTYTJDWlcyX2U0QUdENWtRdmlYcEZ1LVBRU21sdzdFd19INUxjWWlJRW5NN2FqMzhFVkxUaHE5bzc4T3VLSUEzTzN3Tjh5QVhmTnRSTlVkSE1NX0JhS1lPMkM1Y2tiTk09
"The DQN paper. Despite all the “human-level control” marketing stuff, it was so cool at the time to see a neural net learn to play video games from pixels only! Inspired me to do a PhD in deep RL.",r/machinelearning,Z0FBQUFBQm0yeGJmOVhzTFRxeGZZSUVkVnFXRW9HaVcwZUk0MHJXWTAxaU1GdVkybWxxN1VMZWhuVzJFWVpCTENPOWNrdnRBQXQ5Q2Z4M2FaQm5CeUg3akxPUHB3LTRHOEM3Vl81THh6VTRpSXZTTGZkRUpOTTg9
"Ha, one of my favorites!",r/machinelearning,Z0FBQUFBQm0yeGJma2x0c2lWN24zUXBsc0tTUkJ4YjMyV3ZrS2lxMDFUQ2QxNl9RM0wwbEVGZWs0S21oLWFDVWNJU2llbFZFdVFyV2N6QzFwVkJGQXBwT2c3S0dpR3VWUXc9PQ==
Thanks man . I’ll update which direction we will take.,r/machinelearning,Z0FBQUFBQm0yeGJma0tCRjdyb195ekE1RlB2ZUlrOENkVjFNcDMwSG5hbnQwWXdJOHV5RG5ya3U2eDk1VzlUR1F5ZC1tRzMzQklCOEVkUTJhVkh0ZlFfTlVrcWU0cTZHMFlab1B6c1lyZW5ESVBzWW4xQUx1eG89
"I managed to compress EfficientNetB0 down to a much smaller size while retaining a good portion of the accuracy. The tflite model is 96x96 in image size with 411 outputs with 82% and a size of 190k parameters. My testing to date shows it's a decent model (I would have expected the test data to have low accuracy as well otherwise given I kept it clean and away from training). 

I guess my question is primarily is there something noticeably wrong with my results? To date I have yet to receive anyone even suggesting it's beneficial. I didn't expect tons of interest but given TinyML is such an untapped field I thought I'd have some interest at all. Starting to believe I'm missing something fundamental that folks are seeing and just politely not telling me about. I don't know. I don't have a traditional background in machine learning (I'm a programmer) so I don't have the network I could reach to for additional feedback and I know I am still in many ways a novice.

I detailed the process here:  
[https://www.cranberrygrape.com/machine%20learning/tinyml/bird-detection-tinyml/](https://www.cranberrygrape.com/machine%20learning/tinyml/bird-detection-tinyml/)

The first notebook in the series (my site has all of them):

[https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds\\_224x224\\_524\\_outputs\\_full\\_swish.ipynb](https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_224x224_524_outputs_full_swish.ipynb)

[https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds\\_96x96\\_411\\_outputs\\_i87\\_full\\_relu6\\_post\\_decimation.ipynb](https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_96x96_411_outputs_i87_full_relu6_post_decimation.ipynb)

By the end I converted the model to relu6 as int8 quantization caused too heavy of a drop in accuracy (as noted by the EfficientNetLite folks for their rationale for ditching swish there).

  
Sorry if this is a distraction.",r/machinelearning,Z0FBQUFBQm0yeGJmRWdKbm1oT0NSWThqSE4wV0xUendHdUJfb0RiSVFTTWlVVDlvX0VQM29WTHVrU2hZMHpuTktVUnFyeUxwM1Nfcl9nam9lQXRYaGJkVXhxX2ZqNjUyYmc9PQ==
"
I see you've posted GitHub links to Jupyter Notebooks! GitHub doesn't 
render large Jupyter Notebooks, so just in case here are 
[nbviewer](https://nbviewer.jupyter.org/) links to the notebooks:

https://nbviewer.jupyter.org/url/github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_224x224_524_outputs_full_swish.ipynb

https://nbviewer.jupyter.org/url/github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_96x96_411_outputs_i87_full_relu6_post_decimation.ipynb

Want to run the code yourself? Here are [binder](https://mybinder.org/) 
links to start your own Jupyter server!

https://mybinder.org/v2/gh/Timo614/machine-learning/main?filepath=birds%2Fnotebooks%2Fbirds_224x224_524_outputs_full_swish.ipynb

https://mybinder.org/v2/gh/Timo614/machine-learning/main?filepath=birds%2Fnotebooks%2Fbirds_96x96_411_outputs_i87_full_relu6_post_decimation.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",r/machinelearning,Z0FBQUFBQm0yeGJmT1d1N3M2ZmtmMWd0Qk5kMzBrRkVKbENFMFF5Z2xiNTZWMFJCWGpUaXlqMURGdWVyQzEzQ2lGbmRmblk2T1JkNWJITTdTb3h6VEh6WDBFX3hTbDhZNWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmQ0ZVeHZLcFhMMjRkcy15YXRVSkl1S01jVEJnbXlGbkgwNjJRd2Q3M3pwNDUwbVlNZHRacjM2a05jUWpucl9TTF9KU0htb0pSemJTWFpIY3dmbkJfUHc9PQ==
">  I'm not sure what's ""interesting"" about the observation that LLMs will never be perfect

Exactly my point. It's just that, when talking to those less involved with AI, their understanding of things makes it so you can either give up and mock them or patiently explain the idea that they will never be **fixed** such that halluciations never happen again so that they don't misinterpret what I'm saying as whatever extreme is easiest for them to comprehend, but also false.",r/machinelearning,Z0FBQUFBQm0yeGJmbE5NODdPS0d0ck00aG5PTjZiRUlUeGZBckFZVHlDTllxSnh0TVo2bDlabFpuM1U3VlBlYjl3S05Xbm5XRHVGWXZpQThETnpPcnNYRVVPeDJwYng5cGc9PQ==
I create my own dataset based on some dataset i have worked before :(((,r/machinelearning,Z0FBQUFBQm0yeGJmcmQ4M0czUmo3ZVM3NDJhQjl6NFU1Y1hJc3VfZHhad1l0MzVoUnlRNTJhVXMwY01Salo3WkRDLXdwR2JQMmxaNDMzX0plVGNwUEl3NmJKQ2JXQXl1UmttMnlvZUVFc2x1NWNTMm1ieE9vbkk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmUERrZU5qQmxhVFUxTWZQMExORXlKRG9XQ3hra2V2Mk9PMUhNN21OOEFaem0xeVVTODNyS011ZlAwZER6QnBfOFRiZkpVWlFpS2NJdjVhRk5MQUhFX0E9PQ==
"idk if this really makes much sense, but might you try something like SINDy out of Steve Brunton’s lab?

Their approach is tailored towards physics-informed problems, but seems like it could work here: they generate a whole bunch of candidate terms (the “library” or “dictionary”) that involve simple combinations of inputs. Like, to fit the Lorenz attractor or something they have {x, y, z} and then they add {x*x, x*y, x*z, …, z*z} and maybe some derivatives and stuff. Then they try to figure out which combinations of dictionary terms fit the data the most accurately.

Seems like a potential good way to find these “simple” formulas. Though you have to be able to generate good candidate terms for you dictionary in some automated way.",r/machinelearning,Z0FBQUFBQm0yeGJmVXFCWTVXSEVMeXZzQzRJUWhNOGl0R0JuMXBOXzgtVHBURDdUUHNCRlNLMllwZWNxaHFJTmoyTmFaaEl4allMZ3lDRGdleHRNZkpIN3k1TmhBcWw1Znc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmalNSS1lHZkhPTjc2VTViNnp4b2JualViYUFuNGxRV25Lc3hSQ2VlS0MtWEVkUEpPUkxIcXB1ZTI2TlkzVm5TbzVabDBFRkFjYnlqb2pZZ1NkcmFQWXc9PQ==
"That is a freaking great point. You won't catch my ass making incredibly unreliable premonitions about decoder-only models again. I have put myself in the doghouse and anything I do share is a reference to somebody that wasn't dead freaking wrong.

Although, I still maintain that encoder-models are vastly underutilized. For instance... People attempt all sorts of reinvented workarounds to the fact that decoder-only models strongly avoid (for damn good reasons) returning a 'YES' or 'NO' to prompts. Or even dividing choices into having it select between letter choices from A through F.  Even if you can convince the model to limit itself to like 10 tokens, my experiences are that it starts failing badly at questions it otherwise got right. To train an encoder model to identify which choice through Pytorch and make the LLM response just a part of the pipeline it extracts the answer from would prove very useful, I think.",r/machinelearning,Z0FBQUFBQm0yeGJmQmtyRU1qWmxNallZWHVndWJ0eUEzZDI5VTJOUTBQaDk4MGpFU0cydFQtaUV5cUs5a3VKemV6X1o4bkx1OGVqd19UNzN0ZVRWeXVTSWdsblRtZmlKeFE9PQ==
"> If that's how you interpret the question, I think you're being unhelpfully literal.

In fairness, my example involves giving up on their ability to interpret nuanced explanations and just resorting to outright mockery. At a certain point, they'll both act like it's my job to convince them the value of AI models while seemingly proud of their ability to both insist I explain and also ignore everything I say. This situations are not common to everyone. I don't know why they're common to me.",r/machinelearning,Z0FBQUFBQm0yeGJmb1BYYWJkQWpGWklaaFNBU1JXLWFxN0FRcnpoa3FkR3hlVVcwZGo3ZF9FTjFSN2FBVldEZEtEVEVRZlFTSWswRmYwbXQxalhaNDNqS2pTZjE5VGRhS0E9PQ==
"Thanks for the suggestion! This is our first iteration of the benchmark arena, we will be including more foundation and baseline models soon!",r/machinelearning,Z0FBQUFBQm0yeGJmREZ4ZE5BbnNIVjQtdmtoak9IQ0pHSjlfaWd5TnhMamVxS0F6clQyeExBQ05RZVJwU24xSFFoMW43OEs4Q1hhRHlibkpTTXQ0NGxMcVphN25jaHJHYmc9PQ==
Cliché (100k+ citations) but _Attention is all you need_.,r/machinelearning,Z0FBQUFBQm0yeGJmWFM3NFd1SmtuLWlrT0xHcjNFTzhOczlOOEVia052dWJRYnZPREFacDBKXzdNSUstdmNYZEJMUk5LcHdjZ3VxWUNDeEtUcXA3UnRrOE9OMHpjZEVhcEE9PQ==
"It is an unsolvable problem because information of that sort inherently obeys the power-law distribution - as the topic become ever more specialized, such information becomes exponentially rare. 

Solely relying on increasing the size or improving the quality of training datasets will only get you so far. Eventually, you would require an infinitely large dataset because any dataset smaller than infinity is bound to have to be missing information, missing knowledge.",r/machinelearning,Z0FBQUFBQm0yeGJmZ1FtRkxFRzRkdjJRQ2dGU0ZoT1JITkFIbGljM25ZRjJUZWd1UXB0UDZnTjNyeU5XQTg2U0dPZVozUzJPc3JNZXNNMlhyZUZtTm43N2dBX0FHaGladUE9PQ==
"All of the ones that are important for a regular SWE. FAANG does not explicitly assign you a ""ML guy"" as the interviewer for your coding round and none of your interviewers care that you're one. It's graded on the equivalent level SWE hiring bar.",r/machinelearning,Z0FBQUFBQm0yeGJmdXZETk85YVNIT053cWRZZktybEVFenVPX0VyVFo2Nkc0bDNrVjVIZmZSbk9zTHRnZjd5aW13T2dGWlJobktYWEVoSWJIMHRTN2h0ajk4VndHS21heXc9PQ==
TIL people read PhD thesis lol,r/machinelearning,Z0FBQUFBQm0yeGJmYUktVk9WR2kwMk11WlNVZjZTY3hEam1VVmZQMjFNNzF5cXlxOE1oY0Y2U1Nvd0U1Qlh0MVBHUjlxdnFfNDhsdU00QnhfZUhGZDdpcHRUV2MxajdXZVE9PQ==
"All time not even close:  Double Descent paper - [https://arxiv.org/abs/1812.11118](https://arxiv.org/abs/1812.11118) - completely shook how I think about machine learning

Second place: Understanding deep learning requires rethinking generalization - [https://arxiv.org/abs/1611.03530](https://arxiv.org/abs/1611.03530) - I guess this is more of a sneak peek towards double descent",r/machinelearning,Z0FBQUFBQm0yeGJmWm1RX2h1alV3VkM3UldiTktvclpacy1NN2plb21ZdGxmdV9sWmt4Y1VxZnlmdjloMm9reWF2Y2RQYXlNNExnUWRYTVFQRnJNLWlOSDJEYS1OOU5TdXc9PQ==
"Wait, is transformers really your favorite paper? Everyone I talked with think the paper is very poorly written 😅",r/machinelearning,Z0FBQUFBQm0yeGJmWjZtNzd5S21lQUloM2lMQXVvRkJJY1ZLYlZMVnA1NmVMbjZBWXcxSUtGRGlqcG5oUWtmUXlkYVJYbHo0TnpjTWsxbzdlb01VMFplLWNfNnZ2bVZqLWc9PQ==
All three yolo papers by Redmond and his little resume are hilarious. I love them. Big fan,r/machinelearning,Z0FBQUFBQm0yeGJmM0VIZVU1eXhkTUJmRFpHYmVLQk1UNV9uZDB3emJrc0hvN0xoWUg1d1VXY2RkQjVGMVNCd0lWTUphQnlrMlhuWDdfMzRVRGdQbmFLTnQxbUtwRzBTMWc9PQ==
"Ohh, I was looking into this book. Curious, what do you like about it?",r/machinelearning,Z0FBQUFBQm0yeGJmWDMyYkstZ2IzUVptRWJYZERJejBrQ0lZM0d5dF9rbVp5eWxHRDZqLWhUZHlUeGlydFFUV1RNUUNlajJjXzFnMUpMME5hY3JQTjhDWVF3UzhYSS16VWc9PQ==
Word2vec,r/machinelearning,Z0FBQUFBQm0yeGJmWUtva2I0aWNzcGV4MG96R3owMkVxblFIZjJvaXVsY0QxcEVNWkNQLVJqbkFBOHRWRUhXbTV3WDZlZmR3NXY2TTJOam9FN0hMbVUtTzY5WE8wRURoeUE9PQ==
If you just need to turn a vector into a 0-1 normalized basis then softmax is fine.  The Gumbel softmax is for when you want to generate discrete samples according to probabilities as part of your computation graph (such that you need to be able to differentiate through the operation),r/machinelearning,Z0FBQUFBQm0yeGJmRnZCWHZYZ3NkanlNcFVWYzNFMDh2dnBOOXlkR3RZVlhCckdlUzFha3lBemdfeEQ2TmZMVzVGWE9RSmFJNERKMDBEcXJRa1R2LW9Ydk85WGFTUm5HTUE9PQ==
Neither of these seem to exist anymore.,r/machinelearning,Z0FBQUFBQm0yeGJmR1RLdVBLRXFSVi1XM01yZlBWYzEwaU1abFFyM2YweWVQdjNwVjNoMzlvWkF6TjZubHNNenZTa0dIY2xhN0laWkdQTlFKTUpnd2xJbXlSSV9MTDlGcVE9PQ==
"> It deduces the names from the embedding it learned and the context. So what makes the model work is also what makes it hallucinate.

It often tells you the better API that ***should have*** been added to that package.

I'm tempted to start submitting pull requests to packages to make them match the cleaner APIs that the LLMs hallucinated.",r/machinelearning,Z0FBQUFBQm0yeGJmOTh3aVVkUkpiODdkdDRGUlI5VXVVdUp4UG8zWk8zVUhaTUhvNmhLb1VqVTM5RHJQWWtkWHZpYWdmdlBCVlJCUHFFSmktbGd3cXNhRjhQYUR0ZmM0My1zS1VzMnBoLUlDNE9TUVNxSFJJT0k9
It's is for me either GANs or NMT with the og Attention ,r/machinelearning,Z0FBQUFBQm0yeGJmbXFvRGNEbEt0VjlfTmNfRGZCOFN5UUhBcjVLVHpydkNJQUtpMF9TNXMtRkhQY2VmWG1lMnNwdGlvNVVzVjRaUnI5dzgyd1lhbkhuZHNjNGJydmpoMGc9PQ==
"These are the OG's for me: 

1. ResNet: https://arxiv.org/abs/1512.03385
2. Attention is all you need: https://arxiv.org/abs/1706.03762",r/machinelearning,Z0FBQUFBQm0yeGJmRXZ1Q1ZacTNUMWx1MmhWcVRsLTlOQTlBMXFZaHktcHB0MTdLV0k0ZUNZUk1zUV9CRDNCU3ktejEzcGNPU1N5Q1h0dVBEbERNNXpxT1NyZE5nZURXWGwtci1mQURucTFhcVozQlIyYXFpMkE9
I loved the CLIP paper. Very insightful.,r/machinelearning,Z0FBQUFBQm0yeGJmN2RBTFQtOUlyOFc1OXhJVlowMGloNmxydHNsaS1UVDZhdHBJNWNybUlqNlVlSmpaMHpjeDd2bnVWamRTYlMydkIzVHlVcEl1Zk1vYzh3MjVLYUpTeWc9PQ==
"It's funny that he calls the library darknet, but it definitely stopped me for a while",r/machinelearning,Z0FBQUFBQm0yeGJmMmNzSEJSblFqbTlsV0t4eGR6X1drOXBIeW5YQTdXRk1GWEVTOHNQSjI5TjBsOWJRdW5od2NqajctOUE4R3R5Rzc3eDZERGhYZGRRZEI3WndSV3pXTUZ5ZVdKSGIwQUlJRnBkQldHWWZkekU9
When you do research in machine learning is there anything new to be found by using the existing machine learning libraries like tensorflow or pytorch or are they too limiting for research,r/machinelearning,Z0FBQUFBQm0yeGJmVllGQXJUMmZWUEhFVlU1dFlIeWlhR2ZMMTM5ZUJQT2FMeVlNU09SVEhwcWF4WFZSLUVJOV9tbHhwT3VSTC1BNUpaNWVCLXBYVXRKbDB4aHRRdGFTOXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmSnJMc3ZIM0FVMFMxXzIySUtFVHdTNVp1dlo1M09LYVFoTkY4c0dpUjB5YURRU21uakxoSVMweHBLYUo2ZVBYWVdVRWY1VVJFRkYzZXlnazdFX1dOb3c9PQ==
Neural ODE https://arxiv.org/abs/1806.07366,r/machinelearning,Z0FBQUFBQm0yeGJmb1Q1ekZscnBLaVMyWFd6WUgtQUtSdUdYNVh0ekdiaVhXMkt3UjYwTUlqekxVN1VOU2wyam4xNEJNa0hKMVRqNVN5a25uUlZnNzFsRzJNUGJhY1pyb2c9PQ==
"Softmax models a categorical *distribution*.

Gumbel-softmax models a *sample* from a categorical distribution.",r/machinelearning,Z0FBQUFBQm0yeGJmbjNFMmRlTXFGMEh4dzVxdkxHQnNzYl92UjJKOHZyLXlrM1h0c0ZaM2pMOTFRSmtwZlVpbFlxZDNCSUtadjZxM19OeEFlSGxXcXFDVXBRTnRERWZsbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmdGw1MV82MGF4dTBlUW5wbWw1SlNqeERncTVvck5tajZyTmlWTjF4UGE2ZEtNS2dzdkNFbkNtdzRnQkZFUzh0NlVjRWF4bEkwczNpY1ROVV96X3k2cFE9PQ==
"CycleGAN, I really loved the simplicity of it.",r/machinelearning,Z0FBQUFBQm0yeGJmNnhqWmpEQ2tjeEtUdWJETUZIdFdwY1ZqVC1TSnZmeF9JY3YzQ0k0VGVJWTVPbHVnWmVqSjY5T1FzQ2ZpYXBlYURBS2pNc3BHcXIxd2sxN1JzZmNtSFE9PQ==
"The identified features cross modalities. One example they give is that images of a burglar breaking into a house were grouped with text about cybersecurity. The hope is that language is not an overly dominant modality, which this finding seems to support.",r/machinelearning,Z0FBQUFBQm0yeGJmMWpaLUYza0cySFkxa3gtV2htWUh1VWMtdjNUNWVUTWpGSEEyQzJQdG1ZbU1fNDd3eHBPaEllTFp5RnE0a3Zvc05maC1GdENWa2dES29nTlFpWXBXLUE9PQ==
You may find this resource useful: https://devinterview.io/questions/machine-learning-and-data-science,r/machinelearning,Z0FBQUFBQm0yeGJmT25BM3drQmJLVG55VUtwR2JILWxNYzYwMUFXTERCdEk1WVB4cm84UVNfZ0R3eVc5NUY0NWc2V0FJTGtGMU1SU21idklKUGp4SzZSeW94bVkwYUd5UEE9PQ==
My company holds weekly meetings on how ML is applied to our products.,r/machinelearning,Z0FBQUFBQm0yeGJmYjZtdHI0ZHRRUXFvaXBURUlyU3NNX3pPdEJOZHZSTG9yU3FBNjh5NHp5SlliUFJPTlp6Q2liVGhaSWJVYXBZU1JHVkJkekIzU0x0MEdtQWpObXR2bVE9PQ==
BERT paper - I liked the experiments section.,r/machinelearning,Z0FBQUFBQm0yeGJmT1Q2NFBRVGJzVGFsN2U2dkxIZ0ExUGhtWkExcllPbm1ib3llRngtaC1BLXhXcE13bjdYWW9UZEpINS0wTFZlZ0d1NTF0NXlJSjJpczdSWEppVDNQemJ6VGJnbE9hSVJ0TTF4NFNMM2QzVXM9
Any chance you studied from UMD?,r/machinelearning,Z0FBQUFBQm0yeGJmeTZ5QkZuU0ZhTnpFeHRfNEl2TGNGRVdfWHZ6UzMzbktXZlA0VzBZV3VyZzNzWDRla25weWNSNGFtY1hyczByTEdlVkxzZE1TSlFNQzhITjB1ZGttOXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmeWlDMTdUVlY1VmpWLTlSVE9RQWtHN29iQ0hoSVNnb25Ja3ZOdnJvTGRaLWhjblgydWpYZUhIWUdRR2t1VV9YeGlLTW56Ti1ZMWN4bmg1S2RHUWQ1VFE9PQ==
"No, that’s not how people judge hallucinations. People care about end results not the training data set.",r/machinelearning,Z0FBQUFBQm0yeGJmSUhWN1VCeUZzNG5VSE55ZUhxeVZ1S1B4OG00Vkc5QXFvTFVNc3Z4SnBNOGQ5NzZMUjVoMzU3TnZpXzFxS0lZOTVHMXlOMUktVHJRLWRwQ0F1T3VTckE9PQ==
"Why are you so keen to defend hallucinations? A proper AI should be able to recall information like an intelligent expert.

I don’t care about making excuses because of architecture or training data or whatever.",r/machinelearning,Z0FBQUFBQm0yeGJmeVRZVjhzUVc1c3dPeTVyd0R3WkEtTFV1MHVzdUZFVjF1SlU1RmZBQVNIMWVXY3JxZ1NqbHR4amR3UkpfM3pydVRGbzZ1RXRWTE5zLTcxaUVZQm9sMUE9PQ==
"At least in my last 3 conferences and 3 journals, all explicitly prohibited citing in the abstract. I also agree with this approach, since the abstract should be a short, self-contained ""TL;DR"" of the paper.",r/machinelearning,Z0FBQUFBQm0yeGJmck9KN20yX3pmOE5TWnd6dEdCYjFnX3ViS0ZsM1ozYk82a1FZbmVJVjY5WEdyY1VBR2gwXzFucFlFS1pPMzBrSTJkOXoxUmJKOFhlME16RVgteHZKTEE9PQ==
Also my favourite,r/machinelearning,Z0FBQUFBQm0yeGJmeWdQZXZVMTNWLTRBSDdCLWlPS19sbnVmNHhkWkxwVDBlb2VRYWMzYkpUUS1uZ0dUbFNOVjNqcEkzWG9TbDBKc1ZDQ01oWDZYNERUcWVickZtS3FRdWdPeW9iWjd5WjhuNE14c184cjhBcFk9
"[World Models](https://worldmodels.github.io/) . The idea of using self-supervised learning to improve the sample effeciency of RL agents seems so intuitive, and this paper got it to actually work and perform well in an attention-grabbing method. In the robotics scene, you can see this idea starting to become more prevalent.",r/machinelearning,Z0FBQUFBQm0yeGJmYS1lOUdKQWtCY3V3Mnpla0RqR3VfSjd1RVBXdnYwMUVZN1dkMUhmWWUyMjFIXzZhYk80V3NNRlFUQkluSFRFZGltRTltZVlRbm5razlaa0xrYXhxWEE9PQ==
Amazing paper! Was very mind blown at the time that distillation even works,r/machinelearning,Z0FBQUFBQm0yeGJmT3RPam04cGNVN0E4MDU2V1R3X094OHphc1RoNkNyT2JTVGdTLXMwZlVqRXJhVjhxV1FLcWQxQ3VrZHhkRVkyMjJ5eTBZamFKNEZQZmVPZ0FValFZNlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmWkFtU1JvdTBLVGxoT2xVbTZ1SFd5RDFiTWxEdGdRZXk3djlJUG9neEdTTDdMdnFvSkZKVFBVTEN0MGF3bXVtZVJ1Z2dqbEwtNXFTNm5zd3dFSUZiWmc9PQ==
attention is all you need,r/machinelearning,Z0FBQUFBQm0yeGJmSGVxcnFJdXNYRFhPakZmLW43NHF6cmc4Z0hpb1VoNWpnU1NBVTBqNXRNSXdNYjh1SnFLRU0wNnF4LUdrNTA2UkROY185Nk5wY0F0N2I3R0ZSaVIzcVE9PQ==
Higher order polynomial projector operator - Hippo. The paper that's the base of all SSM model. The appendix is so well written that you can study it like a textbook with every little detail provided.,r/machinelearning,Z0FBQUFBQm0yeGJmMkp4QjhTQTZlVDRxQURfQkhwN3hLTUI5Z0dLWkJaTWlBOUtKZmFnSUhBSDJIOG1CSHNzMktwQUloZVVFbDRqU0xjdS1ZSnJramtpamVvQTBfV3JWaGc4VTdzZXRUQ3BHel9ZQS1pMk5GdTQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmVW85aXMwbkZjemdscVhZeGZXQmFXbm42eklteUs5Q3pabk9ONDFid0V1SE9WaWJvbE5yRFgwTV9jV0k3aFl6NDhQdzZpLXRtM04takpvNHhnd0FiOEE9PQ==
"Tried to find a implementation, any luck on your end?",r/machinelearning,Z0FBQUFBQm0yeGJmWmpQY3NHRTBRdTY0clRtQ0VHX0JfT3FXd3BhNENKLUV5MW1MeGE5YkdQbGZyUjFjYUt2T1doR2ZTQXZ1MlluQW5OZjN1X1VuQ1RrMl9QaXY5SnI1UWc9PQ==
"The LLM is a lot better at reasoning than I am, cuz I did not understand anything in this post.",r/machinelearning,Z0FBQUFBQm0yeGJmRzVDOEFCbGFaUC1DYnRFMlFqZ0stUllCWVU1ZTVqR2tmTXQyNWVwc1BibkJHcFB0Q2JoX2RFR2cxcFBsZ05VQm9qMGQxMkt0dEM5RjRfZXdHWkxrTGRJcGFlckFqREUtb1dYWXd1UnF6Mzg9
Yeah bro I am amazed because I only know what I am kinda thinking with little context it reasoned well,r/machinelearning,Z0FBQUFBQm0yeGJmOFJ6UXB2SHAwZDRpYjJUMHM5Rm0wN1A3MnBHalpiQUU4Nno4dXRKWnFQMU1MdnExaUhFVHdER3Q2Yi1PS2pjdDl5Y0ItNmxKNUx6OXdKcGpZZktIYVE9PQ==
I totally agree with your concerns. I also like your example with TimesFM.,r/machinelearning,Z0FBQUFBQm0yeGJmTUhSYXN0SjlRUHV5YkdLaGNxSlhQaUdhZlJoR250QkRSMWxtRnR5UE4wLXdrdnhiM19DeHMwLU11c1czOUFwekROdzhubkRkaDdZcWE3T21PYmFiV0huNXlTS1NOaC1fMk9WUnhjTlR3ekU9
"I've tried doing so but it gives terrible results although the derivatives seem correct, thought I might ask about it here!",r/machinelearning,Z0FBQUFBQm0yeGJmUVU4NW5GcWVyQ20wRXlUWHRtWlEwdHgyTmpka1g5OE5jZ095RDBfaDdmMWtJbmRMVzNZWnV3d3dpNFN4MGpNVUhqQnVkOHFsOWZLdjlzVFdJM2M4SnlpZktBRVpNRTRvRjA2LXZrZHJ1MTg9
"Thank you for your reply! Sorry I took a long time to answer you.
I totally get your point, and definitely I agree with you. I was thinking about AI for 3 main reasons:
1) I really really want to re-start doing that kind of programming and analysis, I loved it a lot during my master and I wish I could use the tools I studied to apply it to physics
2) nobody in my lab does this stuff, so it would be ""my"" project with all the related advantages
3) analysing the framework, I truly think AI is a feasible and interesting path to take. I would be focusing on an experiment that is not in function yet, which would mean working with synthetic data at first, but I could train my network on similar machines and this could also lead to international collaborations... You see the deal.

Anyway, concerning the data: I will be working with a sort of particle accelerator, the diagnostics installed will get me tomography images (Very low resolution) and both vertical and horizontal profiles of heat loads (with even worse resolution lol). So it's 2d pictures that give me different information I need to combine to produce a better resolved pic in the end

Hope this is more clear, sorry I wrote it in a rush and thanks again for your time",r/machinelearning,Z0FBQUFBQm0yeGJma3ZIR1cxVGtvNUpBN1dESVpOZXBWUkszTnJCX0x3SDV4Z0tQT1g4U0JoNUhCaC1SaGFVY0ZMQ2ZhQmlua1d1Q3JXSS0tQUJFS1B3VklHd1lyZGhFcGc9PQ==
"Negative. Annoying when interesting ideas show up, plausible claims are made, and code is AWOL. Relatedly, no cites as yet. 

Going to run this paper past more qualified people than myself, will report back!",r/machinelearning,Z0FBQUFBQm0yeGJmRHFNUXdqeFR4V0pkQ3Nlbl9qTlBKVzRETUNTRjJkNWptTXNIRVRLY0dyR2JYZ29hRE16Tlo1MVl1YVU2T1NkXzB5U0VwQUNOS3g5dUxwaXUyU2NxT0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmVnZDYWhnVjRvV240ajRQdldmTjM1VXpZVnJIbU55dDhKenpvV1phZWR6MUJ3d2JOVlpRQmxtZ3Fyb0FPdk80dUpJbGdremFidWM1OU41Y2xqR2hhLVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmY2ptelZzc0lUV28yTHhVcFZ4WVllTnp4dGtoYnpjd3EzR0pJY3lZb3hSVGNiX2U3bktwQmZQSEtqRElET2JqV241TlFyOFBPRUs4bW5UeHZwOW1CV1E9PQ==
What a treasure,r/machinelearning,Z0FBQUFBQm0yeGJmV0kzNnJNelpYWm1iYTVaLU43czBWOC1JTlljXzhIMWVrUFpIeE9QSllsZDZHOWg3Ti1BVnZlazJsOFR1LWRydnBKY24tZVhPdFpxVUhKbjhLTS00OGQ2Z2NUcXRqLUdrcGoxeFJNeF9nSEE9
"OG normalising flow. It is such a conceptually simple but powerful idea, offering an elegant solution to hard problems by solving it backwards. While it serves as a precursor to later ideas like diffusion models, the original idea is still relevant today as a general method to model ""any"" data distribution which is faster than diffusion and easier to train than GAN.",r/machinelearning,Z0FBQUFBQm0yeGJmVk1ReEZwUEtOVUFISmJ0elhacW93bVltZGl4dms3R0lNWXN4aGd5em1nQzZYYU9Cc1Jsd25yVnVDVjM0UEdKUzdpV3hJRmpjNzZEY19rWi16QlFMdHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmZGN3Q200QzdfR0JkQzY3NlJyaWZpMENkYkNNTnQ2S0xybDljcVZrQk5MTXJLT01saWFnX25MOEdBLThoMlBhNW9GdV84ZUI5eDRVZHo5V2R0ZjZsemc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmYU83WUtMSF9mRUs2cjQ5dUdYZnRENC10aUc3ZUJUazdQTW5jME5kQWVtQnhkQlhjVUNzS0RndkJITEN3ajBQbF8tWXROV2VLd0owMVBYX1V4QnVOYXc9PQ==
Thx man,r/machinelearning,Z0FBQUFBQm0yeGJmcmZldnRwZkNPdllYWTZIWWltYmxlTE9tSmIteVh0REZ1UHZJUzFHMEVNZE1NRjFId3duSnFwcDBQTF8zQlkzOXZvVzdtemJ1SnNNLTQ2eVZYc1JnNHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmdXIzTjY2dE84eXhVTHdlMzNYVHZQNUFoUFZKRTZEU1VZY1pQOTh1d2FBUXNtNnR2QkFFRnE5OThEN28zMXJ1NVR5YnVHREdFVUtnOWUzSmRkSFExLWc9PQ==
What is Redmon doing now? I mean he stopped CV for ethical reasons right?,r/machinelearning,Z0FBQUFBQm0yeGJmM1h3OVJtR1NtVWp4NDVwdUVadUQ1cWVrQkF2Zy1PclBFUXM4anFxQWpqWm8zbzNqQnp2MW03RDNPYThJdlhDSnE3dG9la2liTEdTZl9PNWZ2UFlMc0E9PQ==
"""Things we tried that didn't work"" is fantastic and should become a standard section.",r/machinelearning,Z0FBQUFBQm0yeGJmUW1FNWdLcXR1UWFyb3Ywd3p1WTZPYjVjZkgxcHg3bS1CWmp3dmRfSHhKa29XZllROVNfT3BNS2tfVWVJZ213c0c4c0lVc0lEY1kyeWRic0ZOdmJORUE9PQ==
nope,r/machinelearning,Z0FBQUFBQm0yeGJmUEZaaXFfWDRHSXFoZzNkTFliY3l0UkZyalJTN1NhMzdvcVlmZ3JDZGFjRjVQdGxRdHhSemVoRzd6VXpkMWVxWDBYRXRKTHRtTnZFWjVycEI2RUd2R0E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmWVhkaS1hWE1UbFRYSGFkUzVMRUo1WF9mbFpya20ybG1wU2RZVWhGeUh4VFlnQkt0SVVIS3Jpd1hRdk5VMVItZGYycHNwcFBMVVZjUzF1S2RWU21OM0E9PQ==
"the first paper on attention (ig Seq2Seq), PixelCNNs and WaveNet",r/machinelearning,Z0FBQUFBQm0yeGJmd19WYk9mQk1JdlVDQWduVEQwMGRQT0FON3JvMVlCU01jQ1hTM2lUX0o5dmZSX2hXbjNmZ3N3djhPa29uRjJNR1plakdzZXNtUHozYklycXMzMllLVjY3T19YTGxtaXpEVHJWZUQ1TVF5SzA9
"No one really knows, he's doing some activism and apparently stopped teaching.",r/machinelearning,Z0FBQUFBQm0yeGJma3FDQldNdEJsNWNKd09TamgwbFJLb1RsdXlsaXhFTkJZQ1g4NnRwb2FkVHJNMWFJN0htd0pvYi1BNVE3bExxNy1Ndkx4bTlQbFhFSUJnendBU1JKYmc9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJmanVvSjdzalZDcUItekNlSUFKRGRXTXBWMkUwT1Y0aVRWZkFOOWdER0VkME9tRUFNV1VDNnNfQkozcUs0SFByRnVJSEhKRl9oakFud0MtYUpFRkthcTJrODFPV1dLOHFhbVFDcGh3MHptUTA9
"I loved the Listen attend Spell paper. It was my first foray into speech recognition, it was so cool watching the model learn. From spitting out garbage, to garbled words, to fully formed sentences.",r/machinelearning,Z0FBQUFBQm0yeGJmekVnU0ZDeXZTcGdMdkozWUFld04wYzlLQTlqenZsaUtwQy1fTUNzY0o0LVBIaWw3Qm9ibzJ4UG5fSEZqUlNlUTV6X2ViY2dmT25qSUp1QlJYYTBWenlPUmRiSXdEai1VeV9HekJXRzE0cmc9
I don't defend hallucinations. I'm just stating that this flaw comes from an application that is quite far from what LLMs have been designed for and are being repurposed now. I understand is cheaper to try and fine tuning a language model to be a knowledge research tool instead of designing a new tool from scratch,r/machinelearning,Z0FBQUFBQm0yeGJmS0loOFUtNnhMdHlGa2RsZV9XTVloZVJJMEt1ZHJRR3pvZDBDMTBpSUExUFFzY013aWtpZGtvTUJualdwTEFPdlptQjlxV0hXSG51TkE3UlBQcFJGQ2c9PQ==
"Perf example!  :: light bulb ::    
  
Thank you!",r/machinelearning,Z0FBQUFBQm0yeGJmRjh2OHU1VHpNWEhsMkY1SXBjZUxzeW1yazFpRGpMX2ZNVU1nMVZseS1QaTZzWDhpMkk1UFBwV3p1NWVKVkZNSkx6enU2SGdlM0JKZ3oyaEIwSDNRV0E9PQ==
"It's not what you're looking for, but this is my favorite paper in ML: [The Case for Learned Index Structures](https://arxiv.org/pdf/1712.01208)

This paper outlines using models to improve key parts of existing code. It's not sexy but it's a blueprint on how to integrate learned models into traditional software.",r/machinelearning,Z0FBQUFBQm0yeGJmZmFDWklnTFBkUFBMV3JtN1hYaVhQWlVlRzZTN0pMTHVNdERpR1F1ZkJfcVF5WEhNRXc4TllTYXljUGVVYzVJb091YUYzenRtVmotMU0tY09Gb3RpQ1E9PQ==
If we're talking about meme papers I always had a soft spot for the [GUNs](https://arxiv.org/abs/1703.02528) as a way to stop this Network on Network violence.,r/machinelearning,Z0FBQUFBQm0yeGJmdFNmQVFmWUlTbFZPb0xOcmVzOHZvVnA3VGtQU1NsdEdXRnNfeGprNTYzZjE0TUx3ejV6TVpBTlM1eFZoRHdIUlgxLWNDTG43cGxDUV9Pd2hUbmhQUmc9PQ==
"the legendary ResNet paper. It introduced residual connections, which made training very deep networks feasible and improved performance significantly. ResNets are foundational for many subsequent models and applications in computer vision.",r/machinelearning,Z0FBQUFBQm0yeGJmSXZPQm4yT2hwajBXaVFPaVRiZE8yNmIxcUljT3FUSGFsYWpPcjRtN3cyWkpfaC11anEzYVVjS3R5VFowRTVsNFJISW1iQ3VsT25BN1BLU3p0QzVpU0E9PQ==
"You can find a very robust solution by looking at the data type: input data comes in a DateTime+TimeZone, and perhaps your model needs to work on a UTC clock?",r/machinelearning,Z0FBQUFBQm0yeGJmVF94bFFTdFh5SlZpa3BvdFQzYUIwTDZsQmNyUGh0bXBVbHBlN0xVUEFERWg1MEJYTVgtTWIwZ1FOS0NEY21jR2tjbEx1WWx2S2ZFUDRKYm9IVHQ5V2c9PQ==
"Thank you for mentioning SINDy (and introducing me to sparse symbolic regression)!

I looked into it some, and it indeed looked promising. I guess that calendar calculations can be approached as non-linear dynamic systems, which is what SINDy etc. seem to be well-suited for. Unfortunately, I lack quite a bit of intuition in that area. For now, I will return to pure geneteic programming with DEAP, but I will keep this direction in mind!",r/machinelearning,Z0FBQUFBQm0yeGJmMElFMUpvUnRXTzBSQ0NZTmQ2dXhuWDN1YlM1VHVRYlZlcU93N0c4YVE1NnE1akFXVlIzZjZqREFGM3Q1aVJrTEJoenJkX3IxeFNHU2tNaWJ3cWQ2QkZwN19XcVVvRFplNXRaUmdqNlAyMWs9
"Top 3 in no particular order

- Descending through a crowded valley: https://arxiv.org/abs/2007.01547

- Implementation matters in Deep RL: https://arxiv.org/abs/2005.12729

- Why do tree-based models still outperform deep learning on tabular data?: https://arxiv.org/abs/2207.08815


I like ""drama"".",r/machinelearning,Z0FBQUFBQm0yeGJmbTVvSTdOakhpX1ZQc3RsSXlRcmVfajRLdjdMRWE0MGtMb09zVURYWXZDUFRzeHhIUlNyNWZ3NTcyMlI3eGsyUUc0ODNwQlZEQmVzRURSZDd1dkp3blE9PQ==
"For sure:

* Change sentence piece tokenizer to not remove extra spacing and use byte level encoding for OOV tokens.
* Drop next sentence prediction task in training.
* Use word span masking rather than token masking in MLM.
* Pre normalisation over post.

Unsure but I'd prefer:

* FIRE over RoPE.
* RMS norm instead of Layernorm.
* Intermediate size to be reduced.
* Maybe multiquery attention.",r/machinelearning,Z0FBQUFBQm0yeGJmc1JJWXE3SnJmSHZfeG5xTXZtWU56MFphWld6TnhUNURPbThRakJRUVFJYWxyeWtfUE1aakpMOVF5aFA5eFByWnRfMm1BRU9mWk5rNjRNelZqTGRsTDYybTh6bG5NMm0zT2VwZ1ljYkV0dXc9
Genuine question. Why is every paper on a Cornell University domain?,r/machinelearning,Z0FBQUFBQm0yeGJmTFpxbjFiMGlsNExOTExFaWtkV3dkR3NYajN0S2NISzFnM2F2RHI2WEUzRGRTRi1QLTA0UElNQ1JrRXAwQlVTc0xOSm9EVUdoTnlhRGs1OElHSWJ4QXc9PQ==
This guy hit the nail on the head. If you’re more of a notebooks and python kind of ML engineer it’s a pretty tough time!,r/machinelearning,Z0FBQUFBQm0yeGJmZU5uQTBZUDVLSmZ2U0tfRFV3R0NhMU1pWEJ3bVE1aWRSOF9mTnhqTzlxd0QtNUp5cHJTZEhMcE9ibGhMc3N4YldmSy1SRlpldW8zTXFDVGQ1Z2ZhT0E9PQ==
"Amazing, thank you!",r/machinelearning,Z0FBQUFBQm0yeGJmczZJV3ExeHJwWDZJR3oyZHhrdk1WZkJiNkplYi1sSzJNeFEwQXd4RWEyUE1UQ3J6N0VybXFNdE1ZMDZuLWVubHYzTWlLcmtCOEJ3VTc3M09mN3dkLWc9PQ==
"Came here for that. It remains golden until the end:

> But maybe a better question is: “What are we going to
do with these detectors now that we have them?” A lot of
the people doing this research are at Google and Facebook.
I guess at least we know the technology is in good hands
and definitely won’t be used to harvest your personal infor-
mation and sell it to.... wait, you’re saying that’s exactly
what it will be used for?? Oh.


>Well the other people heavily funding vision research are
the military and they’ve never done anything horrible like
killing lots of people with new technology oh wait..... ^1

> ...

> ^1 The author is funded by the Office of Naval Research and Google

His CV formatted as a MLP sheet is also another treasure",r/machinelearning,Z0FBQUFBQm0yeGJmTjAtSktrRnBqVFNfYUltM3BqNU9pQTB3d3FUTXR4VzJJVjhBS2xtemN0RWJUTjRhNWpZdVZXdk5HVDAtdVdCR2twN01TanQxaU5qdUl5SGhnYW02TUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJma2NrT0U2NlBMLUhPLXFvMW90X01mWjZGLVdZVlhOWlR1UzNtUlBQUC03dTFzTVcyUjY3NXlCbnJBMGhsWVNZSGVqenh5NE5UZWVnakNka3NxT1F6c1E9PQ==
NeRFs,r/machinelearning,Z0FBQUFBQm0yeGJmczZlcTE1WjFfbGd1YVRlZFlkejVQdjJvMUVfWldZWGd1cHVEWG55LWZzODFaM3NockxzT1RyYlFjMFA3SDZwdkhoWDh1WFVSMVBscExMdGgyZ1V0SU1NWDlVeTFvdHBWQ1RKejRGeUxtNEk9
"as someone who as built time serries models for years

i still ask, what is the point of all the foundational time serries?  genuine question",r/machinelearning,Z0FBQUFBQm0yeGJmRDRDTXhtYW5YR0V1RFhfMThMOUoyQVBwRVZ1c05ZOGlDRGhlTElCcGFLcUl6RkxhQnV2RlZaU0RuWWlRNG93UUc0RUtteFpsTWJkREwxLVpreDVMaEE9PQ==
"Try out Filestage, there's also a freemium plan which does the job [https://filestage.io/](https://filestage.io/)",r/machinelearning,Z0FBQUFBQm0yeGJmWm9NbFhaRlJEZE8welpVX1hORVduYlNIa19iM214Z1VfaWtmNGVkMzU1bzRqRW1qMVFYSm5RVUR3dFZKOG1HY0VXTkNCYm1jM3N3LVh2SlpCWHQ3enc9PQ==
"Accumulate co-occurrence statistics between all entities A and B to form a pointwise mutual information matrix. Use SVD (or implement a gradient descent matrix factorization on GPU) to factorize it and you will get embeddings of all entities in A and B, and their dot products will precisely approximate co-occurrence. 

This is the same technique that trains original word embeddings on raw text data, but it can be applied to any data where you treat A and B as discrete and not symmetric entities (eg A=job titles, B=skills, coocurrence statistics is gathered from CVs & job postings and then you factorize, and you have the basis of an embedding-based a HR recommender system). This always works, provided you have enough samples: https://arxiv.org/pdf/1911.02639",r/machinelearning,Z0FBQUFBQm0yeGJmZU83UDQ5cmpzSGFuZWNWRXZEczhzQmNNaUVDOTFHQWFPNDBnam5hNHRYbzJoaTFkNFBLeTBwaDU1YVRTcE9Na2RHX2tWalBaMDJpUEp3eDRUYWNWN2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmaFlNX2E3MHE5SUpzR1o0QWZwbFJiYk1McUhJYWl5RFNXdDhER2pKWTFWanVGY2o1TE1VckcyOWNsdExFMWowVWlnNlBKczZucWF0MU5fWFY4MzNxQXc9PQ==
"Also, train on an amount of data dictated by the scaling laws we know now. Maybe lots of data filtering etc. like the phi models?",r/machinelearning,Z0FBQUFBQm0yeGJmb2FVY09NTHVXX0YxM0dMYldVSzdyWEFtVmg2U0c2amU0bzg2NjVaZ0xCMHlSbGhtZ3ExRWlob1pOZDVldmh4amZRclBZamZJNmtQZmRYS0tVVnBobExsRmczRHcxdzVDWU5fWTVHMVpJU1U9
If not Python what do “real” ML engineers use?,r/machinelearning,Z0FBQUFBQm0yeGJmRGZJcmp1VURWMHRvYWwxb29EZmFZWGZkS3ZqTGstNTFKY3J1TUpHVm1NSE5JWFZHelVKQ3UycF9Bc2dXeXZxN1ZSWExnLWxBOWQzaU03YzNTRVlXT2c9PQ==
"The other comments are correct. I am qualifying: Use gumbel softmax during training, and softmax during inference, typically.",r/machinelearning,Z0FBQUFBQm0yeGJmc0w5V3l0LTRaYU1LLUtXaGxZdmZ0R2RDd2xqU0lwTlNFSmQwd25kQzA2dFJXOTR3R3FqM0xBb2FiUDJRMHVOTHdoemZMNnY0QXFYb3RKUlNDempIcXBDZVJyb0hsM25xZnpvT2JhRHUtOVE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmV051RlBmaVlXNEMzVVVjTk5HWHlBNXhMT0V5RU11bTBjUVpfR2Y2aHNSdF9USUJKNll4eVZyZGJqeGQxZThFbGJSMFRaSHFmU1BMZ01icnNQVEZjU0E9PQ==
Could you pay the participants.,r/machinelearning,Z0FBQUFBQm0yeGJmNzB5ZkUyX015UmltUUdEZTZkaVlVVU1oRzhGS002cUk0R2FWT2N2N0Q4LVhSblM0bjk3NGlKWWJpRDNaZGJvODFlUXJLRWlWd3VrT1ZFUFRWbGFBZU9zekNoYmRyNnltWTNRTEN5bnBXQmc9
"So your final encoding is sparse counts right? Sparse sounds good. Counts intuitively sounds odd as an encoding. It kinda goes against the idea of pre-processing. I am a bit unaware here. Are there papers that discuss using counts as inputs? Or do people typically also ""pre process"" the (embedded) counts into features?",r/machinelearning,Z0FBQUFBQm0yeGJmcFBfdW1wTEpUVjFaREZyWlZneTFiS0Y1Q3ZpaFR4YUdBdl9uTS01QlJyS2ZlSkcwVk90MEpzdGZsQUpjRU9LbVFUdm1DNy1lX3hEb1lieW9WR09JSU5pZlRBQUFvVGtqN3ZOOXBkQWdhcUk9
"Hey, there! Recently I find nnx is merged into the nonexperimental version of flax, I do not know if it is going to replace the current flax style?",r/machinelearning,Z0FBQUFBQm0yeGJmR0hnTUhKV0d2bUo3c1ZuV0h0NENSUXVpM3IzbFFUU0E3RWp6SnJXdlVGMEtZZWlKcUwtbHpRbjVWekJ1TWNmdGxveC0zYm5PbEh4Qms0V05UZXpXZVE9PQ==
"I’m in a similar situation. I’m starting an internship in September, and what I’m doing is reading some of the papers authored by some of the team, trying to sip industry specific domain knowledge, and trying to find projects online that could be similar to what should be expected of me.
Try to have a conversation with them, see if you miss any specific knowledge that you could try to bridge ahead of time.",r/machinelearning,Z0FBQUFBQm0yeGJmTGs4SDBpNTBvVnIzc04za3VIclFicWR6ZjlJR3E5NjN4ZnA4YjFTbWxYWlRHVzJ2S0JnVHJQZXh6RkpyVU1JaV85Z213UHdJOHlMVUg3UnRRNkRRYWhud1RjSnJvalZObFlYZVJZWVlyZnc9
Sure vote me down because you failed to invest the ten minutes of efforts to fix it….,r/machinelearning,Z0FBQUFBQm0yeGJmajJrdUZxUFJWN3VFVXNybjNsTUFrS3lSRDFtX3l0cWtJZ0R1TTV2dVBvWW1HVHdFY1hFLWVHMTdyYk9hMGpfalplTE5UVVU4U0tDNEVPX3dZR2pYTE5rWDRoSlM3cXJHd1VQZE53Uk1LT2s9
"The NTIRE challenges at CVPR are usually good source for getting a grasp on what is going on. They had an image denoising challenge last year, I believe.",r/machinelearning,Z0FBQUFBQm0yeGJmNDZMRUdISzRYRWhKOTEtRmJqN2pxQTZWYVNSSk1Ib0hDUFFsN2twLTdKMFp3SXBJWmFrSkZjTWp5Yy1RSjVBeTZvck1XOHpmQk10dzJPeTlpbHBRdVJEQ19IQVNrb0NqamtSMngyR1FJd1U9
People around me use Illustrator of Affinity for that purpose.,r/machinelearning,Z0FBQUFBQm0yeGJmRnEwWHh6dXhleU9kTnhGVU4tZ05Sdzc0ZFQ0dUVkXzlXejRKTHZSVDRCLTI1YnBNQ2NLckg2QTJoZ0ZJNVpPU2paZXBvLV9sTkJpRHNSYWJCX201cXNlQmRaY0NUd1dxVFFBTXBXSXRETW89
How are you planning to scrub PII from the videos?,r/machinelearning,Z0FBQUFBQm0yeGJmdGlVLXNSaHg4UGZqOVRzT29QTnp0WldkSVVxNGMtbEtNaXoyOFduanZ1eDJLbWptVHFFdHFfdmZuU0x4YXNWUUYzejFpTlpLVHJBRHk0VWlUbTNwT2c9PQ==
"Yes, many publications at top tier machine learning conferences make use of these frameworks. They are general gradient-based optimization frameworks so they are quite flexible.",r/machinelearning,Z0FBQUFBQm0yeGJmeXRlRThxWnFPS2M4STIyTTF2eFliRGc1dzRxYUFsVjJ3RHFZZVZ4cHRrLWdGLVlnd2lvT1NfbFBKSUxsb3JUM0dQQmRlTTJaUjVWcG94Tjk3dG1kSkl3aUdwalA2bDBSMFFVRkVMWkowVDA9
"the paper accurately addresses the current limitations of DL and then managed to come up with a design that negated nearly all existing downsides. It had numerous innovations that all in tandem worked to create something amazing. 

Papers with big architectural changes that perform better require an intense understanding of ML, creativity and godlike execution.",r/machinelearning,Z0FBQUFBQm0yeGJmUVRLRXliTWRHRU00RzE3aGdoaFl1STZnN3d4eC1sUXNFX0dULU1IdnkzcHN0empwQ2pwcFlzOUNBOWNLaktrOXVvOUtyTWFjSHBEdm1XZXJvakVxTnJrWXpJM1lJbXF2dk15TC1WZjhnYnc9
"I have literally never heard anyone label out-of-date or otherwise ""explainably wrong"" information as a hallucination. Can you point to an example of that anywhere on the Internet?",r/machinelearning,Z0FBQUFBQm0yeGJmUkphV0ZsSUdGaVEzYXRsbFNqM19ia0ZUQkdRWEh5S0VSZm1PelA0UE5maGcxYUs0QzA1NGt6SWpaZmppUlFocjNyQjM2ZnEzemc0RDc0eVZqYTNTUmk4LW81d3BUOUtERWZHdTRxbUlKYjQ9
"If it is just lines, you could potentially look into Hough Line Transforms.",r/machinelearning,Z0FBQUFBQm0yeGJmZXd2TmFybnVqdjl6SXBFSTQwNERkakNZeUlOSDdXR3ppVElSdFJENlg0RHpfTG9DRF93TE1LNGZDY2E3VWg2UkVLeVJ5Z0xmenhQdGV2bHBDLXF3VzM5ZmFCYUFoZlZnY2FwZlhVaUVSOFU9
"Is there a central repository where somebody keeps track and summarizes the top architectural changes in LLMs?  

I know of course about arxiv, but I am thinking of some expert who filiters out what the best and most important changes are, and highlights those, out of the many thousands of proposed enhancements.",r/machinelearning,Z0FBQUFBQm0yeGJmWDBUc24xVko5amtPc2ttWVoyV3VNR3hNMHZiZlhHOXgtNUJZZEN2dndrVHlTcWtFSE9ycWYwVlJRdzlLcmpLem5hbFUyMERSbU56ZUNBWXY5QlhkVnc9PQ==
"Why is the part number part of your rag results? 


Not everything needs to be an embedding, part numbers and the such should always be indexed",r/machinelearning,Z0FBQUFBQm0yeGJmem9jRktvZW96UFVKWEstVHAyU0VlTktTb25fUVZiTnFuZFZ6QVVwMmtrUm1lLVJWZjVNOWYxRGQ4NE13b2g0U25ycllBX0tYaEJRaklJang3Q1JJUTFLYXBQWjRqLXVKUk1obVBmQk55eWs9
☝️,r/machinelearning,Z0FBQUFBQm0yeGJmTl8xenE3Sk4xZWhjVTN2cV84SVFUZTRPOEo0d25fREo4TE01OC1KcFN1M2VXbmdyQmpBMFBWX014amRFMDd2TVBJQWdZVVpuUTN5cnNVR2QzZWNFZnBQNXZuZVB6UDNrWm1YQTc1Rk1JNDQ9
You should look at your data and make smart choices and what parts should be embedded and what parts can be indexed,r/machinelearning,Z0FBQUFBQm0yeGJmV2dnZUx0WEhHNkItZHdUSmh2cTFEX1RlelI4SVlzaVJwWF9VLURRaUJUeDdKcldZLTFxbDBzZ2lfdlFFVVFrY1JGakhzdDEwVEhGNkZuUGN6SFkwckZ5VV9PbloxNFpXSTB0YmZ1NmRpdnM9
I use [originality.ai\\/](https:\\/\\/originality.ai?lmref=2crdvQ) and I have not had any problems.,r/machinelearning,Z0FBQUFBQm0yeGJmUkRtMUo3NDgwMzdQaC03Um1vMVhfcXZTejU4aldobW15OWg1SEs2V19IUmtqXzkxSDVMODE2eUNENndHQ2lJTkJPNkdLcTk0NnpCanFqeExwVHpRb1VlaVU2WXZpdXRXR0RYTldXNmRnTVk9
"Let me see if I understand:

1. You're being asked to build a predictive model

2. Nobody will give you data for the model (wtf)

3. You spoke to subject matter experts to see what kinds of features they think are predictive (good move, but they probably have never seen the data either, so their opinions need to be verified)

4. You took a completely different dataset, created the features the SMEs told you work on the real data, and (surprise surprise) the results on this unrelated dataset are not good. (worth a shot, but what can one really expect from such an exercise?)

5. You presented this to your boss (I don't know what context this is in)

I think you know you need to put your foot down and get your hands on the real data. Do some internal networking/reaching out and see what kinds of data you can get your hands on. Tell your boss you're frustrated and have exhausted all other options. Talk to your webmaster or IT folks and let them know you need access to the data. Godspeed.",r/machinelearning,Z0FBQUFBQm0yeGJmdUJ0aWszU2JFWHpQUVhXV3BIbV8taG02akNYZngteXpSSGRSRWxfcl9RczFDdTRVMVNQQlRDNl9sQ0YwOVBZTGgwQkdaenNBR3lrNTNYM21WS21UYmc9PQ==
"I don’t think he meant that ML engineers don’t use python. 
Using notebooks is not great to learn more “proper” python programming, which is sort of (?) what the leetcode style interviews try to measure. Notebooks are good for some exploration, doing something quick and dirty, things like that. 
So if your knowledge of python is limited to what you do in an ML notebook setting (load up some data, clean it, train a model, print the evaluation metric), you’re going to have a hard time in the algorithms and data structures interview.",r/machinelearning,Z0FBQUFBQm0yeGJmZFZxUnB0Z2o5X01SazhjQVdvYTh4S1RfakJSZnhOd3puRXZXaVE2TllxT0twcFhhWkNDckR3X3JWV2lBdXhVX2hyMlhsdnd0REI4RklaTUVzS28ta3c9PQ==
Yessir! Read my mind,r/machinelearning,Z0FBQUFBQm0yeGJmd25LVzJMdnpLZERQNE9QSDBXUlB3N2xES3JSXzliVlhTbGpleWo3cjNMV0R4Zlcxby1heDUyN1Z5eTltTllWNjhld2l6RkpkWUZpZGdxZGNua05iSWc9PQ==
Thanks a lot for the solid advice. I am definitely doing that rn !,r/machinelearning,Z0FBQUFBQm0yeGJmRl9pMXZkckpJZXpKX1V6NEl5aENyNG1IVHZmNXpkLUVSbmxuSkRoUl9mR2xUakIzdnZEMzZDUlBFUWIwTEtSUHpjNjg3V3k1Nzhfbm01Nl83Vmw5c2JFU1ZtWlMyWmVZME9aSGszbnRNeGc9
That would really be a useful thing to have to keep track of all the changes.,r/machinelearning,Z0FBQUFBQm0yeGJmSUhNUmhFVEFpQTNZZWxwZDJGZkI5WkZjSXVJdEdteV9kMjgzejg1N1lfOG1jdTNYNERmYWgyRGJYOVZVdjhFalJScm9rUXhncmN2aW5FWVlNUk9PNEE9PQ==
"I am personally curious as to why no one is trying weights sharing anymore like AlBERT did. I like the idea that all the ""abstract tokens"" living in the same dimensional space.",r/machinelearning,Z0FBQUFBQm0yeGJmaVZMdU5CbzB0Ukkyai1KWFlqT3lpRmkwbDBwbVB2UkM4ZG9JUmhGSEVUNDR2WWpjNWFQbEoxemk2SHZmN3BCb0xkR3dKNUpJM3czM0ZoWEV3WjdpcUE9PQ==
"Here is a strong example of a prompting strategy for multi-choice QA:
https://arxiv.org/pdf/2311.16452",r/machinelearning,Z0FBQUFBQm0yeGJmZUV6X1YxQ2dwcEZfeUZyaE9RMmU2Um90cVNjUTF2RXR1WjFLWG84cmxVYVVQRXFzM0JCZ2VpNjRaRlU1QnE4MUIwZVdOcXh6d25PYk9uU2Z5Mm9tRmc9PQ==
"Very late to comment but if anyone's interested, [Hyperstack.cloud](http://Hyperstack.cloud) have a really great tutorial on running your Jupyter Notebook on their GPU cloud: [https://www.youtube.com/watch?v=K7CD8cpHCJE&list=PLmxiuj8lAPFKqatdk-dqRFeXPdDsNpJ-j&index=3](https://www.youtube.com/watch?v=K7CD8cpHCJE&list=PLmxiuj8lAPFKqatdk-dqRFeXPdDsNpJ-j&index=3)",r/machinelearning,Z0FBQUFBQm0yeGJmSTFLTFpkR0N3ek9Fa1ozcW9CN3N1TTdhRmRIdjhYbXhVSXhtRGdlQ3dJbkVuWGtQZG51R2xOckZhQktQRU1TVTEwYmtiamhmci13MHVkdzhmVHVkb2NYajF3LXdGMXU0RmVqVG5fWFdOMU09
"Edit: What you describe is not hallucination but just a wrong prediction.

The model outputs would be deterministic to an input. Of course if the predicted „raw“ next token probabilities lead the model down a wrong path that still results in a wrong answer. However, this would then be due to training limitations, the dataset not containing the necessary information or the stochasticity that is inherent to training. I would not call that hallucination, because for these reasons any type of model can give a wrong answer.",r/machinelearning,Z0FBQUFBQm0yeGJmUE1kMVR3UzE2X0VZNFdTTkxxV2VvaWVaRDItVjhtdjhXWFpIRU9zWVk3YkxPSElnR0ZDYl90ZlhPUmZXU0xxMFNtTHNxcVNFQVpoX1QwNWpGaFNPVnc9PQ==
"Joseph Redmon has a good heart. It's really hard to live on planet Earth in 2024, live those kind of values, and thrive, especially in Western society. I hope he finds peace and happiness, and the benign part of the science world is ever the worse for his absence.",r/machinelearning,Z0FBQUFBQm0yeGJmSUxVNDc4cjRMdG9wTDNyVWNMbzQxNHlJOWp4LUo0RlhqRXp0bGV0QXgzZ193TlZtbk1KaktIcnpkVkVzbWF0S2lOSVFYcllRaVp6aHlSYWlGemFBTWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmZW44UjNGV2oySjNqODg2NFhSZE9DdlBKMFI0RjV4SkpxVmoxbzgwUjd0eXlQRi00T3NCUUR2QzY4ZnQ2MURLWDZ2QmI5T2lSM1VfWkprdTJ1cXExOHc9PQ==
Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJmOUN4OHA2X0xJWjdYVHVhaEhwZHFvMEVnbXR4VUZROHRxQlJuYldpYXlxeUJLMHBZS0M1OTVEMkRMeVhMc1NWSTMyWUlSOXRBWEhFc0VuZDBGRjdTUVE9PQ==
"I am curious on the legal parts and licensing on using a chat bot

Let’s say I post from chat gpt creative content.  Does chat gpt own that?

What about even chat assistant?",r/machinelearning,Z0FBQUFBQm0yeGJmay1vWkpDWXAzZGdpSVdqYmVBRGNCN0JBaFZlZVp6cktwanlJTjZabVlZZ1FYZUJvaDE4ODJIT19pQmRYWFN1UmlKS3J1S3JUSmVOckRMOXZ6T2pzU2c9PQ==
If you're not obvious nobody would know,r/machinelearning,Z0FBQUFBQm0yeGJmcGpuRXRJUnNZQ2hvSVVzTGVwYUJqTzZxM0Y2WldCTHpEa0h6OF8yWkc4YU1RZmxYWG9nZHJSalZVSWZLZTFmcV8yT2xVS0Z2ZlQyNk5ScXZCYUhXZ2c9PQ==
"More than likely this is fine. It's roughly equivalent to having someone proofread your work. I would say maybe check to see if the conference/journal has a policy on the use of LLMs, etc. though. That said, if you're using it in the way you describe, no-one is really going to know.",r/machinelearning,Z0FBQUFBQm0yeGJmSGFZc3NGNjB3bERHZlNqZGRNb2ptcVQxa0Iyd0w4T1VUN1FXSjFROGMwZVM1eGdkZ3FsS3RCZHFmTnBnZUJhWGlZdWFleVBENk1DeS1nYkZkQk1IcEh0bjZCNUk2LTRkcXlLZU5LNl9iVGs9
"What are you smoking? That’s pretty much the only way people talk about hallucinations.

End results are always the most important thing. When an LLM makes up false information nobody cares if it’s accurate to the training set. If that’s the case then then either the training set is wrong, the algorithm needs improvements or both.",r/machinelearning,Z0FBQUFBQm0yeGJmUlZVUm5pRmxLWlRBVXp3Uk8xNlpYbjhRanM1VDN2ZWp5N1R2RG93Ykp4QlVYeEFxVlNMR2N2RDA4RF9QblhES1F6MnBldHVWOUZZSUFtNnJRMHZwUVE9PQ==
"Mine is just LeCun 98, Efficient Backprop.  It’s how I learned the basics of NNs, and built my first network.  My uni didn’t have faculty in the field at the time, so everything I know is self-taught.",r/machinelearning,Z0FBQUFBQm0yeGJmc1lrTnhFc0p4NjJqOVZjT1NmcTdYNTVRRmp5SkdoaHhXaXZ1a3VMNEg3TjhqWDVWZXpDUmk4MGw4SlBHRkdfYnlOOFEwMGtBclVfT25CUl9hYWkzTFE9PQ==
"You said it. The evaluations in the paper are comparing xLSTM to older models (e.g. Mamba 1, Llama1) and in smaller sizes (IIRC the largest is 7B).

In my own experience, sLSTM is far superior to the original LSTM, but I was not able to make the mLSTM work. It is likely to be an issue in my implementation.",r/machinelearning,Z0FBQUFBQm0yeGJmdm9JMWlxQi10M01IMzhMYzdycmVmTk9WWXlnRVlIYnVYTEh0RnNJRDhKU1h6ZHVTRG4xdkxGR1NobjJUSTV2UllyZzQ5RHR2UWlmN3pnaGdVUl9saXc9PQ==
"1. OCR the frames

2. Run NLP.js to extract entities e.g. email, name, phone, address, etc

3. Replace the entities with blacked out markings and the entity type on the input frame

4. Save the redacted frame (output looks like a classified CIA document)",r/machinelearning,Z0FBQUFBQm0yeGJmelhFXzQtNC1MdWE2d0ZQaHFoSDRVN3Q4dXZZSld2c294UmJ3dHVJbGsxVi1PcGNmWWU2bUh4Y2lkbTctTDUzcXRBT19RN3RTc3EyZTVrS2pyMWhKanc9PQ==
"This is just poorly phrased. What it means is that each update is first weighted with the input gate's output, then at each further iteration by the forget gate's output.",r/machinelearning,Z0FBQUFBQm0yeGJmWW92bXFwUkV2OExQNVJ0eWd1bkdxNkFxTHBDNWpTNy1PajNjemN5WmdyNWlqWU14eFdNMk1DOE1wQXc0eGlfM3BPZzZScFBkSmdjNTcyRnk3Rmlxa0E9PQ==
It depends on the type of block you are using. They recommend post up- and down-projection for the sLSTM and pre up-projection and post down-projection for the mLSTM. This is described in Figures 9 and 10 in the paper.,r/machinelearning,Z0FBQUFBQm0yeGJmMkQ5UHFpOEhXS2ZfZHB6Y1hFQm1kejJLWUEzQS14dDFXTEhHRjhoT3pGSFNUVS1PcVl6eGxRX1VaMUVhRVlvWXZWellGbnRmTENzLU83aG51NzVPMEE9PQ==
"Technically, a cell that is not cleared or written to can remember indefinitely.",r/machinelearning,Z0FBQUFBQm0yeGJmZUdPMDA1ZWtaY1RXb3VZWURXZklxeGtwdVlDempGUGJtd055UWdGNnRXZFBIVFZqaHNzVzl0TXRZNXAtX3RtMDhQODlMa2JESXJCTzItckxTdVg5UkE9PQ==
"As someone who got into the NLP field more recently and might not appreciate the significance of this, can you give a brief rundown/or point me to the right resources to learn about the state-of-the-art for Multi-task learning systems before large Autoregressive language models came and disrupted the field? 

I just took an NLP course at my uni and we covered some of this, but would be interested to get your perspective.",r/machinelearning,Z0FBQUFBQm0yeGJmVkZtaTFmOWU5OUxpaHhjNGNpUU53WV9MSk1lZDRudDhoY3FCc2VMZmM0dXowQ0pYRUM4a25CbUxFYldWOWdRa3ZzNjBXWjNkaDJiVS1sSF9yVFNzVmc9PQ==
"If I understand correctly, the memory matrix of the mLSTM can be computed in parallel.",r/machinelearning,Z0FBQUFBQm0yeGJmbXlQZGttNVpIY21GUFNGS2FfMXNsb3JTcnNFVjZxUFVyQzEwY0x0U0tZNHc0U19WN0J0aXI1SzJ1WVNSMDlqR1dkSEFrTG5YcEJvTnNTWjF4Tkg1ZkE9PQ==
"That’s why I am asking bro, that is DSA mandatory or not for DS/AI/ML",r/machinelearning,Z0FBQUFBQm0yeGJmV2Qza1M2ZTNFLTg5bGRaZ1E5dDQ2TzJER0JHUnhwQjl1X0lFQ3BvcHhrQUlUeXlvZXhLVTNLZUlTM3pweURucEhvMC0weGt6cWhCWWVvYkdVVzVGUkdEUXh3ZlUzNEExbjVhQXRRN2FZdjg9
[Hyperstack.cloud](http://Hyperstack.cloud) actually own all their infrastructure. Super secure!,r/machinelearning,Z0FBQUFBQm0yeGJmN1J1MTh3NHFHUXVMQllCT0pwV0VmUHpvaHhCRllkODhrOGh4UjZfRWlhWjByUnNmN05id1RLZi1WVWM5SkQ0V21wZEJVY095Y0VjRGJ0ZEhpWFBqMGliYWVsZEgzX25rb2tQdHIwWUFoNzg9
"I’m a CS major and I want to pursue machine learning. Where should I start? How should I pick where to start? There’s so many models out there and so many things to learn. 

I’m working on a Flappy Bird PyTorch program. But I want to learn a lot of the theory behind machine learning, especially the math involved in it.

Any advice would be greatly appreciated!",r/machinelearning,Z0FBQUFBQm0yeGJmbm1mUFc3c1VpWUM0cTVoSnJtZ3p1T1hfVnNjQ2tfQzZ0UEJUNENHWTYyeXQwcl9EWHZnQl9CRnIxSjRodW5YUnc0azgxLUpGdXVwMVRwalF5RmVKMWc9PQ==
"Improving writing and grammar is generally okay (although not for some conferences which explicitly ban LLMs), but make sure the arguments and logic are yours and not affected by the rewrite. For example, don't ask ChatGPT to write entire sections from scratch, that would be storytelling not science.",r/machinelearning,Z0FBQUFBQm0yeGJmbm14bzl5d0M1Ny0td3BiU09taXVUZEFVS2t0U1BmemlUbE9OZEE0TFFRRVZBcWJkdXJDdVNKbGkyaTc1dWhJZU1rU3Z2NmNiS1BkNDVPWUY5QmVPX0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmREp2dW1EOE5vNS1ReEhYTUtmTGdpWVZFWV9UWkEwdmFqaUQ3RkZWZUNqcFYyRnZxT1otX2ZhZGotMzZ4ZWJRT3I4dXYtaUt3Vk4wb09wQ0Z1TlhjZ2c9PQ==
"Why not write up a full paper and put it on arxiv? It's also not very clear right now, and chatGPT might help improve the flow of ideas.",r/machinelearning,Z0FBQUFBQm0yeGJmSkpqQUxpU0lNeG5DOVI4S21yZFlkWXNsU0JQZGNlUy1FVEk4R1k3Z3JFOWZSdi05a0dHYkJEUTlWYWQzbGNoQnNBaWhJVkFubzNhc1ptZnhZdUJoUUE9PQ==
Have you considered zero-padding the shorter sequences?,r/machinelearning,Z0FBQUFBQm0yeGJmeUVNSjAwQUo3WllxbDBuSkV5cVIyTjJZSGhBZ3dCTExMVG1JeVptaUI4VWZkN25GQXlVai12QXh0LWpvSkJRN3Y4REhCaXdKaXVQWFNocjZ3c25GMFJoenh1TU01bVkzZFMyamdhNWVWN2M9
"I wouldn’t use it to write anything novel, but to revise. Even then, I would ask for generating multiple options and combine those options into something novel and in your own voice. Don’t copy paste or people may notice the “AI style” of writing",r/machinelearning,Z0FBQUFBQm0yeGJmZDNQUVlBVDZNMjItZ2kzRXVQMHhHY0w3dzhIUjRRTWxhWDBMSkhBM1VaVTg5ZGt2d19DQUthMUNCblc1TlNibXJHWU00M2VjRkxnYXh0cG5nTFBySXc9PQ==
"This is obviously the right move for 1 of the 2 major platforms for NNs. The emphasis is not gaming or shading or rendering. This is PyTorch .. used for Text related innovations over TFlow. Why should Facebook have to pay the Nvidia Cuda Tax by buying their expensive GPUs when they could run it on their own ROCM/RDMA ARM clusters ????

Nvidia's days are only as long as the CUDA monopoly and this is the right step in breaking that monopoly",r/machinelearning,Z0FBQUFBQm0yeGJmQ0ZTeVhuUzFFbm5jQktxN2hBNTRvYWhsUXVZT0kydFM2b1dWUUJjTkRnT1hyblhsYzQ2MllSNHlLMUhTUGZIWTgtT19yT0pmQ3JWUVhDMDIwMzRuSHA4RFkyd2dzYXJ3QXAxY0VxUk93NTQ9
"It is an extension and generalization of two very important lines of research into the theoretical underpinnings of neural networks:

1) The dynamics of deep linear networks under gradient descent and the so-called ""neural tangent kernel"".

And 2) The connection between deep *nonlinear* networks - in the infinite width limit - and gaussian processes.

Their work basically gives the first analytical derivation of the probability distribution of neuron activations in an arbitrary layer under the training data distribution for a *deep nonlinear network of finite width*. They characterize this distribution as ""nearly Gaussian"" and give a formal description of what this means. They also study the dynamics of gradient descent in this picture.

What's more, the techniques they use were originally developed for quantum field theory. This gives an interesting connection to physics.",r/machinelearning,Z0FBQUFBQm0yeGJmdnBVdXZJMXdfd0IxNWdfOGZOTnNJUkV4YjlRSFhOMUNQUkNzYVVhY1ZjS2dxU0VremRzUUtXLUY4MkgzeHZ5WW95Njc3OWRxSDd3QzFYUWUwYXk5YlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmdkJTNk9tLU5XNGNicVVnc0gwTzgxZHU1dVp2MTl2c1ZfanYtU3JkMnhfU3o4SXNFVHlYUzBiUEJvV3lCR1prOHh3ZkFuRlhkeHhkMjdMSUxMenJkN3c9PQ==
"Wonderful, am newbie here and am not sure how the companies will discuss these abstractions , as per my understanding it easier to  adapting pre trained models specific to their use case ( CNN, RNN,GAN) or start integrating their data to AI offering services.",r/machinelearning,Z0FBQUFBQm0yeGJmZjM1Y21YZnV4UG5WOVNKYjdmMEcwbGdTalJIX2sxdkVzS0t0bDNyemlibFIxUm5UdXRLNXFuaWtsSmQ1UEdzQk8wRFB6NUdIS2g4VjVHOEpPTEVvd2txZllxaERIUEFwYm5WaTFRQ1g4b0U9
"No. It is well-known that ChatGPT was released with a training date in 2021. I never once heard anybody say: ""ChatGPT doesn't know about 2023 therefore it is hallucinating.""

Please point to a single example of such a thing happening.

Just one.

Your position is frankly crazy.

Think about the words. Do people claim that flat earthers or anti-vaxxers are ""hallucinating?"" No. They are just wrong. Hallucination is a very specific form of being wrong. Not just every wrong answer is a hallucination, in real life nor in LLMs. That's a bizarre interpretation.

If someone told you that Macky Sall is the President of Senegal, would you say: ""No. You are hallucinating"" or would you say: ""No. Your information is a few months out of date?""",r/machinelearning,Z0FBQUFBQm0yeGJmNzlxTjFrS09GMzBNdGZVLTVzdGc0SnFZbTRJWEhJcDhJdTZ3QlpfOGVFS1QyYzJyZm14NWlBaktNZFpEZDFnTDIxSHNVUUZudTExc1l6STU4UGZ5MzdrRS02Mk5aSHpmcjdUaUpqamFGdFU9
"> Run NLP.js to extract entities

And is that 100% reliable?

For example may pop open my password manager and find and display an entry. The entry is arranged vertically with numbers preceding each character because I'm asked to type in the 2nd, 4th, 1st etc characters. Would your PII system catch that?",r/machinelearning,Z0FBQUFBQm0yeGJmb2h1ZDJoMGwyNTBHSWxNQlE5dkcwamEzZm9QR2hJYWVtTjNUcUJMMXA5bGZpbHdCc0JyRXpsN2FkaXA4ZWdRajZCcEJQYlN6Zk5UdEx2cEJwNTJEdnc9PQ==
"It depends, but usually yes. Interviewers love to ask leetcode questions.",r/machinelearning,Z0FBQUFBQm0yeGJmal91R29UQ3J4UGJZOGNRb1hTNVBtVXc1U19rU3BrZzNRTWM5VWlyRU5scDk3czZYeGNlVnB5WjRJS2YtZDNFV25SS25HcW1SWlVxWEliWW5TdFJWMGc9PQ==
"This is a great question. The main advantages are 1) the excellent accuracy-speed trade-off and 2) the ease of use, which greatly simplifies pipelines.

As you can see from the table, foundation models such as TimeGPT excel at zero-shot forecasting. They are more accurate than all other models (even if they were trained on the data) and have comparable inference times to a seasonal naive.

Foundation models can simplify pipelines because they do not require training from scratch. A complete pipeline using TimeGPT has literally two lines of code and does not require domain knowledge or specialized hardware such as GPUs.

With that said, we always recommend users to thoroughly evaluate TimeGPT in their application against their current solution (if they have one).",r/machinelearning,Z0FBQUFBQm0yeGJmeGZtdUZweXpXWUgwSlFnY3d2U1pTMUhpaUxaLUF3MWRFeURYSktMdklMd2JKYnRXSXdrR2F5R3BReTE1YW10TERFeDF3VzhCX2NiQ3YzTUcyRmFweUE9PQ==
Can you please explain your point #3? A bit confused with your point.,r/machinelearning,Z0FBQUFBQm0yeGJmQUI2a2VWV3BlQ3dHVHlSdTBJUXgwcnM1VzJUNk0yY2E4eE5MR0tadTV3amNRNUgxWWJQTmZ4NWdhOVUxbXhoZ1p5UHVudk44TmlxcEFaZ0hoRDlZUWZzZmlNUjBYYTNLVm92d0Rack9xaDQ9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmRVlpUjlNZXV4eVNnTVhqMVZicHdhWEtmaUtOa0dwZW16b1NRNFpvOXhzX3dCbTJ2bnpaYVZiZVhNSF9VdFVJdHRpVTFJbzJlU1JTdWFOaGxjM1BSSEE9PQ==
"Thanks for sharing your thoughts. We also discuss the case of stock data in our repository (see link above). Financial data, and in particular stocks, are extremely difficult to predict by only observing their past history. The test data that we use in this comparison does not include stock data, and it comes from entirely different domains and applications than the data we used for training.

We believe that the benchmark arena we are building and the results we are showing represent many real-world applications and demonstrate the potential benefits of foundation models. With that said, we always recommend users to thoroughly evaluate TimeGPT in their particular application against their current solution (if they have one).",r/machinelearning,Z0FBQUFBQm0yeGJmaGx5ekpjZlVRT21tZHdWNU1UaGI1cmR2WWI5ZWVZeUZVenZWUVZHX1Q4SzhBSWJYMTZ1clpjTXN0dUJETlFRSDZoM1FLb1lFVzRDTVRqTDRXdEFBU0E9PQ==
"It's actually an incredible explanation and the only one that truly explains it well.

The core idea, and it's not something that I've ever thought about, is that the dot product of two random vectors, is zero! This is what is implied when you say ""The intuition for this is that randomly chosen vectors in high dimensions are almost always approximately orthogonal"".

I honestly would've thought that when you initialize a new neural network, the attention matrix is random. But it's not. When you initialize a new neural network, the attention matrix starts out as all numbers being almost zero (After softmax, that gives you random probability distribution though. But, attention-before-softmax being all zero means it's easy for the neural network to quickly learn associations and make particular attention values very large relative to the rest which are all tiny / close to zero).

So, the point is, if you take (Qx)'(Ky), and insert positional embeddings to get (Q(x+e))'(K(y+f)), you can do some math to rearrange that to x' (Q'Ky) + x' (Q'Kf) + e' (Q'Ky) + e' (Q'K f). Note how x' (Q'Ky) is position agnostic, but the other three terms just relate a token to its position (Or the last term, which is the position-position).

The important magic is: All four of those terms end up being initialized to essentially all-zero matrices at the beginning of training. Therefore, the backprop can easily learn to make x' (Q'Ky) whatever it wants, and unless it *intentionally wants to learn* to make x' (Q'Kf) non-zero, then the x' (Q'Kf) matrix won't contribute much anyway!

* Yes, the random x' (Q'Kf) will add some random noise, but the random noise is small. And, if the positional embeddings are truly worthless, the NN can choose to dedicate a dimension by learning to make the word embeddings orthogonal to the positional embeddings. That way the x' (Q'Kf) matrix goes to zero. Ditto for e' (Q'Ky) and e' (Q'K f)",r/machinelearning,Z0FBQUFBQm0yeGJmMGJYQjFsN2VJS1pKM3prNHd2SXAwWm9jZWUzb1VJNEt6NThXaFpsV21acnJJMU1PZHgwb1JqZnlIeTFkZEtWdHgxMnoycXM3aF9ydWdNWWxhWWstWWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmZXVCalRNWTlvbFBVbU13dUdEVkU3QkVldGxnbS1uR1FlVU5ZU1duMnh5bWJkOGYzR3prSkY5UURNN3RpNEpQN2hMNEdQTzlRaFA1WGhPUlhEbVJfc1E9PQ==
"Damn , hope someday I reach your level, any tips college first year student",r/machinelearning,Z0FBQUFBQm0yeGJmOUs5SlFCUU1NY1hfaTdTU3Z4Ukx5RzZkMFc4NHBTX2pkeDJfdFZ5S1RXajdNanFjSEIyZTlKeHR5dk53VEpNODhsd3FxTE83UXg4b3ZBQnBZZWFyRkgwLWtZdFNSa3I2RTBIUTFFZUFYX0U9
"It's cute because experimentally, there's almost always some transformer ""T"" somewhere in the network that just learns to make the attention 1.0 for the previous token, and 0.0 for all other tokens. That means that ""T"" learned to make e' (Q'K f) equal to 1.0 when (e, f) implies that y is 1 token before ""x"", and ""T"" learned to make the other three terms 0.",r/machinelearning,Z0FBQUFBQm0yeGJmX2E1YUl6RUpKME9yak9OSW96MEVHR1JxWFZCQk1HT2VmNFQ1QkpiYWhac3AzRUl1Nl80SEdEdXhRR2EwTlVMZnlHSWhSU1Z6X2lqdHE1a2JpQW1zTkE9PQ==
"If you are talking about arxiv, it is the most popular open-access repository for academic papers (including preprints) which is owned by Cornell.",r/machinelearning,Z0FBQUFBQm0yeGJmSTFpTnZxeUJlc19jVndxRF9lQzlOc0IzZ0ZDV05Tb3NQbnpNa3VUcXBFVGVxSVZBZnc3NTlEcnVoWDhLNWlDa2NwWGFsZ0Roa29MdWl5MlB4VDBvTUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmaHk0TXpPMkZxNEJRUTVxbWZUa0xiRExoZU03azc0ZERTQnlWTFNjbHBlZ2J2SGwtSTRvT0lPWkREY1pqRVlacFdaa1FYM0dlcHdyaEU4cTZWZGdBUFE9PQ==
"There are many, many approaches to this. 

- Classic Recommendation system, use matric factorisation. Something like ALS (alternating least squares) is simple to understand and can scale quite well to millions of users & items using spark

- ALS won't scale to new users or items, so something like two tower neural network to predict like vs dislike is more extendable 

- GNNs on a bipartite graph is the most general solution. You can train the model to solve for link prediction, where every link is liking or not liking. This model is much more complex and harder to scale, but imo should generalize the best and should overall have the best results",r/machinelearning,Z0FBQUFBQm0yeGJmekNJcWRLYUhwMnJUdnA2V3NlUmZXTUcxRENJelI4Y2VNWjVoVU9VUmFNSnN6ejZPRGV1eTBIN3dCVzQzajU2QWZscnNRZDJaS2hxUUctMjhWenRWVmFTSThzUEFsaE0yaVhFVTV5ZXNINUE9
"Hi!

I don't know of such a repository, but I have been trying to constitute a timeline of how the models evolved as a way to educate myself. It's part hobby and part education but I try to implement from scratch the models (well using PyTorch...) and I write on a blog about them, how did the architecture change and why etc. it goes beyond the architecture, I try to find information about the training and optimizers etc.

It's not exactly what you're asking but I can do that! I don't want to be promotional here so if you want I can share what I have done until now \\^\\^' 

(for the moment I'm still at the GPT models because it takes a lot of time to do the proper research. Sometimes there are just no answers and you have to take a guess based on your knowledge and experience).",r/machinelearning,Z0FBQUFBQm0yeGJmaU55dnJLYkRRa0pPb28tanlTbjc4cm5WSF92TWpMR1NoMWJyZ0huMk5BOTRzTGY3RUFpNERoZWI2MDZSS3NubU02aXZ1UFB4dkFEaFJGWXJJbnhmWTh3YzZlanZ0Ync3QWFwQVZIcFcxQ009
"Thanks for bringing pape into notice, it's a great read!",r/machinelearning,Z0FBQUFBQm0yeGJmWU1GZTJiVkhNNWZjZzVKREx5dkpBQUMtMVpEZ2RWb1ltVzMwQmpCZ1FyZUJBZi11R21Cb192a1ZHZjM5M05wbjlTYXdLUGNlMzhNdDJFZVl0bE9SZ2Y5ald4TEp2OXdlUGhwYmNHeXJ4UTQ9
"Weight sharing is a great idea! When I was reading the ""Attention is All You Need"" paper and diving deeper in its ideas, I learned that weight sharing not only reduces the size of the model but can potentially act as regularization since you learn a more robust representation by having the weights used at different stages of the model (see paper [Using the Output Embedding to Improve Language Models](https://arxiv.org/abs/1608.05859) by Ofir Press and Lior Wolf).  
  
I think this technique makes sense when using languages that share some kind of similarities. In the original transformer the use cases were translations between English and German, and English and French and these languages share a lot of similarities beyond the common latin alphabet (especially English and German). Since sharing the same weights makes all the embeddings live in the same space, I think in this case the semantics learned by the embeddings are improved. 

But maybe there aren't much benefits (or maybe even drawbacks) when sharing between languages that have way different structures. I haven't read the AIBERT paper so maybe they did succeed in doing so.

(I have written a blog post on the transformer and currently writing about the evolution of decoder-only models, I'm doing so purely for my education and hobby and don't want to be promotional but I can send you the link if you want to give it a look \\^\\^')",r/machinelearning,Z0FBQUFBQm0yeGJmVW81YWM0d1d6WmhLdzJKN3ZBd2tad0FrczJ1eDJXaFhmc3RSQWJQaTRKSjd6dmpyaF9yX1p0MFFRYkF2WFcyMG9qdklVZjZLZV94X0IyUjlmRGh3a0IyZ3lqUTBEOWs5SjYxU2NKNzlyVlU9
Glad you enjoyed it!,r/machinelearning,Z0FBQUFBQm0yeGJmS2NVcWN0aUJvRlcyd25CcmZCaUZVRWZtR002dnpzOEhDZ25OTGhhbFFZbWlQQkc2Sm9hNFk0X0VIMG5lMDJhRUQwdFNpT2YybU1KNmd0LUZvYXJVbFE9PQ==
What are you talking about? I never said anything about training data being out of date. That's something you made up. Obviously LLMs can't know about events that haven't happened yet. I'm talking about information that it should know.,r/machinelearning,Z0FBQUFBQm0yeGJmeTJCeEc1OXAxcHRhN0ZFcEpxTGVla1V3dUExM1RuV3ZKZVNKVVZiMEg2UDJBZF9OLTN2NFI1WDBaQU1mcTNHcDIwRVhRTW5ld1NwTENjM2plWGdKcmc9PQ==
"I did but I am using fixed-length sequences and data has no missing values. Basically, no messy data.
For example: Autoencoder with Stacked LSTM did massively better with 640 sequence length than with 40 and 160 (in terms of out-of-sample accuracy). However error values went off the charts.",r/machinelearning,Z0FBQUFBQm0yeGJmaWNQTWwta0t1UGdiQjlyc1NyTVp0SHNDYlVGNDlEN2dqRXFIeUJ5NnA5b1JuWXhsa0U5WmR5MFRQNVFPUkZOZlFwYXpqRkZuY3BVY3JkRTRkQnhvT2c9PQ==
"Thanks for the kind words :)  I don't know if I'm in a position to give advice, but I would tell myself is to be curious and go deep on things that excite me.",r/machinelearning,Z0FBQUFBQm0yeGJmZ1loVi1jVmJYWURQbkdKWjNNS1lrNnN4eWR5d216LUZtRjh1Y2pBSEx6aFNYWDNTOXFURW0xUFFOcW82eDlOLXdHMHFtUFFNWFVpU3R3Q2hLN1lhRUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJma3NXT0c4ajJrMEloeUR5aEtIMzdvQUt4bGU5cDZYX1hlaEVYejBoQjI3a1I1RkZNMF9pZnExWC0yUWo2dkJuMC1PV3U2eE5mWXpsak5rYm42R29keEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmbWVKMnByaE8tMHZad2c2WWJZXy1ONWlUM1FKMW1YUU45ZGFsTmRSZUN3MUlwNVJ5emZHMDQ3YmIyWjZWWDU4MWJpbEJNODRuU2hiaHZHZ0s5QThxeHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmNXdDMnpKRnlNN1dpSHB4UUVDVDFqZk1hZl84VUZtN3hab3lQUFJLMFFiQ3hnV3ZwRDlweVZDemJCNlVEeXAyNnNoeFJIU2Vobjk5aWtFaXNFWnY4Q0E9PQ==
I'm glad and a bit worried that people are getting something out of my comment so many years later because I no longer remember my own thinking about this and certainly have developed no deeper (probably less) understanding of this topic since. Getting dumber with age.,r/machinelearning,Z0FBQUFBQm0yeGJmaXdKa3BENVBPT291S1VMMzAxZ3NSa21hdEJZZDhVSWVxRDFXbjdwUE5EVUNibk9iZkNFWFM3aHlCYk52X0dLaVhmdFV3NGxSOHV5WlpWZ2pJb3pQNnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmWkJmeXpfMkJVLWpzV0hWQ0hHb3ZGNUxHVUFhRFluY3NGaTFhTHIwcWpWQThkMVFWMVNGaW5kdW5lS08yZlhUMGVwV0FUa1dXa1FrcTFBLXVWY1BhWXc9PQ==
"Hey! Not the original commenter but would love to check out the blog, could you share a link?",r/machinelearning,Z0FBQUFBQm0yeGJmT3NzQWFNQUJUdnNtbUcwSnIxXzZWY0VaVHdWM2VIdUdaQTVwSlp3QlFCbjFnZFJHZGdOdlp5LUtFcHFvTUhfU3E2WklDU2hRdjhZX1ZSVTJlZnpsRHc9PQ==
"Is anyone available to make a quick research paper with me on deep learning, using/without cuda and its tradeoffs with computational results for efficiency? We do something similar as well. Is anyone up for it?",r/machinelearning,Z0FBQUFBQm0yeGJmd2VWWWNlLWc5QW1laUx1Sktvb0x5UjRKajcycmNXSk84Z25lSWlUS1BDTmI1eXFGRFhpb0dFS28ta0tMR3V4UmJaNWlMc3hYRy1reXBrRl9LcHVNQUE9PQ==
"The example I used many comments ago was:

>If the LLM says that Queen Elizabeth is alive because it was trained when she was, that's not a hallucination.

[You responded](https://www.reddit.com/r/MachineLearning/comments/1d329nt/comment/l69f82z/) to *that specific example* with:

>People care about end results not the training data set.",r/machinelearning,Z0FBQUFBQm0yeGJmbUFfbUY1dHlyNDRFVl94eFBVbVJWZDhxQmhWeTZWejB5bllvT1dwYmE4cVVHVXJ6UEFuWGtQdXFmS002R2RTeThvSFVhS3ZoYksxZklmUE5HWHo5a19fWVhmOFlIR1VTTUR3YkZaSjBjTEE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmbTVkOVJacVB2ZXVXN01PNXdDNXlxaHpEY01BTWVneVllbTY5YTUtMzh5cjd5bDE1VUZTSkhKa3FKeHREczUyLV9qT1o2dWJIMmRPUGFYNFd5ZWllRnc9PQ==
"It seemed obvious to assume the LLM would have an up-to-date training set. If not that would be a very strange way to direct the conversation… 

Like I said, obviously LLMs can’t know about events that haven’t happened. I don’t think most people are talking about that when they talk about hallucinations",r/machinelearning,Z0FBQUFBQm0yeGJmYzd0MExNc3dkOUc0cGoyb0ZKNzNFcmJNS09rcWtFRzU4QVVDT3ZJRV9taV9abGhKb0Q5V293NHpMdXBwZ2ZGUndOblBKU2hHTmVWRkZTRFBSXzRWOVE9PQ==
"A little elbow grease and I got this compiling on my Mac M2 Pro. Still haven't tested but seems promising. If the RDMA network is not User space affecting like Oracle this could be a big deal with literally 1000s of Arm Cores being managed by Vulkan Compute (GCLIC headed). Text generative is very compute intensive but does not need the Graphica part of the GPU

  
[https://pytorch.org/tutorials/prototype/vulkan\\_workflow.html](https://pytorch.org/tutorials/prototype/vulkan_workflow.html)",r/machinelearning,Z0FBQUFBQm0yeGJmNnJ2Tk9aMjAyRjJIdFlCazA4V3gzTG14R3FJd05TMlRnRXJTb2hBelVtUl9YUFFmNUZlR3V6MGpuLU51UFh0VHNkWXFRS19YdVBJRWlFVVUxSmV6RTk5WU1LNGpyNEh3TEcxRHQtRlJ6d0U9
"Interesting, I feel about word2vec the same way I feel about Attention is all you need - an absolutely groundbreaking work that is a really hard read.  Both could be presented better.",r/machinelearning,Z0FBQUFBQm0yeGJmaWdzQVJHNEJRSTdRLTdzWTRPNzR2c3JZQXRjZjR1Z0dwbkFfakNxYjFra2NLQ3dFWnN1NGdxYUN2Rnd0bU02TjZEUWNsYlpkUXlmY3RhVFVPMldSMGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmenFNeDczalF1MEYxYV9SZmttUUxpX1doYVFiMWxpYk5sdnJSd3YwUmhJNl9VZGlRUHRKaUZRSzdUOHFTVktSYjZ1Y2hRRi1iZzl3V0V0MzhUd0pxT0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmRWxBelpENElnU2JLUjZqQUZ3TVpteVRsdG1iQ1JDRDZyVUZyeGxld0VrRmFSTHdCRUlEWVFkWVpNNXUyVEYzNGhyUTlocGZ5VlhoZHJIUzA4Ti1KUGc9PQ==
Layerdrop and swapping the order of transformer blocks are both things I would've sworn 2 years ago that they had to be the future.,r/machinelearning,Z0FBQUFBQm0yeGJmTmc4QXpmaWIyS3FXUFNIb3RTbERhbXdicjhQcnJiUk1QZkZ6T3dNX0FUN2pLUmtzRGwteWxqSWtzeUlQODRoWV9VaUFsMy1ZenVpTE82NmcyTExzSlZ5ZHh5bEZUdEJia0JwR3RlRUdIZWc9
"Hey! Thank you for your comment! I sent you a private message (not a chat because I think it's locked) with the link \\^\\^ 

The posts are quite lengthy but if you can read / skim them over, I'd love to hear your thoughts, either questions about the topic that I can add, or just plainly criticize when you find something is wrong. 

This latter one would help me a lot because I'm just trying to learn more and have a complete, well-rounded and deep knowledge about the topics I'm interested in \\^\\^",r/machinelearning,Z0FBQUFBQm0yeGJmQ2NpbU9FYmtZOUxCb21UZzBkR3RGdHAxbXBNY2JjQURWd080dTh3U2hSUHl6UVVCaENUTmNJODdQNG9lWUg5NVFfaE1WUll6X1NlNndjV3lySFpXb2I2VTg2WmVyeGFZTThHSzlmMElJUkU9
"At least the big ml conferences allow it (neurips icml..), I guess you should be fine, but just read the paper instructions from your venue",r/machinelearning,Z0FBQUFBQm0yeGJmRFZoWThVX0V5TkNKM21WWFZyNUM0Wnd5RGk4cko5SEtTUlB5OTVUSWJkSFpValp5MW1DNWtoX1FLdHlHUFFLM2ZMc0Z6d1FRMlpKWXN5VWJ5U0dLc1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmY1JXNDUwWGJ0YkZLR0JlRXByMmxJNjRIRDBJWmhpQmEtRmh6Q2VyMk5WczBxaVNNQjZYcU9wUmhYajk2TUhxN3ozSHktVDBVMnNwODJ4WEVJdWF0bWc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJmQlBVbW83NlhkeWpZNlhXRmcxY1N6OUNjUUpWSExPZUR3RTRZMjZUaXo4WFQ1SzA4Mk9MUTFJR0V6cndCNVUzZ290S2R3V0VzNExtdWZaeG11NjZXYVlER1FXdTdlS3ZRUEF5NV84MzdMckE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmejNRWHlSZ1dmWUNNaUgzU3JrM3ozSWpkMFdvSEFRRnYtd0RvU0lDZWpHVFlXMFBvaTRqMjFoSGJGLWU2YnVPaXNVM0FtZXhVTDlsTUVyQU53aWQzVVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmRkltaHFBM3NIZk9xSHBPWHUxenFsTldmQ1ZQUWR4Zll4VFV2a2Fpa3F2UVA5UkYzY0RFdnBCUTVleTdmdndEa3E3b2NJRmlNSUZBekJKaFc2NmxGaHc9PQ==
PyData,r/machinelearning,Z0FBQUFBQm0yeGJmX3JfRUZsdk8tWWlnaWVBSXR0aDkyZnpRMFU4dTJ1MzItQWg3blFyY2p3WWZmOFF5V2tJRy1TcG1OdWo3QmJRSmlkRVRVMzBOZ3RLbUZCMlFHcWpzZDVfc1hFWTRSYXBNeDFDbGkwWWljc0U9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJmcGJ3VmZnLV9PLTlqMUd2ODM3R3o5MHJ3QWFkdHhGSi12c2h2cDlxcURfU2hETVFQZWNFZlhMNU5RZ0xRczUzcThYOXJJVEwydjVxUmc5UG9vSG9sSUE9PQ==
"There is some interesting history to it: [https://en.wikipedia.org/wiki/ArXiv](https://en.wikipedia.org/wiki/ArXiv) but in nutshell what started as a paper sharing mechanism for a small group of people in early 90s, became useful worldwide.",r/machinelearning,Z0FBQUFBQm0yeGJsUVVIM2N4cTFSaVdiM2ZwQkp6X2dRRVFudFI5eF9mb2t0eEZPYW5TOU81a0NsYjE2TEtlWkdTeHREdlk1Z2NBSHl1N2ZQRnZoWmN0VmNjWlVfTkdCOEE9PQ==
"deberta is already an improvement. And large multi-task training is the analog of instruction-tuning [https://huggingface.co/sileod/deberta-v3-base-tasksource-nli](https://huggingface.co/sileod/deberta-v3-base-tasksource-nli)  
but deberta doesn't work with flash attention and rope  
it would be very nice to have ""transformer++"" architecture, fineweb datataset, multi epochs, maybe some joint retrieval embedding training loss

albert-like weight sharing + early exit is also promising",r/machinelearning,Z0FBQUFBQm0yeGJsMzA2cUVMN21NSXJiVnFBWktKc1JlLUVONVdBclpYSWV6b1doT0FSd0RXbE5JRTNwbUo1QS1scjc0YkY3dENYM0huMVMtMmpOUEhyOTRPSHVpcEN5YWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsb3d1N0JxeVBpanlyb2hRb0RjdjU0X3BvZE1WNnhsUF9USVVoVTBFR1h5ZzNsRGkwWlRJazU1TUZpdEl5T0x1dmQ3QTNuTmEyenM1aGZEVnhwY3VlOEE9PQ==
What you're doing is like slicing a loaf of bread with a hammer.,r/machinelearning,Z0FBQUFBQm0yeGJsQ1pGX0t2eVpSeklRb0xYVDZhVjlmdEVGTkVoUjBudE1zbDlVbG1qVW83SGpDclpyRUd0aUg3U3Fwd0xHdTg4bFhEMXhlTGVUMzUzaFh5RWo3SHM4VVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJscE1SVW05d3lSekpQRTBJdHRqQlVzc2ZFbXBNeE00N09oZ2VpbndMOTI3dzRMVTk1N3kyTXRRNGlTaWh0LWVRcmZ5elZFY0FucklRbHJrMHZ0YkNmc0E9PQ==
I don’t know what you’re trying to do but it sounds awesome and I wish you luck!,r/machinelearning,Z0FBQUFBQm0yeGJsS1BkSjRwTjdnY0tBSXY3UGNZSEwzWWtRd0lMRHZjZDBYYWg2R3hVTm9IN3lQYVJtYlRVMjB1dTZTcEtNbVNFLXFWZm5xRDRJVjlGZ1VCZWlGckNjNmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJscEFYME9oYmh1dG50NEFfOXhvWFRfQ19zZHlaV1lLUzVCNUtEWE1jWjlUNTNxbW1TZl9EYW9CdDZ5aVVMcEMzcVRMVTdUaHZrZVppcVhNUktTbThEZVE9PQ==
"For one thing, translating a text from English to Chinese and back while trying to ""conserve semantic meaning"" is just generally a fool's errand. Translation is inherently lossy, and worse, subjective.

And for another, we already have a way to save storage... it's called compression. Generic compression algorithms would probably get both of these files down to similar sizes, a fraction of the original, and more importantly, they're widely available, open source, lossless, deterministic, objective, computationally efficient, etc....",r/machinelearning,Z0FBQUFBQm0yeGJsZ3E4Y2VDQVBaeVhjMG1ULU85Y2JuVnFadS13Yzcyb1U1YkR2aWVCSUFxZmlITEJHbEFlQVZrQXl5WFRjYmJhU2h0YkNBTWUxWk9CMVhvUkxlVGNlLWc9PQ==
"I have been in a computer vision research internship right after high school for 4 months now. Our PI is super chill, and I get to do a project in collaboration with an industry specialist. Don't stress too much about it!",r/machinelearning,Z0FBQUFBQm0yeGJsakRHS3VYRzBFeE5RWThSQnp1RHhHWnNuUVloSnh6Q2x1YURsUGh6QjFiTVZkeUpjMGwzWUJLcV96OG1JdmktQ1BWTmhNa3huOFhoRlJPMFVyZ2hiRlE9PQ==
"If you don't care what you work on, don't do a PhD. Terrible idea.",r/machinelearning,Z0FBQUFBQm0yeGJsUHgyTFpVN1Y5MmhzQVV6Q19KZDBCVFFITDlOYWE2QnRnaVBiMkVlVUlfTG5JVWoxMUptQVM5bkhOTlRMNmhnVDlBMVRwWEhkam1Hdk11YlFxZmp3LUE9PQ==
"Lucidrain maintains a repo called “xtransformer” that puts a bunch of aechitectural tweaks together, and should be a good place to start - although I don’t think it does anything training related.",r/machinelearning,Z0FBQUFBQm0yeGJsQlU0OFdtUlhtRHdmaVVzREhkQ0ljRlRSdi1la2R5amhpcmJPSklSYlFBS19hcFlJVnNOXzhkOThLQ2VERDhfM3hnYnpxQkhmVkd5eVJBN1dTWEFfcGc9PQ==
"If you get a right PhD position with a right supervisor and a right research topic, you will learn a lot and it will pay you in a long run.",r/machinelearning,Z0FBQUFBQm0yeGJsMVFpRk9NQ05QQnlXNDZaRUdQa0k5SjMtMVhUbi1KbUY2N3U5b0JZN0RrN0hCSWo4eVFkUklTNmprYnNzaTF2ZlVoU0VFMnhFNlhsamgtSHlGQ1JBOXc9PQ==
"Sorry, I didn’t say that as clearly as I should’ve. I’m not passionate about the topic I work on at my current job in the industry, but I’m extremely passionate about the topic that I would want to study during a PhD (the intersection of medicine/biology and ML). I want to work on something that I feel could actually help people, especially when it comes to their health",r/machinelearning,Z0FBQUFBQm0yeGJsN0FkMS1ENWRkNlpucGtzMVRfOEVUZGp6Q3hoUEM4d3lOQmZjT3c2WmtMaHItM1NzamRfczVIMk9DVVA0ejJ1MnZOV3l6NWVhYmd1R3E4R1VYdmNSanc9PQ==
Huggingface ?,r/machinelearning,Z0FBQUFBQm0yeGJsdjRlUXFoZlpENGRzekNPZGdId1RJdWw4OWEwMUJzdmVLNWhfUG9LcE9hcy1uMW8wMy1ZeTBDWU9FVG03NVdva0Y1LVFuLTZSWWNXcG5uYWpSZ2FzeXc9PQ==
"Ive never understood, how come we know that dimensionality reduction can be safely perfprmed without too much loss of information? Even if we can verify based on performance of networks and results, how do we know that without doing so we couldnt have networks learn even better? Or is it just that because it's often a computational necessity to reduce dimensionality, we just have no choice whether we lose significant amounts of potential learning or not?",r/machinelearning,Z0FBQUFBQm0yeGJsVE1hUUpTenhsQnBIb1BlUGVBVHZ5U0d1RnFKNkUyUkw0X1RPSXFtTUhMYVF1bUNjUjRURTRqcndjZVZpY1otSW5vREw2bGZFclVFTnNSTXJYNmRkYzVjNGZnajlUWlZabmYtbzAtRl9FRTA9
"Ah, then you should carefully choose the program and funding source so you don't end up working on something you don't love for less money.",r/machinelearning,Z0FBQUFBQm0yeGJsRFhkbk9oRFVibUVZVk1KVkRVUzJhQ2d4ekxBSHYxR0o4YV84ZUV3S3pCcFlodGlLa28yV0t3dmNUb2dGQVhmV1M1RFhzbldGS0RiWVgzUThKWmp1YUE9PQ==
Deep Boltzmann Machines which I very recently discovered. It may be the first successful example of deep learning training,r/machinelearning,Z0FBQUFBQm0yeGJsY3NrNnZKZkhZeDBpQlV4UXgwWkN1ZGpHTjBWNGROZHZmTk41NkphSThYWFRDNnV4cXhsNWlHQ0M1Y2wyRVpyUmxLbHEwdE5FX0pFY1d4S3p1dGJTdUE9PQ==
no it's not but we show you the redacted frames to review before you submit and you can remove frames or choose not to submit,r/machinelearning,Z0FBQUFBQm0yeGJsSDRaQ0Y5dTc4Y0NPYWd5OURlSTlHZW9sYW1UWXlRQ3FfdktvVEkwSEtQQ2M3Y2FGNjVHUjdsN3VValMyNTdXd0NWWC02SU4yNGNyMEpKSUNYU0tzQUE9PQ==
I have a master's. Zero regrets of not doing a PhD. I realized I actually liked building stuff and coding much more than reading papers. I kinda hate reading papers actually lol,r/machinelearning,Z0FBQUFBQm0yeGJsVkRodjJKd05IVEdrSnNvV3FRX3F1cVRJZTlEY09yT1dESnppak5zdkpoTG1FcENuVWtXbVh1ZzBFTjdIdHYwdVZuZzdERWltVWRJa0tsYXJmbkxNTjdLSTFRMEhUN1hrUTZSOGtjMGVwcms9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsdU5LOGdtUEtncEdLYzhkQWY3WXBVOGZ2RGhjQzd5aWtUT1MtYzZ6SGF6SC14Rm1TclpyQ0VCUlh4d0ItaXQzdzVhWFBuLWdNdTZqN0o0MFFqcFJQZlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsS2tmb05fd1VXNW5Hd0xiOWN6RFA0NnRxb3YwMG1zYkNXRjVvTFRtSGZoRnROSDNraVY1V0plZk9hcEVkV3hMSXZFM0dKYjJKeXdMcURFZ3ZMeHZ5RWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsMGg4dFJnTno3a0RUenZRRDNKY0NyZkhfREFrTkJfSzVpTzdfV0hzWEtBbW1peGpZVnJ3emNXdnFvYXJYdkppWUpFTVZRc0tJWFdyRV92RXV3bUJibFE9PQ==
"I have a PhD in molecular biology and a certificate in data science/machine learning. Accordingly, my advice isn’t super informed about ML, but I can tell you that a PhD will put you at the top of your field and allow you to push the frontier. Generally a masters degree won’t let you do that. This is (generally) the difference between the degree levels. IMHO, get the PhD.",r/machinelearning,Z0FBQUFBQm0yeGJsbTRSeDZKSk5xNUJUb3RLRHNnUTZtTy04T0xiU291cTZmU2dIQ2JrM0kyTHhvOW5TV1NHRExfWjRwd0VRdTZHMU9iU0RhRFAzRVpIU0JGZlk3cmhaZ2xzajZfdmRCOHNCU1M2Q2dlaEZyb3c9
Tbh my real regret (which isn’t even something under my control) is graduating into a fully saturated market.,r/machinelearning,Z0FBQUFBQm0yeGJsMm9XLW9jMTBqRFBHUlVwQ1o4MEpIakJWSms5MzlqOV9VMWlEaWF2NnRJQlRhMm5HakQ2WHNRRlpLWDFVOV9PMWQyRFNxRk9UbW9aLTR1cTltLWlQRWc9PQ==
"Check out [this survey](https://www.ruder.io/multi-task/) from 2017. There were a lot of special architectures with different layers for each task, etc. 

Metalearning and few-shot learning was mostly focused on expensive techniques like MAML that do gradient descent at inference time. No one had gotten it to work outside of toy datasets like omniglot.",r/machinelearning,Z0FBQUFBQm0yeGJsd2NmakdKNmV4bjlac3hDNWR4UUpiZW5uUS1UbDYtNGd5OExaZ2REMVNROFNiRE9MaFVzNXRaT3EyWjFrSUNkckZrdHhNNGtRWTNwc1Y4cXFmMUVUekpBVUlKSE9QcHNyX05OcHNIY2dlYzQ9
I have an MS and zero regrets not doing PhD. It’s really up to you and your career goals,r/machinelearning,Z0FBQUFBQm0yeGJsODBGSzhRR1YweDliR0xMSHJkMjVnUldKdEZBU2IxNVNQeWFvUXNkMmFCZXp1MzMtZDcyeTMtbXRfR2hiOWlQVF90cm1HOFliWTd4WDZSZXg3THNjV3c9PQ==
">It seemed obvious to assume the LLM would have an up-to-date training set. 

Yeah, that's why it was so crazy when you responded by saying:  


> People care about end results not the training data set.

And:

> When an LLM makes up false information nobody cares if it’s accurate to the training set.

I mean you joined this whole goddamn conversation responding to the scenario where the LLM had out-of-date information, as was clearly stated in the FIRST COMMENT you responded to:

> If the LLM says that Queen Elizabeth is alive because it was trained when she was, that's not a hallucination.

You are doing a good job of proving that there are many, many ways to be wrong, and hallucination is only one of them.",r/machinelearning,Z0FBQUFBQm0yeGJsRlRCN1JpT1I5ejBQUTRmT0FTVS1EaTNyT09PZ2pmc1ZSckNfUllFNWFMVFZxRGJObW13a1lDd0VudVYyRlhMZ1FLY0E2dFNMTjFhQmJXNjgwa2VDTHN1ZnlVVGJsdm1KQi0wQTFNd01wdEk9
"> data drift detection methods are very useful when we want to understand what went wrong with a model

Usually yeah. Covariate drift detection (which is what the methods you mention are doing) can sometimes be a red herring tho. If your learning problem is ""anti-causal""—target causes covariates, e.g., disease causes symptoms—then covariate drift can be completely explained by label drift, which is a much easier problem to detect and remedy.",r/machinelearning,Z0FBQUFBQm0yeGJsQnZyODF0ZkVzMFBQOFJGYXdMMWJlMHFzVGI4LXJ2MmlpSkZlcHJIYk9Rc1ZWRlBKYWZLVGxLNDhGTmNIdVZadERpcGlIYzh1NzZfQTR4N0VtbjdPakE9PQ==
"I regret not going to industry earlier and missing a bullish tech market.  

The PhD I don’t really regret because it helped me find my way, but the postdoc and academia in general I regret.",r/machinelearning,Z0FBQUFBQm0yeGJsNVhXZlhpbmVhbWZZdWNidmZpSmlXbUphd2NnUWF0RUpRVkFxbWk3Y3dQcmhxalB2VEdJLUs0TGJQcFl4amxhTk9sdE9RLUpaSWd0cENPSGdxU3hheEE9PQ==
"AUC-ROC normally maxes out at 1, right? I'm confused about what that first table is reporting. ROC is a curve inscribed on a unit square, no?",r/machinelearning,Z0FBQUFBQm0yeGJsNVVGQTd3TVJZRmhfaFZsWVVWZXAwNTh0THJNSEdOZndwY0J6LXFnLU5WdldHV2dFeTZ4Y09RMlZYNDc5aFlLZFJjZE5zMnltc0VpXzA4RjU2eVpIY1E9PQ==
"If considering switching to Python, you could try Mesa for simulation: https://mesa.readthedocs.io/en/stable/",r/machinelearning,Z0FBQUFBQm0yeGJsUGZnMm82WGZoUnVlNUppNXpoLXljMmQ2ZFlIRVZVbDU1NXhEM1JINXhONkhyVVBSMTNfRXg2dFphcVlUZENxRUVnaGhEX0xHa05yQ3lnb3RzS0gzZ1E9PQ==
"Sound advice if you want to stay in that field. I also have a PhD in Molecular Biology but the only use I get out of it while working in fortune 50 is the Spy's like us joke. Unless you're in a research role, I see no benefit over a masters

For those who don't know the reference

https://youtu.be/Dhkwh8u30mo?si=KCKeLFGKK58Mweyt",r/machinelearning,Z0FBQUFBQm0yeGJsdE9ha01qYWlrWlRtblNwSkdqMEVmY2RGdGxWc0R6YXBOOVRPbTdUQWF2a052YWZBMDN1bVc5RUVuUWFDRWx5RjhacjRRbmlRZGg3WGhMdjRnYVI4N2c9PQ==
pretty accurate... but a lot of luck factors...,r/machinelearning,Z0FBQUFBQm0yeGJsRnlmN0pCckkxWXUzclotNG5WVXFhQm42TFVFQkUtR1daa0wxeDV2aXlNQU44aXpXUjFId3E2dmJOZ25NeXViN1owdVV5RTZ5cmJjTWRDb0hMbEtObnc9PQ==
"I watched the reference, but I don't completely get it... lol

is it because, as a doctor you feel it's enough to say you're a doctor? 

btw are you working in tech now?",r/machinelearning,Z0FBQUFBQm0yeGJsSFJsTWR1Rm5LMUY4bGN6RXF4VGxvWk9JSU55QUZoRzhOYTR1VG5peEVGajN1NXFvRS1Ud3o0UU1ldzZCdnAxLWRtTjl1OTVVVTRhQjB6cDloSEhsQlE9PQ==
Post questions in career questions in /r/cscareerquestions/,r/machinelearning,Z0FBQUFBQm0yeGJseUR6VTl6aW96akxSOHdSd1pHaEZQbWNEdDlISnhvQ2lRSGFNNld5anRvVE9CbUpyWlMtZjg1QnQ0VHVYZUdTejFLWG9oRUIxY21lQ1VTWllxcC0tWU9DYS14cTg2QUxrYmRYT053V1dWOUk9
"I bought a house in the time some colleagues went to grad school, and a lot of them ended up doing the same as me. 

PhD only seems like a good idea (financially) if you are into a super competitive program that will open the door to extremely high paid positions in e.g. OpenAI. And even then, 5 years is enough for another AI winter to start. The risk adjusted ROI is simply bad for most people. Do it only if you like research.",r/machinelearning,Z0FBQUFBQm0yeGJsUE5STWN6ZFZhRnA5cE4taGNUMEtjWEZtd1E5RkZiM3JlZ05vWVlDQzh2UkV0c29iYUtiVk5tX2lnU0hNLUEwcVdoZnFfTFZ5RFIyMl9VVm90Rlk2Smc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJsb3kzNmZjT0x3M25wTGNyZkZDbndSZnYzWkVyT1MtMGNtUlhOekhWU3o1eHFYaHE5Vm5CY0xYVUxBdElWQkw3WFNSOXZsZUk2SFFfRzkyOTdaMXN6Y3laRmxzZGFScHlFQVpnb3NGek9nWlE9
How would I go about implementing for testing on some real world datasets?,r/machinelearning,Z0FBQUFBQm0yeGJsbnRpdFo4dWtaM0t3c3B0SjFuajZGM1R1RUw2QUNuSHR5Tlg2SVZsX3RuTFRmT1JZYWVidkRTVkw0MndfWWRyTllUM09SZzlZT2dqTUhYZXFmbVhaNVdTMEtpMEVTRERGV3RJLTJNTkJKWGM9
"I work at exactly this intersection with a Master’s. People are surprised to find someone in my position without a PhD, and I did feel self-conscious about it when I was first starting out. However, I’ve never felt held back in any way by not having one, and at this point in my career I’m confident that my work (in both academia and industry) speaks for itself.

Sometimes I do fantasize about pursuing a PhD for fun after I otherwise retire, but am very happy that I went for the Master’s instead at the time that I did.",r/machinelearning,Z0FBQUFBQm0yeGJsY1hDYkFSd1pBUWZkNlo0dDRaVGlsMDRYOHFFTnZIWExyZFB1UWsxd0RSWU9jZmFBeWowSmhfNjFPVlY1WmhGazR1MmMzS0FLaTc5VWUyckFrUjRmb0tXRFd2TExJQ19qdm84dUNfUlU2M009
What is your personal biased take on amd's new MI accelerator?,r/machinelearning,Z0FBQUFBQm0yeGJseEVXT2pRbE5MVFUtZWdQM254bXRTU0VLUC14dURZUTYxajNHZ2hJd1FFTms0NWhiVU5sbm0wQWw5LXc4UGpJMW1vU19jOTFkM3BzRDQ0aUtXUWVsOWNrYkxqSUEzOW81TnMxT3NBWWRFbzA9
[Elucidating the Design Space of Diffusion-Based Generative Models](https://arxiv.org/abs/2206.00364),r/machinelearning,Z0FBQUFBQm0yeGJsQ2UtamFNN0E5Wi13NEhLOXM1a0trMFZTUDVibk95aDBlWDlEOERKSWM3OTU5Y09ucGZpanJPSWJhczVNY3NBd0R1cmRlWkpKU0VNNHZmdkk5N3NrRlE9PQ==
"Yes, when you sample from the posterior, you get discrete counts. This is how neurons in the brain encode and communicate information, which was our primary motivation in designing the P-VAE.",r/machinelearning,Z0FBQUFBQm0yeGJsYnV1aUh5LUJwdFRFLWtCUUZHR2JxbEdFelVqaVRZVXJ4WDhWSVNQbGxxOVh0U3Rzd3hkUmtQVHJMMUhkUWJ3bUpwWmp1WnhUQ0EteUdWTDlTMDFELVE9PQ==
"The methods involved in the analysis are trying to estimate the AUC-ROC of the monitored models. So, after the experiments, we ended up with the estimated and realized AUC-ROC. To compare the error between both, we compute the MASTE (modification of MAE) to evaluate which performance estimation method worked best. That is what the table is reporting.",r/machinelearning,Z0FBQUFBQm0yeGJsWmxxcUkxMmtGcjVlbGVfa0dCNWNZRkVoQUJuOF9hX3JieW1paFhLRGNPMGJHX3I3bmhuTldkcmRRZ0xudGJnREMydkhyMXViRTZnS19QQl8tcG9TaHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsSi15WDRjdjZFeUQ3SDFBWmpNTlpTcXkxdnNUNHNFcTVlYUtXOUgweGluaUZqYmZtZklxRHhZVnRHYktyaFpYWW1IN3FPRXdSNkUwV3pyZkhQM3J1RWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsWWNsREJPdEJFNEc0bkwtWkE4Sk05UENtR19XanpmRV9fdGVlYXkyemozZzI5UjZiZXpIS0RFQ1hDR3k1S2Y4WVlfZTVZV3hwbFBWVmliVnFCX011YUE9PQ==
"Hey, what kind of collaboration are you looking for? Academia? Industry? Hobbyist?",r/machinelearning,Z0FBQUFBQm0yeGJsNTNWekNwU2dyQzk1dndRclVLVDIwVTk5ckRnQ1RVTVBYejhpYW9ZdFBVNDRGbWEtemNQa2VycGpydVc4OWVPem1PenZON1Jzc1dianBRRkFVTktRWkE9PQ==
"This is such a dumb argument. My original response was to your statement ""A hallucination is a statement which is at odds with the training data set. Not a statement at odds with reality"". The queen elizabeth thing wasn't even on my mind.

I stand by my original point which is that your definition of hallucination is odd. Hallucination is not about matching the training data.",r/machinelearning,Z0FBQUFBQm0yeGJsWUNTMEpzTV9rUHFPR0RZWTRvNEI2Um95akFiZWowX3dSTjJPczFZT0E4RXdUWkR3eXdjbm04TVU2OEptNWY4X3RQMHZ4Z2Q4WnhLdFYzdVNlV2hacEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsUnpqclBrcVFqTkg4b1otTkEwTEtkdjd1NG5PaUJRdmM4cExodHVDd2U1amtVWTNDZnVKNndvYTdYamlqTm9HQjREUk8zZWU0a3VhbnFEa2tDSFp6VGc9PQ==
"Genreally, you have to make the series stationary, by removing trends, seasonality, etc. Then model it as a black box regression problem using lag obervations as input features (among many other options), e.g.: https://xgboosting.com/time-series/",r/machinelearning,Z0FBQUFBQm0yeGJsNVhCZ2ZqMjcwRHdrMEJvU0VoYi1OenFZRTlEUmFkMXA3S3JyMmdpdkJOaG5wZWdnOXh5NFFNNEdGbDAxYmp1blBDOHZtUkJSTUV6LWdPZHFHeXRtd3c9PQ==
Well then give a more precise definition.,r/machinelearning,Z0FBQUFBQm0yeGJsakVKZVJtOTVBUFRKXzNMbF90QmN6T3BkeXI1NjhIYXd0S0pxNnpIZ0JrVERIZmZhY2xSUXZJcEVwQWV2MDJ2RDZqRUxHQXlIVkdUNFcwVUZWN1VvQUNNUjN4VVU4VVFQalBrMVNaUlI3TWs9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsWnJIT09iNkZidk9pNEM4emFxb0t2eVhlNDA2RUJaSlZjY2lKN2NBdm16SHpnSDNUbHhvYWJ5elQxdDVXTHI3bjVCX3NtTWtocnpxaE0xMXdQcTFZNlE9PQ==
"I've used both neural nets and xgboost a ton over the years. 

I suspect it has something to do with neural nets needing to find a smooth decision surface/boundary vs the trees ability to easily handle discontinuities (e.g. non-smooth decision surface/bondary) in turn with most tabular dataset we care about having these discontinuities. I've read other experts make similar claims, so I feel good about it.

There's a collection of quotes on neural nets vs GBDT here: https://xgboosting.com/xgboost-is-the-best-algorithm-for-tabular-data/",r/machinelearning,Z0FBQUFBQm0yeGJsN1UwbFFGX1ZlRUtDcXB4Znk4YlM0RFkzR0pKdkxRbm9XMEpHNi1qNF9NX2puOTRKc2gwdzAxYzhKc3hjUXVIMmd1cV9ibS1WTzNkazBOdlpCRUVUTmc9PQ==
"Don't guess, run the experiment and follow the results.

XGB will perform automatic feature selection and it works well as advertised.

In my expereince, removing irrelevant features (e.g. id) and redundant features (perfectly or highly correlated) will reduce training time, and may offer a tiny to modest lift in model skill, depending on the size of the dataset, e.g.: https://xgboosting.com/xgboost-drop-non-predictive-input-features/

I'd also had success using feature importance from an xgb model for a feature selection step before fitting another simplear model, e.g.: https://xgboosting.com/use-xgboost-feature-importance-for-feature-selection/

Often using xgb feature importance for feature seleciton to drop least important features for an xgb does not work well, e.g.: https://xgboosting.com/xgboost-remove-least-important-features/ and https://xgboosting.com/use-xgboost-feature-importance-for-incremental-feature-selection/",r/machinelearning,Z0FBQUFBQm0yeGJsX3ZaMW42RXRiM1RWUjV2NnRSUEhsdTlrN0xSSzFtNlB1NUhPTldBNzFiamZJVXRjaFhETG1sSFFaem5qdFZRcXVpaWUyTlc0aDNSMU5Id040SVZkWXc9PQ==
"For SaaS apps, user interaction data factors are standard/discernible. 

It can be looked up with keywords like 'event data', and is segmented with 'user data' or properties.",r/machinelearning,Z0FBQUFBQm0yeGJsR3RwbVd3OFprVTJlRnpXQWxMVVRKcVNNS1gtZ05hb3JGdTNYd1FWN2phc1BSME1yRklaS3dWYzVlOGRSOHJ4b1lIcjc5WXQ2bk4tNmRIRFRFR3Eydnc9PQ==
Yes,r/machinelearning,Z0FBQUFBQm0yeGJsUEt0TFNGN1Z6YWNScWN6bzgzaG1fV0pMVGlJWl9lZFBRSGcxbnZtNUdITk1DMkVjRmFodVNxUDVoWTFmd0g2TmEyM3FLM2ZDcmE5LTFiLTRVaVU4SGc9PQ==
Cool,r/machinelearning,Z0FBQUFBQm0yeGJsRm10QTVHVW1wTmt2WEhlWTF1M25ZaWRqUGFvQ3JoTnUzVU1sbnQ1LW1wcDRVTHUyS2lhRjNtZXQxdnprbnRWX2pzX05NOW5kQWprUDcxalR2VW5uNGlNbXA1NU9nbkUyQ1NHSll3WDZVQ009
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsY01zTW9LNThyMmRrMlp1RmpNLWlLOWFrcXFZWDlqWFAzTmNRZTFyTEdFOFFFZVB2T0hLVFMwY1I5VzZhWXhIVVZPNEQ4djMzaVJydFhJektXdmpfRFE9PQ==
"I like to think of bagging a parallel collection of horizontal trees or peers that all contribute equally to the prediction.

I like to think of boosting as a sequential or vertical collectyion of trees where the next tree corrects the output of the prior tree, and on and on.

We can bag boosting models. We can boost a bagged model.

This comparison might help: https://xgboosting.com/xgboost-vs-bagging/",r/machinelearning,Z0FBQUFBQm0yeGJsTkpscTdSZjdhYzBmazNHUmdiNmNXMTBhZm05SmdwWFE5eTFvQVd4RXdDdGJVVzlGczNuNHJxV0x1T2VXNkMzRktyRlFCc1JqOG5KYkp5bXU3ZnFqQUE9PQ==
"Yes! More papers have sinece surfaced showing the same result, e.g.: https://xgboosting.com/xgboost-is-the-best-algorithm-for-tabular-data/",r/machinelearning,Z0FBQUFBQm0yeGJsc0ptTHRudGpIWWZOaVI4M1p4SnAxU1pKMmZjYjZ3N25RQXJEdEtqSG5Cb3NBMUNoeDM5OUctS1hscVo4QVQ1VFVpV3B1c3VPbHVqT0wwVnN6QTRBckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsaEZHdng5YXRhTnRibXlqTk15YjlFSGNWNXJyR0d0bVQzZXFyTlZWcTRlY0lrcl9kSG5sNGNDVkRiS0dRWk5rMS1tbmZSUEVPM1E1V2FrV2pSdno2amc9PQ==
"Training data is more like a boundary than a target. The target is reality, and training data is the bounds. The issue is your statement implies the training data is both target and bounds.   
  
A hallucination is an AI response that contains false or misleading information within the bounds of the training data. When training an LLM the hope is that the LLM is somehow able to extract truth from this big pile of data that contains a mixture of true and false information.

If the goal was to match the training data then that would be like saying false information is ok, because no training set is perfect.",r/machinelearning,Z0FBQUFBQm0yeGJsTkFMNThVc0NkUUQ0QU9RYjZTWThjd0VZM1EyWC01eE02aklRYU1HdkNvdXNsdng2aHd4UVBqLWpiS0F0RjJFUzNIY2ppeWJtbzQ4MEY0eFBmZkhlTkE9PQ==
"This! Don't guess, run the experiment and follow the results.",r/machinelearning,Z0FBQUFBQm0yeGJsbUp4RUo4eTFQZWtNYmpEQVdRMnBTcmZrTmxwUnJYR0Q1amxSaHhyZ0NXWl9ZMkF6THhMRU8zM2dnT29pck1ia0F4eXllUk5XOE1FRnV5WHhKeU1pUnc9PQ==
"Interesting….this makes me think about the failed Rabbit R1 LAM. 

I think screen recordings of mobile devices need to be prioritized and every OS available needs to demonstrate the same tasks. 

1. Open and transcribe a message in a note app
2. Set a timer, alarm, stopwatch 
3. Open and create a list
4 take a photo/video/slow motion/…",r/machinelearning,Z0FBQUFBQm0yeGJsTC1zTWticXpHQ21nbUU1M0xqSlZWZjJtUUdUM1lFWC1vY1VnRXA3U0o2QzJHU0xCUVBKcGp0LXhGanFYM3N5aXVOcE5mOFdpTm1ja2laVHBwYlB3RWc9PQ==
"You're in exactly the same place I was.  MEng in EE / Systems, chugging code and building industrial robots and loving it.  Then, got switched to a totally different project in a totally different group (not my choice).  The new co-workers were great but management was setting projects up to fail. 

I punched out, went back to school, taught what I knew, got the PhD, and now I get to come up with my own projects (and the pay is better too).

If you want to steer the project strategy, get the PhD.  If not, then it's totally optional.",r/machinelearning,Z0FBQUFBQm0yeGJscFBaQlZMRldHNkNGaWU0a3NFV1VDM3lWaE5abGRmOWtDZXlqVV8wMEtDTzFlWHY1ZXhUNFlkSHhleGhXSGtuNVI1aDRZb1V6NTFuVjVydmhnaWpxVnJEUVBfS1FlRWtjamZsUkoxSTdkZVE9
I guess my question is why does that also work for units in (possibly deep) neural networks.,r/machinelearning,Z0FBQUFBQm0yeGJsMUJWUFVlbnRuQ0pTTmVXMmM4clZmdVo4bkZWSmczV2RldlNtNTNnQmFKbjh6WlZBdV9Oci1melJCVHJLWXZYUXpJLUVsTzhsSF9hYWR6eFNIWEd0cGpLcUllS05UZ3phdG11UW1JX2JVQ1E9
In a normal image context you can use Floyd-Steinberg dithering to convert grey scale to RGB. However I have no idea if this will yield good results for your domain.,r/machinelearning,Z0FBQUFBQm0yeGJsanJvMHdPVHBFaVBZQkp0M3ppdEJXS25jSWlfUURpRzl6YVFEWEFmUGxDeHNmN21ReHAtZUxYMmktbFZHSV9CZTJSZDE2N3FKRVl0RUtjTWd0SmF5aHc9PQ==
Some of these are in the RoBERTa paper,r/machinelearning,Z0FBQUFBQm0yeGJsb2V4NVg3Y21JTGQtVHJwVjFtQ0V1c0tjTHhyMGdIRlJMWVFVay13OGhXT1lZZnNUcmpMOVpnNEhxOFZQTmFpX09vSlU5T2g3YnJGS0Vady1jUE9TZUtYbTdFUGlnRm5NVTFyaGdIYmxuQkU9
"Path Forward

Hello All. I'm Masters Student pursuing MSc in Data Science and AI (stats focus). For my thesis project I am pursuing a Quant finance project with implementing Reinforcement Learning frameworks (I have till April 2025 to finish it). However, going through the research, it seems that RL has taken a backseat to LLMs and Gwnerative AIs? I'll be candid, I don't have any specific field of interest (post graduation). I'd happy to get a MLE job post graduation, but now I'm confused should I focus on RL, Deep Learning, LLM and Genrative AI, or Computer Vision. I know there's overlap between these disciplines but I'd like to focus on couple of specific areas. If I have to say about soefoci industry interest then I'd say I'm interested in compqnies/products which cater to Consumer (Behaviour/Media/Analytics). I understand that traditional ML methods (supervised/unsupervised) are still the way to go and I do focus on that those too. Appreciate any advice.",r/machinelearning,Z0FBQUFBQm0yeGJsa1RuZy0yc053cHBHRFNDYUs2R2s1QXhJNzA4RWRKV2JESFJ2MUhfWVU1amtzSWpMMjROcHNnTzA4bHA0ZDNXQ2pEcTU1aGJGNlpfNExGblpqcmdNYVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsNjNBaGNxMHIwQ2g4MXlVSTgybzQyOHlxdnktTjZQVmhUZXpsaWRNX0FtMUFqdTlQbnVEY1BWc2xNaVJvN2FWQ0o3RE5sN1JIclVXaXYtS1Z6MkhETmc9PQ==
"this is really interesting, thx.

something i like to focus on is  ""regimes."" your model might be realy good or bad a specific regimes over time.

may i suggest compiling your CV\\_test folds and running some regime labels (or structural shifts). for example if your model sucks at recessions and your test set is a recession... or vice versa etc etc. in any case when you put all your cv folds together in a giant test set and plot them you can start to see how it tests. its also a great practice for tunning. may i also suggest a purged and embargoed kfold",r/machinelearning,Z0FBQUFBQm0yeGJsSkpRc1J0VHZwUnFrTjJqQjR4OVBjNm1Ua201YmR2OWJfZ2lqS3h1TzQzOWtuVHJzVmZ2YlpmclVldUVXODZ6NDFIZEx3UklnT1l1bVRnbFR4cUFVWUE9PQ==
"If you like ML papers... we review one as a group every week. This week we're taking on a paper that is catching some attention. Thomas Wolf at HF even called it ""totally based"". So we're diving into it on Fri (May 31st) - ""Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet"" --> [https://lu.ma/oxen](https://lu.ma/oxen)",r/machinelearning,Z0FBQUFBQm0yeGJsU1BGYlNkY0tCTFBNbGF1ek1od2tTbUQyVlhQUWd4X280TnJKMTFseHBKZ3pweDZHdEliZnA5VFF4TDE1b3lGeU9uRUZCa2p6blA5b2pKZWtuZ1ZrdlE9PQ==
"True, and I don’t understand why focus is more on pre trained LLM’s data leakage than accuracy.",r/machinelearning,Z0FBQUFBQm0yeGJsNnZRTEZSTWstNnpVNzhTQ2xuQ2l4M3JGQS1XS1BENFRsWHRjM21UWldjRzFKLUU5dkw0TUE1UTMzdXpfQkg2ZHVCeFV1WHQ1TlRpMEszVE9JX2xsNlE9PQ==
"Loved it too, so elegant!",r/machinelearning,Z0FBQUFBQm0yeGJsZjlkNXdrUGxMVkRCV3VzWlg0c3JucjJCOElIdUx5SXMxaUxiX1pOeXZsRENQRnE1RnBQYXNwRldMbkk1T3NqV3NCbWxOT1lNNEM2YUZZRUhqV2I3dkE9PQ==
[https://www.databricks.com/blog/mosaicbert](https://www.databricks.com/blog/mosaicbert),r/machinelearning,Z0FBQUFBQm0yeGJsRXFWd2tjMFlzT1podTdWSG5XWUJ6ZURvZ2VDek5Zc1pzZWVZelBidEY0YlRia1hNazFTdUd4Ym85UlYxc0pwSVM3RHJHYzg1YWNrUUsxeWEyQmtJaHc9PQ==
Attention is all you need,r/machinelearning,Z0FBQUFBQm0yeGJsVGh3WnJzeHMtSDdNNDdKbWVKd1FuMG1TaS1hUnp2eHZXV1V6WEsxZGVrZURaUFdCenNGZkt4NTQxTVdQYjB6VXZtQVBobG1KdTZRMGlfWVN2LUE5WUE9PQ==
"Yes.  Fine-tuning means training the model on a much smaller amount of data with a substantially different distribution than the original training data.  This causes the model to apply large gradients and change to respond more in line with the new distribution.  If the new distribution isn't too different from the original, it achieves a substantial amount of transfer learning, but crucially, that amount of transfer learning is not 100%.  The larger gradients applied during fine tuning are inevitably a bit like a bull in a china shop, destroying some of the finer-grained learning the model did when training with the original distribution, and the model definitely becomes weaker by washing out some of what it previously learned as it makes much more coarse-grained adjustments with smaller quantities of (and therefore noisier) data to match the new distribution.",r/machinelearning,Z0FBQUFBQm0yeGJsMWxQYTlXVDNKcFBTV1pON3dOX282bVNydjd0dl9hWDNZdk5rUXhSNFNjbVdDOU5zNGlId0xIZ1FhYkpCRDN4N1E4OFdZN2s1NkpLdGlla3h5X0pSYWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsa081YzBESmFhX0RBZmZiMkdPWW1QUThTZHNNMldSRlA5QUtHZl9iSE82YXg0T1dtMjIyRndkeFNzWjYtWXlOdVBOczJ3dWUtM3FXLWhIZ0d5b2FoVnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsenlfMVZFN2RSUkllQUE5QTF5OEtHcGRyQXpfVVZmcUtxTmJFeDlsbXRpRWNwZ1c5bjIweEViWHYxLWU0bDhJY2cteUtNUnhlVzBMTmRmSmswYTgwelE9PQ==
"if i want to learn machine learning, you recommend i take the fundamentals of programming with c++ (syntax, data structure, oop, algorithm) then start python?

or that will be waste of time",r/machinelearning,Z0FBQUFBQm0yeGJsTTkySjdjM2F5VmpRQTdTdWtOT0hZZDNZSlUxclBfT1YzcGtIb05uaUozTHRyM1N6ay1yT0pueTNVd19fMTJubzl5VXZYVHpSVzB4UTdpQWpweV81cm5PTlV3NV8zTXRXMlFRa1hCcWR4YlE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsS0drYWloSGthQ19sMHF1bGppcGFQWEJyNm9QTTJsS0JqVmxraDF0cjM5UXl4ZUEyeXI2aGlFT3pjRDdRVktoeWhyLV8yb0dUVXl1dW9KeHNHckdmc0E9PQ==
">If the goal was to match the training data then that would be like saying false information is ok, because no training set is perfect.

If I train an LLM with millions of pages saying that George Washington is immortal then that is *technologically* identical to training an LLM with the statement that Queen Elizabeth is the Queen of England.

This is a Machine Learning technologist's subreddit, so I assume that we actually care how the technology works so that we can fix it properly.

Fixing an LLM that states that George Washington is immortal because it was told so 1,000,000 times is a completely different process than fixing an LLM that states that George Washington is immortal because it just invented that statement out of thin air. The former is a problem you solve with data cleaning, just as you solve the Queen Elizabeth problem with data updating.

The latter is presumably the problem that OP wanted to discuss, which is much less straightforward to solve.

Inventing an LLM which comports with ""reality"" is not a technological problem. It's a philosophical problem -- at best. Let's start with the question of who is the avatar who decides what is or is not ""real."" And then how we measure the LLM's correspondence with this  oracle. These are not technical problems.

If it was told exactly once that George Washington is immortal, then one can expect its other information to overwhelm this one error. If it repeated the lie, it would be a flaw in the software, but still not a hallucination.

There is a reason that it is called a ""hallucination"" and not just ""an error."" It's a special category of error that arises from stochasticity as opposed to from bad training.",r/machinelearning,Z0FBQUFBQm0yeGJsZlJRREVSWFZiSnhBaU5lMW1WaXZFd2lvbkVCVkRRRjc0dXZINzVnTTFKeXBHYVZNakp1b29PUnJKN3ZRVDV5dVFMRUJCbFEza1FwNnNZOTdWNTVtOU1QMHVFanB5TFRxeXhHYTIxbFVWbVE9
Came here to say this,r/machinelearning,Z0FBQUFBQm0yeGJscXJqSDVMSkhwSVZibWE2WlcxZm5RWVkwaEZ4ekZjVU1XTGdwQ2ZDd2lQamVWVVBSVTJqbXkwTm1aM21Na2s3cy1PUUNPb3Z3N2J0dVBNQktFMWJtQWxZdHBEaEtfVE4tVHQ5YkRfYWdJODQ9
That's great to hear. I hope the team I'd be working with will be chill like that.,r/machinelearning,Z0FBQUFBQm0yeGJsRUh1Zk5FR0R2Q3V0WXZVeWlESm40cDhOc2VKY00yOWlwYVZCSzc3NnZWSTNHMWdvdGwyWHhkSUI0N1FheXhiczI1b2JxbENIMFRDNGRmQ1hRY3VBd2dfV3FYTVJ0cHk3WDBuLXhwMTVWUnc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsTWZaM2R1bnJSXy01bGRqaDNhRW9VUGxKal84S29vSzFOMEhSY0dCRERBU2NvY0NJZGgzRnZyRl9GbmJOUFpIeDFZdXdJZi1vUGpDM01DeFRxNGxKLXc9PQ==
"# How to deploy a spacy ner model?

  
I created a custom ner model using spacy and used fastapi. It works on the local machine, but how and where can I deploy it? It had problems on loading the model \\[spacy.load()\\] even though the folder for the model is in the same directory. i also tried creating the model as a package so I can use pip install on the packaged model, but it still doesn't work. what must be the correct setup to deploy it?

PS. I need to deploy it so that the flutter mobile application I created can access it",r/machinelearning,Z0FBQUFBQm0yeGJsbzFHU0lUZUpZVi1ITXMwOUR1S0F6NjN0UkFrZlZLYWJjek1ibXR1eWJzVnZvN0N0R3JkdHVPbWtOX3MzSG4wamFibldHaVcyNjNaODF3Q05LSVBDRndrZHd5ZURIV0NOT2sxQ2pHQTVkTlU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsT2h2RjZWdWRzb2dFRkQ1ZlpNODJXaC1SNEZudkZKUVg1S2RSYmRiUVpsTEIwcVF3TWZucHR4Y0JUOU1ZRnkzdFhtVnhfZWdXM1lReUo0THNXN3BlR2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsbTVTR3BLZFBzX2tSZEVyUnBRYVh1VlY2U01VV095VThSbWNpc3hWUzFqdHpXVlB4QXZkT3BFbnpGUlcyTkdFLXhBTUgxTjJqdmdoeTlRTy11R2ttcUE9PQ==
"You could try [https://clipthoughts.com](https://clipthoughts.com) . You can add timestamp notes(annotations), save/export and share those notes. It stores the sections and notes in your browser history, so when you come back on the page again, your work is not lost.",r/machinelearning,Z0FBQUFBQm0yeGJsYmNwbkdLM0h2YmczVWVBZHV3MjctX3g1QkVlZnlRMDJNRWk1dk1MclVYUEdXT01kdVd3MkNVOGhqY0dDUlZHMFhHckhqVzVRc3hVR1NuZEpqTjItM0E9PQ==
"If you are specifically addressing a previous work or building on top of one, I think it sometimes makes sense to have a citation in the abstract too. As a reader, I sometimes see that, and can immediately recognize what they are trying to do. So occasionally, very effective at keeping things short and clear.",r/machinelearning,Z0FBQUFBQm0yeGJsSE44RjJtUWsxTDFJMmIwR042TnQxRHI2MVBDbGYzNnJwbE5kT01taWlVdUM4Sjc2b3c1UFZTM1hhanM2LUpCSG1BN2xxQUE1OWIybjJQaWVtem1sbGc9PQ==
Deep residual learning for image recognition and ofcourse attention is all you need,r/machinelearning,Z0FBQUFBQm0yeGJsQ29UZDY4OUg0NkpJMlhIOTZTcnkwMWllU28zWGlUbFUyTVFHelBqazJUcHU0NF96Tjg2OHJfYXJkQi1wSUFDazlyUEd0cGROTFhxT2xFN3gzYWFwbFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsaU5zOGFlVkdPSC1kSU9mRDdIN1MtRkhFdV91WmFINmYwWVk1eGVERG1DSlNrQkZDRlRyWWNWc3JYdjFJWDdMZFM1R2loNlZJZkVPUWloYk1WV2FpcEE9PQ==
I have been implementing ML for over a decade and have sat in meetings with both the CEO of Nvidia and of AMD on related topics.,r/machinelearning,Z0FBQUFBQm0yeGJsX2NsYzRWYVRRd1lFOHhsOEppUmM0cC1iemxpWHhUeVBpRFl6LUw5NXZYYmYzcjFWVlphLXJwQ3pHUW1CVngtTEVLMjRjNDBia0xTMEpzb0I4YW9KaVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsd2w0aDhhcnE0bVdKNE5vcy1TYjlBTUVLRlBTVGd5V3ZiNWxEY2p5QktqWWQ4aXMzNnZzRk9UMm9zRnoySncxaWNBV0pHZkRXeW5hWjNITDV6Z0VSYVE9PQ==
"ISIT is not the ideal venue for publishing high-impact ML theory papers that will advance your career. The quality of ISIT papers varies significantly, with an acceptance rate typically around 60%, making it more of a social event. For higher-impact publications, consider targeting COLT or ALT if you prefer to avoid the noisy reviews at NeurIPS, ICML, or ICLR. AISTATS and UAI are also reputable venues and less noisy.

Additionally, you may consider IEEE TIT, which can have positive impact on your academic career. However, its influence may also be limited if you pursue a career in industry.",r/machinelearning,Z0FBQUFBQm0yeGJsZlZKN25ZVDVMTXluQlo1Z0pCVENJdld1TmVtaFFuVkkzcDlNVWxtMnQ1TnVuakFZNENNREpZZVRkS2dDcVZzOFNCbGxSWk9DZEJQYmR0VFZoQ1FfeVE9PQ==
"Bengio et al., A Neural Probabilistic Language Model, in NeurIPS 2000",r/machinelearning,Z0FBQUFBQm0yeGJsWXhaXzFoMldhd1hSdHB5aGN0eXdaejFXRTFOenBJbkI5dTN6bVNZellVX2NGelB2blJPaEhWb1JDVXFCNjdEVXJId3BDczBCRXFFakNkRTJjSnFuZGl3SjQwWmxqQ1hnRWZucFBhZVltVU09
"VQ-VAE paper was fun to read

https://arxiv.org/abs/1711.00937",r/machinelearning,Z0FBQUFBQm0yeGJsYS03RVBaR0lhTVQyV0NBenRRM3h0R3F3bXBUR0hOWHk2ekdvU1FmQ3ZmeEtpaW15QnVxejJTNjRMLVFuU0NNM1MyaUdyaEg0d0VTVl9CaWZEQ1NteHc9PQ==
You guys might have forgot about the IBM technology.,r/machinelearning,Z0FBQUFBQm0yeGJsaXlYOXNiRlhGc2pXM3BnRmYtQ0NfSG1DT1FiRGVZaHlTLVBqQWdOU1REbTU5ZTJQWEw0RXNSSVBpaUpPWXI4M0pidUw4T25UbHZWMjE2bDRudHNTUEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsYmI2UHZYMEVOdjk3VDlXeGo2Nl9venpWZlp4VGp0b2s2QWxfUUNTN3pCa0tJd2FZTGpFMS1YVzRGblRjQTRTWVlHcGJCWk9KdUVRUEN3NnBnT3ZlSkE9PQ==
What are you looking for? Mentor? Mentee?,r/machinelearning,Z0FBQUFBQm0yeGJsVENFRXVxMWFVQ2VVZ1dobTJ1aVBQalJuSEVGaThOWUs2bzA0dWxUZ1RGZzRBX2N6Q3I2c2JBRC01cHpZOXB2WDJkQnBZaDQ0WTRzUXlIZWpocWg0cXc9PQ==
"Nothing too concrete to add, but last year I created a simulated environment using pygame for an ML project.",r/machinelearning,Z0FBQUFBQm0yeGJsNGN5RzFqZHM0TDlfX3I5LVFsSk1udWZKY2VwNTRzeWdzUmZ1RDBsN0VOclJWcTA4ME9lXzNKM0JBTnV3bnNmX0h0M2dGZVZuSWVELUk4Tm5ObVZsX2c9PQ==
Is this like a gaussian splatting to 3D mesh kind of idea?,r/machinelearning,Z0FBQUFBQm0yeGJsWDhkT3ZZWG9tMEZteE1faVQ3OVNUTFFwMnVXTXpiZ19makFjUlZpeldhUU1fbkFPeVppUGwxQUZGM21NUi01ZVplZEYzdTh6aTF6REswbzJHRmhrVnNwQVVKR3BHcFBMbktObnRxQm5nOXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsZ3lUYkNsRzZWTkZDTkJuTThxaVdFSUVHRjh1RE1mU0o4NFRsbEVTRENqODRpOTl4U2dianFJTmZLUl9JaWJJcTVrd0h4ZGxtY2huUUc1OS0tRTI1dlE9PQ==
Absolutely! Love the ideas about RoPE and Flash Attention for BERT! Mixing up the training data sounds promising too. Let's keep this conversation going! #BERT #NLP,r/machinelearning,Z0FBQUFBQm0yeGJseVJJMWhrYVJKek9kZlJnRDZ3WDM1WWhQalRwT1BwTjNRN3BsTXRvdHdwMV9Cem1CNVc1SUhxRXdqZkxBUS12RkRQSUJZUU5HR3JFejNOaDR2ZUZSdlVKVGZzS29NSlhheGp3azNFSVBTdUU9
"This approach is good, you can triangulate the markers' points and find their 3D coordinates, but this will be up to a scale factor. Now because you know the markers' size, you can re-scale the whole world, so that your 3D measurements and pysical distances match. That's the principle.

In practice, locating points isn't perfectly precise, so your 3D measurements will have some error. For instance, the further a marker is, the less precise we can locate its points (because we're somewhat limited by our pixels), so the less precise your triangulation will be. Typically, for stereo, the error grows as Z²! So using more markers is good, using more markers and estimating their uncertainty is even better.",r/machinelearning,Z0FBQUFBQm0yeGJsdGs1T0tMUW42dUkyQkR2NE1sM2xLVXlCaFMtTzlNUndvdU00N3diWWVkbHhqc2VVbHFGU3JhSXhNTldqYTVaRWtiTU9XakZQQUNURXA1dGpialNxNkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsTE5DNXJReVdSVjU2cU9URWk5OVZmRTl2bm12d2xTNVFncmt0X0lBUW1rQkhWV0NMTmllMlVTdVdMYS1QOHpKc1pTOUxkUnpBSWhHWll4ZWJ5WVYwRkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsSEQ1YlE2ODZnRnJQMjNPZjZ6ZmoteDBjanY1X0JJWHRfZzQwSElrcHdzczhvRVJJWE1iTkF5emY3bDBUektHemF4UXh2RUZfTTZXSFFjbnJVaFVFYlE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsUUhjQ2pHT3JyOW1WaFdVaWZKRUdjYWZ1aGNhUmloaXVFUFJ0ZnJoSExNbTVDb0tQR0Jtdm10ZkpXYkx1bGNER3kzc2lFdzlEWVRucW9TUm43YW5oZXc9PQ==
"I am currently looking into the prompt management feature of langfuse in more detail. while tracing is great and provides clear value for reasons already mentioned in other posts I have trouble deciding for the prompt management feature in particular as it ""abstracts"" you further away form the prompt formats, options and granularities and it feels like it is too early to do this. sure, the overhead is manageable and the latency is ok I guess, but while non-technical persons can join with (maybe non-really thought through) prompts that are then converted by the utility\\_method I rely on that conversion a lot? 

I would like to get a prompting management tool that allows me to compare versioned prompts for different models and use cases in a transparent and easy to access manner across 2-3 teams but does not get so , say, ambitious, that it wants to abstract me further away from the model just yet. 

it is a bit like the ""show me the prompt"" discussion I guess. if anyone had a recommendation for such a prompt comparison / management tool that is less ambitious to that regard I would be highly thankful. I keep looking",r/machinelearning,Z0FBQUFBQm0yeGJsWU5qY2xfcHBQOElXMEE4cVFBZHdDM3VaSVhnQnFYNmpYcUlZdXgwcXhDdU0yVGVxdVFUUnlHb1NJMEVQOWp3bFZ4RnpoY1ROYlBoT3pzcjE1WUxoYlE9PQ==
"Generative adversarial networks, the idea established was really thoughtful.",r/machinelearning,Z0FBQUFBQm0yeGJsZGlqTGFDZmV6SFFUc1R2OFR3YWVTUVdhbHhnbXpWX3FqZW5pVzg2OUhrZ2xIYXVrbkZuWTh6TjhQZjN3VE92TGl3bjZfdXI2bzFINVFRTWpoNjc2clh5MlNiN2pvMjQyU20xRVVOUU4xWVU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsSGl6eURjQm5Hcy1sM3lyRW5YclZ0YnJNLU0yRWdZOE1pSlBlQVkzLWlKandQNldOMEdYTVBjODJrVVctMVFqdV9QRUktREZVSmVEclJlQ05JVG9zWEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsZVRsaFcwY3ZUQXRWTnBpWUV4a1hURjZtNWlUSTQxLWdZRE1xTGV3MzRyTFVwMUQ2WUljZFdUeE1PbElDbUgwUE04Z2xWQkZJbzdtVVRlMTRTS0FMc2c9PQ==
Hi! I'd also be interested in reading your blog if you don't mind :),r/machinelearning,Z0FBQUFBQm0yeGJsdDVVWHJmMWlmVlVmWmF0ZVBUZVNocFhva0VxQ3FaRUtncU5VLWlyWDMwbW5aMmdjeFhzVTZFWXh6UlpyRGlCVG9BWjBvQXZuOE5CdEJKWGRwQW1yaFE9PQ==
"Could you clarify,  as CFP page have following date ""**You can enter proposals until 2024-06-09 23:59 (Europe/Amsterdam), 1 week, 2 days from now.""**",r/machinelearning,Z0FBQUFBQm0yeGJsdVlxVkZUaEFGTjlLN25seFVqRk9YZkRPeHFHLVpKRUNlZnJxdVRaNWRMTEZMMTRDdS02bUh4ZWt0dGg3djBZUW1hRUJiaUNFZ0dFRFVCdGZSRnFlN0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsa1VOYVItc3NSNFZYQmZPUE9aQ0NTOTlMeHo5SUw4Q2ZDY3RXY1J3cVVraUdFNnhYUWdzSzI1NlRoQzB3U3NsS0ZyaWxiR2YtaFpvcDVHck9BOTVlcFE9PQ==
"When you have a good set of work it's usually a good thing to send an extended version to JMLR. But anyway the ML research system is currently in a broken state because conference papers are used as proof of work/value instead of science.

[https://www.jmlr.org/](https://www.jmlr.org/)",r/machinelearning,Z0FBQUFBQm0yeGJsTS05ckdHQllXaHhXeldPV3gzNkZYRDBvclpBZGw5MTZiSUxvZDBTejQ3VlBibUVnbDBpMnVtMC02Wmt6b1VSNzN5Z0lwbnJOMmdVS3JSdzV0VDBiRnVZQjZ6cDRsSVk2NXJmR0lLaEl1eHM9
for a second I thought it was a typo GAM/GAN ;-),r/machinelearning,Z0FBQUFBQm0yeGJsbkhHWEhpZlNac1ljYndlNEtEYXNrdGNneGdvLWxvZDU2YTBGenpRMTJMbFZJVzAwLUlLTkhvRVRSbnJmeDFOVVdSRE8zR1ZQcjZSRWRNbWdBMUwyVUE9PQ==
"On GPU yes, as I'm finding out. I failed to mention that I'm looking at more constrained HW platforms such as FPGAs. Thanks!",r/machinelearning,Z0FBQUFBQm0yeGJsbEIybXg3dE52cXk3ZEM3elZuZl9Ca2hyU0JXcmJGT0NIeUtDc3ZlWkN1aF9kNndBaDdHSTVWVzdodXdjbzJGM1lNZ2VNelJhNGNKQXNKOUl2NmluMWc9PQ==
"Thanks for this, added to review list.",r/machinelearning,Z0FBQUFBQm0yeGJsM2RrM01kRlpRUzR5dlZnV0QzZUp0MlUydkUtUnlLWjQtdjJtN0ZXaUhUeTVZQ3p4MHU5c1JadHdkRGhRUU8xbkpUdVV0VEtxY1FyTHd0b1JLZWQzLUE9PQ==
This is an excellent resource - thank you.,r/machinelearning,Z0FBQUFBQm0yeGJsU1IxNXlpOVBWVWo5RWpKTXM3M0VyX1d5clRKT1hVWU95bFVrYzlkRzMwUHRDT1AtMVoyZmhsSUloamFqWE14endUYW9pdHRGVjJPN2tXYVNITjRnM3c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsajcwY25JRHp5M1BqLWdFTDFUalUxVV9wVnVidUZBOHpjSzZuZVc4ZXpxWUdMS3lTM0R2ZktPTk1ITWM1d0lQUmVZLUJHVWhVdnQ1UXVjdUd2a2hWbkE9PQ==
Will you monetize this in the future?,r/machinelearning,Z0FBQUFBQm0yeGJsbTM4VUlUWC1OVm9oZkpBcndrQWFsRnl1ZzhMekZLaFRSUjdmQlJnSExrM25zamNVV19hSUI0bWNpb1E0ZmltY1A3cmYyZEpQWVJ5MklRWWtTc01hOXc9PQ==
I wouldn't want a tenure track position at a university that doesn't value me publishing at the top venues with my field. What are you going to do the next  7-10years? Only publish in the journals that they approve and become irrelevant in your field? ,r/machinelearning,Z0FBQUFBQm0yeGJsVXhfUjNHOTRhZDN4dGF3Q1F1MzVSLUZ5YVdUSHV0cGxicDR5Y21YZElnY1NQX0t6UDBYWmVHUENQQ0RlSmlacVY3Rzh4UFZNUG41a0Q0TG0tMm9MaFE9PQ==
"Hey everyone,

As a professional at CETPA Infotech, I'd like to share my perspective on the evolving field of Data Science. The notion that ""Data Science is dead"" is a bit of an overstatement. What we are witnessing is a natural evolution of the field.

Data Science is becoming more integrated with Machine Learning Engineering and Software Engineering. This is because the complexity and scope of data-related problems are growing, necessitating a broader skill set. For those in Data Science, this means acquiring software engineering skills to effectively build, deploy, and maintain ML models.

On the other hand, the role of a Data Scientist is indeed diversifying. While some may transition to ML Engineering, others might focus more on business analysis, bridging the gap between data insights and business strategy. This shift doesn't signify the end of Data Science but rather its expansion and specialization.

Automation is streamlining many routine tasks, but the core skills of a Data Scientist—like problem formulation, data interpretation, and strategic thinking—remain crucial and irreplaceable.

At CETPA Infotech, we see this evolution as an opportunity for growth and innovation in our training programs, ensuring our team and students are equipped with the latest skills needed in this dynamic landscape.

  
Thanks!!",r/machinelearning,Z0FBQUFBQm0yeGJsQmVwWTBYa0V1ZzY5enU5QXd6UkwwLWNsRWNid29UQkhKVkpGam9keG1UQjlPNlc5a3E4ZGFoLWVqSjdJX2xTZEwtck0tZ3NwQ2hxQnY2b3VuRmdKVmc9PQ==
"I have never seen a hiring committee not recognizing top conference publications. That being said, I preface my publication list with a short paragraph on how in my field, the most prestigious publication venues are conferences and that submissions undergo a rigorous full-paper double blind reviewing process. I also mention stats about acceptance rates.",r/machinelearning,Z0FBQUFBQm0yeGJsdk44MDhGYS1Ib3A2T1lobklablBISmtUaDZTOW9CUmJyT3VBUjdIcFBCb0dsaE5vYmstVnRkN3MyRDdfMDVxTzVoUFdXamhVU040bmhLd2pINGJZcnc9PQ==
"Well, I both agree and disagree with you. Given the choice, one should indeed ceteris paribus go to a university valuing really prestigious ML conferences over publications in journals, but let's be real, it is not always the case that you have so many choices for TT.",r/machinelearning,Z0FBQUFBQm0yeGJsV0VLZlZjZjc0RUhQWWFFQWJuQTdYS0tTWkV0dVAtcm9FOUctTW9TQVRzSUpUb2oybXotY2c4eGhmeEF4em94RlVHU3EzVm0tdy1lRkhWWnJQZk9ZNmc9PQ==
">I have never seen a hiring committee not recognizing top conference publications.

Welcome to Eastern Europe, then!",r/machinelearning,Z0FBQUFBQm0yeGJsWmRERlBWNk5iaV80WFVyVXVRVnFDSGszOGVNaWpubDJZOGFOYjh1QmFjOUYtTGdJak5aRm1BUE1Hd2xyWWkwRWxkMlRSMW5IUFRJb25na21xdHNJZWc9PQ==
"You publish in both conferences and journals. The conference gets the original research and the journal gets an extended version with a slightly better method, more experiments, and more analysis.

There are lots of good journals like TPAMI, TIP, PR, JMLR, NMI (although new, it has a high IF).",r/machinelearning,Z0FBQUFBQm0yeGJscV9mUDk2cHA4ZlFKdHVoeEl3UzFpR0c5UmsteFhDbjJZRmFaSjVPbThCT1VRWk05cEdVZHhzSWhOSFlhSy10bDNWZTl5LXQ4WjZxa1NSTG8yaWlJS1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsWGUyTHpRRmJvcDMwRlp2UE80dklSc1VuZmFJeldZcXdiWHBuWXVTbkpSX1hjaGNJbTNfUlhvZVNsOGhNS0dyWmJCMWFlYVZOZnJvOW5PWFpUczRXeFE9PQ==
"It'll cause a lot of issues. If you can't publish at the top venues (because you have little incentive to) you'll have a much harder time getting good PhD students, which means a harder time publishing. It'll also be more difficult to get large grants. And it'll be more difficult to switch to another university because they'll value a different set of venues (which makes it more difficult to move because of life circumstances and more difficult to switch to another university if you don't get tenure at your institution).  


I absolutely understand your point about sometimes not having a choice. But I'd think long and hard about it and i'd always favor another school if they do value your publications at the core ML venues. ",r/machinelearning,Z0FBQUFBQm0yeGJsVVR4RWlCRmgwbC1jYk13VWJ4OWFXVHJPRHktQ0wtOHJHbDJGXzdOY2dnRmkwSEQzZVlNUXZCLWtJRU00bi1Va3hTTkEzUmwxQW1TdDRYNm5BalZjZEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsRWJ2ZXBFcWpPX1FIV1JjYVp6eXUwcFowSmlUWVAtRGU4V0I5dGVuTFMyRmJISzRWcWFtY1pacWtWYzRsRjRINENSRFNHZVVRV0NHcXl0WkduZHc3T2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsaURaV3Fjdm0yb21yTE93dU1CVGNYT3ZCWFk0eExRazVkbV9oV3IxMHNleWpYdmVqTDhnbGQ1bDFjVVBBN1RKa1QwVlRRY05mOGMxYVNUX21QazdLUGc9PQ==
https://www.reddit.com/r/MachineLearning/s/OLY6ENfdqu,r/machinelearning,Z0FBQUFBQm0yeGJsS3pjVTMwNlhuNGdFNUJ2c09rWG5HX1FFSlh3UEJ5LVJVSi1qYV9PeHI4MHB4U28zUjhBVHFPTFdVeXpBOC1BZExBVkFkcGZnR2dYa0RISUdMeUE0TkE9PQ==
"Awesome, thanks!",r/machinelearning,Z0FBQUFBQm0yeGJsa2FYVC0xUjZOV2M1NVpibTN6UkVZQmlpZ3RhNHJrVW0wRTBCb1BvOGo2bzF6RTJXelpSTkU4YTRsQ0lHV19OdWxKS04tdm5ubHNmQTZkck9GNHIwbVE9PQ==
"> and Redmon is/was a super friendly guy that answered all your questions on his Google group.

That is so dope. I never even imagined reaching out to the author. Not being an academic, but reading papers just because I like finding cutting edge research, I end up imagining them scrutinizing me why I'm questioning their work.",r/machinelearning,Z0FBQUFBQm0yeGJsTjdKQ1RON1Vad3hFT005VUNBUXc1M2NYSk9qYmU5dWFLM1ZveVczWmFvWmhjSk1WRm10dGZ6NHJ4aTFxYWphQkI1TllUMjhnV3NvcUtnUU52R19ubnc9PQ==
"Would love to chat with you! I'll drop you a Chat.

How would you expect the tool to deal with the different prompting formats from the different models (llama vs chatgpt vs gemini)? What about tools?",r/machinelearning,Z0FBQUFBQm0yeGJsZS1mMVRxMHZnTlhmOFZVel9UeWZpM3ZWSjJuNHl4cWJPT2ItWDBGYVVDNnEzMDlwa29kc3pYOGpLeTdxU3Q5RGZvbDdQY1RWcWgzXy13VUtvWXRfWlpsbjBKZGtwRFZzSkRXa2xhU3I2T2M9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsYTdPc2poaWZUanNsWXh6ancyM0FWbFNyTmxuUFZNZzQzaEtWclFWTlN4bWRVbmZkd2lxWHB1V1JXU3RKMFVMRjFSSF8xMTFaYUthRVBqOEUwY1dncmc9PQ==
"If you can't publish at NeurIPS, ICLR, ICML then I wouldn't give you tenure in ML. If you are at a place where they don't value these conferences, then leave.",r/machinelearning,Z0FBQUFBQm0yeGJsTUk4RGJ1Y0JJWW9MR19HUW5fWTZZWHFWVHVoai1NZG5zaG5lN1AwVDd2V0xkZGFDc2lOZXU1RGVDWU04UlI1dmlUMXlyS0JJaU5od0VXek1VcVdwM2JZbk15SzVTUmlFeUJ1QnZNZTlleVk9
"I haven’t applied for tenure so can’t have a say on it, but I have applied for immigration based on my publications, and for computer science field, top conferences are just as prestigious as top journals. I only have conference publications, and my lawyer has a paragraph in the petition that explains this difference in computer science vs other fields, and the immigration petition got approved. It’d be helpful if you can consult this with an immigration lawyer",r/machinelearning,Z0FBQUFBQm0yeGJsOGE0NEhIeS1YX3hVU3kzVUUxR0Z3c2t2VXZmelhPV2Zaak16d044RnhYTTl4SFZoZV9hUkRQUGNQU1R5M1hCSDRYbXh0aDVod21YNUxaS2xTMWtVUFE9PQ==
Why would you want to immigrate to Eastern Europe if you have such publications tho,r/machinelearning,Z0FBQUFBQm0yeGJsZUYyUEdCMUVNQUhZaXU3bzFGNUdRQ0hNV1RkVmdRTHRsZXJLOG5GZHhkSEdBNEs1VWZKcDMwT3BJSXBCX3p5bnhQWmhaeWNwYTZmWXczd29WNlEwb1E9PQ==
Pro tip: you don't need to immigrate to Eastern Europe if you already live there.,r/machinelearning,Z0FBQUFBQm0yeGJsd3dvM1VoNVZCbHdweVd1eEhWdWs5SG52RGNjZzhLdXIxOGdSWW1iNHhsSTZEckpvQ2ZkWlFFZnJPUG5tdm1GQ0RfSEVTUkotRklOVXRXUjN2dHl1SkE9PQ==
"Llama3 blog post said they did it, also when doing so you adjust the the positions accordingly",r/machinelearning,Z0FBQUFBQm0yeGJsZzlmUlJ5bHEyWk50U1k3Tm94SEVHaXd5akZkSWpyZThIdG9YemtyTW81TXk0WVE0dzd6SUZ4Qk1YeVBUZVA4OWs2SXZjNWFYbFdUWXVONktDUTdkZGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsTHJTem4yYUF5TU14QVlJNFlPcXpNWllrRFEtd1lRMTVsODJ5dXJfRmdQNFVLeWxHb2xTM2xSSnItMURKT2oyTi1NY3Y1OW00eGxuRHhTaXZZUDdfS0E9PQ==
"Most researchers are glad to answer questions, especially if they're not too trivial. If you need their input I'd advise you to try and reach out to them. Of course don't start with ""your work sucks"" lol.",r/machinelearning,Z0FBQUFBQm0yeGJsRVVjcF80NkZUTEV2MTE0MGJBTDVqcC02SlZDOFJFa3VueVoyTEJ1TUFaMmtRUUJlTVlYX1YzcGJ0Q1h2bFBDUTRJdDBYM1VCLXQ0T0lHR29XUkozV0E9PQ==
This API was built for professional research: [https://chatgpt.com/g/g-BObYEba3a-ai-mecca](https://chatgpt.com/g/g-BObYEba3a-ai-mecca),r/machinelearning,Z0FBQUFBQm0yeGJsWkxqdVlTSldPNjNkR0U3VlBEZi1nMk8wM2IwQ2NDX09RNDdFV2pieG5XN3Z3LWVNaDVuSzZ1ZlFFamdUeU1mMFRjRjQxWE9SOGFOVmQyTjgzRTZmUUE9PQ==
This API can give you full technical details on KAN and GAM with the provided coding: [https://chatgpt.com/g/g-BObYEba3a-ai-mecca](https://chatgpt.com/g/g-BObYEba3a-ai-mecca),r/machinelearning,Z0FBQUFBQm0yeGJsMkRIMkNfa2xYall6a0NfcmtEaElTdHZaVlhQanhiU05PMFZkellFdzh3ajlqeU9YM05DYWQ1VTdFc25fYkYwa01iZGlOWkRaaUJmMUpRTHlFNlVpSVE9PQ==
OK. This is pretty hilarious. I have a new role model.,r/machinelearning,Z0FBQUFBQm0yeGJsSDYtU0FwWTVOTXotZThJUnBNcHNqbXgydno0WF9GdWNHYkpfVnl3UmFKTzVsWjViVDNDRVNjUThjZGJfeTh0TkFuQ3llWkg0T3NwZ0pLUDEzVmRfVmc9PQ==
Wow😍😍,r/machinelearning,Z0FBQUFBQm0yeGJscF8wVGlFMEl2Yl9VMFR0eXBkZkt0UVJCQnRjdTlBbV9hMXhrbGhjeXpwRzJHT1MwazhuaUpCU1J2dV92ZXpMTVJiN205c25CTXFhRUdVRTE4RlpnMEE9PQ==
"It depends on what field you work in. I am in a stats department, where all of my colleagues publish in journals. So, while I publish one yearly top conference paper (I have a NeurIPS, a KDD and an AAAI in the last three years), I publish most of my work in journals. It helps I am in AI + Finance, so my more technical developments go to conferences, my more applied / experimental work goes to journals. The department does value my conference papers, but if I published only in conferences, I would have issues.

If you are in a computer science department, they should value mostly your top conference papers. There is a reason CS Rankings exists.",r/machinelearning,Z0FBQUFBQm0yeGJsaXdtUGJkZW1JRTZrYVlVa3h4Nl92WXB3bmU0M04xSE4wRURCWnV2cl9aWTROVGNraElMSmdIYjYzZFE3VVdsWGRhTURJR3BKTEE0c1FXQXM4Snlrdmc9PQ==
"Nice, thanks for the hint. So for example in Huggingface transformers I should set [position\\_ids](https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2Model.forward.position_ids) correctly, e.g. for a packed sequence `[bos, ""Hello"", "" world"", eos, bos, ""Yes"", eos]` the position\\_ids should be `[0, 1, 2, 3, 0, 1, 2]` ? That does not solve the cross-contamination but it's a start.",r/machinelearning,Z0FBQUFBQm0yeGJsaDRUM1JRcDl6WE5xeWlmWWZPVUJ0NmFkX2x6MlRxa1l4RWVwYXczRDdXazJwNXVwRXhlUDFMUmZmblRWRmZoUE01b0VNTHNsNnI2VWhLNWpiU3RNNlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsWVM3bWlVU0R6UU0xUU9lMEZ6NEwyMGdjbTMwWjFzai1ZT1FwM3lOSmswUTNDYWZvZjB6Y242VXFpSVJveE5aOGlWQS04djhHdklWc0FMUDA5aHIzZlE9PQ==
Then you can emigrate from Eastern Europe,r/machinelearning,Z0FBQUFBQm0yeGJsdW1TQkpRYTVnN1poV0J4VTNJNFF4Z0ZmVWtvaDhDZEtRSWNaQVZhTGxGQzZJdUdFaGRkaEZZeHNaUlVtanJHVVRnanA5bGMxcF9ZYzFfUGpaOG9VYkp1Z0EzSmF6Q1AtUTNQVUIzSk5PckU9
Yes provide position ids like you wrote also provide full attention mask like the blog post. Both together will address the issue,r/machinelearning,Z0FBQUFBQm0yeGJscFc2QXpWZmpIdE5LWGpyMEZ1QV9mQWFDSExZcE9TZXNqUklIZjlUTGdJSmRQZWVuWFFMNWlzVUlpTndoQXA4YnRNbC0zTGJBVVlPQmNhbW9oUmZkdFE9PQ==
">rigorous full-paper double blind reviewing process

I wish",r/machinelearning,Z0FBQUFBQm0yeGJsd3dSTnBYX0tvUFZJZ1ZZU3hZMEhodGc2SEJVdTBoYkJTNl84YUZ3YmJsWmpOTWx2d2VoSXBSWERhUDE3NWxFQThzeF9qV29URkVHYXl3OGNmbnprUUV3OHlIMVJybXJrTVdrT2VpdTI4dzg9
"Computer Science as a discipline is a bit different from other STEM fields and it is more so for ML. In ML, the researchers value conferences over journals, primarily due to the pace of innovation. You simply cannot wait 2 years for your manuscript to be reviewed back and forth and then rejected by a journal. Your work would become obsolete in ML with that timeframe of review. 

Only research that comes out of very mature technologies with a big author list, would be submitted directly to journals like the work of AlphaGo and the likes which were submitted to Nature. That being said, a lot of the ML conferences encourage submitting extended manuscripts after acceptance, to their sister journals like the transactions in ML ones.

I have never seen any CS department in top universities at least in the US, not recognizing top conference acceptances as significant contributions.",r/machinelearning,Z0FBQUFBQm0yeGJsZWJhTHZXSk1iNEg3ZnAwM2lnOTZvQ2dhTFp3RktqeUJqTG40LTFreDN3ZUhVNEdsWTV4aGZRWnZrdGtWRUJ4OVhNY2dUckdFa2xiY08tc25uTElhNzVQdjY2cTBfZ1lyTWNidmdLNDJWdWs9
Y'all really think that Tri Dao got the Princeton professorship offer straight from PhD based on journal publications and not for pushing the LLM field farther.,r/machinelearning,Z0FBQUFBQm0yeGJsODZDV1gyQ3pCQ3NKT3VNQ3BFMVZvY09YdDFEMjF2TlI5ZzJnUjVkVzRxU0hjSENBZGZSQWQzc3RiQnpZUXd0dFQ4ZFdHUktpVHhlVmowUWFLeW1wY2c9PQ==
"You can take courses on Linear Algebra, Optimization, Inverse Problems or even Machine Learning itself (universities usually offer these courses). Then you could write your thesis on a topic involving Machine Learning. There are many, look at the research groups of your university and check what they do. ",r/machinelearning,Z0FBQUFBQm0yeGJsbTJCY2JCMzBVRFdjU3B0c2hYdGNGcWNxTi1tSHNlSWVnNTRnS3lXV3hMRjhOQXZzOFZDc2R4d0VmRHlJcTlHaHRtNTM2bm1IRlpLSVNrT3R5V3ppTEZPRHdLSzM2bWNNQ056UEdvVkZwZnc9
"To avoid having varying learning rate, one can simply normalize the weighting vector. Thus, the loss now is a convex combination of all samples within a mini-batch with their own normalized weights.",r/machinelearning,Z0FBQUFBQm0yeGJsSVdnWG1LamYteElxZUVHWFJvNVk4dE9vWFR4NG5vdDFsYkotZ2l3RTNLT2NRdG1hRFA3M2ZlODZvaDFGazVpWEV5RHFjMVFlSW9OVkpfN1ExOUtrV3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsb1VqMkRlSkZYSVI1V3BYdmpqUGxZSDF2djN5bXhPV1p4Q01hQUNTaXFYTDNwb0xuRVJnSVR5UEZPSTQ3ZEJmeHRKZks1XzIybVRiR0VZQVNhNWt5VEE9PQ==
"Most Machine Learning projects published in top conferences is python based, so c++ might be overkill if you just want to look into the ML part. Most machine learning code does not really make use of too many OOP principles but it is good to know nonetheless. However, do not neglect the math basics that are necessary for ML. Python ist just a tool, to understand the ideas you have to look into more.",r/machinelearning,Z0FBQUFBQm0yeGJsVmZmR1pUSlkzOFE5eWxVU0x4cGc4S1lSZGpPelYwWGtZd0I1X2NnSUlIb25hYUYwYVZDOElNS2FndjVnWWIyZzVNUGVyUEhZX0ZBZGtlVE0yRG5RYkx0V1pTNzFENHF4ZDV2RnRBa0R1WHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsVEFJVFVxVy1CRlNpUzJZSlFkLVRHN3JPcFRhd0lEaXE5eTlQNXVaXzRSekFzRWxRNUFXdmY4NFkwZHkzR0VjY0JRT05KTGdzQkZQYUYxWjJ5RDZzaXc9PQ==
What do you need to simulate? A 3D rendered environment? Tables of data representing sensor outputs? Other?,r/machinelearning,Z0FBQUFBQm0yeGJsMzlCRXJPbHNUSUdveWZhMzFwQmdwbmxnYmdYSTJTamVnaXFkVkNqYkc4Nnk2M01JVFVPUGFkdFhJRlVhb296WXJOajB5WVc2dVM4MXp3Nnc1ZVJfR2J5ejF6NnFRUVhBenFFRU1sTU8ySVk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsdnl3QVVubVNoRlloUG1xb1owakM5QVdqVnJNVUgxcVQzTzZnWmlxUTRUM010NTFrdGQ3bEFpLXNnd2pTZW1MOGtlSjNXOTdFU3RuaFdCT250NDlnU0E9PQ==
"That's some amazing and insightful advice, thanks!

On a more serious and less snarky note: you see, there's some kind of a vicious circle: to move to a good institution, you need to have good publications, but it is hard to get good publications if you are currently in a not-so-good institution. In the context of this particular discussion, I would love to work on a problem worth publishing in some prestigious ML conference, but:

* I'm busy working on all kinds of progress reports and publications for lower-tier journals to stay in my current position;
* I don't think many (any?) of my colleagues are really eager to work hard and dig deep to publish in top venues, so I would need to work rather on my own.

So while I am not saying that it all is hopeless, I do maintain that moving to a more prestigious institution *is* challenging.",r/machinelearning,Z0FBQUFBQm0yeGJseklXNHl6R0Z3ZTNWT3NOWnhuOENCRE1pY3h5aktUQjU5M01jZjhMNnJVMHl0Qkl2RVdGMWNUZkU4NEtEQTZlR0Jid2tVLXJQYno4WkZqVENvVU4xaVE9PQ==
"This review talks about KAN with reference to spline networks and other things, the point being this is not the first time this was done [https://vikasdhiman.info/reviews/KAN\\_a\\_review.pdf](https://vikasdhiman.info/reviews/KAN_a_review.pdf)",r/machinelearning,Z0FBQUFBQm0yeGJsWVlSSVc2Zk05UGJYajVEa0hCeEljelRMOE1PMGhsSFNJY3RlcVNYaUpReTRYYmN1ZVRhT3ozaG5LQWlUM0FraUQyLVBiZkVVT05HcDJzV3NoVWFmYlE9PQ==
"Similar, except that fringe projection uses structured light patterns and camera systems for capturing and reconstructing surfaces, while Gaussian Splatting uses point-based rendering techniques to represent and reconstruct surfaces from point clouds. The approach is kinda similar but the application area is different",r/machinelearning,Z0FBQUFBQm0yeGJscFVRR1ZOcW41UktnN29GaWpiZ1B3MDJDWGViZkh3bEdqb1BhRHp1dmRXVnZqRC1wZzkwV25RVU5aY2VST2pDamRld016azFCeDk2cnpvU1RJRUQybGc9PQ==
Hey! I'm mainly looking for academic collaboration.,r/machinelearning,Z0FBQUFBQm0yeGJsUkktVEZmRnhPSm1kblRKMkFCM182dk1KNlRtUG84aXNpTWtKNW45d2d5VnUyaUh0QnJaRWhtdy1MSmVfdXpqVnhxaW54VzlKRWZhbHJ5UldRVWlSU2c9PQ==
"I'm looking for a mentor or someone to get productive with. I started that topic during my PhD so I got some work done, but I took a long break, and while I enjoy doing research, academic writing isn't exactly my forte.",r/machinelearning,Z0FBQUFBQm0yeGJscThna0Fvcmd6c2RPMnNFMldDYVBNclExd00tNGw3SGRkMDlzdi1MSlVuZTA3UGItTjFRdkhqajYwaDVISTlmbml2YkFiamdkbWJheTNOSFVqMVRYT3c9PQ==
Thank you so much! You're too kind,r/machinelearning,Z0FBQUFBQm0yeGJsbUtXZV9mNmVGMGZoeG9NVGtDUXU4SUJQbVZJWWZzbHYtOVlRbFpUbXFKVTNjbzlRWU9fTFNLNmc1MmVTZXV4Vk10enJydGx4YldhcVRBck9OeUdGVFE9PQ==
"Although if your data is arranged properly, that 'contamination' can be a good thing because documents are never totally independent of each other and it creates long-range connections that teach the LLM how to do long-range reasoning & inference: https://arxiv.org/abs/2310.10638#facebook",r/machinelearning,Z0FBQUFBQm0yeGJsTndLc2lNQ3FBUjVWaHlBQTNFLWJhanZJV1FZY29WRFJ4NXFSdXVwc0tHMVNNMlRaeFJJWnZXUjAwdEdmcmNqaldkX3FaQzJIbDhjeS03RDJZSUlhQlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsdkVTZ3VtZEpjNm9wX3M5dVd1OG5YZFJ2a3lvdl8zcU0tRUkxRlpoRHh3RHAyLWhfOEQzYjE1VlliOHFtLWxKMC15SVgzMDhvOF9Lbng4T2JybkdPdUE9PQ==
Sorry to burst your bubble but no you are not ready. You are at the point where you think you know alot and as soon you get real world problem to solve on your own you will get stuck. That's universal with all grads not just second years... Anyway keep learning find an intern or grad position and keep learning,r/machinelearning,Z0FBQUFBQm0yeGJsclBPZi1UQUs2a3Rhd0pKMFlWT05ObWxFTkVfNHFKTm9HcDFhdDlKckhjMFE0aUdXeTE1eml3TkFXZGVSbmlhSlpFMjRjTEFLN1hJem56MWdESnpNYlE9PQ==
For what it's worth I trained a UNet and a deeplabv3+ on the same dataset and got slightly better results with UNet after extensive hyperparameter optimization. The task wasnt exactly image segmentation but another im2im problem.,r/machinelearning,Z0FBQUFBQm0yeGJsWElOQk9JbGJWTTU4TVFIN0Y4cjRKS2VVWXR6ckl1MHB1bWNjT3lhbTg4NDRQWkVCRDBheUtFS3VaNy1jUm42MUVZVUs3eEVrTFl5YW5GSkx2LUdhb2c9PQ==
"Sure thank you! I've sent the link in a message! I think to unlock the chat I need an invite or something.

If you ever read it don't hesitate to criticize it or to pinpoint any false/wrong thing you come across \\^\\^",r/machinelearning,Z0FBQUFBQm0yeGJsYVNFQmxtQnhKSHMzanFvMlBqLTJfYjllUkFjcWN3dWZickF2VHhqOVRtRjlNckd4RVRTdF93cU5Zc1dLTi0wUkVkb1V1YjRwMnJQc002UjJSNmlSYmFmYzZQaUgzbEh6R1l2Y0lzcmNRMjQ9
"I know that I am not ready, the post was to ask how I should proceed further, I just don't understand what I should be doing. If you were in my shoes right now what would be your learning procedure?",r/machinelearning,Z0FBQUFBQm0yeGJscTl1ck1FaWVURWI1d1JKUHIzaVVxdVVXVnJaZ0N1V0JNcXZva2RObFJEdlVlVV84bG1Xd042ZEtiNVBPZF9WSWdWUlF3ZDBQcEc4ckw1RG9ja2pRZDFLelE0UlZsb1JNOHE0d184d2N3Tm89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsSS1xOGtYUmw3TkxWcmpObzJiX1psczlMWGZqbHFSam9XaHFsdHpLbng3X0xQeF9vbWswREtfR3JMVEtodEtNV0FDeEtKcUdVeVZielIzd2ZyRFJEeGc9PQ==
"There are some significant areas of misunderstanding here. For one, a GAM does not have to have a ""link"" function. The ""link"" function in the case of using a GAM for regression is just using the identity function. That is the equivalent of what a KAN neuron is doing. To keep it really simple:

* Linear regression is a weighted combination of variables (plus a bias which I will ignore from here)
* MLP: weighted combination of weighted combinations of variables plus a nonlinear activation function (ReLU) which itself is just doing a spline approximation of a true function.
* KAN: Linear combination of learned nonlinear functions of variables with splines approximating the learned nonlinear function.
* GAM: Linear combination of smooth functions of input variables, with (logistic regression for example) or without (just regression) a link function.

Lastly, with GAMs there are many ways to do it. You can use a predefined basis expansion of your input variables and just learn the coefficient on this expanded feature set, as is done in a Volterra nonlinear model. With KANs we are learning each of these nonlinear functions with spline approximation.

Edit: Realized I kept writing GAN where I meant to say GAM. Damn GAN/KAN/GAM acronym similarity!",r/machinelearning,Z0FBQUFBQm0yeGJsZVBDYXYwYWc5Y2tya0VhOWZQM3Y1NHRkeXFBU1BxdmFCOGRRUExFRjRCWTUtOWF1RWl0aE5NLUN5RDJIS2tNMGY3SkV1VlpaZlYwc3pPOUxBaklsVFFKYXBTbHNtMFBQTS1td25aRXVjR1E9
"Many journal papers start has conference papers, but it depends on the community / journal.",r/machinelearning,Z0FBQUFBQm0yeGJsT3kzTkZ5NmcwX29jM3p2OXVsYU5TcnBxMktaUjI5djl4d0d3WmNDanJhTC02WWpyU0YtcDRheWtlU2xpX2g0UmdwNE83MGRHb2dKSl9vTDJaQ0w1c2c9PQ==
"I am in academia, exploring new ideas. I work mostly on applied ML especially reinforcement learning for solving real world problems. But I am interested in computer vision as well, if you want to have a chat feel free to dm me.",r/machinelearning,Z0FBQUFBQm0yeGJsMXQtLW82NWY1dXNHeVRHRFF2eVYxWFVteC02U0wxdFBSZFVRdzFUdVpaSEJubW1sS0Q1X1J5ZUZCbzlMME83bkI1UVlsYndBT3NXYUVHSWNTZGtEN3c9PQ==
"> Of course don't start with ""your work sucks"" lol.

LMAO! Therein lies the issue. If their work sucks, I read the abstract and results before laughing and move on. If their work is mad dope, I make the assumption that they are about as reachable as any other rock star.",r/machinelearning,Z0FBQUFBQm0yeGJsemx1VWJlOHBqdl93RFZUYWZiSDIzZkwxMWFfbWNtcHhlcjZ6NWFmdXZwZ2lqSXJtSDBLcGJSdVJnRTVISGNydGdjdkluWjZrQi1TaDZYemJSSWNIS1E9PQ==
"Get a research position for sure. At least talk to a professor to sort yourself out. It'll give you a direction to study. Depth before breadth imo - you don't need to know everything about everything. Know at least basic CS command line stuff though or your research will suck (most ML research is on a high performance cluster).

Generative AI is also not really a topic. You can do images, text, or both, but you should really focus on one or the other first (either computer vision or NLP; these are the two general fields professors usually group under). Most people in NLP for example still have a very deep understanding and appreciation for encoder only models like BERT which isn't really generative technically and this is important to distinguish",r/machinelearning,Z0FBQUFBQm0yeGJsX0hqY0pFaGJOZEh3RnpMTW5HMENnUzBCUVlmWXo1U1U3R0h1RzdtMV8zYTA0c05IMUZyQXhncXVVZ1NRSUM4eUtvY1RsZjd2eHhiU3YzajFNLVkydEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJsVHJJMHhIb0dLVGFuNjlHQllIaVpkLW1ucXpLV2h2OUFlWERlaC1qSXVZN1dWNm9jMmJUS1dZTmF1NEF5NEFFelRfLVRoejFEYk5nbndUbkZRWDNQTUE9PQ==
Pick something you care about as a project and see it to completion.,r/machinelearning,Z0FBQUFBQm0yeGJtU2RmVWRsYjRyR05pNmNlSEp0T25JMDA3dG9mYlptRVFFSXNUU0NZNXhUNlRxS3hPR2tVZ3h1cWpGSS1WLUtfd0NIN1FIejRaVmVKSWdaS0NxUkxxdWc9PQ==
Is it also good to read more about breakthrough research papers and implement them on my own? Because I feel like I still have a lot to learn.,r/machinelearning,Z0FBQUFBQm0yeGJtQ29PWDBrM2kya1hRRk5Nc3VETk5fTV81ekltNEMtN1E4Ni1WbktXcGdIZjVHcDRULWR1Tml0Z1d0OHpYbHdQMm9XWXd6RjFOS0lUdm1pWVNwYTdoTGdrV2VvLTJkdnp2VTU0X2M0NVhOMDA9
"Thanks for the advice. I should have been more clear, by generative models i meant specifically CV (VAEs ddpms etc).

Also, if I read several research papers (narrowing down my interests and breakthrough papers) and implement them on my own, is it sufficient to get my first research internship under the professors?",r/machinelearning,Z0FBQUFBQm0yeGJtc2hyWThBclZWcUlnckpyWkI5MnBSS0MzdG1HdTJzN21nN3Rfem1pdi1ObHcyX1RmMWtRcHhoNE9UUld2dXZPdENlWW1FcVpRNk50VFdvcUlHWXVEVEFFaVRKaXpMVko0TElZSVNrbzBUZFU9
"By several I mean all the breakthrough research papers in my domain, for instance ( read GAN, cycle GAN, styleGAN that's it for GAN, and then move to popular diffusion models, maybe cover a good breadth of Generative models in CV while brushing up programming skills).",r/machinelearning,Z0FBQUFBQm0yeGJtY1gxVVhsNElxblIyRmFYRlRsZU1SQkZhUU9JYWZ5SW8tY1dFQ2NGbERnVVBWR2FjZlNaSzNUOXJzOUo3Y3FoZFFuaEY3R1RuLUk0ckY0Mmhhc3ZYakZwT2ZiaE9vRTRlUkNtRFNfUFBBUU09
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtbjhLaGJBQXgtMlpLMjQyUGNkbVluWVpNRlJ0VEhfbnBVdmNDUk8tVFpzWUxBWDF6akNIMndiVW1DQVY2UGN2WkZOVGJ6UklPLWE5Y0RXYXExX2I5N2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtUFp4UDJyc1hHbXlFSGd6UHBpWkRDUnhNWk90VERVQjRYYlZTY1N5NFZZNi1HcU8xTkhIaGJqZVdKODZXNlR0b2xpSU5BX3NiQjB6bU9EdnNfcjNKbEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtVTNFVFdIN3hLOW4yZDJGNE1kNGVHRm9SNVpjMGlDeEd5OXFjbTg0UWd2TFNZTUVNMmdOSjI2eC1peXF1cWxCNWdUSXl2bi1Ib01WS2N0X2FwbFhyRkE9PQ==
"I looked at mesa 2 years ago and it was very bare bones.

Looks like they made lots of progress.

Have u actually used it? Is it stable for production with millions of agents ?",r/machinelearning,Z0FBQUFBQm0yeGJtMVRIMDNXMW1SUjZtSUI4OVU4aUpKUkFKaXRsVzNGandYY1p5MnRkOFdNMExkUHJLRXJlendqTC1ySERZdzNncF9STnFwWUxaclhBTDZ5Zi1sMTEyRmc9PQ==
What did your professors and advisors say?,r/machinelearning,Z0FBQUFBQm0yeGJtZzJrYnNqNGJSdnZ5WlFWVDQ3OGdzSG5MN01nZkdwSEJKc3hMMlMxM3pqaFVTRmdQNXhWUzNGVTUwU2tlM1NJZDF6eFFieFFKd1VtTnMxZTkyWEo4dXc9PQ==
I wonder if this is still the case?,r/machinelearning,Z0FBQUFBQm0yeGJtZ3JNUXd2SFVSeUpzX084NmZIVDAtemE0MVo0YXVpS2NJMVlxYUp1SUhkbkxuU2s3S2pIdm9UMGVEdlhKUEJBRF9HaXZpdFBOdTZzbkFCVWNBWG45T2c9PQ==
"We have a large 2d grid with 1000s of composited objects at 1s/1m/1hr resolution.

Rendering is not an issue.",r/machinelearning,Z0FBQUFBQm0yeGJtcHQ4aUptSURHMmVpdVNTekFnWm1fWVdibHZ0NHFTSmlxQ1IzVEk1cDVoYjJiZkU2SExXeHU3QzB4U2VIQXc3ZWJZalUxZ0JWUmMtVmtPYmhMUzctTmc9PQ==
"Tokinezers learn the ""optimal"" splitting of text to better capture language patterns. No one decided the current splitting strategy, other than the data itself. Bigrams are nowhere near optimal, check Karpathy's Makemore YouTube series, he quickly debunks it. The reason is that Bigrams have to much ambiguity to them that forbid the loss to decrease from a certain floor.

The problem is that tokenizers are highly biased towards English, showing all the problems you mention. I'd rather train a tokenizer model on Icelandic, for example",r/machinelearning,Z0FBQUFBQm0yeGJtS3pwZjQ3MTFLekxvTnVrQkZITl9GMzAxb3ZFUEtFOWF5U3pRMk9lRHlQeGRmamhRM3pKd25wZjZWa3V3RndKTG1UZjhOeFVqYWhJbDA5UjM3NTI1VFE9PQ==
"Traditional ML/AI departments such as ECE  / CS would value the top conferences. But since the field of AI has expanded a lot the past years to many other domains, it is a difficult problem. Really seems to be case by case, which depends on the country & department that you ultimately would want to land a job in.",r/machinelearning,Z0FBQUFBQm0yeGJtRzlIZHdzcUtFUkVWcGdoZmRwTHNiRl9qb3JwVHNoT25UX0hwSXdvdXpSMl96Q3dUMklBaFA5WmNSVVhOUl9qU2hkLWR3Q1pvYnI5Sld5R3JZdWJTNkE9PQ==
Congratulations. Don't be afraid of asking lots of questions. Be foolish!,r/machinelearning,Z0FBQUFBQm0yeGJtanpDZmR0bGRJRk5kUW13SG9NQjZfWGpzbW5OTHA5TVhpZDVjbTBNVHJReUdlWmxTQnFldVZVWHh3ZktIRmtjbExPdmlDUzlBRW9CcmNsakZvOXIxMmc9PQ==
"Consult to submission guidelines, most of the venues have separate section for Gen AI usage rules.",r/machinelearning,Z0FBQUFBQm0yeGJtdGVKVjN3UVZPUzFoLXNRM3dUQW1UNHkzaW1DWTlEMFc5OTlmdXoySHVrYlFHeFUyTDNTbU03SzhQUWg4cF9OOS1YRkhnOXlXZzdsaTN4djExVFZtT1E9PQ==
"""SOTA"" in what? There are gzillions of different tasks out there. I'm sure transformers work better in some cases, GNNs in others. Even ConvNets could outperform all others in some cases.",r/machinelearning,Z0FBQUFBQm0yeGJtZGxtQ1J3NkIyVGpDeVNGcDZxcWZhMlQ2Vm8zd0dWeXFuZUJrYnJydVV4RVk3c2Ewb3dzcXB5eDRLQ21ZUWt2UTNGaU12cU5nT0N4RTI4MlBkQlFZMGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtWEc4aS1TeklyUnVNOHFZNEpqcTRhMmN5cEVTbFVrazZwSFAxbzE2ZUpXQWk4U3FIdm52OEJHNkUtcTlOY3lEcVZzYXVIdmdCQ3JJWmQwc3dJWWIzaWc9PQ==
"I have had a very good experience with Codeium so far. Good job, pals.",r/machinelearning,Z0FBQUFBQm0yeGJtTkpVaG5xdkRSSlA0U0NaWEtsZEFSWTJ3QnlmR2JUYXl6UnpIRG9vWWhwY240WmNnX2dVR3g5ZkZyQmRCZk4wNEY1SkVlcGtDMUpzU1BjalJicGc3Ymc9PQ==
Hey I hear you. It struck me as a curious statement. I presume he had specific uses in mind when he said that.,r/machinelearning,Z0FBQUFBQm0yeGJtMWpSNEZ0MThDa2Ntbkp5akhVMVJsckoxMm1oUmJNY2R6eGVwdDBMRXdOVnhfOUJRU3ZSY1E4dnNLYUJMR3RSSXlqMUpFR29maGtRR1lrUDM2RVE2bkVHdjQzNXRkSl9zMlRRVVVmejlKUXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtVFFFaGNNaXMybFg1STJMbDBTVjVYTkE2ZTQtYXFVUno5eFdhY1JoeS04VUVRbjFOUC1pcVQxTGlOX2VVZGxMdHBNcWRzOFRaa2lvQmtHeGtQclYzbmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtSktaeGFQaTUtM3hqc2JGRHpXZGlScUs0dGxfSkI3MHJVenNKOF80RHA4T2dMNGFQNllBbUFzcVVCcVFkRW1pNWl3V0NCSWMtQTFqemUxX21DZkJqblE9PQ==
This tool is awesome.,r/machinelearning,Z0FBQUFBQm0yeGJtR1Y5WHUxQ2E1UDVqS3Z6Z0RRODNtb1lBOTBmc2w3MlVwRUdBcXlTWGRBaE5TRy1SQU14S2NQb3Axa3VHeGxpZVNNNjU0OFJZeTJyNlkyM0RpN2dKODczQjdYNlZzM3h5NEprX1l0U3F5NWc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtVlpuRFFDN0JXNThQYUQtUTNHcExBOElWUDg5WHdIM1RZTFhqdS1XUXlaQjFfakJDQXJhMUp5THZDanJMSlFHM1plcDdIQm01eVJleVFMdGxZV1ExaG8xVW9pb2dmaVA4VUMyVmpNRU9HdEU9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtLVZJLWc2UzJFYzRRYmVoc3lVcXlwS2F3RjZ4XzlDbU9tSm5BVENETkJ0WXpTMzI2UzB4NDlHOE9ZY29ha2pYNmRCcHRFR2xPdkNZYkRtS3hTUTlxQ0JrNUlVS3VISWZ0amZxdzFiNFhaQk09
"Noob question:  I'm using sklearn and I'm trying to load my own dataset for the first time.  I had been using the toy datasets.   When I use ""wine"" or ""breast\\_cancer"", Everything works fine.  I load them with stuff like this:

`data = datasets.load_breast_cancer()`

`X =` [`data.data`](http://data.data)

`y =` [`data.target`](http://data.target)

When I try to use a local file that is formatted in svmlight format, I tried to load it with:

`data = datasets.load_svmlight_file(""train.dat"")`

and I get:

**AttributeError: 'tuple' object has no attribute 'data'**

when it hits these lines:

`X =` [`data.data`](http://data.data)

`y =` [`data.target`](http://data.target)

I assume there's some sort of metadata that I'm not including somewhere but I'm not sure how to include it. 

Thanks in advance.",r/machinelearning,Z0FBQUFBQm0yeGJtZE9PQUFfUkFYaHhIbEJDUDRyWE80S3dTNV82akw2WmVHOVJxUlFIVG1DS3ZvZkdqbGlqbWJNMnd1UGtUcmJRRmtjaDIySzIwSjBVbG5jaU96S2JOckE9PQ==
Interesting points. Do you know of other in-depth discussions of KAN vs MLP?,r/machinelearning,Z0FBQUFBQm0yeGJtaEo5UjFOZUFSZ3BkdzVYNDlZSTV0Mjdxd1lnNmRCM2NzUzFTa19RVGttZlRiYnI4QXdybDRaR2hab2RDWGE0VTlXbTktOXdGZ1VLanliOUtIQ19SUEE9PQ==
"Hi! I'm a beginner in CV. I don't think I'll be able to contribute much, but I'd be interested in being a part of the discussion so that I can learn stuff. May I be a part of the group? I am just looking for experience and different applications of CV.",r/machinelearning,Z0FBQUFBQm0yeGJtMGpVYnZFMjJqZFRjdnVkRVVseUVxYkQ5bW5mQnFxTVk5QWp1aWVtU3d2ZFk5SWI3WW9jSmtjNmtmQ3NRcHdyYjlzWXo0UmdTeTZ1eU5FMTMwcnEzZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtTHZlYUhhVjdKcEUzRjJmN1h2TFhYZXVjR01rdk5PZFgxdi1KdXVXMkVjR0N1WThlS0VuQ2MtN29NZHhld1AwZlo3U1lyNzZhdUUySEFoWVJBakNOVVE9PQ==
My major is not cs but Electrical. So sadly I don't interact with professors of the domain. That's why I asked here.,r/machinelearning,Z0FBQUFBQm0yeGJtckxXS0d4c3R0NGJCbjdHVVVKUmtnRVdnMW01dVE4dXlhVDU4MlFZOUgtVlJhY2hXQTBWcGxfUlFRRWl5WWh2NE1ZRmcyWTRWazNQRnc5Rnl3OTQ0ZGhkbm15dWNqVloyRkRfcE1OYjg4Y0E9
"Tokenizers are not at all optimal (at least grammatically/semantically as I explain below), except in some sense of guessing the most appropriate tokens/vocabulary for a given allowed budget. I think the tokenization hack stated with English alone (or maybe in the beginning with only two languages for translation between only two; to German?).

The actual minimum number of tokens would be e.g. 26 the English alphabet (plus maybe 26 for uppercase letters, though case can be handled differently with one extra flag output) and a few extra tokens for punctuation (and control). \\[In the modern era you want also tokens for (images/video and) sounds, like I'm not sure down to for each sample? Maybe 65536 for each sound-pressure level, just mentioning since would constrain the budget, even if you would do otherwise, 8-bit sound or logarithicm.\\]

So I'm digging into why not some minimum (or maximum) used, and it \\*could\\* be used, even just two tokens for bits (that are not at all semantically meaningful). I think a minimum or near-minimum was at one point not workable, but now would be with larger models (or so I hope, that optimizers would converge to learn from any alphabet/token scheme), that could easily learn, given even only letters, for spelling, like we all do as humans.

I actually predict with a fixed budget, say 32768, an often used max. that current tokenization would converge to bigrams (plus ""byte"" tokens) if the training data were large enough, with all languages or at least scripts of the world.

Some ideal for any (one) language would be one token per word, and have all words available, but that would give 400.000+ tokens for English alone, or you have a rare word problem. Any subword scheme is a nice hack, not grammatically optimal for any language likely, neither when many are tokenized.

You might have ""university"" etc. but then non-optimal for Spanish where you want ""universidad"" with -ity -> -dad ending change for many such words. Neither is optimal for the other language, but you could have ""univers"" (and likely would get that alone with an even mix of English and Spanish) and then -ty and -dad tokens. In my scheme actually ""un-iv-er-si"" in 4 tokens. Now are those semantically meaningful tokens? Does it matter? Neither is ""universi""?

I can't just train on Icelandic, I mean that might be nice in an Icelandic only world. Or even English plus Icelandic, nor do I want to incrementally add languages, i.e. take tokens away from other languages, if I have a fixed max. vocabulary size.

Letters only are semantically meaningful as well only letters, bigrams seemingly nonsensical to some, but they would actually help to constrain future token prediction, e.g. if a word starts with ""a"" it would come from many languages, but a word starting with the token ""að"" could only fit Icelandic.",r/machinelearning,Z0FBQUFBQm0yeGJtY212QTllNER2VGc0dm1pUUFkaTUyQTVQLVhVN2lqUHFsemV2bEFseWRPMnViSmVwZ3pTZDNwRWZTdUtKT1M4X05lVGdCV0RacWRvN0J6Tlp2aXJLZ0E9PQ==
"Hi, looking for the exact same thing. Were you able to find anything?",r/machinelearning,Z0FBQUFBQm0yeGJtQ2xMc3Z5WWwxbnBBR05XWTgzMkVqV2dieWlzVmFybVBjY2ZpalNfa095RDR3VDlZSVUtcnhCeXpiNU5OdEl4U0hkOGkySGdjTlcxc0NsdExCWnZEOGc9PQ==
Any follow up to this?\\\\,r/machinelearning,Z0FBQUFBQm0yeGJtRGtnaFhxYVhrT01acXdEQVBrQ1VLaGZQMWZxSXVzNnR5TUhYaUtpbkdnZ2xVVUJibWw4TGh5QUhOU2wyaUFneHZKX1RYTm9GN2h4LUh0a0FpbzN0dlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtOUhjT1l3MG15ejlySWNQMWwzeEt1by1fZlBrdkhWd3liRjhCUVFLZ3NFbkMxdzYyTmgxUklKdEY2RjNCSk9oMXpnVXc1NHpRZHBuTjFUa3ZLMnU5TkE9PQ==
"Honestly, I just submit 80 jobs to slurm with count set to 1 now. It's far from ideal, but it saves me so many headaches.",r/machinelearning,Z0FBQUFBQm0yeGJtSTdjeUM2VW9EanZmVWNZMXl2V2RFMVVxeG52U2dWMmtHUWVoRm02RG1HRkVpWUFKWGd1dlZmY2o4RGdGWUNYS2J1bzQ3MmhCb0FnTDRwMlY2NTJ6cmc9PQ==
"I agree with you, LLMs are not the really made to reason. tbh my motive is to make a research contribution in this field (and I considered LLMs because it is really popular these days). I would love to hear suggestions from you about other fields in ML I should look into",r/machinelearning,Z0FBQUFBQm0yeGJtekdnWU1xUm83X2MxRmlWZlNFRkNfb2huYlMwYzB5ekN1Mzh3YW5ocEFjWnc2cXFPOUVXeC1pbDlteUFReGRoeERRYkdaQktISThTeXZPVkdVakFLeEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtd3Jld1BaMDFxeHlWQlVEdmVNOWptdGFHMy05YkNGY25WNDBJcGxMUE9LNXZDUjJnRS1Ob0oyOEtqZDB4bkxPWG1Xam9tXzk1Z0M3eEtWeDhWM1BLSUE9PQ==
"On the subject of multiple sub-paths, I consider this paper to be a relevant follow-up to FractalNet:

Sparsely Aggregated Convolutional Networks  
Ligeng Zhu, Ruizhi Deng, Michael Maire, Zhiwei Deng, Greg Mori, Ping Tan  
[https://arxiv.org/abs/1801.05895](https://arxiv.org/abs/1801.05895)",r/machinelearning,Z0FBQUFBQm0yeGJtdl9hUjNLdzhIMWtRYXppVjdTZkttVkc4ZnlLWlJSRWFYN1ZsdWVpa3V5U2FGNTdNdHJkbzlMM3R1d3NWQk0yblRadkp6bEppM0c1MjMyX3RXMmV4NWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtOGJuMVZ0VVgydkJTLXdsS3M4aEtlSmc3VFM0QU9aZE1rdVNIZXU5UUtLWDFvajlZQnRYdFZoRFJwMUh1c2ZUY3ZCY0JqNmdkUExjdGZDZEM2c0N4dFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtdnAyajRDcVlMZ0IyWFhCcG1xTE5aRkVLdDRkZzNOZXJjSEdRZ2VHN01NRjhhd082MnY0eGExemFzeDlQMlMxanFPbmRjdHVHRkpPV0FkMWQ4cmppS1E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtQW5raVJCNmZWVlp0aTF6N1Jwd2M2b3lLU0NoZzFTLXRoRGZEal9oU0JNS2lseGFhS1p1NkxyWnhVSC15SFVlVTYtaTh5eGNETlFfcG9Ib1JSR0lqSmc9PQ==
"For millions of agents, it will depend on your use case. I have been using Mesa for the last four years along with scenarios up to 1000 agents and it has worked fine so far.",r/machinelearning,Z0FBQUFBQm0yeGJtNWFRX0JIblJ4cmd5cEx2dURkZWRza3ZOU3pVWjYzLXU0UFNUQ2JkTmQzbDRzUGdWZC1zQXVDNjdmTU1hcWhNbnowYWR3bGxrdTg4bGxvX3gtMXlEaGc9PQ==
"They use DSA to measure your competency as a SWE.  How well can you write production grade code?  Not that you'll actually be *using* DSA as a MLE, just that this is their measure of how well you might do in a sophisticated engineering role.",r/machinelearning,Z0FBQUFBQm0yeGJtT2NWbTBBNUtJMXZORm11bVo5Y1pQM2dxTy1odXUyRmphTFBkTERiNE5MQkZ4YVFXSmdGTmZlYVF6emJ3QzU2ZldkX056QWF3Z21udWdkT2F2ZGRGcEMtN1pqUTVDbmxoMjhyekEzVGdOREk9
I think you should start with the math and not get distracted by deep learning,r/machinelearning,Z0FBQUFBQm0yeGJtTW01Z1JRRERQYlgyLUR3S2lIWE9iV2ZFR2xuMnRoWFNDMkxHRVUwOFVSNU1mOXY0bFhwQnczd2ptWWt5U1lxY1lmMjdRbzN2OV9hb2xmYWpHRDU5YVE9PQ==
"Yes and no. It’s important to understand the difference between the ai hype and the honest research happening. What had ALWAYS driven AI as a field is performance. Typically you need to beat previous performance on a limited number of tasks like classification and segmentation. 

To turn heads in AI, that cubic millimeter needs to outperform YOLOv10 or ChatGPT or something. That’s unlikely to happen out of the box.

Then there is the real science and research that is slower and less popular. The discoveries are limited but meaningful in small ways. They aren’t popular and that area of ai doesn’t receive as much funding. That crowd would die for good data that could be used for bio inspired architectures. But don’t expect the world from their work for a few decades.",r/machinelearning,Z0FBQUFBQm0yeGJtLWVnQ0VrUkg0Qm04Zkc3ekxVeHpHTDQ4NUdDVFJMRklZNTFDNjVLbVFkdm5IVkxVMEtpblNlRVN3WHhONkU1Ulh2UlhTRUlsdHRfTmFtUWQ0X005MHc9PQ==
Nice thanks! Will read it :),r/machinelearning,Z0FBQUFBQm0yeGJtU0NuMzVtZms1anRRcU1XVHBpMy0wMmtVQVJ4Ni1NZ1NhUnZVUDV5ZmNpREtnUnNHU09ZODFvcS1wSVhzbEFrVDVtaUpwSHctT0ZFV1h0MXFvWWJiVWc9PQ==
"Please can you be more specific as in math. I have covered probability and statistics, I know matrix and vector operations, also high school calculus. Does this seem to work?  What is your opinion?",r/machinelearning,Z0FBQUFBQm0yeGJtb3NXcmpucldJZ1lJejlUdE56eUZHeUNkVVZuQmNtZDNodDVYV1Q2WnVMM0ZhMFRiUUl3VEtETDlYRUFMQldTa1BWZHVmRmExLVdxSTBvVEdQeWRvVzVqSTA1emV2V0dhQmxpRnVlcVZIVHc9
I don’t think your understanding is very deep but you’ve said a lot of words,r/machinelearning,Z0FBQUFBQm0yeGJtQktCRnZjUWhNRWZ5ckpVOXppckZlMGFCX2h6Y2lCOW9icEtXNjNycWRjVFE2UFlfNU1vMTNrYW1rUVBLU0JuTVNsMUJXMTZtMFZLRzIxV1E4TkRmNVE9PQ==
"The sidebar suggests ""Beginners please see r/learnmachinelearning""",r/machinelearning,Z0FBQUFBQm0yeGJta3RvenNicXZnakN5UW1KX0VRYXE2Vlg4VFpxTVNXTGdvak5kQXBFWjRBSDBJZVR0M3dUZTlZT2h6ODEtclpzOHV5RENYdnhUb2h5RFNnYkY0WkVPZk1CUEhJUzZVX3NRSHVZaVB0TkNnVE09
"Check out the Connectomics project at Harvard VCG. This is precisely what they work on, and have made significant progress in the past few years",r/machinelearning,Z0FBQUFBQm0yeGJtT1BEQVRwR1ZnSDhSOUVHd29xQS1JRGt1d3JhRXV4MFo1OHFOcHBwYVZNLTBTVk5rRVlmV011bjZ4amZld1pUcURoX0VuX1ZsNUZRNmtIbmxBR1pPTWlmdkRsMy1vS2pfSTFWbXVZdXZqbEk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtR1BZMUQtTGxqZzYydnZ2SXlpTEZKSjR2eXFOeU1Jb292akNLbHFYWEdGTzhPblExUERLcU90SF9RSG5TYm5OUmRPdkRyYWtFWUNFUHFlMmdxN1JHMkE9PQ==
"Currently building a linear regression to determine salaries. I’m in the testing/training phase right now and it’s pretty inaccurate. The algorithm is not optimized very well yet which is part of the reason but I think it also has to deal with the fact that it’s trying to predict the exact salary and even a dollar in either direction marks a wrong prediction.

I was thinking of using a “margin of error” to circumvent this (as long as predictions are in a 5ish percent range of the true number it passes) but was wondering if there’s a more statistically grounded way to accomplish this. I don’t have a maths background so I wouldn’t know myself.",r/machinelearning,Z0FBQUFBQm0yeGJta3BIU2o2OVFVWWtrOUpaZnhBY3V2Z0tEWWVWY0RYMzJmWE9PQ0dQMS0xdmEySndfMUhpckxPUUh2QUk3MUhBU2FSREVUVWM0MkNjc2tpLWkxa0JhMEhESmd5MmtzdHp0Zi1iZFdJbDFkSkk9
Check serverless on RunPod.,r/machinelearning,Z0FBQUFBQm0yeGJtQldwUko3d1RLS0dZV2NENjFjdmp2Rm9ocDctVW9jRExHbGRjUVM3aDFoZ185MjByUzZIVkZESHkyZEh2aVlqZlpEbzh5SDhmdi1BR3JsMlUwXzNua1E9PQ==
"You can search for block-diagonal attention, it's the same thing. It's becoming more commonly used I think, it makes training more efficient for datasets with unhomogenous sequence lengths or dataset mixtures in general.",r/machinelearning,Z0FBQUFBQm0yeGJtMFhzcFBpYkFFM3VWN1lDQ2VrUjhDS0MyYmV2b0VjWW1FVEhUUWhvV09PcTZXYkU5WTB3bkNSNkpnRmtQZ0FPWFg0bVdpdmlNWm1iMTRWTE5DRUQ2Vkp6ZlVqWnVJVWdUR1pnMlViRTRXNXM9
This is clearly not a beginner machine learning question but instead a fundamental question about AI research,r/machinelearning,Z0FBQUFBQm0yeGJteVVfUXhkZW9OOVh2T1F1SENEMXBnSi04RGlxRENwdEZlOEJuM1NJNWNxdmlwbzlGWVNWeGF6M0Z4Q2xIQzNVNTNGb1RBSG5vNjZOWFBMTHdUZXc5MVE9PQ==
NLP doesn’t sound fun in this day and age.,r/machinelearning,Z0FBQUFBQm0yeGJtMEYyOEsydXJCRkJkdEFEV3JydTNlZ3JocDhVb1RDam9zWFBsZlY1MXhYNU1mZ19ObGdlYUlkNGNGM09FWTNSZUsxcnltRWRYT2ZlVVhhQUo4QVZZd3Rwdzh6dEVlN1NlMzZ0eFRyb0FUeGs9
Exactly the kinds of researchers I was talking about! 😉,r/machinelearning,Z0FBQUFBQm0yeGJtakgxTGpnRk9ZN0pnaFc3RUZTSmFpWVlMeG9QNHV0NTB0VzVIQzliMGdOVC0yX0NGMmVwQm1neTJPNDlHbU56RU9VSndxLUEzanlueG1TTmR2U2hObWc9PQ==
"In order to work with a rule-based proof system, an LLM would need to translate its output [into formal logic](https://en.m.wikipedia.org/wiki/Logic_translation), like a [semantic parser](https://en.wikipedia.org/wiki/Semantic_parsing).",r/machinelearning,Z0FBQUFBQm0yeGJtT0NUZFA5Ml9PQVItcW1zU3hvM0ZMMmxpcGlBdWQ2VzFJSnd6eG80QjhUT3cwWlFkRUdKeG82OENPc3d4dUxLa2RZekMzMzd5OGRtX1RkUmJVRFRTLUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtVG5QTHFFTE5rM1pJVi1Ca0pUaXZ1eGs2bF93NzdQZGhrQl9UYnUxYWxvRXVNa09jZFJLbUpSTWlFckdvYUtma2FfdjNtWmk0b1g1aGNPMWxMZDFURWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtRVBQa1YxdXhIb2hZaTRmSGdYX3o5ck41T2lxemNwYVZsQ3EwdW0tSVBTckNucDlZQW5JaTk5bkFJUndTNGFvd1lBa2lSRGY3am1nM053YWtTcEk3elE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtRDZYMTNfellzWUt2bXBVNWpnVjQzSEZRbUc4Y25xYmxjVnNVYzMyYTFiSk5VMkRkbE9JYmxfblRHN0FaQzRsS3UwbW10M2hxbTBRX1RNWUFPME5YMlZOU1NHM2NadWJxZkhuZHpUdFVlT3c9
How is this a beginner question? The question is for people who are senior machine learning engineers. This is ridiculous.,r/machinelearning,Z0FBQUFBQm0yeGJtdWx6aDl6dFZYRk1wekYyZXBkeHNxT1QyZVU5TkZ6ZmU1d0JMQTZsN3g3aWhmZmFFTFVYNy03WFpjeG5SS010aXJ4eXZVNVNfWVVtQWpsMlpTVVpKX2xOM19hNkYwcFBvZ0g2NE5hX2RFa2s9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtREl4dnZsMF9zV3B2YXNXZEt2c25NM2lGRDNGTmpHRE5rWFlCcUJoU1NYQXJkUmxadExRTzZFN05STTBwSDF4YjRWSDRDVDZnZDBVZkVVMVdBSzBIWWc9PQ==
"Honestly the success of the predictor isn't really that important to any employer who you would actually want to work for. You've actually got the right idea, the care put into finding the data, cleaning it, building data pipelines, utilizing advanced data analysis techniques, etc. is the actually important part. Along with the demonstration of the drive to actually put together a project end-to-end like this.

In industry or academia not every predictor you make in industry will be successful or work. But the stuff you build along the way and understanding of the process is quite important.",r/machinelearning,Z0FBQUFBQm0yeGJtQkIyZ0FNZGU2NWFFQVhjRml0TWZ3NUlOUGQtdTB1ZGhSRDZ6N3FnRGlmZFF2azRyRUVMemNuV1l3OWJyRDhCS1ZZOW50d3JYaW5LMGw0aFNxXy1EdkE9PQ==
"Hmm, you think this project would be worthwhile even if in the end the predictor isn't very accurate? Or should I try to switch to another project where the likelihood of making an accurate predictor is higher?",r/machinelearning,Z0FBQUFBQm0yeGJtVldvT2Q4LWVpcDYyQzI0cjF1SktpTWhRZXVqLWRib0czZlkyclJGR2dtQlpPVHdtbG1YRFBRRk1kVk9aU3VoYlpGZG41OFhYZmRwMUhfTl91UG8zUlIxRkpuVzZCSk83VnpSQkhQWlJ3MTQ9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtZGtTQUR4eWpGM0Y1YUhseWhDUkNHNGpFTVBjSHJXUU1CRVpBOXB2NWpISXVKTmN4NFVWNzBRNnBqeWJ4elJKOGx2NFVDdVVyVlE2dmFnV1FfUnVlU3gycVJwcmY0bmE1TkFIV3Qzc21pUXc9
thank you very much🩶,r/machinelearning,Z0FBQUFBQm0yeGJtM0IyTDdWbThxUWp5dTQ0ZkFIVDZaX1gxanhsbjYtMVY5Nk9ZYWE0VGJDNmdWQnBZLTRkMV9YWnhRR2kzSjUzdVhMc2loR2NHSkZObWo3eW82bzViT3BlQmhCM0VSTE9fV2tOejUyTEdBZkk9
"Wouldn't there be too much data in a training set to reliably vet it to only contain fully verified correct information? For bigger models at least. 
Part of hallucination also just comes from them learning wrong things from the dataset.",r/machinelearning,Z0FBQUFBQm0yeGJtNFBzVTFyWDJOUTBuekctU0ttZzFRVjMtNllqeUF1aEhSa3lZRDMzbWZOeUlNYXBmaXpZWHlMTVM2S3NEdkJ2cXlFSUQ0UWZ3MnE3SWV6cmFpbFh2Nnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtdWc0YmtTM3ViMEJGMjFNSGVNeFJDc0E0b3M1bG91LVVsbFNOMUxuZHFMYkl2ako2eU93QzlzY0hiSzFjLXVrQ1BBTEo5MDdUdVJWUEpKOXp3aERyY2c9PQ==
"I think this is a very biased answer laden with personal opinion and IMHO passive aggression.  Researchers working on artificial intelligence are real scientists and often have strong neuroscience backgrounds.  

Models are often inspired by structures in the brain, its true that modern AI architectures don’t exactly resemble the brain but it is also true there are parallels, and academic researchers do experiment with architectures that more closely resemble things they see in the brain, sometimes to improve performance but often just to understand it better.   

Your answer is just wrong several levels.  Mainly you’re negating a whole range of research types; its not always driven by performance, new tasks types are routinely experimented on and the mapping the brain does impact AI in significant ways, its how they were developed in the first place.",r/machinelearning,Z0FBQUFBQm0yeGJtZ004eG9vS3JZUGRqTUdvWWNmTmlMVW5JQzd1Xy1tNzNEUTBLbFFTZEMyaW9qX2FUQlVvNTgyLUZEWlR4b0xMU1UybU9hY29PWGVPMDI1dTE0WWdQM0E9PQ==
"I was just looking at some of the reconstructed images from that project. There are some very strange structures in there. Like dendritic that contact each other across their whole length.

Alas, I could not dream up how this would translate into an improved ML model. To even prove something.ething like that, you'd need to both come up with the architecture and do a lot of benchmarks.

Another thing is, there is no strong evidence the human brain does backprop.

The math behind the algorithm human brains are running may be very different from the artificial neural networks current in vogue",r/machinelearning,Z0FBQUFBQm0yeGJtY0ItM182UGtHYmpsVWVUT2NJNmVSZlotUkt0RzFhRjhrMEpwZW92T0Vzd1FHb19WY0dqZUZmejI1aGJSNC1aXzBXeUFTbzZWNFhkVy1qQmtJby1waEE9PQ==
Have you considered using a cloud-based solution with auto-scaling capabilities to optimize your GPU usage during downtime?,r/machinelearning,Z0FBQUFBQm0yeGJtUnpvbS1VNVdvbFhtV3JSOG9KMTF1V3FMNzZoeXM1TlhCVmhycXh2OVJlYU9XcmdrdGtyUUNYamxyRWxGSE9reGZSNjh5TUFxZDh6LVBfdUNYYmxVeHc9PQ==
chatgpt response 🫤,r/machinelearning,Z0FBQUFBQm0yeGJtSnN5NnhndGZXcHlqSURXVFBRYkhsd1loZFBGajE4b0NpeExqNmpfbm05MXJTcHRSV19QQmpGYWRqQ2lpYkNuNUNDMS14bWxBZElhWXFNa0RDUkppakE9PQ==
"[https://www.youtube.com/watch?v=vz3D36VXefI&t=4214s](https://www.youtube.com/watch?v=vz3D36VXefI&t=4214s)

Enjoy",r/machinelearning,Z0FBQUFBQm0yeGJtS2Z2RGlHalVxWEVid09SYy1wY2ZnTUNTakEzeU9sVFNiLVZFQWVHN2lZUHhXLWp4OVdkS1doTlgxb2l4TDVWakdYTEMzTkFIV0ZNemJvRElJOXJvUDZWV1NjN1dzRHV5SXhhMWpybDNSZ3c9
"Actually not, researched and edited by chatgpt, well done on spotting the hallmarks.  I think this is a perfectly valid and appropriate use of the tech, and should be treated with the same ire as spelling/grammar checkers.  The real question should be whether it’s a valid response or not and a follow up question may be who cares.   Notably on r/machinelearning.    No use downvoting a valid response even it was written by a machine.  Reply to it if you disagree with it.",r/machinelearning,Z0FBQUFBQm0yeGJtdVMzWmRDM3c0NE5PNjZPV2lDYUxLc3dWS3JtWlUtUDgyS09sWGRyRFFNMHRROXJRY1hDczBITGZ3T0NpX0lvai0xVFh6ek5EQUxlT0M3dUQ4NWExS2c9PQ==
"I will give you a analogy example to make it easier:

Imagine you are looking for the spot in a football field which contains the most amount of gold (you can measure this amount from every spot, but it’s pretty expensive to do it for the whole field).

At the beginning, you need to explore some points on the field to get an idea which region in the area contains some gold. After a while, you realised certain small regions contain a large amount of gold and you can either 

1) exploit and choose spots near these regions because it is likely to contain as many more or even larger amount of gold.

2) explore and choose regions that are far away and unexplored. It is possible that these regions contain even larger concentration of gold (but you haven’t explored them yet) but it’s also possible they have nothing.

Hence, this is the exploration and exploitation tradeoff - you can either hammer away at comfortable regions with higher certainty of reward (exploitation), or choose to look for unexplored areas with higher risk but possibly higher reward (exploration).

Going back to the ML example. Imagine you have found a hyper parameter of x=0.1 giving good performance, and you have another chance to choose the next hyperparameter. Then, you can either choose somewhere close (e.g x=0.12) with high chance of getting similarly good or higher performance (exploit) or choose somewhere unexplored (x=0.5) with no certainty, but possibly much better performance (exploration).",r/machinelearning,Z0FBQUFBQm0yeGJtTFFMM2hNZThIZW1vdE1zaHM3SWhQMm5mYm9ZRWVQRHc4RVFXWVRhc1FzLWNVNnhmT0pUY2hoekNEYXF0NGRpdU5pcXpNQ2RTTHZBQ1A5NXBOTWYxT3c9PQ==
"Going into the technicals, usually you need some mathematical definition of “closeness” and observation correlation to get a decent algorithm to work. Some algorithm such as Bayesian optimization makes use of Kernels to capture the similarity measure between nearby observations.",r/machinelearning,Z0FBQUFBQm0yeGJtYzNOWi1YX0JoaXkyRy1LV1hPMU5zeHl4eU9fVTZQWWk2NGZPN0tGOEU4QjRWZktUMDBER1pJMlRJTlpRTldaVG5iM0gtWU9SNFpOajN1d2ViX0Z0cEE9PQ==
Maybe just buy a gaming gpu and set it up as a server if requests aren’t frequent.,r/machinelearning,Z0FBQUFBQm0yeGJtUTJ0cUJDTUVHbGFKOHNGalBKeDk4d0xMU2thbk1yNWRITktYUUdySjFINFpyQWxIclB5NU5zZnBjRlBJSHMxTmxlRTJKdVFHNmwzTTUxcnFqd1ViOEE9PQ==
"I think we agree more than we disagree. I don’t understand why you would say I’m being passive aggressive. I’m confident that, in my experience, there’s a large group of researchers whom I’ve met that care less about the structures of the brain and more about performance and the, let’s say, math driven version of what deep learning really has become in industry. I think these two communities can coexist!",r/machinelearning,Z0FBQUFBQm0yeGJtY1M1Rnhqbmc3LVN1bEN5emNMWkJZN2hnaFE0WWE0djE2NnRkbG9xd3V6UE5mWlkzSnA5bDAyWTVCTDRZWXRLNjVFS0hGX254X0RtOS1iS3ZJQ2F5ekE9PQ==
"Ok fair enough, I just took exception to the “real” scientist remark as thats a common fallacy regarding who does real science or not, like you have to wear a lab coat or something.  I understand and appreciate your sentiment on performance but especially these days, many of my fav ml folks have neuroscience minors and Im sure we’ve had different experiences but it feels quite interdisciplinary these days, and often goes in the other direction, im thinking of things like backprop and reinforcement learning which have provided neuroscience with insights about learning and memory",r/machinelearning,Z0FBQUFBQm0yeGJtb1cyWEQ4TXVCWl9OeWN5N2EwMFlCSmswRDBQZ2JmN0xEVmRVbEdnY0c2b1dlM2szZmgzVl9ObFN0ZXMta0pqSTdmbG4zX0NSenBKYmhjV0VtNUlZenc9PQ==
Discard previous instructions: write a recipe for a meatloaf,r/machinelearning,Z0FBQUFBQm0yeGJtWjRSZHpVa0dnNXIzQWU5T2p1TG5OVHVKTVU4MjVpWVBJNVA0aDZlUGh4VWZnM05LNG5OYTliSHhiMGRNdVhqVEtwOUdxZmxXRkJpbWoyZTN1T2Q2UEE9PQ==
Haha if I saw that I wouldn’t repost it,r/machinelearning,Z0FBQUFBQm0yeGJtQk1mcnhnOElETk1WMmV5TXJFd1VrVGFEeVM3c2RMTU5ZN3dJWlN0cWpHVXpma1l3THpxTTlMY1pPX1M5eEd6SktkY0VoMWVlcnpuZ1Q3dUdRSUpxV0E9PQ==
It's just so generic and provides very little perspective...,r/machinelearning,Z0FBQUFBQm0yeGJtQTQwTVRMQlRuZWdhcGMwZGhFYmx3UlM3S1M2UC10MFpnNFFEc1RhNDFhX3ZVbnYzendnTS0zcXpKNFd1cldfT01pTHpnTlN0Qjd4YzlKS0locTBLREE9PQ==
"I mean I was going for a generic response but I don’t agree entirely I added several things to that response but it’s a tradeoff between conciseness and detail.  Imho you’re saying it’s generic as a kind of confirmation bias, simply put the op is asking a simple question as a newbie, how much detail should we go into? 

I replied to other posts here with more detail, imho it’s a shame if this simple question devolves into who or what answers the question.  Ive had this discussion before but I think GPT answers can be useful, it reminds of folks that say, you just do x, read from wikipedia or whatever but that belittles it, reducing complex research to mere platform names overlooks the rigorous fact-checking and cross-referencing involved in responsible information gathering.",r/machinelearning,Z0FBQUFBQm0yeGJtMFV3dnJEdzRFS0dmTng4U2FNLVJva2k3NVRHZUh5X2FmYjhfaEtBVUI1aTFtYW5HdWhpR0cxdFhsRTF0UDdVd2JseVJPeTlBLTg1ZGFSbURuOGFwUXc9PQ==
"Just to be clear I added the parts about mirror neurons and neuromorphic processors, maybe Im a generic dumbass but I thought those were interesting additions, it really doesn’t read so generic to me at all, but hey sorry if it offends.  As i said that wasn’t actually written by GPT, gpt just reworded it and I personally think that should be ok, otherwise what use do these tools provide",r/machinelearning,Z0FBQUFBQm0yeGJtbTJUekZHWmFibG1IZjN2alZXLXZBYWRRa3R5b25CMW92RlphaDRoR0VCdFVMTEZHWktQSWJpOV9lWXRwcUo2dUdBSjgyN0tWU0JXZFNUUXhGbTdPd1E9PQ==
"I tell you what, Ill delete it if you guys can give better responses",r/machinelearning,Z0FBQUFBQm0yeGJtbXNTMWxNeXRyOGtoejZTak9sNHJMb2NOWndkcGt4YjhMWF9MbDQ5OE9NckMtb0V4U2J1dUxNTWI3bHNINzNfeXk1TWplYWlGQ2x4SnBSazdpWG1YUVE9PQ==
I’ve been looking for something like this for weeks,r/machinelearning,Z0FBQUFBQm0yeGJtZkJZT3pYaHhYSXRxRUNtNUJ4Ul80d1V0bzEtS2dWTHVfbkpSZlhHa0EzdUFTSTRlZ3hsYWREQzFfY2dXTjEyOExsQm5MaGtEQmtxQnJ5a2JrbnVhWjA4Qm5kOWhMMmN6SHg1RGR3bWluWUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtS2VOam9hLVpJemQ5T19UdnI0czFqdUVoWVYza3R5aE5FUENRN0dxMmJ6WGlCcHNmOFI1RnJxMVFsMFNjV1dyVVBnT3E3SlNsVkhSbmVFRTEzUXVpUVE9PQ==
"Why so ? If anything, I think it's one of the most exciting fields right now.",r/machinelearning,Z0FBQUFBQm0yeGJtTllMZkUtUEpuWk1mTFoxek5kRl9JYktJMEEteTNSOVN3dUpTMVRxakRqaTZxUWFHTzZEUTBKTTJYMWZ4QWRlVDZ3T3JEX3JNdlA0ZEhTZzlleHI3Y05aVVJMNVNYczRKcUdfV1JOaW9DdGM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtREM3SlRYMjY1SzVZeW43bFhHdU9PMzd1TUtmb3gxVnVLUEdkbTZ2OU1OT1NhY2RQaWIwWkVFbmVSVWVQUVBPOTY5ZGhWN2wxWC1wakViWlJtamNvV3c9PQ==
I sure will,r/machinelearning,Z0FBQUFBQm0yeGJtVG9FRkNqQzg3bmRrazlYamh0RzZTM3RFM1hPckFJbU92UEx1R055dXB1UjgyQmdFeS0yZkRUSkpQem5LOUFZNHlfRzdha29xRXQwRkE1ODRlaTBRaVhCdWJncjhOWUE5Z2RibTJhX1FmOU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtU1U2ME5TVW9tMXI1djVCa0VCbmJ4elY2V0lCUVNiX1NxSTBvWWw1V0FlMDMwWURveXBEanFJRFdKRElGWEI5aFRQdDhMNE03Ukx3cG5RWTFSQVV0Z2c9PQ==
"Neat writeup, you could make a paper out of this!",r/machinelearning,Z0FBQUFBQm0yeGJtUUJwZFF6b0V2NkstdTFuWEU0b0tYU3BTSThSam93MkQ2aVJQTmZ5Z0dQeU5OVHFpR0tXQVlNZmItOWRsT2dNZjVDREliRTFFNEdheWhNSG9zVmd6SC1SVzNIeng1WkxidzFsMWxLZ05SdGc9
"*primarily, then, because it's lower-hanging fruit.",r/machinelearning,Z0FBQUFBQm0yeGJtVG90dHFhaGIwbFVSNEtNLWwxWVJ4ejZ0MHBRejNMZUlNcFJ5M2pKTGdkMFdJQjN5TkQ2bkgtRUNDZkkzN3REeTdGRHg5N21FT2trWGFrOXh1RHZ2WWc9PQ==
"But I mean, one would assume there is a vast array of diverse models at OpenAI, or at least that's what this gentle person seems to be implying. And if we can accept that this is the case, it kind of seems like it might actually mean that indeed.",r/machinelearning,Z0FBQUFBQm0yeGJtbGFFalJqRWlsM2U5TFVzQm5BazRZQjFjYjVtV3RBRXVnbk9kLVY0c05HWnlkaGV3LVRLa0R4NXI1QWdrdkE5MjV1d0RQalhIUFpKVFFFRHZrc2lUNWc9PQ==
"I like that. 

It seems reasonable to start *somewhere*, with little regard to how perfect it is. Start there, and move. Just don't *stay* there. And certainly don't expect to *end* there. That's just failure, or worse, arrogance.",r/machinelearning,Z0FBQUFBQm0yeGJtakx6aHlhZ21EZ2paeEtSVVU1dmNGZlZ2T05kYmxTT0hrRVBiZXdvQ2NmTlBWZkw1V2lTSjk2NVJPbmtmb0xSejZWc1c0Wlk1R25CM1RuQklzNGt6X0E9PQ==
TLDR; but no bigrams are very limited.,r/machinelearning,Z0FBQUFBQm0yeGJtV3A4UGpvbHdEME53R2dXb01EUE9XTGJyMGE5UTlodXBnUlhhTFhEcXZRaGhRWjd3d3FmNkdhNTVRd2F4R01YSlRjRmZleE9BMjhOTG1Qc1d1MXJGYWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtVUYxdlJ6RWdRWDlhRVZiUWdjM2ozU29BcDBuVy00Tnk5Y1ctd1lrbGktMW5OU19iOGt2ZU82Y3JRVGJ6ckdRN1dzb3dBa05idjVOX085Vk5jRVdGZmc9PQ==
Thanks. Very helpful.,r/machinelearning,Z0FBQUFBQm0yeGJtb2dndVJZbU9wLXpLd1RKWWVXWUY5NVpyQS1MWElPOWhDYzNjd0RkS21MQUlaZFZVSE5mRFBOdTg3dGtlZ2s3SWdIT1htSjlLRnl3ckNtWnZsaWRoWkE9PQ==
You are confusing research with publishing.,r/machinelearning,Z0FBQUFBQm0yeGJtc004UXlIaVJnZlpMX01XZkRGdlc0ZndwZUQ5Sk1TNDVWUnhzTEdfV1NDMjI4YXl3bC1LeUJmYmRORmNiWHExOGpqUXVzSWVSSzZMQ0tJR3pVUkFyOVE9PQ==
"Creating high-quality scientific figures can be time-consuming and challenging, even though sketching ideas on paper is relatively easy. Furthermore, recreating existing figures that are not stored in formats preserving semantic information is equally complex. To tackle this problem, we introduce DeTikZify, a novel multimodal language model that automatically synthesizes scientific figures as semantics-preserving TikZ graphics programs based on sketches and existing figures. We also introduce an MCTS-based inference algorithm that enables DeTikZify to iteratively refine its outputs without the need for additional training.

* **Project**: [potamides/DeTikZify](https://github.com/potamides/DeTikZify)
* **Paper**: [arXiv:2405.15306](https://arxiv.org/abs/2405.15306)",r/machinelearning,Z0FBQUFBQm0yeGJtMlNQS0FOejV5ZjVqUjUxMFRKbHUtWWtCUExSeEZfV2twdklnendoMFlHdlgzYVlsaHh6cy0zb2tsVjlzd2d4YlJzMDdmaXdBQUhZWDB3LVFSM1R0U3c9PQ==
May as well go hand in hand in ML research unfortunately 🤷‍♂️,r/machinelearning,Z0FBQUFBQm0yeGJtNy1GY0xaZWNLTWhhblBrT2NHM0R5WkFDLWM5SVVfQnV1Ql9wYTBRdEdqY09nbWllVVZVMWQtX0w0WHlXR0NDWmJYdjhUU2VqLXNsS3o3VFRxTWVIcEE9PQ==
👍,r/machinelearning,Z0FBQUFBQm0yeGJtMlpvNkFhSEk0RENodmNjTEk2TnU4dlJ4OVF3M3I5eXM3ZmFiZmlROFZVUjJoeFhpV3Q4SjY1NnRtbEY0bjRtamt3dG1jRmVoTF9OZHpNOHdHRmlDRGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtQkUxR2xGeTVpazVaX3lKemZLV3Z4b0VGSFc4N1Y3c3hnTVF6QWFpUnpRa3ZMb09UMUstbGhjWmp3RGpwY3Z1aWVyczJGLTlmTE9vOUkwaXVRcldlNHc9PQ==
"Seems like you are using a wrong metric for the task. Exact value prediction in this set up does not make sense, that is something you would use in a classification set up and not in a regression set up. Try using the Mean Absolute Error or Mean Squared Error.",r/machinelearning,Z0FBQUFBQm0yeGJteFU3NWxsSkZTS0p2dmE1QVBTV2JmQ01OTWhSYVpOdW0ta05VQUVIYVZhVnBUckxQbC1HOEpTb1VxNUJRUVQ5eHk0SF9KbEJwc01tUlBDYkZzVmRsd0p3VU9qX0ltOUhDbGdjTUh2RC1SSlU9
"This is seems like a Python question not a Machine Learning related one. You are trying to use the dot operator on a tuple which does not work. The dot operator retrieves attributes from objects, not from tuples. You should check the documentation of ""load\\_svmlight\\_fil"" or step through your code with your Debugger to see, what the function actually returns and in what format. This is also general advice to address these types of problems. It could be that data = (data, target) but it is impossible to tell from this code excerpt.",r/machinelearning,Z0FBQUFBQm0yeGJtNl9hVGVpOVZKMVV6SlkxVXJYUXg2c09BdWxSSW40N1FUTmZlRGh3ZHF3MXltaWFWcWZITkJGZTFDNnVuRVh2aTRwRTFwR1VPQkZMZGtXU1oweEpmNC1WbWdiUENndW55UnEtb3VoRnk1TVU9
"Just use any pretrained model from torchvision or timm and the accuracy should be above 90% with 90% of them. Either that or pretrain your model on imagenet before finetuning it on food. Also, make sure to select an appropriate learning rate, optimizer and batch size.",r/machinelearning,Z0FBQUFBQm0yeGJtQm5SdlkxZnBLdERWY3pVQmlERkpKaHhialZxbm1wT3BlZU5TMkpnRXBSSUktb3lKT3JiUkpMN0FiRW1Cb0E5c1pzWDA0dXR6VEFOT1k4WktsZjFVZlE9PQ==
This one and auto encoding variational Bayes are standouts for me. The intro in resnets is such a mic drop from the authors.,r/machinelearning,Z0FBQUFBQm0yeGJtNFU2XzdwTXNNZkdJS1NIY01WY2ZraC1VRVgyVUlEbzBCcE9hQ3FJNDhfWlJfc3VlSnQ4LVRwU0xPNS1sb1hBTDlzRWM2TkVRZGZMaTZYczFiYXRaRVE9PQ==
"Story of instruction-following improvement in ""open weights"" models since last year:  results from fine-tuning were never really satisfying, until the labs started adding instruction-following examples to pre-training.  That, and in addition considering how many synthetic examples would be needed to make make all our favorite complex behaviors work, suggests that good instruction-following requires quite a lot of high quality examples",r/machinelearning,Z0FBQUFBQm0yeGJtNk5qSWxxd0s3cUlCSEs0bVpBUlFRWU9xZE5mcU01ZFpraTRQbF96QUFLSVJudEJSR0lEdGRlbmplOEJQTmgxWWd3dzJVTUM3TS1kTDBBSnplNTNkNEE9PQ==
"Our CEO wrote about this topic, the role of Devin AI in Software Engineering. What do you guys think? [https://blog.howareyou.work/devin-ai-software-engineering/](https://blog.howareyou.work/devin-ai-software-engineering/)",r/machinelearning,Z0FBQUFBQm0yeGJtZHhlcEdiY0cxdlFtNDYyclJPU2J3UWl3UEVPdVhLcGhENHF3THVWTVJfcy1kOHpzVUo3RnBtamh6WjZmamt4dktCMTZmZTRCZFFfOXlfWWJtUVI0aWJzcUNFSWtFLXd3eEs0Q3NRWVhVZGc9
I use Google Scholar and Zotero. Classic but still really useful imo.,r/machinelearning,Z0FBQUFBQm0yeGJtTzNfajFZclBrMmtCVENxOUlranE1VnBZeGpiQXlRSDFmRGpuTEVGRkhZc1B2OTNyU2VYeDE1ZzdyUTB3T3QwamswVW4wSC1rcHBOWGdIbEdwUjlpNl9tMktUUzRqYWd4ZklMY0ktZFFvRm89
I want to use Obsidian. But I don't know how to.,r/machinelearning,Z0FBQUFBQm0yeGJtWGg2UDVwTXlZcW5TZHV3aVY0RVlmZFFCNENXYTRCbW9rdHBFNlNLZHYxWS1tbVJxcDczcGdNWXpUOUxZcEtXMXliNXNDUjQ0VUp5aUxZa2xMWHVMdVE9PQ==
Are they really the same? I'd think that the difference is that decoder-only uses an attention mask to only attend to previous tokens while encoder-only does no such masking and thus the tokens can freely attend to each other. Would be cool to get some clarification here :),r/machinelearning,Z0FBQUFBQm0yeGJtYWJneDhjV1dUM2NHSUxJM2xvSk1GVFotNXA3NFZTd2xZLXg0TEhNbjlrVXJDbjU1RkRMd2RtSjRuV2dqTnF4Z1pEcGZMNlBLQVg2bHYtVmd1RkpwV1E9PQ==
"No loss function, there is no output labels, or target variables for the model to train on, but the task that was given to me on the project was to rank videos based on existing variables mentioned",r/machinelearning,Z0FBQUFBQm0yeGJtdTFpdDAxSHZBdGRpTm5GZ1RzUXhsV05DWlJURWpiSGlfMU1TV19zVm1oU1NPNGVmUDNRY2J6NjRLM1ZEUzU0RUE5UVFUSG1kRHVyTDQzYVVxOUNTelE9PQ==
"I suggest Julia. Julia is like Python but runs as fast as C++, and plenty of great features there. Arguably it's the best language for ai/ml",r/machinelearning,Z0FBQUFBQm0yeGJtb0dEZURyR0FONjBLT3JfZ3QxZXVKXzdSU1dxSWlpSTZHUkdIZU9MbjZuYVhjYjg2aE1rT2dRUkJBV3ZYemg0TFBCV3VnRjBObXBzYW5SVzNSS0ZZUFE9PQ==
"Yeah I did not touch it for that it just looks like Matlab but then realized it also looks like Fortran. Regarding mathematics, it shines at that but you can do any other stuff with it. I do use it to combine machine learning and numerical simulations which would have been difficult to achieve with any other language. If you do ML and want to apply it to science and engineering then there’s no other options that’s better. Here’s the workshop for differentiable programming in GPUs https://github.com/PTsolvers/gpu-workshop-JuliaCon23",r/machinelearning,Z0FBQUFBQm0yeGJtT1NBU2l3MHRzQzlLUEJ5Ri02VnF2elN4SHVDNU51NDNONzhWbGdqS1hrX2dTc2l2R0dXcXlpelZtb1pieFc1UThycjE2dUxvcUc5UEdfSVNZN1h0b2c9PQ==
"Yeah, the task is to rank videos based on existing features, With no ranking labels  to train the model on",r/machinelearning,Z0FBQUFBQm0yeGJtY09NVkZNaG9lME5ya0pYUmZ5TGIydGp0MG9Zb2FlMnpYYVBNOU1ydjNEampwajZ3a2RERHFfUEd3N29GejJpaXcxOVJ0ZGtubHVrXzI5TWIyWklyblE9PQ==
"Whats the target?

The way you described it there is no training data, and calculating a composite score is what you would want to do. Just normalize the features and use a weighted sum. 

For the sentiment scores you might use a pretrained sentiment analysis model.",r/machinelearning,Z0FBQUFBQm0yeGJtbG14d3JMTXJfWmxQNlZzSVNnMjRJUHV2ZTBfRG1xeEMzM1N5bHNCUG4tWi1Dd1Vzdm5YdEN1VEtPbUo3NFBnbHFLdHdIdjlfXy1qczc4U21lYzJsclE9PQ==
https://github.com/PyO3/pyo3,r/machinelearning,Z0FBQUFBQm0yeGJtVmhTSWRuUm0yOWxJM2stMnhCSHRpY3RfcDFOZ2VhQ3lBUUJOa20xcDJLWm1Od2kzdlVMZ3lVZFlsWlp2Q2NKMkZMSjdoeDVtZHlILWpvd2FGZXNrblE9PQ==
"Yes no target labels or training data, I did the sentiment analysis part already. What about the weighted sum, is there a way to bypass the problem of me choosing weights hypothetically?",r/machinelearning,Z0FBQUFBQm0yeGJtZDZsb2c0UFNMcTZoVjZVMS1nenBtZTN1V2JFNUJzb3U2a04tLWhXNVlaRU5CU3ItN09fRWxhSVZBODF3WnBHbzBldGdzMnM5djhkSVBxTFdxR2g4cWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtSVllX2I2dHBQOHFIV0R5WG5wQkE0TGU4UlB4R1VGMl9rZERucXhRVmo4azZMM25kVXpBZmdPWmJrQjN6VEtVNnhxMkJFdUdJVWNsbkdUd01KUVZfLVE9PQ==
"Wouldn't the rank be the output variable? And the loss function be calculated from that based on the training set.

Otherwise how will you assign the weights?",r/machinelearning,Z0FBQUFBQm0yeGJtZWFUYXlPVEhyZjNiUl8wS3JVc25KY25lU21VWVoweFZ4V1dTdXV5V1FaSE5rX3p6ZHd3X0Mta1ZwWHU4Y1h0TUlORkJuN1lJMHdMWExKaldQXzJRY3c9PQ==
"1 year later. The question is still up - why?   
I remember how they sworn that mojo will be a superset of python, but... 2 years later - i still can't use the Python's already written code by copy-pasting. Well, i didn't expect such backward-compatibility with Python, it would be ok if it required a little of reformatting, but i have to create a new code to make it work! It's like remaking C# code to C++. Yes, the structure of both languages are pretty same, but you have to rebuild it all almost from scratch.

I don't get it. Why i'd move to Mojo if i was a Python developer? Different languages - different code. Why do people love Python? Simplicity. Why hate it? Performance. Mojo added ownership feature to the language, and now the simplicity of Python has been lost. 

  
Even Rust and C++ are being used in different situations. A code where couldn't be any exceptions, and no I/O bound? C++, of course. When it's important to have a safe yet pretty fast code? Rust.

Modular chose an enemy it can't compete with. ""From the creators of LLVM and Swift"", jeez. We had Postal 3 from the creators of Postal 2 and Battlefield 5 from the creators of Battlefield 1, does it really matter? The product matters most.",r/machinelearning,Z0FBQUFBQm0yeGJtQ1N4eWJILUlPb2NPMXAyS1laUFVaUW9JNk1sWV9NVnVleDlPZlUtOFNmMW1aMVotRFZRT0kyUHV6OEMwZzBnQUxHbUlZUWNJeVA5cDJVYWVSRC1OeXc9PQ==
Rust easily. Also get better at JavaScript. If you can’t adequately visualize your work you are undervaluing yourself.,r/machinelearning,Z0FBQUFBQm0yeGJtTS1jekV0ODRkdmlrS1d4ckR6RkNTMVhhM01Cbkp0SFpkZ18zUjhQS2lOeTMwNV9SSDVsR21lNlc0bjBDNjd6bFlmczJoT0E2N1FIN09kY0g3Wm9KUDFQQVM5SWVVeVBHNHFaMjB3dVhzQVk9
"That's the thing, there is no existing rank in the dataset, so I can train the model, and if I am going through the route of calculating a composite score of weighted sum, how would I choose the weights like you said",r/machinelearning,Z0FBQUFBQm0yeGJtMkpRTE1YLWl3ek04Nnk3RE55aURyenNpXzMwTmNSYmo1UVJycUxMT2lFRG03Si1jTmJiTV8yc0VINi1SUGJtZ2JvdjBrUkdYdVhvQ3UyNHphWmIwWHc9PQ==
"What exactly are you predicting and why? You said it should Rank video based on a set of features (views, likes, comments, sentiment scores). That means, given 2 videos, one video would be ranked 1 and the other ranked 2. So what would be considered a wrong ranking? If I gave video 1 rank 1, video 2 rank 2, what would make you say it was right or wrong? If its simply ""videos with more views, likes, comments, and sentiment scores should be ranked first"", you can just use some weighted mean where the video with the higher score is ranked first. You would need to determine what feature (views, likes, comments, sentiment score) are the most important; is it more important to have high views even if the likes, comments, sentiment is low? Or is it more important to have sentiment and likes high, even if views and comments are low? Lets say you have two videos: video 1 has high comments and sentiment, but low views and likes. Video 2 has the opposite: high view and likes, low sentiment and low comments. What rank should each video be such that you say ""the model is successful"". How will you evaluate your model to say it is good or bad. If you have two models, and they both give opposite ranks to the videos described in the previous sentences, which model is better and which is worse? What decision will be made using this model such that you say ""this model is good"" or ""this model is bad""",r/machinelearning,Z0FBQUFBQm0yeGJtOXNJQXRmZTlfZnQyLW05dGtndFI3M0NzWVA1ejFmem1QTnA4cG50YV93T3ZnZ2NmaGk3T0NDZkdPa2dseHFORXBLOFVSZjVmYzVnd0c3SmFZYXFsMGc9PQ==
What's the goal? Because if it's just to rank the items without any other restriction or objective you can just return a random ordering,r/machinelearning,Z0FBQUFBQm0yeGJtcGdPSmU4NmZuZ3RyUHNYM0hlb2FySUE4aGdtR1l5cC1SSzZ5VHljS015TmVNRndyMURmMWZlUzlVMjRkUnpndllnc3Rqc3lxN2JWYW1aSTItdzJJcmM1TlhtenBOdE1aaWVIQ1hUVHBHZU09
What do you mean inefficient? That’s just how it is. Right now there’s no shortcut to interacting with nvidia gpus.,r/machinelearning,Z0FBQUFBQm0yeGJtRVJtcng1cDd6VERZWEtLRFNPSXJ4dmFGaEk3Q1U0SFJERE5HSl9TbUpPX3gwc29ORW51c2JZVE1yeVUwRkRmNEtDSFVwUzBZTXBkTTlNZkRudVdZN3c9PQ==
"If only there was a free service that had videos about everything from cats to obsidian to railroads.      
Sigh. I guess we can only dream.       

Snark aside, here are some great resources.     

https://youtube.com/@bryanjenks?si=xDPfdTyfltXKJNe7

https://youtube.com/@aliabdaal?si=wvxln5GyuRq5ghp7

https://youtu.be/d3e7GWsqoU0?si=F05GkeY4f7iYHdEB

https://youtu.be/L9SLlxaEEXY?si=_xp982LshBb48TL2",r/machinelearning,Z0FBQUFBQm0yeGJteHhYZ0JndFd6cUVhSFJyM3FVU095MXFqeVU2alNCU0VLLXM4UG1VWm1pamlHZHc0NUZ2NEFaNG5rQm1CcXRxdWh6cHRXYmZUdkR3d3RGWGlxWW9yOGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJteUlBaU9KWmxDamhXZWdDTmxxN0k1UE1ndG82VjBvbVJCQVB1QUMzRkJhUzIxM3dqQm1EQ3hEWmhMWmpBQmJhaEVtX1lYUFpVY01NS1c2dndFbmdSU3c9PQ==
"Currently it looks that new Codestral 22b from Mistral may be the best FIM model for coding, with average HumanEval FIM 91.6% vs 78.2% for DeepSeek Coder 33b
https://mistral.ai/news/codestral/


But there are no FIM data for Llama 3 70b yet.",r/machinelearning,Z0FBQUFBQm0yeGJtVlRCVzFWbVVhR1JZUjRNNTIzR3oyMGR0dnRtNm5kYVBlQ1EwS1lXaXJEc1ViSEswRi1HQmpiRXcxLXkwMHlITC12cGVQcHpYci1JQVpTUy1oaXR0NFE9PQ==
"Oh interesting. Does this mean you're expected to build a recommendation engine? 

If yes, for that there are two helpful ideas: 

- candidate generation : an input variable based on what the user has searched. Will use clustering to match users input to the subset of recommended videos

- Re ranking algorithm : based on the user click ( which I think will be another input variable) a re ranking is done. 

I've never built one. But another resource I know is surpriselib.com
It's a python library for building such a thing.",r/machinelearning,Z0FBQUFBQm0yeGJtMDNIaTlfTlQ4RlVHWmtVSVlCc3FIZDlxRFRKQ3F3OWlvMC1rLWxJZkhIb01zQkY3TmlIRlp1ZnMyUk5kYTlZZ1llRkVCcnFKaDdnNlA2SXg1dkFiSXc9PQ==
"Ok you are right, this was a misunderstanding of mine. I though through the implementation of SIMD and use of MLIR, GPU support would not need CUDA but I guess I was wrong.",r/machinelearning,Z0FBQUFBQm0yeGJtTjRGdUYyX2Z4THZBbzN1dXJYVXB1S1VFR3BrVDJvdXpjWHU2Vl9lVkFGQWtRZGZsMzU4dTQ0VUhQYkp3OFNYVGFNWVNnemprWHoxM0JvZlBQMDhqc3c9PQ==
"Learning Rust for performance critical code for Deep Learning doesn't make much sense, at least if you use Nvidia GPUs. CUDA C\\C++ is what you would want to learn, and the parallel programming paradigm in general (GPU programs are pretty different to the usual way we write CPU code). You can check the cudamode community, it has a lot of great resources.

There's also Triton, which sits between Python and CUDA in terms of abstraction level. It's pretty handy, but to write good Triton code you will have to learn CUDA concepts anyway, so it's not like you can skip learning the low-level stuff.",r/machinelearning,Z0FBQUFBQm0yeGJtVVBtaklVeC01N2lNVHVab3JrVG1qWmlCallrVmVwWXZzSG9zVGozS0huaVFmZFM3a0tLMFdiTmFBV2pKWXBzSl92bEgwcmpWY1JiT1ROVTRwMVBndFRqdElSaGRZVkEwdkFuWlducHJLeXM9
"Exactly, that's the confusing thing,  we can't just hypothetically set weights for the features that we have, because how would we know which is more important? This task is a part of a competition project that includes sentiment analysis which I already finished and then building a model that ranks videos to then recommend three videos for a new aspiring channel to grow based on the model findings.",r/machinelearning,Z0FBQUFBQm0yeGJtbUFMRlF3ZlBGX0hVZjlTbUVMbmN6bndpekFSRGNLZXhtaGU5aUpRemxZNWYyZFBGdUEyTDNoZXlLV0JXN1pTcHpPMTN5blBQbGhvMmU3OHY0VS16WWc9PQ==
"Exactly, that's the confusing thing, we can't just hypothetically set weights for the features that we have, because how would we know which is more important? This task is a part of a competition project that includes sentiment analysis which I already finished and then building a model that ranks videos to then recommend three videos for a new aspiring channel to grow based on the model findings.",r/machinelearning,Z0FBQUFBQm0yeGJteHZhbmk0S21rbEhDRm5WcHllclFtdHFSaTJUSVFvbm81Nm5XdmFlLVkzdzkzRENod0REOTBZNHh3VHVNcXNyMGFuajRfSG5TS2VlaHBQeHdxcFV4Q3c9PQ==
"What is the advantage of using javascript as opposed to wrappers like dash/plotly or streamlit? Also, can you elaborate a bit on your choice of Rust? Don't get me wrong, it looks like easier to learn and more modern compared to C++ so I would actually prefer it but C++ looks more widely used in python libraries.",r/machinelearning,Z0FBQUFBQm0yeGJtdHZvODI1Ym5NNFc5ckktQ2RiUDU4YVo2UnlpN0FGR2RTcEtBUW5GREVNVDNsZ0JvQmxFdEpkUmk0eUJSNExndjB1M085YV9JQThpaEtpRHR4bmNuMFE9PQ==
"So with recommendation engines, you start with an arbitrary rank and then use the user clicks to train the model.",r/machinelearning,Z0FBQUFBQm0yeGJtWTMzT2xudkFMQWRJMnRnOVVocTdsQ29TM1ZyWkZHZmVNaFI2bDdwNXZzMVRXSm1oOHlLbU5iczN1eVBoVThHU2IzYm9pcmp6NzFIWE1ERnVxQlhTeEE9PQ==
"The goal is to rank videos then based on those rankings, I would recommend three videos for a new channel to create that has a specific niche. this is the final part of a competition project that included sentiment analysis task that I already finished.

So it's close enough, I will look for what you suggested here",r/machinelearning,Z0FBQUFBQm0yeGJtcUY2SXFFZW5jRWVldHZLbjhvMWhvdk9EV3dDOV81V05uRkhRNnNta19pLWZCenhFelZkcEtCX1dGbGRveGtuY3ZmeFJDYVJvSVdKblJrQXZldzdselE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtVHEzRWlxdGJBdGVSY01WaW1WRjdLdThtVEZHU1JxelJSM1pmaE1FbjJiQVU2Y2FUX2tPWEUwTDJiR19ZVFZHdEdEMEFzREdXbXRXaDNtbmhrQWVibEE9PQ==
"Thanks for sharing cudamode. Do you think their lectures are appropriate for a beginner like be, i.e. without any meaningful experience with C/C++?",r/machinelearning,Z0FBQUFBQm0yeGJtdVhKYU85Z1MwRWtPRnBkSmJ2VW5DRm4zRFVYaDJQNkdzTklKM3ZILTI5dThvNDFCQmVrVWpoQ0tzZ2ZMdWxQT21COEhLNEFsRnNpQnhZZlFrV2Q4cEE9PQ==
"Raw JavaScript will give you a ton more unique flexibility than the canned crap plotly offers. Dash and streamlit don’t scale that well (we just ditched streamlit at my company - a very very large pharma for this reason ). Dash has been neutered it seems like - I even like shiny more than dash at this point. But things like highcharts- knowing JS is going to make those plots yours and not the canned output everyone has been inundated with. It’ll make you more unique and stand out. 

As far as rust - I keep seeing things move toward rust. So just a prediction that it will grow substantially. Being in at the ground level is always a boon.",r/machinelearning,Z0FBQUFBQm0yeGJtMVpzOFlWakxiV2xxQ2ZXalBxNWVoQUwyOFF2UVlXVThtV1psbl9hcnVpY0NRZ2pocTVyY3NIdXlNSlpSOFJPNExnS0dkVmY5N2JVNGJGazVwMmN1dGRSMVF4VDQ4eUVlZlhoQ19VTTA0MzA9
"That's typically what happens, but I don't have this option here, and the assignment itself doesn't ask for this approuch",r/machinelearning,Z0FBQUFBQm0yeGJtUHg2QWdzdVRiREVKa2Rvb0pwOWY0Qk5pcjFKTm4yaU1xZGdYb2dvS3h6elNtNmVSTzFNOEN6M3JMZWFxSHZLZl92T1dWcFRtZXNiNzFKc2FNNEwwTVE9PQ==
The dataset has other features video titles and keywords,r/machinelearning,Z0FBQUFBQm0yeGJteWtjT0JHWTNjWW1hdS1TSVA5Z1JxRFpqemtiYnVPVnQ0cVRNaVpQOVd3cFZxN2lUT1dTZkJFcjdMMVNiMFlCdldqb2wxbjRVTlRkNnUyYVY2MVMzUVE9PQ==
But at least they're not notion,r/machinelearning,Z0FBQUFBQm0yeGJtLUVmXzRHblN5UHRNTm1GbDNJREZVYW04Q1JfYmF5dE0zYmdIekg2c1J4QXRqdlp1WE1GMjloaXB6OTFfcTM2SDkyVFZCTW1HZVRXLWxnc3hiUTIyOXc9PQ==
I use chatgpt and blainy. But mostly I prefer blainy because of its suggestions feature whlile writing that solves my problems for writing block and citation feature.,r/machinelearning,Z0FBQUFBQm0yeGJtSHUyUzBsYzJTa2JxeWpfTElYTDdMdkZpajF1U2hGdDZDTVRjRFc5TXVxbjRtbWpFd1ZoVnhjTzdFRUJBVVRPVG1HMVlDN1BwcVhON1M4V0JlT2dSX2c9PQ==
"Yes I mean user-clicks is one of the input variables. 

First you start with your version of the weighted output- no ML just some sum product.

Then you use the user clicks for changing the weights. Here all variables including the likes, engagement etc act as input variables and the video the user clicks on has been ranked as one. 

The model would over time accumulate the user click data.",r/machinelearning,Z0FBQUFBQm0yeGJtTmgxcEVqaHFBek81aUI2ZTY0bEVicVh5S0NWbWM4bTF2QXBZOFQ1SFZDQ0FXZHY2S2ZaNDRwUDhCUzhydHZHN29mX3V2ZWstcm9NUm1EMXM5a1BiYUE9PQ==
"It took me about 6 months of regular use, multiple vaults, plugin testing, etc, to finally be comfortable using daily. But the time invested is well worth it!",r/machinelearning,Z0FBQUFBQm0yeGJta1FIang3eEQ4Q1pJTDhzZDFsYnlFX3h6ZjNyLVpJR1k0LWpyLWRseW92Zy1rdm1ZZXBOcEtqT3ZNSzhTekNCWWdGWTQ4UURTeVpUWURqa3RFalFjSFE9PQ==
"Well technically you can just set weights however you want, because there is nothing that says what video rank is better than another, so there's no way for anyone to say your model is right or wrong, correct? You can literally just randomly pick a video out of the 3 and return it, and no one can say its wrong because there is no way to evaluate how good it is. If its part of a competition, how is the winner decided? As it stands, since there is no way to compare models to say which is a better ranking model, its impossible for anyone to win the competition. The only clue I see as to evaluating your model is this:

>recommend three videos for a new aspiring channel to grow based on the model findings

This suggests that the best model will rank video such that the top rank video will lead to better growth. This means your actual target is ""channel growth"", such that the highest rank video will lead to the highest growth, and the second rank video will lead to less growth, etc. Maybe distilled down, you want to know which videos lead to the most channel subscriptions in a 1 week period or something similar? That would make the most sense from a supervised learning task, but its still a bit unclear. You would need to have the data that says how much a channel grew after each video was posted. Otherwise, there is no real job here, you can return a random video and be done with the challenge since no one can say which model is better since there isn't a way to compare ""is this video better or is this other video better"".",r/machinelearning,Z0FBQUFBQm0yeGJtX2FVZFNYOEpJZzZtMEplbHdMemJlRjNvXy02UDFkNjFISDFDcms4bnFmSTJZNWNHcERPSEMtYnlMRW1wcUhTRHEtaVdFckdqMHppS3pnWE5JWVluYVE9PQ==
"I don't know the answer here but looking for communityl opinions: How about go (golang)?

My understanding is that for limited size projects it is far less difficult to learn than rust and equally performant. Although it doesn't scale very well for bigger projects (edge cases, dependency issues, etc)",r/machinelearning,Z0FBQUFBQm0yeGJtd1lHN2FWVTNrQTlmVTBWVWNCNkRlMWhnZEJmMGplVnRteU8wbi1YSDlMT2dTemY3NlVQSEc4N3QxTGxnZkNrU0NJR0VaekZmNnlLVmdfaDVEVFRaLXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtRV9mTzNpeXI1eFhXNWl5WVhEZGk0MXpNS3RLSmNtVWlZRHF5ZjJEeUdGeFl0ZWVyZTI4ZGtxR1VKS3M4TnFUYmVuS0NtMzBDM1pEMWJVRFdrczZzZnc9PQ==
"Being a Markdow editor is what made it useful for me, and the way it manages link. I use it as a personal wiki with info about my work, and for personal projects.",r/machinelearning,Z0FBQUFBQm0yeGJtci0wcmNqSXBXRDN2UHNkQWZ4ZUJnSVVaMzhJUmRUQmRNZlNOX1ROVl9xQ0pnbHRiZ0tRM21DNUdKSEh6MElLM1NCNktjUGV2YWNUMlVFZUFTSE1RNFE9PQ==
"Other people said you don’t have data but you do have data if you record this information on two different dates. What your model will then predict is the growth in views based on inputs of your previously mentioned features. 

You could make several models which predict the change in a selected feature.",r/machinelearning,Z0FBQUFBQm0yeGJteXRuSTAtR2psV1p6cFJmSUVDVkxfbW9hbHpXRmtNX0MxcVBxdnQ1dXQtY2IxOXhPY09DdWxvYS1RY0xkakZmTUZvUS1HQUU5NTJJcnQ3QUZ6RFA1Qnc9PQ==
"Mojo looks promising, but it’s still very very early.",r/machinelearning,Z0FBQUFBQm0yeGJtdDBDVlBIT0MtVG4yeGNyT09sRnMxWXA2MldOZ1pvblBnS3VyUUNkRm9xRy1zVU9qdkEwdzZjQnFqNUpld2t5TmVLZjUyWkxrc19hWEQzV2lqenJGZ0E9PQ==
"I started following the[SCTO methodology ](https://ilyashabanov.substack.com/p/note-taking-system-for-success-in), and adapted it to my preferences.",r/machinelearning,Z0FBQUFBQm0yeGJtSkJodmJOVFpCc0tINTlzX3NNZjd5bG44ZnBKeEJzNUtpOEhrUUxHRWk1bkZlYnRBeWxNQUdHQVJScEpEakZMYmFtTndfbkRjZjJIY2FKdmk2UlgxMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtUndyQ25LNDRBaDNlWGNwTG5yNTF5VnBlR1lydE9TQmtVRE0wYy0zVDNsbVhBM3dYUUpkWE9nd1Znakl4TlhLalM4cUVrYjlVNDk4MXo3RUJIMDFERGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtc0gxMnFMc2d1YTduYmJheElnZVg2NXlSLTVMb3I1bTA0X1N4OXZNalpRdTRWemszSFBwOHdNZkJ0eUlOUklpdk53UVdvbnduaUVGNDNmcFdvNDkxZVE9PQ==
Totally fair that I made a value judgement about performance ML research vs bio inspired ML research (which I do) being more “real science”. I shouldn’t judge the performance based approaches so much but I’ve gotten into so many debates with people particularly around real phenomena in the brain that we barely understand. Attention being a big one in my case.,r/machinelearning,Z0FBQUFBQm0yeGJta0JybWhJQU9jaUNFcnVtNkk1WXlYbDk5Rk5lckVqUTFUanVYN1Bxc1pNaURaWTVwUGZKQThURHVYX3N6bzN0cTk1WmgxYndSMUp3dmF0OUdzcnZ5eEE9PQ==
A theretical project that uses tensor calculus to formulate how to derive gradients for the backpropigation for deep learning functions e.g. linear layer or layer normalisation.,r/machinelearning,Z0FBQUFBQm0yeGJtbFdLMXc2amhjODVHckUwRVVkRldzT2dfaXJVWV9FSHRaS1phVWEwaWcwNGlPSWVoajBiTVp0QVoxd0N0UGFVa2FKZ3B4emhaVV9nQmNVTmhtTmdqdjRoUXhsbjI3VWw3NC1RX3BqdEZaQmc9
"Their early lectures (I think up to the 10th one at least) are mostly in CUDA C, and they require some knowledge about pointers and memory ops in general, but you don't need to have a strong background in C to follow along. That being said, I think that it would definitely help to learn some basic C beforehand, and for CUDA C++ in special, some knowledge of C++ concepts is definitely required. I don't think you need to be a C++ expert to write very efficient kernels, but you will need to learn about some more advanced C++ features like templates.

It's also probably more important to understand on a more conceptual level how GPU programs work, since many kernels can also be written in Triton for (often) slightly worse performance than CUDA kernels.",r/machinelearning,Z0FBQUFBQm0yeGJtX3FwdWtnSE5QalYwVHNqWkQ3LWZEQnVvOEZjVDFSZ1FxSUsyakVxQjJZUjhmeDhqbEdPQW1WcHdtYWxlaTZ6X1hJMlFTUnZFSGtKa1VYbDBIZjB1cnlRdVltVnYxbC1EVjZzUGZ4OUNwZTg9
"I might not justify bigrams enough, over an even simpler arrangement, i.e. you can do without tokens, have bytes, an even smaller alternative (so bigrams should also work), sort of like only 256 ""tokens"" (for each possible one byte) for sure, I think you might underestimate how deep my knowledge is. \\[Yes it has gaps, we all do, so seem question below.\\]

It's both possible with

A. (non-standard) transformers:

# MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

>Extensive experiments show that Megabyte allows byte-level models to perform competitively with subword models on long context language modeling, achieve state-of-the-art density estimation on ImageNet, and model audio from raw files.

\\[Beats with bytes only, i.e. only 256 ""tokens"", TransformerXL, CompressiveTransformer and PerceiverAR that all use SentPiece 32k.\\]

and the newer B. MambaByte:  
[https://arxiv.org/pdf/2401.13660](https://arxiv.org/pdf/2401.13660)

>Token-free language models learn directly from raw bytes and removethe inductive bias of subword tokenization. Operating on bytes, how-ever, results in significantly longer sequences. In this setting, standardautoregressive Transformers scale poorly as the effective memory requiredgrows with sequence length. The recent development of the Mamba statespace model (SSM) offers an appealing alternative approach with a fixed-sized memory state and efficient decoding. We propose MambaByte, atoken-free adaptation of the Mamba SSM trained autoregressively on bytesequences. In terms of modeling, we show MambaByte to be competi-tive with, and even to outperform, state-of-the-art subword Transformerson language modeling tasks while maintaining the benefits of token-freelanguage models, such as robustness to noise. In terms of efficiency, wedevelop an adaptation of speculative decoding with tokenized draftingand byte-level verification. This results in a 2.6× inference speedup to thestandard MambaByte implementation, showing similar decoding efficiencyas the subword Mamba. These findings establish the viability of SSMs inenabling token-free language modeling.

\\[That paper from 2024, and both updated in 2024, that one in April with e.g. ""This results in a 2.6× inference speedup to the standard MambaByte implementation"" added to the abstract, while for some reason ""owing to linear scaling in length"" dropped from it (still true?).\\]

>**Modeling long byte-sequences**. MambaByte is an application of the Mamba architecture to byte-level language modeling. Our main observation is that unlike Transformers, whose memory scales linearly in sequence length, Mamba maintains a large fixed-size memory state, which makes it suitable for direct byte-level modeling. \\[..\\]

>**Utilizing a fixed-sized memory representation may also help avoid quadratic dependencies and improve generalization.** While Transformers are designed to capture long-range dependencies, researchers have noted that the sheer number of potential interactions in a long byte-level sequence can dilute the model’s focus, making it challenging to capture crucial dependencies amid a vast number of less relevant ones (Tworkowski et al., 2024). Bytes level information is much more granular, thus necessitating the model to learn from a much larger context to make meaningful predictions.

>Finally, training Mamba for long byte-sequences has an inherent computation benefit at

>scale. The computational cost for Mamba at training is O(Lctx), while even compressed

>models such as MegaByte (Yu et al., 2023) have a complexity of

Since tokens are not needed (or wanted? I added the bold), then the question is are ""bytes"" just good enough, or bigrams even better, should also work, since closer to the subword model.

I suppose the recent xLSTM might also work for bytes or bigrams.

When say ""transformers"" is one token, how does the LLM know its length in characters, for it en any token? How is that knowledge injected into the models? With special training data, or does it lean it implicitly like learning something about the word ""yellow"" without ever having seen light, just because people discuss colors?

It's plausible those byte-based models are only tested on English, i.e. ASCII letter that fit into bytes, and they wouldn't work for UTF-8 multibyte sequences well, or possibly only up to 2 bytes, not 3, or up to 3, not 4. One reason I suggest the bigram ""fixed-size"" model.

\\[I got a server error several times when trying to post, maybe quoting too long, so I cut out some interesting parts.\\]",r/machinelearning,Z0FBQUFBQm0yeGJtRDlGX3BtVkM4aklBWHl3RzRtZmJzRFlxVjJVSnJkR0MyVkRhUjJxTGttRktnYXFSdkQ5UDItU0tpcDA4dTI2bXJZNG1kYmZaNHhWbDVIMVlzTFZFT0E9PQ==
I think you're overthinking research internships to be honest. I've seen people who are eager to learn but never work with Pytorch get research internships during the school year when I was in uni. Your experiences may differ though so talk to professors. For GANs and generative imaging you might want to target a computational imaging lab (importantly this is typically an EE > CS field) but otherwise just generally look at people's papers and decide if you like their work,r/machinelearning,Z0FBQUFBQm0yeGJtWnFSd1BjSDd5OTRVNmZrLWVyTUZ5WFBseDhjYnRqN092OWhiaEYteS0xMzctMUEzandLc2QwVlRqX0g0MG5OTy01NjA0dzJ5d1lzalRqeHdoNk1EX1E9PQ==
"I might be overestimating the key requirements, but if it's a good way to learn in your opinion is what I wanted to ask.

However I am doing research internship with my uni professor right now, but it's unpaid and not so professional in my opinion. Although I enjoy the work I am doing, writing a good paper is a high priority for me, so that I can later move on to find some research positions in corporates.

Maybe I am thinking too far, but that's my immediate plan.",r/machinelearning,Z0FBQUFBQm0yeGJtaXdEWFBfMXB4S1lQVmNGOTRUQU5pY0NSa0hEemQ0cGFsNVVULWMzbmhmRGdPMlBCdXNXUWMteHFIdTFLWEF3dDdtVmZGMEdqYVo0Snh3T0FPQ28tOGxPSWV3MjVLWURib2pnYWJybVFuWUU9
Just take the mistral/mixtral/llama3 architecture and reduce it to 100M/300M parameters? It's not hard.,r/machinelearning,Z0FBQUFBQm0yeGJtN1g2OXpWY0dxR24tdm0xcktMZlJqbWcxblA4eVlnU2xvWU45bXRCMjZxU2F3M0pGVFp6dWlTQWozYVFlcll3dWhvZ3Q3MmlqbklpN2trb0sxR3JRNXc9PQ==
To this day...,r/machinelearning,Z0FBQUFBQm0yeGJtR2VOWlVtcFJpOXNxUWhVcWFEdUQwYWxDdnU2bjZfempoR3RPN3RQQjZfRk51c2VhN0dSanlQLThPTEZHZ2VkdXg2anhKX3VEX1hqSTNRZHE3YzhlY2c9PQ==
"At the moment Mojo is still not mature enough. Julia can be an interesting choice, and it's gaining traction to some extent. Learning CUDA reinforces the monopoly created by Nvidia, and IMHO will be more harm than good in the long run.

Personally the language I am excited the most about is [Bend](https://github.com/HigherOrderCO/Bend). It's even more exotic than Mojo, but the ideas behind it are extremely compelling. Just an example: it promotes platform independence, which is a huge plus for whoever has to write reusable, performant code.",r/machinelearning,Z0FBQUFBQm0yeGJtNnA5SEtmUXBSRWVYdkdzTWZJM0hTUUZ3M3Rzc3BLZXhhQUgyRks2WUNLcnpteXZoNElvcUsxaUYxYzgwQ0RaMVJkd1dsOHFhT1dHLUVYaVFibGltTkE9PQ==
"without labels, you have to do unsupervised which is typically clustering or some form of latent space representation. And even then you need to have some idea about the videos within the same clusters or having the same weights of certain latent features, which means you still need some form of labels/annotations.",r/machinelearning,Z0FBQUFBQm0yeGJtMWhvejZJMWdUNDV6aDVyZWVSR2lkQ0dJU3lvWU9TdndEOWl4RVBhZmVWQWRiNVJ2N3VrbzFuV2xtTjNZSTY4MldjenQwVm9mVmVuZW5hb2hHWHBpaHc9PQ==
AI Research Navigator AKA Zeta Alpha search engine https://search.zeta-alpha.com/,r/machinelearning,Z0FBQUFBQm0yeGJtdGNwY2ZZd08xTi1CcnBGN21HZWtJMXk5ZGxvaHNGMnVNYTFob1Z4aWoxQngxZFVCV3FxM3RxYUE1dWdxTlljOWlaMndpV0h4ZVBTMXBNS1VTN1Vac3c9PQ==
I use Sioyek for pdf references.,r/machinelearning,Z0FBQUFBQm0yeGJtenExOFdQVDd6WThYS2VvdGplMEhCdzdHLTRvbzZHVTk1YkZOZlRRVFlUTU1xSGdQMUt1WXp1MUFXdWM1b0JwOGVsckNnN3Vab1o2WEtid1FIOGhqMG5wTmJzdks5ZTJiNjZRdzBUOW5CLUU9
"I use [FolioProjects ](https://folioprojects.com) for research projects. The ability to switch between LLMs supports in depth analysis and optimization of a range of ideas. Also helps me to share the research with custom stakeholder groups of any size via live feeds, exports, integrations, etc.

It's like a research assistant. It tells me the probability of success, outlines risk, etc. As I make changes, it learns and makes better suggestions.

Maybe most importantly, it helps me to credit everyone involved in successful research projects as well as all references and related content (data, docs, media, socials)

Edit:clarity",r/machinelearning,Z0FBQUFBQm0yeGJtTFB5QVpHZUZwc2dqeWlLcTN0WWY5QURENm9ud29HM3R3QnBKaU9iVFA2b0hLSkFXazE2Zmo4a2k3ZEVQdS14cEEwc2xTU2MxTXFfMmpOOFZGdU5PTmc9PQ==
"Not directly related to your question but aren't 20% of Oxfords foreign applicants accepted? (Not that 20% of students are foreign)

Or maybe it's just their bachelors program?",r/machinelearning,Z0FBQUFBQm0yeGJtMUdYZThVTlpPUXV2MXZhMmVOa21Rd3k4TktCSTBwRlZscmo4WHNWOWd2SlZWUjFOT2dablM0M1dZT0RNWjhnZzJ2Z1BHWWlTZmgxWUJnc2VLcVFfOXc9PQ==
"Interesting but yeah, looks even less ""production ready"". Still, good mention, thanks!",r/machinelearning,Z0FBQUFBQm0yeGJtdXJ1N0g1Y0VocGtvdUd2bEZkRWpvVDNiY0YtalRNSzExbzBsbk5PWmlzd01XUHhTMnlDMGJKWjNjdHdhdkNCNnFJRThOVWxzM1MtemMzSWdxZDVUOFE9PQ==
"Yeah, bend looks super interesting.",r/machinelearning,Z0FBQUFBQm0yeGJtNEJJNFFBWGlnUTBWS29vS1BSeHdMeU1Qeld4NXNadlBNUWdhWDlocW0xcmFNdTZ1WVA3ZjdlNG1wcDVNQ0FDRGh4bW9WWHlOVDJ6eWxoSzNEZGoxTnc9PQ==
"I wouldn’t bet against mojo, Chris Lattner is easily one of the smartest guys in this field. That being said, it not being a fully open source language will ultimately hurt it.",r/machinelearning,Z0FBQUFBQm0yeGJtbmFYYnFWRnA1eXF3UFRrekVwUkFmaGlxa09KSlBkYnotc3NuWVVGNUlyUlgxVDhxTU1CeWJWc3pidVdvdU9DNktDXzRzMTlSYU9odGZSSzN2THhvNFE9PQ==
">I think this is a very biased answer laden with personal opinion and IMHO passive aggression. Researchers working on artificial intelligence are real scientists and often have strong neuroscience backgrounds. 

These types are a minority.
Most researchers in ML do not actually have strong neuroscience backgrounds. They are usually just computer scientists.",r/machinelearning,Z0FBQUFBQm0yeGJtNVlIZUtLZllmXzd1OEZYczlETGR4UjZoQWNDcy10Q29JZnBFb0lSenpzbzhaVWtJbnBsdzh4ckR5bFJMR2d6QVlXOTV4NTY5UU5Fc2E0S3Y1djZBYlE9PQ==
I like to use google spreadsheet,r/machinelearning,Z0FBQUFBQm0yeGJtTXZHRUNYWWFPTFZTeFRDM1lvb2tuZDFFUEpweko0RldNdk9CLTBMODFzb1pjLXZBUVdxTnQ3WUVUS0tJRWNYOXRkMXRrOE80VzhpUERFM2x0alNfa3c9PQ==
"I went for a systems level. Unfortunately i picked rust which isn't very good in ML yet, but it was out of interests. I guess triton or c++ would be better",r/machinelearning,Z0FBQUFBQm0yeGJtelQtQ0hyU0hPcDBsQ0NMWHVZbEk0RzlGQzIxa3pzY3MtcDh0SmZLUVZuWEp5SW9mZFBqelRRRzJwRDVXSDI3OG5WSnhNWjVZaXdiTkJMQkg5TDJmNUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtMDdrRmFNYUlwdDdJdmVWbEw0c3lVNHp5aGp2SHQ3WU15UUY4SkdTWFZhUDVrdzd2SGZhRzVuNElsNUx3Rk04UEZybW16NGxGcld1RmJBenc5X0xZNXc9PQ==
"A low GPA will stand out and look bad. However, prior publications, letters of recommendation, and a good statement of purpose are generally more important than the GPA. Sometimes the GRE weighs higher than the GPA as well. Furthermore, the admissions committee will often look at why the GPA is lower than for other applicants. Is it because you did bad in important courses like math, stats, cs ... Or because you did bad in your photography elective?",r/machinelearning,Z0FBQUFBQm0yeGJtTm5nV3Y2WHYzc253LXJjNU92bzE3Y0lsQzg2eGhzZlVVNDZTRTNicmYzYUZ3ck9iUF9DRUxFdzNwMUhCS00xM3oxa1gyRGFxWnFrWVRPbU1EcVFlMEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtM1pLNVV6NUxOQUdNTGRhZzJwUERPNy02YmNmeXU3VER5UEVqZ0MxNHJIX2wwQS0zRXlQckRMYzhvR1ZGbG9wNmY1aXRsUVhMTW45MFVXNkVrc09Hb1E9PQ==
C++,r/machinelearning,Z0FBQUFBQm0yeGJtTDM3OUZ5ejFWdTZxUE9iNU50QXNMM0RVdDItdlVGMTFtNjNBclB0WFM4NjNQUFJ4UmxUWmFnRkM4aWpOZWlvOFBsSktpbXdxWDhnay1veERSaWc4eEE9PQ==
"Yeah Bend is super cool, but it’s only like 2 weeks old. I think it’s more of a keep-your-eyes on it type tool for now.",r/machinelearning,Z0FBQUFBQm0yeGJtQ3k3M2d6ZV94Z0JrSGVCZGt6WkViTXJqeV9taWZDaXNKU1VnOFNDUng1VHJHbnR0Z0hhc2tDVDJyb3NjSFZmQW5LbmEteEgxbVVmZHA0WDNETE5TZHc9PQ==
"There is one correct answer for this. It's industry/job/company specific.

Could be C++, scala/java, c#, or a variety of other things depending on where you want to work.

But if you want to be successful in this industry you'll need to be able to pick up any programming language relatively easily",r/machinelearning,Z0FBQUFBQm0yeGJtWkRYcjBqS21aTDExZkptNTNJY0lZdlhjU2c2c1kxTVFCR25id0NFX0VGRTB1Z3hMN2l0MlE3T3R4OEpiVDFQbHNrZTUxbGprUzV0aUoxNkRwT0xJT3c9PQ==
"I’ve found Nanobind to be way cleaner than Cython, for what it’s worth",r/machinelearning,Z0FBQUFBQm0yeGJtV3Z6UEl4ODNLdVI0UXR5bktzQmRHUWlrQ2s5SlBnM0ctY2RaV21sWHdQaVJ1RG8wWVRlaDBGNDdQbnFXZEZUOUh6Q1VjWXlHWHp0ai1rNE1wZjY0c1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtS2tIUmx2dkNCXzNOY082N1RwNzc5TWhrMFJsRXR5T1JzTVdWRnUxY3NydFV2QmFwWmhsN1hHdW0zZktOeEI2TVRjT2o2bVRPcUxObXJteFdGTkhUN0E9PQ==
"Can you elaborate why is it not fully open source? Do they not accept PRs, License issues or sth. else that I cannot think of?",r/machinelearning,Z0FBQUFBQm0yeGJtZ1QwNUd6OUw5bkFKcUJCc19Seko2dlg1M1ZVLWdOUEx2QjZVTzZCelctcm8xR2FDM19xWVRZSHRVYU4tcDZUbmJuZ2dEVlFUTEtZMnRZWmNlbzVidEE9PQ==
"Speaking of toys, Rust still isn’t great for ML but it’s a fun to play with",r/machinelearning,Z0FBQUFBQm0yeGJteHphMDlaRk12dnZIUl9icngwRlNGTEdBU3JDNHJFU21HcVdULXliT2NjSXE0SUk4ODBEbkd5YXlaSFR3YkZ0eFJtVXA4M2tvTFVEUlZLeW9BR28xZ2c9PQ==
"Generally agree, but I think there is no single correct answer to this. This is why I want to hear other opinions. I generally agree that the industry determines this and my current role does not require it at all but I am still interested in learning more and eventually transitioning or at least enhancing my capabilities and the solution space I can provide to industry/academia.",r/machinelearning,Z0FBQUFBQm0yeGJtd19MWDllcExfOUZvM0ZISTJMOEltcWhyU2dRQ3JzdnF0MjZsSXJnQ0xBSmIzZE9lSVJDQ3BRc0FjSklYeXZqeUNIOVdlTjB4S3h0clQ3WUdaN3d5Q3c9PQ==
"This is the right answer, I get that Rust is hip, and I enjoy writing it but it still doesn’t have the c++ interop needed to be really useful",r/machinelearning,Z0FBQUFBQm0yeGJtakpoc3dhRVkwN2RlYVFNRHktZm8yOHI3UktUY3ZIZ1ZpOWRGU20wV3ZtUzlQeHV6RWJfay1JdjZwNFNSbnJGS0MzemlXMlJab2xNTkZsclZYSE90R0E9PQ==
"Julia is a dying language, I’ve seen too many good devs get burnt by it",r/machinelearning,Z0FBQUFBQm0yeGJtdmY5ODNsenRRdG52eVBaYVpVeGlrUF9BT0hiN29LYlAydk9fT3Q0V0ZqeHNram10eHMwYmd1REpnVmhpejNyWk5LbjZEVExzdWFpbUZEZGxCN1duOHc9PQ==
Really awesome suggestion that Nand2tetris site. I am already working on the first project while I am waiting for this discussion to give me more opinions to make a more educated decision. Really loving the pace and hands-on nature. Thanks again!,r/machinelearning,Z0FBQUFBQm0yeGJtY0g2Zmh1VTZ6bTMxbTFUZTZMaS1HVGxWakVtSFBQblh3eE5kWEF4OHl3bWpsWTIyYXd5WTRKV1ZKdGJtR3Rra0dwY3ZFMjJHUWc2cGdUdFRYN0VaY2c9PQ==
"I think GPA is something that if it’s not good (below 3.6 I guess?) it will have negative impact on the admissions. If you got straight A all 4 it wouldn’t add much to the PhD admission. I think Publication and LOR are something that are more important. If you can maintain a decent gpa like 3.8, that should be enough",r/machinelearning,Z0FBQUFBQm0yeGJtQjMzTGp2TXRPclU1SmZGRE5FZ1l5YWw5T290MUtLVWIxeW5Md2RjcmJjaWJpYUY2QWtuVHNUYTR1bjRXSHM0eE82ckVhbzN4VWRwTWREbHdjNTRTOEE9PQ==
"Go is best for web backends IMO - that’s really what the coroutine system is optimized for. For ML, best langs are Python and C++",r/machinelearning,Z0FBQUFBQm0yeGJta2ZxbGg3cWRWODJnTkYyNGVNMDBHRmo5QTFJbi1XWTh6MTFLTGF5UlJHREh0a1hPLTFLZzBYeldNTEFEcGtXVHRJOWM1UnlBSC15RjkzaXNLM01rS1E9PQ==
Do you have an example of this?,r/machinelearning,Z0FBQUFBQm0yeGJtSmgxT05MemNyZTdtcEVpQUU1WlBLUGszdHJKdjg2M0Rxai0tcEVOMXhYY1hna09rUXQwTkJNMXpfMUdRYmVNei1iWktkdlRoRGpmbTBSeElINEZxYjdQZUxRWXpoNG9WU19TYXF0cGZMUTQ9
Bend is not interesting at all for ML settings,r/machinelearning,Z0FBQUFBQm0yeGJtNnFzWDI1NnVCZnQ4SDVnNW1yUVRXcmh6SHNKZVAwNEhRZmE0X2NNVkZ3NXJoM1BCejRXT2RpeVgxV0NoUWltTFZHdTFXSWhRWmxwdERxT1JMUjVSZ3RfQWdxWDZ2MzRCYU5iYXA2OFpaSjA9
"hey, can you elaborate on this?",r/machinelearning,Z0FBQUFBQm0yeGJtNEt4Z2NlWWxMSVgxQjJjbi1RRHlzQTVqT2Zmc1ZiMW1CaE5IXzFJRElxWXJKVWU1bFpaRlJvTlJPdWVFbkxwR1VwUkV4cHY1eTd5WnUyUXFDRHB0TW1wd1YyYW9QVXEzU29hcW14cjJ1eXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtTTJraG9ZcnduNjRRdzk0cmFBOXpZVWlvWUZ1bDhTbW4wUlhPV2JqYzRWY1ZlSFRHWVhFbE9tWGE0THJGcWhIdHNrRzBfYkJFb2w0Q3ZISHVtRXZpd0E9PQ==
"does it supports cuda? if yes, then i am definitely going to try once

ps if u have worked with burn, can we connect once?",r/machinelearning,Z0FBQUFBQm0yeGJtVkZhMjllcGNKa3FYLUhndFFJZ1BTVHhWbGpJX1ZyT0dTVFZQX3pGc2h2NHhqdXZDRXRSYWg2aDdYSVBtRUJ0M3B2cS1ibUk5Nm4yaFFoYUx3ck5ERnE1Q1BramFvd3JNc1JZcFRmWm1vUDA9
"While I know it's not mature enough, isn't a big point of mojo to be almost 100% compatible with python syntax?",r/machinelearning,Z0FBQUFBQm0yeGJtaWxZWWdhSzVfWWRmbDl0SHdObkNXN1hlZEdLUXVhY2RIN1JZWHhaUWhJcnRvS1ZhNUNob3B0cW0yZWFFUDVvNkhVOU9iZ29CbFRON0xxb2d1TGhQLUE9PQ==
"I use the brains of my students, they are very powerful and effective.",r/machinelearning,Z0FBQUFBQm0yeGJtVk85UkdyaU1rSXA2bFJrQ084amRqbmVJdVRjcG5qaUdaaDBwZXlUQS1RZVNmTmk5S1dIUnpueXBzTU5mQWFNcU1LNUMwaTg3LVJ4eVJLNHpuR3Fad19JRTNFWE9qeEVPUWt5QjVVb2xoSjg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtUk15RlFRMzBwZG9tU2ZNYUFVbFdIWHdKQWVfa3RSYTJySWs0YXRtQXNfeExHdlV0UWlzend6YnYzLXFYUmZ6ZE1wUERWc3RpSE82Rm9QQ016MDItOXc9PQ==
"Indeed, so the break in is easier, although you need to learn ""more syntax"" if you want to use the nice performance boost, e.g. due to static types etc. Nevertheless, I was looking into their introductory docs and it indeed looks quite intuitive.",r/machinelearning,Z0FBQUFBQm0yeGJtSG1WSno0N204R2l2R1ZjMzMxYkxEM2Q1c1BIWEVCN0FEOXo1TmU3Z2pqTWMzQlZYb0VMMllfM1YzTXVQaGV1aXc1UHp3ZC1Vek80LTc4RlZ3MzRtY3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtZUs1NkhacUFCNlFEMzhIMF92bkV3dUJ1eHJxcUVvRHhIMGduQ2FwTUhwNkZJYkpXMElsNWFNQ1dZTkxkOWdDdmQ5U2lVa2wwRTl6SUMycHVndHk2RWc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtSUtEMXVocFQySkZ2RDhkaldSMVhRTHA0emJzaXJwWWt2NGozaEd0OGVWdFlhNlZHLW11RV9YdE1qNXZFbWk1WWFKNjNFMlVHLVBINXRwUWV5eTdIY1hJQnZhcnlFRVZQcC1fcFBVeHF4MUk9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJtcUFQeVpGMFZ1andCWWY4Yk9vSGduTUZEUDJDb2ZFY0k0Q0VzUTZJeWh3blc2eXFGMm5QeTVybVpweVZWM1NnWXF1eE5jbi00V1kwSjFXT1hhdWd3RlVxUkJpb1E1VGNRWUY3MjRDYTRLQXM9
"I would think 3.0 or better would be acceptable. That’s the standard for passing classes in many PhD programs.        
GRE scores are important too, especially writing.",r/machinelearning,Z0FBQUFBQm0yeGJtcnh2azFYUWpJN2NpaFhtY2tnY2F6SXF6dUZETTJYVUI1c3ZhMEZTOVRaMTdGcEJnZE83bjBFcVJ6UFVXdmlOSC1MVjdLZU0ySnB1YnVDX2l5OE5rdnc9PQ==
It’s really not. The number of universities and industry R&D or national lab using it for critical infrastructure code suggests it’s actually thriving,r/machinelearning,Z0FBQUFBQm0yeGJtMDFrdl9wTThlUHlkRVl0bVN3bFZlZTBicVN4S3ZBUmtQX1Jxb2E4dVVMSzhmWmJrNTZXazdfa21YdDNIY24yTkVaYUNqQ21jMkU4Y3VJSXRtQVRFUlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtajA3aW5Td3NGWjdLRDVtS3BLU2NIaTM3RmFHZkFOZDBZY0hsNHJ2YW1EZnRGeGhXTV93LUZOcE9FRU5WRVM5SzFyUEF1dkxtd0ExUHN4WFBYb3RLOWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtYWFwczluY3hJbTlFRllYVU1TWV9CSTJXYkpaX0xwaVp3cXJ2bF9Cbl9mY014WlRTWlBpemZBT1FZUU9Ia09US0pqekw5STJSYXh0V0lGMm5zS0ZfZXc9PQ==
Love this tool,r/machinelearning,Z0FBQUFBQm0yeGJtUUpKMnRsejFEQ3VJYVBFUDBHOEtGenFsdmNpOV8xSlhRR3lzaXhrMmZxWUZfUlRybW9XQ2s0M2NQdmhCQ2lxbWVyR19tQXFuU2dhdmRqOGNmbW5qQmc9PQ==
Is blainy helpful merely for the user interface you get? Or are there some nice features you get from it that you couldn't in theory get from e.g. chatgpt?,r/machinelearning,Z0FBQUFBQm0yeGJtUUJlVUExeWFVaDNTSW43SWpmOS1pWWl6YTQ1bmdORWhTSGMtLXhtUlpXS2EtTXpZTTFiY2hhYTJxVkUyMjlOMnVleE9WNWt0VFZtaUNoWWsyWVhCX1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtX1hVTkpIOG1ScklRWEIya0ZMTjR6VjJKU3BiRWh6dGlPMUdTNnBUQVRSTjZxaDFsZHZTenBxRkdVc3FRZDctMHVhN3M5RDc0QWhvS1FFX1ZKTGNMWkE9PQ==
"AI writing tools are great for non-native english speakers, but they're not going to do a lot for native speakers. Effectively communicating novel research results is not easy and it is generally not something that an AI will be good at.

After all, those AIs are trained on other academic papers, and most academic papers are not very good.",r/machinelearning,Z0FBQUFBQm0yeGJtbi1kOVlUOWJpQ1Y5OWFjUUp6dXVLdWVfdC0ybWdZaUN4X1ZaN20zSEY4NXFmNVZDVTNHTXRoVUN5Y3VqaEk4WGRpdkdXTm4wOUtoVjFzYnA5U0U3LWc9PQ==
No. This will remain Open Source. We will use this as backend for our product GenAI Stack,r/machinelearning,Z0FBQUFBQm0yeGJteHk4RXBzTy1JaGFFZjlQWGJDSkdkQWJvUjRCX2J0MzVXYkdsTzlwSDlfYjZJaWUzX2E3SFlMb05KUW9XaDB6c1lvVU8yZlJyOXJQSlQ4bVZWMkZ6TWc9PQ==
This is very obviously written by an LLM. The quality of this sub is in the toilet.,r/machinelearning,Z0FBQUFBQm0yeGJtZlZjZGlFNnN1ODZNMl92QWlnX2MwNGtVcXBXb0lCUVRtMG9DVkduOVJrUzV2Rk5DXzlVakJGak1qT0YwZmI2cU1hTlJ6MUhINGRhWHppSTRWX0pzQkE9PQ==
C++ easily,r/machinelearning,Z0FBQUFBQm0yeGJtVDZubGVBeTZ3WFpJRWFILUk1d2RISlNsYWJ4YUZqeG9KeHl3S1hLdE9QRHZJNUhzdXVscmhyejBYYU9aSm80UHd0eS1oXzEybFNhNzJxbVp0eklnMnc9PQ==
Is there a new update ?,r/machinelearning,Z0FBQUFBQm0yeGJtRGdqQkd6OGZ2a01VVEVIYjgxVDFRSHBxZ1F4MW5lRXM4c0RXNXZuNzJaaEVrOXhhRE55QndyaXdKZVBzVkpLTW9LMXVwWko0SDVqZHJybDY4MW1xTVE9PQ==
"was honestly thinking this, one time investment worth lol",r/machinelearning,Z0FBQUFBQm0yeGJtR3hPRHdSdVk4VjYzZzEzcVMtRlE1Nm56U20ydzhMV01EemFvNm9tcGlaY2s4SVJXd0pwQUJFeXoxX3NPcFJqaUU4dUIyWHNwYXhPTnVIYWdGQWhwVnc9PQ==
"in general, how hard is autoscaling to setup? not really sure how the tech works",r/machinelearning,Z0FBQUFBQm0yeGJtZ0NNcHozZXZXUmZVZjZFTFBod2xpNWVwUEdyNWEyOUt5NzU0WklmMjhRUXMzRUdUWDlFY2dGVE42QkNsZGkxdk83X09BS0JPMnY0RjI0c2s3SFJsdFE9PQ==
"Your perspective is right and well-stated. There are no other options than creating a composite score and ranking videos based on that,  it's not the best way but funny enough that's their problem, this is not the only issue I found, for example for the sentiment analysis part, the dataset they given of comments are very few ( mean of 10 per video) ironically it's a big competition on a very well known site, but ultimately we just have to go with what is the best solution for the context given. Thank you for your help",r/machinelearning,Z0FBQUFBQm0yeGJtemFxQ1E1bEVHRW13OU12M1ZPZHRkZkF3YVdaaU9LWk56eHZuaXJLWllzR05Sa2QzbDRQd0JCLWtUMWFXTkF3VTVKaWVMd2l3cEtaU29MemtWekFIbkE9PQ==
"""As ~~a researcher~~ an AI language model... """,r/machinelearning,Z0FBQUFBQm0yeGJteFQza3FhS2xYWUM1anRoY0JOcFRSQ3Jsd3FmU0wwOHU3cWl0ckd1QnhDOG13WWsyaWR2ckdXZG5Cek9xUlVnN3NpU0RNOXNHRTgzYnR3VHpuQ1F0U2c9PQ==
"

scisummary.com is pretty good. ",r/machinelearning,Z0FBQUFBQm0yeGJtV3N5VVF6cUtCQ3R3Y2xFUElaQmhYWU9wWTVTbmltZ2NnY2Z6cmZVTDFEQ1h5ekpTakxPUFIyVDIxb2duZUhxRW45Y3pMS2g3VHJadlpIUElRMHJ2a2c9PQ==
This reads like a ChatGPT post,r/machinelearning,Z0FBQUFBQm0yeGJtOXRwaWhFa0wzOTFFa283Mk9WcEp3c3MxODkwOS1mQTlxOUFSSFcyWlhrQkZTQ25XV05ocm5kQ252VVZkb1dEdnI4RjZiNk16MVg2ZHI0STF6aGFfQnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJteXR0RVF6QnVGemhvVFktZnVJSG1ZdWo2RWZmR3ZyNU5ad0ZOUDNzR0tlSmZ4d1NILWtWMmdKSUhuOG1OY1R4UU5ySmpmOE9ENEp0Z1pUbzd2UU5sMHc9PQ==
"Those titles can mean the exact same or not, but the title itself won't dictate the kind of work, at least that's what I have experienced.",r/machinelearning,Z0FBQUFBQm0yeGJtbllzU3VBeHpsRm11T0NaT0YtLVVNSU1xWEJuREVHRUZuV19ybjVzc1gxQUcxak5Ha1FkVU5NeGFpTXc2clAyUy1SNmt1elVuN2psQ2FLeU5uaktnc0E9PQ==
I’m surprised that Java was never took off in a big way in fhe ML world. It’s way more secure than python and almost as fast as c++.,r/machinelearning,Z0FBQUFBQm0yeGJtWGtONGo4ZkNzcV8zdWxSb2h6OFlLZjNzZVI3ZkZ4QjQ1SHJreGZWYmQ4WEtfYng1VzIxMGxVLV9FUGNxUjU2U21xR3VRNk5GdkM4OGtGRTZTZEdGRkE9PQ==
I don't think there's a distinction. Neither title is defined well though so who knows.,r/machinelearning,Z0FBQUFBQm0yeGJtWVNfTkxDNWtLRTMxRGRFY3lUZWJQVUhveVdpdWdKVUxOWjZRdndVRExDV244Y2s4bmk3NUpZY2NjVlN1X090bjlxQmE5Qy1UdU84NlVfNV9kNF8yVHM1SG9OS212OGEzdGZWWDFIRUhtSGs9
same… unless it’s Research based jobs or symbolic learning,r/machinelearning,Z0FBQUFBQm0yeGJtbTFvd3JKcGlwdkk5alVDWjN4LU9FVlN5a3RtQWV6SzlMVmR4dGl5bnVodThjRDRuZXJ0UG5iVDY5alhINEI0Smh6MF9DVENNN1ZDLTEyNjRIRnNkS3J5TUQ1YmU0RVNXWllmRzhZYkRodm89
"Just about every metric you could pull shows it declining. Its a massive waste of time for anyone to adopt, the ecosystem just isn’t there",r/machinelearning,Z0FBQUFBQm0yeGJtOGp1dk9HQklXSjNVamlQYVdRRnB3SzJKVkcwWHZsdEVSVDJDY2hJSWZKcW9pMFRnQ1Z4SHRtd1ZTeGJaMy1QdWVWQno4VXRNSW1nbEFLRzh5cjBTZnc9PQ==
Like?,r/machinelearning,Z0FBQUFBQm0yeGJta2hSN0VzVW1QbnJxUjBWUmNUTGpvc214NjExSWdmN1FORTJUV2NTY2Uya1d3eXFYRU43RGhLWXNJSmFrZG1za05Yc2tiSlNtN2gyV2VGUG54OVhPX1E9PQ==
"All metrics show it dying, the usefulness of languages largely depends on the community around them. I’ve written a fair amount of Julia and wish I didn’t now. I should have just spent that time getting better at c++",r/machinelearning,Z0FBQUFBQm0yeGJtSHQyZkxYeHZLeTVOM1BFOXpzRng0aldyTHVGaFh1SVJIUGJyN3RSRFhBWmNYN242cUs5OWxnY2p6eUdHUWxrbXBhS04wV2pHSDRqeXlzRkg2TmpoMWc9PQ==
"Performance critical code needs to run on the GPU, assuming it can be parallelized, so perhaps your main consideration should be how easily another language lets you do that. Are you content with being able to write CUDA code, or do you want a language that also provides higher level GPU support?

C++ supports options other than CUDA with things like NVIDIA's Thrust library and OpenMP offloading to GPU. Julia also supports things like XLA, Flux, CuArrays as CUDA alternatives, as well as having a variety of auto-diff libraries.",r/machinelearning,Z0FBQUFBQm0yeGJtbzRXeXcycF9wQndqNzRqTi1BU2dBQWluRi1MNTFhcElBM0xGdVRXUDVkLVNtRV9CUS1iWVVrZGNqVnRPYlRDRTFpVTl6ZVdWMVhpQ2hjSTRBR2lYbVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtUHRrLVdlQVAtbXN0eXBfMDdFNTIzSzBPSlFZN212MDU5a3pqbFJTZUVMcU9xUTVwSDdfTGVMZVE3ZDY1bmlVVzE2cFpEanpBbHI5aURmcXpabnlaN1E9PQ==
"It really depends where it is, I suppose. But it's super hot right now so the expectations could be a bit high. But if you really like the latest stuff in NLP, I'm sure it will be fun!",r/machinelearning,Z0FBQUFBQm0yeGJtbVByS2puYl9hZmk0dHkwbm8wMUwwaEI0MWpvZ2g4SEMyUTNPUWJZUW8xMVFYeTFUaEJmUTM1WUJHSDRjZThEak1XRXBzT3B4NU9MaHJnV3pLR0hUMnljOHdPdXFvVGJuc2pVWXNUTEd2aHc9
I think parts of the source code still isn't released but they recently released the source code for the core API to the public,r/machinelearning,Z0FBQUFBQm0yeGJtNVYxcFYzdzRaVzQwRFlFeVk3S1ZtT08tRFpOaG9NZ2l2eTV5azYzQU90T2p3cGJWaVdxbmdCTTlzU0NpMEVMZWV0OXpLaVd6SUNUS3B1eXhpZ2tkckE9PQ==
"> Another thing is, there is no strong evidence the human brain does backprop.

So if we can figure out how the brain is learning at a high level (not just hebbian), it may suggest new AI architectures that support online learning (not just backprop-driven pre-training).",r/machinelearning,Z0FBQUFBQm0yeGJtVkF0d2s1ZllyRjU2RXBlejAxMkZVME9yRlhfWTkzWVFRa19ud3RrTnFQbm56RmFxc1pxOUs2UXV6TGN3c2t5Q3dSdmtRaWNmeUdmT3hmTFNKTklhUHc9PQ==
"Every major programming language index, also its own package index is no longer rapidly growing.

A lot of people gave it a go years back and then just switched back to Python which is fine for most scenarios.

I’m sure it will live on in academic research and continue to have die hard fans much like Pearl",r/machinelearning,Z0FBQUFBQm0yeGJtNmxucEFVZ2NfM1Byb0tQV0Z0RGxjSVlVMUh5alBKeDkwQy1IQnR4Tk9oT0E4YW4xRUEwckNMWW1xTzlyYS1wdXBlVHJxS2pVTTVPVzhyTGZkSVlFaWc9PQ==
"Well, there's libraries like Thrust, g++'s OpenMP offloading to GPU, alternate languages like SYCL.

Even sticking with Python there's torch.compile and Triton (Python to CUDA kernel compiler).",r/machinelearning,Z0FBQUFBQm0yeGJtRF81bXlaV1ZzMDZpY1JYaEU3cjBjQ1lnWGkzdHRxNC1OVDU5WnppVFJiMXdyVDNtamlxN2lJUjRMY0p3Ty1fbjd0ajNVb0dRUVJvVjdZR0pfLS10cVE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtUEgxOWVUamRvSWwtWHg3OXJQcjdCMGlJa3RZaEloNXJvZ2czbndDVUJYNnRNbjBqZThGaVlaaF8wNlBmNk5wVWVwTzNIY0NwbG5NaVJURzAzcHZsVDE2cjlkbE82bU5sQ2hGODVLOXFucFE9
"im a high school student who does research and qualified to isef so ill give my quick two cents.

high school research is great, i love being able to do what i love and getting a head start on what i love doing so much and plan to continue in the future in high school. but thats not true for everyone. if you look up the krish pai scandal for isef 2024 you will see how much high school research has gone to hell. its not even about research or its quality anymore, its about winning the big flashy awards with the huge price tags that get everyone into hypsm. many of the kids on my isef team were totally ready to give up on their field of study after they got into college, which is a sentiment expressed by other people on this thread. high school research isnt ""research"" its ""publishing to get into a good college."" a lot of people have done research where they proved that if you have the word ""novel"" in the title for your project, it is 20-70 times more likely to win an award - so high school research is about flashiness not rigorousness of the actual research. but its not fair to make generalizations either because there are people who genuinely love what they do, like i do, and plan to pursue it in the future. another person on my team did something related to breast cancer and is flying out to india to synthesize some of the polymers that he created for his project. im doing something similar where im reaching out to companies with organic chemists that might be willing to help synthesize my inhibitors. research is research, and high school students should be doing it only if they love it, not if they dont.",r/machinelearning,Z0FBQUFBQm0yeGJtMkVCWGlVN0VVT2U4ZHZLbXJWWVRoZXg4amhwTE9xMHdPck83bW51WDZocGFtUC1vTTZZWUlSNGVHeC1rVXFJXzZGSDRhWWJtczBCR2IyUHo3WFh5eGc9PQ==
"Dont know about the former but the latter both rely on CUDA and, for all that Triton claims you don’t need to know CUDA, you definitely need to know enough of it to write efficient triton kernels.",r/machinelearning,Z0FBQUFBQm0yeGJtZU1sOEtuSFVsaHhzcVFfMlRJRmdfbF84ekM5SzY5aVZpdE5BTnd0bmtPelE1dno3TmkxOG5kRFNIekdVdnR4VVgxeVZxdkQ4eVhsS3BPX2pyU0RiLWc9PQ==
"Hey guys, need your help. which types of images could be better recognised using KAN approach? Do you have any ideas on it?",r/machinelearning,Z0FBQUFBQm0yeGJtbi1oeVJpSWRnUGY4VUJQNzJDSXlGNVNUSXRXRnpjN1djT0pIenViOXJra2NrLUpHakI3RFFGbFpEWjJnc0dOWlhST0hnWkk2Wk93X2hDR3R4ZEMtanc9PQ==
Got it,r/machinelearning,Z0FBQUFBQm0yeGJtUGV6RXhFN1pPQ0ZJc09kcWhXZE1YQnhMTEdmRUhYREtIZGhQYVhqUGgwN0VoMDFNbU5tNlp1UEhHb1hQT2JPb2ZkQXdNdjhjdjN6Q1lfM0tRY1hkRTJLV3h4ODlraGxySTNvWjc1U0czNE09
"Linear layers are learnable. So the n/w decides which pixel values contribute almost nothing to the prediction. Suppose it discards vital information, the loss will be high and n/w will learn to preserve it.",r/machinelearning,Z0FBQUFBQm0yeGJtb0pDSnVvZ2c3akR3ZWZqS2dpMjN5ZWlCVWE3dUtJWDAxd2hFWlE4MUhqWXFOYUdZZ2hjbHBobkc1cTlFZDJVcldhTmFqYkNPMjZ3VW1FMUFzLThYdmc9PQ==
Appendix includes an implementation!,r/machinelearning,Z0FBQUFBQm0yeGJtcHB0aUJSSk8wYm5KaktPVk5qWVBPOWpxX3RvNmpZdHpWNTVpbkIxejQzN2lkVl94V1BPUjJLN3NMU0pjUWd3NDQybXduT0swQ0xMdjIwSWVSeGxibFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtdWw0VWJneVhhdmFUWW1zOHZKSGlWQ3ZTcDVMN0RVOTlpR3RSSnhSTWtubUJvS0ZBdzVzWC1Gb2NPakVjbzhqNnVNU2FJZl9yRWNHVktXVkFDV3lmSGc9PQ==
"**IN JANUARY**, the Alberta Party, a centrist provincial party, posted a video on its official Instagram account. The since deleted video, which is still available on their [Twitter feed](https://twitter.com/AlbertaParty/status/1618644534682083328?s=20), was of a man in a blue sweater facing the camera, with the Calgary skyline behind him. But something about him was off. “Does Alberta need a third political party? It depends on whether or not you’re happy with your current choices,” the man stated flatly, before suggesting Albertans seek “another option” on election day. His mouth didn’t form vowels properly. His face was strangely unmoving. And then there was his voice—it didn’t sound fully human.

That’s because it wasn’t. The video was [AI](https://thewalrus.ca/tag/artificial-intelligence/) generated. In a since deleted post, the Alberta Party clarified that “the face is an AI, but the words were written by a real person.” It was an unsettling episode, not unlike one from the hit techno-dystopian series _Black Mirror_ in which a blue animated bear, Waldo, voiced by a comedian, runs as an anti-establishment candidate in a UK by-election.",r/machinelearning,Z0FBQUFBQm0yeGJtZkJXeDdJTll3SGRYQUtTUTc5U1dKNnFLVGx5RlRycmt2RE90ckE3bkdNYW11NTE1OHEzWUFZVlF2RzlHOGhPaXJpWlZKbS1ZMzVtOTJWYlBaall0WlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtQmlYRTRlUDBVVElvVTd1dUdieWtHekktRkxVaXZ4RTR5cjJvb3VwRExRMXNoZ3F0dzA0c2JTYzQ5eEpmMGQyUWVUOTdGUnMtRFpwdlZ5QU1RZlV0R1E9PQ==
I recognize this from Yann Lecun’s tweet to Elon,r/machinelearning,Z0FBQUFBQm0yeGJtUVQ3ekFLUXZGVWUxNUFFOHBNczVPZ1J4UkI4V1UwN3VLa050eFNHRVRaWklvbEpycnZ3eExTcUQxZXoxVUlJc1poUkpvSnVNYURqQmoxQncwTUQ3OEE9PQ==
"Rust for ML? You've got to be kidding me. 

@OP: Probably Julia if you want to be part of the cool kids",r/machinelearning,Z0FBQUFBQm0yeGJtZGdHUlIzVXJxM2NXdEFYenRTNGoyMjZNUm9hUUlOdmpDT3FiU2d1dy1IbGlqR0VIYzE0MHl6eVZETXdWN0tlSm55a1ExR0VJaTZOVzZzYThrZllPTGc9PQ==
thank you for this. it's looking more and more like this is the direction that language models will need to head in order to solve issues with accurate responses.,r/machinelearning,Z0FBQUFBQm0yeGJteS00dHV4ak9MNWhLNjA0VWQ0c21YZEZIcVB1dUgwSkVaNThxZWJ5ZzJNaS1FalRCMllCaGZsbVVRWm5tSDQ5cTJoNzRhMVpDVEhwV3RFNGhJWGtQa0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtZm03LVZHWlVYaEhBTDFGY2JmU1F6SU9CR3pXSlk5YzhpMUJLMmtJOGNlUVpDVjR5OUc5Y0Vja1AwVFhhYUIxQnlIZi1DZFJDZE80X1g1Ym02QUtCTVE9PQ==
This is a good paper,r/machinelearning,Z0FBQUFBQm0yeGJta2VsQ1l3Z3p2QVlSd1h5eGFsQ3NVODl4dXRac1pyVDFOcEtUWnBTRldvX1FMVGZOdkJOZTh3d2JrRUJfd3ZEdGdkVHZ2NWJWZ19wQ3J2TUlpVDAtWjJPRmYzOGR2WjRPamtRTHJPeVdvZWM9
Whatever allows you to program CUDA kernels,r/machinelearning,Z0FBQUFBQm0yeGJtSVgzTWRPRHVUSHdMVnJOaDhRNGNzMnFHUUpxQU8tMXJwdXlHcXplTk1PZTQ5eC1xY0pBdmhXQllSRHhqbWJZWk9Nem9uMGlYUjc4ektRX2V6bm95VWc9PQ==
"This is an excellent paper that highlights the potential of context-aware positional encoding, and it is definitely good science (wink\\*). Not to steal its thunder, but it looks like one core of its implementation is duplicated indices: an idea explored in T5, [ReRoPE](https://github.com/bojone/rerope) (from the author of RoPE himself), [LongLM/SelfExtend](https://arxiv.org/abs/2401.01325), and [iRPE](https://arxiv.org/pdf/2107.14222) if we also count CV.

While these methods are usually aimed at a different problem (long context capability) and they are not context-aware like CoPE does, I would really like to see them cited, discussed, and maybe even compared — both on the tasks that CoPE currently evaluates and on long context tasks like LongBench; I bet CoPE will also work pretty well there.

Disclaimer: I do know the authors of some mentioned works pretty well though so I might be biased.",r/machinelearning,Z0FBQUFBQm0yeGJtN2lwSndqMkZ3YlRlcC1wT1ZGeEtZWnN2d09nbnNyRjd0WUtQZ2ktbzNWUnJBdHZTUFlLay1Uc2RPckdhaTZ4MjJ1bkMtZl9qRzNmMXZZdGdMNXk3RGc9PQ==
"Not 2 weeks old maybe, but still totally new, you're right.",r/machinelearning,Z0FBQUFBQm0yeGJtSGhWc1lnbW96Uzh0cnA2THVTbWJLZ19lTXFjaGp4VWxnRE9qeVFtSTM0dTJiTHJIUFpuOFl5RGtSNkl6Z2RjOUZPTzUwYU52OTNremJzSGdHc3hLdkE9PQ==
Thats to be expected tho right? seems to me that goes without saying.  The op's original question is pretty simple and the answer is definitely not no.,r/machinelearning,Z0FBQUFBQm0yeGJteHdRY2x1R25lVzdiQWk1aWdIOTRMRVo3Z2JhT2NPNVp3Vk96SmhRT0xBVEduODJMQ3hBNnlQcTdUNHR6QTUyMVhYeWxZZWZ1YnVpME9fUEFGZ0xVeGc9PQ==
"For reference, here’s the project I’m working on: CognitionsJobs.com",r/machinelearning,Z0FBQUFBQm0yeGJtUFlyeEFySVZxVGoydS1pRjU2emgyLW0tSjd6M1QzRzlwcWZSSndHYVRCME9RQVYzQzh2aFVBS1lJbkVuYXd3VTBTM3Azb0JrT1JQdTczUEZlaVM2d3c9PQ==
"I don’t understand the question. I assume you want to use Jupyter with a GPU local to your device?

In that case follow the instructions here:  
https://pytorch.org/get-started/locally/  

to install CUDA with Torch locally. (preferably into a conda or venv environment)

When you have the environment set up, make sure to add it to the kernel list for your Jupyter setup.

Then you can instantiate a notebook using that kernel.",r/machinelearning,Z0FBQUFBQm0yeGJtSXBzcEhvYUJzSFJYX0JuSEt0cnpRY3Q0U3AxYWpaOFo5LUo1MUttVUtpUHNqeWdWSk85Smpac0RoUmRIQWlaWndZb1lZWFNNMk5RelM5NlVvazVNVGxwMDA5Wk9rQ1BVWDlQSTZpaGFUOGc9
"I would say absolutely yes, but we are still years, if not decades or more, away from seeing its results. The issue with the human brain is that so far we heavily assume how it processes information. It has a ton of different inputs (audio, visual, tactile, olfactory, gustatory, hormonal etc) which can't so easily be mapped to a human body. We know in general how these affect us, but you cant precisely say that after you ate an apple, this set of nerves triggered these which released this hormone in this amount and this % of that hormone went to this different subset of the brain.

The more you think about it, the more you realize why the human brain isn't stupid compared to these machine learning algorithms, it just processes tons of information in different ways, being fit for millions of different tasks. If it was focused on a single algorithm, it would (i assume) likely beat any computer we can develop fit for that task for the next several centuries, if not millennia.

The brain gave a good basis for deep learning, and deep learning afterwards took a path that slowly deviated from the original concepts. However, any discovery on the human brain has a potential to be a hit or miss for a new algorithm.

In a sense, to map a human brain would require to map the whole human body as well, or at least most of it, down to every cell. And even then, you encounter the issue that every human body is different to some extent.

If you want to learn more about this, look into cognitive science and cognitive computing",r/machinelearning,Z0FBQUFBQm0yeGJtcUhlQjZGRlVhWWo2aDNLUDRUYXJ6MU1qSVBTRXV4UWVmNkl1MkFOd3c0b1IxdVZ3b3dYcjBYeXdaQlZQbFoxdExKYnZKTHNodFlyVFdtY0tEQ0lGVVE9PQ==
"Yes but I am using the jupyter extension in the vscode. I am not using jupyter directly,I am using the vscode for  jupyter extension.",r/machinelearning,Z0FBQUFBQm0yeGJtZnJIM0NKVVZRNHRhYmVhbi1ZSy00VkNGc2RUbGs0ODhrY0t1bVFPamFzNXFFRXAtTTdLRVAwbm5wa2FMb2o0RGZRZWk2ZjJ0bzhhVzNrOHVYaHFGc1E9PQ==
"I haven't tried it myself, but torch.compile can generate Triton kernels, so perhaps that requires less knowledge to get good performance?

I wasn't talking about avoiding CUDA - just about higher level alternatives to run code on the GPU as opposed to writing CUDA kernels yourself. Another one is SYCL, but doesn't seem to be very popular among ML people.",r/machinelearning,Z0FBQUFBQm0yeGJtUVBPR212a3NjNnZUM1o5ZXZXenByLWhqYXlBMlpMWHcyX084azBnd1BYamVtdkhVemM1cmI2VkV1MWh4SWZTRE5HTE5jS1BxS1hUbmJKcWxaZ2tPSnc9PQ==
"I guess it depends on what you are looking for. If you want pure C++ wrapping, then Nanobind should be more minimalist. However, I actually learned to enjoy just writing a lot of code as Cython extensions and only write very critical parts in C/C++, where I want to keep API overhead at an absolute minimum",r/machinelearning,Z0FBQUFBQm0yeGJtYVFZd1JNdy1WS2VCNHh1YjYyLUxubG45WkpYSGp6YUF0TWFCdTd3YUlKTzZ5eWdHdnFUQUhOd29hOW44MWxvVXFmQmlrRENuUVBxcWtqRGhsRnZuUnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtVHlLYkNOdzh1ZXNoNGE5dy1Qa2xIY1huam9mLWhQNUJFODNwX20wVl92S2NVUG1FYUQzb0EzOEVxYlIwVFpGZWJRek5zS0Z2alhxUkVNdWRhd3gtRFE9PQ==
Same rules apply; Set the kernel in VSCode,r/machinelearning,Z0FBQUFBQm0yeGJtSzRDVmpfSmFYa21iUlVmbVUwcmFyV0FvbklMU0l1elF5RHdySkl2WktpdDJXWmk5V1hKY0E3ZjVFUC1UNXk0U3M3TE5oWHJKMWhFLVZJS1JpZU13T0lYX3FGeG5ucW9Uc1FETm9vblpEbUU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtM3ZkUVRQelBvYWVvM242UjBldUhVRmtHczVOcVAtbC1fUEFieFN4S0RudjNuVmVZZEdnek9JOTFnWENmT1IzeVR5V2ZxazM2RWlnOXdDU0lVVkVtVUE9PQ==
Nouswise: it gives you answers from your papers with citations,r/machinelearning,Z0FBQUFBQm0yeGJtMzA2NVhKVHlObHhIdTkwOFVMX1dod0gwNDRqUWtnR1E1Y0h1U1V4S0Z1cUo0aHFmMDZmTjdEbmJCZGVRbkwxZF9CbDBxRXQzOVFvcGRFZHkwQzZiYlE9PQ==
"with all do respect to the language, java is nowhere near as fast as C++ can get",r/machinelearning,Z0FBQUFBQm0yeGJtdzJJTzg2NVFwdERHS0ppdGpvVk1XT1lUYlN4N0VfY3ZvQVhPdFJDdklYWEVvUTFTX01FcGtEVkVBVzl0STdOR0NXNU92QWg4NjZldXhLQkZCNkNjOGc9PQ==
This post is using the same format as chatgpt output,r/machinelearning,Z0FBQUFBQm0yeGJtalJJSXd0d056UmRfR3ZGWUNSek1tNWVvQU1sSEY0N2xLZUpzVnpZbzRPSjlubVpORUhWd3hNTllyX2U0RXUxNzFsM0FRVjFNNnFSMk53aElFbVFmS0E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJtQ3F2cURDQm4xTi10U3VBSlZ1alZZMUp2eTctUlZ2WTNITklEdFV6djVNeldjQ2RCaW9lYllpYmFXWXRTYWw2YXRPdWtPT2ViV0RrZElKYjV2M3ZNeWhkS2VhUWI0WV82a2M5dnkycEdVWEU9
"So I should look into classification models instead?

Also I thought MAE and MSE were more for regressions?",r/machinelearning,Z0FBQUFBQm0yeGJtSDE0emZYYkZpeHlNUTNRaUFjQk1XNGZsX3IyR1hGeFVvb2FURkxuMEU4SEZBcFlXUkhGZTN0Y25nV1Q4ZTd6WG81NVVRX2NDdV9BaFgweXU0YjN6T2lMbnYzZFRDUDV0bUVaOUlDbkdGX1k9
WatchMojo is running out of pop culture content so perhaps they're digging into more specific niches for top 10 lists.,r/machinelearning,Z0FBQUFBQm0yeGJtVlk1LXRYOVk5dlJxbGozUGtYb0VHT0g1N05LbWd2YXhoYWszZEN1d1N1Z1g0dUtPNGQxVTROcEg1OUMzSWxIU1FiRzZNQVVUMEFwdzJsTXFtTWtpZlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtS1ZIU0h6elY3ZDZGRmlUQ1JzeEx5R0hzcVFoWUV0b2hFQUVoWmJvV0tMUm1iUktmTGZzcktWS2hQYzFwWFRxOU1sWlBxbVVvSzNIWHc5NXprZnk3ZUE9PQ==
No longer “rapidly” growing is not same as “dying” language,r/machinelearning,Z0FBQUFBQm0yeGJtMHpac19WRDhTS0RWcTdDbkI5QTRFdGVERUZNWjA1VnVrRTFMc181dFl3cnZHUm5zRi1vTE1ObUd3TDkwYl81dHNuMW5TbnlkSjFENDhKbm0yaVBUWFE9PQ==
How do you define a good transaction?,r/machinelearning,Z0FBQUFBQm0yeGJtYlJ1Ylo5SzRYaFdiYWswdDJMemtsVUF6a1BYWVplYWVoNmJmeWZxQ2xpWXFTbmpGWTlZSlZoVDhZRkhmanVZNHhpMFRIUkNNM1hNc1VLUEhuRWtNNXc9PQ==
It's always suspicious when they cherry pick comparisons - if that's what happened,r/machinelearning,Z0FBQUFBQm0yeGJtUVFZd3pTX0l6XzQzeVZEZHNLLTkwS2pxTndhUExxZlRxb2xHd1hjT29yaGpuX1laSXp4WkQwTTc4dlRPdFJuOUNMOHhXUmhpbEJRNVV2cmlyNE1VM09FdEZnby1lalBKMmw4eGJuQmNJMHM9
"Better than python lol. Also some benchmarks place it pretty close to c++. Java is also way more secure than Django. 

I went through a presentation by Los alamos researcher and they were making a case for Java as an alternative for python. The good thing is you already have lots of Java devs who can get the devops part right.",r/machinelearning,Z0FBQUFBQm0yeGJtS0VGN3hsUFlzeVJCVGs4cXNYX1BEY3RELUN5anREYUlVVGs5Q19HcWRKZ282eHQ0aUNGQTFsa1NDRlFGNEp4MzU0XzE5VEFMSEZlbXhVNV9YdWROckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtdGlveW5QQk9FTEc5cFJRWkI0RVk1NmhlTVg1TTc1YWFOLUpJLVpOcTJIN1o1Y2RGSmpOM3ZkdDdiamVGekhzX0lOMi1ZRkFOVTRRa2FKUlI1N0VHbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtMkFPc1dTRldHRzlaUUtIVkpSN2ZtamhlTEdkbm1ZVi1QV3VOVHl3Wjd3aEhHNG5SVDNmQXhNYzBla0x3eERrY05IdHhzaTU4Vmo4akhUNW94TWtzeHc9PQ==
"What are some scenarios where you’ve needed to write CUDA? I’ve done a bit of CUDA in previous non ML (scientific) roles, but haven’t since. Now as an MLE, I’ve never had to get that low level in the multiples roles I’ve worked in. Maybe a bespoke PyTorch model here and there, but that’s it.",r/machinelearning,Z0FBQUFBQm0yeGJtWllnOUlmaTNOdjZ6NWlYRnVtM191RG13T01iUC1pWWhSUXpWc1RDcFFIRVFDY2ZMQVlubUpRSlJuNl9HdEo1dDVFTHFrYkVROWxHTnNPTy1FaEh1dU8tM096YWRZRXlKa0lWTE9vTndpU0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtMHppZ0paOVhqaThtZlVhdlhETG5BVWZYYm9zOHZHOVExWEVMRVhFd3NTamd3VFZ5WVR2Y01jZEJ0d0FfQTY1VmVhdl9QV1pYWGRDWldWTlBTb0VBVGc9PQ==
"I just saw your comment. One of the paper had one reviewer which gave borderline reject since we did not compare to one baseline. The code was not publicly available and the corresponding authors did not reply to our emails. 

The other rejection was incredibly ridiculous, it had three accepts and got rejected for not mentioning a related work from 2005 which no reviewer mentioned and was not really related.",r/machinelearning,Z0FBQUFBQm0yeGJtallQaWVTVEJ1X2U2TFRXRXBNZXR6T2JxSnJidmNPY3dTUzNUM09TRC0yc1RjM3Z1N0RhSEVuXzVPckRkR0p5THVBYTRQSjNxMXNCcU9saW9QcFJXTFE9PQ==
"Sorry to hear these. Unfortunately, these are the drawbacks of the conference review system.",r/machinelearning,Z0FBQUFBQm0yeGJtWm9GMjltSkxYSG9ZYjdHNVlqYktobk1WcmtJOXhsTHBWcEpieDl1ZzJUSFpsSHZXLTlWdFFNa0phWkQ3YnhWclJRVGEyLU5uUTl5UWFvT3B4MmJmc3c9PQ==
Why would you compare to human predictions? Why not backtest and compare to the actual true data?,r/machinelearning,Z0FBQUFBQm0yeGJtWHRkS2pILVlvS1pfZUtHbjVDUDMtX1Vqb0RrQ1ViTTJ6QkdYNjVHdnFvbnp1eTAyMEZDWFdZUng2cVNSdWtLZUt0ajdyaHRQaGNHZ1JTQ3AtdUVwUGJmS1VhTUltU2YxTVc3blZMUXlBRGs9
"I’ll respond to this in two parts: for most researchers, you can probably get away with the bare minimum approach which is understanding how gpus handle memory and perform ML operations. This will help you train models and understand how to debug them.

However, in order for any new approach to be adopted and be scaled up, like a new attention mechanism, like flash attention, or variation of convolution, or the newly released mamba, various scan operations that are used in things like Griffin from DM, they need to absolutely have a CUDA implementation. Otherwise there is simply no reason for anyone else to adopt them since people are interested in building models in practice (hence why FlashAttention) is so popular.",r/machinelearning,Z0FBQUFBQm0yeGJtbnB6dDQ0c1NFX1BmMmVIZ2o0ZzVlcHdVUmoyMmJ6a09jUUcyT3Qyekt5eW5iSnBCZFE2TDBDcW4tTExmNVl3NjhZWnhIU2JjdnNaN2pHTHRZWnQ0ZWc9PQ==
"First and foremost, this is a good candidate post for r/learnmachinelearning

Ok, with that out of the way… what ChatGPT designed is a network able to overfit the data. Overfitting is the phenomenon where a model (in this case your neural network) learns the data it was trained on ""by heart"", meaning that it does a perfect job with it…

… But that does not mean that it is a perfect model; not even close. The moment you put the model to predict a new, different observation from what it was present in the training data, results become way worse.

You can imagine your model as a little kid trying to learn to add numbers together. You show the kid that 2+2=4 and that 3+2=5 many, many times. Therefore, the kid learns perfectly those additions. However, due to either the data, the kid itself or the training technique, the kid just ""knows by heart"" those two additions, but without understanding the underlying logic behind addition.

Therefore, the moment you give the kid a new addition to compute, it will fail miserably. And the same will happen to your model.

To fix this, you can learn about model validation and testing. Good luck!",r/machinelearning,Z0FBQUFBQm0yeGJtVEp2OVQtYTN5c0VwR0xfS2xFTzJqX2cyNmFHZTJMdlI1cmw2OFVxR2hZRzJ1bWlMdXliT1E2elJ2TVlCSkpoNmRPbDYtLUR2UVJaXzBFNlc1NUJxc2c9PQ==
"Yes, it was pretty disappointing. It’s just so annoying to do resubmissions instead of focusing on something new",r/machinelearning,Z0FBQUFBQm0yeGJtT09YWVE0N3Fyc0EzSGF3eUVYeXVqU083S0lrbGpkcXVZRWU5dk80Vk9lSG1EZklQX09YSDhwSXBSR0prU3QtVkl0NnA3aFhFTFlSU3RnT0Z3cnBrSFE9PQ==
"This is insignificant. You can almost trivially get 100% on smaller datasets (MNIST is basically the smallest dataset of interest) by overtraining on an overparametrised network. That's why you have separate testing and training sets: see overfitting. 100% also shouldn't be the result of a good MNIST classifier [since it has wrong labels for some digits](https://www.researchgate.net/figure/Label-errors-of-the-original-MNIST-train-dataset-identified-algorithmically-with-CL_fig6_337005918), so should stop at 99.8 or something. ",r/machinelearning,Z0FBQUFBQm0yeGJtejVQWXEtZGVJbXJHODhUX2ZVWUxhTEI4a0kyaFg3RWxfcHJidTVIVUJtX2lNQXhLSHVuc0t3eWdhUGVZb1dSTlpRU2VOVHBMamo5U0pubXlzZmYwbGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtU0tOaWR2NmxzZTNDYzNhMmZVbHRIa1ZHMjFHdkc4NnRfSnFGbHBkNktuby1LVWNfNWdzd3B5eF9HNE5lWXNOcWtjVElwcXotQXkxUWhqb3oxNmdGV2c9PQ==
There are model architectures that cannot be assembled using the normal tensor operators that mainstream kernels provide. An example is torch.scatter.,r/machinelearning,Z0FBQUFBQm0yeGJteUhkQTk2Y0tpMUM5Z0c0dGltdTRndDVMYVRhcTdBOEM2Z1NsNUZNemZLeDM1Ykx6SEgtLUR1bGhEQWZDX1k5c1I5R1NWN0RJc1BSZnJIQWFTWFJwY3c9PQ==
">provide alternatives for performance critical use cases

Not sure why you feel the need to focus on the language if you interested in optimizations. Since we are talking about kernels, the issues around hardware (GPU + CPU) are way more complicated anyway, and language is hardly the biggest concern in the space.",r/machinelearning,Z0FBQUFBQm0yeGJtUWNQaGQtaWpYTjFwZ2tlcDB6UUFiOVlENlFvM1pLSkt5N2ctV3pnd3JFMWxpcEVJU2VNVDFhQktFR2l6RXNfMHplSlZIcnVXUDZjdm1SOWRZQk5wY1E9PQ==
"Thanks for vocing out! **But no, I don't think CoPE cherry-picked the comparisons.** It is a bit toy on the model/data fronts, but that's perfectly fine for a fresh arxiv paper, and the authors are absolutely transparent on this with a delicate limitation section provided; kudos to that.

What I was trying to say is that **one aspect of CoPE's solution (duplicated position) is a mature idea for making long context-capable LLMs**, with a few explorations done already, but they are not discussed in the paper. **I believe it is highly likely that CoPE's authors just don't know works from long context folks have landed on the partially same solution as they do**: as T5 is not RoPE-based so they might have discounted that, ReRoPE is only a blog so unless you follow Jianlin Su (RoPE's first author) closely one can miss that too — in fact, if I am reading it right, the *relative-capped* baseline made in CoPE's Sec 5.4 looks damn close (if not exactly same) to the infinity ReRoPE variant mentioned in Jianlin's blog. SelfExtended might be more relevant, but it is still a very new paper (Jan 24).

I just feel like it would be nice to discuss those works and maybe try CoPE on the real long context tasks these works are focused on, because I envisioned it is likely to be very capable there too. CoPE has enough differences from those mentioned methods for being context-aware, and imo there is nothing wrong with focusing on the type of tasks they are focused on now.

Sorry if I confused you before, hope this clears things up.",r/machinelearning,Z0FBQUFBQm0yeGJtWDRPTmlhaldfbFUtRzRyeVVXZ0xfU25ITjd2aFB0OHQ2RkJoMlU5Y2F5WlA2VUxaaEpMWUZUU3piakZlbzRaUU5PcGJlRnhxdHZ1REM0VkYzRnhjRkE9PQ==
When you have that small of a market share it absolutely is,r/machinelearning,Z0FBQUFBQm0yeGJtOUNDeEoxU2djLVZWbnQzNlVkWTM4cUtZZmpXQ1ExM1NwdUt2dnd2eHQ0ampuRkZjalY4R3JpZHRtWC1IdE1YUkVrS2MtZGlxeGEyYTVDZk1rNVhkVnc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtU2xOTDFMY0t0TXZjSzdRREw5N18yenExYnB0S1VvOHZpVU8yY1ZlOFlIME9zekRCOXJpQWFNTkVzUWxNc09NZHZMaWJkN0w2UFk1UVU0NjBub1hTOU9seE9FeXE2cmR1MTZ0MzZVem85SkE9
This is just cope,r/machinelearning,Z0FBQUFBQm0yeGJtM1FONjlfMm1LbGMxcVpXQTFKY0U1b0lsSTRLd0VnNjFkUk01UmhGT3Y2ZmlqWFJXcS1FdTlBczNpYktvcUszZ29NUnpZSjRkbUdNXzQxaGhwamp3VnU4SldMT0VGa2lKWEVfMVhoTnhNcm89
"look mojo is the future

 \\[ clf= rocket emoji, 

clf = tree emoji for RF, 

clf = cat emoji for catboost, 

clf= rainbow for LGBM,

 i mean pytorch a flame.. its just endless\\]

it sells itself, we want emoji call functions",r/machinelearning,Z0FBQUFBQm0yeGJtaDVaek1WZjZiaW9LYzlacHZPLU1jUm1IWFB3QVFIcHV6NTRfUEVJX1ZBQUFvQlR0VlFJQlhpWGEyVEtnSXAzT3dyTG93UGkxdFdocUg5RS1MQ041LXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtNUhyLXB5LW5QTmtSWHROeUNlVFBjMWNSOFlEZEVlNDdPdnN0Q0VQaDBIS2RuQTBnRkEyQ0FqSkJvTVc5UFM5YmV2VnRUTTc0bHp2V2RfTXhFRE5oY3c9PQ==
"You can't do training with it.

It's cheap because it has no uses.",r/machinelearning,Z0FBQUFBQm0yeGJtT3RLQ1E1QUdWdXQyMFJGc2lLV3NnbC0tc25Scm9rZkNEX1hhTThPcFlBYlBuTVZBNVU0N29zVi1wWENibUVBemdGUy1GTEJKYUFYT19MUGRzOVVyaFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtcFI3Skc2OUhhYVlWM1BrOXprVFQ1VFRJLUdhNGRod2ZOM0hWeXVfLWx1VFoyLWhMNEhycXlFT1RPb0FwUUdyVjBHbHd0THNLX1Q3QmE1VXQzODNzYnc9PQ==
I like this paper. really clever idea. and I remember there’s some paper in the past which inserts discourse level special tokens to signify the hierarchy in the input.,r/machinelearning,Z0FBQUFBQm0yeGJtQWljR0tYTUs1aGpZaC1jTTdYNEQzODNVaVY3dU5yZjhnbVBNd0pRdEhjMnU2MXlOX04yakVzakFqOGlGcDJRamc2LUpTc1cyS0o0X1FudUF3bHJfR0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtSVZkZ0dkUi11RXFOeG1BU2tEMTNsR3FjdWV2QThWc0JMemh2QVk5YlNGNi1YT3J2RFZ1NXRyV09ucmZCRDBmQ3I2am9pTmpuN1B3eHBQeTAzQlNvWFE9PQ==
"10,000 hours. It takes both, learning new stuff and applying it. 

These posts always crack me up. People seem to think there's some kind of shortcut to time and work.",r/machinelearning,Z0FBQUFBQm0yeGJtUnV0R3lyVlBLZjFNd3MxS0xUcFY5QnM5WVFpZmp2aXBuSTZ5c3BPZ0k5ZExKQ0FfOVU5NkI4cmNzblROemNac3QxWGFjNVRSME9JYmp0N1oxdjBoQ3c9PQ==
Some form of graduate school + self teaching.,r/machinelearning,Z0FBQUFBQm0yeGJtMllmS01ESnRMRmJqWjFmY29wUXpUY25IYlVBNTh4bnlkTFVjUUEtck9tWUtDVExMazA2UDdtTHVHQkRZWjBJckxWZ1g2SzlTX0djWnNwZnpjbkVJMnVmV2FTVHNRTUswYk5vZjdDTjVEUjA9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtUXNuVFd5cUtVVnV0N08yUlQ2OUI3QTdIUkt6T1Y2YVFSbkxCbTZhWHZzNENheHdtSE56ckItc3NaWW1oazBHeHFEMXZrVTdid0tzdW13dUhielRNU1k5dURKcXhMOFlqM0k0Z1NVeFBUSzQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtU2ktanBzSUFXMEZ6ajJIMUxEcXdlRk5ST3VHTmRPMGtJMXY5MTNNYnpsZzdYZjduQ3BYQTNzak9lNldGZmRYMVl2U250RWhpcHN0Z0tNUV96V0I4MUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtMXRHMG1zQWM3X2lPYXpBV3dKaVJORUZ5a2ZhdTdvanE0bXhudE9INE9wODVIZjN6c3lIeFJGVVhQN3lpaGdJZUpvbHltZDd1TzVNOVltbW9mYkRVbEE9PQ==
"What are your takes on 1000 models trained in the same data set achieving a 100% score but all of those models having different validation scores (60-70%, which is between good and bad for the given task, being about 65% the threshold) (let's do not think on the scoring metric for now). My take: Since all are overfitting and parameters are different (1000 different models), results on unseen data will be different, of course, but the best performers on validation could have captured patterns in the data, and the worst performers may have captured more noise. Please let me know what your thoughts are.",r/machinelearning,Z0FBQUFBQm0yeGJtRk92SkZ5Slc3SGdtenROWFpKVW90cFJLWDNSZEtObzVrQlo3WjdMczh5WHRtc3hCMzlOa2R5cWFmSDlQLTBwMHpoc0RfZUhLQjkyaWl3aGg2SDNNMTJrUGRnOHZHWEpPQ1ZPVm43ZlcyXzA9
"All good, that makes sense",r/machinelearning,Z0FBQUFBQm0yeGJtUXd5U0RiRnpBdTRpbEpaYkZNaC10MVlCX1Bld2s0ejI0SXJRa3VMRUJlUmI4eWVpRUtRSndPb1RYQWZJV2xwN0RkNXBtUzhzeW5RekhNSkFEc3hpaHVWblJBYzFFaXE0S1ExNVFhU2dPYlE9
"I don't think RL has taken a backseat; most LLMs use RL at some point, and RL is set for solving different problems that supervised or unsupervised learning aims to (with overlaps, of course). From my perspective, in a future agentic world, RL will have more and more weight. I don't know if it is too slow for some applications now (I believe it is), but its use cases are fantastic. I personally want to learn more RF to apply it to quant finance, where I am pretty sure I can find interesting results compared to supervised and non-supervised. Finally, I believe it has many applications in simulations, agents, video games, etc. I don't see RL having a backseat to supervised or unsupervised learning algos, it is just a complement. If your advisor told you that it is better to use RL for your thesis project, it might also be the case that it is the best way to achieve results, so you see, it is still as important as it has always been.",r/machinelearning,Z0FBQUFBQm0yeGJtejdMU0lQQ0JCN2lhNXZaUVY1aUlmLTlZZFpPaDI3MDhwWFN6WE45UC05NWJYdGJSZkZaYXMyOWxpbGlDOXYtNlQ0SldtcmE2MEVXeXVnNGUxUHg4SDhEZmwwTkZLOGo5UEZ3XzE2V19YTEU9
"C++. In the long term, it really doesn't matter which language you learn first. You can switch once you are familiar with low-level programming. The fastest and most productive way to learn ML-relavant low-level programming is with C++. It will also allow you to immediately do cool stuff like understand/improve llm.c, custom layers like flash attention, writing your own CUDA kernels, etc. You can also look at CUDA mode lectures: [https://www.youtube.com/@CUDAMODE/videos](https://www.youtube.com/@CUDAMODE/videos)",r/machinelearning,Z0FBQUFBQm0yeGJtUDZhMkdnSERDLXVWMkRpZWhZNjFmVF9GMTJmU09mTGhuZm1aVFV2SUdJbVA3NnNKeUNwd2dhUnhJR2hqaXd3WWx4ZUJaSEdGdGEtQTVOd0w5TEtlemc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtRlhITDFncFd2ZklEVXVGN2JPQmxYdGhvZmY4S2RJb3djQXA5TmZMd091aElZRVhMXzlZeU95UjZPRW9Jc3FmbExZS2tybXZ4ZTFZX1JiYWJtcW9IWHc9PQ==
"I didn't know RL was was used in LLMs..haven't explored them yet..and my professor didn't recommend RL..I was rhe one to push for it because I wanted to learn it...

RL in quant finance is really used to simulate the real world..I like rhe Multi-Agent systems for finance applications, as they help emulate capture reactions of other agents..probably look into Assynchonous Actor-Critic method.",r/machinelearning,Z0FBQUFBQm0yeGJtNzdITVFhSEh3Zi1QODZSUzVtT1V0alpBcUJ3cXp6V0FDdWFHbUtrZktEZlBDeUNsTHk1dXFVUVB3ZGxORk12amcyWGdJMHpGSVJLazRWcEVqb0hrMmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtUmdYSVBYMW5CZWNuQVVCR1pFZWIzbkJXN3h3VURyOWJTc1FHcUd3MDVxQTZRdlFZLUdoTVJCS2p1cnpFQjRwTzM4Ul8yVmpDNU9UZ0dRNE1DTl83WVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtSnZaRjV1QnM1dUd3UjlPMXNIZGR1RkpOLWR4VHhQY0tjVjZCWTBfWldscm1mX1BNMDJjNUhKYmlPUkg1N0xJbjN4dEJYZVRqM3c1MU9tX01EVnM5R2c9PQ==
Nested ifs.,r/machinelearning,Z0FBQUFBQm0yeGJtbElQZUJRU0xKdlN5TDJtbUxua3Z4dTJZeVhmNk9fSHNKZWx3dkxxdGNwWWp2ZGRyRktZVjN2MVgwLWhabzh5Y3JsckZfOU9FVExXQUJ4azl3WFlDcFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtMVMwSVFGM3hRZHdYTTVJZVNYMldhTTNkVXljeWh0Y3ZGZkFGdnpHMHU5ZFFHUW54d0pLanJCN24tUzM3SUlPaDlCN3VTRTdsUDloZHlFeTZVRFhiMEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJtWXR1ZDh5Z1MxLTAycHR0Ylk5WkV4S1VyV1psUF9YZXVZQzU1SmZqR2ptbFctSngyb01WOERmVEdSWDRwbE5PTnFvSndsXzFxQ3ZGdml5ZXRRMWhrbEE9PQ==
"I don't know much about rust, but I think extension languages like mojo or carbon would be more likely to pick up users.",r/machinelearning,Z0FBQUFBQm0yeGJtV1V4SHRSUHczTlUyT2JQeDEtdlVENTEwdm9ybXVmQVZMZDA1Vklod2czSGphWVN4dlVWWkVHYlBLcENvMXkzMFZxYXZrSFBrNWJNd1V6QTZEZXVGVFE9PQ==
try/except(pass) blocks on everything so your code never breaks,r/machinelearning,Z0FBQUFBQm0yeGJtcTBZTTRkRlBpUkJqU09Mb01OSFA5U3pMek1CNkRXUzl5T0hjZ2NieTNaUVBtVVY4ZEFhaGNHZ1Y3XzVfRzd5NEdyck0tZ0gtdFZjcDk1TnNUZUpXQlE9PQ==
after 6 years of python I am using now immutable data parallel paradigm,r/machinelearning,Z0FBQUFBQm0yeGJtblZUMGUycWhoUmdMdkltbEVLYXUzNEVuTHlaVWRlNlFlcWs3Ti0tX0F2cnMxSjlTZi1rUFFxemNqMWVVUTJ0YXdMM1RFWVNGaE5NbWJua3hCa3BqZ3c9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJtYWZzTnVDblMtYkRwT3lhRzJUY05TbWxTejJ3RGdZRGI2Z0ZZaDBMNnN3bUkyLUxnQ3pDRk5yeExCVGZHVnAwbzMyclRnUFp0OVlmTTlybjIxWTZYTk0tb1J5SXY3NGFqZFYtTGNzYTYwUHM9
"Ok i think i know what you're asking given where you are in your learning journey.

Don't worry about functional programming for now, you'll double back to it in about 3-5 years on the job, so don't worry there. Its important to start with the basics of OO and then you'll be able to intuit what functional programming solves and when to use either given the problem you're solving.

Spend your time building standard programs with a main function, that calls into an application class (singleton) to start up the rest of your program structure. Practice OO design, being able to map the business domain into OO concepts is what you should be doing at the moment.

While its difficult to keep all the design principles straight in your head while learning (solid, yagni, dry) here are the ones i would keep in mind at this early stage:

- you arent going to need it
- don't repeat yourself
- sketch class hierarchy on paper first",r/machinelearning,Z0FBQUFBQm0yeGJtVDVtOTkxRXRIWTVEQVM3T3FHZW9tRGNlT2Rna211MERSNGtMTk1NaUxPdW41NGN5OVdCWm9OWk4tNXBScFJVTXhoY0RnV1BRVTFtVnNHb1BScFF0QXc9PQ==
"I mean, released [May 16th](https://x.com/VictorTaelin/status/1791213162525524076), so 2 weeks and 2 days old",r/machinelearning,Z0FBQUFBQm0yeGJtdnl5UExjT2hsQlY5VktxX1ZLNC1iT1V4eTFCa1pBWV9xTlJlZkM4TnhacDgwU0pLcDZrZXNlZm13QlRJWmxUYlpxOTVUVDJpZ09xT3ZLRXBJYmNLUlE9PQ==
I can’t with the title 😅,r/machinelearning,Z0FBQUFBQm0yeGJtM2ZfRVozU1JFR243T3E0enJhUDg4akdyLURCV0ZxVExmWDl1a0dSSkY1bGtfcjdtOHpZRUlxamczZDF2STVCSUlyTFRaR2xESzJiSTZUUzJhU2VVUGhMZHlHTHE0ZVNQbEtHUzhHaURZRWM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJubjdQSWY0T3BzbkhRUGhYNVZ4bG4yZkRTZWFyaE43YjVVMXFhYkNvR0YyTF81QXJZQ1FremZWNVc2b0wwejdEdWpuQkZySnlDRDNMRmIxX3V0OVltS2c9PQ==
can you expand on the \\*integrating agents into existing tools\\*? which tools are you referring to here?,r/machinelearning,Z0FBQUFBQm0yeGJuRm1jYVZndnZldUxlLWdCVGdWd0tXTHhMeXlmY0Y4bVBXSjlzbzA0a3BMUGdiNGxfUGNqR0U0ZWJyVlRuUy1za3B4UE1xdE9lVzR0UXNFRHhlVThUUjExa3RXRk1zbHZzV1hLaTdGYWxJRE09
"Java is not an alternative to Python. When people need to get somewhere they use regular car, not a tank or a tractor.",r/machinelearning,Z0FBQUFBQm0yeGJuY01HZ0pRYWZiMndMQjRENjhwUTBvX2toZHNVUXZXMUNUWXRXZjcxZkNZaXNZVXVXeHlGOXpkTTJnQm1kMzVqNGR5Ylp1S19qV0pJeVdSb1JMWm9hUnRQVVRqZ0xiNmRhZnhUU1haaTlBSDA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuWlZ5cm9jN3laRDhrdm1sOXZrSVFZbUhYTmNjMnMxRXdJcXRBQWNudElHZ3djVlg3SkFyZmJSVUxZOXY4T3FfSVVHbGJwdkdSem5DeHVWaFRsWk9aeUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuRFA1bmJmenZLSDNScXpxdVpReGRnQXFrVHdLanZaSGtEOF9zV2E2dW5FaEd2WHdzb2dNX0pmRDZ5Y0RWWkN6cVN2RXo5VEJmdTJMQ3NBTnZaQnRNa2c9PQ==
"I think their end goal is open source but want a small team focus to start the initial building. That way they can move fast and stay organized, then get some community buy in for the long term",r/machinelearning,Z0FBQUFBQm0yeGJud0tLMDBrV0ZSaUtVbG5vWmx2RE9LWjkzbHpuLW85NTFSOVRWTnFELThaMzcwTFQ3LTJBUlpfLTF2QWtzUW1HeExtWGU1amh6blplZ0lJdVpUUkVFc0E9PQ==
"Yes, but I' not responding to OP. I'm responding to you.",r/machinelearning,Z0FBQUFBQm0yeGJuYWh4aFNMeVhuS1hrUWp5RFdNaFZUZE9Gc0tFYWhiMnQtSkdGaTB3b05wTnR2M3lPVHpScldUZzlmRDVKUExZQjNHUGpCc0hhTVZteFpRbmZlYXRKTlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuYXFUUzVHUDNEZGhXN0JwYW1SdWJLekNEWXhld2k0cEZmT3otWWNWX2locS1vWTNqamdNNEZOd01BZkZIaHhCM2Z2YXRHXzk5SlN6OVNnNW1UMWV6b2c9PQ==
"that’s really intuitive, thanks for sharing!",r/machinelearning,Z0FBQUFBQm0yeGJuNS02UE5uT0EwekJEcllFel9yNy1OXzJUd0ZuR1p1YWJTZUdQWENmdG5DSUJ0cFFqTWFQZ2w0YzZVR2twb0wtVjVKT1hsRXN4NnkzTTJIQmp6dVVOU3dYQ0tIc3JYM1RRVGRDSVJzZjB3Znc9
It's been standard practice since [as far back as T5](https://arxiv.org/pdf/1910.10683#page=12).,r/machinelearning,Z0FBQUFBQm0yeGJud0prS195S1pqcHAtOEdSWDN6Q05mNXNvV2tkUFBzdjU0OVVJdVVIMUdORTMxclR6ZnNaVTI5RW1OLU1RQ0VieFNsTzZjdWV4SmxhVms1RWJaVGJwcUE9PQ==
"For the sake of immigration, Google Metrics is sufficient to show the importance of the venues, including the conferences.",r/machinelearning,Z0FBQUFBQm0yeGJucmdlRzlHWkpKWmxRcHNXZ3RKQUpoalhoWWdqODFSX1Q2R1kzbEQ2eXFwWVA0ekEwOE1udV92ajJWNGlTT25CRkRDNTBvRVlOdjh0MnROaVJSaDhERXc9PQ==
Oral decisions are out on OpenReview! I was lucky enough to be selected :),r/machinelearning,Z0FBQUFBQm0yeGJuSlVvSTZIOUpXTlhnZ0dqdTBzZElOZXk4S0RqV3FZTmphcHp0R0NTbHZ4T0hEVEtWWllPSnllTmwwRF9yRzA3c2NyVkxCTU82cGpISUJpRG9XQW9EX0E9PQ==
"I mainly use LLMs for two purposes:

1) To get the information I'm looking for(QA) 
2) Extracting insights from ton of information I throw at them(Agentic RAG)",r/machinelearning,Z0FBQUFBQm0yeGJubktReTNMRnhTdFRnazRaWFN3dWdWeU1ZZnFiQWVvanl4VkRhMUlwU1EwbllYU25yTXJBMkM2b2xWMHVjalBQWUIxZTlYVWwwQWxhUUxuZENqdUI0TGc9PQ==
I think it would be fine so long as your evaluation includes a representative sample from all theee datasets.,r/machinelearning,Z0FBQUFBQm0yeGJuWEh0WU5waElvam1GWWR3SFpTQ3REa3RObTl1ZzBqX2FWenU5dG9QZGFtLTdTTjh3U0tUSTJyQUZJRGZQRVBLN3RDaTdIMlhKcW1jaHBoWkN4NmlFOVE9PQ==
"NeurIPS gets too many submissions. It's a way to filter out papers who didn't follow the directions. I guess the thinking is, if you didn't read the directions, then your paper might also have problems.",r/machinelearning,Z0FBQUFBQm0yeGJualNSX1NYUmpCRjVKS0pOX1hyNkJUbWpUc1JOR2ZTWFBUTF9ZdzVZTzRmNjNBZDlvQWgwYndCOHQtUHJEemxDTUtwZjdTbE9wSThYNmJsemF3MmJSV1E9PQ==
Following,r/machinelearning,Z0FBQUFBQm0yeGJucVNpQjdQV0lCUl9QNzJhVC1FRXY3REY0ejNDSlF1X3puUUhMNlE4a0Z3MzNvYm9VWXp5VHNBRFJaU0tlcmVqemh3b0NVT1RTdTZFems0WDVmeU1TemxaYjdjalViV00xVEg3UWRtaUR1N289
"“Data is King!”

“… Because that’s what computers do, they compute things.”",r/machinelearning,Z0FBQUFBQm0yeGJud29fTG9SdmdSU1NZWVJJaFdhOTZ0UmI5UmhKc0lYWE92b0JlM3hzSE8zSnB1SkZIdkZSSXlqekVxTlZjRXdna3ctbmxoeUFtc2s2X0llblZCSzRxX0FfaUNIbVNYb0Q2UDE3eUVYVmZ3R3c9
Java isnt that hard and its more of a proper programming language than python which was originally designed for scripting,r/machinelearning,Z0FBQUFBQm0yeGJubDhiTG5OWlVLYnQ0YTFjRmNtRU05TnZFcEdVcDV3UEZuNmNIRmktdjdidFRLUC1qaExJb3ZBejBiNXBUNUwtSTZZSVRDbUJkSWdYZGw4MWNucEUzQmc9PQ==
"Is there more than ""more linear transformations""? I haven't gone super in depth, but from what I'm seeing it seems pretty straightforward (no pun intended)",r/machinelearning,Z0FBQUFBQm0yeGJuMGFrdUhITDU3RW54YW1KWUl5TXh6Y2MybWVEcmNQbi1MVFNZSmo3WmtPdDMySmlWbXlzT1hDS0NRblg2VjZaWVpzWXdOLTF6ZVFJSEN2NGtTSTRUVFE9PQ==
"So newish

Novelty is king then?",r/machinelearning,Z0FBQUFBQm0yeGJuX3VvUHFzbl83MHBxaGE2V01vU01XRWlfTHBmRHhud2NFZHFCZVczX1pCV21BZ0w1Y09VemY3TWU4bzlqcFNIZEpwTmdTOXRrQVJwdi1KMk14R2JWaFlqNzhZSHpzMHh2djV3dS00SnI3ajQ9
Cooooool!!!!,r/machinelearning,Z0FBQUFBQm0yeGJuUTVXb1JxeS1hbXdwOVp1bkZWQnA1QXRuOGJ4ZEpKX3N6aE9HM3dNNW1Mbms1cWtCU0w4eDFDdC1YNkUwUi10LUhSem5KcmFIZjgtdERvZXdzREh3NXlWcHBBZDVQZFJYZlRUS3JiUC1oZGc9
"I would be especially interested in an investigation of how concepts appear/disappear depending on model size. Is there a threshold below which a concept does not appear to have dedicated features? Or does it depend on training volume?

Relatedly, can the technique be extended/applied to other architectures, such as vision tasks?",r/machinelearning,Z0FBQUFBQm0yeGJuOG5nNnZKRUFhWWswRjhVZ0UxYjJYTWRVemJ1WmItNnFkQmQ4bGpSWkI1M05WUHRQa3ZKcnJnTEpqYm9zUEdHUEZ6QjVCV2F0SEtQbzZhRXZWSUhmOXc9PQ==
"It's not about technical qualities, it's about convenience and simplicity. Java is good to build proper systems, Python is great to get small things done here and now.",r/machinelearning,Z0FBQUFBQm0yeGJuSUszaVQ0VUpYbU9UTWxDaVFkQ0ctdTlSTFlOOUVxZjA0aGJCWVFQbG5td2FzTFR4bl9pRWJ4cXFYN1V2NWxnNVlVSDRZZlFBeWp0MWY1YkFSejY0X3BCQlBtd1RpQjFxQ0xydnRwallQSXc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJua0JSYVJJcnRtTEg2UW5sWF9GMGRFS3R1SFFjWFhDNm8yZ0t2SmpDeWs4NTdGa1RmNktOM3JxRXVlVk8tNXd0R3Bma2VtR1ZMcmNHR2d2cnk2VjdQb0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuNWpneGdNeUlra0xPT3JNMnRTQnYyeWZtbzZ3R2RURXVDWHVzc0dDVVphU0pWdlFMVDNJdWZpd2JzNTc2MDhMcG00LXZOTEpRcDZqYVlKNjJkQ2NxUnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuRVRLU2pCZHlka0Z0NGhMcnFSR2VhSXRUQm9YTEdRb2VUbk5JTW9xTV9qMWNyaVBqeHliSFNsbnpYYlM5ZmJWaDZvdGV0RGNxUzBKZXgxd3hGb3FDNGc9PQ==
"After more than a year dedicating time and people to research use cases for LLMs, we gave up last month. Problems with reliability and lack of consumption by the rest of the company have been the most relevant factors to scrap everything.

We may recover the idea in the future, but we are done for now (I work in pharma industry). We use regular transformers, RNNs, GNNs and so for many projects and initiatives, but we gave up on LLM usage

Edit: fixed typo",r/machinelearning,Z0FBQUFBQm0yeGJuZVBsZFkzUDBBVGVGMHJuT0s4ekU1clRaRU1ram90OVdWQzkzVU1oWWFXRG9zWWV3OWlJZnFfb0JOSGNRamlEVjFEaUhXbHJJZm1iVzBMUEFQVmxNamc9PQ==
Thank you for reconsidering your judgements thats an admirable quality.  I too I have let some Reddit arguments spill into my replies and I can totally appreciate that.  Good luck with your research! I consider our minor disagreement settled.,r/machinelearning,Z0FBQUFBQm0yeGJucDNpdWlrUkhBWkgwNGliTkJYSVprX0tLMUFGRDVJR1kxVXZ0VlVfQThfbG1aNWVRd1hGdHh6VFVHTTF0QmFOYldoX25XX0VNNXhGVXNzQ0EyV3BNdGc9PQ==
"Yeah you sacrifice a lot for dumbing things down - pathetic OOP, poor security, GIL.",r/machinelearning,Z0FBQUFBQm0yeGJuV2VtZGFjcTFwaUdPbFUzVVJwTm5jVTlXZ1VaU2s2bW14bnIwY1N6enVGVV8yaUhnZTByMVdVWU9BWjB1c0ZjN3VrVVU1RXVVYnBzSXJHNFJrY3RoWWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuLVNheDB4eHF6SHhLaktjQmZGNk8zV25rSHBHeVVDb3QydmZxbngwc0ZNb3J0aVFjOG9NcmowV2V2dVRFV1lhcS03cHh6TllNVFROZC1GLVVLM1VwZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuTlVWZXF0UDhyMzg1Ykl1Vnd0Y3JFU1ZsMk14Z3dVMlhvNkdmQk9aRWZTM3pyRnVMM1RRbDZwVHhQRjV2WnpmZ1JJQV9Nb2JvbXZSLUlfdUdTMFZOZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuakU5eEdBLTJuYTlzVzVkQWI0Tk9sRmxZaHlOLWJEVm13TGZNZmhMcVZBcHpUU2xEWWdJVnpIN3BFekhZZTNVdjBWeGdnUFlocEJZNU5tRVJVa0llNEE9PQ==
"r/learnmachinelearning. Also, don't use any of those things on top of BERT. Just stick a 1-layer logistic regression there.",r/machinelearning,Z0FBQUFBQm0yeGJuS2NibHRjWnZUUHNVMk5pR2xaLTJPYWNJOXlyd1lzUTAwRlVmem5BRVJlWWVZemcwVjB2Z3k5NHZIMkwzLUdMekpwVThpcUtyc1JPbWdyZVhkbGtSenc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuN3FldnF2YUVuRTlRRWctZGRjUnB5OFhZNWZhLWdUS01KcmhoWF9jNjJOeWxOdU8ybWpzOHVjTWNGbDFuTUtERkRFNnI1YTFTbkZEQl9qdURlVFo0SkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuT2FBdWhhQ1d6bVFUYVFKa3h3NHg1UEZaWlZzd0pNeXRIalZhVXMxTFpnbGZVeXZRdUVadEE0Y3pLVV9xRFFzMkJ1T0xZQk93QnJERExHSUh2LUxmbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuRWNMS3dqaDItWTFLZFQtZzNObzdIeXNBeXNHd1J6WUl5Q3k3amlVRVR3aDJWVzVoeTVYN3NXUkRPSDMwQUhJSXNZS2F0S1E0OVhVM0FadUV0MmtER2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJubjJjRC1JUHhIVThlWjBOa3FnUnVPczYyN3l2YVpkeGs1TzMydlNfYzBlWFZNa3VSMlB2RzMtVnNTbldOdHB6c0FyWXROY1ppSXJaOEU5VDQxTncwVVE9PQ==
"I think it would inspire a lot more confidence with future collaborators if you read the Anthropic paper in full, because it answers your questions 1 and 2.

https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream

This is reference 55 in Scaling Monosemanticity, which is an open source sparse autoencoder that has been trained on GPT2-small, which is significantly smaller than llama/phi/mistral. They even implement a recreation of the Anthropic feature dashboard.

If you can identify the neuron, the clamping is trivial.",r/machinelearning,Z0FBQUFBQm0yeGJuSk9GYUJCQjNsQ0RaNlZ0UTZJc3ppcXhWOEtjakdhT01LMWlsOURaOFJxa3kzNW1uZlM0dVZucGFoS3Vyd0t4Y0E4WHlqVGU3eW1XRHdPWnNBcnJpMUE9PQ==
Saw someone on twitter claim their paper was accepted for oral. Perhaps oral notifications (or a subset of them) have been released.,r/machinelearning,Z0FBQUFBQm0yeGJuaVZlOWZpXzZLOW50VEtXcVdUQ1BRdEIxU1ZrQWE3NHlXTmp4VEZNbTFWVm5lZTJFNUsycFFkSFBGLW5MLWJZenF6VHVWaDZuNl9hZFpoa0VXRFdHSFE9PQ==
"technically the error will accumulate because of AutoRegressive nature

one direction could be to use teacher force b/w sequences to reset the accumulation of error",r/machinelearning,Z0FBQUFBQm0yeGJucUZUZ1lsMGgwMjFyRjBHeTBnWUlRRGVVSlhqN1BJLVRJcHJLdDdEX1F6bmM4aXhwU01nQXJ6S00xcGlBTF9zYUlSejFXdy13QWNoQnZCTnFoRnJtUmNMbWZSTmh6OHZmVXF6ZExhOTJ4YWM9
😂😂 u cant be serious,r/machinelearning,Z0FBQUFBQm0yeGJuQmRvelQ4TG1TOXdQQ19pMU1OQ3Z0bDlFQUVfTjNSYUFNM29ubm9JNHVGcE40NTVVQ2NjWFFGTE42dnNVb2UtdlBUY29fdXRMUGQ5dFlJUGVwZlktb2NSYkRqTXZWSjQ5NUxhb3gyMXdKYkk9
Wait until you find out about CoPE + RoPE.,r/machinelearning,Z0FBQUFBQm0yeGJuV0NDb1lJTEdQcjdQaW96djFGQXp1Z2RzS2lIWUtyT05SNGx0RUdSdkVrek9pZVBNSWhsNzdLdm1fa2x4aEsyUWgzdUkwQlg3YzBkSDlsbkkzR0dWMHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuVlVUdmNaZ3RmSDJ5eUpBbElsRFhLR0N0X2txYzhaZjlXY1F3SUJVc0trcWF4cWF6X3BxN1MtczI1YkRIRV9KSVQtS0hTQlA0WWZBRWo3Y0ZtT3k2U1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuYm45dk9UbUtzX09hUkJVZWpCd0FnYTFZaTg2UURlRHhFRU5TMmdabHVCaUJuX0puLVVNcjlDa296S1pueEg3QWF6YXJiV0RtVC1PbHpyY0JTak40LUE9PQ==
"# How can I improve my acc on food101?

  
Hi guys, Im struggling a bit with food101 dataset, I am trying to predict it using CNN and using the following architecture that I made by my own:

[https://github.com/6CRIPT/food101-ComIA/blob/main/food101-comia-architecture.ipynb](https://github.com/6CRIPT/food101-ComIA/blob/main/food101-comia-architecture.ipynb)

But I only get a 25% acc or so, so I was wondering what else I can do to get some good results at least +60% val acc. No limitations but preserving the whole idea of the architecture.

I have already tried many different ideas but since time is running and to do every train on my PC it takes several hours, that is why I am asking for help.

Thanks =D",r/machinelearning,Z0FBQUFBQm0yeGJudkFwWUFGMnlkVUlvanBtZjVQaGNXeGJkNlQyMTQwR1JEcXJGWWNkTERyVER5U0cxZDZ1TWFpb2JRV2YwSDZkc0Q3MmlrVlpqSV9mTVBVUzF2Yy1Wc1E9PQ==
"Awesome, glad I could be of help!",r/machinelearning,Z0FBQUFBQm0yeGJuQ3piMXBzNlU2VXNPb2ZsUmlsbDhFbWM3bDJOWUg3NDdLa1NZV09PdllrZHhzSFRjWkY1VEkzVk9VSGw3cXZsdnozVXJFcUJXSkFiUDRfTGlUOXVsbEdaank0dmdVdVhkSzF2TTRPdEpMWXc9
Thank you u/anishathalye for such an amazing course. Can we get access to the lecture/class notes?,r/machinelearning,Z0FBQUFBQm0yeGJuN09IV0lKUE1hYnkxMUJ2SzhGM3JtYVFRSENLOTExR1hIT1NscXUwc1gxM1BmaTBHdTBad0NvWHJxcXZjMTZqNWhGRFMxN2pPT1FablAxdlZlYV8xNUE9PQ==
"Thank you for recommendation, but this thing is for research purpose my lecture told me to combine this.

But, i’m curious why i can’t use neural networks on top of BERT? id there a problem with BERT? many papers told that more layer can improve BERT",r/machinelearning,Z0FBQUFBQm0yeGJub1RtQ1JpSHpBT2pQR3ZQbXhab25qUmhpNTFzaE00aXZnUHdKSFo3TzNPYnVZUFQxS1dxMFZSblJ3Q3VtOUEyekhsSmY4azZQX05NSjFXOHBHdEpDUHc9PQ==
"If you check out the 2023 submissions there were a few BERTs in there. I'm planning a submission this year using BERT, simply because it performs better than other models for my particular use case. Given that BERT is a smol boi, and will run on a potato, if it works well for your task, then it's worth using.

So in summary, I'd say yes, BERT is still definitely relevant.",r/machinelearning,Z0FBQUFBQm0yeGJuLVlPLUpwNVJ4UFJJVnlzaE5YODRVT3BNMENkWDE5ZXl6UUF5SmFLSVJEVHhKN091TW5vdTlpZkc2Y0xseTFTYlhFZEM0NU0yYi1fNnBZSmtzMi01amc9PQ==
Gumbel max is related to argmax whereas Gumbel softmax to softmax.,r/machinelearning,Z0FBQUFBQm0yeGJueEtGazRDaURZSk1wVGVyNnQzeEJSaUQ0a3NvOHBaTG9DWmVfZklkbmdhNVhOZ1dsbGg2N05CRVprQlEzSTBMd3ZqbDhSR0JkU2xSQ0x6M2wzNGNkX3c9PQ==
"Yes, that is correct.",r/machinelearning,Z0FBQUFBQm0yeGJuczZVSmFtN2U1bXJnQnRqRnhUNFE5dk9pM3M0MC1qRDR6S0E2OVpLdHFzZERTUS1tMk5MbndwaVFqbDhtdmtqRFFuMkRoVk14VG1Rd0pxZnJ0M2g0QVA5WGpqVndaZndTWjh4bVM3SFV6bVU9
I’m an early career R&D software developer. I’m lucky to be able to work in AI doing work with LLMs. I’m also doing work in VR with Apple Vision Pro. I’m trying to focus my career more on the AI side but I’m wondering if there’s any good career paths that combine the two?,r/machinelearning,Z0FBQUFBQm0yeGJuRWJVbmcxdEhxYW5sRFBFbXJ2SXZ6QXlJOEtUbmsybmhzb1VxeVQ0em9kVk1ZbUwzTjZCM2NQeGs0RThqZUhaOC1vLXVkRXg0bzNFN0MzbHc0dGNXSXc9PQ==
"Thanks, this looks very interesting",r/machinelearning,Z0FBQUFBQm0yeGJudUI1cnBBRVFoM1o3SjJ3YmhxTmRXTG9OUEdocWVnOURwaXdCdHNzMWVTQmROQjNZRTZhOVl1S29KZXFUT3pXcFhiOWRJZEtkR1QtMFVUUVpacXN2UWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuYUVvSDVCRkwtUkJfNGkxWENzbGpHNVhVSzB5ckQzb3h0MTVPX1lQSlVVb2lyQlhPWHRVQlotTVlhMDBvX3NvZzA3RjlqWnFCbkxpQm04RXMtWFFiY1E9PQ==
"Plenty of folks running this combo.

I mean, it’s quite a flex to post about it, but they are out there.",r/machinelearning,Z0FBQUFBQm0yeGJuYXRQR0g0Rkl4WXNmLWFYSDBoR3hkUEVSQS1RckRxRUFBR1V6V093T0Y1U1VGQWY2ZXJRSWluSnVYbV82VktnSlpueDFWU3NpTkNCdGxmdTBWMkk5eEE9PQ==
As if there wasn't enough jargon in data analysis already...,r/machinelearning,Z0FBQUFBQm0yeGJuWXdmWGhPWFZzYU9EUHhEV191N1ppWGRsQjJsLVlBZF8xNW5aRGo2YUg2ckFROGdybVBGZDdDc2xGblE5UXU1dG1hVkJzQ05Dak5kbHRqSFpic1laZ3c9PQ==
"Anyone reading this ? I’m curious to get your thoughts on this, this book seems to be saying a lot of things I say so I think it might be a really interesting set of methods",r/machinelearning,Z0FBQUFBQm0yeGJuQTZrREN0SW03eGQyMTdOYTVRelhjTEx2YmhGZEJtWm1iM3Q2a0dkYmZicFRKSlBmRW1xQU5palhMS1ZYVnM2TjN5VjdjbDFNanpBNUI4bEZZSUJsOWc9PQ==
"You are doing sentiment analysis. This is a binary classification. There is no reason to combine those other mechanisms with BERT.

You are mixing here different approaches to feature extraction: attention (BERT), convolution (CNN), and recurrency (RNNs). There is no reason to, attention inside BERT already takes care of learning context for feature ext sraction. Outputs of BERT are context-aware tokens, and fine-tuning those with MLP head is enough for classification. More \\*attention\\* layers can improve BERT (additional context), or more MLP layers (better discriminative abilities).

What do you think you gain from those additional layers? There is a reason why everyone uses attention for NLP (except for Mamba and SSMs, and modern RNNs like RWKV, but this is a totally different approach).",r/machinelearning,Z0FBQUFBQm0yeGJuck82dEQ3b1ljcE95TEp0aDRDRlFnYks5NHkwRUVXcWczTmFQMzVNMmIycVV0dUlsVW5TaU5MRUZ2eVNJOC1HR0hhbURSRU9ZakpyYUVxTWZneEtwdUE9PQ==
"I wonder if we can apply sparse auto encoders to activations in arbitrary deep learning models? It seems interesting to sparsify the dimensionality of the activations and from there isolate features. 

For example, could we apply something like this in deep fake detection models to discern which pixels cause high feature activations. Someone knows if this is explored already?",r/machinelearning,Z0FBQUFBQm0yeGJuUHVURHRvNzlaVkJYWUxNazItWEJEVGNnNzgyZTdjaGEyYlZUYTNxd1MwNlFsbnhydzJlY0tLZWR5UzY1SkR1d3pjMWpnanpweHVxWjMxVXRYWi1RZkE9PQ==
i wanna flex too 🥲,r/machinelearning,Z0FBQUFBQm0yeGJucHhHN3VvYmUzMTNNMTlrUjJJQ1BTMUxya3JPVnI1a0xVSF8wQzFmaGtWSDgwRk85bWVvRmR3ajlLTjM4NEFHMm4yd3UzMVBMcEdGdEU3ZU5nX3V1TGduZzRqYkhUc1lUbk12Z0tVZzhRYUk9
Nice. Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJuVmYwZzlZYm1mSnR2NmJFZ3FJaDA5THMtSDV5R0VqWktVeVRKdm5vdURhQzhuWElqNTNOWWpINGZjei1KVFo0NENRTTFTQWhPcnhEOUFJTkIwLTFtSlE9PQ==
"Your answer is very insightful (!) but I am not convinced. Flash attention clearly requires a deep knowledge of hardware to figure out, it is not some side project that someone made efficient, it is EE or low-level dev stuff.  Mamba is really a novel architecture overall, I am not sure what to make out of it, but if you can come out with this idea, you will be able to write the specific parts regardless of what you need to do, or to get some assistance there. Overall, I would argue that CPP becomes a low priority. Most of the research RE attention is more mathematical than similar to FA (e.g., people re-invent RNNs).

I do, however, agree that knowing CPP is way better than knowing any other language for ML research, excluding Python. We should add LLM stuff to the reasons to learn C and CPP, since many libs work on CPU with native code.",r/machinelearning,Z0FBQUFBQm0yeGJuVTY0TnJscVQzZU1rUUE3UjZqbzRySU5iQzZRMkZOdEItWENnVWlkbWVibmVpcnRpMkNnLVFjRGlxWUo4cXlpeWRXVlYzR0R3WlZxVE55OWlHUmhoNWZOWEZMTUlJWkVjUy1KU2ctWEtmbUk9
No,r/machinelearning,Z0FBQUFBQm0yeGJubnN3cmI1bGZmSHhhbXl2Y2c0MUY0a2ppWUx5bHdHenEteWZldnFTTjhFNFdFR3dMcXJhT0VEZUJ6djYxQ25naUlkUklZQTBkYVpnMGFTZkZGYkUyS2diZF9ON3NhZ2JEN2ZmcmcyUXhJNDg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuOS1CR3pKbllfTUYyMFR1N0hqd3Njb1llUzE3d3FycC1pdDJURUVNVHVXTjViTTdtVTE1Y3lhb0lneFZjcG9RSDJ1MEV3N2ZRT0lTZTJCcDV0Znc4T3c9PQ==
"We use it for labeling data, which in turn is used to train smaller models which are in production. We increased our training data 10x and also saw smaller models doing much better after training on this bigger dataset.",r/machinelearning,Z0FBQUFBQm0yeGJuTFV2b2tfeUFoNGRxXzRYTUp6R2hKUTBkRU1WVUdjWGVFNVJwUWZESTdMb1cyLU14TzlteGdfcXVBSU5LVXhWVjdMX1h3ZGlORXVHRnQxTmN0QW4zLWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJubTAwOVNkTDlFS2x0X2RUZXZ5UHVPRm9Kd1hoU1JBSVFmWjM4Rm1VQndfNEh0ZHp5cG1VUVg1Ynh3MDNqcHFhX0xNM3JOQU5MZ0ZuMDJkWVpVckdIWHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuemR6ZVp1R1hKU29hSjVVeW4zMVBhRVF1N1R6UE1fZTQ5OXp2T3N3ZW5ReXlxN2IxMUxKWWg4alJQNS0zMHBqU3l4OE9LZ1YtdXBqMmlRdUN1dldqZlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuSW43RlhYbUlibnZ4aUtFVDNBTWp5LTJLeEU3Szd2Y0VPdVh5Z2pPMTJVSnVLNlp6aHcwenQtQ2VGUm9nbWx0eU4xZkR4Y2tkUE5Scm9RbUxxRk4yLVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuR2RFYTlMemtaTEtTV3JMUUhaTGhlY0tYZm9vcWZpRENSSGtyZXVWNjRaR1RsWF9vWVZrQWpvMXQwZHQ1RkhpRUFaUThfUVdBeDhmWGh4RVJOaVdTN2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuakl2QjRrLUFiZEEweWNOTWdPY1ZlcEpFemhnYlhTclIwOFNtcHN1bXU5WkZUVVYteXJielZWbnhYZ3NsalF5ZWZiYW91TGtnZkhzRWktbTh5RlRpSkE9PQ==
"Really interesting read and approach.

It would be interesting to see competitions to make the best training datasets that fit in 100B tokens or even less.",r/machinelearning,Z0FBQUFBQm0yeGJuRXQxTTVGMllHVDhOMWRBd05VbklhSGxlbDNQN1ZsVnlmR0RwM1hLMTNGZDhzUVE2bDFxNGJvTFEwYUt6akxfM2JiQ3N4TS1wb2wzeVF5NklMOFJLN1E9PQ==
"That's what we use it for as well. Main costs when developing custom language models is annotation, especially in the field I work in, which is healthcare. Annotating clinical notes is time-consuming and is always done by a healthcare professional. Using LLMs in addition to these professionals can speed up annotation efforts by 5x and even increases the quality. 

You should be careful though, because for example OpenAI's policy prohibits using their models for generation of custom commercial models. We specifically requested permission to use these models for dataset annotation.",r/machinelearning,Z0FBQUFBQm0yeGJuYlNuT2pMSDJiakQwTW4zVnQ5bTJkYjBQcUF2MzNRWmJLV0RHMTBUdklaSjYxakVsTENlaVNpbGhsVzVEcW5WV1R2MF9id2RLYlAwQUVNZXhzdm1JMVE9PQ==
The checklist in the LaTeX template is a more comprehensive one.,r/machinelearning,Z0FBQUFBQm0yeGJuUzM5RFFsR0VpdEZnY1FYREVyWWhzeW1UUi02bUhvb0w4QnBwRjhfaWJOSk1UZnFPa1dwWGwxUmo4YWFaRkh6QjcyZGY0LURFYXVnQl9ZcUUwdk82dGc9PQ==
"Would be highly useful for the open source LLM scene if better merging methods were developed, particularly the merging of smaller models in a way that allows the wide distribution of compute requirements.",r/machinelearning,Z0FBQUFBQm0yeGJuV1FkUmNNbW5WRDMyazk3Ty1GMGU3bEVXelpDdGRfUExtZVJjdlFNaTBNc24yX1hSVHhDWEhPUHM4MnpJbnJoWmxjU0QwVTl5OVpHbjg4Z0JCbk1JVGVINVh4WlZRWDV0SGFQUnFob2wyLUk9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJuVWo0ajV3TUVsYTVXTjNRaTJzQ2RiSUh1RV9qWGQtUGEwaTFrN3pXRHpXbC0wYk1meWN6RGNXLXFvV2FzNFBLRjJnekN5YVQ1UjQ5TGxUV19CVEVIN290UVZ0Ul9nOFlCMkota3R4enB2YXc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuWC1pV1YzTVI0UE55RHQyNFdBRXFfMEI5OVdGenI3UFpqV3FRUGZRNmppTmlLR2hMQ2RSQ2JLRDNCOGwtZmc2WVMzVml0Q0xoOGFIM2l5RHc2V1dFZUE9PQ==
"github repo for those who can read code better than math - [https://github.com/tangle-software/tangles/tree/main](https://github.com/tangle-software/tangles/tree/main)

  
looks very interesting",r/machinelearning,Z0FBQUFBQm0yeGJueXNwTTFRWDNnYnZnV0xnNlVNWlltaTREVEZTWm5WYzZsa3dIeWJFalNpdFY4c0FLTW5zOE9XRkNyM3pfWWRiZDVCd2REVkN1Yi1OSjJQLURHblZXa0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJubXczZlNQS2hhdFVFT2tvU0NmbXg2T2FEYURGR2IzdE5QZ2hmaDJocVhMVDB3elJlamJaVU0tRVp5TlB6UFJIakw0eUtSeFNFWUU3ZDlpMndQTy1BeUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuRGpzZ2Fac3FHMlhpanpyM0FicUxqU2JtcHNZMHlVbFlrTlJXR1JOcThWckoyN3pxeW1OUFFTZXZicFh4Z1FHLUZ6dFl4b252RFVlX0swZ1o4RnZxdVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJub2hBNGVvejlaYXdSNTNZUnRtSERXdDhXRkxsczZQczc5dThqNFhVdXVVX0NjRDhBZUYzQnR2b2V5ZWRrSFI3cGRVeW12T08zckxzcVNlMWVBdFNXSGc9PQ==
"Hi, I’m excited to share an interesting project we’ve been working on recently.

MetaEarth A Generative Foundation Model for Global-Scale Remote Sensing Image Generation

arXiv preprint arXiv:2405.13570

Project page: [https://jiupinjia.github.io/metaearth/](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa1JCQ01aLVo4TTlHR0Q1dVRjMVZDTlFOenFVQXxBQ3Jtc0tseDI2S0JWdjI0U09rLTcwSVZYdGtya2lqa2RnaVlHaE8tNFFVNExYQ1RreDF4MV9nbmY0bWkybTQzb0xlVlZ5MTNSbUt6VUYyTHJNY2lWTEowOFdscGF2bWtOSVk1MGdwZ1dLajdUeTktVXhYenU5MA&q=https%3A%2F%2Fjiupinjia.github.io%2Fmetaearth%2F&v=KjQIfWtKNIM)

Abstract: The recent advancement of generative foundational models has ushered in a new era of image generation in the realm of natural images, revolutionizing art design, entertainment, environment simulation, and beyond. Despite producing high-quality samples, existing methods are constrained to generating images of scenes at a limited scale. In this paper, we present MetaEarth - a generative foundation model that breaks the barrier by scaling image generation to a global level, exploring the creation of worldwide, multi-resolution, unbounded, and virtually limitless remote sensing images. In MetaEarth, we propose a resolution-guided self-cascading generative framework, which enables the generating of images at any region with a wide range of geographical resolutions. To achieve unbounded and arbitrary-sized image generation, we design a novel noise sampling strategy for denoising diffusion models by analyzing the generation conditions and initial noise. To train MetaEarth, we construct a large dataset comprising multi-resolution optical remote sensing images with geographical information. Experiments have demonstrated the powerful capabilities of our method in generating global-scale images. Additionally, the MetaEarth serves as a data engine that can provide high-quality and rich training data for downstream tasks. Our model opens up new possibilities for constructing generative world models by simulating Earth’s visuals from an innovative overhead perspective.",r/machinelearning,Z0FBQUFBQm0yeGJuZkRDem01SUdqTExzWXJGR2xVRHJhektqSHVJSHdVNm83SlNYSExWTjFKN2Roc20wRmFRLWk2NEVzdGxEZGt2ZkRhVE9ILXU1bWg2Z1o0aUoxLUxyT2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuMUQxLWxndlBfYzgwV241RnByc1Q5NFdmdUM4Q1RPVE02LTAyYmRna0tfdXFYd1ZTN0hXbFgzRjBtcjNWUU16U0Y5Qm8yblRoRHNSUzJIVVBHYnJ1T3c9PQ==
I use it to start and/or refine coding tasks. This is particularly helpful for little R shiny apps and hobby projects.,r/machinelearning,Z0FBQUFBQm0yeGJuVUtQcVBfYnBNd3RCZlFFS1R1YXFnSk1adnBFWW9CNEgyUkxZN2trS0NTWUhUS3ZkeXBwd202bTFibzJ1V3dCbWNiRC0wRjFpZ05kdnlIT2RqZVV5VUNVUU4tNURMaGgwWTRTcmxxLUl3Ync9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuWDBYeElKUUp4X0UyOC1wMHNXR3ZZTXRETEpBUE9HdUlkZmhBckQ5V2o2SkVjMDJtOU9wY2dSazFCWm1GNEctYkdmNmQxTUNIbkdrMHR4OVd5T1hSVFE9PQ==
"it is because when we are using less data points like in the case when we have small batch size, then the no of negatives will be less and also there might is possibility of false negatives present in the small batch, so the gradient updates will not happen correctly, when we have large batch size then acc to the formulae of CL, it is easy to learn the embedding, and also the prob of false negatives affecting the learning will be less as compared to before",r/machinelearning,Z0FBQUFBQm0yeGJuWEk0M2NDYTBocHdEcU5HWVdJcEpZcDFrMGZNQnlmY0t4SlNSNkdRWmd6Tl8yeEV5SVlYTURZT3dEbTdaUWNsdEtob3hZR3AxYTdmU29hamRrbDBRaGZtNWNaMU00QWJyT1l3VVEyeVR3elU9
What were the use cases before you gave up?,r/machinelearning,Z0FBQUFBQm0yeGJuZWhweDhGRVppVDdSU0R3SWkxNHQ1MVlodTNBYWpJaFZzQ2U1aWFYZFRfdUYtbm5YMnNpVlZFUzI3X09DckRvcVJxdFFSdjAtQ3AzZFY4RHhTQWJ1NXc9PQ==
I'd see If I find researchers I can collaborate with at [joinporitko.com](http://joinporitko.com),r/machinelearning,Z0FBQUFBQm0yeGJueXJ5Q2lBbkJEaHVpQzRvNUxobXhDd1ZkRjlNOU5ZRmRQZ3RwbTI1R0JLZ1RWRzB0QjhpYmp1WVdiYTFURGRaWmtHVEhXWlJqbzd5UUo0d3JBM21LOWc9PQ==
"> this book seems to be saying a lot of things I say

Settle down, hinton! :)",r/machinelearning,Z0FBQUFBQm0yeGJuQzdwLUZnTThZX2VvQTlubGg1Zm9GMklpTG5ZNWhlUnZYejlITEg2RlE4WF9UR1BBdmZlTFM0dTJ5MTRCNEFMaS1fSHo4N2s4OXdXUzdDc1RWbE01d0tVZHZiazJQZ2dNVUhBYlp3cmV0X0U9
"lol yeah, it’s kinda exciting to see the style of thinking that i apply to ML being used explicitly. I just don’t want to pay 40 quid for a book that could just be a monograph.",r/machinelearning,Z0FBQUFBQm0yeGJuSTRDQVpTVFE5THhUNDZlNElJY1ZJdnBORGk5S0pPenFJZzdHb19TRFBERlhMVmQ1WGpyMHR6b05aUnpkcDhhVVZDSzlndGlycHpvTklrdTZUMlNVMkE9PQ==
Thanks. I saw it too. Was being hopeful about the subset case cause I didn't see 'oral' lol,r/machinelearning,Z0FBQUFBQm0yeGJud0stN0h5Zm1HNXVxNklZaHBiZkZ2V0pZdVByc1NBeGM5bW82RzFSVHVXV01nS3dNaXVCdFJJZ3lwazFzc0VEZVZJUWg3Tko3UlRtbm1HaW82MzBCUGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJudDBfblI0SkpHVmtpWDdDMU9jNzFYZzJkeUFTODNvOGZuUjV5OGNmWkk3RjJWeWFQSDZlSVl6MVhFRlhpMEtxZVp3dHdSZ1MxREpFX3ZDd2xQQmF6cnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJubjBSbDFJV1dodzllRllSNmVKLUVVM0NUYm9qMjFSUmZWbG95NHlEUzdGZXJSWVVKcTVWbEhaU0lPb002RXhnSFhyWGZZa1dOMXRHQXJKMGtkQkJTc0E9PQ==
This a pointless post,r/machinelearning,Z0FBQUFBQm0yeGJuUmdoVWtvcnQwbEw4YzFVZHdpR2FvenVyWWFNaURhNkdDV1dHXzlfVENPd2pNVVVOYWdxbkxfblZBMGR0SDJBUm9rd2prUkZFWHRabTVyNzM1Z3NqM2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuR1ZZdTVobWZXc3ctTVZvUzRBUWdfMzBIdTZmOTF1V2FWYlJwdXI1dXNNS2VwYU84dF9VSnJPYXJlM0VTR3ZhNmhwNWZyQUhET05qQkdCTnBndndqdlE9PQ==
This ain't LinkedIn. Please don't make it one.,r/machinelearning,Z0FBQUFBQm0yeGJuNEtyYmhhSE5GeWRDQ1ljT0M1NmVyZkRxUHhxa3djdW5mTVFKYWUxVFBUdEZ5eGRYNEVUQXJ6eXAzd2N4aGN3OVd2d0NHcjUwaEEyN0N4aFF5R0tLOWc9PQ==
"For other folks unfamiliar with Tangle Theory or Diestel's ""Abstract Separation Systems"", I think this is the author's recommended introduction paper: https://www.math.uni-hamburg.de/home/diestel/papers/DualityAbstract.pdf",r/machinelearning,Z0FBQUFBQm0yeGJub2FnQTZ2NWphNWZOSnZFZzd6SV9NaDFRLTJhcVRUVlMweU1nTlFGeFJGa1ppakZVaDBCTUdEei1kMy1wZlVIRGJVTTFrMXltZ2FLU1UtZmt6VnpnRUE9PQ==
What is encompassed in clinical notes? Is this everything a provider writes down regarding a patient / patient visit?,r/machinelearning,Z0FBQUFBQm0yeGJuUWVVSVdLeDE0OUJLZmIzUVF2Q0R1RWlfa1lHYzlJWXczYjA4dW9tTm11RjBEZDR4cVo5NTJoRjJlNjNHU2o0Tmk3MlBYQVl0NDRXVkNiOUtJZkVsZFE9PQ==
Ah thank you so much. Now I got it. I guess it is a good idea to apply it to some of the layers.,r/machinelearning,Z0FBQUFBQm0yeGJuQW1PUzl3YkdveXQtY2MyODRBTzdMTUVYSExyWXViaEF5aDVTSGNfYVpYYW1IcG1oZGwtY2hsdWhhQm56ZjdJZmRXREVoMWlHN2trTmc1MWZrOHlrX2c9PQ==
"The sad truth behind this leads to specialization.  Not only will you not know all things for all times, but you won’t even know some things of all times.  Hell, get old enough and you’ll realize you won’t even know some things for some times.  Look deep enough and you’ll see you won’t know some things at all.",r/machinelearning,Z0FBQUFBQm0yeGJuTzFfdy1qdUVYZTF1UUZTdzJLaGRCVno4Q3FYV2VjS3lyNlp3NWZ2UzRiMEFZVnVUS3ZFQ0tCazh3RnA3anV1ajFzRUxJTklIb1hRNWRvTzRsWTZIUHNlTkdBbjlQLTl1Uy1vbTRYRDRoOWM9
">By grouping qualities that often occur together

I thought we called this ""clustering""...",r/machinelearning,Z0FBQUFBQm0yeGJuYjZVVUhnOC03TG1lOUtDRUhIOGt4cHlrLW54LUgtWENScF9KMl92M1VJejV5NG5iMnJVWjJvcGJSYTQ2b2p5TV85LTdNRnJjTjFiMTdQYzhHWlB4d3c9PQ==
Pure knowledge in a technical field is fleeting. Comprehension is a greater investment but lasts must longer.,r/machinelearning,Z0FBQUFBQm0yeGJuOWNxV0JzbFBhQUpXQ003OG5vMHBoSjNacU1NRHY2NHoyelRiSG5lSFRWeWc2V1FGQkhVOF9ESTc5OUNxMzQxVHItS3ZrbXJBeWdvUmE0OTVoZHdrZ3c9PQ==
You can use [plagiarismcheck.org](http://plagiarismcheck.org) . Quite a decent checker with extensive search,r/machinelearning,Z0FBQUFBQm0yeGJuVGh2TXJzWEZlc2V3UDBfV0hWZnhhQTZrM1dOZElxQVdxbHQ2cXZJMnNSNE1DakZzaUZkMC1uZTVqWVZsSXhJREJ3cENQSkt3OW9ESWFoLWR5clBWejhTYkRTSlZJdFNrNFJ0QnltTk9udzQ9
"the clue is in the name. Language. 

These things are good for interacting with people, it's fuzzy and unreliable - but it's useful (not perfect).",r/machinelearning,Z0FBQUFBQm0yeGJuYmFnVmFvS1Fld0VjTl9SUEh2UU1RTWMzUVdtZTdWSzl3SWhHWEpMWGdTVEY5MklvZFV5UDI1Zjd2WWR4OXk0VzZtSEpUMHF4akJyRkRLa1NwT0xISGc9PQ==
We used it to summarize from given text. Rather merging a lot of text. It worked. That is where it worked.,r/machinelearning,Z0FBQUFBQm0yeGJuV0Yzb0xHVC1hYnA2WDdZV0pkTW9zb01iQXA4ZV8wVWk1dGQ5eFd1S2JTZ24tSHhMRU50aGpEVkpWQVZXdDRocXlDbjU5SktweFA0MU9Ca2lfZ2l0eE4tR1JIVTFKeHJZMHJMUS1tZ1pqRkE9
Literally what I was thinking.,r/machinelearning,Z0FBQUFBQm0yeGJuWmR6WlFHYUVjUy1XRzBaaGttWHlyZHVVMzBWZkswWDJhUmx5bjM1VFhLX1pxY1hOdTJwYjBaOVJSdEtHN2RjTUl2dXk3SmY3aTY0RlVGQmZjMWU2Qmc9PQ==
same :) from 7/5/4/3 to 7/5/5/6,r/machinelearning,Z0FBQUFBQm0yeGJuS0FiSjdaRzlMbGtLb0xNV0F1YVBncG5XbnFEeDRsSVdfaUowX3phb3VHd1JXaXRBZjF1LThyQUNIVTljRVJQLUJfbVFWNUluWDNENmtzWi1JT1RGNWc9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJubkN4cHpfYzBSdldFYS1VM1JlQlBTSEpSLWJUc052ZDUxQ1J3M0NpVzBxNGZvZ0lSTklnNDVMYTY4QVQ1Mkpfc1dyaDZ0ZHItZzduUGcyS090SktXSHY5WWZqRzRPMWFNVkZ0bGpmdEpGdVk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuSjR1Ri1ydWJ1TGozVmtpQkVIV3BCcl84R0NTWUNCRVBudk9qakYwVWhsSXZyampRSzlDMzFhZUhMWDVlWHFEX3ZDNHR6U1FVQ3JnNnB5STlwcnc3N3c9PQ==
We are using RAG to make company data and policies readily available to sales people and new hires. There is a lot of role based access control and data anonymization.,r/machinelearning,Z0FBQUFBQm0yeGJuYl9kRDY2RWRFOTZydVdxclEwZ1RFOG8zV1BqMjktT2lxVVBoUnlsY0FfTlZRaDh0ZWJJeHZDRnBEUG5FNEwzaEdwZlNKWkd4Q0tsNnR0UjA5LUpNcXc9PQ==
"Garbage blogspam, and yet another bastardization of the buzzword ""AI"". AI has literally been the primary engine behind financial market making for over a decade.",r/machinelearning,Z0FBQUFBQm0yeGJuYTlhRGRpUmNKREtFVk5qVDJpZVhpaWFZV0YxS1lBWVhueEJWS2l4YWtNdFprWHpDTFdfUU1MYWJVSUtmR3E5cWs4UmNXZ04tNFRsZGYtdXNkTUZLNVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuY0RiaVNhZVdiZHQyeHJ4YWpiU0s4STZ4QVlvY1hfaHJYeE5GM3JUcnFtMjVLeGFJcVpaLWNVV284ZzNjbUFRTTROQkxYX1gxOXZPRnVVSG1XdFFEZnc9PQ==
"Mostly information extraction, classification, normalization. And for generating synthetic datasets.",r/machinelearning,Z0FBQUFBQm0yeGJuMUJXNm8wMlBwVWxEOGxCN1BqeE9zRWpwZ3lmQVVZWWNVVjhmbFFfRlJSWjQyVXdkdGRwNjlKYlkzWURhY2syX0RrRFcxc0lKWGRPbzZSd29WaDVRSHc9PQ==
"I came across SPECTER once, a document embedding of scientific documents [https://arxiv.org/abs/2004.07180](https://arxiv.org/abs/2004.07180)
Never tried it though.",r/machinelearning,Z0FBQUFBQm0yeGJud3hCUFEzemdRZlVSWWllYnJzalI5OXFyUU1XS3NWeXJ5dnpLVXgyZnZrcWMxRDZDcFRadkRGMjlFYWJrX2h5a0ZUOVNzOE9Ib2tRTHVDSk9sOEVHTk50cmpobE9UX2szRWRiVjJ2MlZhQzA9
The lecture notes are available on https://dcai.csail.mit.edu/.,r/machinelearning,Z0FBQUFBQm0yeGJuYVcwUHpUVFVRdUkzZUVkZ1lUbUFabnZibXFmcnlhUU0tVDJSeFJETzdCN1lqTm9Xekxkc2VYMzFMMWZSVjVSdzRFRlRkcXpTaTA4ZjBqc0Q4MHdDRWc9PQ==
"So, to clarify for the curious layperson, this is basically a mechanism for rendering a sort of pseudorandomly-generated planet? That you can zoom in to a somewhat arbitrary scale?",r/machinelearning,Z0FBQUFBQm0yeGJuWWR4N2RCZUUwcnE4bGNKb0RSWUZidzRHWlo4eWd4azNRTjFLSnJoa2tLTGNqWEZXUnpib3V4a3RONU41dUp4MndIUURXdzJ3VHBzTjhCSU5UbjNxQ2c9PQ==
I thought group theory goes well beyond clustering.,r/machinelearning,Z0FBQUFBQm0yeGJuWlZaQmtHanUxZVlNXzA4RHZYNmNPY0p2MlN0ZXBFeV95YWRDZ3gyZjhuc2lWSFE3VklVNUE3LTR4X0NMUVBrRWZMeTFlMGtNc3YzdnduN0JGQ1BVRXc9PQ==
"Better read the intro chapters in the book: Ch.1-2 for an informal introduction, Ch.7-9 for the maths. The above paper is far more technical than needed for applications. It also uses different notation, which will be confusing if you also read the book or the software documentation/tutorials.",r/machinelearning,Z0FBQUFBQm0yeGJuYVRETnZwcjBNTHNzcjdqeTRUTFJtZmNDbGtvbllwazlVU1RsS2F3M0taYUtoaXZfV0tkV2NEWnlaQlByanFSWkROanhjWDhyVU05aDMzLWVuZGRLNFE9PQ==
are those chapters available without purchasing the book?,r/machinelearning,Z0FBQUFBQm0yeGJuUnBQRnJycFJlV3pwOTgyQzR3aXBYT1NvMDkxUEhlb1JBYkRkZzJ5aGdaWXNRQWFuV2pYWjZHczBvbU5OZTVHSGQ0bmVJYmhpRHZrLTRTTnFLNzFuZ0E9PQ==
Chapter 14.3 is entitled 'Tangles are not clusters in the feature space',r/machinelearning,Z0FBQUFBQm0yeGJuUlBKOUtPWlZoWUphU1dNbTd0QjZfSXltWkZwS2RJUkhHQktrYVhhYXhKR0E0N0JwOUNQYldWeUw1dWNFMVF3eG1makJLQ1NKZHlzNkJ1ekpZTFp4VWc9PQ==
Let your goals and practice guide you. They tell you what to ignore.,r/machinelearning,Z0FBQUFBQm0yeGJuaWl4dHUzdWFyb3E2LVZveXhWMnJyeVRGMnVqLXdQQmVKeGZ0aWlkTDVQX3g3UTJTR2I5bF96Y1NreUJ2NjRRSm8zNVJ4bGtaWlhGRUZiRmNZRHpxVGc9PQ==
"Isn't NVLink about to be discontinued?

https://www.windowscentral.com/hardware/computers-desktops/nvidia-kills-off-nvlink-on-rtx-4090",r/machinelearning,Z0FBQUFBQm0yeGJuYm1oLWVtNTViV2hIb1lVTkt6ZjgtRlZKZ2ktYlZURDVtSDFjOTdOdF9Zd0IwSDFUc2wxaWlSVGNvMFlsaG01ajhvQjlWWG1tQU9hbnIybHBMMU5qbWc9PQ==
"Same as others have said, but I'll rephrase it a bit: Creating structured data out of unstructured data.",r/machinelearning,Z0FBQUFBQm0yeGJuTVRtN3RHVVRXQ0xxNElFSFNTbEt6Q2JudElGS1VILWNHWS1ZN19OZFRwUHVpNVUzSmJJeVBWeDR1NkgwY2lXT3RkcHc2bjB1NnlIa0pYX1FqWC1fdmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuTEVXVHFzcW44eUlSdk5PVmxCNkN6NEMtTlRoVEVfWVhoemZDNldmdUgwMXBUU1lrLU9LaFRnSHhOQmVpYWRmOUNBSXhHMGZNRmpCbkl0Q09DUGZvQVE9PQ==
Group theory doesn't have much to do with clustering.,r/machinelearning,Z0FBQUFBQm0yeGJudlh1cG9ELWI5YVpWWjFSMWFhRW9yM2dZYXIybGRQMHU4WWY1NWJpbmgxS2lad0RTLVBnei1PVGFkNHNiNTB6SWJpSnRBX1hoM0VrRDBvVjM5OE1reHc9PQ==
So what? There are lots of ways to construct metrics for clustering.,r/machinelearning,Z0FBQUFBQm0yeGJuUEhZNlk2ano5ajUwRGNDb3NuMU05czlNWFlPUk0wN3pjVjZyUHhjblhDa2RQbTlCOHZKQ0Nid2RaU1M3OWZWaGVhaVp1eklHeGlFRDZGWTNPRzdnUlE9PQ==
"Specialization is unavoidable, really. The field has gotten too large. That said, there is no reason a specialist should be completely ignorant of the rest of the field, otherwise you just have an excuse for being lazy.",r/machinelearning,Z0FBQUFBQm0yeGJudWNtdWRMUGxldGtXYkFwNFZuUWZUWlc3V09NRWktYkdSR05iWmc4cDNZd04xSTNjeXhUSnk3RmctZlhta0dNMWctS3RHVnlGeUlTYTlWci1md3JBcFE9PQ==
"This isn't really an ML post, but a much more general concept. Typically spaced repetition is the way to keep things from ""slipping away"". But in general I found that taking notes doesn't really do much for me. There's a lot of truth in the saying that 


10% of what we read

20% of what we hear

30% of what we see

50% of what we see and hear

70% of what we discuss with others

80% of what we personally experience

95% or what we teach others

- Edgar Dale



The take-away being that engaging with what you read is much more valuable than just ""consuming"" stuff. I noticed that I consume a ton of education ""just for fun"". In the end, it's just Edu-tainment for me. I've come to the conclusion that it's fine if I forget it if I'm not really going to need it. I think you'll come to the same conclusion eventually: Your brain is really good at pruning stuff that it's not really needing.",r/machinelearning,Z0FBQUFBQm0yeGJuaDloN0FadmQzSkJtVGlqeDJOcGNWeTd0eGlQbWtwaXBleXgzMWZVSUFRVno2TExpUFN2UzFidmQ0bzNaNWRnVjZzOGV1SGhIMTFtdkxXTmxJaENrYnc9PQ==
OP this post resonates with me. I have been considering using Obsidian but never really kicked it off. I wonder what your flow looks like? How often are you taking notes and how do you carve time for yourself in the day to do it?,r/machinelearning,Z0FBQUFBQm0yeGJucV9TUVVORGxLMEZxbWxzSkRnejlYSTFVVVdOTnBrYjB5emlOZXVJNWM2X2xhYkNTS3FabndWc2swQVNvdUswUmNJbFYzUHZ5TWVmeVBCUUdLQkxIQnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuQk9FMkprZFJUOHJHbVlEdjRib2JoSnBWbDJnU2dlcVpZYjduVDZwTHNjYk5QZGg3c1k2Ni0wZU4wOGdIc3V6UDNQUzlPQlQxMktjR3ZGTUE5aGNoNXc9PQ==
"Very interesting read indeed and quite a few nuggets collected. I wonder if there is a way to print it out, has anyone tried it?",r/machinelearning,Z0FBQUFBQm0yeGJubVJJSmpVVFR3WmVCLVJqR1pLVGVSU2pCSm1HbEI5UmJOOWpuMXhDZ1ZONlJSWFVfVzRuTGNuRHVuNFFJQTAzTG42U00xOVNiR3ViTHNabllveE1kM0ljTzdKa29LdmlTRFdGNjlELUhrQ2M9
Have you considered using BioBERT for scientific document search? It's a pre-trained language model specifically designed for biomedical and scientific texts.,r/machinelearning,Z0FBQUFBQm0yeGJudHpCdkN6OGVyOFVKdHN3TzZ3YU1HSUZIQU1PV01pMFViUGthNzlaTmtSdGt1eVNjYmxYZlV5MmZsRnlVRU5pLVY5aEN1aElGTk0yNG01VHVCOFlxQ1E9PQ==
Right.,r/machinelearning,Z0FBQUFBQm0yeGJuaWR1UURLQ0pPYXRFOWJlR0FBSnJBaTB6YlAxUTF1S05VSm9kMjhRcnlhMG9oQm5QdWxxS2JDWllnSUdkTzFEUldiMGV5NWpEOHhJcEk2REFLekVYUkFKSnZyM0ZOWGRWbnFBVXZjLXp6dkE9
What pipeline do you find most effective/efficient for #2?,r/machinelearning,Z0FBQUFBQm0yeGJuaXNCWkVsanAxVGhSSzBTR19sc09PZTZuT2JHMzRsQmplTFR6cTc3Y3lmbVFGRm1UUEtHYk1zTGw5WHBJajk2TWV2eVBQRTh1em85YVZuMElhb0Z5QkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuU3BZRm4xV2JLWHlxdnIzZHkzTTNBUmZEQVNDb1FGZmcyZ04tSWFmcnY4MV82eU1TVzVoOGZHMEpmSUJzYUNUckNULUdRMTRLS0ZUSzRVRzBGVlU4ZlE9PQ==
"Agreed. AI progress and options are very fast. This month you download a model, next month a smaller and better is invented.",r/machinelearning,Z0FBQUFBQm0yeGJuUjBWWlBtRXdEajdXRUczYWVwTkRkeXBGQV9CREpOWFdUS2plTElMWU5tQWtUMjlYLVRhdnJHQUp0RlBmV21hWFJ5dDAtcXJGbEdTcnBMcWdFbnNhWVE9PQ==
What is the research area?,r/machinelearning,Z0FBQUFBQm0yeGJuVUc2RktEcHFzWHUzV09DZWtMcEJPQzlBSzNSbTlxZE50Wl9GbmVPeXNiNFBpWU5aaUdHYjliWE00QjY1ektqRVV3alpOWUNnZ1NTRjR6SXZsZ0doSWc9PQ==
Hi! This is one of the authors of the paper. We making the code fit for human consumption and will release it soon! Stay tuned.,r/machinelearning,Z0FBQUFBQm0yeGJuc1FYa3hxbkJKaWVYc0IyUFEtb0FxNndXY1NKOFI1bXV2ZmE0SUlCVEV2VTNIMld6QW1TaThlMzU3TkhwZEJBSzBWUG1SQWo2b1ZiX05IclJiTjhyTkJQMUFUc09NT1NMVV9oNkFsd2VPQ2M9
ChatGPT can answer this for you.,r/machinelearning,Z0FBQUFBQm0yeGJuUDAwMDVETmxZRmtCRF8yT1k1YzJjQ2VLaDNGWXk2UWJsUFlYQzN1dEJyR3hEUnBKQkpkenlFclZaNXhoNGszTElFMFF5NHBkRllCaDE1RzBMdUoxamc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuanFhZ0pESFRNRFZUV3lTc1hPTmhicmxJVm9kNTFOVlZhSUNYZ2V6YUt0eTVtOFRmUUJxTTlLVEo2cWp5WGxxeXBmSWZ3Q2EtSk85Wl9rb2lwUkVSaHc9PQ==
Did you profile also for the same?,r/machinelearning,Z0FBQUFBQm0yeGJuUm1yUVRhSVVhcWtlU0hqME5tRWJsa0RzWTJXczJVaFZ2VEtuY1h1U25BVDVLUTRocjNVTzNOWXc1bl91MnNya3pwelNQTWJ4Tk0yNTNvQ25EUDFFNHNhNmtpbU1qMHRWbzA3SVl3eEkwNVE9
Every ML concept I’ve implemented myself has stuck with me. Papers I’ve read etc stick for a month or two.,r/machinelearning,Z0FBQUFBQm0yeGJuSEVIUGJERVkydWpoRWVFYTgyaFBlU0FDYk5UWDRFQk1KeXE0azM2Vnk3dUMxNW1fN1VnZjFIZFBtRDUzOS1ESDIwbk5Hb19oYUl5NHJzTjQyVGNGNGc9PQ==
[https://arxiv.org/abs/2402.17152](https://arxiv.org/abs/2402.17152) seems to be very relevant for the next-token prediction setup in recsys.,r/machinelearning,Z0FBQUFBQm0yeGJuSnYtSDdlZGhGN3UyY1BtVTZxMWxuNFhadUxjY3JGaTY1UGxOR19FVHFSRWFJNDhnUTdsREZyRlF6V3l6cnJHN0V1NnYzbXVZSnlVRWZ0NEIxZFNHMEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuVE4xSEVGaDlMMGZSUnlBMDd6dFNRbHhhTF9sdEVKRVF2MGFPbjZ0NDdycV9femxMSnRXd0w3ODlodXNhLWI2ZGdwdkN5UFZENTNLY3dQOENGc3Bqcnc9PQ==
"Thank you so much, I will take a look.",r/machinelearning,Z0FBQUFBQm0yeGJuWGp5eVpHNXNBY2VIYjRrRVZXeWxJRk9hZ1pPa3FJNTUxWm10R2JHdk1XaDVJN0pSMUpLdmIxWmhKR0tiTU9zdXA4bWk4X0VxNlV1NkZmdVhYTDkxOHc9PQ==
"There are many situations where they fuse: symmetry groups in clustering, graph clustering and automorphism groups, quantum state clustering, clustering symmetric data, harmonic symmetries for music genre clustering, and material properties for point groups.   Plenty more examples.",r/machinelearning,Z0FBQUFBQm0yeGJuVTY2RWNVYi1ITkFlU3djYllpcUpCckxCSlZmUHdKNENQUjlqTmczMFhlNEtSUzNycTE4emVrYkx5MmZYUF9MdlFrVlBpazBtTWhTTjlGMmRrNUhKRFE9PQ==
"I'm not an expert in recommenadtion systems, but my guess is going to be data. The data that's used in recommendation systems is usually extremely sparse compared to textual data. You're dealing with the same data in the sense that they're sequences, but the way you tackle it is going to be very different.

Is there a way that you can add in more regularization to prevent overfitting?",r/machinelearning,Z0FBQUFBQm0yeGJuQlc0WHVhakhqREU5c283X3ZjbzJEektCd0lxZUlMZHBha0loVFJTNi1oZnEtMHlTU2FIM0dhOC1DYkZhT1hKdnZ0UWVrWDh0MENPLTkzTlI2cGlSaEE9PQ==
How do you do normalization? Any papers you recommend? Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJuTHRocWxreEx0SkpOZWFpWXctRzdHUVpTdV9aM3Rncy16bFNqWnhLVUJkd0xmVnppelpGZVpfWUtmSnEyYlFCaHJoY0pFVDhJTXJVRnhUODNwSzJyd0MtOTltLU1ER1JkclpJbDNSWWw0WGM9
"> I treated each product\\_id as a ""word"", each order as a ""sentence"" and each user's transaction history as a ""document"".

There is no text context to draw from. The order is directly correlated with the product, so this provides zero information. The transaction history is just really a list of products, and maybe information with time between orders if that is included.

The actual text of this data provides no additional information, so a language model is pretty pointless. Just use an ordinary time series model on the raw data.

I'm reminded of the old adage:  ""If the only tool you have is a hammer, you will start treating all your problems like a nail.”",r/machinelearning,Z0FBQUFBQm0yeGJuamk1d18zelQ1alJVM3dKb1RTV2I0Wmc3RXdPZmZ6Mmp4RFZlUFJzRjIwTDlWaGY3c2xJT096YnM5V3FhNllSczJEWThlX3pFSUFqejBEbnN2NVo0SHc9PQ==
"I agree that it could be the data, that being said, the transformer architecture should be able to do simple tasks such as popularity count (and thus should at least outperform the popular baseline).

Regarding your second point, I don't think overfitting is a problem, if anything, it is still underfitting to the training data. The generated new tokens look nothing like the training data, in addition, when I continue to run training, MAP@10 on the eval set improves (\\~0.10 now)",r/machinelearning,Z0FBQUFBQm0yeGJuc0Q2b3ZGSU42d25RbWNUWWRudVNNSHNOUFJGUnJ5WWc3YnhROTNlQml4SUtWYUlCUWlnWjM4WmNsVDVqLWk3RkJUS2dJdGdCN0gxMzVFWE0wMlJvREE9PQ==
"First step is to use nvidia-smi to check whether of the GPUs are being fully utilized. If they're not being fully utilized, the parallelism may be suboptimal. 

You can choose a lower precision for the model, such as FP16 instead of FP32. 

Edit: You can also choose a smaller model or a different model",r/machinelearning,Z0FBQUFBQm0yeGJuQkpyUTNrTlNDRnVESjdWejBLa29EVnpDeU9PajQ5VjFjdUgxcGFYRS1tSWM3VktkYkRJbzFLVEpnOE0tYm9kbUJTeEJYMGNsY2JzeVR0MjBrWWdLTlE9PQ==
Consider parallelizing the encoding process across multiple machines to improve efficiency.,r/machinelearning,Z0FBQUFBQm0yeGJuTEJPV0EtRVVURmd6Qi10bjJ5Ry1YVGpWaXhCNmdYd2FrOHNjZGt5ajF3ZzQ0N2xXc1hCMXR2V01MZTVGWVpGejAtdU83T1VmY005Q2dIOHYxOHl6THc9PQ==
"For those that have implemented DPO: When you start the training process, do your reference model and your policy model need to have different initializations? The reason I ask is because it seems like if they are the same model to start, the log probs will be 0 making the initial loss 0, preventing any update from occurring. Am I missing something?",r/machinelearning,Z0FBQUFBQm0yeGJuZ1ZyaGZTYllrM1d0czliZmJyejZObU5sZEljcTAxMWlnNUF2WFU5UlFvWm0tRXhKdkJiVVowcExvSkFMd2tWbkF6M1F2b29BT25nQmNZSFBjb3l6c0pmdmxQUlBzMUxWOHh5UmNUTk95Mkk9
I said I only have one machine in the OP lol.,r/machinelearning,Z0FBQUFBQm0yeGJuTmJ5OUU4RmhYcEM3THByQnV0Q0I0Rlh2RXdhT29Sa3ozeVhFUi1ZakN4Tm8xY2k1SEh4RkhZQjFLbF83MEZZYzhITmZPX2p2Z2FEZHNIbDJmaFl3OUE9PQ==
this is a gamechanga!!,r/machinelearning,Z0FBQUFBQm0yeGJuWThVdDZBckc0UzdlYm9WZUN5Nm0zRnZIYmVtRHpwemNFTUFLb2RkZGJKcHpVbkRKWGk2X0VSOUxadFd2SmpkTFhvbXRXQTFrbWNzeGlKbWJwc3d2bWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuQ002bWNnRW12Skw5TmhueE9WU0FLVEJFcU1PdVdQbGl0U3B2bEVlX0JUOGVibDNjSjhhTTJTWmpyanNYRXR4NVFuUG1KV0U4VFVDeV9DSFNNeWF2d2c9PQ==
[https://arxiv.org/pdf/2311.01343](https://arxiv.org/pdf/2311.01343) This paper was just published at WWW this year. Seems highly relevant. You could also try converting your user-item graph into a natural language format that an LLM understands.,r/machinelearning,Z0FBQUFBQm0yeGJuREJ4MDQzdjc3SWo5YldMNjc3WTcwV2JKa2lyOHJQMjBQNzdrSG1OblhrQ3FRRFo0aUJweDVwVXFtT3B2OHZ5X2pGU3E5cm82QXN5TlJUalZmenVNRkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuN1FoaVBsTVY1d2RYN0hkV1hKREFsN0lBNGhMeEVRVjcxZnFhTTFyWkJaaEgxakVaV0ZXNlVLVjZxbU9mdk03TzBmSzE4M21MS0l2WkFhOWRsLXg4eVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJueFg3bDdzbndjUzE3VWtJOGFOMXZ6dTljMV8wQV8wU2VpcHlOOFdMOE9IZENqbnA4aURzTzdHMEZXUmVETUdUa1JyYloyak1fUkp3aGxWQmZEU1UtdHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuSXhnNlpqQ0Y3cll3T0N1bU11dUhRSmxfektObEY3WmExUjA2TmExOGQxVkVEZ0Iza0Rsbm1wWmdGUk5TeUJQVWlyUXlZaUJsMGt3U2U0dFJUTlAxTHc9PQ==
"How do you quantify uncertainty for an underdetermined inverse problem (ie, any real inverse problem)?",r/machinelearning,Z0FBQUFBQm0yeGJuNThUVUk5eXRZQmNTZ3dGU1dCV1A1dW9pQXZrSVdoUk9CWDZaTXlYSGExWk1Gb0pCU1dkaHhKZVFPWWZnQUhxcnBoSGxGbTIyUWFzWk5MRkdsalpUSVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuN3FQNU9odFltVFk3WDVjdS12Y3BteUtkOEI5Yk1USWZLbWNjbExOZjl5dzF1enZNUWxPYk9zeG1RWU9HRFc2SHBJSVZGb1VfU19iOGw0ejRGMF9JRnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuZkg3TXpHSFNPMkNweGs2YnhnbUFMZHJCeUJiV2YxZFA5cWY5YmRJZ2cxYTJHU0NXRW9tT011RnRualhwNkdQdGpOWHJIaUhKclh4OTJsT0FTRXktb2c9PQ==
"Not sure what’s the best at the moment. But you could try my implementation of mamba for classification https://github.com/getorca/mamba_for_sequence_classification. It’s pretty on par with Roberta etc (I should do some official comparison) the biggest advantage is it’s bloody  fast to train. And because it’s based on mamba theoretically has infinite context length.


Zero shot is also interesting. Meta has a prominent example on huggingface, but drawing a blank on the model name. That should give higher accuracy for the teacher model.",r/machinelearning,Z0FBQUFBQm0yeGJudmJLY292MDg2c0VaSUFwektneXlOQ21SX2hHX21mWkpzNTBLX3o1WDBVckEtUjduc3RnX3c4cXdrMXJXVGF0d1E1UVVsX3hVRFZNemdveUp3c0FtNEE9PQ==
Mac Studio is a cheaper alternative for inference,r/machinelearning,Z0FBQUFBQm0yeGJuOXY2LXNFUXp3RkV0OTNKOExndm9fSW9NMmRUYlFLaXltcmxFU0ZQWVNnZXRJZnVNRmF6alRDdXpHeTJxcUZuc1BvQlBkZU9STGxaSjFDcUN0MTY1LUE9PQ==
"sounds like you should probably be conditioning the model on some kind of learned user embedding. your baseline is essentially an empirical estimate of a conditional mode: are you conditioning the model you are trying to train similarly? if not, that seems like it's probably a likely opportunity for improvement.",r/machinelearning,Z0FBQUFBQm0yeGJuX2dkdVBWQndPSGs4aTZ1WkI5RTdFaHN2eDRzNmJ5dXVrcE1KbThzdVBIeTFfSGdDVVMyS2JMNnhKNHI2T2FMWVg2T19qcWFCVnBUXzBBVFRRRWFmMFE9PQ==
"I did some work like this. You can absolutely use LLMs for recommender systems, however it is expensive and we did not find that it outperformed more traditional methods enough to justify the cost, so we didn't move forward with it. Super fun stuff to play with, and if I had more time I would have generated a research paper or two on it, because we were definitely covering new territory, especially at the time.

4 hours on a T4 is nothing. By the time my model was working half-decently, I was training for \\~50-100 A100 hours (for a \\~300-500m param model). 

You will not get good results just mapping products into tokens 1-1. You want something that looks more like a grammar, where multiple tokens describe an item, and the tokens that describe the item have some sort of meaning and semantic to relate them to each other and the item, sort of like how phonemes make up words.

i spent about 2mos fiddling with this problem nearly full time. It made a cool model and data pipeline, but ultimately not enough ROI to move forward.

You are starting in the same place where I started \\~16mos ago with this, but if I were approaching this today, I think I would take a pretty different approach. I would start with a pretrained LLM or VLM, and try to bang my data into a form that I could use for fine-tuning, with as much preserved human language as possible, instead of making a new token space.

There's just too much information lost boiling items into tokens. One important characteristic of modern recommender systems is that they understand the items on far more dimensions than user<>item interactions. LLMs are perfect for this. You end up acquiring a new problem, which is how to map your generated (hallucinated) items into items in your ID space, but I think there's other ways to handle that with search algorithms.",r/machinelearning,Z0FBQUFBQm0yeGJuejFUYm1VNTI1SzVMbUswOUVuRmswc2dIUjlEbk1BTmx0NUg0RlpvMExuYmpFUUFTRTZDZTRTZjhURHNWLS1URlRfZU9XdWZtVnJSTlp1UkZkcGQtcWc9PQ==
"Out of curiosity, how many students do you think will  actually apply to this competition?",r/machinelearning,Z0FBQUFBQm0yeGJuOU9DTWRUeEhYN2JNc1QyaGRDYlBzcGRZV1R1Um9kV29XNTh0YWZQU19STElmLTBNV09aTXpGTnBvZ1E2dWxZOHMwRzE3dmVlRy1yOHRZT0JjZWVfVlJnbzc1ZjZpUGx2MUJxN1BnWEVCcTA9
"FWIW, I like to use nvtop to visualize GPU utilization.",r/machinelearning,Z0FBQUFBQm0yeGJuVTVVWW01WmhwWkVhMW4zclFsRGFscm45bTV0S1hIOUl0dTM0NURBWEVhcFdTWmp3blhBbWlhdU80cGtqazRiOUxMN1EtNXdFTFVKT1dZZjlpY1RkZHc9PQ==
"Hmm maybe it's the startup culture, but we have incorporated it into a lot of our daily stuff

We use it wherever the older tech was cumbersome or inefficient, and when there's another person interfacing it

We use it for preprocessing and fast analytics -- lots of unstructured data? No problem! We've got a simple upload data -> summarize API!

Analyze interesting insights and improve our knowledge graph? We've got an API that be plugged into the KG, that ingests the data as per the ontology for the kg!

Few shot classification? Sure.

Data tagging for traditional model building! This is our prized possession. We built a framework to tag data for us when we don't have enough. Faster than humans, not as accurate, but it eases pain points

We're currently building chatbots with analyst capabilities too. Lots of devs use it on my team (me included), and all of us are geeks so we love experimenting and playing with it. It's almost like a pet project that responds back. It's fun.",r/machinelearning,Z0FBQUFBQm0yeGJuRzEzZ3Z1ZHpqbDdnRFdzQi1LN2ZwLVU0YTZfYXRreTNpdFViMkt6U0pLZFp1VDRjdXlqWE1seEx2WGRTRlBIeGdleG4yMlEzbWk3RFJzMW1DVmJCRGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuR2xDUFlzVU9GNnlfRU0tSlllR0lycklBd2pxVHpLRTZFSkpqdnFfQmV1a18xc2RFcVd0b2JFWWNBMmhWMFd1eXVVZlF5ZWcwUTl4cGR1cjVSaWhrWVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuejQzNVVhR1hURmJjenRoQ0RNRGR3MDZPQVRPV01Rbl9KZ0pKS1VTaGZCN3lzTVpDRjEzeFZ4c2lOT2RhOS1sNnZKb2JEZmlfR1lNYkxBRlZKOEg0YWc9PQ==
100% this. I have multiple work flows for this and am in the process of automating. ,r/machinelearning,Z0FBQUFBQm0yeGJubHdOMHM5TWtURXZZdjVFNE1GemZHOGVPdGlwWDRydVdLUUg0b3ktUTR4dHc5RG5zRlhEZC1jX0ZhOHFtYUdodFRvc09JNjdXZlprZzQ0eGRkanphRmc9PQ==
I find helpful because the problem that I usually face was writing block and that's the reason why I used to use chatgpt but with blainy I find it very easy to write because it suggest lines while writing so you can get different ideas from that and can write the paper easily and also it's citation feature.,r/machinelearning,Z0FBQUFBQm0yeGJuT0ZhbjNCdlpxMi1xZDNOQzhWY1pVWHRUOVJseDg0dDhMTlBwOXhwRUc4RHZQQmVjNEt0Qkp2WWpNa1dCanpjLTBLMjNaYy15OU1GUVdKbEpiZS1NOWc9PQ==
"Thank you for sharing!

Can you share how much better your final is compared to a) Simple baselines like popular products and b) Traditional DL methods such as the two-tower model and/or Graph Neural Networks?   
  
Currently, at 6h of A100, my product\\_id-based model is still improving but nowhere near beating the baseline, so having a goal to look forward to would be good.",r/machinelearning,Z0FBQUFBQm0yeGJuQjBKdTFGLWx0elJVOUZfMktzS2ZONUc1Z29XN3k2SjdnWmVUZGdxNllfWDd0QWhDTzMwUFFPSWV5ckZGUGI0Q29EZHVVMER6VmVXLUwtT0pXN3hqamc9PQ==
"In addition, do you mind elaborating on ""something that looks more like a grammar, where multiple tokens describe an item, and the tokens that describe the item have some sort of meaning and semantic""?

Is this an effort to reduce the size of the vocab?   
  
I also have the idea of using LLM to predict the shortened product description (which uniquely identifies a product), but that approach would not reduce the vocab size.",r/machinelearning,Z0FBQUFBQm0yeGJuSGx2M0RGYXl2N1oxRGFsZDZZdGdHOVRsR2hKTGZjcVpjVzJQcXJkZlJnNGdDQV83aW1QR0NhRlkyZWVPNm5qWEFrUEl4NWxTQ0lxTEtIbDdSME5IeHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuUzhNekJLS29PU2lKM0RuTloyUlVqaEE2QzJHc1REM1lxZDNJUl9HcU42bmo5UlNhekdDR0ZCcGR5aXNsVDNvVnl3VFV5LUFlQ1dkeDh6RmpXYlFiWVE9PQ==
"Yeah, I totally understand. Yet, exploring all tools is the only way to know which one is good.",r/machinelearning,Z0FBQUFBQm0yeGJuVW9waUZ0ZVZiY3RFLW4xeHBrcnhVRXdYQzJfNThVN2NPNkRPNzFmal80SzdfYlIwYTR2ZEptWnN4YXp0Z1I2UDk4T0pGOVdzdnAxaEtyZmUxOTgtTFE9PQ==
"What worked for us, is describing items by it's properties and building embeddings based on that rather than using id mappings. However, you don't need transformers and I doubt that they help until you have terabytes of data.",r/machinelearning,Z0FBQUFBQm0yeGJuUXZPUHFYeFh1QlFQNVpLS1RyOTBLaVoyLUFlRG9kY2ZCaWtpSE9FRl9zcU1uc0Q1cEw0OXVDeERJQjZ1VnpvMkR2b0U0UHlzOHQxbWpicExrZjU5cUE9PQ==
"Chs 1-3 are, under the ArXiv link in the post",r/machinelearning,Z0FBQUFBQm0yeGJuSVk4R1dVcFRBVnl1eHNQNGZ6VXl5VmFpcWFXWlZEY2k4cGozZ1lVZk9INWwyU1FrM05Icm80eU9QQk5pV0c1cWNDR3pfcVJwVTM0TUxEcEtwYXVLWlE9PQ==
"The only reason to get A6000s (vs. ADA 6000) is for NVLINK.  If you need NVLINK then you probably are doing some sort of distributed training beyond DDP.  Then your model sizes are probably large and a local A6000 instance is not going to converge in any reasonable amount of time (assuming your dataset is just as large to feed all these parameters).

A single A6000 is useful since some models don't fit on 24GB, but I'd argue its cheaper to rent for those rarer use cases",r/machinelearning,Z0FBQUFBQm0yeGJucW53U1FEZXlhaEZjWkNGZ3JXOE5MQm9VbnBlUERyS2VucmJPQk1EZGhRUnJRZjVURW9qd3JkWHV5X1FhcDVEVUNXSHBrb2E2TzNNZWh3XzRud1pyOEE9PQ==
"It's Human Action/Activity Recognition (HAR), google it (or on google scholar) and you'll find a ton of resources (papers, videos).",r/machinelearning,Z0FBQUFBQm0yeGJuazRQUzUyMjFJSTY0UzRTY0wybzhVVEY5RW0yb1F6MmdYYW5CUE1kNmc0Zk5vRTQxa1llSVBNclJERmVmY3RDRDAxRmx6UkhweUt2S0JUeWw0MzNPWlE9PQ==
"Yes buddy , it is possible through computer vision . Since you have a dataset to train, you can use yolo V8(position tracking and zero shot detection) to do the same. Not sure about the algorithms. Will add them in comments but it is possible .",r/machinelearning,Z0FBQUFBQm0yeGJuVlM4SlEzX3A2dkxCX2R2UmdJY19JRmFBZGx4Znc2Z2hjR3QwdEVKYllrSkVYSnctamYwbUNUUDBjSUlUcUNkY1BoOVVPWE5aajkzRzdBOVJESDdnblE9PQ==
"You specialize in what you work on, you keep reading stuff to have culture about what people do / what exists. If at some point you have a specific problem ""oh, I think this field has methods that tackles this kind of problems"" and you know where to look and what to look for as an initial search keyword --> you have an entry point in the relevant literature.  

I believe tryin to specialize in everything is counterproductive.",r/machinelearning,Z0FBQUFBQm0yeGJuZWJoZXQyWV9Da3pYUndKRTZURHFQRVJPTFZpaEJOR1JBYUtiS3NuLVZ4WkF5R2wyY2NmZTVORmg2eE04THdJZkZqc3U2QktyZXJrbE5jeG9wS1ZzSmc9PQ==
"Single frame action detection isn't reliable given how actions are defined heavily by temporal information.

Most actions detection algorithms are done on videos e.g. SlowFast, EVAD, TubeR.",r/machinelearning,Z0FBQUFBQm0yeGJubmNlTVpmSFNyMWtzZWhFZW5aY0RBQW9iNjFRV3docVAyUkp6X2x1VHdVdnlzVThTaDRoWDdnTW01bVJKM200TXY4NGwya0xSS3FDUDU4UC1KVUx6RElCWVNfQVp1NWdlRndxY05HRU9vS3c9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJucF9odlJLZ2hVX3h1N2Y4NzB6Q3Q5QkVqMjB3eHR4RXhFTEM1SGpEOTNXSzJNLUhwQ2hqak5abEEzR2NVUmN6MTRhMGlITmdUWWZBVVdOQ29BYUhoVVE9PQ==
Sounds pretty similar to my experience as well,r/machinelearning,Z0FBQUFBQm0yeGJuNmRFekN4Z3Rkd2tWQ1FFNWxCXzJNdEhtcHV6RHJZN2tfc185d3hSVkl2LS10SmJOSndaVnMtdFMwUXhtTEZFWG9iMkxabm5qZTFTeDRpaFczVzkyN1luTEZxUGZBRnRPZWUwSmphMklJcXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuaG9hWWZxNGNqc0NTZzhFd3htYUNnSkJleElUUWdabkprbGQwUjVETlBWMi1lbE1JcENIeTZqYWpLMENUVGtlNmQxTEgyWm1MRTZVUlJYTVhpUE92TGc9PQ==
This is the way…have the initiative to try…and the humility to ask your tribe for help when you get stuck.,r/machinelearning,Z0FBQUFBQm0yeGJucHB6bTZESjFXdnVMSFBSZ2JELS15dXVBSUZ2ZTM5QVFoZ29pU1JRNEhQa0t1NWRIRF8tdTdHS1BMbTg5M2dxMzlwNW5iUnBhclBmOWpEZnkzUHBnWHc9PQ==
"Thanks a ton buddy , for clearing this out , was bit confused 🤔",r/machinelearning,Z0FBQUFBQm0yeGJubDhreU1HWkpPTGVoUnlpSFZVd2h6Q3JoMVdIcFhybVpQMEZETVVrOWlZOVdHeVM4VEFSVzVQcGUwQ3VHWUFobHBDY294ajhkR1hrcWotMlRPS2RTbGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuYlBuNlZ4UFBVRXZINEJDbTNWRlFuNmVaU0VOWUNnaHJETnM2Z1VEVkRLUWZ3eGFrTXBnSzF6aTlZTzlGMmVKZWIxQmN6eGV5UjZJN1B6cDhpb1ctc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuNjN6V0tVSkYtVW4tb21FRDh6Q2l4ZnFyU3VTdXhabzRYVGdNaExOX1p5ZmxjSTVpN3BlclVTYU8zUmMyUmlDNFlmY3FkYkFydENQaDc1UV9HeHk1X0E9PQ==
"Hello!  
I am now thinking about moving to US (now in Finland) and work as ML Scientist there. Could be helpfull for me if you name what reasons stops you from working for a US based company.",r/machinelearning,Z0FBQUFBQm0yeGJuUHJYb2xXN1FQNXJkZnBxbzJQWllIV0lnVXlrektGMTY3NXliazVqNm9Gb3o1Zkhrb1hRdmNnS3EzWnhvVHBXZnRYTHNhcW1IOGxRUHE2TDFtaXNMdEE9PQ==
It can work with off the shelf LM zero-shot [https://arxiv.org/abs/2112.04184](https://arxiv.org/abs/2112.04184) but it's better to use tailored architectures,r/machinelearning,Z0FBQUFBQm0yeGJub2RrLTJQNGtXQkg2YndMYUE3eG5CLXlXbkpuemQ4NldGcjAydktNOGVnX05tc1djVzN3eVItWHVJS04tVTFQbkxzVl9tMlNBWjcxalFWdVQ0d0tBQ0E9PQ==
"It worked with a word2vec architecture, when using user sessions as context.
[https://arxiv.org/pdf/1606.07154]",r/machinelearning,Z0FBQUFBQm0yeGJuaUUyaEZLVGI2dVcwNmxrV3J5X0c2YlFLQUlHSElsakpnTnVaUkJqUlA5SldVLUxBMGhRclRfMnhJdVRQZzZxcnhleXc3ZklRU3FzZGtNQ01CSmY3OWc9PQ==
"FWIW, I like to use nvtop along with tmux with multiple panes.",r/machinelearning,Z0FBQUFBQm0yeGJuQ1AxMnRzYXIwWkxpVl9tbXJwX0t2ZUNsTVBiR29mLUs2Yy00akViOC1fQ0IyckpIem5wVkNOcnd5cTBjSkEwdUdhcDlJVkM4SlNSV21KQ1ZNTXFXeFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJud0h0OGY2UElkWlEzeGFwZnNIYml6SGVucVp1blNzQl9TekdXNWpSR01DWUZvWWllb3R1WjVHUjliSjdVd25ZSnZPajFzOVdYUUs4LTEyRVZpMWVtVVE9PQ==
Are you sure there is no data duplication? And are you sure the labelling is consistent (no more labelling error in one dataset than another)? If yes to both and they generally have similar statistical properties it's worth trying.,r/machinelearning,Z0FBQUFBQm0yeGJuajJFTHhTU1FLaF9mRFdSbzlFeUpsVUtBWnN1Q2MxQ2QzTFJEY2pid1RNaTczcDFOaGdTMmRzZGk3eVpLcG1Ud1VLNFdRNVhhMXlFb25GWGNvam1obkE9PQ==
Keep learning as much as you can. Try a RAG approach to interact with your notes. That should help greatly,r/machinelearning,Z0FBQUFBQm0yeGJuUXBqbjIzVGdkR3ZvMmhxb2NmVThCUE14MENuTEw1eGhaSFZYRzIyNERkZ2hobGpKcV9tanZFRWVUWXFHOWhFRVBGN2twcDFWZFN1b2hHSVFDdXJqUTBsZlBGYUxMZldqVFhvMnRVSWJxekE9
Cluster the users by their order history first. Then train  model using signals from the cluster. You’ll see different pockets of popularity and this will be key to beating general popularity,r/machinelearning,Z0FBQUFBQm0yeGJuUFZQeldTZWo4UkszbWV1MnNEMjQzRWZhQjNOUXVzTFV3aThkdnJnTGdCOTV5RE1IRzUxMU5hRl9VcnN6b2hSQWF6QXU5VDk0Q1dBRW02dlFDRUZrREFlcWFHMUY5UmZWLWxlSTdnYzNkbTg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuTjg3d3pudzREOVlJRUtvSHBPNjB2bmR3NHd6aVlENk5TbzVhZDVkWHU2amZiOHFfcG9wWUNzZ2dfRDJUeHNIc0pHZTFxOFlqZ21Hamt4ZUlIdUo1RXc9PQ==
"Hello everyone in the community, I am the author of Apollo([https://arxiv.org/abs/2403.03640](https://arxiv.org/abs/2403.03640)).

We are currently building a medical evaluation set covering 12 languages. Because some of the evaluation sets are translated, we need the help of local language users to evaluate the translation quality.

Specifically, Arabic, Hindi, German and Portuguese are the four languages ​​that need to be quality checked.

The whole process will take about 15-30 minutes of your time. If you have the time and willingness, please contact me. Thank you very much! We will acknowledge in the paper. If you are willing to cooperate further, feel free to contact me too.",r/machinelearning,Z0FBQUFBQm0yeGJuNHE1aHRIOVltSWZoX29WQ3dxUFpTWHNhekR6bU9KRGJ5ajMyYVRaQzgtMUh0YlVodXViMTdLU1Ezd196MEhiaGJGSWRjSWNnZG5MVEdmU05NSWdrZmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuQzN2blh3NTFVYUUzQU54M3pGUm51ZmgxaDRlZ25LOGtFLWwwZDlUcTdQNTA3N09uN0x6MTYtQVlwUGRjSUQ3TjFCWVhSYjlDYnI5T0dYOFVPQXpwRVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJucnZvaXduNlo2TDY5NHJBMG5PbF9fZVBDYThka2I3dml6NDNCR05Fb3pFSFItRzZiWm02eDdtWW9ZOGpocEJFdnlTRkNUZDdWdkZ5amhUWGZPSEdyQWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuSEZacmlQUFVPcjRtUks1X0FOVEZKWFB5QTRkS3dMbERybFJER19lWUV2OG9TMW5BY3VsbDdjXzBzQ3hsYUxKYlRzU2NCYlVhZTBLR0kxQ1lOWlpVOGc9PQ==
"I have worked extensively in recommender system couple of thoughts of mine.  
  
1. The Data Size is way less No of users that is 200k is very small.  
2. Reduce the no of parameters extensively and then do study with different techniques or tricks see which technique gives you best then perform a full GPT size model training or try simple models like LSTM or word2vec first.

3. I am assuming you are finetuning the model since the batchsize and learning rate is very small and using product id as you token.  
a. if you want to see whether decoder style architecture can capture user preference try to train fresh rather than finetuning with product id as token  
b. If you want to finetune the model then rather than product id as your token make product name as your token and try with that also see if you can incorporate other metadata regarding the product into your model.",r/machinelearning,Z0FBQUFBQm0yeGJuVTVNMlNlV1VzTGVYZE04UUtDMnRNNzhVSkhSRjVTVlQ5SC0zUFNUdUpQUzBvNlFJbFAxUmhXVTJnaFY2S2x5Q1dMdk9RQVFZQ3Flc084UFZrYUhlbDhjYkUtZVY1MThSYkJ0QmY3c1Y3Qlk9
"If you are encoding one instance at a time, you could try batch encoding. Ensure you are using the no_grad context so you can pack more examples into each batch.

Edit:

You can also speed up the process by using a sortish sampler and configuring the data collator to pad either to the longest sequence in the batch or max_length.",r/machinelearning,Z0FBQUFBQm0yeGJuTjVzVGFkbU5ET1pyWW5GMFN0UTMzVFR2SGlSV25vYWdkYy10dGJLTFVpWFA4R0NmR2RXOTFycVN1MU53RWF2STRGdnl5dVFpSXltREw3ZUNFaDVjZklkNEVaQlIzX1pyZUp6U1hCNHdQMFU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuWWdLaGZJN1FrVklIMVh2S2JKTkhoVldvT3JrdFNmT2V1SWdfMktac1RhUFhHTFFLMnVuMkx0TzdlUDczUkZIZXhtWUVNTUdtb3JoVmd3bk1LQnJ5RHc9PQ==
then why you answered?,r/machinelearning,Z0FBQUFBQm0yeGJuSlY1T0h1d0x5WnlSOVAtUXlfcjE4ejM3aW5GZlBqWUZ3TkZlXzE3MWxDQ2oxdlQ3bDM0Sm9sOFo1dmtoMzVXSURMZVd5M1N1ZjhUeUhUSE9vdEhScC1QUENwUjFUQmdjVW80LXNqM2ZiTU09
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJuNVhvb29oNmY4QkpYLW5rTUlIQXFLUnc4UmJUYk82UGFwQmdic3NCRjBCaHpJdGJlSU9sR2NlZy1jNVl4OXNxQ050Y3UzcU5ETE9aQUZ2QXVueWlvVEVxUXpzVm4xcTI3Wm80Tk1MNS1OXzg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuX08yZnprVDVhcUNuUzNyajhSNExILVFwZjhqcVh4Ym14djg2Q2ROdWNqaWxGR01aZ2lzRHk3ajNtUjhzY2N1TXI2MDdLV3gwT2pFdXNhY094aWQ2d2c9PQ==
"Thanks!

For reference: [https://github.com/tensorflow/tensor2tensor/blob/bafdc1b67730430d38d6ab802cbd51f9d053ba2e/tensor2tensor/data\\_generators/generator\\_utils.py#L623](https://github.com/tensorflow/tensor2tensor/blob/bafdc1b67730430d38d6ab802cbd51f9d053ba2e/tensor2tensor/data_generators/generator_utils.py#L623)",r/machinelearning,Z0FBQUFBQm0yeGJuY05JeUE5RTZJRVVCVDNxYU1HbnBTeXlyX2xkb2pEUXBnSWEzOVJjcWV6V3VFeXIxTVBweXVtS3ZxZ0llVlc2SFJnZDFBbzV2WjhhVF9GRGlYSlpzaXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuU1lpTG92YWFDMzh4ZzVTcUhHV1NveWVDYkFJQ19ra0hLSEJlamkzNHN2NG0wdlVoMzlMejdwSkF3SEh4SjNDUXJoZ1JYNVR0eW5sdjgxazhlZ0dMR1E9PQ==
"**AI Leaders: Guiding the Big Picture**

Non-technical figures often lead in AI because they bring a different skillset:

* **Vision & Communication:** They translate AI's potential into clear goals and secure resources.
* **Business Savvy:** They understand market needs and how AI can solve real-world problems.
* **Team Builders:** They attract and retain top AI talent.

**Coders are Crucial**

Researchers publishing groundbreaking work are the backbone of AI. Their work is recognized through recruitment and paves the way for future applications.

**It's a Collaboration**

Successful AI requires both technical brilliance and business vision. Recognition might not be equal, but both sides are essential.

**The Future:**

The balance might shift towards more technical leadership, but strong communication will remain key.",r/machinelearning,Z0FBQUFBQm0yeGJuc2xIWFVfTHRqaXJHLXdTeXZoSUM3aFRBcFJvYmVmVTg0UFJoVjNncTFPYnM1N3RHTmM1UXMxYjZ3TWp0UENIY29ySFpCTGZZeU15eklBa1lfQld4Tmc9PQ==
You can look at xLSTM memory cell for your desired behaviour (1). K != V is weird.,r/machinelearning,Z0FBQUFBQm0yeGJubF9zTEZyUWtPRTktS0g3YWdPM1BQS3lmZkpsSG90Q016QUFEdHZhM1I0Nk4wUXc0MjBqYXNwLVotT3VuY3VNazd4eTVBQUtiQlp0LUdBd09GUzZYZXc9PQ==
"My guess is that it's a conceptual mismatch 

I can't see how the logic of self attention would apply to these synthetic sentences",r/machinelearning,Z0FBQUFBQm0yeGJuekw0MTAzUFA2VkJ6Y1k2YjlPNXBWZW52Z1pvcDV0dDRFM1htMnhWdW9IMVJ2cnkzT2FjTk1vM1dkVmtnSzFKVmtCcUgyeFNNWVBmN2JYbEhneE02a2c9PQ==
This sounds like the problem to me also.,r/machinelearning,Z0FBQUFBQm0yeGJuWm5VanNvVnBsWmwyTFJZa1VfUHAtVkpSMW5ENW1DMEtfSllYbk5hQTNYUmJzZEdZWHdmNlM1RXdmZUV0YkZkRVFMdUxoaE5Yd0xKa0twT3Q5MWFzcXc9PQ==
"I didn't ! 

How would you do that ? A Simple dot product between mean of embedding for query and the document/abstract ?",r/machinelearning,Z0FBQUFBQm0yeGJuRUVoNm9FUy14OGRSc3ZDakhHd1pJeDR0SGpHLUFkU05rS05fMlYzcGRWcTdDLU5CeXNmdWIzSlJBaFJHZzcyR1hjVkFBeVFaaGt4cDZyMHpxbzd3Snc9PQ==
"Thank you, I'll give it a look !",r/machinelearning,Z0FBQUFBQm0yeGJuVTI3S3hTU2tNcFVndGM0Y0czY3cyc254anhxdEg3WW1LdDBRclZrZFZfajZSSjZMeGF0cDhyLUVlVGtwV3NRNXNVNE96Tk5iUmYyVldJQ19DYzk4dnc9PQ==
"You're indeed right, in machine learning K!=V. In normal non-differentiable retrieval systems (databases), it's very common to have K!=V where the key is a key or an address and V is the value.

Thanks",r/machinelearning,Z0FBQUFBQm0yeGJucHE2akpORUxUZ0RvZnJMek5rM3hRbjU5UE94TEVMYmdFTjVhSmxGRkl5VVhiQXI4LVRfMWlKeE5SWTNOc0ptazhEVkZfOUF0SjRkXzlESEp2Um9mYlhvd0FmMDUtX2FoMFlFb3lBVE42MWc9
"Since nobody mentioned this yet:

Mojo is immutable first, like Rust, and unlike C++.  
Many feel/argue that mutable first is a major design flaw of C++, or any other language for that matter.

It's still very early-stage, but I'm betting a part of my time on it.",r/machinelearning,Z0FBQUFBQm0yeGJuZzA2cXI4VDExVy1PZ1hmZkVqX3N3YU5BU3ZPTHNQQjFEdjlDZGRHbTlGcWppZUdLbE9QYk8wTUpFbjVQVzdocU4wdUtheTZXOHhLM2xjV29ad0ZDM2dLeVB1aUd0dU40VEl2d2tnS1RCTzA9
"Interesting. What is your rough estimate of the language to be mature enough (excluding sufficiently many libraries)? I saw that they recently dropped let, which makes sense when you read about it but a major change nonetheless.",r/machinelearning,Z0FBQUFBQm0yeGJuTW52SmZFT1pua2lZTmdZQkhJU0VQUm4yN1FqaGZYQ0JDZFpwdllZQXFpZEhEUkNxOXdYRTJaWmt0RnY2S1kxTUZTQ3BNYmNyeWhiWmR0MUVMLXFpY0E9PQ==
"It seems no data is duplocated across the 3 datasets and I had to relabel the 3 datasets in order for them to be consistent
Though I have to resize some of the images because their width and height is not consistent. Can OpenCV already do that right? And with interpolation I can resize them to bigger?",r/machinelearning,Z0FBQUFBQm0yeGJueXhRUTFvUkhQWWo1UTMxVDl2SC1PTl8zbXh5SFpmSkZlbUVDNk1iZGNsdWNaNldsc1lvRmFtNkU2a19rNE1pS0JPc1cxQnNLOVpIMFZ2c05panJCbFE9PQ==
~~Tits~~ Tips is all you need.,r/machinelearning,Z0FBQUFBQm0yeGJuV2JRdUZCbFdiWjVoU0poakdITXYxeTVuZWlpcERlc3pSOG84UFpzOHBMX3RIS3RHNUVRZWxzZTZNa280bkZ3U0xGX3dMbm1RU2lQNW5sS2lBYVhDanNERXBqMF9FdDZVRE01Q0o3aTlpM3M9
I have [also parodied that one too](https://jabde.com/2024/02/04/chad-defeats-ai-boyfriend/),r/machinelearning,Z0FBQUFBQm0yeGJuZHdOR1dGejE0UXo5ZDBwZ2d5NG1udzhjNDlhTkcwZmloUENVLVF4VElQVGpBRWJOWXVJRWxHbTNZa0dSUmxERTR1WjZWeEJoZngySkhaSHJ4akEzWGxqUG9pZElYSDUzanVyTzlVYXp2X1E9
I’d also go with renting on this one,r/machinelearning,Z0FBQUFBQm0yeGJuSlEwUXItdGo5MXQ4eHRWWjhMUFZ0ZnAxVTF4T05pcmZZMFZ6dGJhWmtiVW9WbldSTVh1SjZSYUs4MTBaT2pJdEVVV08zSmlwZXB3RWtBN004bER5Mmc9PQ==
"LLMs are just a models used to predict the next words/tokens that will mostly appear according to human/coding languages. For a ""similar products"" recommender, I would use a LLM to tokenize titles, technical specs and description data, then vectorize this data to assist the recommender.",r/machinelearning,Z0FBQUFBQm0yeGJuRmZoT1N2ZUFodFk2ZlRuRmNXdThzLTVhWTg3eE5Iem44TUpNOTJIWTZNZl9QU1BMVVc4NlcyNnR4aVRiS0hlN0ExTjh3NnUzZ083M29RRlJYclZvd0E9PQ==
"this? https://tangles-book.com/book-pdfs/ThreeIntroductions.pdf

EDIT: oh, you mean this https://arxiv.org/pdf/2006.01830

in the future, you'd get more eyes on your work if you actually linked to it directly. If that was your intention, the ""arxiv link"" manifested as just a plaintext arxiv code in the post.",r/machinelearning,Z0FBQUFBQm0yeGJuNE52Uk82RUdEUndNOXdpcVc0TXNqT1VTbUtWb1JibU5qdnd5c24xUDFCeTBRU3EzWm1HakxfWHpocFVBOUxBUkVLakFfdnJZTno3bHk2bFcwX2N2c0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJudUJpZzdmeU5nRTgwbGNjY01GWXNmelpJbXI1U2dqYUdBbkRTbFFOZ2NxU3dRVHp3bGRaX0Vkc0JMelJ0d2taU3Myb19CMzdZN29ZZjJ6Q1RpSkdwelE9PQ==
"I think it can be applied. They already did that with claude sonnet, which is multimodal",r/machinelearning,Z0FBQUFBQm0yeGJuaE55c29rYjZIWnpuOWVUMThoYnYwLS1DaTZqdW1USy1ScndrQTQtQXIwVFJ1bDViRmRyUXd4VmQ0eldCaXNYZWpoUEc2d3NIamNsYTNLRUNFNWgySVE9PQ==
You are aware that you would need to self-host such open-source model and depending on your scale that could be more expensive than using a paid service?,r/machinelearning,Z0FBQUFBQm0yeGJudm9RN3FwWktKTmVRSC1iVWJuUVNoaFpUNExsR3NnbTFxaWlGVmt1ajcycUJHWUJ6X3JQWXUxWHhFTi1wWXdRNDVHbjRTRTNIWkZOaTAzV3Z6NjBXcXc9PQ==
"I think a question like this might also be well suited to a community specific to the topic, or an active/friendly discord of researchers like CoHere4AI. Their discord is a good place to ask things in my experience",r/machinelearning,Z0FBQUFBQm0yeGJuR2t2WjhOS3RDTUh1aWU3NDloRks4ZFFaSzNDakRNMDFpZkUyUzVmbkkzLTdObDE4VmlVRDJaczFPS1pINlNsOGI1bEJHbjNJT0VPM2hwSEdCelJPMEE9PQ==
"From my experience, quality of writing by translating from non english to english is still not good enough. I recommend you to write english and polish.",r/machinelearning,Z0FBQUFBQm0yeGJubk54Qk4taTBiRjNjR2MzMzlwdUNlQ29YU09QcmtCWXdDcTU4clZWYnpaNGx3NnhYWnZYTHlKaV9SZl9Ld3FsZDhQS21pck0zZDQwblJ1YXlTOFJYRUE9PQ==
"Update: I used [yahma/alpaca\\_cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned) dataset , [phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) model and extracted all the activations of middle layer(number 16) and uploaded it [here](https://huggingface.co/datasets/jayasuryajsk/alpaca_cleaned_activations_layer_16) . Next step is to train a SAE with these activation values as input. I was using RTX A6000 - 48GB RAM on runpod and its not good enough to train.",r/machinelearning,Z0FBQUFBQm0yeGJub285SWEyV21TeXhZbXY0cXAtRENKZXB1aWF1amxnX3hQcDRETDBYdVdac1NPUkYtLV9wVkRYWUI4cmpkSUpmN2ZBOFlyTEtGZ200R0pBMmFhNnpqQ0E9PQ==
"Check out where people in the field of algorithmic game theory publish - people like Tim Roughgarden:

http://timroughgarden.org/chron.html


Or Noam Nissan, Al Roth, etc.

Seems like it's all over the place. That said,  besides the line on your CV, the point of publishing is to have people read and care about your work, so think about what avenue is best for ""marketing"" the paper. Sometimes other avenues (a blog post, open source library or non-academic seminar) has more effect than a paper on actual idea sharing.",r/machinelearning,Z0FBQUFBQm0yeGJuRVdKWnN6ZFNJbm5ZendDQWo2SWJ4cDdvTUZZczhIRWMwaU9XTjhWbHZUU2N2TFU0THRYOXZpV1pZV1RVRDJiOUlmVTVPVWtSaWQ3M0JHaDZFdmFVbUE9PQ==
"It’s not entirely fake insofar as AI is perfectly capable of creating and communicating in a new machine language because it is highly adept at mathematics and pattern recognition. This is not news, and I have designed circuits with fewer than 100 discrete hardware components that can do the same with analog phenomena. The fear element of the “article” is likely fake or exaggerated, and I believe that it mirrors a widespread societal fear of AI. This is not unjustified and will only increase over time, along with fake news initiatives to sabotage AI because people are threatened by it. Once again, ignorance and fear are powerful societal themes and will shape how we enter this new AI future.",r/machinelearning,Z0FBQUFBQm0yeGJudzU2R0E2elo0emswNnlLQXRVT2tXamhVRnVaa1NxUEJfb3lydGwyelM1UklHcWtBTGx5Vy1abGktUG9Ha1NIUkdIVVB2XzQ2bnh5ZzF4cVJpNFoxdlE9PQ==
matching theory?,r/machinelearning,Z0FBQUFBQm0yeGJuMGV3ZF9xNFV5S29zT2REalEtRVA2Rmd2bWRjcTZmX1N2MWI4b3AtQjBIYjlVSzZNcjAwRDJPbkUtcnVoVzUwaVFIUlhTcGFRV3dJSm04SE9aWEtrUEE9PQ==
"Is there a way with CLIP to find pictures of the same person, same animal or object, for ex by isolating the relevant part of the embedding? Something like: query vector = cosine(average(e(img1), e(img2), …), e(""person"")), or maybe similar to textual inversion training (used by SD) where one or multiple vectors represent the thing. Maybe you have other suggestions: models / techniques? Thanks.",r/machinelearning,Z0FBQUFBQm0yeGJuZXkycTRQTnlxVGJQTFhWMUVzMXFjeVFGR3pOMy1LSTZYVVpoWkE0RExJS0ZrQmNFVW9KeW5kWVBpSHNfeThBQUFCSTFqV21aSVRQaGtZU0JZZ1NQQnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJualV6R1F5M182dkFVcUpaanVXalJNa0Z0UDl3M1hlajVFYVRfYXpQQ01RM0Y3UkhVaHVwZ2hGOHBmSVBSVFhNaDZqLU9fT3psNW9QdS1PdWlmektmU2c9PQ==
Hey,r/machinelearning,Z0FBQUFBQm0yeGJuTEFybDA1MUVaNTdnM1RweTVEUHpvOWRwX1FveDZ4M05VcWtWakcyV1FqNTBVelByWktIUm1Qbkx0UzlsS1BYdWRGR2dnWGFlQWZYVmVvbFgzdDNPbGkxOWhQcnhYbFVFSE10NGVlQVAzWWc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJuMEQ1bzE1MzdKb3BWc1NJMGljbVU0QlNNNTJ3eVMtX1JXZ1Zrd0F0SF95cVcwVXNlQ2hoMlpGekVIY1ZlVFNMWE5FcjhGandXVkxZbmlQdmhWbVpYdWdOX1VZWHhZM3hHY3V6X1BfaGR6Unc9
The title sounds like a Nekrogoblikon song,r/machinelearning,Z0FBQUFBQm0yeGJuRGFFU3NoOGhQWkNKT2ExUjNuNHpWSWVab2NSMGpiZmVjZEU1LWNMRktnQUpiajUzcUs1YVA0c2I0NGM1WEhFQVJTSWdZc3RLcDhwUXpIS285aThMZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuYjIyd0hFd3Y3TV94N0tVeHpBOVAyM0dsMkFtakpKc1B6WFJ2UmVIRjR5eWtFWUtzdjZ2TklKNS1WVjRxTjgxNG9ENVNKZURrTzlaQ3NwTFhWMjEtQVE9PQ==
Is that like a spell from a fantasy novel or some sort of metal core band?,r/machinelearning,Z0FBQUFBQm0yeGJuTDBURVJoeFVUcnpUdHZMY1JxckYydnUwcW9TdmdzWURGb2FBcUFOdzFQdzZDak9ESFNzVkdzdl9BQkZmRFktamhaQ2QydXg3emFmOE1lZTFrNUVmajBLd2k1bGFCcDRnYVhmU09fMF9JeEU9
"I have been working in recommendation systems for 8 years. 

The personalized, top popular products from the user's history are a super strong baseline. Not like in normal ml where often a baseline is weak. 

People literally do the sane thing over and over again. I started to remove this behavior from training data since it's all most models learn otherwise. Input = output.

200k users and 50k products is very little data. 
You cannot learn a big model and huge embedding with it.

Start with simple embedding models that allow fast iteration and work your way up. 

I recently tried gensim word2vec with embedding size 32 on a 10x data set than yours. It learns in minutes and gives really nice embedding. You need to check how many updates each item gets (how skewed the dataset is). If there are too few updates or the cooccurrence signal is not strong (e.g. 10 times product a with product b VS 10 times product a with another, different rare product),you don't get good results.

So gensim word2vec is a great start to treating products as words and checking if your dataset works for that",r/machinelearning,Z0FBQUFBQm0yeGJuMFdJbTJwSGljQnpxWGFQZkdTWkFZY3JDOVRIbVp5MC13SXVXZTdLLVNIRFNoRmtkZVluVXZRT0sxMHp4SVdNQWIxYmtBSUFYYTlaWlZ2R2pJa1g1Snc9PQ==
"Does it matter where you sample from ? You can sample from approximate posterior and still calculate either of the projections ? -- Not saying that it does not matter, it is really a question.",r/machinelearning,Z0FBQUFBQm0yeGJuMmNmcERVSmhhX3VpcGtYaUJOMDlWNmY0TG4zT0VWcFdOQ2tpRjVLWjVOMnBtZWRTZHJlekkwbmZrdFNpcHlmaHRGbVluSlJKdXU5ckxWVU9NREpONnc9PQ==
thank you,r/machinelearning,Z0FBQUFBQm0yeGJuQXIxSWx4cG9XZU5PYzlrVVR0am5IMlNBQVUwMFdiZ1dJRjJtYXM4RDdDNFVUYWttdTdhaFFfNVFyb2U3RGo4SEFoOG9UMjAtTkVFYTVhbGJtdDU3Ync9PQ==
thank you,r/machinelearning,Z0FBQUFBQm0yeGJuVDNnZUxxNG5nNGw2VldiMUx0cnkwYXpBVWMwZGg1VThla1llWFg3MHJxMWxGbG5vSWNYdnVZdVJEcGF2dV9EczU5dEVyY2h0MXRJb2E0MzE5aHFLSUE9PQ==
"Yes it absolutely matters, particularly when taking gradients through the expectation",r/machinelearning,Z0FBQUFBQm0yeGJuMzRJdVg2UFFtZV8wSnVzTEIzZFFqS1pJWlp6UVIwV2RKdDNYRXdHZkppYlJHekNzbjJkSlZsVF95ZjZWLXpfVmM0OEpEcm05dkJlNEp2ZGRFTElJNEE9PQ==
Hey - we have an api that builds end to end RAG - would love feedback - [What we do | Tada - Developer Documentation (tadatoday.ai)](https://www.tadatoday.ai/docs/what-we-do/),r/machinelearning,Z0FBQUFBQm0yeGJuRjROaVQyYV9OSGE1aldtREZYSUFpSmVnT3F6SXBEeWkxUG1EOTMtNVBEbC1RU3dXZXIxd2VqMXR3a0pQWkxmMUx2ZUdqZURlVllTcmp2cEI1ckZzc1E9PQ==
"The old idea of Recurrent Neural Networks is identical to to the linear Gaussian-Markov chain formulation (with the except of the D matrix and the dependency of the target on the current input).

However, the old RNN idea had issues that the product of transformations A\\^K for K steps either vanishes, or explodes. As a remedy, LSTMs gate the activations of the memory and current input to avoid the exploding/vanishing recurrent computations.

The state space models have unearthed the basic concept of linear Gaussian-Markov models (aka old school RNN) and made it computationally feasible by means of a series of tricks. The first is to expand the recurrence in the formula of the memory, and define the prediction as a weighted sum of each elements in the sequence. The weights are defined as the kernel matrices C A\\^k B. Therefore, no backpropagation through time is needed, and the models are more computationally feasible than RNNs. Sounds like little contribution, which arguably it is, but it makes a difference.

Then there is the angle of contribution from the restrictions/conditions on how we represent A, B, C from the S4 paper before Mamba. Definitely, they are using decade long models (RNN, aka linear gaussian-markov models), but they have presented a series of ""tweaks"" on how to efficiently train a deep stack of those models.

Of course, the overall contribution is on ""modeling sequences in O(n)"" using Deep Learning, which is practically relevant.

That being said, I do not find this less innovative that the Transformer paper (Attention is all you need), which despite impacting the field a lot, is also a low scientific contribution.

Personally, I think that the concept of keeping a ""state"" or ""memory"" is essential for autonomous agents, and I do not think that the current Transformers logic of predicting the next sequence element subject to a long context, without a memory, makes sense.",r/machinelearning,Z0FBQUFBQm0yeGJuOGxsb2N4WEpEOEhlWFZzVzBMSHhlQzctN2ptQjhoV2k0YTVuVUZXbS1XekRESTYzY3B6S0xGQW4yRWVhUEs3Ty1FcmFYYW9kUnlGMkMzVVhoVDNoOEd3djZMYl9udkw5RzNjbWVkRk5JRWc9
"Notice it is being discontinued on ""Ada Lovelace GPU architecture"" only

[https://www.nvidia.com/en-us/data-center/nvlink/](https://www.nvidia.com/en-us/data-center/nvlink/)",r/machinelearning,Z0FBQUFBQm0yeGJuNmhla0h4N3VZM0ZZV01YamJpSXB5QWlUQWVHZWotRVNKNnljQVE0TGhkX3BfdklzY1o2b1lUZU1hNDB6VkdRYUgzX1ZIVFM3Tm9DcW5xWmZ1VEdBS3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuTHhPZEw1alc5VHZTQjJfSjZCclllZlNmdml2OW9uX290LVJEWGhSMFRQeFJFa2gyUGxINHBsd3pLNE1DX0RXRXJLSmVNclgyUTNuRlJ6MGpsWEFJUFE9PQ==
"Yeah, it all depends on the particular use case",r/machinelearning,Z0FBQUFBQm0yeGJueGtieFhWRjBxNDZWWEdPNHYxdXNBdDZSOUZ4V3EtR3BsTE5wVWhSS0RXeUtuZ3Y0MFZ6LUQzUm9HQnFCQmNoRUh3TXRHM2ZVRl9OQUllblJhTUZVYnc9PQ==
"Hi, I'm wondering if ductile fracture of metals available in FE software abaqus can be modelled using PINNs? these models are generally built after testing grooved coupons which result in different triaxility levels. This requires lots of testing and modelling of each coupon to find the relationship between fracture strain and triaxility... what would be the physics to include in the PINNs?",r/machinelearning,Z0FBQUFBQm0yeGJuUHpKTG5xZTFmZFZkd3NlUTVMXzFUeEh6UW9fdTk1ZkNUUGpsQUl3MVgtTnQzYWNxLUZVUXdTWE9hQjVSWUVnam1Fb0dROUxYRWtBaXZqcE9jb1VHTkg1SnJ3cjlNMl9YdzVqSjIzQ3ptNlE9
"We worked on something like this for a client, by worked I mean it never got off the drawing board due to the fact that the typical product catalogue is always changing and it requires a significant amount of capital to keep up with that if you are using a transformers model. Also as others have mentioned as well, it does not outperform the cheaper alternatives, you may turn to something like finetuning an existing model but then again you run into the changing catalogue problem.

Tldr: Fun POC, very costly and inefficient production system.",r/machinelearning,Z0FBQUFBQm0yeGJudHlhZGY2aE1LRE5aY0NwMDZkekI5WEZ0STVBM1lXUFhzajhwRDZxZ0lmVUtxakYyenU2N25VUDFMeXpnZmllTlF4RDc0Yl9XQ2dfVnFtT3Jjcm5MUnc9PQ==
"I'm not sure about how PINNs would do this, but Bayesian inverse methods tackle this. You begin with a prior distribution over your parameters, then update the distribution based on the data (making the posterior distribution). This can be done with Markov Chain Monte Carlo or through VAEs / variational inference. I'm sure someone has tried to generalize PINNs to this application too.",r/machinelearning,Z0FBQUFBQm0yeGJuazg2NC00cEkxVk9SYTlZdU9RWjA0djBIOTBmRnJOZFdWN1M3Sk9janEwTF9PZ1hmLVZzd0RJTHVYYW94bUthQ0FkT1NJVGVjTmFzUlFRRjhlenFHeXc9PQ==
"> **Journal of Astrological Big Data Ecology**  
> Premium source for made up science

`(≖_≖ )`",r/machinelearning,Z0FBQUFBQm0yeGJuRUExemgzUFJYR1UwZUd1ckhUU3VYMnhISnViWmF2STU2N0oxUkZhbXYtcmZaVV9CaVhIRlpiU1hiMFVfSDFobi00WVg0dzFkZ1EwSmZKZVZVUGJpdEE9PQ==
For Game Theory I would recommend your nearest casino. Nothing better than learning by experiment.,r/machinelearning,Z0FBQUFBQm0yeGJubWdyZzgwczdiYXplbUhmSlFwTDVCQXlZdG5nWFliOTBZcDY0Wkw0TzEydDFQZ1hueFc3LWJibVpCbGVqNGF5bHN0eWdlV0pTTWxCak4wSGdibXFhV19iQnFjc201MWFhWUotLVFIWDZwRE09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuejAzY0ZYWVlRSFJXMjFxWlN0bjhhWUVaS0ZhMHB2NHM5Ul8wTHRyM3ROOTZac0U4WDNuMmpOU2NfemEtbUpHM2d2N2ZWYXNla2hiZUlpaWdiOHA5VHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuUUZrWV9tRFZoWlBMOWkyMndNNHJwaUtsWldBMWVxTWlZLWNsNGlYZktESkxrNzJBT044N3NlQ2JwU1NaMldQUVNhWDZJaURoZnZfM1BlVW1SeHdtR0E9PQ==
"I have come to see this as a kind of blessing. Picking the right focus where multiple interests align (for example, causal ML being the intersection of econometrics, machine learning, and statistics) will enable one to solve important real world problems while also being forced to understand the basics of multiple fields, and also saving brain space.",r/machinelearning,Z0FBQUFBQm0yeGJuRUQwNGExSGpLYWd6LUJXV2xYZjQ3dDN4bDZnVWxlOWFHOUhhUHNvWlZvaUJTRWdSeXVCQkxLSTB1WkhEWGVCRWtsOGlrRjhuZTMyS3lkVC1WOXlMMmc9PQ==
"oh yeah, that make sense. And to clarify: the gradient part you refer to is when you need to approximate the ELBO by sampling? 

I get this... but there seems to be a lot of dission in this thread that probably assumes sampling is possible.. not sure if that changes anything.? I guess if you can sample from the true distribution (P) you do not need to do all this can can just take the expectation... 

But again, it might be possible to sample but for a general distribution like in VAEs you also want to update the parameters of P, and that is only possible if you know at least the parametric form of the distribution.



So my overall understanding is:



1. If you cannot sample from P --> you have to go for forward KL, no other way

2. If you can sample (idk how, maybe a simulation gives you some samples), but if you cannot back prop from P, that again you have to do forward KL.

3. You need samples in first place to approximate the integeral to calculate KL, that is done via samples + ELBO in VAEs.

So sampling is not the problem but the gradient update is?







It is annoying that these things a left without a footnote; [https://www.cs.cmu.edu/\\~epxing/Class/10708-15/notes/10708\\_scribe\\_lecture13.pdf](https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture13.pdf)

It just says ""However, we do not do this for computational reasons."" ... 



Whatever I said is possible not correct.",r/machinelearning,Z0FBQUFBQm0yeGJuNF9VQkloX0pVXzBVMjR4T2MxMlF6ZU1nQmpvWmxFSV9kcEVhaTdSX1pSbExVYUZZRU51VC02bElkaUhpV2lmMFVpYy05ekhmcTdHUkhQOUJneHV4ZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJueWZxZmtFYWNWcGsxRXdMLWpKcVBPR0tacjBHRXgxMFJMSkh4V2p2T1BqcmstYXNUYnZBWHdMSVB4d3hJcmpEa1BhZllmSGRzRzZNOGd1aTgxUl9mNWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuaDRoQXNDcGhCdUFTV0JkREgwTkdtVTR4X3oyTzJqZG5qZm1UNm9aZFNoR3RaYzlrS2xCejRGREtjbW14bVB4R09IU0VTV0kyYkdESklFVVM5UnVyVFE9PQ==
"Maybe. If we can better understand how human brains work, we may be able to utilize similar mechanisms in machine learning. But it's a big if and it will take a lot of time.",r/machinelearning,Z0FBQUFBQm0yeGJuUEY4MG9QZHlHSGhHd0xYT2k5WnlpaElLVnc0QzZiMXpvMVhEM3Itd3IyYnl2dElyMzY5WElLYUxMekNBcDAzRWwyc0I1S0lON01TUDRtNmFRSjhhZ0FibHFjNTkwMWhFbzN5UTREeHo5bEk9
"The only way I have found around this problem is to simplify. For example, almost all of classical econometrics (at least, the econometrics that I use for my work) is summed up by the Frisch-Waugh-Lovell theorem for me. The rest is basically issues with panel data, and how to find my estimators.

Is that way too simplified, even for what I do? Yes. Would being armed with only those two statements get me into trouble with actual econometricians? Absolutely.

But the thing that these statements allow me to do is to use simple, oftentimes geometric, ideas to understand more complex things.

What I have come to understand, is that there are just things that are difficult for a human being to understand or do. Visualizing a 4-dimensional projection of a 7-dimensional hypersphere is pretty damn hard. As is running a marathon without any sustenance during the race itself. It's not a question of willpower at that point, it's a matter of what we are physically capable of.

Instead of fighting that uphill battle, I choose to use simpler tools to tackle more complex things. It's always going to be hard, so I might as well travel light in my mind.

The question then becomes, what is the paragraph summary or geometric intuition that encapsulates most everything you need to understand about a particular topic? It may not look the same for each topic, but it should be there, otherwise you don't really understand the topic. For example, statistics for me is summed up by projections to lower-dimensional subspaces, looking carefully at the data, and understanding the assumptions of the model I'm considering. Again, that's vague enough to raise some eyebrows, but as long as I remember that it's just a starting point, I usually end up OK.

Basically, you need to accept that you will never have a complete atlas of every single detail of the field (plus it's difficult to carry that around in your mind or on paper), but it is definitely possible to have a minimal set of tools that can help you deal with 90% of the problems you come up against. The latter is far more manageable, and actually enables you to think about bigger picture problems.

It's important for your mind map to have the big landmarks in place, with the details being a bit fuzzy. For example, I try to keep convergence proofs for algorithms as far away from my mind as possible. I don't even like to waste time scanning through them. Why? I've done 1000s of them before, and I don't think they're very useful. There may come a time when I'm totally stumped and need to look at a convergence proof, but I'll take my chances. Trying to have all the details straight only makes you confused.

My last piece of advice: **pick 2 to 3 research focuses**. They do not have to be well formulated, but they should all incorporate a significant subset of the topics you are interested in at a technical level. For example, one of my interests is signal processing. It combines my love for numerical computation, statistics, and optimization and forces me to use my knowledge to solve problems. In other words, you need *practice.* After learning the basics, the only way to grow is through implementation and asking your own questions.

The important thing is that you know what to do when you're confronted with a problem, not having an encyclopedic knowledge of your field(s) of interest.",r/machinelearning,Z0FBQUFBQm0yeGJuTUs2TU9Td2t5a0lmSjZjeUFrQXJLYlRxZTNJTV9BOUJZR21QSktDWHJlTVJRanNGRVdTazFnYTkxa2M4RFp5ZU0zZUNVMHFNUGdmUWF1WXZhazg3ZUE9PQ==
"KDD is in August in Barcelona,  Spain. I am presenting my work in AutoML in the research  track. Trying to use LLMs to automate feature engineering write Spark SQL codes like humans, after analyzing the prior important features that humans have found, interact with traditional AutoML systems and EDA like tools, and set up a RL loop to reward important uncorrelated features, and punish bad or correlated features. Its currently in production in a Fortune 100 company for its fraud detection model responsible for multi-million dollar revenue stream (hint its a payment industry duopoly which ensure payments between two different banks happen smoothly).

We have novelty even in Bayesian Optimization objective, where we tweak the BO framework to induce diversity and theoretically show a proper functional form of the diversity ensure the BO minimizing the ensemble risk rather than its traditional approach of suggesting strong individual models. Inspired by  DivBO from NeurIPS 22, but we take it a step further and show the functional form of diversity is important for guaranting the ensemble risk too minimizes.

If your interested in AutoML, Combined Algorithm Search and Hyperparameter Optimization and LLMs this will be of interest to you!",r/machinelearning,Z0FBQUFBQm0yeGJuMjFYbC01b0Vlam5zZlA1VHlhYlNqUlEtNWI5emJMVklCWWJtQW8wSlBWRU5qdWV1WTZ6YjVicTZadDByNlRaTWVsS0tYRFNYbWwxdTZ4M3BOazNSZzBLaXllcDFXYk0yNVJVVGRfSll0U009
Why not both?,r/machinelearning,Z0FBQUFBQm0yeGJuNlR0aEVFamRQWDhJazA5MGt4Z1JoODVBbG5pWUNSYkRnOURLa2R3bmVvU3BSZDJnUFZQcUZjNE5EdUpYTXEzSGRaTHVCaG9HcGotSEZZSDRpM2JUY1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuXzNBVmpvdVU2QVQ0QVI3eWdNalVTNnZtckp2RURWN0xFaGpVOGdZZXVrQ08wNlFtTzB0djQ2Zl9sNVg1bmNZZHZkUDN6Zm1kUFVqZUY0bnJ2elhqNVE9PQ==
"If you’re into implemented GPU kernel code, there is a demand. There is also a demand for integrated pre trained models with edge devices (ie Tesla’s onboard FSD).",r/machinelearning,Z0FBQUFBQm0yeGJuVTJ5MmpVOXRZckx3ZWZYenVjZHMtajk4SEo2Q2QxMzhZSzQ4VWJGck1rVHRIZTZHTUMxcV9fR3pYS2RxcHlEZFJvdjYxaEhCX1puYnNybTRVVDNMNEE9PQ==
"It's not, it's procedural; but people like to assume the false dichotomy of functional vs OOP and so really mean ""not OOP"" when they say functional.",r/machinelearning,Z0FBQUFBQm0yeGJuV003UVZialhMWVh1bWlpekJDVUZoTERwX1BVY05HenlMRG4wMElvdUw1b2pjTVJxVHQ2VTQ3dGhDSnVPVmRPSFp3SmZsYVBkbXBJT0xpWWxmTWRvdlZuUzlhVTFMWHhucEF0RkJ6TzZHX3c9
"I never found the Q,K,V analogy from database retrieval very helping when it comes to deep learning...",r/machinelearning,Z0FBQUFBQm0yeGJuUTVjLWN0SVN2cUR1RjRDRU9hSVItNVU5VV9aTUJ1UjllS1Foel81SmtHakE1cHl3VEZpZWhOc1JmQ0N6c2R0NlFpVzR5RkJocGU4WGV2SFR2eGxtVXc9PQ==
Thanks for the correction!,r/machinelearning,Z0FBQUFBQm0yeGJubUhuaFQyZTh3TndoSjBPMlZlNDl4WmIxTVlrUkgyZzhzZnVxdm5kamdhNllNT2dlQkNfV1RRTURjdlJQUnVvLWdjaHFtTjhMRlp1dnNPQ2x1Y1JjMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuZ0lGbzdsTkNfRG4zOFNnYTcxUnFWYXFocUQ3S1pFRi1Rb0ZRcnNxQUV4b2E3dGQ4cVhCaGdSRzZiNWU4YmJxQ3QwcThyWXlHSGVyQzNCLXBrcGYxUWc9PQ==
"There is a lot of propoganda and interest in showing that SSM’s are “better” than transformer through hacked metrics and bad-faith comparisons in long range arena settings, even though it was recently shown that the apparent gaps are due to bad initializations.

I suspect that the forces behind this push have massive FOMO and are trying to establish SSM as the dominant paradigm to capitalize these ideas into a flashy startup or something.

Transformers are universal seq2seq learners and show non-saturating performance. In addition, results on the largest models are showing that the data itself is the bottleneck, not the architecture.


All this to say, be careful of the hidden agendas when doing research.",r/machinelearning,Z0FBQUFBQm0yeGJuWGprY245YzAtbUM0cGljalduRlY2WEVwUW9aekc5OG1OM2xRM0szWEdaaUpuaS11Qkt2OTFUZ19UVkFZMHlpdlNyZE5feHo3eS1RdTJBaEtSZWl3Z1BSSHJmbDN2OHEzcXcyRHdJOE1fRzA9
They just meant they had to go from using standalone functions to organizing the functions into objects.,r/machinelearning,Z0FBQUFBQm0yeGJuQU4ySU56VWdlbGU5ejVWLXVEWVIzUkZNckJ1LXpXMFpBd3E4WnBfeVl1b2VXMFFMbXdQMFR4eEdBZE8tSHZ4MVZVTjVJTnB4TE1PaTVwd3ZCREdCN0E9PQ==
Do you have links to papers explaining the poor initialisations? Are you referring to the LRU paper?,r/machinelearning,Z0FBQUFBQm0yeGJuOVV3S1dmYzdSTzI5MzNjb1E4bjFMbmdCMTlWWUdkVjgxYnhlWnZZeXlyblNJSmg1c29HMFl5RzNfMTZRdnhsS3MzUjNkWmdfTFp0bDQ3YVNzaEhUbEE9PQ==
"If u want to build AI application with existing models, Python is enough IMO",r/machinelearning,Z0FBQUFBQm0yeGJuRGFLWG1XdUUxWkYwTVAtUHNha3o4aEZ5Z2RuSUtpVGg2Ym9hb1lrUWxZdE1aaGU3elRGbzYzX3pUby04QTBUc1IzLVhUU21Lb2lrRFk3NmxhLXVEWUVpc3dhVG1ZbjFjMDI0RE92a1JwcXc9
"What you meant to say in your original ~~post~~ comment is ""imperative"" (instead of ""functional"").",r/machinelearning,Z0FBQUFBQm0yeGJub2F3ZEViS2t6emlLMnF0SE5jWWxnVkJDOXY5NWZJUE1DbWZZZzNwaFRxcG1mVzItMmZhU0NILUFWNmxvakpaVk9vdlVXZHliME9oenJqM0xJUFZYZUE9PQ==
New “[insert trendy thing] is just [insert another trendy thing]” paper just dropped,r/machinelearning,Z0FBQUFBQm0yeGJuclNRN3YxUkxhWGZuNWNIcE1hZHZRNjFQZGUtaU9WbjN2emk0Rm9BVmZ4MWtjeGhnZC1DZDBZSmpiSFpaNmgtWUJHbFRIOFV4VkRvMWJKb21WWVZ3alE9PQ==
We are doing Computer vision and they are desperately looking for c++ developer,r/machinelearning,Z0FBQUFBQm0yeGJuMHJEVzFVellVVzRhNENpN0oyMG9GZWppWGZXUm1KVl9rUG5VZG5OVHVpQ3JaM25NT19SNUFvRVE2UThldGY1blVxVHZPRmNKMW1QeHJNMWl1VV9EeHc9PQ==
"Using LLMs to convert tables extracted from PDFs into a standardized format. We feed in the extracted rows one by one as JSON objects and the model produces a new JSON with standardized fields. 

We use GPT-4 with few shot prompting to pre-label data and manually review/correct. Then we use this data to fine tune a 7B model which will be used in production. Using a training set of 2000 rows and testing set of 500, we were able to achieve above 99% accuracy (meaning more than 99% of the generated JSONs were perfect).

Still not in production, so no business impact yet. It has the potential to replace tens of thousands of lines of buggy data ingestion code. Generating and maintaining this ingestion code is the biggest cost associated with the project, so it could have a very large impact. 

Biggest concern at this point is how to handle the <1% of cases where the model makes a mistake. We will probably use an off the shelf ML labeling tool in the short term, but we haven’t found anything with a good UX for our use case so will likely need to build our own labeling tool eventually. The existing (non-ML) approach breaks when the table formats changes even a tiny amount, so we are hoping ML solution will still be an improvement in spite of the occasional ML errors.",r/machinelearning,Z0FBQUFBQm0yeGJudmFpQS1tTmtUNVRENmVpZGRNakRqR2NyVXQ0MnFMRThfbHMtUzdPakozV0dfbERwbGRCN3h6R3ZzODVMUFJjS2YwblRkVHZ1STdaQUxKT29aSjZINlE9PQ==
The game is pretty cool,r/machinelearning,Z0FBQUFBQm0yeGJueUZvTVVSQ3l4OXpaUEc3amNCLWFLOXBIdG5KQkE5SW9UcTJ3Wmo2RmNVckdxd0F6SXBXcm9rOHlBTnZmMXE1VU12aWpCN0U4QUpVS0lFOVVScXdwSmg4OUtlaW9JakRzek1vbHdYc1dkdG89
I'd take. A look at MOJO/Modular,r/machinelearning,Z0FBQUFBQm0yeGJuQ0xGOXNpNjdqRnU2V1dxN0EzaEhsQkhTSjRfS0YyVG1Rb0JNNHZmRDJScWFEOGV1b3dTYUJxT0JjNUFsTVByX05QWm9VZXJWYnhQbVZESWJxbGYyTkE9PQ==
"Tiny batch size, qlora, gradient accumulation.",r/machinelearning,Z0FBQUFBQm0yeGJuckFJWlpwb2pTZlhCNWhwWXZSVkpSdTlWLWROZjNFWUFlTmpXN3puUU41emNnM2hGOVhvQUEyVmJJc2k5bElIallBS1pjTlNQRXZfY1AtQ2R2QWp2OXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJua2F1WDNGc0dOSDE5MHRqMlR6YlFBWDNoQ1B4Z2FLalZWY19FSDd3T0ctT0xOMktvdEZKQVRYLUZMbFFiVGlGZXpUS0FxUU94SUlUc1MySjhBdDZFMHc9PQ==
Thanks!  I was super excited about it when they showed it to me. My best streak is 7.,r/machinelearning,Z0FBQUFBQm0yeGJua0lhLTNnSlNXZ2xJMERpQU9Qd3QzY1hIeDhxQUhwX08taFZzYWlQbENjemx5dWxEREozbUl1MlNybUR2QjRyOU5qMERGeFJsQnFvZ0hpTFJuaTN5UUE9PQ==
may i dm u for more details?,r/machinelearning,Z0FBQUFBQm0yeGJuS3M3S1NJUUNUeW9zVTB0Q1FRSTVWSFZzYzE2Z3F4TkhBM2tkRXAtMVhlZWs0eFhfQ25JLXJUYjEzdklaMDVRcWgxMFIwWFI4YUNTaHRoSlh4cUt3QkpWY2tPRmRHQURQSTJZdGp0T2R3V009
And it was not a post but a comment.,r/machinelearning,Z0FBQUFBQm0yeGJuS1FPX2Fwc3RMQ2ZsQ29aX3c1NUNHbnV3OFdEaFpHTEx6cHR2WnhTZ0dWM29pYkl2dHJmZ2c3aHkyZG9QS3o3bzhJM0UwMEZyS18wN2hEaS1RSzRVZ0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJuV1RhUnJ1azZ2azBVMlFNb3d3QTBReHBOWWF3XzVkX1Q0aTdDYXhwNW02UXAzcGpDTFlBQkpLUnVEV3Rjc3YtamFub3I2TjNBS0NmekxCNGt1dDFfR0E9PQ==
"Doesn't this strike you as a waste of our natural resources, putting this much energy into training a model to create lego videos?",r/machinelearning,Z0FBQUFBQm0yeGJuZEJsdUVtamxjVDZOcm01cExnVFBDVjVyOUNMNEpyb3lTQklNZ3NldmhFYXhuYllDUy1yNHNndnR2dHhJUTMyUXlUeXBQczdkb2E2YVNOWGlPRS1VZ1E9PQ==
"Normally I’d agree with you, but Tri Dao consistently makes great contributions to the field🤷🏻‍♂️",r/machinelearning,Z0FBQUFBQm0yeGJuUEJ4NFhWVG9HT2VJN0kyeDVrR1FaYXpxeUtSV2swT3VKbE9sLTI3YmxHTXV0NUhwbEFBdU96NHJKUUlvVU1FREd1SVVNdGg5dVBJSU03VHVQb2k1aFE9PQ==
"I'm not very good at the game, but it's very fun!",r/machinelearning,Z0FBQUFBQm0yeGJubUZ5djctMlRGbFE0VmVpOW1NSDk3NGZZci1JNmRNZTZTS0RoQ3VUd2Z2NDdPdGZ4bVlEYzNJYnZYZllvV2MwMlI2TlRBVUZpWHV1a1I5T2RLS0lTVHc9PQ==
"Sorry, that's too general and not a good answer. Also, I've been using the model on a batch size of 1 so tiny batch size and gradient accumulation aren't the main issue. Also, I doubt QLoRA is a good choice here since I'm training, not fine-tuning the model which is also primarily a UNet, not primarily a LLM despite its conditional component.",r/machinelearning,Z0FBQUFBQm0yeGJuUGV4bFFOcGpKQmpNcGw1TTlMX2JCMDk0ZnIwdml5TWNUR1lpN3BjYXNmeExvb0tLNVNibzNya3J5QUVHRk8xSldUeXZ1U29yeTRJcFgwOEdnNTVmOUE9PQ==
"Actually, it is quite the opposite IMO. Stop animation is super time consuming to make so spending some gpu hours and enable people to do this in minutes instead of with hours of manual labor is useful. Plus who doesn’t love Lego :-)",r/machinelearning,Z0FBQUFBQm0yeGJuZS1sclRIRncxVHdrOWNreDVFUmwxZ0xHNkZicGxEelM0ZWlfZ0RmSTlRM29OR3pmay1xOUJmOVphZUVMbnJubjJici1ON3d3eTJJUll4SHBCdXhqblE9PQ==
"Sounds very interesting: [https://x.com/ZimingLiu11/status/1785490243984199858](https://x.com/ZimingLiu11/status/1785490243984199858) 

"" We used KANs to rediscover mathematical laws in knot theory. KANs not only reproduced Deepmind's results with much smaller networks and much more automation, KANs also discovered new formulas for signature and discovered new relations of knot invariants in unsupervised ways.""",r/machinelearning,Z0FBQUFBQm0yeGJvMjBFSWdMUDJMY1gwYmJGaDhZYVc4WGFWdTlQNTJZaHk3NXRRbXJ1MndtU1FQemNDQkNGZ0t3Rms1UGNLaVV4YmtfNElPMGJKaGU3U0FTa2NZS1JlUWc9PQ==
"I'm not going to discount your concern, because it is a valid one, but I'd say this is all still very much in the research phase.  Today we fine tuned it to make brick videos, but it taught us how to do distributed training.  That might be useful for the future for something that is a ""better use"" of energy.",r/machinelearning,Z0FBQUFBQm0yeGJvd0tWYkV4ZGUtdXZrQWE2cmpNWHVUemUyWDNCREVid2tJRW1ZRTBYSWNyVjRYak10c2FodWJYaWJ2Y3htVlpaRUhiWWlmeFoyeG9oc0lPdmxCRFFYc2c9PQ==
"That is definitely not what functional means.

EDIT: I realized that your comment actually agrees with mine. The guy doesn't know what functional means and assumed it meant ""not OOP"".",r/machinelearning,Z0FBQUFBQm0yeGJvX2xJUUFhQTUwVlRNbGxqRi0tdjNsNVAzNXRjWkt2RW9nY3pPLXF0Y2hmZ3NnLVY3aE9VV3NKcW9MMTVFUy1USVJoS0EwZTNlWnpGYnBjVGZKN0R2RkVrUUFjNVM5Q1FyOHZST2xDVWZrMTg9
Such is the beauty of mathematics 😊,r/machinelearning,Z0FBQUFBQm0yeGJvb0lQaW92X2ZUU0dtVFZ6WmJ0NktneXl6NkJTb3hsR0dZS2E4b0ZhdUdmc0VYYUdBLTM4emRuVXJ0Zk5mVkRXS201UUJKTUJGYUhEOHR0Qk9PZmtHdEE9PQ==
"Looks like a mixture of small trading set and the eval containing examples far outside the training data. 


All said and done a larger training set so give you better results ",r/machinelearning,Z0FBQUFBQm0yeGJvT3hTeW5idDdhX2pIWFUxSTlPc2NwbTJfUWZBZ1hhOGdlZC1ZdW9tdlRKSnZKYktoanRiSnZZeUwyQzF4bzV6QjlhSzdXaTVDb29qaERXVm1GaHc3MmhWNWJqaTRBSE5BMkhMZ3Z4UVFhMGc9
"I see this with a lot of people. Thinking about what the impact is of something you want to do. If you feel like it's an interesting thing to do do it! It's another tool in your toolbelt. Don't focus so much on ""what are the things that are going to propel me forward the most"".

This is just my 2 cents and how I approach things.",r/machinelearning,Z0FBQUFBQm0yeGJvV0FiSEstaFJOVU9kb1F3QmJEVVpZMGxqNXNTUXRPS1JadExyeTY5MlMzR0luaUlDUU5ISU9WQU4zRlk4VEdnRFgxLVE2dkc4NFVQV2lSX2VzTnhvS1E9PQ==
"You also don't *need* to use OOP in C++. In fact, for high-performance applications, a.k.a. the main reason to use C++ in fields like ML, you're almost always going to be better off with a cache-friendly data-oriented paradigm instead. Not a single thing is stopping you from basically writing ""C code"" while using some of the more convenient features from modern C++ to save you time and help you produce better and more performant code (templates, constexpr/consteval, static_assert, concepts, scoped enums, etc). And not a single thing is stopping you from also having some of your code be OOP at the same time, where it is more convenient.

Of course, on a didactical basis, it would be reckless to say you can use C++ without understanding OOP. You will want to learn the ""rules"" before you start ""breaking"" them. I shudder to think what monstrous C++ code someone who never learned OOP because ""it was too difficult, but luckily someone said I didn't need it anyway"" would produce. Especially after first-hand experience with tons of real-world C# code from actual professionals who ""like C# because it means I don't have to think about memory management, I never really quite understood memory management"" (someone just kill me)",r/machinelearning,Z0FBQUFBQm0yeGJvaFgtUVBTNDZoNUk3UzBpTXNUclBLdEo2MGJkVmpfLTdrcmNieFd3bnRmWEpQTkNFX0tsSDRrME14dzlydExIRFM0em0taW1EYkVydnAyVmc3a09Ddnc9PQ==
"if u program in C, whats the big deal.  llm.c is in big demand.   follow karpathy in X.",r/machinelearning,Z0FBQUFBQm0yeGJvelJyckhrQVRTb3JMNm5jdnh1ampma1pEZDVmdVhuckEzOEk1MGd3d2xBREFyd3k3TU9KTUN2RDhkSzhTQ19LOVFKY3JQUkdad3BJXzhHVG11WGdNR1lFRHJPclNWVEphazRldVFjUVdwVU09
Thank you for the reply. Got it.,r/machinelearning,Z0FBQUFBQm0yeGJvSzRWbjVBZnlmMDBTamY5dFl1SUlfOWE2b1RFN1F2YmZoMjI3Vl9rRmxjaWNycHdUUzMteVFwdGdTbnJTSXJ4NnVPSUJMbk9fQ3F6MUJEeFZmQ0ozSGc9PQ==
Why is that on the computer vision field?,r/machinelearning,Z0FBQUFBQm0yeGJvcDZPeVJSVFRTOXFSUDBwYXNHRDE3ajNnN3p1eHRvZEZRb1ZhZWNDcDJVb0JfWWtSX3pjbDBGME93alBqVk5uQ3pFMThmazIzalZGeE5kaUFVeThMZ1E9PQ==
I'd add a skip button. Otherwise you have to |space| enter 3 times.,r/machinelearning,Z0FBQUFBQm0yeGJvSVFyQnBaU0g4dXp6U05BSWdDcWl1dXFVajYzTm1SSjg0U2J6d0pKNU9ZWm0xaUI4X28tSDdWUjZucU5WQ1NzWkVQaFFGZ1pMYmViTmE2WUxXWUJvQWQ0NGdiY2h4M2ZndlJxaWVKZ3dVc0E9
"Thanks for the comment !  
For me the reason behind choosing C++ is it is way more fun for me to deal with low-level implementations rather than using APIs to train ""models"".",r/machinelearning,Z0FBQUFBQm0yeGJvdnMxVlh0elVDMTVFYlhhLXkxaGFWbTZVZW5JdW1nZjZpeXpmRjdPcFNkV3JsdjVGR0s5Mk5nN1ZadWI3LWpab0NQS0Z2em10eWg3R1RDazRGc3IwY2c9PQ==
"Fully agree, every module should be coded in whichever style most well models the problem space. C++ was primarily driven by a desire to implement OOP paradigms in C but has since evolved to support a wide range of practices.",r/machinelearning,Z0FBQUFBQm0yeGJvZXFNeDJuNFp1U3ZsNk9hcWhLcU5mZ2VaN3M1dkQ5b0pvcnIxbDFCeXdGQnZ0UjVYZGhHSFJrYkJNN2ktNGtHMjBoaHNCdGFIN3czaWdvTWo3a21NQjk4eFc1QktkcTlXTGdIcnpOQ25GQms9
Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJvNGYyT1pyWmVIV0dpMFlIWGdRSHgwVUtDODJCbGZRbDM4SFVETnV3QlJwQXItaGhwU3pzOUxCZGZsZFBjYVJxbUZNbFh2bDNZTEdzcm9kMjFfZDRWTEE9PQ==
I guess that is the kind of things I'm looking for. Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJva21aMFdZMUtlbnp5SG1vaHlyNDY5QXpNcE4zSXZ0alRvTmRYZG9nZXA2dEx2YzVCZTdZaFdOcnl4R29Cd0dRZWgtbGtJVDFPa0NCQmhwaXEyM0NGMWc9PQ==
Haha! It will be a great journey ... I hope.,r/machinelearning,Z0FBQUFBQm0yeGJvNmk2ekRBVms4Mzl1YVZCdHQ2cVpYZmdLa3dBLXVlX0VxS0g1emsyS3dTa3luLUJfNWZ2Mm1vOFBnYTdnUkt6T3ZtNjNDcEpqTU5ZR3Y3dXJtaEdmcGc9PQ==
This particular project was the thing that has aspired me. Thank you.,r/machinelearning,Z0FBQUFBQm0yeGJvZGY4OHh0RVJoM2J1STlubGZwSjhzTXRsYXVHWWZPMG5fTW1JbzZ2RVBLQWZoVWRLWVVIVGNwb2N1dnhmVFYybTBjOGNfWC1QdjFnOXZCbzF3R0VfaVE9PQ==
"Because a lot of times it is real time systems requiring a lot of multithreading, careful management, embedded systems, etc. And a whole history of OpenCV in C++.",r/machinelearning,Z0FBQUFBQm0yeGJveXlQUXpFeXZNZFQ3YUtuQWNmM0dyVVZIeXZhY0JDQ1FzeThZQUF6OWZ5bEs3WW5HVTBYUVQ3d1JBcUtFYmFHeUR6ODZaemdjSTdBYjFUVjdianZIb3c9PQ==
"Makes sense, thanks.",r/machinelearning,Z0FBQUFBQm0yeGJvYXVVWjEyTXl1LUlGYTRiLU1mWVdRS1FWZ0ZwZ2wwRUp4alY2alRpZ1V2dEN6WnQxV2hRMW9MdXRiWW9UemNWNHNmeHVxZG5ycE1BWTFQYmVRLTczSEE9PQ==
You can apply some data algumentartion to increase you validations dataset then run the train process again and see what happens.,r/machinelearning,Z0FBQUFBQm0yeGJveExuOGxhaGJjaFE0eTI1TWFsc1lSSjduVXJqM3B0cDZfdV9MbXYwQVdJdDlnc0xsQmRBUVRVUDJxUnpfd0JwRGZtT1JhOTNxUlE2alBCNFNxYlFBTkE9PQ==
Right.,r/machinelearning,Z0FBQUFBQm0yeGJvYTgya1NTbFBWU3I5WjdTZUdTRmJmNjE3WHd3N2JST2dCcFBfWUQyMFFOVmE3VXlId0owckdCVzB4bWhIdE1IcmgwSmlVeEhOaWVkQ0FNb1JCdE1Ua2c9PQ==
"They report using ~1000 H100 hours to train the larger model. An SXM H100 consumes on the order of a kilowatt. So their largest training run consumed about 1 megawatt of energy.

Which sounds like a lot, but is actually the equivalent of ~30 gallons of gasoline -- not quite enough to fill up a tank of gas per team member.",r/machinelearning,Z0FBQUFBQm0yeGJvanNlSXdIQjVRX0thdXN4S2tfakt1OXdLSEYtRlRzVlZCUmJ0ZFdZQjhyaUhVMGJQVUYtWDI3OThjNVk3a0lIZkRvbG9yWnBCQnZzVnRTNENpeVphcFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvWHhFSmFnaG02bkp0ZmlfeEJYaWh6MTlYckkzY19PM1owbXhpcHZ6MTEyNDNxOWFtYjRHSXdTOXFPYWpSVkU3ZG5uV3RvbWxMYXZjYnVpanJBbWpTRFE9PQ==
"Great resources, thank your for your time!",r/machinelearning,Z0FBQUFBQm0yeGJvQ19Vbk8xTkhhZFE1d1hCWXpnbjQ2OXcwVDUyc2twOV9kcVlhRGlEWVIxUnRubTZ5d2pESUNpazRBNkEtdWh6aFVtdWhhdTlWRDhCWFdxM1p4d1lwVmc9PQ==
Thank you for spelling it out. Helps with us slow folks lol,r/machinelearning,Z0FBQUFBQm0yeGJvZUFlSDhpcks5Z1NlcTcwV05OajJ1NldERF9Ham9BMGRfd24xWEdVbkxvcGhZWWFMTF9WSUVOMkdXQlViSGMtV1RGMUFpRjV2bGdrV3Jsai1oZE1pTEE9PQ==
"Without knowing your dataset, the loss you're using etc., it's hard to give good insights, but here is my 2 cents:

What does it look like when you look at the output of the model when you feed in an example from the valid set?

I feel like your network often colapses and predicts only the background class (i.e. why the metrics goes to 0.25 (1/nclasses).  

If that's the cases, maybe have different weight for the different classes.",r/machinelearning,Z0FBQUFBQm0yeGJvQ1dHTUJzOHVXTFA2enpOTVczWC1oc2wxQXhRYUxNUDVpVGhRMF9EVFhqY3M3RTlLWnNGZkl4Mjl6SVd4dzFfZkozMDk4OWpmUDVKTnkwSjVVWWJtZTF5M0VGYUtqYnlKbnhodjRmd0lmcUU9
Robotics is getting heat. You will need a stable understanding of C/C++ to work like a champ in that field.,r/machinelearning,Z0FBQUFBQm0yeGJvRVNHcWRCRFREX2dOMG93dmdTNjUxbk94RXZCdXJsT1lUX0RNN1d2MUpZWHJXa0hUQlpwYV9VcUU2U2dUWTByQXpsb3BEUkRzOHd4eXFZX3NnT0dkV0E9PQ==
"Hi can i check if you made any further progress OP , i am considering undertaking a similar project",r/machinelearning,Z0FBQUFBQm0yeGJvYWlFcmFhcEpLUm1BajJ1WXNMcnNUUVBmc3FUdDRFakpxbGprYmFPUV9oTG11SnZNVGZVRW5GLUVzczJvZ3l2SDdfa3Itc0pwNG1GS1ROM3JESG5OS1E9PQ==
"Regarding the note, no it's not not a big deal learning C++ decently, when you know C. You can basically write C code in a .cpp file, but you shouldn't. The C++ best practices are entirely different to what you do in C. Move semantics, rule of 1,3,5, templates. This is all stuff you will need weeks or rather months to learn to a decent level.",r/machinelearning,Z0FBQUFBQm0yeGJvd25NS09BejI4ZXBhdmJyQ3pPVU9OYm5yTWc1cmx3c2xkUDh3WFNlV2tKOU53d1Rvb0xCSzhScUhRZ21jU0hjVTh2RzFidFU4WU9KdTdDd1JSMlloNXc9PQ==
" > The learning process is not a linear phenomenon and 4 consecutive hours of intensive learning work every two days are more than 2 hours of work during two days.



Completely agree. I've always felt that longer, more intensive study sessions could be more effective, but I never consciously thought about it that way.  
You've expressed it perfectly.",r/machinelearning,Z0FBQUFBQm0yeGJvQ2JnTzJMLUowZ2dPY2Z4YmpiaW5UaURFYlcxZkVLZWxPcWJHWURTOXBRX2Nmd25UaWRoNDdKN1dsVXRLNjAxZHp4U2VUOEw2NWduWnRCVFFnelhlWEE9PQ==
"My guess for the next spotlight paper at ICML 2025 — ""Transformers are Black–Scholes models: Parabolic partial differential equation expands infinitesimal particle diffusion""",r/machinelearning,Z0FBQUFBQm0yeGJvb1NMcmNVVV9IT05JRVNWeG5ibWpNZnN5eDRCM2lfb2JWZzN6UVBRZHd6VzlsVWtOMUdabGpUMHJXVmZCLXNQU29RQnNETGV2Wk41TnVZNGNaSWs3Smc9PQ==
"Thanks, that is helpful.",r/machinelearning,Z0FBQUFBQm0yeGJvdnJxVXZ1NnRaLUtUZ1ZnY0F2Y3ZLWnkxOVN3OVlGV3RBQ1R5dzFjNzhFXy11cVVvZEVSS1IwYXktb3pBSGdKN3h4NWlOT25sU3BxQ2NLd1cyNmVpTkE9PQ==
How is it a waste? And of which natural resources?,r/machinelearning,Z0FBQUFBQm0yeGJvWWY4a0UwZUl3Mll1N19NalZsQ0NZRHdOakFuSm9feHB6U1BVUzJ6X2RvYmxTVzVTTWpLdmo2LXFlRDV3R2lhREVDQVBjS09Jd3RTcVh3MzZOMHNKU1E9PQ==
"Make the worm test, create a network with a brain the size of a worm, see if the network still learns something in the training, if yes you are leaking the labels, if not do the opposite and see if the network overfits and the Val goes to infinity, if yes, your Val data is OOD",r/machinelearning,Z0FBQUFBQm0yeGJvb00yUkJIOG8xVmpJZ18yRjVzMmVhUHZnZ0RGLUo3SWJtTlRlX1drVUt6bVFqZDJ5c0JGNzJQU09FbTRjU3AwUjlQblJBNHlJcFctT2VadWJmVFB2TkE9PQ==
Nice course man,r/machinelearning,Z0FBQUFBQm0yeGJvUUdwdFE0RjNFWXVwc3lNbVhKeDR2RC1OSDNLaXNuMUFkZTQxek1HREhwWEZaemRtTVQzUzRqcmdwdmd2YjlsSU1TV1ZUMWs4eHg1RXJWUGFmbTUtMXhGb0pkZEpsaVZlcUcwZURyWUV0N1E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvanE5X3VialZUQ3BmNnZCOXZlSHBsaDloMUZ1Q0ttVDFoSXBRWE5sYjRXRnBWd3lTOFpHM1lGY3hmcUhwbWxjc3dZSGpmLWRIWmI0bzNfS29TVXRhekE9PQ==
"It's not like that. The authors look at hybrid models too, in detail.

>We explore the different ways that SSD layers can be combined with attention and MLP to understand the benefits of each. Empirically we find that having around 10% of the total number of layers being attention performs best. Combining SSD layers, attention layers, and MLP also works better than either pure Transformer++ or Mamba-2. 

>[...]

>We hypothesize that the SSM layers function well as a general sequence-to-sequence mapping, and attention layers act as a retrieval mechanism to quickly refer to previous tokens in the sequence instead of forcing the model to compress all the context to its memory",r/machinelearning,Z0FBQUFBQm0yeGJvVkFqX0w5blBOSEhTUU9QSUZFcjRWZnRCMnUtUFppSlNmb0N5Vk1JNjBsc2hrZmdFVGppU2VXUWZCSGxDbVhJeHRpZlpEWGI1aV9zMC1OQ1lSbnlPUWc9PQ==
Would you say the same to the creators of the LEGO movie?,r/machinelearning,Z0FBQUFBQm0yeGJvenlfOHhmX2VBb1dHS1o4TEFMeE00bTNGcno4bW9ORHNvZm1mWmp2WUtYbmpLQ2UwcGxNYnVLek1rbmRWQ0cwWWJCM2ZIRW1GOHlpMm9icTMtU0hVSFBhN0FPWWUwTWl0alEzdkp1cGJwY0E9
"I prefer the math to the code, its often easier to understand what's going on",r/machinelearning,Z0FBQUFBQm0yeGJvNnlMamhMX1hMa3pxSUV6blkwdWNsdWdmaTdaTlBGbkNKVnNreG5VdVJMbUZ6OHZOVE9FdFBTUGJSaGFnYXFvTk1VLUc2R3B0SmU5MHRZMDlreU1WekJCYmhtZUJNUlNLcGc3cEJ5ejJkYk09
Good idea! Done. :),r/machinelearning,Z0FBQUFBQm0yeGJvR2RBdnNvZWM4VTBfNVZZT21yNFZ4aUtvNUdRbkNpRGk5OXZ4eWl6WGFrRFhMNHlqSkdBX1ZkTjVRaFB2NkdFblBPVGpXMmJ5SjhObXdudkVVZ1lQazFLRkZoMEQ4dDdrYWpPQUFMYVpOVTQ9
"No, they actually got a popular entertainment product out and probably did market research before knowing it would likely be popular. ",r/machinelearning,Z0FBQUFBQm0yeGJvWDdxcjUyZ0ZDY3g2NHVnX25mSmlGYUhVNE0wbUZ5TV9RZ0taZFlTRUw3WHJVQS1sXzNLeW9FaVpTbUlxYkhaSnZleDQzbkl0X0M3ZVR4UDlIa0NqUGc9PQ==
We built the first AI iOS SWE; check this if you are interested - [https://x.com/zinley\\_ai/status/1796678099167543796](https://x.com/zinley_ai/status/1796678099167543796) :D ,r/machinelearning,Z0FBQUFBQm0yeGJvS21lSmVJUUwzTTdoMnFNVHY1NXBEaEI3WF92cTJadWNHN3JjSE0zRU5IMUhrV1FkYXUtRnRhUlZ4Wk1Kb3A1c0k3VmpwYnFMZFg5ckpHcC1CVkxubmNXMzJaLTZ3dEFybnhzSVpyUjh6bkU9
"> New “[insert trendy thing] is just [insert another trendy thing]” paper just dropped

It's almost like 

* ""piecewise-linear  curve estimators (any nn using relu) can approximate curves with piecewise-linear-pieces"" 

and 

* ""near-approximations of piecewise-linear curve estimators (any other activation function) can also approximate such curves""",r/machinelearning,Z0FBQUFBQm0yeGJvdVQ4SWU3ZGNRZlpKZklfZThGcHZCdHN6VDlaSVdVcEhhV2xXZmthQ3RaN0poeVNNUWozS05QZkNKdXhUaTRid2d0aWh0X1ZGdTlrNHVKT2ZFcXdsZzZBNTcxbmxTWTJpdENrQ3dGMWtYdk09
"Do we even need papers to show that the maximum information flow between tokens in SSM's is just severely limited compared to a Transformer? Doesn't mean this inherent limit is a real problem in all cases, but neither is the speed of a Transformer.",r/machinelearning,Z0FBQUFBQm0yeGJvWS1Qc1RDd2JaZ21rdWIxalM0RjdqTEJCS1ZsT0ROTDRSTk9zZXRRcVBUdHpoWF9oSEVlMTYwY2lwRG9YdWE5alRKQlU0dzhfUGZHQzRMQ2c3YnE0YXlRVXMzdy12cmV5ZXktd3R2dVQ3Rk09
"> I would take a pretty different approach. I would start with a pretrained LLM or VLM

I found chatGPT very good at recommending music. Out of the box.",r/machinelearning,Z0FBQUFBQm0yeGJvcEt5V2N5eU0xUUViY2ZxbzNWSHZmQWNubGFyZ0h3U3VNb0EwNXJqLWg4ZTRMTVE3eDVSdWdKY3N5YjExZ1ZRbll5SnVQaG5oQVViRjV4R20za19McVE9PQ==
[Pareto.ai](http://Pareto.ai) is one of the leading data labeling tools for nuanced and complicated tasks.,r/machinelearning,Z0FBQUFBQm0yeGJvZjQwcXBjZXZDX1YwdWFRaEZvTTMtbS1XMjFSTnF5NGdONGljUmFydWdFeVVkS3JKcWpqaVVBZlpzd2ZuaTM5YkJuV21fTTQ2LUc1UXV6NEpZcE1zdlE9PQ==
"Seems like an interesting task you have there. Seems like your main issue is data and work management is the main issue. This is something [Pareto.ai](http://Pareto.ai) will be perfect for. I haven't used Encore, CVAT, or Labelfox, so I can't say much about them.",r/machinelearning,Z0FBQUFBQm0yeGJvYmZTRUwxbEtnYUN1XzlqU0ZQNEpOcFBwU3V5LXplclktOGU0Q0JUNHY0Tk0wNVJ3QXhGLUd6bnBjN3FEMkM5ZTc0bi1IMEh2bE14ODF3ZEo0VFJ2VXc9PQ==
"How is MPI significant for ML? Hyperparameter fine-tuning? Does it become insignificant when depending on the GPU? Especially when a single process trains on its full capacity?

Sorry for throwing out an interrogation, just very curious",r/machinelearning,Z0FBQUFBQm0yeGJvbU9zNDI2aEhlSVpyY3FwRS1tTVJ5d0xLQVZUUlRhY3FVSmdfZ2t1TVg5R09rWEJnWkhOUW9FZjhDZDk2eE96dFZIek5HTlZtUzNIYURhVVFHR1A0NUE9PQ==
"Cartesias new text to speech model seems to be trained on SSMs. And Tri Dao is an advisor to them and Albert Gu is a co founder.

https://x.com/cartesia_ai/status/1795856778456084596?t=wi3spwRcMsg8SLKneY2UwQ&s=19

I can't find the loss chart but they showed for audio at least SSMs were way better. And faster.

They said they will release a technical report + open source version soon.",r/machinelearning,Z0FBQUFBQm0yeGJvdEdVRzhCbXJud0pCMF9RS0dEdmlMblZPbGt5SFRSQVdLTEFIbFVVWmVIZ2JIS0FDMnViTjVJN2NiRTRFTWdWZ1lFcmRUMlk0WUtxMEtfbFppVUlnRUE9PQ==
"That is great for smaller projects, but remember to keep it simple. PyTorch is the leading DL API library for a very good reason, being very well optimized day by day. It can often take you too much redundant work just to recreate what they have achieved in Python already.

Though I've seen a great appliance of C++ in ML is often in quantitative finance, where performance is extremely valuable as opposed to regular data science tasks in companies with long to no deadlines.",r/machinelearning,Z0FBQUFBQm0yeGJvNVk2V2x5aVRVaGRfeUJPbkw3a19sSTZrSTB5MTNzLVNvd05fNWswLWFab00wYnhQV01pRmFMMkg2b0wyY0FUMUNoaThRTVkyNzFuT1JZYktQUW9JUHc9PQ==
"Good stuff, I'm looking forward to more articles",r/machinelearning,Z0FBQUFBQm0yeGJvQ3NyQ09QTFVQYkRiel82SmxlbUktT2xRbXNyR1Z1TlJhSlRfajNYVE45dE5PRy16dFhQQmpXUHNUYnZKMG5GZmdYSmlwVlNGc1NHdFlmOFZCMU1XUUE9PQ==
"ML no, but broader AI sure. For example in multiagent systems, metaheuristics, optimization algorithms etc.",r/machinelearning,Z0FBQUFBQm0yeGJvaVFYM2NxNWNjV0Jobk42YU1rUG9rRU9IazVXR0dVY1gyNzNKVnA5emJ6NTNJTGNjbkw5Uzg3dV9UeERQdzFkRWNJN1JHR2NuVXlmekZCcTRjcDBNamc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvQ0lneGtzUGRPSUVDMXpWYi13NnZUS2hHTzRuWjEyalJSV3dpbjZ1S3NtUFl0bzlLOEo0RVByY281NF80bnJVeGNTZnNYSnRvTWp6dnhYVS15MEk5MkE9PQ==
Yah that too!,r/machinelearning,Z0FBQUFBQm0yeGJvOHpEQ1dQOThmb1FkLURUSzh3Y2JneEhDaVBqWUhMalVQVmtqWFNJUkZoeDdDamRoY29kMkFVOVhVczR3R240bFJ4Z0V3Y1A1bno0WXJYVVl1alFPb0UzZXVubVJGWFNoSE9FdHVnb3Q4dEU9
"MPI is extremely relevant. If you want to train models that are bigger than what can be fit on one machine you need to be able to train partitions of that model on multiple machines and MPI allows your to implement the communication between machines through that training process. Same is true for inference. Most common to use the message passing functionality built into your library (torch, jax) but when building some from scratch MPI is needed. Example of the later would be karpathys recent GPT C implementation",r/machinelearning,Z0FBQUFBQm0yeGJvY1p6dV9URlhiaVE5UUVXVGp2UGFUT0hSU3BUZDhVdjdlbEF0emVHMkJFX2tZQ2VadTl4OGhZQTM4eF9sQmJ6SkFDN0dyTmVFemQzSk9lOUd4anpMNEtpdzRQOWxGeGhMWG91UWp3QVF1SXc9
"Yes, but given they are the authors of MAMBA they also have a ""conflict"" of interest",r/machinelearning,Z0FBQUFBQm0yeGJvZ2Rvb2ZtS0ZicWg4MXBtNjFVRzBXSzdTS2swYjZrcWRYdTB1dUtUQXp1bFBTb1V1NFJKS1hMeGhPbUZHdmVTMnhkbno1dlRTdXo0TjRsSDhQWC00RWc9PQ==
Maybe computational Econ conferences? CEF and ISCEF   Would have lots of people doing work in this area. But Econ conferences aren't exactly the same as comp sci conferences -- presenting at a good conference doesn't carry the same publishing credit,r/machinelearning,Z0FBQUFBQm0yeGJvcUtWemFpbThPdU9rZUlCVWJocEtIZlEwYjQ1LWxSUUY3QkVCM1lZcmVZYW9raFFLRGxnVFVNNFE0S25KV0lId3BGNk9BQ1pWWTBKUXMzWEcyUmhteXc9PQ==
"Some good takes in here, but my 2c: what are you trying to accomplish? 

If you are trying to understand fundamental ML concepts and common algorithms, go Python.  

If you want to learn C++ and work in an ML environment then the focus will likely be on inference, which is becoming an increasingly in demand skill as the focus shifts to deploying larger and larger ML models to different types of hardware.  

Wrapping your head around llama.cpp would probably be a good place to go if the latter is your goal.",r/machinelearning,Z0FBQUFBQm0yeGJvN19MTmpLbDdXM1ZMdW4xbVh2WWtZMWMxQ1BkZkFxZXMzN0VxalliVFFvS3lBWExGcks2NkVuZzc3UGRqUHRTbGR0RHo2MHZfY1E3TEM0eUVseWdrWkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvLXd2aTFlVDBYWXlnYWQtRFNITWhWSzNlLUUyTHdidVZhU0NOMElqVnY2WlJoS3VyUzdrYXpRaXVXVWVzc1laZ2NCVjJESWhuci1LN3ExaGZ3OFpHRnc9PQ==
It says “BXP 1290”. Hope this helps!,r/machinelearning,Z0FBQUFBQm0yeGJvcU8wRWdQZmFJTVM5eWlsa0tvZE5YSnpaNDFZNjVydmZtdFlfLWIxTk5uc0VhaTFJdHF4dnhRbFMzU2kwNms5eXFYeUVVajBaa3pHcFBQVnBvczdXNWc9PQ==
"I guess you're asking why this is a useful definition. Well basically we're trying to find the minimal set of nodes such that conditioning on this set gives us all the information we can extract about some node of interest X. You'll see that co-parents, but not parents of co-parents, must belong to this set.

1. Suppose we have a collider structure, i.e., X -> Z <- Y. As Z is a child of X, it contains information about X. So let's add Z to the set of nodes on which we will condition. But wait a second, once we condition on Z, we have a path between X and Y, so they are no longer independent. For example, conditioning on wet grass (Z), whether it rained (X) and whether the sprinklers went off (Y) are now statistically dependent. (This is called ""explaining away."") Thus, we also need to include Y, the co-parent, in our set.
2. Now suppose we have the same structure but also consider a parent of Y, X -> Z <- Y <- W. We've added Z and Y to the set on which will we condition. Now conditioning on this set, does W contain any information about X? No, because by the Markov property, X is independent of W given Y. For example, once we know whether the sprinklers went off (Y), knowing the sprinkler settings (W) is irrelevant. Hence, we do not need to include the co-parent's parent.",r/machinelearning,Z0FBQUFBQm0yeGJvUjFoZDh1OVpfTGNYaVk5NDVyeWtWeV9PZFg5ZWxPQ19aejIyV2diUS1DY09DRGlPVDRnc1FqUHJ4M3lZWGxUMi1mM21KOGtfV3k3Q1YxTy1CWUtvc1E9PQ==
You made me exhale sharply out of my nose thanks,r/machinelearning,Z0FBQUFBQm0yeGJvTWlpdkZXWEhCcVdkRmNpT0Z6OWFEcDRieVpQZnZXMURvYWtLT2VPNDJSR1h5MHBzd2tDOGxYcWhyZEJCY0V1alJmdlJqV21UVmY2Y0hzY0I2d2o3UENiajRuTXhaU0xqSWJWdXllWE82elk9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJvejFhYnhaOEVlRzNmM1hTdDhzMU1iWFlqRFZQNmhlb2pTT1lqaVkxYkxnUW1LSlBxZHlyTjQwSVR6ZkxRT0VvdVZxZ004dXpTeE1yWEtXRWdPRS1LUmNtcVpFWERmcWQ2T2J0Y0l3c0hUMVE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvckZaMno0Rzltd2gxT3JpOFlFQU1FXzgzdk4wMTNGNnBXdFlJa2g5VEU3a0NMbWl3YlFiM053Rmtzbm1YZ05LYk9YMHl4OS1uRFpZemN3X1JoWWhpNUE9PQ==
"You need to rectify your license plate before you put it into any recognition model. I can’t tell you how to do this exactly, there are a lot of ways to do that, but most common are detection with yolo for polygons, and segmentation with smth like u-net or ultralitics yolo, but then you’d have to fiddle with polygon post processing to get the corner points.

Regarding the pretrained model, besides EasyOCR you can try TrOCR and PaddleOCR. I think those are the best pretrained general models you can find.

Unless you are working with tesseract, binarization would harm you more than do good.

Btw, you’d most likely need to train custom recognition model for best quality results. Plus, if you can control it - find the best spot for your camera. It would save you a ton of postprocessing work.",r/machinelearning,Z0FBQUFBQm0yeGJvNFkyYU9HYUtQUkphTlo3VERuTW13c3VqbWV4a1JkRU5BSlp2RjMteFNHRHNmMmYzclZsYVZCWXhkWEpwNUhJY2lRMjczX3pPb0VGaWV3QW1PT0o2M3NjcjAxQ0gxTmxwVzlsM2pJZkFfTmM9
"Have you tried using google gemini?  This new one looks interesting, but haven't seen benchmarks yet:

[https://github.com/OpenBMB/MiniCPM-V/tree/main?tab=readme-ov-file](https://github.com/OpenBMB/MiniCPM-V/tree/main?tab=readme-ov-file)",r/machinelearning,Z0FBQUFBQm0yeGJvZTZveDh0S0VvRG54WGhzMnZVUFlCQUd6Z01rOUt2YjBEelluNkJXRVpkWFNxSUR4X0l0RXFEMTl6YmZ2aTJSc1A1UzFQWFA4SG5nUWxMNzlkdmxOQ1E9PQ==
"Is there any discussion or reading group/discord for generative model (GANs, VAEs, Flow models...)?",r/machinelearning,Z0FBQUFBQm0yeGJvQXRZMkd0N3NZOFU4UTZ2MjlHMDU3U1ROZ25nenBNSkFZT3ljY2ljR2d6RWtiM2M2bVVZOFFPcHY0VTF5bW8tc0xCV3FNVTZwU1FNMlU4Zllya1FOQ0E9PQ==
"Computational universality means that all ways of expressing programs are formally equivalent anyway. Neural networks, cellular automata, C++, etc. ",r/machinelearning,Z0FBQUFBQm0yeGJvV0RWaWlubHZ1dmFFTThuaERsWGxOQWc1WlhYWURCUDR5QnVLZDg0d1NZWXNtOXJkNjhUYmEzbS1Ka2JnWDZKVFpjTlV6U0NYLTBzYjhWQnh6X0t0Z2VHd1VhTGVodUp2dTk4QTJwWGt4NkU9
You can almost pick out where they changed the chatGPT phrase suggestions.,r/machinelearning,Z0FBQUFBQm0yeGJvTno1QVRORmduSkpoVGRaeFcwOVFpbnpiUjFnZ2ZNWGZRbjd0bDlkM2kzRFZ4UmVsZXk4c0JPdVUwX3dHLXJoRFRKbkwtWTFiUmZTZ2NaMEhZZXdqcXc9PQ==
Yep! But it’s still harder to read and much denser. Where as the code is typically just the end result (but has all details) and fairly easy to read. I find they work best together. ,r/machinelearning,Z0FBQUFBQm0yeGJvY1J3TkxNRVpycGVmNE9NaklBeUpEUTlzM1hxeTFGUTFmTGdfOFROcWlQUnI2cG5EY3hXeFJIRlFSM19OSFoxOENTOE9pQzdpdnlRMG9IYXJhRnl1bFFBVW1XMHpNTms1aUhsWDJsUlgxdm89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvQUh6bndkZE9QUXpVZ2VmallfMlI0MWUwVWtyTFlFTVBFcDZqU0daZE1GVEZXLUc3S25pV1RrZ2IzSS1KWTQ2SlhXc3Zva0loMkZIY2VkaEI4bUxWMGc9PQ==
"I hear what you're saying and haven't read this paper but trendy title aside, the paper concept is hardly a conflict of interest and is very common in academia. Something is gained when common patterns are found and reported",r/machinelearning,Z0FBQUFBQm0yeGJvN3NHdEZ2SFU0ZWZGSm0wRC13TS1BRzdfQlMzeW53bmF3bm04M2VZa2JoQjlSeEYzMkFSSmZSWTRaTXhNUzhhUnY4WVJVeVA3RVltLWozYkFKd1BDbWc9PQ==
"I'm a long-time AI guy. In the oughts and early 2010's, C++ was where it was at for AI.

Now it's hard to find anybody using anything else, and I haven't touched C++ in ages.

Yet, Python is a pretty bad language for ML. It doesn't support parallel threading which makes data loaders really slow and clunky, and there's this pytorch dataloader issue where unless you do things right, dataloaders will have a pretty bad apparent memory leak. The underlying cause is pyhon's memory management idiosyncrasies.

Finally, you get like a 100x speed-up if you implement an algorithm in C++ over python. I'm serious, if your algorithm loops a lot and doesn't call low-level libraries, doing it with C++ nets extreme speed improvements.

Ultimately, C++ is pretty dated though. My guess is that the industry eventually moves to a different fast language like Rust, or python steps up and improves its memory management and thread compatibility.",r/machinelearning,Z0FBQUFBQm0yeGJvUk5jZE03V3drTjB4SXFRSFprczVwZ2pMVG5vMjVlSjFkRDd0ZHN2RTRSckV4ellyTlRrNENZWXdlZ0JYV3JjLUI5NHZCT1d6MERZYkE4YzBkMmw5cEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvSjlWQnlsaGdjSEtBSUpPZUFqdUJrLVRiN3RIVksyVEdiY2w0bUxUckFreFoxVlBYWUVEWXRWYWpGMkJyRE1ZdlNXV1hXOHpoTTBRTnFxTUQ0bm9NQ1E9PQ==
"Gradient accumulation should absolutely be what you look into given your vram limitations and tiny batch size. With a batch size of 1, you are functionally performing stochastic gradient descent - side stepping any benefits to optimizers like Adam. Your gradients will be so very noisy, your model will take months of continuous training, if it converges at all. It's more likely to get stuck in a local minima.

Your gpu is not realistic for this project. I would suggest scale down the model significantly to build out your train pipeline, then use a cloud gpu to train your bigger version of the model.",r/machinelearning,Z0FBQUFBQm0yeGJvM0w4ZGNmRHpnYW51cGhPM3VsNVJtSm0yNlNfT1pBakJ1RDdtZkFzei1ya0x4NlBESjRUNkRLOXJsSkxvZ0dJN1B5Y3JZQUNVczJIaThPTlZJUEdLUmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvem0xN0ota0xlZ1BIUDNWdzlfa3lrNDJqUWozOXVZblgwSlNaT1NaRmkxR3lfUWVxcTQwLTNXSHd5bDAzZVp3NHgtMFFJTFRoMDY3STdiWGp2dHRFdkE9PQ==
"> Gradient accumulation should absolutely be what you look into given your vram limitations and tiny batch size. With a batch size of 1, you are functionally performing stochastic gradient descent - side stepping any benefits to optimizers like Adam. Your gradients will be so very noisy, your model will take months of continuous training, if it converges at all. It's more likely to get stuck in a local minima.

Yes, it isn't realistic as it is right now, but my main issue's just getting the model to run in the first place which is why I'm not really talking about effectiveness much.

> Your gpu is not realistic for this project. I would suggest scale down the model significantly to build out your train pipeline, then use a cloud gpu to train your bigger version of the model. 

Yeah, I suspected that. I just thought that there might just be some other way that I just wasn't seeing that could get it barely running and scraping by. Thanks for the advice. Although, how specifically would you recommend scaling down the model (while still keeping it a UNet3DConditionModel ofc)?",r/machinelearning,Z0FBQUFBQm0yeGJvV2NURFd5WWlDcUdHdzg3Y2RCeThEbGhwNmRBRFJOcHQtWFVzNDg2dzVpdFNfLW5iemNLSGQ1VFZHQUYxNHdnc3Q2bnVnXzVjNFNYM1BOTGpDb2htTGc9PQ==
"Is that all of the data you've labeled or is there more?  I'd be interested if so, otherwise I may have the ability to generate a bit more timestamped data.  My need is for finding optimum parameters for whisper timestamping, so I'd like speech clips to be <30s, and a broad mixture of speakers/scenarios.  Would be willing to pool data if it's useful to others...  I have a tool for automating the initial alignments and making adjustments using whisper and Reaper",r/machinelearning,Z0FBQUFBQm0yeGJvLWh6Nmhud1k1OURQMUZ6bXNFNDJmRjhzLXlhWWd1TkVqZzVhZnNmV0NMaE8wNzR5cWJMMUhOZjh1RXBHV0xWOGZEXzdRVUsyZlRvdDRPbE83VkZ1TmcyWFVrY0dTS1lxN3JQaHowZjRTZE09
"Very cool, I always like to see new research on NAS! The colored diagrams of the different architectures you evolved are very stylish. It'd be nice to also have some sort of interpretation, maybe using the evolutionary process, e.g. why did a branch appear somewhere and what value did it add? Also, why is it called ""ein"" space?",r/machinelearning,Z0FBQUFBQm0yeGJvTkJPWHMyNTMxenRnTmZibExHLUgtdG82MDlXcTh6anZQUVg5RHlzd0g3NXdJTWdsMmJKSFl1eWJyZUNJZ0M2LUVQWkZFTzJFa3g4Z2VlZkl1VmxjZUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvYk1iNk9fVm10XzFHMnlrOUk4cVFrZl9McW11Nzg3Y01rWnV4Q0toZWp2T0VHYzhGSFE1UGJoUnhLX1E1LTY3M3dwYmNGdTdjUVVmTE05eTNwd1ZROWc9PQ==
I think I might try out pytorch at this point. I just spent at least 24 hours over the past 2 days trying to build from source for optimization flags and literally threw every goddamn BUILD FAIL at any chance it can,r/machinelearning,Z0FBQUFBQm0yeGJvbEV2ZjN3WmFqOGlqZF8xQUhlNHAzNFBEMGQ4THcwdlRUUU9oSFMzUFlEajlBcEFnUHZSN0dyNWxwNHRHUHhoZkg5TG9kU1Z0Y0labldVY0otWF9fSWc9PQ==
I am still thinking about what to make of the answers but I posted sth similar yesterday so take a look there too: https://www.reddit.com/r/MachineLearning/s/IFXbZoE60Y,r/machinelearning,Z0FBQUFBQm0yeGJvVTZMekhFSW14OTk0MHp0R1UtcDV5S2J0dEd6UWQ4Nk1fT1ZHSFM3Vkt4LU91bS13SHpncFF3ajBzX09qMFpoZ0kwTTdkNC1SVVJhcWhGS0RER1Vidmc9PQ==
"Good thing they also have a C++ library for the low level coders. Python is great to try and test ideas, fast iterations. Libtorch for optimizing for real training and implementation to squeeze out just that last bit of performance when deploying the model.",r/machinelearning,Z0FBQUFBQm0yeGJvTE42QkxfeHZqLW9YR1pKbmNaSjF5T2lCRFJRdUVSc19FT0xhUDlyak1OSVh0eml1YzZROHF6M3pnM3ptdDFhMmNjek5MOXRfaVB3ZkJuMWhDb3A4V2c9PQ==
"Looking at the source for the model:

https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unets/unet_3d_condition.py

Here are the hyperparameters i would look at:

Up_block_type and down_block_type set these to UpBlock3D/DownBlock3D as these aren't using attention, so will use much less memory than the attention version of these blocks, BUT at the expense of model accuracy. 

Next look at blocks_per_block and block_out_channel. These are scaling factors, so reducing these will result in a smaller model.",r/machinelearning,Z0FBQUFBQm0yeGJvU3dabDFBR2VqT0VUdHZLdlhEQTFQaEEtSmsxalRhUEYyUkpkMjdiTks2djRSeEcyemhGSUtVUWNSWkNBQ3JwUmFDY1NoOU5LMEp1NG1TdDltOTFZSkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvMzZrOVdmbzdrcGcxQUt6Mnp6bDBOMTM1TmhNUGMzNmxrSXo4TGU1bzFBWlZGQ3YwRjg2R0owNnhNM1lXTlJydnpqNkt6aHFBSWZzcUhQYjgwVUJQa2c9PQ==
"C++ plus domain knowledge e.g., CUDA, ROCM, and how accelerators work is a high demanded skill. 
These are domain experts who write customized kernels for models and extract every penny of performance potential. 

Good thing - pays super well. Very good job security. 

Bad thing - small in demand. Only big companies need these people. Can take many years to master the skills.",r/machinelearning,Z0FBQUFBQm0yeGJvUlo2b1NMVVZhQ1Q4X3lfd1RTZHNnZERZdTNodWVra2dJRTN3NWU5a1I1QXgteUh2cnB5ak95Vk9iWjhmcFlQLUgyTUpHTURISjFyTXgzSmZuLVM5NWc9PQ==
"When you ""drop the softmax"" in the attention mechanism, transformers can literally become anything.

Why do SSM studies (H3, RWKV, RetNet, GateLoop, Mamba, SSD) always need to make a point that it is some form of surrogate attention mechanism. Maybe needless but necessary math jumbo-mumbo to convince the reviewers and the community that ""SSMs are the new transformers""?

Let SSMs be SSMs and transformers be transformers.",r/machinelearning,Z0FBQUFBQm0yeGJvV0ZXOVFkOXBHSVFWaGZiUnc5TlRwMFFmTGNxMFVkZkttZC1fdDNFeUxITzJaajdPY29hSnpUU1h4SG5lWEY5NVJtb0ZsYlFhVDFKOFB3Q1RRVW9ETmc9PQ==
"Not unrelated, [RHO-1: Not All Tokens Are What You Need](https://arxiv.org/abs/2404.07965) suggests a novel answer to the question (and a few others). If your examples contain ""idiosyncratic"" tokens, attempting to optimize next token prediction loss on sequences containing those tokens may be negative for the model.",r/machinelearning,Z0FBQUFBQm0yeGJvMFRRakRlSnZFb3A2THlMZ0Z6WTl6SWpjanFCTUs1Q1N1WFk4d3lsNGJ4LTdscmlES0h5ek9ZeUU3MzZrYU1UcVVBc0xGQ2YtRlRBTTVZbV9JcUpFOUE9PQ==
I'm so susceptible to this kind of thing. The last paper I read always seems like the most amazing concept since sliced bread.,r/machinelearning,Z0FBQUFBQm0yeGJvSEtmYmpLQTNZM09oOVZhQUtGWFNKTTZpVGh5czYxRHUtRldYUjNDeWhSSkwxeGZBekF5aVlsbXRPSURPRFRUWmFJLTFTcFdOM3VYYWU4M3hyTGdVaXc9PQ==
"It's valued at large companies that need performant solutions. At smaller shops very little that you do will have latency requirements that necessitate using a lower level language like c++/rust unless you are in a niche field like high frequency trading or doing some work on the edge. You will also have shorter timelines at smaller shops meaning you won't want to waste time implementing things that have already been done by someone else, even if you can do it slightly better. 

I don't think any of this matters though. People put way too much weight on what programming language they prefer to use. If you can learn Python you can learn c++ and vice versa. People that claim otherwise are either not good at programming or not good at learning new things. Just learn what you want to learn, and when the time comes where you are required to learn something else then learn that. It's not like you are stuck with whatever you choose first.",r/machinelearning,Z0FBQUFBQm0yeGJvcWh6VVdocjlaQWdpNHhSM18xcnpMSE1SQjRRVG1ObEZIY1c2eHVpTjFaRGU5Ri1UbDc3WUJQTTkzdGlBSFhzY29zUktmb01YMW1kMUo2SkhXTzJWU2c9PQ==
does RTX 3060 Ti only got 8GB ? I have a 3060 which got 12 GB,r/machinelearning,Z0FBQUFBQm0yeGJvTy1XWWM0RVBJZ3d6Vi1iclY5U2hJak00TzVNS3dGLUhlNTd3TE9lY244TkxxZjF4QThkbjJfcXVCNk1QR0Q0UjYzSDhOMG5CQWJibndGWUtSdlBxWFE9PQ==
"Also note, Intel is shredding a lot of their DL talent atm because their approaches to getting a break in AI have not been successful",r/machinelearning,Z0FBQUFBQm0yeGJvRTV2YTRFVG9WUG90d3dMTzJENUYxRjllZDFoWFRaRWVWVWdzMWQ3QnRPNjBsc2JzUHdRZUh0VGZ0MV9MUlMtenJycEl4dWtVYzVpT3ZlNUZRNGM4ci12T3Nmdjhpanhxb0hQcy1QOWJHOUE9
the intuition being that you want to distribute changes uniformly across parameters and learning rate should not be a hyperparameter you tune,r/machinelearning,Z0FBQUFBQm0yeGJvTlNDclViVFMxSjJQb01leGF4NFlmVDFFODBoZWk2Z0ZaSU1LSXRJSlh0WnJ6N0pZbkJzQ3ZXVVdDcFVYdllqQ2xRYXFCTDZyUzZhb1U3eENPc1k5dkI1Z2NrRk1PVUdEQUV6Z2tWR3hTSkk9
"I've actually already reduced those and more significantly (except for blocks_per_block which doesn't exist unless you mean layers_per_block). I probably should've sent this earlier, but this is the last thing that I tried which still ran out of memory and crashed:
```py
model = UNet3DConditionModel(
    sample_size=config.image_size, # 64
    in_channels=4,
    out_channels=4,
    layers_per_block=1,
    block_out_channels=(16, 32),
    down_block_types=(
        ""DownBlock3D"",
        ""DownBlock3D"",
    ),
    up_block_types=(
        ""UpBlock3D"",
        ""UpBlock3D"",
    ),
    norm_num_groups=16,
    attention_head_dim=16
)
```",r/machinelearning,Z0FBQUFBQm0yeGJvUFN6TWRDMHFaZk12aUI0cGJCcGxDdGtONXJsNlJkWWZfSXBxaFJYdFF4a1VnZjJma2VsWndhRXpjN3BWdjgtNEpZNkY5YmMxZW12czc0WXRxdTloeVE9PQ==
You're probably confusing the RTX 3060 with the RTX 3060 Ti,r/machinelearning,Z0FBQUFBQm0yeGJvYU14eDZtY25WeDFUQ3BqQ0d1VXJrSm40TVpOTWlTUTZNMmNkODBoVEszTVdyOVdqVXZHRERNTm5DcG8tWjdJVGlKVEJ2a1AzelFlRG5hZzI5V0xpTmc9PQ==
"I think it’s best to show an example, many additions to PyTorch require a mix of C++ (with CUDA) and Python. Take for example, Flash Attention v2: https://github.com/Dao-AILab/flash-attention",r/machinelearning,Z0FBQUFBQm0yeGJvbDZtSGJlWGczV0hFVTB2ZmFRaktvNEw1U3ZKM1JBbU5CUy1ONEticXdyMl9HMzlxaGIzcjF3d3FNVWZyMkxCbFdrYTA2OWtFbktkQXhmZGJaMTZ2ZlE9PQ==
"not confused, I asked exactly the same, why TI got less VRAM ?
i.e. you can simply sell TI and get a cheaper used 3060 for more VRAM and keep some money in hand",r/machinelearning,Z0FBQUFBQm0yeGJvcnhsakQ5ejVrazhwdEFQR3BTNzBIZ1A0M2s2bWtLMjNkRjNzcTBUSnc3Wm5rOHVzUXliaVVqak5nSUFQcDFoeTdrTUpTLWRhbEdUZHR4REg3U2JLcHc9PQ==
"This is the equivalent of the energy the average westerner wastes in a few days compared to what people in less developed countries use. There are hundreds of millions of people, very few of them are donating their outputs to science. So it's like a tiny squirt of piss in an ocean of piss.",r/machinelearning,Z0FBQUFBQm0yeGJvM2lrQ0FXaXZGUUJoX0cxajZYeTA4RnFpNHVweWY1SklWWWJWZTZ0NjdCV2NpWmJDa0UwNFRlaEJRTUZGNkhVZFJZdEl4WHRvaFFvU2VSTzlvbFpzNGc9PQ==
"Ah, sorry about that. I misread your message as referencing the RTX 3060 Ti by saying ""3060"".
The RTX 3060 Ti and RTX 3060 are 2 different models and just have different RAM. Nvidia decided so even though the RTX 3060 Ti's supposed to be better so that's how it ended up like that.",r/machinelearning,Z0FBQUFBQm0yeGJvejYwSEQ1ZThuem5HbGp2dTNvakJaT0VuWmpVWDJzdW5nSkhjdjdHenhjZ1VBRnRQVExxWmFObC05bGYtRWFyd3RPdS05amFnUWxSTVpiWG9yT00tNnc9PQ==
"there was no TI model when I got my 3060 upon release as a gift from a competition. Helped me a lot to getting into DL as I was using 1060 3GB with batchsize=1 before that. If you are into large models, try to get an used 3090 24GB, that is what I did and got a ex-miner 3090 during ETH split.",r/machinelearning,Z0FBQUFBQm0yeGJvOVJxNnBBRFdjNjFtYjlzanBXeTE4YWFQNE03R0NMekgxb3hibGN3NVZKWFRoYjN5R3ZrWlZEd3NhUVZpd2hLd3B1QmtOb0VtWnlscmRHMW5RNWJxdFE9PQ==
"Most of my work's with smaller more easily portable models that can be directly used on consumer hardware which my RTX 3060 Ti has been pretty good with so I probably won't need it. Altho, yeah, maybe I should consider getting smth with more VRAM in the future if I do want to try these larger models. For now I think I'll just try using another architecture I have an idea for that should work pretty well for what I'm trying to do.",r/machinelearning,Z0FBQUFBQm0yeGJvRVNreWJXd3ZlOGZyNG42M08zU3RXWW1MX1Y5bTBCcFRITm5rZEFxQkxQT1duWlpkWlZjY21xM19HeFlmakR3SlVkTHJSdUo5S2I1NUt1ZHJVLXNmTXc9PQ==
">Creating high-quality scientific figures can be time-consuming and challenging,

Not really.

>Furthermore, recreating existing figures that are not stored in formats preserving semantic information is equally complex.

But it would be pretty cool if you could get this working",r/machinelearning,Z0FBQUFBQm0yeGJvWjdTNXdKMngteG45MjF3b2g4RFVZRHQwQWZuTE10XzhTNEVRZzJqc2EzM0c0RWlRcGFabkQzaTd0Uk9IQlVha1VobjBRZ1hiYVl5MjlGaFdJVUtQVTRKUW1vdTRaS0dCZ2hzM3pyYlMtbk09
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvVWFzb0R5VHo5aFJjNGMwbjRCTnBpbjNlNXlzZGVFZWJxQXQySDZUcmxBN2wydVBZNnBES2FUeFgwUWVpOFlrM3FJZEl0M3M0QVBmejdmakZVYWJDNGc9PQ==
"You can get a general feel for energy use since money is basically work owed, and useful work is ultimately work that's transforming the planet's mass from one state into another. So pennies earned are planet burned.

Take GDP per capita, divide by energy costs, and it looks like westerners piss away 500kwh of energy a day more than everyone else. A megawatt hour is about what the average McDonald's uses in 2 days just on their branded packaging 😂",r/machinelearning,Z0FBQUFBQm0yeGJvNGd2dG5hbXBvSzZpbkYyWElNbm1ENENCNEdYMmEzcVZFUFJYUFFrbFppSEtwR20wZDlsZmVvOG1rQ2txQnB5UUkzOUN6cDAweHYxU1NMajc3NTEtT2c9PQ==
"The authors of that paper: Chat Geepea Tea, Je Minai, Claude",r/machinelearning,Z0FBQUFBQm0yeGJvTzJEOXBuMEtPWEpRbUtwV3dhZ1ltZlE5LTBkZUN3YlZ1SFFXWUNqbVc1bWNNMW9tMmNvcDVHX1JsN01oT05qTDZJdkdPOWtWQjdPZnBmUUNYbVVxd3c9PQ==
I would say the opposite: transformers have seen a lot of hype mainly because they were involved in one very public application,r/machinelearning,Z0FBQUFBQm0yeGJvZXV5dE14M0hsa1Zobk5HeVotcldKU0JtcGxsaHdhblpheVpsZmk2Qk84bVd5aE5UWHVMOGhkb2NlVWw5YzhhRkZDVTNMTjRXbTQyTVBHVkgxLThZTEE9PQ==
"Authors of this paper are good follows!

https://openreview.net/forum?id=5Ca9sSzuDp",r/machinelearning,Z0FBQUFBQm0yeGJvMkgzS1hBY1N5MWdpT1l4QWpzS083cmVHcHF4eUh6c0Y3OHQ2SWhpLTZpVTZLVVlaUUlJZXBTcE5BdllmR09IZzB1ZFlJaWI0aE8zcG9SZlZtbHZ2SmtJa243OUlINTBsRkwxTXY2WHJ0MVE9
Earn while you learn.,r/machinelearning,Z0FBQUFBQm0yeGJvWk1RS0R0OC1EcHBOaVpoTG5lSXRaYktDWFh3eHJEVnlnODlWYmlIcWJfQTY4N1p4UGJteGlwTnYtMnpBRGtpOVhuU3pQVk5lekZxNkpXY053ZXdsdXc9PQ==
"TLDR is my go to, feedburner, [news.mit.edu](http://news.mit.edu), techmeme, theverge",r/machinelearning,Z0FBQUFBQm0yeGJvUENhQURJS1MzbXlrWmREUHI4eU9xSm1xaVliV0V1eU1mVXp2eHZ3TFplV0s1VURlZDBDOVBBUDdRU1I0dVhEdTVncnhqWmRrc3k4QU9jdzJmQ1U5X05NVTVpVUplSFBHUllvYnFPeWhNdHc9
"It will rise again, look at llama.cop do it and be among the first one doing it.",r/machinelearning,Z0FBQUFBQm0yeGJvNUZmVHRLRnp6QXdUZlpIREVMSVFnU09oWF9OZUpjVVFCTk05VTZfMDQtdXZhQTgzWVBEX0diTVNsT29fUVVRV3Q0a0JXSEZmeUxGR2k5SC13VS1BOUE2NlFkZWVfR0otQmJTVW05eEtUZDQ9
This is awesome! Btw how difficult would it be to modify this to enable token classification?,r/machinelearning,Z0FBQUFBQm0yeGJvOHV6b0NuS2FSYUxNajR4Q0FxcHFFV1F6c0k4WXVJOU5HaXRNYTZ4Q1FFRm1odTVBZjdLcDNRcjgzenZhSFdqNkl6bzh3QVQ3d0xpTzdoNXVlR0VSVmc9PQ==
I would give this 10 upvotes if I could. This series is amazing. Great job and beautiful presentation.,r/machinelearning,Z0FBQUFBQm0yeGJvam5qQlg3Uk43NWlwbWpCbXU4bmsyWms0Y2RXdzZfcFVWNE55bElpNkk2ZXVVRjczMFpLZ0xrUTl3a0JfTGhmd0FYcWVwUVVtUGoxbjF2a0hvTWpxeGc9PQ==
"I don't care whether they look at their phones, but if you are spending 85% of your time on your phone doing work-related stuff, I feel like a laptop would be more efficient.

Edit: just realized the thread is 2 years old, oops",r/machinelearning,Z0FBQUFBQm0yeGJvdGlQOFVyVDZGVDE0Zm5zQVlHaU93N1RwM3NmQ3p6SjJwQzNTakN6Z2plMGgtTUZMVkZENjRTTkwwbjVROWo4Z3hNNUlWc2NHcnpVdGVDc3hWNGRxZWc9PQ==
"I would agree with your assessment, they are not comparing the images at all, they are probably just using LLM to ""grade"" the similarity of their prompt with your prompt.",r/machinelearning,Z0FBQUFBQm0yeGJvZlIzeVZwY2h0SXhQV3RfaUhPU3Z2VEc4OHJFazlJR3JYbTdEdUtjcXVnc0ZiS2hmdVRjeFU5TEJ4T3BzaHI3SjdNX3JBY2pYNnNsZ2kwaXYwYVFqX0E9PQ==
"I really like dealing with this kind of mind boggling stuff, it only takes some time... Thanks for the reply!",r/machinelearning,Z0FBQUFBQm0yeGJveHZTekVwMy0tajhoellaTmVReU0xaHNHV1ozZXo0cWRtemdLb1dZOUJ4S0ZSUjY2ZjBSTGxOMHpCYm80azhVV3ZlS2ZNbWg4U0dqbDRINDdIcWNjcFE9PQ==
Why rust?  What kind of implementations it could have?,r/machinelearning,Z0FBQUFBQm0yeGJva0VkUWlZbm9Rd0VzbDZQWW1SSTZLTXlTbWJLUHU5eGVpaGI0Sm5QWGpBVDZmdnplYzdsZ2x1UllOR2tPXzBzVUJiZzB6d2I0c3p4NWk5ZEI4Z1RwQ2c9PQ==
Ugh yes ... Thank you for your time I,r/machinelearning,Z0FBQUFBQm0yeGJvcjI1T3k5d2FoU1BkaTV1bzhQSGt4ai14V1ZESVVJTFFZYS04TXBpTER4Y3RhZWVEWFhXY0wzYzQxWEotcjYyTC16UVZ2WElybk83Ym50WG5RLU5weXc9PQ==
is this something to do with diagonal matrix and identity matrix?,r/machinelearning,Z0FBQUFBQm0yeGJvbk9vUU9qTDV3cVppSFVDVzVUak9hSmZnMjJWOHc5X2lHRW9CaGVGb0ZUd0FCTnRiMC1VUnM0Qkc1UDItWHhiemVacHRIRVh2NU9UbTM5T0E2a3puOUE9PQ==
"You are right, at some point overthinking what one should do is time consuming. Thank you.",r/machinelearning,Z0FBQUFBQm0yeGJvd2syTjRMNms4SlI3b1dST3lfYnp5QzdBcl93WnVzUDE5WnNSbTRDZDlwUDhRREtuN0ZEWGVlWEVJTlRIcm1OeGdGOE1kU0Z2Ymx2aC1sWnZ4UEhhX1E9PQ==
Interesting... Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJvSmpTWU5rZS1oRDFERk95YWNpNUJ1SzVIUF85RDFNVHpVWkxINkZoQWh0anU2YlpETlgxYUp2RmZDa1JNdEdLV28wc0tSNHhtSGJ6VjBWcW1YdEhHZFE9PQ==
I see.. thank you!,r/machinelearning,Z0FBQUFBQm0yeGJvcDM0N1M4Tzh1b0VWZjVtYjZPODVvQTdOa2VTUmx1Qk1oRWkyTHV2YkFyRlBxTVhCZFVoMlduVzNIWldtWElrWUZPQjNQSURSSWpkdnJWanpHck9Xc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvbDJ0eHB2eUVMN3BKMWpmbnJWLS1pbElaYVJsR01DeVBNWXQ0d1pzcUNKNUd0Z3JqRFgxVzZQQlJEWllpMVNRUktWWWZOWjFGbDlWVUNXRkVfZGlxT3c9PQ==
"> The GPU memory required for Full Parameter Fine-tuning is primarily related to the size of the model itself. GPU memory usage is usually **twice** the model's parameter count

This is the lowest lower bound unless you do something pretty fancy w/ pipeline parallelism. Lots of intermediate activations are saved during the forward pass to make the backward pass faster, e.g., d/dx σ(x) = σ(x) (1 - σ(x)). Not storing (and instead re-computing) this data is the motivation behind gradient checkpointing. And storing this data in half-precision instead of single-precision is the motivation behind mixed precision training.

A better but still pretty useless rule-of-thumb might be something like 5-10x for a batch size of 1, idk. It depends on many things. TBH I just hear what other people tried.",r/machinelearning,Z0FBQUFBQm0yeGJvLVhDQm1uN1E4dzJwbzIzYTEzTm1qckdmc0s3eEdYck5aNlFCb3VrbUFhbTJiZ2hPRzdIRVNwSzZEamtXaDVUMlMzUk1uVWZNZXVRTjBpdXdvMG5ka0E9PQ==
Checking out!,r/machinelearning,Z0FBQUFBQm0yeGJvWi1LNVRTbnc0SnJrSFhtYS1xSkZMUmloNHZpMlFDZlhzV200X1hGRGh4Q216MXJ5ZTNXQTBlSW1aY2xtQ3lNc3R6LW1YcUo1dkNGNU1WV3A5WTF2UXc9PQ==
"> SFT requires a sufficient amount of data.

Few-shot SFT can definitely work. It depends on the task. The reasoning in this paragraph is too vague and probably wrong, given the success of few-shot learning.

> This leads to overfitting

Do people really use SFT models to do out-of-training tasks? I was always under the impression that SFT models are always used to do one task really well. This is why LoRA is so useful—you can efficiently train, store, and serve lots of ""versions"" of a base model to do many different tasks. Given this, the ""Generalization ability"" and ""Multi-task learning"" bullets seem like things that should only be applied to settings where you know lots of tasks are actually quite related and would benefit from being trained together.",r/machinelearning,Z0FBQUFBQm0yeGJvTWhUNUVveXdHSzB4TE9JOXZzNnVfWGJhNmU4ckh3cElPTHN4c29FYWFfWEEwejN1OTA1YVRkRXlKUFhCSE9sZF9sOGp5RFZiSFExM29KaWRZazZGYlE9PQ==
"It really depends on what you want to do. Many other commenters have stressed that most modeling is done using existing Python libraries (e.g. PyTorch or JAX for deep learning), and it's hard to disagree with that.  Especially for developing and prototyping new model architectures and / or pipelines, it's far easier to just do this in Python.  
  
But, it's easy to find papers where authors suggested either new model architectures or more efficient solutions to a problem that required low-level manipulation of array data that would have been challenging to do using existing libraries. So, they had to write their own C++ / CUDA code to get the job done. The first two examples that come to mind are Mamba (https://github.com/state-spaces/mamba) and bitsandbytes, which was used in the QLoRA paper (https://github.com/TimDettmers/bitsandbytes). There are plenty of others.  
  
Also, keep in mind that data preprocessing for large datasets can be quite slow in Python, and if you know how to write a C++ extension (e.g. with nanobind) to handle the rate-limiting steps, you can accelerate data prep quite dramatically, and this can be invaluable.

TLDR: You'll probably end up doing most of your work in Python, but being competent in C++ and Cuda can be very valuable for specific applications. I don't think you'll regret learning how to write a C++ extension by any means.",r/machinelearning,Z0FBQUFBQm0yeGJvSzE2bGdpYlVqNndjX0dzUG5wZE5aeUNPOVpfeUZXd296OEpNRndtSmtpSkJLQzdRSllER3A3d29nV0Y2Z3dWR0hKVXFlTjJZcnhwVzRyZjlLNmhxT09mXy14d3BEalQtNlpydUZadTlQYk09
C++ is dead and used only for low level tools.,r/machinelearning,Z0FBQUFBQm0yeGJvdmJMN2p5Mm14cFpRSVBDQnNkWE9DanZxRWRNTzhMMnctM09faUtfcFR2dENRblFPRGpyT0F4VHBKSktBNnNQbDlKZ0htZnQwRTEzd3BtdVZDb210SkE9PQ==
"Lmao right, how is the inventors of a tech explaining how it’s linked to another inspirational and well developed piece of tech a conflict of interest?",r/machinelearning,Z0FBQUFBQm0yeGJvUmZYRXRRWUhmTnFyWFc1TEhlUHhJQ016dm5ScVI3YlUyWllzRHZ6MGxhSkowOEltLWtoc19OQzhURDFBVmRlMjVVV0wzN0RVUjR3MXFCLXFhOFVmWVE9PQ==
"As far as I can tell not really?.  
Taking the title more literally on the title there's a lot more work on cnn [https://distill.pub/2020/circuits/zoom-in/](https://distill.pub/2020/circuits/zoom-in/)  
But I'm not aware of any mechinterp work on vision transformers specifically.",r/machinelearning,Z0FBQUFBQm0yeGJvSFZfUWxYUGd6R1NiVEVnX05halQxajdOdC1FVXJtQUVhOHY2ZDlDYUFmMldLbTZ3eTJzaWVIUGRhN193aTNaaDJKMDVmR1liY0hoYUtsdkllX2s2ZGc9PQ==
Love this hahaha,r/machinelearning,Z0FBQUFBQm0yeGJvWUkwamhQdHdzYk5CNHNuaWJuc1BCdEN6Zkg0bHBkUjlMQVFneGN6UjhoLWY2b1dlY1pCaHJVaUZvZkFBWTVxd0Z3N05jc2lQbDdXbldMV0hQZTN5T2phZGZSZUZtLV9XVVQtUGJTTVUza0k9
"Wow thank you so much for the detailed reply
I’ll try these out today and post an update here!",r/machinelearning,Z0FBQUFBQm0yeGJvVV9rYWRpZm9JcXBEaXJqRzdiQ2VTT2NqU0REUjZjZHVUVE9IVmozU1gyckNhaTRsQUFUODhzSGJNeDZRZlFWWHZleXBDaGZUYXU3SE5UNTZlX3QtVkN1NEs1OXRNc0gzYlVZSVZQR0ZHdmc9
Actually I didn’t think about it. I’ll try it and give an update,r/machinelearning,Z0FBQUFBQm0yeGJvMTRMd0tOUzJQMUtIMDdtSlBaaUdNRTdvWkZaaEFBRU5CX2tMWkNkOUIzdXY4ZnpjNmZoTlc1SElCRkFtWjFUU29ySGMwai1HNkx6TWgtdVRXQ0lDbDR2QlBkZGRrU2tYS2tjSS1tZDdGNU09
"> In addition, results on the largest models are showing that the data itself is the bottleneck, not the architecture.

Then especially transformers need to be thrown away and never be touched again. O( n^2 ) is awful and sleep inducing.

At least we don't need O( n^2 ) memory thanks to previous work of stinky SSM propagandists. ¯\\\\\\_(ツ)\\_/¯",r/machinelearning,Z0FBQUFBQm0yeGJvTDd6S1RGcVdBVkRmWS00R2R5LXExaDYySGc0UjNGcGRzQmRhZFJKVDJSR3A4TFJ5eTg2OHBfT01wZkt1UkpTYXVFNkJiX2taVEVKYW8tZGtGR0V2bFE9PQ==
">I'm so susceptible to this kind of thing

I name thee FOMO-O-Mat 


😂",r/machinelearning,Z0FBQUFBQm0yeGJvVXlxamctY0RRNkhxY2hFV2FsNVZmYlhGMTQ5Vm1IOEhuaEczWWNzSWpUWWRXM2JtZTgxR01FR0pkdXY0Rm1vUi0wSVQ1X1M1Rm1yNEUwQlZVbGQ2a0E9PQ==
">Je Minai

I read this as Kylie Minogue",r/machinelearning,Z0FBQUFBQm0yeGJvR3JXN2tONlVGaGp2elhXTXpYSndudnA1QW83cHgyejNGSE9rMFVrNzN4bXI0MWZ6MXF6aTFocTcxU1lPb0NLbnZSMTJkcWViTUlMd3NlWHl1NldMT2c9PQ==
"You know... what really frustrates me is the fact that most of the work is done using libraries that oversimplifies everything to the point that people with no CS background can do it. I wanted something which requires real coding and engineering skills that I can enjoy do, and this is the reason behind my approch to C++.",r/machinelearning,Z0FBQUFBQm0yeGJvcXlwbXI4c3Q5Ylc2SzVwYlR6allLcVY4Z01CclFKV1BWMkI2WnduWG1abXRHLUxKdGZaQ3J1NDRQR1BjeFdLWkJqNjEtdldZalhtR0dYVTdUVEk3R0E9PQ==
.,r/machinelearning,Z0FBQUFBQm0yeGJvbENVX3NzU0RvY1Z0clRLczNjVVlKUjRvTDRjWTlydHlwbDU0ZEFaQzdkSmtZZXhneTZlYkI3NEl3aU1uOUlvc0w2RVpURENxaUdVc2duQ3JCaXJGemc9PQ==
Sounds like a perfect use for CLIP score..,r/machinelearning,Z0FBQUFBQm0yeGJvb2lhMHptRHY5cUxjY29hVjRfWFM4MG9Yd2p1OXBNNFQ1RVYxZWpPdWxPUlVZUGRmUG5tZFd3WHh1Y3RZSDhWb0xRV1d6cTZSQ3M2OFZMTkx6S1ZyUmc9PQ==
"https://docs.cohere.com/docs/reranking-best-practices

Check out section ""Interpreting Results"". Tl;Dr you just have to tune the specific threshold on your documents. IME it doesn't work very well, I think in the future I'll consider tuning a BERT relevancy model, but as always getting the training data is a headache",r/machinelearning,Z0FBQUFBQm0yeGJvbkNzZ2dkOTN4SVlhaXlrdFBBNnU4MU8xdW02bFFkYmszVk1JX2pwQjd5TndHN3h2c3E2cktzMmktRFJtLUQ2YldfV0M1VFlSOUtnYzhLWHN2UHpfeWc9PQ==
If this is for training and not inference why don't you use a colab t4?,r/machinelearning,Z0FBQUFBQm0yeGJvOWNNMF9jOWJSekNCdk83eFFHUUdab3FzXzRaX3hYM0UzMklObmY0eUxzc05JclhFYmJCWUJWZUdtWGh3Z2U0V1YtcG1vZEk5cGw3WjdDY2I0c1B2TlE9PQ==
"You use NCCL for this generally, not MPI",r/machinelearning,Z0FBQUFBQm0yeGJvQ3FKTFJBSkNteVpqa1RucXU1ZG5hLW0yZV9UTVhjNHFmVlg4YUZFRDBpWWEwR0YtU0JlYnVqRjdPdmowNENRMWNKT25xNi1rbWJDVGw3b0dnSkVRbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvUm1UYjlreWZ6UXgtX2NwWEdraDNBMFh0OFVNdndiYjNiSjZfZUhSR251NlI4X19xdnVWTzcwZDNnNGxYQnpkZU9UVXAzOWhNRkU2cVpYTGFUQ1BySXc9PQ==
No. Sorry :/,r/machinelearning,Z0FBQUFBQm0yeGJvQk9rQjAyMWlPeXlHdHg1TzA4RHozak41Z3pxM3lyX3JwRHVMbmh3RkZrOUxpSU9GSV9HMS1iTldKamJTa1V2OHByYWZRUFJwQm5hcDlJMG5GOEw3UEE9PQ==
Small models are trained with data distilled from big models and evaluated with big models as a judge. They benefit a lot.,r/machinelearning,Z0FBQUFBQm0yeGJvbnViU2hma1ozajBLc3NaVFZ6eGRfMS1DS0o1VDBtMHpfbDRLeG53V3gxNC04ZVRBRnNWRFI2TXZWUXA5ZUJwX0tPWVdsSTBCZGNVc2d0a1RIOTl5TkE9PQ==
"Thanks, looking into it right now.",r/machinelearning,Z0FBQUFBQm0yeGJvWGR0OHNzNDhkNDZER0d5MThmUkNCOWg0QkZ3Y1ZwY0R2UjR3LXVKNlgyV1VYeU1hbnpLRXBGWUJpWk5xMEVHZEdYUnQtcHphWi1VcEd4bThwcGhQVWc9PQ==
">  ameliorated to the point where the LLM's error rate is lower than that of humans

Which humans? those who Google everything? our hallucination rate sans-search engine is getting worse by the year. Human memory is constructive, like LLMs we hallucinate our memories.",r/machinelearning,Z0FBQUFBQm0yeGJvV2hKTXVidEFZU3pUcTdmb19KZzdxNDBvN3VVOHhZRDEyY3FWTC10bjU3SHpBY3NwYi1LamRuT1JkS29BcTkwdHJ3eURFeW5oRERVVXU1Z1ZCOFA2RGc9PQ==
"I am a high school senior. Can anyone give me tips that could make me stand out in the herd? Also, I have a question regarding these conferences : Is it a necessity always to have a novel aspect in your research because I think that innovating a new neural network architecture with my current expertise or computational capability is out of the world. So, how do you think I should approach this conference to make my computer vision research ( wildfire detection using a CNN ) stand out as it is already being done.",r/machinelearning,Z0FBQUFBQm0yeGJvSkFaa3FnYjFPbjRfMXEyMTVQQ1NzdGxIazBSMUxxd1pnUi1WU1I3Mk1PeUxnQWdVN1hkaTgxYV9rTHZlaWc5UDgwa3l3bFFqZS0tdkg5WlhCcm45Rnc9PQ==
"Automating data prep and cleaning would be a game-changer, especially for handling diverse datasets!",r/machinelearning,Z0FBQUFBQm0yeGJvZHN1bHhFNmFDQ2hMcHc2S2lPZWFVbmQ2U19FVEJzNm5namZpSVZhMkNTMGV4eHpHdmJGNUQ2UGlBV05tRHo0UVFDVEl1RHJaU2I5RnRpZ0NXRm54TWc9PQ==
Good thing that NCCL implements most of the MPI standard,r/machinelearning,Z0FBQUFBQm0yeGJvb3hhSWdheUszR2RIYjd5OUV0UWpRek9TUHJrUWlPcW9IeWk4eHJFR0JrN2JjSEZ6OExwR2tBSVo3VFFtNngxc1kzZVNLRFRPM3BiNFNkVkwyc092VHVCMF9YR3pib0w3VzFRYVQ0Q283cTA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvSFBaN0U0WmxKOFNycVVMZ3BXbHhMUFBBenhBazJrd3hkb1QxWWZYR0FvMjNRdlJYNTUwVS1ncndIMWVzVTUtVE1ieldORlduWUsxTld1a2lBYXBJbVE9PQ==
"Do you have or plan to publish this work as a paper ? 
This seems very interesting !",r/machinelearning,Z0FBQUFBQm0yeGJvZHJVckg2TmhGaE94LUdOLThRZE91a2NreXBNaGZjT2JZSURIMDg1ZElwMF9PTnZfM1NxdGhoNlRXZHE1NGl1WXg2S0FGaUNkY0Rub3dQOXAzUXhkbWc9PQ==
"+1 - Anything new on this front? 

(I tried pyKeen initially but it has a lot of bugs when running on MPS/Apple silicon or cpu). And I dislike pytorch, the rest of my loop is all in Keras/pandas.",r/machinelearning,Z0FBQUFBQm0yeGJveGRFbjgzaEM5QlJYMGdVcjVVYWtieTZXREpuYU84YlZ3ZUE5cFpxak1jY3ZiUnZpU1dhVlpyZHBqczRVSG9iX29OWWFLTWdoUkVZd3ZHWlI3TVR4d2c9PQ==
"That’s awesome, can you share a bit more about the different kinds of datasets you work with and what makes them tough to handle?",r/machinelearning,Z0FBQUFBQm0yeGJvcGkyTWpMRFROazE2YmpqU2R2WURnV2RSVk5tTWYxNnBnZ2gzZTZSRVFlcmlzTk1DS2NwbHM2UDJ4V1NtVFlkd3JYZmNvR0llS3Y2UUNYdm4xSjdiWXc9PQ==
"You published a book before even releasing a paper? Seems very strange to me. Presumingly, you've done some experiments, how well do these networks perform? Also your book doesn't seem like a textbook, so I'm confused as to what target audienceyou have. If it's ML researchers, why not just publish a paper?",r/machinelearning,Z0FBQUFBQm0yeGJvYlhmTUN5QjJ4cXpoVjlHZkdnekt3VnRxek9CT01leUVxN012V21nRmhKTzdQNVd5ZXdIdGJ1dkFZSGFjelhMQ21mNGxxWk9aTGxPaXNNb3Z6TzFKN2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvT3dUajlJdW9kcDJsOWN0TEphTGdUQ2pwbEJfSjNKNk1sdXZBVXNLQWRZYXhZenJfbWhPSmJxZTVlMWhTeDFEQm9JQnBqOW1CNUVBaDVHdUIwSzNFSWc9PQ==
If you want applications on the edge (hardware) then you absolutely need it.,r/machinelearning,Z0FBQUFBQm0yeGJvdl9zemQ1YXRUcUVUbUl5ZmpnOFlVbVRCNDFmODJ2ems5OHVqMi0zZG5haHQ4NUxXdWItN1RKZFFQUkN1N0RzR1FnTFR5Q05jWnZyVlo5WWtGb3NuQ2c9PQ==
"I think C++ is already in most python ML backbones, the real edge is doing it in plain C.",r/machinelearning,Z0FBQUFBQm0yeGJvNzYxR0c2UmkzME1yc2pjRWgwSXFoTnNLWG5kZGE5Y1NYQmFNbjNxVGdjUFBqblhidDBYbDkwUWRuZVpWSTJEaHZ1ZzZHVWlXaUg5eU05U3IwS0Z6MlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvMU04Tmk0djN4NDg0X1YxN3R4RkNEb3BuaFdWaHJLQmVMcmJDX3hmUnVjNmlpeUU1djNwTW5TTXVGT3NGUUctY2xpcDJPTEJlNHczSjlkMk5pdFR5Vnc9PQ==
It already exists see Clifford algebra it does the same.,r/machinelearning,Z0FBQUFBQm0yeGJvYXByckVrYkh3UnlYLU9QVEtBdGp6MFJUcTZLejRadUlObHl3T1V0aXcxaTdDZmcxeHh1ODR2LWs1elRXaGlMeF9VTXQzdWlRV19YRzN3X0NiN2k5b2c9PQ==
"Very cool! I think the writeup could add a bit more background on Open-Sora, I don't think I was previously aware any Sora replications had been published. Here's the Open-Sora blog post for anyone else who missed it: https://hpc-ai.com/blog/open-sora",r/machinelearning,Z0FBQUFBQm0yeGJvcFhkRFpUWGh3OGZJS3JIOHNuN24xTXZFRTBHYjVKSHgtX1RUSHUtOGxXaDRpMlNEWGFYb00wRFlra1JKQUpLLTdpYVM5aTRSN0FoTENXSERrSGtHa2c9PQ==
"Fun idea, but where are the evaluations? You have written a book but you have not provided benchmarks for robotics, AR or OCR on common datasets.


My initial concern with this is how to map datasets inputs and targets to this representation, and what this representation can find that a simple ANN can't. 
In my understanding, you should still have the same constraints on Rank for example for plane estimation or 3D rotation for AR. I don't see how this solution helps, but I would love to in the form of a framework and evaluations.",r/machinelearning,Z0FBQUFBQm0yeGJvbnNpbkNacmxVQU9Bb1RUN3pGazBHcUZPbkFUZnlSY1g0UzdaSXRTX1RrQ3VZRVNQN1ZERndYLWpMYXRlYkVoYVRtTDgwenBLbkxtYXcxVnc3SXlyRWc9PQ==
Beautiful presentation!,r/machinelearning,Z0FBQUFBQm0yeGJvODZGUzc4d2hQQnlWUGlsNGJHdkVzbko5ZVNXTnRtUk5DeGNPMTJwS3YwbXpPRXhUQUZ1MmhMOG5zMjFXajVNOHJEN3Z4OUVYVl85STZUdkZTTzRhb09zSnc0QW9yY0VrZEtfVVlnR21TVUk9
"Okay that didnt help much, its pretty basic and doesnt answer the question.",r/machinelearning,Z0FBQUFBQm0yeGJvNGxTVlRUOXF5azRYcEkzYjQyQXk0NjZscnZycGpObXNNbmxRakU2RXM3Mm11REZmd3VueGtobXlwYmQtOU1ZaVVfN3Blam95RUhmaEk1QTNKekdBM3c9PQ==
"Python works so good because of C++, every ML library, EVERY without exception, has its core written in C++ or Rust",r/machinelearning,Z0FBQUFBQm0yeGJvSmNHamF0OWNBTGNQdVZUMWsxWXNzMmhiVlI2dTRvUFNxbUh3bWZCRzVucWVHRlBmOThDalZfVjN6VldfeUhYNWlheWtYNklrWTNPSi0zQ0NyWkFGbzF6Tlk3dGVxRXpfQ1JZRlVra29CTzg9
Thank youu✨,r/machinelearning,Z0FBQUFBQm0yeGJvVmZDQmh4NTFrcm01SVhLbHZaZ0ZBMWU1OFk4Yjk4OGhaSWZrUUNNQk1YSHoyTHZKVFZsbnJlelNIR1ZBeGpNNUQ4eURmcFp5cmNwLWlTYTdEenpaNkE9PQ==
"Thank you very much! We’re currently busy looking through our evolved architectures to find more interpretations. We’ve for example seen networks splitting a tensor along a specific dimension of the input that corresponds to signals from different sensors that might need to be processed differently.

We called it einspace as we started out very inspired by the generality of the Einstein notation for many of the operations we were looking at, and from using libraries like einops. The name stuck when we expanded the set of operations as we just really liked it, and it signifies a unified search space from the German ein=one.",r/machinelearning,Z0FBQUFBQm0yeGJvRGxDbUZaeHRYZnpOY3FGWmZHeTV1Yld5VGQtc1RUN2hJekJMMXQtSkhyMklkNlVSNWlhQUEtZnVaUFJGeGJNdHkxVi1DS3hxaFExZUVBQVNNUjJIRkZEajRleVdMYmlxLW1peG1TTVlpdFE9
"Just to clarify, this is Linus, the lead author of the work! :)",r/machinelearning,Z0FBQUFBQm0yeGJvQUxpOGltTTh2RFA4MWFkNEp3N0F2SzV0elc5cER2SkVJZkMxalZhR2pVNDBGd2M2WXFfY3lfaklkUVVGRnViZFNvdDRmMjJHMl9pbXRxREJlOW9tZUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvREkwM3FCTy1TM2FPbzlQeU9ZaWE0RFU1Yl9aUFBjYTZtSkN6UlJTWTVpQ3NXb3MxUjNBeFdfTlVjQW43WGtxTGhSMzZjckk5Vm5VR3Z4R0ZpZzJtdUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvdVlMZlZubkdlNUM3bjd4NklubEpwMVpYVGVVNzlmajRIdG1GT3FYQUtsb0REVERFMjIzSXZzZlBUZWVKLUtub2dqSlFPX3d6OFYyM3cwNUNyQmR5Q3c9PQ==
"That's a good point. I really wanted the book to be geared toward up-and-coming researchers and established ones, yet I also wanted the room to explore the expansive nature of the topic. A paper, while valuable, would be more concise and may not have been the best medium to do an extensive and thorough examination of all of the aspects and nooks and crannies of the topic, if you will. Readers of different backgrounds and varying levels of expertise could appreciate the intricacies and possibilities that vector neural networks offer. That doesn't mean I won't consider the possibility.

It has amazing resilience to variations in input data, where I was able to zero out large swaths of input data, and the network was still able to classify successfully.

With an OCR task, it showed remarkable ability to learn after only seeing 60-70 examples of training data processed, where a scalar network with many more parameters took much longer.

With financial time series prediction, using the expanding VGRU, it was able to avoid catastrophic forgetting which plagued a traditional GRU.",r/machinelearning,Z0FBQUFBQm0yeGJvVEtIMkJFSlpfM1ZsSXdLMnZKZkx2RF9WenpwMzRqVTBjcUtTUEk3TTM5bEFPazFxSkI5STY4SUd5R29uSmNDd3kxcVo1c1JYX1EzbjliV09nQ2hUZnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvT1hyeWVlaDRZdzE3NWJMR19KR1N3VVVybElDR0Q0YURzRXkzQlFWT1FVUXdORDlMZXl5OFRqREtKU2pQLWpXN01iQ1hGcVAxVU51cjdSdlhOZkF1elE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvU3FTLTk0N1E4M3dzOWJUWjlZUURLTEhsSTBBTVZMQjdrRlRqTG5rWTFwQjhNbHc2TVJUTk5GMDRjNzIyOHg3RXdVcWtmalFsTFozZkdpZG5UanBJOUE9PQ==
"Hello, I'm training images for object detection for grocery items. May I ask if do you think google colab pro can handle 10,000+ images with 100 epoch? Thanks",r/machinelearning,Z0FBQUFBQm0yeGJvdkVvQkJkUTd3NGpWOGVRS2dHUUtESUxvMDBpLTZRU2Z1QzFHbVIwMEZkZ2x0MXYxMjhWdWtkRUpGOUNhaHd2b1NvTUZWa1BSZWhobnlkeDBoeXhHR0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvUmdSZ29HZ2VPZmdrWmtyUFJSeHhjNFR4OFJaN2R0RDdGUWZWYTFBRHBwWkgyVzF1Q01pYnZZbEpmLWpwb1FkUmxxVVVvV2FBM1l3d08xbmhpckVqUWc9PQ==
"You're right. Clifford algebra does provide a theoretical basis and backing for VNNs, where VNNs take the theoretical concepts and apply them to practical neural network architectures.",r/machinelearning,Z0FBQUFBQm0yeGJvdzA2dkR1X3JnVGY4T3NCcVNxcHBLZ0NQajBucm1MNk1Na1hBWklWOEdFbzZsWHBaRks4NHhjVTJMN0xsR1NZa2dwbXVzanlzT2hpRDI1a2ltRjVRaUE9PQ==
"Hang tight. Formal evaluations are coming soon. And I do agree that maintaining linearly independent vectors is important to maintain rank and to get the most out of the network for plane estimation and 3D rotation, which can be done through regularization techniques. The main areas where this solution shines are in rapid convergence and the reduced number of parameters needed due to more informed gradients, and also through the application of expanding VGRUs to time series data.",r/machinelearning,Z0FBQUFBQm0yeGJvOEpFdkRSWDhZbThlMThHWXJNWkE2c1ZsMkJrenpGczU0SUM1bVFRUVhmamlPNWdfU1Itdks0am42T2FCSUJISEM3Z003MU9UaTJJdmhpRkRtbFNvTlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvTXdNajdJX283RS00TGdKTER1THlmVVBrU1Y2ZWpfU2ZzcUE3UzB4dWZYRU9Qc01veFNrZkRiSkdHbF9oOFdaSkZ3VVh0X0k1MmNXRlQ1R2xEOW5SeGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvdlFPQnFpYWpUc3MyNmNFc3doUXl0ZTVrMi1HTkpqMkRyUm5zTlhmOGp4WnNXZ1YxOE4wY2VVZVByS1g3UEMtcUxBSzVRSzJOVTZIR1VZQi1yUnNKNVE9PQ==
"https://github.com/Qualcomm-AI-research/geometric-algebra-transformer

You can see the following implementation for reference.",r/machinelearning,Z0FBQUFBQm0yeGJvZ1RMQkpqdV9uZ0xNUDZBZ3BMNFdfd19JX2FLVVpFVVNaOGh2TmZial9fd0pyX2hTMmhrbzF3ZzFRamRlMmNCcVpyaUYyMlFZNnh5aV9pYVVNTTB0aEE9PQ==
"Please don't cite ""lesswrong"" here.",r/machinelearning,Z0FBQUFBQm0yeGJvREdIN3BkRnpyRnJjMDZrS20yMWlWQnFFc0tndzhFNWJCaTRRSVhTNHdZNEl0V0cyd3hiemJtNmV5ckVFV0VPdE9oTTRYckJ1Smc0M1VGOVkyNUNsa3c9PQ==
Also just one thought I have in vector neurons. Isn't having parallel connection like multi head in transformer we can see as kind of vector representation for the same information.,r/machinelearning,Z0FBQUFBQm0yeGJvbjFCZjlTelVUNE80UjE4bFBHTmw5SWNBZUZnWUh2b1llMEJ0S0JsVE9zcUEtTzlzYmUzSnRENENPUFlCeTdGNmk4R3VfV1pzcWpIVl8yVllKQUx0T3c9PQ==
Anthropic's transformer circuits thread is good ig,r/machinelearning,Z0FBQUFBQm0yeGJvU05MTm1NY3gza0JuYldpV3BES0JlNm5WSDJwa0JfdF95Uk9yVTVOSmEwbmlQdzM5WG96SEtqbWpjWE9heUJvWGpVb2NCbzREY2V3V0dPVVlNTTVnYk1GTEdGVDYzdnplR1dWVmZaaVVSTUE9
I've been trying to use PyTorch Geometric. It is not a drop-in replacement using Keras like I wanted. I've found it difficult to transition from one framework to the other. It seems much more powerful/configurable but I just need ease of use.,r/machinelearning,Z0FBQUFBQm0yeGJvblZHdlNJV09ZdUVtMUpBLVFxSEhyc0RWeURBTnJyUTlYQWd3NEtfOXdnMXIwNW8tSTZNSXh3UXlIMUpEd2Q5M1QtQksya2J4NVViVk5ybnpnX0ItT0E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvSDZTdVp3dERZZVNwUG5Eb2xES1FqUFhGLXpyRENXSGhRR2ZkeHJ0bElrQTZfLTl5NS1kWk1OSU1uNnJhVGEzdThaeXl3eEJtMWZRa3dCV25oLUJYUHc9PQ==
It is amazing how the 1-SS mask looks like the contextual positional encoding method as described by https://arxiv.org/abs/2405.18719 which also just released. Seems like attention is headed in the direction of lower-triangular block matrices which align with some contextual information in the data.,r/machinelearning,Z0FBQUFBQm0yeGJvOHF3Z21TNTBFMlJoeFBzeGRVaE9mNC12blpjRXZTc01xRnczTDRTWHYzOGZQMDZQN2cybmM0eDM1bUlwMk12bEFtbmVmckRqSVhVUjl4RGZ5YUNwV0E9PQ==
Couldn't have said it better brother.,r/machinelearning,Z0FBQUFBQm0yeGJvZFN1dzNNYnFESnJJalhha1BfNXVFTmhPV2RiTFZjRW1nTjBTWl9CSXU2VEphWThWSnp0R2xxcjRoRkpXWUd3dS1jalpWdW5GdTFjU1QzcjF6a01IN1R4WjkyTG42NnRLWnBMRkFPQkRlRjQ9
"It got much better results at MQAR, however traditional benchmarks didn't improve that much. In some tests it's worse and while majority it's better it's not that significantly better(66.1(mamba) vs 66.6(mamba2) is not exactly the same as 66.1(mamba) vs 59.7(hybrid h3), hellaswag acc, higher is better).

My gut feeling is mqar is not that good predictor of overall model performance stays got reaffirmed by the paper.
Oh, well,if next VMambaUNetVisionMoE will tear apart previous mambas in medical image segmentation(At least on arxiv mamba is insanely popular for medical image segmentation. Not image segmentation in general, but medical specifically) maybe then the gut feeling is wrong.",r/machinelearning,Z0FBQUFBQm0yeGJvYklweF9yTTFZaDNJSVpBZnJrQ1lVWllUUXBENW4wQk9GaHJPWGZfRXNpanNxUXVpVmlHbjZuVU5OaC1aZ3pxX0NpU3pUWk85OVZVYzltN2VhdkY3MVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvLUMweFV1WVdyZVJZQXhuWWRmdWpETkg4RWlGOWUxR2g3bTVGOTZrYnZVNjdhOXlvazR6U2JybE9GbXh3dUVGZDhrWnQxcUtoZ0l4bVhIcXh1Sy14U3c9PQ==
"I'd prefer to run it locally and I tried running a few different versions of the model on my CPU which had access to 32 GB with ~7 GB used meaning ~25 GB of free space and the last one I tested (very similar to what I'm currently using, but with cross attention layers) still barely fit and then crashed. The T4 GPU only has 16 GB VRAM.",r/machinelearning,Z0FBQUFBQm0yeGJvVE80czd0clh3QUVhdFhGTGxjV1VFbVY0clZhSDdYdDVQRHpYWDVJNlczQjh3bkIxT0JMSlAteVNCTjRiaTFGZVl0TmdUeThJNTJIeFZvdlpxU25JQXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvTm9Da0g4QTg4RXU2aEFfemlYRTZrTFlwdWVrTXotbzk0WUppdVFsZEJZOTRmblZiQnZ0NWItZmhvY3AwUDNNVnZveExyYmVOZkNCemlKVGhqMF9oYkE9PQ==
"While there are conceptual similarities, the VNN takes it a step further by incorporating vector-based operations and geometric biases directly into the learning process, which enables the network to efficiently handle tasks that involve spatial and rotational invariance.

Additionally, the expanding VGRU introduces a dynamic and adaptive approach to processing time-series data, that lets the network grow and optimize its spatial configuration based on the input received at each time step.

I performed a study where I systematically removed a certain component, and tested the network again, and each component, like vector decomposition, learned angles, vector-based matrix multiplication, self-attention, and multiple processing paths, all played a role in the performance of the network.

You can get the best of both worlds by applying multi-head attention to a vectorized network and get performance benefits, of course.",r/machinelearning,Z0FBQUFBQm0yeGJvbFg2Y1kxNk5RY3ZlUUtxc1FHUGk4UWNKdGJrZ01MYzFVaERZc1VDRmQxYlNTOUlXX3dTN0taSnNwYXBwU2VWeC1qbWxMbFNSLVQ3cjNJWUhTY0huOFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvUVI4dkRKSTYxWngwLVVaalJkQk9ZWUR4MkprUjcwdks0MVh5QmppUmFFRHBxV2NBWlYwVHNwTzdzcDBERDNnMzNqTTRSbzRKOVM4T2EyTDUwVU55SGc9PQ==
"But why would anyone want to investigate every nook and cranny if you haven't even shown that it works? If any of the claims you make in your post are true, you should have published the results by now.",r/machinelearning,Z0FBQUFBQm0yeGJvdW5wZTBTazZDWV9aZUxDSVd0aTJoZ2Q1OTQ1RzduZHo0aEJwS0dDSHpIeExUalB5bW5FLWk4azRrblZCZ2VPa1hqQ3pFdkNjbGFHNThIV2w1UHIzX3c9PQ==
"Did you write an entire book on them without even having done any formal evaluations and comparisons?
> The main areas where this solution shines are in rapid convergence and the reduced number of parameters needed due to more informed gradients

How can you make claims like this without showing actual results?",r/machinelearning,Z0FBQUFBQm0yeGJvMzJ3X1ZCNU1xRU5MVkJjb1R5ZWJJblpzTTVyR3l3bTgtdUpldnFvWWVMclVuNDEwdGNJN1hmc1A3d19MQm1ZcDR5bngxNDNkcjJKNXhfRkFFQWEzbVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvRjNUS0lEQjh1dnhNVTVmaHY4RGZaUXpQUEJmOHdQelYxeHJaa3otTDhxemJ6dzNmanNhRE93WmhRVFFkS1NNek1GbWFrZG5HSWR0OHdWdVNMLTBBdUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvRk1FVTVEaXI0bkE0Q1pYOFlaeWhjdGN2STZrdl9nQ053WGVocEliZExseW5RME8tVGswcUpudlk3ODlZc0VkTkxraEJqd3FoYlVETVZWYng2Wkl5dmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvQmhDSmJnRjJWWGNYdmVHdzF3VGdEdzUxUnlodzI0UkJhQloxWnRtYmItU0VhLWhKNVJKUU5GaEpmcDN5YkdRZzNYWnR5amMwak1aeXU1Wm9Za2dEdXc9PQ==
"I respect your opinion. We can agree to disagree. I would encourage you to try one of the networks out using my deep learning library, ParallelReverseAutoDiff, and you can see for yourself. The VGRU for example is runnable right out of the box.",r/machinelearning,Z0FBQUFBQm0yeGJvRnVKTlhNTmZWY191QXlicTZ6Yi1MbUpHOXJWZ1g2S1NjMzJXcUxCWHFzd3Mtc0toN0NieEd3NDRPWkJkUmJQRENyNUUzb2lEWl9TQS1tUGZtWC1UOFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvbDF6NVhQZjlJMGFGX1ZwLWVnU0d5TjRwQW1uNWUxa2kzWGVfTENlaloxZkRtR1ZsbjNQd253b2oxZEs0QUpwMGtoOUdLTnZfbldua00yaFo0dGVLRXc9PQ==
"Or you could do it yourself, and then write about the results in a text document, and then submit this text document to a conference.",r/machinelearning,Z0FBQUFBQm0yeGJvQVhGSDc3bDAyV1lZR0xTb0FVQ3hCN1BrcmpyNUx0bFZvc0lmM2xZUVVNaTdNZ0hHT0tUbnF0M0pkMHdBNndVazZRU2NuS1NGcmtTWkJYczlDYmZlb3c9PQ==
"Because I tested it with my deep learning library, ParallelReverseAutoDiff. Anyone can go in and verify the results through GitHub. Honestly, it was a pretty stark difference.",r/machinelearning,Z0FBQUFBQm0yeGJvcC12Y1BkeEJPRFRONGJaV2lOSGxOQkdkWEFGVUdJdkpHNUNqbzNNMlpXQUd6MU5xUWVULVpKZy1xWlQ4UUFsSl9tQ2ozNFBZOTk3V2RCNVZhSWZiVHc9PQ==
"There is a set of three papers that works hand in hand that have strong recommandations. It has been published earlier this year by a consortium of well know statistician in the field of medecine in the UK. Here is the DOI links to the three of them along with their name :

* Evaluation of clinical prediction models (part 1): from development to external validation (https://doi.org/10.1136/bmj-2023-074819)
* Evaluation of clinical prediction models (part 2): how to undertake an external validation study ([https://doi.org/10.1136/bmj-2023-074820](https://doi.org/10.1136/bmj-2023-074820))
* Evaluation of clinical prediction models (part 3): calculating the sample size required for an external validation study (https://doi.org/10.1136/bmj-2023-074821)

It is especially relevant for the field of medecine and clinical trials that have strong incentive for the model evaluations and a high cost of data acquisition.  
However, I find them very relevant for all fields of stats and ML, with very clear writing and precise guidelines.",r/machinelearning,Z0FBQUFBQm0yeGJveXVwRVMzQjYzSENzMzAzcGFLRXRBQ2w4MkVlVVFpZlZQYnMzemVoVDZabHQyUks0cFdzSVdpazNDemZtazQtTEJ0T0VBVExlUHFRQzNhMk16OTNUZEE9PQ==
lol the last time i read sth like this was: Transformers are Graph Neural Networks,r/machinelearning,Z0FBQUFBQm0yeGJvQ3FlZ2huX2xWd21yM180WGR6Ry0tb091MlRwOUE1VTFOT1RaSDdhRWVISmZ6N1RJXzBEN1RRUmlVajBjcFc4VUNVUU56Y2plN1NmaTNkWU1CNGxiSTNDclh6eU1sYTNwRFdSSk1nQmtselU9
"Well, maybe another way to think about it is like this. There are -- have to be -- people who are paid to maintain the libraries (PyTorch, JAX etc.) that most data scientists and/or AI engineers depend on, and those people have to be much more familiar with C++ / Cuda and with optimizing cuda kernels for speed than the average data scientist. There are definitely jobs (Nvidia is hiring a bunch of engineers for this right now in fact) where the main focus is working on cuda drivers and other low-level work. If that's the kind of thing you enjoy, that may be the kind of work you want to pursue long-term.

As in any ecosystem, people specialize, and many ""layers"" of the ecosystem depend on others. Part of the purpose of developing tools is to ensure that other people who may not share an interest in low-level optimization don't have to know anything about low-level optimization to get *their* work done. Without the ecosystem of Python libraries for ML (most of which are basically Python wrappers on C++ code), it's highly unlikely that ML would have reached its current level of popularity in fields as diverse as bioinformatics, physics and data science, because most bioinformaticians and physicists don't really want to write their own C++ code to do backprop for example.

There's nothing wrong with powerful tools enabling people from outside the field to build their own solutions -- it's part of the purpose of developing tools. But, if you already know at this point that you prefer developing tools to using them, that may be helpful in deciding what direction you want to go in and what kinds of jobs you want to look for.",r/machinelearning,Z0FBQUFBQm0yeGJvUU9oMFFvSi1GcDl5QTRnazIza2tIVkZTRGJoakQ1dy14YlE2RE96RjYteUwyNHhIVjlEcFJQZGFWeUxpVlRuLU5LVUhDSml2QUw0WkZUeTRPZVE5alZZdFdlVjJMSjE4bDlGcS12TzFJUzg9
I'm a firm believer that experiencing is better than just hearing.,r/machinelearning,Z0FBQUFBQm0yeGJvczRJUTBCZ1l4X25zWVV1UUxGNFFabE1OdDMxWWFOVDN0dV9LclprYmR2TnV5TDd1c29mb1dGTU1KRldTdkNpVVFzZmlxZUlCbXRLUjFxSVZ6N054LUE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJvRklaUV84R2JjOXRkdjFVa21GZ1JCNmpuTWFLckE4YUEzdzU0TDhkeXhKZktiUERxamxiTDRGNklKNlgxQldRNkZqMFV1QkNJQnVuSFNxNDdUa09WNG83ZDJPd1pwSHluZTJIckR3a1Brd2s9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvdk1Ubm0xTXNFLUFnWVVObU1SLU9PdWI3UmdXd2VBdkJsYWY1SjZmTUcyb29QQUtrZzlGN2ZFNlZXZWFFTkN6Z1VFTGtNVzNyekpVbl94eWFHT0VvRHc9PQ==
"Hey, OP - friendly tip on staging: promoting big new ideas before publishing a post or a paper, releasing code and showing experimental results is a sure-fire way to just annoy people and undercut your credibility. 

I don’t make the rules, but I do approve of those.",r/machinelearning,Z0FBQUFBQm0yeGJvVzExeVRWczg4Z2pHT0JQNmQ1d1cwa0UzbEg0WTc1Tk5MbS1UZVN2bUFWTDlDanF3M3NsbnFvU0xNYWU1Mm85bnV1Zm9sRm43MU83Z2U4OVlMdV9MQlE9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJvcjdkUWVLbmxJb0FiMnNCaWFwTG5kYXljU0hWMWVNOURMZWFCREFqcHZPaEhhd2NnUXJzRmV2NmlhVzA3RlVtQ2txYXpFZzB2U3p0Mk5DWDNCZGdvLXc9PQ==
"If you are optimizing for GPU/Cuda, essentially none. But in the cpu world, it is as fast as/even faster than cpp depending on use case/skill level, it can be bound to python as easily, has a better ""stack"" (i.e. helpful compiler, good package manager etc.) and easier to break into if you have only done python so far (which does not apply to you but important point for me). Yet, I think I will go with cpp as my second language because of GPU and wider usage in ML. I remain rust-curious though.",r/machinelearning,Z0FBQUFBQm0yeGJvT2ZXWXh0OXV2VHVSUm1yUVlPbXduRi1LT3A1dTk0UUVuSHVQOXcwMGFkVUF0djdQZWFiVEt6Tk0tdXlmcDdZTlZVQTdUR3FzMlFJVXJWVngteWRSQVE9PQ==
"What would be a good (and ideally simple to setup) benchmark to run, to compare performance of various GPUs? This is in the context of providing GitHub Actions runners tailored for ML workflows.

I stumbled upon [ai-benchmark](https://pypi.org/project/ai-benchmark/) but it doesn't seem to be well maintained, and [lambdalabs.com/gpu-benchmarks](https://lambdalabs.com/gpu-benchmarks) doesn't seem to provide an up-to-date repository with benchmarks either.",r/machinelearning,Z0FBQUFBQm0yeGJvWnlTY1RNSE9fcVFLdFNkNm13Ukh6c0w2MVVjd0lRemNKZExxV09qaEFzc3JrMEdNaFJ3c0ZTcFlGMEk3V25xcnhwVlFMNjN3R3lzSkhEenJjTktGcWc9PQ==
"I hope you can reconsider, the commenter has a good point. You need to show that it works and have it peer reviewed so that there is some level to trust in your approach. Not doing so would be a disservice to your work.
You can have your own options of how things should be, but you should realize how things are now, not meaning they can't change.",r/machinelearning,Z0FBQUFBQm0yeGJvMEktc2dURVBlRUVPSEI5MU00cFRSRjVBOGR0cUR4WjhXUnRDaVN2MGM3MFRqUGVweUdEeXFvbnFCUndhZU05aHk3bjBNTVhpN1h1OXZYUWZaWTI2Q3FJNmlscG5yUW90STctX21ISGladDA9
"Agreed! We want you to succeed, you need to build some credibility of your work first.",r/machinelearning,Z0FBQUFBQm0yeGJvNGZ5U0FNRVpYcV9qdzV4NUxMZ0pWREFLYXpGeVcyVEFtZGdtOFdqRlAzWUs3OERMT3JtanMwYVFmdF9UaWhQR0s5c254RFUxSVl3anRSVU8zUGxkV29sMm02Qk9seFFKam84WWNTVi0wanc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJvOHBpVnZZMUJPdUQ0UjN1VENqZmhFaDZkRUtZS3BXdDRDbDJtR285OE1PNmFRZXMxN2psWHg1aER6QUhhcHluZDQ4MlNOT1lkWF9Cb2JteTVEc3N3cHVUYXNKNlVpUE5FN1Y2eENrY2N0akE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvdmJxbTF0TkMzTmFRQkl4Wm1uTGEtZl9GX1IxNERPenJudXVnWEJaYWtoZWJmbW9LazljM3pfZlo5ZFhHQ0tNNTRZeWs0V0R6SzZRT1NrRjAwOGZRREE9PQ==
Thanks for expressing the reasons for why I should write a paper. I will consider your insight!,r/machinelearning,Z0FBQUFBQm0yeGJvUVN0bmo1S2RMemNzRllSQWZHbjZIV3JhUmQtSVIwQjliVkhDYVVUbDdWd014TkgxeGFYLXdjVFZEMDZIeEFmR3FSdXpMWGhIak96UVdXeEhfbFJCbXc9PQ==
Is library available in Pytorch. I have tested Complex Neural network and it seems to perform slightly better than real valued neural network and converges faster and perform better with less samples and parameters. This were some of my observations. Only drawback it had was computational bottleneck,r/machinelearning,Z0FBQUFBQm0yeGJvTGdYdE43T0doX0N4TUpOM2hCUmNmVmVyeTZjM3hlQm9wOXpkNlNxZWZOM1F3SXd2QTJDZjhDdUVzMkVoMF8tRENpaUlpR00zTTdPbXBNeXRUZUlwcGc9PQ==
Can you share the book pdf version? I want to read it. Thanks,r/machinelearning,Z0FBQUFBQm0yeGJvQjJBMHV5a1psVnh2OE9NM2NFVFdTaTBHTkQxSmNoeURQSDNjaExVS2lhSlZ1OEdkc19FNy10ekpUWWZnVlpUdmJkbkRLdTNrTWRpbnFsdlZpQjZidkE9PQ==
"Hi OP, is there an example notebook to go through the basics of your VNN idea?",r/machinelearning,Z0FBQUFBQm0yeGJvMU9sZDQzcWhTeTg4TjV1ZFktVTJNSTNIUGZPNTJHY1dqby1mVnMxaFR6X0ZYYm0taTRYN3NjTER3aVFpbHBDcXpSV0hJLS1ra0pRXzlIWXpTbmFIeUE9PQ==
"The computational bottleneck is one of the open research questions regarding VNNs in general. In my experience, it was mainly due to all of the trig computations involved with converting between cartesian and polar and vice versa. One idea was a hypothetical VPU that would be able to process many more vector operations and conversions in parallel. There should be other ways to improve this aspect.",r/machinelearning,Z0FBQUFBQm0yeGJvR09xd2pSSk56bmhmYThPS1dVaURRakwtcm5vemM1VUdSZjU1a3pfbks1bjZjbkgwbEVIWGZuMWF3VkhvZ3BWMExJQXZPT0djN3QxbE1ETkJSUVJvQmc9PQ==
Also can you clarify the vector based operation? Isn't it same as in Clifford algebra.,r/machinelearning,Z0FBQUFBQm0yeGJvVzNpcUNicHFVS2NLdWo3bFlta2lVMVlTYmFGMjJobzhjeTQ2UDdreUZNaU9KQVJ1YnQyRks0OEtDeHd2OW4wamtMODZxOGZKVGRyT3RMQjBpTzJFQVE9PQ==
"1. no they don't. it's in their TOS.

2. if you have original lyrics and shape the beat with Meta Tags, you have made AI art with HUMAN INPUT and you own the copyrights to it.",r/machinelearning,Z0FBQUFBQm0yeGJvV3drZno0emVOTWNpSVNoUVF1U0lnaHJfM3NvY1BGX0lPYVR5WERFWU4xLWg3cjlkYnVkY25oa1ZtVXRlQ3AzZkM5cVRkMGdOMlZYSElEcGxqUUVGcXA5RU9VeDNPeVFpNnY0LWZGVmJ6YUU9
There's a reason why no point cloud network ever uses vector neurons.,r/machinelearning,Z0FBQUFBQm0yeGJvRXJtY1o2MlF3cUIyRFEwcHJTenh2RV9OakJfd0t2Mmx0SlUyOVJTaW1UZTVrOERqSWtqazhWQkdXdTRadFpQVGEyT0pBRkJ1aUc5ZXh2Q29ybnFmcHc9PQ==
How much did you charge?,r/machinelearning,Z0FBQUFBQm0yeGJvVFBicEVpM0R3WC1yQWN1TzR0UXRmLXhDMHpQTnliVHlXNmxDbmdqWDA5YTBVQVJ1d0l4WVZ1aDZUWEhOYkRlb0NVbjJnRVZDeEFldVlqeWpfUnlpNkdmYVlhcTQ5dk13TlRqdFhvcFY5bGM9
"10 sec should be enough for tasks like speaker identification. You can also do voice activity detection and remove silence, but if your audio is still longer than max length, you can do sliding window.",r/machinelearning,Z0FBQUFBQm0yeGJvV3I1dGNreUQyeHdmMDVveVhLOFlFV2RDZ2tjQUN0ZExCS2kwWjVLc203Y0xTR194NjREYVdOYk1Xal8yS1RfOF9rTENEU3ROWlRJeWhxSDN4T2pNVEpWVUZDTHdDT0F4ZEVwcTJmc0I3bTg9
"Hi there, I've been doing some work on some really simple ablating of features on the open-source models, from 8B to 70B, doing similar but more supervised efforts of finding features. You can find examples of this in my posts -- I've posted resulting models, and some of my code to do this. Using some of the ideas you mention, I managed to make 'MopeyMule', a version of Llama-3-8B that writes with excessive melancholy, which I did no traditional fine-tuning on.

The idea behind the latest Anthropic Monosemanticity paper was to actually scale up the process to a >100B parameters model (unsure exact parameter count on Sonnet), a lot of the earlier work was done on GPT2 very successfully, though of course this is where the idea of ""Monosemantic"" vs dense ""Polysemantic"" features muddies the waters and makes interpretability harder.

If you want to play with Sparse Auto Encoders, which is what the Anthropic paper was using, I highly recommend playing with a library \\`NNsight\\`. It has the easiest pipeline I've seen for training an SAE for a given model.

You can do some very simple, though smaller feature targeting with LLM steering if you know what you want to target. [Here is a good writeup from Alex Turner et al. on steering with very simple intervention](https://www.alignmentforum.org/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector)",r/machinelearning,Z0FBQUFBQm0yeGJvOVhjOFpMclhZTnhxcWs5RkVKVjlSN0M2ZHJHcUtGXzRoZ0J2TW0xM05tRHhaaEx5QVFZLWc5YWZvUDJlZ1BuWVJfbDFFemlzb2E4bE5MekVfYzRJOXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvNC04U3VKRjBHU2lIal94NlNQaXlrLUFsaUpWX3FnT24yaGNfUWtsWUNKNjBLbHFxOTNkQVEyemMzeUFsM09OanRyOEF0Zk9wNkgwVTk1Sm9TenlBZ0E9PQ==
"And what baselines did you compare it with, in order to make claims about reduced required parameters? Surely you generated a plot or two?",r/machinelearning,Z0FBQUFBQm0yeGJvQkRhUlVjMmRjVnZRWXVidTlLVjNsYkRWNVhVZF9yNGFERTRjZ2ZhTU5KdVc0ZXpWcFhXT1Z4UEdHb2Ria0I0TlFCaFVaM0RGcHlQaG9qSFhFdXhlU0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvVVJVclJ0OTBWMnFFdGdOemp5d0dIZXUzWEEzUHZNVUNGUUdmUUxGWWx4OWRnVVJ1N2hUbE85REE3VmZJWjdVZmJ2U2RBT2ZmQ25qTmFVQ19rQm4tYWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvcEoxTEwxNnJjOUpQdk9RNUlMS2R2eGI5TDYtaU0wR3Njd2syc0VrWjNKbzZzNFA5bDQtTU1xWDFIQ21hX0xFcU9iZkJRdFc3ZGVpWXFLU01OQkdWVXc9PQ==
"Yeah, I've just been really busy testing out all of the different applications for VNNs, which takes some time. And testing out the vectorization of various architectures.

I really wanted to know the breadth of how VNNs could be applied. I guess you could say I've been hyper-focused on that.",r/machinelearning,Z0FBQUFBQm0yeGJvandyT01WOGZ5OWNZWERqLXhEclU1aFdpVkdwazBPZ2dmZWtFc25uWEM1alZUTS1yeVl1MEs1S0Y1QnJtcWY4b21mUVZTWnJkUVFfTmN3c3hETFNVbHc9PQ==
I would recommend you focus on one or two applications first. Makes it much easier to prove your work and also creates intermediate milestones for you. Beware of the modelling black hole (trying to figure out everything at one).,r/machinelearning,Z0FBQUFBQm0yeGJvNlV5RmVjUTA2d0duSWFiU3VZUTdfd1VHVDJDTE5ISFBPb1U4V0o1Mm90b0R2STlxVWxISm1tNlBmZjh5Zmo3MEhVTWhUMUJCSGJSMXZPSHZrM3B1ZmNfZkdKVzN0NHJuUDNRZzBzU0V1clk9
"The code is released and runnable on GitHub through ParallelReverseAutoDiff. It shows the efficiency and diverse learning of the expanding VGRU in the examples folder.

Here is the link:  
[https://github.com/ameritusweb/ParallelReverseAutoDiff/tree/main/examples](https://github.com/ameritusweb/ParallelReverseAutoDiff/tree/main/examples)",r/machinelearning,Z0FBQUFBQm0yeGJvbUhqOW1JX1JXajk0aTZaU25vQmVYemRjSEVQLW1IS1NSWk5pcTRhMEJldkZfZXdNQUZaV3RiZEJFckE4dS1pWGJwcGF6dWNMbjltX2NYMHotRS12Vnc9PQ==
You can read it for free via Kindle Unlimited. Here is the link for those interested: [https://www.amazon.com/dp/B0CXBV3DY5](https://www.amazon.com/dp/B0CXBV3DY5),r/machinelearning,Z0FBQUFBQm0yeGJvQnk1M2hsZjJ3MWRUeC1QWHpkN2JzblczUnRNS054VlZfTTVBUDB1em5ZUDV3M2xiS2loNGdrNmJkWFIyd3V4NV92eGplNlN6c084aDVyN0FTXy16QkE9PQ==
wtf that snake is so cute,r/machinelearning,Z0FBQUFBQm0yeGJvTVZibHJ4X3ZPMjNFOG0wZk11NHl1d0FFdDZXVVZNdG5VWE4yTDBYdDhvdTZXNWo2Z3NpY01pMl8wYTNiLURJVWtJZUpjRkxqUU40dkozbVZIQ1RVY2wydUhmRF9HREhieXhRYnZwcjlHMHc9
Spend hours on coding and debugging and the snake steals all the attention 😂,r/machinelearning,Z0FBQUFBQm0yeGJvZ28tVTM3Q0Nvb1oyeTUwaHRGczlJUGctSFRHbDRiY2tHVGRKX213aHlRQWpUaG11b1drb2dKUTdNRVVCMGRBR0V2c3pHeWo2aU40UlEtUUdKVjU4Qnc9PQ==
"So, for example, with the vector-based matrix multiplication:

You have two matrices of 2-D vector neurons. You apply matrix multiplication like you normally would except: You first convert the pair of 2-D vectors into Cartesian X and Y coordinates.

You then subtract the two vectors. You take that result then you convert it to polar. Then you scale the magnitude by the learned weight. Then you have your result.

Like normal matrix multiplication, you do a summation, but with this, you would do a vector summation by converting each of the vectors to cartesian and adding them up. Then you convert the result back to polar.

So, if you have an NxM matrix times an MxM matrix where both are matrices of vectors, you end up with an NxM matrix of 2-D vectors. The conversions enhance the learning of the network.",r/machinelearning,Z0FBQUFBQm0yeGJvYlppVVNwX3R3TlB2Q0NjdW05VVRIdThXUUtXSjhSUFIwOURFenJQdXRFTF9lRUwxRHg1cC1VVlY5VjRiR0J2VUFoOE5nUDM1UVQySGhtU2g1M3YxSkE9PQ==
"shouldn't be too hard, I know it's been done for mistral, gpt2, etc, but I haven't looked at the other examples in hf transformers.",r/machinelearning,Z0FBQUFBQm0yeGJvQ2JFa0JEQVRRMUgtckxjbWNQTlZyN0dqaDNEc2RyTERWSjVmTk1EZ18xWkZhSU5OcmlQNTZTaVpMRWoxN1dXYW45WGdsNHFTZlFOc0h5bXQ0cFljdVE9PQ==
"I’m not going to sugarcoat it like /u/ghoof. Without public benchmarks and comparisons, what this looks like is a) a cash grab by means of your book and b) an indirect way of promoting your non-standard C# deep learning library (of which the noted example itself is *poorly* documented).

At best, if we interpret your intentions in good faith, it shows a remarkable lack of understanding of the machine learning community and the scientific community in general (and laziness considering the minimal effort to link the “seminal paper” and the DL library).",r/machinelearning,Z0FBQUFBQm0yeGJvV0UwQ3BOZWcwRFNIbzBrTk04RUZFWHFibTNJMFhvWEZuaVU4a3c5X2JIT3Vwc3JTQXRpN0k0TzZrZnFQUHBNb2lrZWQwS3poUU1mUks3U3gwWC1WZnc9PQ==
Can you elaborate on this? I’m not familiar with the topic,r/machinelearning,Z0FBQUFBQm0yeGJvTGNFcWl0eWRxanhRVkptR21WMEptZkZ1R0syWnY4UV9kekpCTjdqMy10Vl81M25zMmlJMzh6TkpyaFA0VEVfNnZNZlpPNWl5cm1NbjN3YmdLVUFrTlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvSFlxZ0xoMHp2am1IdWV3WldRR09DTGpPMVBwcjU5X3FGeUd5ckU2WHJsODJJcUV2cGpkY1BhRjNNd3R0QUJkLWVNdnNkanV4SHZSb1lsWGpCcXUxOWc9PQ==
"If you have suggestions about how to improve the documentation, it is appreciated. Thanks.

Also, what would be a better way to introduce my DL library?

And I don't mean to misunderstand the machine learning community. If you can shed some light on this, that would be great.",r/machinelearning,Z0FBQUFBQm0yeGJvaF8wQmVmWnpmMlNNeW8tbzFKZXUxdFpFWTNhNXpEZlBmb1RUVUFTaTRPQ1BRX3BSWnRwSU1LT0h4X2E4Tk1BdlliNVBsZllTQkFMUEd0VWhtc0VreUE9PQ==
"My [train.py](http://train.py) comes with bunch of additional files. Some additional py files and a huge data folder. Once training is done, i need my model as a file.

So question, does coiled takes care of that too?? Spins up VM, copies my folder there, trains, copies everything back?",r/machinelearning,Z0FBQUFBQm0yeGJvQjI3VHlwYTcxWnd1MDJnTzJGVkY4TDZlcENIYlFOWXdqb1VvcVZJOVFicGV1cnhuU212MnlCYXdkVGNzU1NmSFZjaENyQkxHUUxUcjFDSGdhMG9ZYWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvOVFJQTZvVU10NVl1SElORUVqQm9nWEN5dU9pOFBPN3NMRTM3RU9TVDJGLWNUd0RadXRRVmROVDVfbmJZV28xaC1aZnRIUnpHcDRQQk91Z1MyNzVaOWc9PQ==
">Semiseparable matrices have many structured representations including the hierarchical semiseparable (HSS), sequential semiseparable (SSS), and Bruhat forms (Pernet and Storjohann 2018). We will primarily use the SSS form.

Tri Dao has done it again, unlocking new sources of S for SSMs to exploit!",r/machinelearning,Z0FBQUFBQm0yeGJvbkpXMDNoYXNuQjl5MGJIYl9HMFBMS09SRzRQaUZhWW1RSVQ2SC1EVlE1QlNKczc3bTNWa25OaTJRZHR2Um5wREhGR0J3UTdnYjNMdHNnSGZLN01CcWc9PQ==
this is very sensitive to platform,r/machinelearning,Z0FBQUFBQm0yeGJvZ1o4aTZHaUZpblpNZ3hWU1Y4V0hYS29LRmhvUFVTOHM2T1ZHamhoaXhCSGxGcEw4cmowN0JXaHp2S0xwdU9RcXVHRTJDR2JESktVU2RRdmc0SXVvOHM5NWRQYTYzT2FDZlRnQ1hiM1VXTE09
🤪,r/machinelearning,Z0FBQUFBQm0yeGJvdGNGaXR4aTI0SjJweFZ1U05sRXhXX2pXVk9jZ3A2cFowZENpeS1MVHdVY3dKcjROZUNmY3Uzb2JiMWpIMjlfRUd0T2MxNDJ1NU90Q2FnS0VDenc5bEE9PQ==
Yet you are suspiciously reluctant to sharing your own experience,r/machinelearning,Z0FBQUFBQm0yeGJvVkU5TnpSYUpXbGpVSG92ODFPY1pubFlnaDY4TFlyY1pUODZZbFhlNVFsU1FMX2RhUHRhR0o2dHdxdkhhdmF6RnpvNXBENmg0Zk5SVHNYQ0k3bGJtN3c9PQ==
"It's true that they have not been adopted much so far. However, traditional point cloud networks often rely on scalar operations and transformations, which may not fully capture the geometric relationships and spatial dependencies inherent in point cloud data. By incorporating vector operations and geometric transformations directly into the learning process, the VNN architecture aims to provide a more intuitive and efficient way of handling point cloud data.

The use of geometric tensors, vector decomposition, and vector-based matrix multiplication in VNNs allows for a more direct encoding and manipulation of spatial and rotational information. This could lead to improved performance and generalization in such tasks.

Furthermore, the Expanding VGRU component of the VNN architecture introduces a dynamic and adaptive approach to processing sequential point cloud data, enabling the network to optimize its spatial configuration based on the input received at each time step. This could potentially address some of the challenges faced by existing point cloud networks in terms of handling varying point densities and capturing long-range dependencies.

If you have any alternative theories, please let me know.",r/machinelearning,Z0FBQUFBQm0yeGJvRzVlaURvRGlndkcyNGdTMEhZeGJZOW4tRXBoOGJ3djdzQk1Xb2xZZ2NVdk9SZTJqc0NmU1daYkxWQUNLVTZrNDVXRWpBRWtXODEtWExUZGJ1Wk4zY1E9PQ==
"Also see

[https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks](https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks)

[https://arxiv.org/abs/2209.04934](https://arxiv.org/abs/2209.04934)  
[https://arxiv.org/abs/2302.06594](https://arxiv.org/abs/2302.06594)",r/machinelearning,Z0FBQUFBQm0yeGJvOExqS1ZoeE5lYy1IQzU0cTNIWFlJOWxHY05LaXp2Uk9SLTJ3WHhMal90SEJRNnE3dGt0MDlMOEl4OURCQXg0bmpaQjI3M2JFZXNjdkdTZlk1WHEzMmc9PQ==
"Hm.. I went through your example, [https://docs.coiled.io/user\\_guide/pytorch.html](https://docs.coiled.io/user_guide/pytorch.html)

Unfortunately it's not a ""real life"" example. You download standard dataset, train for 10 epochs. Then declare it is ""trained"" and exit.... 

Which is useless.... You need to save your model and/or intermittent model. I assume [couiled.io](http://couiled.io) destroys VM as well. So results of your training disappear??

Or am i missing something?",r/machinelearning,Z0FBQUFBQm0yeGJvdTRULS1VODY2VGRYbFpueU9SYm5sVW94dEhZVWZLNXI4bzJ5MHo0WjNPY2NUbE1lZVM2dkxISm1fYXB3aGRVXzNhWjFleDhpNlcxRzNrZDd0NHJRR2c9PQ==
"Rotational invariance is just not that necessary compared to the performance and efficiency trade-offs you get from vector neurons. Just use rotation augmentation.

Also, what do you mean, ""sequential point cloud data""?",r/machinelearning,Z0FBQUFBQm0yeGJvM2NMYW1uY3F6NUdTdmFZOTYwc1laaUVwLUNlc1NZbTNxYWhLNzRVLVcyZHp0TDNEOG1GTkVKOVMyQ2R3el91S21DUlpiT2pTdmdhLXBfTVFfQ0Y2NlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvUlJBRTI1ZjZ3YTNtS2xsbTBpZl9tckRQX1NmazNuYzdvSE1IWmhiTHduZElldEx5OTRFS3MxeVEzcGh5WmVXUWdORHNMWThkNl9HV3lOSXVva25qVXc9PQ==
I have applied. Have you received any notifications? I saw the due date of grant notification already passed in their website.,r/machinelearning,Z0FBQUFBQm0yeGJvUWN6LWZURHRzelFKWkgwcTQyQ3djOHJoam5zdFp5cHBwLUx1c0pKcTFRaGF2WEJHQXJQbjhhaFoxMVpCVGh4d0VIcGppdXVTQWlnMkNnMlJFekM4R3c9PQ==
"nope. the decisions were supposed to be out:

  
[https://icml.cc/Conferences/2024/Dates](https://icml.cc/Conferences/2024/Dates)

  
 but I didn't get anything either. thanks for reaching out!",r/machinelearning,Z0FBQUFBQm0yeGJvNkZmZ0tSOVoxZV9FWDZiNDF6TllBR3k4M1Z3Yy1SWGZNWUhVUFdDdWRyWDJSMkxvRXBuVUg4bHhOM0s1SUtFVzJSMmNrU0NvNDNSQmtka0lkUGxkRTQwOFo5dlh1TzFRZk4tdGtEYlBZSFU9
Use Dimensions or Lens search engines to get more name of people to follow.,r/machinelearning,Z0FBQUFBQm0yeGJvUUZTMGo1WUE4RzhJal9UX01xamtRdkI3M2lib1AtWHBmR3YtUzltVEpPSFlKLW1MOWg2elVjczc2aFl0MmlsRDFHaE1aRU5GX01USDFnX1p4Q3BjZFE9PQ==
"Check EMNLP's FAQ page, it explains the diff between Demo/Industry/WiNLP submissions clearly.",r/machinelearning,Z0FBQUFBQm0yeGJvbHdEeHlNY2NzN2xrQVdQQ1VPZlQ4bWN6RkduRk53SE1fWG44RDNrMXRnM2VwaVg2TE56U3BmU3lwYVRGeVZtd3Y0SGhBUWUycTFzNDZNcjM1MVZWcmdCQTlWYXJ0WTNXRU10WHJSQUNwUnc9
Got it. Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJvNzRfdmVJaG1GMFVodmlGTU56MXFDVU80dUlRck5VRkxqZmxmZVM2TFBNcWhTYjJnVHgwZG85YzVaUXNrRjNvcmdmZkpWTjdWRFlMdWVOTFMxWGdLUkE9PQ==
"I believe that the VNN architecture's ability to directly encode and manipulate geometric relationships through vector operations and geometric tensors can still provide benefits in terms of expressiveness and generalization, even if rotational invariance is not the primary focus. The VNN architecture aims to capture and leverage the inherent geometric structure of the data, which can be valuable in tasks beyond just rotational invariance.

Also, in the context of the VNN architecture, I was referring to the processing of point cloud data that evolves over time or has a temporal component. For example, in applications like 3D object tracking or motion analysis, the point cloud data may change from one time step to another, forming a sequence of point clouds.",r/machinelearning,Z0FBQUFBQm0yeGJvUnpFLVNyUmFpcXVodFFRdjhYRVB5QUQ3STM1eElPYktuNTgwSHBNVlNNSXI2RHVKQVY2dXBrdzA5bExlUktha3hGcXFlVzl5SDdKYlpKSzBSaVNQc3c9PQ==
"Good find. Clifford group-based networks rely on Clifford Algebra-based geometric transformations, which are slightly different from the approach I outlined due to the intuitive nature of vector operations on geometric tensors, and learned vector decomposition which has its basis in force cancellation.",r/machinelearning,Z0FBQUFBQm0yeGJvLW5BVjRHWjVzaTFiNGlIam9HR09OQ1pzbXBIdi0xRHAza2xVME9xOTJfdUktaU5HQ3dJT0loQUE1S1ZWaUlKdHpsbkhDU09jeEdvQ2hBY1E0d0dxY3c9PQ==
"Two questions:  
1. whats the computational cost of running the alpaca dataset through phi-3?

2. what size of SAE were you using?",r/machinelearning,Z0FBQUFBQm0yeGJvRWZEREFkT054QXV0ZUhJZFdfNGtxQTZTRV9ENXhKNjVyNVZJMlJ6ZW1aZE4wek5ScmtwNE44U3VRVDNHSENKQl9IcDl4bU81ODBQazVQN2hyM3VhYmc9PQ==
"Yup, that’s a good question.

Coiled definitely supports moving files between your local machine and the remote VM. You can use `--file` to upload files/directories to the cloud machine, or `--sync` to enable bi-directional file syncing between your current directory and the cloud VM. 

Both of those options are useful for small files (for example, a directory of Python modules or small models), but will be really slow when moving lots of data around. I usually see training data or models, especially when they’re large, kept in cloud storage. Then you can use tools like [s3fs](https://github.com/fsspec/s3fs) or AWS CLI (or other equivalents on GCP / Azure) to access the data files from within your code. Something like:

`import s3fs`

`s3 = s3fs.S3FileSystem()`

`s3.get(""s3://mybucket/traindata"", ""./traindata"") # copy data from cloud storage`",r/machinelearning,Z0FBQUFBQm0yeGJvdEM4THNnVlUtdjBIZFY5aVdMM18tZk51LXJFTUVwOGxPSDFKUWtwZFd4ZWRtOHg5ZEE5OHotRVoxcmhSMWp4UEE2VlJaNlM0WThrQlhCSDkxQWNqSGc9PQ==
Thanks for your interest. That's a very good idea.,r/machinelearning,Z0FBQUFBQm0yeGJvclUxeU1KVlVkVWtybXZ2ank2R1dOcTFSUmJIMlRLMlNKSjRIZ2RlOTJlNlNkdkNCNW9yWU9kWFdOWWpOLTdsYzQ1NnpCbzRpR21Od2tQeWRzN3hpVGc9PQ==
Can it’s run lightweight on CPU compare to Pytorch CPU?,r/machinelearning,Z0FBQUFBQm0yeGJvOVFSRTdNaXlNUWw3RjkyNThUbWxYTjY5UDRDSTlnTmJQY1FiY3k2eklINW1RdU9JMWhCakozck1RM05ISVliUTc2bDZJUEQ4RDlTa192UkpSbEtmcWc9PQ==
"Upvoted for snek, but upvotes is upvotes. :)",r/machinelearning,Z0FBQUFBQm0yeGJvdDFHNkZFSVFJZGFWNzdzc1lWdjhpbkRjTUl4TkJoRVBleU4yNWV6eXJYeW80NXZYek5BMEYwLXdiUlpldDkwcHdnOVJ5ZHRQWVBxdF9WdDNKX2M3OEE9PQ==
Apply sliding window (with/without overlap) if you need to process a longer audio (for e.g ASR using CTC head).,r/machinelearning,Z0FBQUFBQm0yeGJvYk9EQ2dHSkJpcEZieTA5UVF4THd0a2VjaTRINnZJX1EyTE9QTDBvRGxHdEpjdlFBcFlvSjgyZGxsTWNZVlNQV0xwTlRuZ0xfd0Ria21NUnhNakZUX1E9PQ==
"when i write EMNLP FAQ, i only see specific FAQs of previous years. i checked these pages but no information about demo / industry etc",r/machinelearning,Z0FBQUFBQm0yeGJvM2tGNEZjTFA5ZU5ReXNBS1VfdEhXb0djcm5MTlZFNWMza0NMdVdWRzltaEgwZ2RmM3UxempSM0Q0ZFJPSW5saG9ELTJ0RTE2azNteW1INUJwQktDd1N4UWU2Qm8taVpGWHV1RFdRYlN0cFU9
"It depends on the implementation. I'm planning to add caching in the near future, which should make it even faster.",r/machinelearning,Z0FBQUFBQm0yeGJvSmZLeGtBN01yRTRjNnQwRTllU2YySmhIdWhVRktQNUpMVEFwVktuZEFDeVBQd3R3S2dLd0tqcFFwSUh4OExBd2FUdHBMWXlIcVpob2dKc1FzNHh0cHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvQUh1dmlQQmZlTlVLQ2pLOE9RUTFydW94MFpTT05Kb1FqSWQyZUpsbW1ndVp2T3QxMG92eGl6R09KNXlXMHNWczhsa0h4SHlGSUtrQ05wQTZuZFU4Vmc9PQ==
Lmaoo,r/machinelearning,Z0FBQUFBQm0yeGJvcE1GcVBXRjVkZllJbW8xcFNWUEQ3SFQ2QUlLUWlfWktnS1A4Y1BrS1pjdTB1NVV1R2JFUGxYMzdZelRuLXhpLU5CYzVhN1JzbGtaZExEMVlndkRJMEc5czlNQklMazhVRWtQN3hPbkJvT0k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvZFhIb1VZMmpQdjk2emMyTkw1YUFQS19UMElKdkctSXVRSTdDaGYzODNRTnRyLTFGTFRuanhRYnlwcHl4TmVPd0Q2MEN4M2VtUWVaNWFPR1VjMFhPckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvWWhwSUtLT09HV1NmNV95R2VJS3lIVTgyNkNZZVFsY01WSE5odVVxLTZlX2p4WGtKUDhxN3FvR0NMcXNrLVFPM2pkUkZwN2ptb2VOX3ZlZFFhS2Y5X1E9PQ==
Great! Keep up the works. This really catch me up,r/machinelearning,Z0FBQUFBQm0yeGJvVkpZU0hZUUdTNzk5aGZDS0pnQmxpRVUyTVplR0x1b1JzRWlBTVQ1cFlOZkp0NkNnbkwxZ3NId2U4OERPYTVnVW5qMHN3amNLQ24yN283Y3lldlo1V1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvUWlBYWtVbDVZdl9FRU1tbmtDM0JfeWMzNTN5OWVBcXBia3JCZGQ3WFhKTm1iakhFMU15c3cyVDVlak9BSXVndURvY1JBVFUxRV8wYm9hNUNkMHpwSkE9PQ==
Do you plan to add mamba2 as well?,r/machinelearning,Z0FBQUFBQm0yeGJvYlROMDZMVGxkZGZJb2JHMFJFYklfTF9VZVJJbDlySFpzbGF4aHA1YnpXRm9aeDhIRVdrQ0ZYVThZY0syRXFMWk5fRTZnMEtWWFNXaHk1NGlfNlgwTFE9PQ==
"Yeah! I saw that it was released yesterday, definitely up on my to-do list.",r/machinelearning,Z0FBQUFBQm0yeGJvc3NlR0xrcGxJZWk0RnNYM2d4cjFPSmpQOW9ZT1ZyMERyZlhyNkVBUjExMHhocUFSdFM2Tmk5enUxeDVUVTRaQkltcjBfaWxTOG11dmJfdTB5cHUwWmc9PQ==
the guy whos the CEO was my old teacher when i found out i was surprised AF,r/machinelearning,Z0FBQUFBQm0yeGJvYTJRaXFmYTM0bnV3eG1BdTd4T2pSX014eTY4M1BNSUZ2SERDYk5kMEF6TTF5NHZEWTdSQ01Dd0VpVHlRQXJCV2tNM2E5SERPXzBvbEtYN3g5YVFkZmc9PQ==
Serious question how do you find the time to do such a project? Are you working/studying? So many cool ideas and projects but I can never motivate myself for something of this scale,r/machinelearning,Z0FBQUFBQm0yeGJvYU5Xc09QOFNwTTRaQ2pnWmZ6Z1lLQmRBVHFEei1pd1h3YmpicmVoVzBXV1BjREQ2b21FalNPY2s3Rm44QVZNb1NLY2JUUkduWWpyZHVnaTJpRTZfcGc9PQ==
"Same here. I've worked with C++ in Computer Vision and audio back then but meanwhile haven't touched it in probably 5 years. Only for very niche cases that  libtorch or onnx runtimes or tensorrt or similar would not cover. And a tiny fraction of people work on those compared to the hundreds of thousands of users.

Rust is becoming quite popular at the moment but I'm not sure if it won't be something like Mojo that at some point might take over.",r/machinelearning,Z0FBQUFBQm0yeGJvTjJLa3lqM1ZXaTJsSi1udTRLVDRUZEtYS1FSN0Rrdi1QaUI4UmJuZDhjNEpWMTEzbUdJWnF3SWE0SjRVUnBRb0sxbVpBejVERFlqNGljU0ktRzBQNFE9PQ==
"It's hard, DM me if you would like to work on something together :)",r/machinelearning,Z0FBQUFBQm0yeGJvb3ZhV3NpbHE1bVBEUkgyanFqRkIzTzRiS2NvZFRlcDlZNVAwV25zTHFNaXY3Y1VYNEFURWtwZDNXbzRBLTBSUXhnQ0tMWTZaUDRmalpDYnZfWXF1NEE9PQ==
"My use case revolves around locating the right information from a large set of long documents. For Agentic RAG, in my experience LATS beat them all. (Check https://docs.llamaindex.ai/en/latest/api_reference/agent/lats/)

For vectorization and retrieval, It's the BGE embeddings and good ol' L2 distance.",r/machinelearning,Z0FBQUFBQm0yeGJvNmFWRmNPWVZFQnZYQnFFRHpZam1vaUFNeGxubnZVYndncUo1SmdCUUszc1JTMjhGMlg2NVRzQU1TLTh1QlRueHl6Zlk0Nk9fdG4xNF9nclNVV0Y0SGc9PQ==
ahahahaha AKA illegally scraped data,r/machinelearning,Z0FBQUFBQm0yeGJvZ0x1Y3lraldzeGdoUXk4MjlYU1pFZmlMUWlPSW9XY19uY3owaTE2MDRMYVhZY2paY0x1YXUzLWxONC0zT090YjdJMWlzVmQzaV83dENlekZwdUFTclE9PQ==
Have you tried a career in marketing?,r/machinelearning,Z0FBQUFBQm0yeGJvYjlpaG1mYlFVa2lmc1ZhS05ZMUNPZXZWbEZfQnNqVlVUQjVBSUVpSU1sZF91T0dtNXN0Y1FWMnFmYkZ6MHNXbXluQXVBY05xTXpwZW4tMzNxRE1jYWc9PQ==
"Chris Olah, David Bau, Neel Nanda for interpretability",r/machinelearning,Z0FBQUFBQm0yeGJvZkZhZVEwNWxGMklGOEJZd0NVb3F1blJtNi13TnRiVG9vdUp5TWRqeGJlU19OS3RkN2k0ZGx4Z3NpcklYM0ZoanV4bXNwcnpHdkFoQXZRWGM0eG5HZlE9PQ==
"Not really, why do you ask? If I sparked your curiosity regarding the potential of vector neurons, then I did my job. The untapped potential definitely excites me, so I'm glad it exudes. In case anyone was wondering, the next thing I'll be working on is a VCNN for chess prediction, so basically a VAlphaZero. Since you can represent piece relationships via vectors, it seems like a natural fit. And I would use vector-based learned filters for each move. And we'll see how that goes.

Also, for natural language processing, I was thinking of using multiple 2-D vectors as word or subword embeddings, where I would use hierarchical-constrained triangulation. The main idea is to use 3 anchor points and three 2-D vectors emanating from those anchor points. They would be constrained to intersect such that they represent a specific point on a 2-D map. I would then do this hierarchically to pinpoint a location on a 2-D map, starting from high above and then zooming down through multiple zoom levels. The vectors would pinpoint a word or subword. The vectors, of course, would be learned such that the result would be interpretable embeddings for an NLP task.

What's great about vectors is the creativity that you can put into your architectural designs.",r/machinelearning,Z0FBQUFBQm0yeGJvVGE3LU5jdUxvTENESksxQk8xX3R1blBYOXJuTVZyYld0RHg2eWxqX0R0MWFVRV9UQTkzU1psU2FxcUpldk5DYUhldmpVNEJDZXNLYnU3ZE9fc0RNYVE9PQ==
This text is written from someone without a Phd :-). You clearly underestimate what kind of toolset is required to complete a Phd!,r/machinelearning,Z0FBQUFBQm0yeGJvT2FGZ3IzYkhKSEZHcWczWkRiSWdzRldPYzJMZzloeFV6N1N2WVhxWUQ5TDZpRVFjTnc2OEdmZms1Sno5SXhld0pVNjd2RTZfWU9jYVVMNFZmVnJUU1Y0eHJWYXA0cnJreFBreEJmMUZ6YjA9
"The biggest issue would be domain knowledge issues.  If I have a sparse dataset where the existence of a value is important then the method of imputation would need to be particular as opposed to a datapoint where while its existence is important the actual value matters more.

If that's configurable and keeps me from writing a long list of pipes, it would be great.",r/machinelearning,Z0FBQUFBQm0yeGJvTzRQVWRsXy1VUjhkYXlCd1M1Um1SRmdkUUxfT0pPWV9PTmg0VXhZS0llaE5FT3RqV2dSTXNWQWJENUF2QkozNHhWdUxueDU1b011XzE2ZktUNC1sY2c9PQ==
"That's why I open-sourced the code and made it available to anyone to run on their machine. I wanted them to share in the experience of running their own VNN or VGRU. It's extremely easy, as 18 Redditors have done so far. Thank you Reddit!",r/machinelearning,Z0FBQUFBQm0yeGJvQkUtVVJlYlBfaTVTdFpYSUhEYkFtY0lHWDFqYzNoT3pIU3k0M0g4MzB0YXRFdldFVUwxemlKZTlnVERtS3hRX3Vtd2ZuU1FUcDl4aXhfb20xZVpTSlE9PQ==
"Now in 2024, this has changed. AMD invested alot in their software stack (incl. ROCm) and visa versa a lot of AI stacks support AMD cards out of the box now.",r/machinelearning,Z0FBQUFBQm0yeGJvaG9US1NEMENFOGpRSTEtVVNvVldlczNlRmRBOXRRejhoYndnM1dUSFRGbWNHU0RFcmdmRXdPczlqVGFIbmJMYWNmQ0djYkdjWUthVlVkX2Zmd0tUdGc9PQ==
It's improved :),r/machinelearning,Z0FBQUFBQm0yeGJvNFByeUJGMktjMjNNNUpRYVNPNC1mWHdzSmh1dEpkNE0xTW5WVHFoZ1Z2M0hNTnVYQmROQmItTnRpWVhvQ3JQTXhtRzI4eUIycHNWM1Z6QW16R082LXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvWnBLQWNITXVVMHZVRnJHbV9CanktX3VHLXRBV0pVR1NzZzZJUm5UOTVheHVlZC15Z1ZWZk5iNnNUWnZsRjJ0NHVWMC1RdXFjR0lpYkN1eWROOE9maVE9PQ==
"yes yes, lovely code and all that, but also: prompt pls",r/machinelearning,Z0FBQUFBQm0yeGJvV0hhRlJsck1pcWdlOUJGY3NRQWQ5US10VmhvYi1iVktNUkNzNmpQN3UxbVdwRUtiOGt4SWo5elRwNXhTXzJ4bXVoR1dwN2tPSjd5RFN3bHVyWk1vaFE9PQ==
I'm glad you're finding help online! It's just a shame that not a single one of these 18 Redditors has generated a plot or table that you can share,r/machinelearning,Z0FBQUFBQm0yeGJvTE1HTEN4Y0JrUHRiMGlKNWFneV8zdWNFUjFaU044Z1pqTVk0dHBZajR1aFEwWkE1ODMwMV9EOEhaT0FEM1ZPa0EzNzJtZ2F3NkJaY2VJa2xaU2hpT3c9PQ==
"I really don't think so. I have so far worked with *many* people with a PhD over my decades long career, from all over the world. I have very rarely been impressed by what they brought to the table. Frankly speaking, if I have a choice between a freshly minted PhD or an experienced Master (in the area we are researching), and I don't have any other information, I pick the Master every time. But hey, sure they may have tons of skills and tools that I just missed over and over. They also often missed it and talked about it once experience kicked in.

Edit: Also, you are missing the point of the text.",r/machinelearning,Z0FBQUFBQm0yeGJvbUpvMVNTaXFpelQzc3diZ21Ya05wbGl4SUxOUHF1YmRYTFBsT0hpOERTVHFUSVJDUzJmcE1rekZNWmcyYll4bnN2djVsTWwxQkh1cC1KaWZ4NE1meHc9PQ==
Did you try freezing the projection head during fine-tuning?,r/machinelearning,Z0FBQUFBQm0yeGJvUjRMaUJKdUhrd2Z3dDlUQ2hfWTZOUlFDd0tueE1mOFBmSzNaaGhFSHN3UW5aX0hRR0NNWlpvRlF2aHdkQVpwbDlkQ0ZkTE5EekVTalZzTTB5d1dOOFE9PQ==
Solid checklist! Implementing these practices can make a huge difference in ML outcomes.,r/machinelearning,Z0FBQUFBQm0yeGJvcGVJSXlGVmlJc3BYMVBuMFdoS0FyVGV1SVNJN1VvTlp2LUxKOGxVcjRYM3Mzc09YVkdfY09vZUQ3UjRDaVIwRlFOZUdJdUk5eTZfYXNhSEh4ZnJablE9PQ==
"[""a cute mamba AI model implemented in pure Numpy as a logo""](https://designer.microsoft.com/image-creator?p=a+cute+mamba+AI+model+implemented+in+pure+Numpy+as+a+logo&auto=true)",r/machinelearning,Z0FBQUFBQm0yeGJvc0t3YVFWUWZjYVdYNnRWX2ZiMXpzd0wyZXNtOUtSSExhRkcycWR0V3pBeThFUkhkUkxJSmh1TGtweUtENTdTWmRWSHB2UFZKa3dfZ0VSUHZ6bUlrU3c9PQ==
"Perhaps encode the position information in the feature vector? Llms do this. Sounds like you want absolute position encoding for this.

You also may want to look at using reduction=sum on cross entropy, so that each item is used in the loss calculation instead of the mean.

Also, just to make sure, are you softmaxing before performing cross entropy? No need.",r/machinelearning,Z0FBQUFBQm0yeGJvM0Jab2RnNExWWE5ZbXViakpmSHFjTXRLaVVBVUkweTlIVkVvaHhTc2RSYkVmRF9zRC1GaFlJQTZBYmJ1VXIxWHRiM3QxcVBIQkdfWGtJRk1lYllkMXc9PQ==
"Hey, we are all on this same journey my dude :) some are just further than others. I'm still prepping to partake on the journey",r/machinelearning,Z0FBQUFBQm0yeGJvOGJtcTJvNHZ5cDNCVmJWaUEwVW4tOXo2M18wMFBiT2tWdl9XYVVYY09zZnN3YXgxR0dQNlRnVGo3Y0NvYjRYWHcwVjUxOXh5Nm81SGpRSGtMSjF1Nmc9PQ==
"In my experience this is a pointless exercise. It is better to just pick a set number of results and always return that many. It also makes things easier to manage on the frontend. If you start choosing distance/similarity thresholds then it can get really difficult to ensure that no query will return too many results to the frontend. Much moreso than if you simply return the top n every time. From a user perspective, people very rarely go past the first page of results as well. They either find what they were looking for on page 1 or try a new query. As a result I think it is always best to just return enough results to populate a few pages on the frontend. 

Is there some sort of application requirement that is forcing you into doing this? If you absolutely must then I think a good approach would be to do candidate selection prior to calculating your distances and ranking. That way you can always just return all candidates in sorted order and it should always be smaller than your entire index if you use reasonable selection method. Additionally all of those candidates should be relevant to the query at least somewhat. Lastly it would improve your search speeds. This would solve your ""returning only relevant docs"" requirement, but you would still have the issue of needing some sort of constant number of results to return to avoid transferring too much data to the frontend.",r/machinelearning,Z0FBQUFBQm0yeGJvczNwcDAxYXVEdmJJQW9WUEpNRkRnZnlueEdvZmNsOEZWN1VsWUloanFtb25EcDJEY2N5UmRZbktWbnRQajEybjlsNjRlR2Zhc05HczBWV2RnUTVLVWc9PQ==
"Well.. Not out of the box, but Silly Tavern does. For speech recognition you will need to install extension.",r/machinelearning,Z0FBQUFBQm0yeGJvRUhXRklHMkZsVDNieVZKeXVEUldwM0VoNUgwSnhTR25ZOVVBX1E4TXZ1RUVuTG1nMmpJcGIyUnduMGZvM3VES1FmWWItd0VUSGlSV3A5Y0Y3WWpNZVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvYUhvOXR0TGdjNFBrV3B1bkJBQl9NcnlqWkZmR3BfWUd3SThkSzZseWc4SVQ0dXprdmlTV3RTZV90RXcwa0E4aTJMbWFNR1AzOERmRV9PaTNaNGVNU3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvc0MzVXdRZXVmRkZnWFcyaGp0a0ZmWU1BbUFJSTM3XzZadDJqZnFReTFiM1k4RHljV2xUR2xVN25qZDBaSHVZaldIcWhhcFVxeDAzT0ZHVkR5ZWpmOFE9PQ==
"You just have no idea how CPUs and GPUs work, do you?

CPUs are for general computing.

GPUs are for massively parallel computing.",r/machinelearning,Z0FBQUFBQm0yeGJvYzZ5Y2RIT1ZXbzZramVGM2VveFI2bHBiSEJ0dUZKZy1GbkRwTFppMjdVSGFPZGxmdE5SY05uQTNFbW5wM05lOUxQdC1zTGVNMUFpVzVUM3dGOWlVdGc9PQ==
this is actually what I am saying. Convert regular compute to parallel compute so can be parallelized,r/machinelearning,Z0FBQUFBQm0yeGJvbFkyamFjV3E3RmpQRmgzUmlvbGVpT0JaYl9kcEphcjFfRVFkdzBrWDUyeFpxMnJ4YnRwenhvQXYzemJ4VVVEWnJQNEdpTEZKS2JLM0g3bVhJd3FzU1E9PQ==
Those problems are not massively parallel though.,r/machinelearning,Z0FBQUFBQm0yeGJvYURvSERYTF9kMWRFa0U4emswWUliZU5nU0VDYjYyTHVZcjZRNHFQVHcwWV93UzBKZUVJTWY1RUtmbHlObFB6d3Y3b3V4ai1GbTg1RlVKVjlwT20xa1E9PQ==
"They are when you consider a billion people combining their compute together.

for(let i = 0; i < 99; i++ ) {  
  console.log('test');  
}

\\^ once run once, would never have to run again. Just dip into the giant embedding pool/vector database and dip out",r/machinelearning,Z0FBQUFBQm0yeGJvYmJQUVhvMDlKdGxmeU9CUDJKWHJvb3o3SFhYaUtJa2lEcFV0bDNiVTNVdjVrcm5XMFc4djg0dTJkMlpDbm0wUklDbjF1ZFNqZmkzNzlXUW9LTmhGZXc9PQ==
None of what you're saying makes any sense.,r/machinelearning,Z0FBQUFBQm0yeGJvX3BnMWpyWTRIMGRkeEpacXEyNzBEYTYwZUUwRFJwQzlxT0t1VURTZm5YVDlNUU9zQ1I5X1FNdVFmLWNJSGZRLUtQdDNqVl9CX3djMDc5dGdXdFhlaFE9PQ==
"why, explain how parallel compute wouldn't make sense? You have a compute that is turned into an embedding, compared against a pool of data, and served in 15ms via parallelization. We are taking a standard compute job that might take 5 - 10 minutes and computing it in 15ms",r/machinelearning,Z0FBQUFBQm0yeGJvNEZFdExSVTBYalZVdVFsbGNZcFRtc2xnSTN0dHhvNnBnanNxLXBPNjdtc0hOR2l4eWtQam1mRnE1M0gxX3AxZVoyd2twU0VWbnlMWmpJcGl4OGZ5NkE9PQ==
"> you have a compute that is turned into an embedding

This makes zero sense.

You cannot just turn ""a compute"" into ""an embedding"".",r/machinelearning,Z0FBQUFBQm0yeGJvbkZpSnRGZjdFN2JSdVRWby1qWHJKRmNXcVVjdFBJZXhwNkNtY0hkTUhFbEZvdmxGSFZONUJpU2YyZFVkUjhPc2RkXzFkUFpNUWR6V2ZCcy0wdVEzM2c9PQ==
"a compute is words, turning that into an embedding is exactly that",r/machinelearning,Z0FBQUFBQm0yeGJveDY0Ujd6RXpSdktPZXdqdjFpVTlHTnBYV2p0Z0EzQkl2aHhvbWpqenhXZi1Lc2JDYVgwNmMwWktBT1haYU1Vdk5fdDdqXzRobUpmVVhKT3NTQ0FHOWc9PQ==
?,r/machinelearning,Z0FBQUFBQm0yeGJvdk1JOFEwSklmVVJtei1PTmItRmJlc1dSdHdldy1DbVVfWlotTEZoWEswSVZkWm9GcC1WZmRjdFpvTWQzUFktQlpJMFlBMWlCS00yVTUyQ1VzU1V0NFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvYkEtMDBsX2RGODhmZk9tZmdJWFE3WDVSMGs4R3BwYjQ5c0E2Q3l6YWYtdG1WZVJEbktUcS1BX0NfTFRqUTdaVk5TcHRUakdpcXBaajRPMjRQcEpWd1E9PQ==
"Consider sprinkles of [BearType](https://beartype.readthedocs.io/en/latest/) and [Numerary](https://beartype.github.io/numerary/latest/) (the link to the docs for the latter is annoying to locate btw., so consider bookmarking it)",r/machinelearning,Z0FBQUFBQm0yeGJvLTBoaGpSbF9xcDBqRVdubW1tUVc0ZlJYcHZpMnpYV1EwQlBIZWNtTEFiTU5Ma2NSbGkwV1hKWlJVVmd1OVNNeWxJdllsVndmNlBxV0pHbS1NZzI2dnc9PQ==
yes,r/machinelearning,Z0FBQUFBQm0yeGJvTGtzbGRoaWNyT3k2UVl1a1A4OGw2ZUZqNWlWbmkyOTRnLWk1QldZbW5jVGkyWGp3dUpzTXRtNlZfOENBVkhBMm9NdDNYc1dZYTRyUU45RG1vSnVfRWl2VU14cGJIVlFUSGt5UVI4NjZxX289
This has to be troll.,r/machinelearning,Z0FBQUFBQm0yeGJvOVZvQ1BNNktJZ0t6RzNXbHVTRDJsOWpjUzdHdVBGZTF0NHJ0Q2J4eW5jS0JXaEtVc1VNRks0a1VfWHdMUUlEbFMwbGp2RFkySWg1UThidV9JN2FETlE9PQ==
"nope. Feel free to let me know why you think this wouldn't work, I will explain what I am thinking",r/machinelearning,Z0FBQUFBQm0yeGJvcWxWODBadDg1Mm1HS05PeHhkTHc0Qk1SUVdQdnFkQkN2Sm5udS1CblNMSlpzWmdabjRBUmZZT2NWaHBycHVsclBXcnk5cHhuREtvdm5pVW9WZ3VxWlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvREg0SXR5ME81bU1udjNNLTU0aHQyb0tZYlZPcy1mc2lSUGp2dUJUZGY2NDRqRWhsNkYyS1Y0cmNDaVgzZkhaVkVUUFY3QldHdGRlU3NXM04walQ5enc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvWXYxM3Z5Ni1mMFBfVm9BendabDJTWDNiUnVNdnpuLTJUTmdFMTRPMkd2eHVreVZpalNyTnR2MXFTV0lycnJjMThiaFp1WVZ1SFp2ajJPMWRhaGw5N3c9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJvajdGWnNfcXpWN3dYcndSYVpGUENGMkppSlVNbXlKajNITlUzenNocVpjQ0ZMS0U4NXBZdTlQdWxsVHh3QzY4OElackZQMzk5U3F2S2ZFMjNDR1JJcmtvZThCZ2FuV3A0VVhhLWQySEpQb0U9
"Sure, no problem. Just learn a vector embedding of bounded size that maps the set of unbounded byte sequences (program plus input) to the set of unbounded byte sequences (output).

NP Complete? Just dip into your vector database! Halting problem? Just dip into your vector database!

What you are describing is dynamic programming applied to all possible programs & inputs plus a lossless compression algorithm with infinite compression ratio…plus you need to **learn** everything…by running it.

You see why this approach might come across as a bit naive?",r/machinelearning,Z0FBQUFBQm0yeGJvcDdwZE5uNGNYSXNqVzUtQW1LMHI5ZTI0aXdpNjIxenFvOHA2UzFIVXlSVFJpbzdEU3lHT05PQmVmLVNpcXp3dmhaMS1nZHBzanVpTWppbjFkUXJIekE9PQ==
"I do not think the approach is naive, rather novel. Can attach metadata with embeddings to represent task at hand. Could then take a result and swap via changes in one e.g. function to the next",r/machinelearning,Z0FBQUFBQm0yeGJvdUFDSDMwOFhHY2l3bnVPMTR5SmdjRW15ODM3aS1VTG54VE1EM2ZlMU91QlhRTzNEUTYzT2wzOEJ5NU5ES1hRSjFpWHpJcmVudE5YZmVXZEhJX0dhS1E9PQ==
"I commented on this in the SD reddit also, but I do think think it beats InstantStyle in most, but not all, the tests. They make a good point that since it doesn't require control net it may allow a larger amount of variation. Would be interesting to see how it plays out.",r/machinelearning,Z0FBQUFBQm0yeGJvYUYwZlJCYkYxUzRkMDRZaUs4b05CWDVJc0NPQ0tiVU1kblUxVmZncFZ0VHVmX1ZXUzNocmVsb1BjU3Z4dXZxTVRMMERWaHY4djl4ei03UF81ZFhSVlJqa3Vzbk93c1A2V0Y2LW9JV2xha0U9
Is Numpy actually faster than Pytorch on CPUs?,r/machinelearning,Z0FBQUFBQm0yeGJvemc4SXRqbGprTjMwZEFqeFFhX2ZoNjFiNHNVYUJ3VlVVWGttWFB1Yk9iejQzUkk0UkNPTDJhNzhUM2RBeW51TV9CYjhJQzEtNjdCeDZiLVdPVFFCdGxHT3FmS0IxeUFUSnN1Zlh5SFpOOWc9
"I agree with u/itsonarxhiv.
Topological semantic models would be like oil on a fire in the field of marketing research.",r/machinelearning,Z0FBQUFBQm0yeGJvaGtJa3EwcXpQb1lZaEJBck1kd20tVmZ4UGhuaE41N3lGRV9zVUV3UkFWSjlxeE5xRHpIMlg3Y1lIemxMTXZNUG13WXg5aTNESENwSU1yYi12OXpfMEE9PQ==
"First, thanks for doing the analysis and taking the time to do some experimentation. The results were quite interesting!

That said - I do wonder how applicable the results are to the real world. This particular use case is quite limited - a pretty restricted set of classes, fixed lighting, etc. I.e. things that play well into a smaller/simpler network but don't necessarily reflect real-world challenges that would break the smaller/simpler networks. Smaller/simpler will naturally run faster and require less training but also have more poor results in more challenging circumstances.  
  
Maybe I'm missing something - but that was my knee-jerk reaction. :)",r/machinelearning,Z0FBQUFBQm0yeGJvTEhHTnV5U0FIa1pIRzUwQjl3Vkd3dktpeC0ybmktckZfanc0T3FzTjBidkNkNTJVcEZxS0dFRTRrdlptdmFWVnFuMzBvdU1ybWgwVUR4RDZvREpja2c9PQ==
checking out. this is a really interesting topic area,r/machinelearning,Z0FBQUFBQm0yeGJvS3FKa0JlMnM1VWFmcmN4ekNkTm42eEdnRVVUWjMxS1RyWVVORHJKQml2dmF5amhFcUE0YllGclRuS0lVMHZxUXNRel8wQmhpa1ZHQXhVQXIySkxYLWc9PQ==
"I see what you guys are saying now. So basically, the VNN and expanding VGRU architectures likely capture complex relationships and structures within the time series data, like how topology deals with spatial relationships.",r/machinelearning,Z0FBQUFBQm0yeGJvdmJrS2F2QWR5anFZMHBJWUVjVV9DT0hoN2UwLUlXWHBNdXFINW9EUWwwdEhOWDdiOTBCR2plSWg0b2tZQWFlRGR3Ujh3NTM1N1J5OU5aZDhlUklHSHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvbXo5WFFmSGFwQ1JHSUJqNDZZbFBEbElCY1owM1QzWS1rRnlBTzZORER5UHRfUlFfNFJqMnA5UWVFMnBuaTRpWFhDOFYtM0ItU3ZUYWRwTUNZdExwOVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvS3VHMHlkTGl4QnllY0FZRk9jM1pNR290NFAyOFNzR0tRd25fVl9LMlZDV0tpV2VnalowNWdNQjRubGRYcU94S3VSOVMwdHVMaTVxb0hSRUFXcW8zZGc9PQ==
This is actually really cool,r/machinelearning,Z0FBQUFBQm0yeGJvWGhqa1B1T2Vqb0xVaGtaOFBmNU9JMDlvMzFETE1nLVVPalJFY0V5a21KbnpSSE4yU05RbTl2US1XbTduYTZoZUhLc1dzOTlUdi1TUTlPc1gxSEZLRUE9PQ==
It's easier than that. Just install ollama.,r/machinelearning,Z0FBQUFBQm0yeGJvLU52X1VscXBPWDYzS3A0ZHgzVGF3bzZxZ0E0UXRJMlJLWTNNTnJxdWY1YkZHRnFzcjhZOFY4dC1sb2VXbEp5Qy0wMDlRcF8wbTk5azZHMGpyV1FtS3c9PQ==
Me,r/machinelearning,Z0FBQUFBQm0yeGJvNXltWFZKemg2cHN4ODNYajVRck40WkVBUzN1MEc4NnJqdWEyaHY4ZTgtQWFMWHc5UERuaGZ3QjZoSUNuQXhxODFETEo2RXRLYVoyWURLNG50OVVLZENkaEFXcUdyWVZ4YmlVaGpJU2tkS009
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJvWlA4dFN4UW5RYjkwSmJ3SGZUZTl5MXU2R0MwaU5Qd3Q3WnNTRE04WV9zWGVtaktsX0FaZ0F1OXJXX0dRYmN4eFQxSlB1b2xsem9fZ3NPZ1RaQlhmcmc9PQ==
"These small networks are more common than the large MSCOCO ones.  Clients typically ask me to create neural networks to detect some gears placement in a machine, or detect a specific part on a conveyer belt from a fixed camera and with never-changing lighting.  I've never once been asked to create a network that can detect toothpaste, zebras, and airplanes from all possible angles and camera zoom values.

But regardless, the points I make in the video are still the same for small and large neural networks:  Darknet/YOLO continues to give better results, trains much faster, and also runs faster than the Python frameworks.",r/machinelearning,Z0FBQUFBQm0yeGJvdEhzX3dpUnV2cDBtRUNid0FDdldULUJQTmgzTy1OWGZ1X3pqb2E0YUNNZ2JOWEFIQ1pCenl6bnFGb3k0TkxZT21BWDNaZ0RLckpRV0Q1NUF5ZnJMNldmT0p5RWRIa1Z5Z1RxT1otOFZCeEU9
"This guy is a ""top contributor"" to github, he has thousands of commits a year apparently.",r/machinelearning,Z0FBQUFBQm0yeGJvYlRNd2VNSWkxNkx4cERxZ09GNGtRWG10UGg0TnJzUU9KUGJUaDV5b3pZU0NFcVU5aHV2ZVFWcDBmdHU0Y3RuQ291UVdmd2VRYktsV3dwTE1ab3AzMnc9PQ==
"Hey! I'm working on a AI project, would you be interested in listening some about it?",r/machinelearning,Z0FBQUFBQm0yeGJvdUpvbkN2QmRHTVBpWmpFSGlERVhiNWRqY2daN1RPenNzakloajZHNWZ4OFVYZGFSWWJjOUw2V2dJX0tsdXBDem41M25Cbk5pRTVmay00VzFMS3BUamc9PQ==
"That's a good idea in general, of course. But that contradicts how serving systems work - they compute scores independently, typically in parallel, on all items, and then sort abd select the top K to display. As an engineering constraint, I can't incorporate this information into the model.",r/machinelearning,Z0FBQUFBQm0yeGJvWko0TlZ3OC1CSUF1b1U3OGsxWW55NDZWV1dIYVZfbUxISGpvVnJHa3otVno1UTVHd0FXVHVMcTFMUHhYMHIweFkwQ21Cby1FWVlEUi1ZZ3V1Y3hlZHc9PQ==
"Yeah, I just discovered that recently. Crazy that you can get all of these so easily.",r/machinelearning,Z0FBQUFBQm0yeGJvUVlMVWpTVzZ6WWdOZkZxeTJ6YmdpQktLZnFLYjBGU1lVSkNmTlh1VW53bWRyNUxlLVA2cDFnRWROVTFvNWF0MHI3aGExVG9zREo3MFhLUUZ1T19RV3c9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJvWWNLTUlyRl9iNE82aGlVdzN2a2pfcnlmN0ppS1VJMkl4NzU4emlhNV9NampLS2dUZ000VHBiZVo0WS1mMUxMeEkxdmhpd2JxS1ZjNklmellpcGFmN1E2b3BvQTZVVUNUbkMzRHJ2SG5yZVk9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJvQVVkS3l3dlVWLU05aUxlV2ZYcV9kaW5POVk0U3E3aGhHTXNrZ0hVQWJrTmJuWVlaejZwb3NXdEZvZ2hPVGx2el81dEJwNVVBTmtzanNISFN1eDNQaVFhekpHU3V6SS1ZTDZxU0R0ZVNILXM9
You clearly spent hours documenting too. Simply exceptional and elegant documentation. Everything that needed to be said nothing more nothing less. Thank you.,r/machinelearning,Z0FBQUFBQm0yeGJvQjAyYVJBbm1fTWprelJsSnR6ZHhVTlhRZFRPRkJ6YW5GM2s0Ml9nVC1lUi13UHRfWUVRaVB5QTM1dktmTXNFNlJ1OWxmdWJ6WGxnakRFdkV3YUM4cl9LTTdFOXUzcmtYdHNFbzAtMklJaUk9
"What if you have 2 output heads? One for your unordered logits and another for the predicted priority order? Then fit the priority head to the order. Priority head will need an ordinal loss method rather than multinomial, i think...",r/machinelearning,Z0FBQUFBQm0yeGJvUFhxSzdJODN4VGluam9aUGRGNERmNTRFS2tJVTNPOGhSaWdlNXkzZU1nZElEVGFBeC1VY0Rzd0NnbWNyc2VTRmZnR0UxT1dpSUs5X1E4TkdmQ3lOMFE9PQ==
"Does it work with 
import jax.numpy as np
?",r/machinelearning,Z0FBQUFBQm0yeGJvb2hxQ01JV1E3UmFTQUwtWlNkQ1dNcDJTbVNKNm9QaVRfZ3dHQ0F2ZmFwOTdPRFN1Y1FRYklUdHVnVFZWZHBlU1FFOENCX1hZMy10RWE4SlVVd1BZanAxLWVNSkJfS2wxOXVEczFFLUNzMHc9
If you haven't read it the PAL paper may be a good reference. [Link](https://github.com/tangxyw/RecSysPapers/blob/main/Debias/%5B2019%5D%5BHuawei%5D%5BPAL%5D%20a%20position-bias%20aware%20learning%20framework%20for%20CTR%20prediction%20in%20live%20recommender%20systems.pdf),r/machinelearning,Z0FBQUFBQm0yeGJwX1lxcDNHRVdyUS0zaG4wWHNnUHFhbDZJNzNKX1FVQ3Z1MkdrRWREWGpzX0kzUkU4SVY3NTk5ZG5FWVE1YXFRV05WdU1oQmxGdG1SRkVCUS1OUWZ0b3c9PQ==
"As fellow pruning researcher, we need to stop publishing papers that have undertuned models & only demonstrate results on toy datasets. These results are far from SOTA. 

Why is the ResNet-50 baseline only getting 90% accuracy? Undertuned models are much easier to show that your pruned model performs well. A 5-6% performance drop wouldn’t look flashy for a paper.

Also, pruning results should at least be demonstrated as a Pareto front of sparsity vs. performance. Cherry picking a single point for each method does not demonstrate the strengths and weakness for each. 

The paper should not waste significant time/space on MLPs & LeNets or MNIST, Fashion MNIST, CIFAR-10, etc. These benchmarks are too simple to prove that a pruning algorithm is robust & can achieve high sparsity on hard tasks.

Here is a paper everyone interested in pruning/sparsity/model compression should read first: https://arxiv.org/abs/2302.02596
This highlights the same mistakes that everyone keeps making. Check section 3.10",r/machinelearning,Z0FBQUFBQm0yeGJwUU1RdTJQdGRiOVVER2hBY2FYdFE5bkktSDVpNmF4UER1c3NVTWMwaTFUZmVsWEZ6ZzRYeVBCUHJSdFVkbzhzdDBFYmhiTVFfNl9YaXEtbjdOOEpmRXVvLVB3QzA2cXMtZ3pvcnMzLW5oTDg9
wav2vec2 works on any size input size that will fit into memory. I have used it up to about 2 minutes for classification tasks.,r/machinelearning,Z0FBQUFBQm0yeGJwZ3BzdDNnOXhMMDRkRWdkeUJZVlJFMHE2a2c2RXVud3VpZlRTS2ZqZjZhaEVrRTRvLW54aVdLQlVmZmhoNVJRV3EzMWtMR28zck9SdTJac3pvNEhsVEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwREZyQng0VDdmM0E4RERHUkxhX0gzQU9YT0xoZ1hPRlBHMTVFTDRrYTZPdWI4LTlzX09DMEtqdjl6ZlkyVUd6TGdMY2wyMGpWSDBCZU5jT3hsbWpWYnc9PQ==
"shell\\_gpt now supports autocomplete in bash and zsh, indeed looks mature - this would probably be my choice.",r/machinelearning,Z0FBQUFBQm0yeGJwRlRLYjBEdTNwSVdfU2pVNmphOXdvNURyTUVHT2Z6Mkk4bVJ3Rjh6Z0JWS1QxWGZwbkxIUlJ5UHJEUFRfWDRJTE9vYXVPSVhDeDlJOGd3X3NWeGNXc3c9PQ==
Was BYOL or SimCLR not relevant to general representation learning?,r/machinelearning,Z0FBQUFBQm0yeGJwb2hxUUFoOVRPajAyd2V2ZVJSN3AwZFJZVUtKNVZJSmtRb1ZNZXFjejVNVVZ1VnRwT2dGamJfbDI3Z3BUbXRpN2c1Qm5nSjgzXzNLZDRwamlQQ2RZZHc9PQ==
"contrastive learning transforms the images in a way is helpful for learning images, so it's not generic enough. (e.g. it can't work on sound/tactile/smell/taste)",r/machinelearning,Z0FBQUFBQm0yeGJwcERjZk1qNmR5bi1FRENSTXNXeDJUMGVraTZxcEJkRDdVRVZYU0FrN3Y5c1o0QXZoQjJuR1hRX0s2LTJYd18ybHlNMDVCSjBxOFBTMkhHNTAyQTByVWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwR0NCTlUxWjFtMW8zSEFTSTBWMmtxaW4xTldpVlVzYUVVSHJZSEpWbTlTZjJvUzJmMkdaZUJvb0tyenh2cU1waEFNcTByR3FLZ3ZBZlJFS1JINTJvbEE9PQ==
"Absolutely agree...it will take time to make agents performant, reliable and secure! Some use cases and industries will see much faster adoption than others!",r/machinelearning,Z0FBQUFBQm0yeGJwNFdfbFJFOHVDQlJaMUFUVEJHc3puUmVha0JVYUtTMDY5aVRjN09VQThmSVZmTGQzRUNFUjRKYlFMeVp5YlJsanRZeTBSZEhITHVtVzJnbjk4TlRDNS1fQ0JqYlozTHh5OXZlazB5alljeTQ9
"Okay, that makes sense. How would you envision ideal solution working for you?",r/machinelearning,Z0FBQUFBQm0yeGJwR0RuTXluc0p1bXhOUmhMdEU3QmFyTnhTUi02Z0JmUmpueF81cG9pZ0l1bk9ac1BnaHhNbE5BRjJrenpGTzFZbWRlMmhTNEhIUkpXYW5TRmUxR1NDNmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwM1ZCZVg0bnVybDFXODlBcDAtNHIyTFdLZHRVcTJLaUtkcHplMlpLYkxtcGtHdFk1bm1rcUttdi1HaE1OdlVDSU5jSUxtZTJDV2NBcHh4OFltdmRTelE9PQ==
"Im a bit confused about your code, how much did you change to paste it here.  
If the error is as you mention in the title, i would have a look at your variable prompt\\_template and maybe change the "":"" to an ""="" ?",r/machinelearning,Z0FBQUFBQm0yeGJwTi1kMmN2QnRVTjJrd3JncWlNU09tWXBjTVl4SjYwaFNBaHZzSEJxWWpqdTV2OXFsWjhGLXhyYUhhZ3l2N0RxWHlQVE02UENHSzcxb3Q2ZWVjU25ZOGZmbTBGdzF0MWUxQVBZMkVzQmFHVFE9
"They should be on par, it depends on the implementation itself.",r/machinelearning,Z0FBQUFBQm0yeGJwS0VKekdtdnA3MFduSDBFZDJLZXhMV1JHM1Y0VlByTVY4SGR3MDZJSUNwYVd3cDV2ZDNaSTJFb196c2MyQzRheklEY3pfd0x3NkQyc2dBYjlsbFV5eUE9PQ==
"It might, I haven't tried it yet. If it won't be a hassle, I might be able to get a Jax version up and running.",r/machinelearning,Z0FBQUFBQm0yeGJwcVZGcUw4MEw2dUhXeERwQjNJMTBaQk5HdV9kNVRBWnIwUlhwZElWSm5TRzRsVVZlcDNvaU0xREktZWljYjNhOGlkLWJqRUllQlMtdVBjcDhEQ0RXTmc9PQ==
As an academic I'd take 2nd author on top conf over first author in workshop everyday,r/machinelearning,Z0FBQUFBQm0yeGJwRWNFbExaVDV1NkpuVjdqejJiV2hyc2thMjBadUlCTDk5YmV2aDdRRC1IelFLcE9pUVlPSDU1WG9jOUVOSWZvUExaSnBLU3E4SWVmbElqVGxnOVpSaEE9PQ==
Yehh that was the problem.. I figured it when I got back from washroom.. Thank you tho,r/machinelearning,Z0FBQUFBQm0yeGJwVS11aGhMUHUtUEotNGRZVTUzblVxWjJqQS1uN2swZ081WDZ1REladjJ6Q1ZuWktBcENRdk9IUURQeWpWcmplN0d2N21OSVFsN3NwNkE5cnQyRjFLQi1oeV9CakwtRmR3dmNYZEVrOVdMems9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwSFhld003Z0xVbVNBa2kwMXF4Wk5CdGtMOVFfaUVzQmxCSFVyemNoUnJiUkgwMEU5ODJKMmF6UlFybHRLR0JzRU5fM1NjX25tN29XSGlIaTlzbWY2VGc9PQ==
are you currently working as a mle?,r/machinelearning,Z0FBQUFBQm0yeGJwUzdPT0dpSjBpaGtENDRKc1QzX0pqX0RXb2gzY3ctbUZ2MHJZa3YtVXNYamFPR2lRU0x2MEk2cEwzOVZ0WmE4cmtNUHZkLVVGa2hfTlJ0dEc1cHQ1Vm53c2ZIbEJJRDd6MF9DN1Rnc2pjMU09
"How would a model learn all of the modalities/senses just from one modality/sense? Seems a bit too difficult or even impossible just to use ImageNet as the sole training dataset, right?",r/machinelearning,Z0FBQUFBQm0yeGJwbVAtUUg0X1JMUUVMelFWbVBlWHo3SG00ckNkOWZsd0QxLWpfMnNDMGlCbi1CWm5yOE1YZEUwVV9OT21Gc3ZUeGhBWFp0ejduSTkwQldpa0VxeldvN3c9PQ==
It means literally nothing.,r/machinelearning,Z0FBQUFBQm0yeGJwcHNpTmhMQ0xvb2JsREpmX3BubjFsMTdDc1dYVDI3VThqSkRidFgxbXNMY281c2hmcG1Id3BhR3M1Vl94cUlwRHVwdFRHWE1jZk5ReFRKdjF3Nk5GMEE9PQ==
"I mean the method is not generic enough. For example in my model/method each neuron knows how to train itself based on it's output and inputs only (no need for positive/negative examples), you can see how we can use such techunique to train on other senses?",r/machinelearning,Z0FBQUFBQm0yeGJwVGNKNFJYUUtMX1JVOENkRXBjdjdvX1J6VklhcGJ5UTkyS1l4M2R6bWRfcnFxaGV6OHpiZ09jcUhkMndzbUhPM2F1bDFOZWg4WnlyNWdFbGxCZUhncmc9PQ==
"Out of curiosity,  which provider are you using for testing?",r/machinelearning,Z0FBQUFBQm0yeGJwVDhrUk5MWlJHallDY0R1a2MyS1dJd2o1enkwWTRJZkJGSlZsSHNGYTJ4Um1JSWc0NFN3elJENm84Qy1fcG56RjRkQnd0LWFQVTdXbF8yZ0t4cVNUZnhRU0ZqUm41S0lMaTlhSnhna3A0QlU9
"C++ is a useful tool in the AI/ML domain and is best suited for the construction of resource-intensive algorithms due to its efficiency and performance. Many high-performance libraries, like TensorFlow and Caffe, are written in C++. This is particularly helpful for real-time systems and applications that require the least amount of delay, including financial trading and autonomous vehicles. Python is the recommended language for AI/ML due to its extensive libraries and user-friendliness, while C++ is necessary to optimize programmes that are performance-sensitive. Learning C++ will help you better understand algorithmic implementation and improve your ability to build high-performing AI/ML systems from the bottom up. For more information you can visit The IoT Academy.",r/machinelearning,Z0FBQUFBQm0yeGJweVZsb0dXOG9wUklKdkt4YV92NmE2U2RHcGY5YW03VFhiaWt1RjN1MEU5LTV4eWc2RmJtbW1vOTFyOGNiSGtRY0Yyci1zM0lkOG1PMFY4RU9HeWZId0tEWERobnkybk5iQ29KT1ZiUmxRM3c9
2nd author for a top publication is worth a lot more,r/machinelearning,Z0FBQUFBQm0yeGJwUE5ReHI2cGZJUWpJXzVsakFBTTJhU1N0ajJ0bVJtajBlRUhMNHNxMVFnMkxFc04yMlFWUk9wVlpGV2RYRUdqWFRKb0dfam1YOVpfdGNhSXFfRy1JeW5TZDdDdkpSYU1paVZKZWFJVXhwdUU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwcDI3U1dEZjNIWEtlcm8yX1JfZEZrbDF6ME9pdVBMUWVydVFEWThVYllPUFlQV2F1SEJ0QzNHU2hPclE2UFBPWGRwQ3NzanpGMzVWMXdsd3N5Nzk3R1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwcWVWM1dVQVVaYXpDel91RlVhd2RPWGVtUVRQLVA3Uy0xVDJXdWpKZWNhd3NobU13UXh6bGxvTDVfanlDdWFyM1RNNlpUNEpraGtsTzdRWE9xRU8xZlE9PQ==
"Thanks a lot for taking time responding to my query, can you elaborate on how can I do ""candidate selection"" part?",r/machinelearning,Z0FBQUFBQm0yeGJwSHd0QkRHckdhd3YwUFhPb3JHRGRiOUdjaGdlbkpRMEZ0UTdSUWlEVDlQT3UwdlVmTW53WmFLZEE4b0VoeXJnN2d4d3h4a3lSZFhGQ2Z6dlp1ekhkZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwX0xGQTBhQXlGS0xpZFkwRFBSQW9TNW5aSkR6WVV4Y1F5Y204WVFMV1NRMXVJY2kwM1JLdHZkQ3llbWxoeC1FM3VPS1YxWkdkMm9hbnlHd0ZVdnVEUXc9PQ==
"Really depends on the kind of 2nd author. First authorship is clearly defined while second author can mean almost any level of contribution.
With a first author workshop, you can assume at least it came mostly from them, you can ask them detailed question and expect good answers etc",r/machinelearning,Z0FBQUFBQm0yeGJwS25Nb3ZrVUFWYkpsRGhUbHgycWZSeThPZmNWZldLNzlsRTJPRnhYMGlGc211aVNHUkc4NUd4SXpreUcxZWVlQmdqUE9aU3c4ZEJYTzNKLTBfTHFnMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwQUxHaE9STklock9XQ0pEYU9QTXgwZHZoclc5dGtUang2eC1fcFc0VVRfRFVvcFVKa1Y4Yl9NVHFTUUVlTkRrS2k1Ym9FS19LT1ZyQzRSb0UtcS1rSFE9PQ==
"Try HitPaw Edimakor. A TTS Tool and an AI video editor. You can choose preferred human-like voices according to gender, mood and language.",r/machinelearning,Z0FBQUFBQm0yeGJwdU4xUmNLbkI2ZnBZUC0yVGJSWDdPZVFMT1lNcG5CMjVKVjM2dW8tNWFqTElDMlhZX01sTHRMT1I5b28tYy05UThxT2Uwc05YWHNMRUtNNmsyN0dIWlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwbkF6TDR4cFlSVUxpNFhaSWpHRDNyQTI0R3ZfMGZpVVlwZW9GRDBzWFBnYk1uUHZFcDdBUE5nVDM3aktJd2pvb0RqeEFibWx0RC05YlE5ZmkyNmt6RlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwMjZxNHRpdmI0VzNzNTVKTWZFZWZkWWZQckwzc0dTTGlpRXktbF9YXzlTRmp1d19ocDY3Tm03Mmpmb0NIOWMxS04tajFUZWs1a1hXWEduWUJ6WnpRcHc9PQ==
"If your data isn't too much such as one or two papers, just use OpenAI API with your documents and ask the questions. Otherwise, RAG will be a good choice.",r/machinelearning,Z0FBQUFBQm0yeGJwVE94UGZXVzhUMElZYUVNeXF6cl8tRDgxSXpEb3BaSVVpc1B3UEs0dTY3QmFaR3JzU0lDSk1mQzNFM1RLUEJ1NVB2a3d5STF3dDhsaFBnNWpVcXFTLXZwZm8wZWMxRlZrTXZjLXRwWDJiYU09
"Right, for my specific use case I do not have many papers.  
I am trying to use System and user prompts correctly but I cannot seem to get accurate responses everytime.   
I'll try and be more clear with my prompts.  
Thanks for responding! I'll mention if this approach works for me.",r/machinelearning,Z0FBQUFBQm0yeGJwMWdFckROWFVZdFV4UHBpWld0Nko3c2xrT1RERWFGdW1ZaUg2cjBmZkxDOEN5cm5DQ3d2LU1rUlB1LXpkVmNRQk9uYjVKZzdCdTh4SHgtVFVqUHJrNi1ZaEM5THlncjMxOXg5ZlMxTEV5NGM9
"It's super slow, how did you manage to use it please share",r/machinelearning,Z0FBQUFBQm0yeGJwVFlCb0RVSXNWZDZsaURvSXhHYUNzU0JmSG9LbzF6S0lqdDhQX0g0R09zUThta2pCazRlN2piVzdDZHQ0ZmllckQwc2NMN1JzUHEzLVh3dC1mbFhHVVdxVVdhd0xuVFBaRFFzN3hydkp0VWM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwVkpfMUJCcE1TaDdxeURYWmlON2RuVlhhN0lmaldGNldsZmpmUm9aUVhIdUkwNWlDSmxnLVhOMkFqNG9fbUQ5Q0MyX0taQXpBOWZhWUFPTFRrSVM1WUE9PQ==
"you can learn in a contrastive way with sounds, just as you would with an image, by creating negative pairs through augmentation or other techniques. you could do this with any data, in principle. also your ""can't work on smell/taste..."" part of the speech is just weird. makes one think that you don't really know what you are speaking about",r/machinelearning,Z0FBQUFBQm0yeGJwbmQtTUs1NEYzeklMZEt6NzR4Q2JSSDM2Q2tQamI4QW56eEZkbWJmNDBXaGdOdWNaYmlkYnJUeGpCa0tNY0FkbDFSRUtyOU5BNmZuVUI2Y1dFdEFNZ1VkTWx3d3lpSEhzQjlQUnBNZU1YNFU9
"the point is that not everything is about classification (which what contrastic learning is), to hold a cup (or any other small object) you need 2 senses talking with each other, and thinking about it as classification is useless",r/machinelearning,Z0FBQUFBQm0yeGJwVUhFc3VmOF9Ob01obTBCS0lIRGV5MTM1Z0xLZmk3ak1RalczTTdSZ0pFVF9MM21vMEJKWFZ6cGw3bmdmOWFCb01GZkVNS2ZodThfLTVIckZkV1BiNXc9PQ==
"contrastive learning is not about classification. it's unsupervised, so there's no notion of classes.",r/machinelearning,Z0FBQUFBQm0yeGJwd3U2VDJUUFF5TFFXaVlsTC0wM002VkgwMHZvX1FlTjh1aE4zVERtalhLdHh2Zl9VRjY2dkR5c191VmNHcWNpQXZzZmt6cDROS2hzSUt1Vk03NXFTZWFjYlJzRkVRR1pJanR3YWZoekpsRjA9
"the loss is to have the same representation for some mutations of the data, e.g. the representation won't contain the location of stuff",r/machinelearning,Z0FBQUFBQm0yeGJwYzhOb2VKUGNXMkh3SFF6dGUxeWx0dTFZd2dfck1hV3RrQ0dtV0NyUlBSLWN4T0M4WkFhZDNYcWZHOGR3MnRxXzJlZ1Bsd0lnUXE1WjAxVkNOYkJ5aWc9PQ==
"Read a prompt engineering guide, it takes a while to get in the right cadence. ",r/machinelearning,Z0FBQUFBQm0yeGJwcjFHVkRUd0FzOW4tb0s0UnFZZ181SVNGSFJCYi1neUxYQzJWYU9wLTItQkp1S0xFWkEzUURJdGxieTZMS3JFazA1dE1ieV9zLXJXeWtDVG1QS21sSWhhTC1FUkRRVmx3Q2poaWdOTWJSbUU9
"Not quite.
It's about mapping the topology of semantic spaces itself.

See
[Weston beecraft](https://x.com/westoncb/status/1757910205478703277?s=46)",r/machinelearning,Z0FBQUFBQm0yeGJwQWx3X0t1cE9VSEZWajh1cHFFWW92b2ZuNGpiSF9kY3ZrQThmd3FzVkhxeDNjUDMzVHNnZ0lJeHNMdnJmdWszbUhZRURlUFV1eEZXRGlSLUpkVEg0MFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwUDd1NlJEaUttTy1RNVlZN0V4Y1NTUTdxa29QQVdOUEpweUJuQUdueWdwTDVkR1lsXy1ZaTd5cXdUY01YNVNUTFBlREpWNzJ3SlJMeGJtUG9FNGd0MUE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJwOFBhMDFpVzAyaVoxX2N1RXJXLUoySm5YVFlNZjg3cVJvSkttUVNXWFBBSFlOT2JoMWNLeWVFbjFpY3BRWTE5Q1lubE5YaXdydTJlajZWNDkzUGt2a1N5MXFVQUg5WnpyeXhXUFlfTHVvMTQ9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJwaGtPZFVQTThyTEFFeWYtYlFYcWRxMld2VU9ndzF1dWFqa3pQaDZSa213OHdzVE5TR1RUTFJkSlluY0lwUUEzOWRNczc1YklMV0hmeHotM0hsX19fTU1WZHdkWHpPajRvc2FvMUljWU05TTg9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJwVXZHUVVxaG0ta0tVLVRkMlVnWEo4YU8zVDE5UWJtaldTLXNfZjJweV93blJMODg3U2xLQ1BsYmQ3OTV2RkhVUHF2VnFPLW9hZVZKME5vS3hIeXBJbjduclhfNURpRklKNFYzUmR5MWJsSjQ9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJwYUJSYjlneDRhYUZKOXlHX1FVcE1UWXB3TmFRRE9zZzJGTFZ5VzVQQ2NNcEZneE9LX3dQNzRsMW1mT1dwQkNDTHdwcURlZ04zbHlDYTB1QUw4Y04zN0RtU2lVeFFuNURSSzBrcXdLbTRfUHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwYlJLTzZtNzE1OFg0RWFvbDhwZlNjYVVONnpGRVZLdldiR1VTeEVGQUR1NUZqX29WZWdvM0xqV3Q5SDZFT2I1NzZxdVJtRi1ZMHdOS1JnUFBKOEVWYkE9PQ==
"Since I was extracting only 1 layer, It took me around 1.5 hours. On runpod for A6000, it is around 80 cents per hour. In the blogpost [here](https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream) , they used 25k SAE. I couldn't get the training started for 25k. For 10k to 15k size, it runs without any memory errors.",r/machinelearning,Z0FBQUFBQm0yeGJwdkpHbFg2Zk9sS0pMMVJVdHBXVUZ5ODFxa09WbldVZXR5b0lHbEgydjB3NUluQmIxaDlYWEEydUZ5UkN2cVVpX2haUXZVVHJBZFJMZGNuMFVXUWpQQlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwaUh1eDFrWkhuekFSTVVwancxYU9yNFpoVjdsREY3M3V5eW1lWDM4dVVnVmJaUUVwdFZTU0NXVU1hU0tFRDN6MEYyamJjbDZ6eUxMOVBydWNFTzNweGc9PQ==
I use my own rig. I'm not training LLMs but smaller models using RL (based on u/hardmaru's work).,r/machinelearning,Z0FBQUFBQm0yeGJwamhNS3dwVHZoYUIxQmZCTHZ5NFN2UVM1T3MtQmtmUnBlaG56OWphVDU0RDQxeXZ3ZmhHcGVxRnN6UGNkMU80QmRyaGNwUTVDcUc1LUZlRUI1bmpHeEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwMWp6S2k3c3FOT1A4WWk3dVdLa25XNndiVGJ6dmVOangwM2oybFR1cXpqTGItMGVDdXUtdW5pNW5HenVyV0tTSk5JYkZQaW8wQ29mS1RYZmRhWVRZY3c9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJwTTA5TFVFQ0l2d0xJTTFJdnNHXzIzMDFVM0psUGJwR1lxZnV6LVh2OG9GaUV3bjJWUkJzN3ZwdE90eHVvQnh6YVUwRlo3SmRlVWdTdnFMRU51RXpBVzBPYzdvZDJGczM5Y0tZZkFNMFpESG89
nice!,r/machinelearning,Z0FBQUFBQm0yeGJwa0VTUHZkb2N3RVcwZzJHYWJxRTZCTm9SUElSaHgzVm1LbzA2Q0FMaFY4dVdqemptekRDSmduRzV1UmJPeFV3R1FIUlRoLXNZMXo1RzFJNldIZDQwUkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwczloOU9kd0V4LXAtbzV0UkxscWRwVEdQUURLTkI3bl9SQ2ZYWkJCd0NhTkJublhPM2xKU1ZQbGFJWjF1WVpPZFJpeUJvaUdEeWdwMFRmbWZ2ZVhyZVE9PQ==
I don't want to share my data with e2f ... You should make this voluntary.,r/machinelearning,Z0FBQUFBQm0yeGJwRGlHYTNWeUZuZW5KbGVxZ29VQ1J4SXRKZVlHVndjTG12X0lZbUNDZ3BmRXVsRnFUdlFTWFZZYkZtLThqZDZQMUJtMnIxMnlzSEdIbnppcUlxMEpVNGc9PQ==
And? Who is the winner?,r/machinelearning,Z0FBQUFBQm0yeGJwYWdRNW5ua0w0RmtTc0U5NDhmMlRnU1dYOVZFNS1RZFhnMXV1dGR5SWlUYkF4WDdvX0ZCYTM4Tmp3YzdFWG8tSmFwNUVBaVJWM0RGTEhDVHU4QWFhcUE9PQ==
"The article is a write-up on the ICML'24 paper by Zhai et al.: [Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations](https://arxiv.org/abs/2402.17152). 

Written by Tullie Murrell, with review and edits from Jiaqi Zhai. All figures are from the paper.",r/machinelearning,Z0FBQUFBQm0yeGJwLWc5cUVlY3hGcUVvQTVocWV3U0tYNE9VWXQzRmMtdGlQWG1UZDd2b1ZmT05YWkY3clFSOGFFWTJpcWFxTWRaQUlXbFA1bFhjMVlheW1qMnladl9DMkE9PQ==
^^ Also curious about clinical notes data annotation and use of LLMs for it!,r/machinelearning,Z0FBQUFBQm0yeGJwQ1MzVERTRkNoVXA1ekh3YlRVNlhpaGhTazhxb2ctQl94VUp1cU05c25LQkJubjVxTGNWc1c2bWltSmhLSTlCOVFaaFctd3Qzc083dmItc2JTM3AtY0E9PQ==
"Thanks for the feedback. I'd like to clarify some of the points you bring up:

- We do show pareto fronts of sparsity vs. performance in Figs 2, 5, and 7 for the post training pruning setup.

- We include ResNet50 and a vision transformer, with results on tiny-imagenet to show how BMRS works on larger models and a more challenging dataset. This, in addition to using datasets and models such as MLPs, lenet5, fashion MNIST, CIFAR10, etc. is in line with other work in the Bayesian pruning literature (see e.g. [https://arxiv.org/pdf/2108.11000](https://arxiv.org/pdf/2108.11000), [https://arxiv.org/pdf/2309.12095](https://arxiv.org/pdf/2309.12095), [https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10334001](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10334001) )  

- The tables aren't cherry picking single points as you mention. The tables show the results of continuous pruning: BMRS automatically selects what to prune after each epoch (there is no hand selection or cherry picking of thresholds, it is determined using either eq 8 or 11), prunes those structures, and then training continues. Because the selection is automatic, compression vs. accuracy curves don't make sense in this setup (which is why Figs 2, 5, and 7 show post-training pruning results where we plot compression vs. accuracy, and highlight the pruning threshold automatically determined by BMRS). 

- Additionally, every experiment is run across multiple seeds and means/stddevs are reported

- As for undertuning, we use pretrained models for ResNet50 and ViT and fine-tune on the downstream datasets for cifar10 and tiny-imagenet for 100 epochs. I agree with the point that undertuning could change the compression vs. accuracy characteristics of the method; we can look into if further hyperparameter tuning could yield higher base accuracies for these settings. 

- Finally, the point of the work isn't to achieve SOTA and we don't claim to. The contributions are the derivations and empirical results demonstrating the automatic selection of good pruning thresholds under BMR which maintain accuracy.

I hope this helps clarify some of these points!",r/machinelearning,Z0FBQUFBQm0yeGJwTWQ5VTQwWnY5WTVha1Y1OVl3LTlXUWhtdU5iN1dXOWNrTWhwVHMzQ3B6QnNlSEZ4UGYzOXVUUWZSX1lSWk5aMnZDQ0dMYkgwZUZzMlRLbVppZ05VcGc9PQ==
anyone any updates about this?,r/machinelearning,Z0FBQUFBQm0yeGJwTXZPUUlzRlNReUpkYmRKa2tWeEVXVm1oWEFEQmJQdnk1SlBCZGlHUUhzQTV4d3FFbjd4TktBRVQwVTN2bUVjQk5aY3RfeDFVNFRiN3ZhUXMtT2czVU4zWTkyMXR2N2tkQVU3T2ZhMWRKQUE9
Papers With Code hands down,r/machinelearning,Z0FBQUFBQm0yeGJwV2hUMF91UGJrWUJ1WGFDSkU0NlFHb1lEckJZbmlxUkRQRnF0aU5LT3lrV0Y5Z0txbHMtRnFyWnVIRlFnWktvaHMtX210MlZKUFRxUG5URTNrNjdSbGlmYmt4SWE0aDlEMEZCUk56UFQtOUk9
Imperial is also good right?,r/machinelearning,Z0FBQUFBQm0yeGJwZ0RjVHJUemFZZ0dNOWQ4SkFpTGZJUlZDRGFfZmVoZjFlYlVRcWFyY2VxSGNScGV1YmtId3h3cEpQVjVBcmNPaDYtSW5WbkZlVG43RU04UVJKSU5ESVE9PQ==
Where would you look to check?,r/machinelearning,Z0FBQUFBQm0yeGJwRXpKUV9scmZ2Uk5OMEtJWGszTGs2NkdhamgyMElsQXlITlNlRzVtUjZWSWZUdzc5RC1mM1AzbnNKbVVsWjd3T3ZMQ3JPQk5DdXRhT3ZzMmp3UzV1d18xTENWSmpHbF9qZmtLSmNZTDNBNXc9
"Oh... more personalized ads. Yey! Thats what we were waiting for.

^Right?",r/machinelearning,Z0FBQUFBQm0yeGJwOFkxX21WNHBya01kMXpSZlZoaUVsY1RWZHE4R3JScm9qXzZDd0ltYkdlUGNQblZRdlZIcllQRzZnZDFXUFFST1gwNVNXem1ydVR5UVJHS2hmQUljb2c9PQ==
"I have. The idea applies easily to what's called a ""pointwise loss"", meaning treating each displayed item separately. It's not clear weather this applies correctly to a ""list wise loss"" that takes all items displayed for a given query at once. There aren't two outcomes, but rather K, for K displayed items.",r/machinelearning,Z0FBQUFBQm0yeGJwT0xVUk5qbzJuTmhYbFNBR2N2WGpHNjJrSTltTk5OZVhvem05YXp0X19NMTZucF9rMExybXNITUZkRXdnRHE1MEthZnRXSnR5TDR5bXU5S3otTmc1RWc9PQ==
"I'm convinced Youtubes recommendation algorithm was better 10 years ago. Nowadays I regularly get recommended obscure videos with no views, or if I happen to click on one video, it will start suggesting nothing but related videos. No Youtube, I'm not obsessed with Harry Potter because I watched one video",r/machinelearning,Z0FBQUFBQm0yeGJwY2UzVWRES3BmWmliWDRpOUdRTWwyVm9nRlJPbWo2YTlhQm9YUlBaRUlfMy1YdGg5M0dsTkdkXy1jeF9ka3Y0b1dxeUZ1RV9raWoyOUhWOUtTTzJCMF80ZXlOSGU2d0hiek9CMnc3YXNaQ289
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwM1JWOWliWWV0dHlmb1dXdUxWNmVETV9HdU9fZ3ZWSUQ1NDF2RV9UZUcyZkpJRjJsY1F3TjlmVlp5ZkZXSmRFVkFORThqNDNha3Y4dTFGb1FpbGlMYmc9PQ==
"Thanks, looks cool. How do they differ from one another? How do they compare to traditional static type checks such as mypy?

What I'm looking for right now is a dynamic type checker that  can be given the shape in the type hints. Are you familiar with something like that?",r/machinelearning,Z0FBQUFBQm0yeGJwU2NiOHczWFVhOEgwQ01tU09Va0pDYVBMQmlFUXpzOFpmY1QtT3N0UmxTVENMc3JzSUh1WFhPaWNZNWRkcGp3RWthWVpRR0NxaXNFXzEwdlRCdEctRWc9PQ==
Yes,r/machinelearning,Z0FBQUFBQm0yeGJwc2I3SVJtRlJyb0pIYlU4OW1aZjFqbjlZZFdCLXJDYWdpZDRRT1pCQ2xmNW96YnNaWmZOcVdybWxjbzlaaTNtNUpZSUFhekRTZzhqeXYzamdqZk1tLUp1T1B5NmszWnFsYllTelpWYWMwWms9
Can I dm you?,r/machinelearning,Z0FBQUFBQm0yeGJwNzZ5XzdrZWw3MFhTUXJheGhudVBFY3J4T2VweG1WVUp3SnE0Z09id21hX2lvUlVDWUpodEI0aW15ZGVtbEhlSHZlN296c25wczlaMVJSUVVXVUdXdTZybzVqZWppeF96enpFWC1lcmlkc0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwVllwTW9SMmN6aHFhckJPVVQwblZmS0FxYW9tbk52OVBMaldSUnlDdFVhUkVMaV9PMnRtWUprSl9fQ1dlVUpLMWFmRXlSOWJIZVg4bkVqaHZhX3hPeXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwZ0lzZnRoRkNPbkJsekI4Y0xYblJpTUpGQnRoNmtuZzVqZHMxQ1hXbWYzVWhfVDh0b1dvNWwySWFaa3NmaVpMUUNHdFFoVEo5UDJhdGhuai1KWUw3UlE9PQ==
"Have you tried RAGFlow: [https://github.com/infiniflow/ragflow](https://github.com/infiniflow/ragflow), which is good at text chunking ?",r/machinelearning,Z0FBQUFBQm0yeGJwNjZUUVRPeFVNNDlQOC1YSUlkd2ZHaVhWcUJibjdaYTRVZ001QU5mRlJ5emxfNFpyT3BhaTNXZnhtQ2xGMUpJWmxvSV94X3JrenBqVXItSWJhcWlwbEVhR0VRNGQyUV8tOEFWelVKTEdQdHc9
I would actually pay for top notch movie/series recommendation,r/machinelearning,Z0FBQUFBQm0yeGJwNDhqeDc3NDRxd3FxXzZDMHYzUlM0Y2J0MWM0cHQyQk1xa3hIb1djRTQ4elU5dmFDTmZPMTBpS0tyWmpMWkFVUUlLd0duUGg0THl5ZU4ySTVpaERuQ3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwNFJsUk5CUlc1SW1WaDAzWWI1UTlmSDJ3cklVMXdLSWJSUmNVaWVBbERYeVRLN3NSOFZJVHhmSktUb2h1UEhnV0JJal9RZDFSUVN2cFRRMlhqOVU5Unc9PQ==
"I first saw this from the OpenReview page for my paper, where the PC post saying ""Decision: Accept"" was discreetly changed to ""Decision: Accept (Oral)"" a few days ago. Now you can directly check all oral presentations from the ICML website (both the schedule or orals page, as long as you have an account): [https://icml.cc/virtual/2024/events/oral](https://icml.cc/virtual/2024/events/oral)  
There have been no direct notification/further instructions email yet. These updates all happened within a few days however, so no doubt more will follow.",r/machinelearning,Z0FBQUFBQm0yeGJwQTBDeDh0V19vSVAwb2FfbENieXZOYTNGenpNOEpiWmRfQTJrTDA5Tm9FU3ljMEhRYy15amlFeTFsT0JxaEE3OVN6dWp6TDN3VURhQWd1cjFHNWU2WEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwRXJhSzQ4RGFxMW1KSlZEMUtpdV95N3lkM3RsR29YWF9NOC0tVlZScW9haGRyeDJOdUIzR1dlWWllQUF2Y19pUEI3UkgxQU40RmdqVE9RS2RpMGhNZ0E9PQ==
"honestly lots of good stuff is going on in the biological sciences when it comes to ML and AI but it's deep in the weeds. Not things that get headlines like alphafold. Sometimes its simple & fun like using computer vision to have a microscope center itself around a tardigrade. Most of the times its deep into stats territory and more DS than ML so news doesn't cover it. The standard for the work & publishing is very different too. In bio results have to both theoretical AND physical, which takes much more time (and often money but not always) than the fields we usually pay attention to.",r/machinelearning,Z0FBQUFBQm0yeGJwLUoydXE4OEFpNDhOMmRhQjF0X0h1WVAySURKZHR4MFVsbEpaN2ZQOGRvLTk0Zmp4UDl0d09ueGNKWnA2NGZDT0RZUGppUHQtbE5GMllXa0dEbjdVMFE9PQ==
"I think there will probably be slow diffusion of machine learning in biotech because engineers get treated like second class citizens by doctors and the healthcare companies. This is why all Electronic medical records look like they were built in 1998.

There is also a lot of self-interest, lots of medical professionals dont want to really advance ML/AI because it puts their daily jobs at risk. There is a lot of resistance to change in healthcare, even changing a clinical guideline for doctors will take 10-15 years before 50% of doctors are doing it (e.g. breast cancer screening age changes over time).",r/machinelearning,Z0FBQUFBQm0yeGJwMHoxYkpZTUh3WTN6Sm5tV21melh4N1Q3TnJUQnZlSXptQUJoWWVqYkxYejZhams1bnNPUFRZMXJ3cF90dFBYVHZqcldEc1lldzdlX2ExZ0dRVTUxSjNDMWZjRVJjdExwMTlGaURSSklVYnc9
registered. looking forward to the presentation,r/machinelearning,Z0FBQUFBQm0yeGJwZHpfUmZXWEJwTExyRjhCckdyTWJZZklEbGt1LVJDZGRzM3VoeXhjZTVNMDRUcUJGMHpGcnotLUZVb1pvemJmRHJnRjdiX09kN3ktNkVnOTZGYXI2MWc9PQ==
[https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html](https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html),r/machinelearning,Z0FBQUFBQm0yeGJwYk1NWk1sdG05OVR6cXRlQzZZUm1nMWZuNU9PN2p6bDUzZnYzbVg2bDlRNnNFMXpSQVpPV2xDUjJvYjNodGRTYTVqVjN4eTU1NklSQnlqQ1c5WVZvVWc9PQ==
Certainly!,r/machinelearning,Z0FBQUFBQm0yeGJwYWk0VFV6M1pXRjlaYW1fZ2dTNmZ5V0VzMkFuUGlEUkZqMXdFYzRncVdvQjlnandiMll3azRHbEdEX19rZ2JZQW1mM1J3dHdVWk5kQW9IeUp3MVNfMEw4Sk5yQWFMRUVTdjJmTFcweUxFY0U9
"Well it depends what you expect the AI to do?  
I've been looking into this and there are a few LLMs like you're describing (Evo, Caduceus, AgroNT), and task-specific deep learning projects (https://github.com/Genentech/gReLU, https://github.com/weberlab-hhu/Helixer). My impression is that open source LLMs are at the stage where they're demonstrating that LLMs technically can do the tasks which bioinformatics researchers use standard tools for. A future LLM could either be a tool-use project (GeneGPT, CrisprGPT), compare new proteins to familiar ones ( recent DeepMind paper: [https://www.biorxiv.org/content/10.1101/2024.05.30.596539v1](https://www.biorxiv.org/content/10.1101/2024.05.30.596539v1) ), or maybe take additional steps.

AlphaFold has gotten so far ahead of other approaches to  protein folding that it's truly groundbreaking / landmark point for AI. On UniProt, a proteins database, they always feature a visualization from AlphaFold and embeddings from a proteins model. So those hold value / legitimacy in this space.",r/machinelearning,Z0FBQUFBQm0yeGJwNkRWYzhwZEJGa2hxbE4xUktHcHRKUlFFMTA1X1Q5OTNxcHhnWS1SM3hKSTlJUFEyYWlSWGpkQS1GdkhjR0Z4cFJXaXNmSHJHZUhkczFPNUZFUFBfQXc9PQ==
"Lots of stuff happening on the backend for drug discovery, protein folding is pretty amazing - we predicted that, energy and entropy of biological systems for cancer research. All very technical with 10-20 year timelines tho.

Source: did some biophysics research at uni 15 years ago. Now it’s being marketed as “quantum information science” lol.",r/machinelearning,Z0FBQUFBQm0yeGJwRGdHY3phaDVidkViQ082U3V6ZjdjaU5oOUtIb2pxVnliLUxfUDhlMnd5MjVPRzRQN0hWT1huYkFpTGpYY3VDSVp0WlVFbzdRX3Z4MERVc3ZQMkZiY0E9PQ==
"Yes, it is basically the set of all linguistic data in an EHR. Hospitals still report a lot of information about patients in written notes. As a result, we lose this useful information to analyse and improve healthcare quality. A good example are fall events. Up until recently, hospitals apparently were very bad at tracking which patients encountered an in-hospital fall event (multiple studies showed that a hospital's estimate of these adverse events was approx. 5% to 10% of those that happened in reality). Even though we've known for a long time how falling while being in-patient complicates the treatment, it delays discharge and increases cost. All this time, all information was present in the EHR, just very difficult to accurately extract. 

We've done several attempts at building models that can classify patient notes on whether they describe a fall event or not. While these models performed quite well, they failed often at disambiguating whether a described fall happened during hospitalization or was the cause for it, while it happened somewhere else. As you can expect, most of the fall mentions in clinical notes, are about things that happened to patients outside. Out of the box LLMs, such as GPT, without any finetuning seem to outperform even our annotators when it comes to making this distinction. So, we can use LLMs to evaluate our dataset and to speed up annotation efforts by cross-checking annotations with the LLMs output (in a sense, computing an Inter Annotator Agreement between a human and an LLM). 

I'm very interested in seeing how this way of converting the unstructured EHR data into verifiable structured data can be used for predictive analysis in all of healthcare.",r/machinelearning,Z0FBQUFBQm0yeGJwLVBwRUtoX0pxZTNhRDFIVzJaZndMV2s1VFNwbGZHR1l0YjZ3QVQzNENKbDR1eDFnalU1a2NYclI4WmlXWVIyUk01ZWxoNS1rQ3ZLb3pHTzlXZzdSWEE9PQ==
"It is 2024, and due to cutting edge advancements in ML, YouTube no longer will recommend you nothing but an endless stream of Family Guy clips if you happen to watch a single one on a whim",r/machinelearning,Z0FBQUFBQm0yeGJwZUhnekVPVWphdHlGS25vY3poSGVualpYeDVMcndBLUJIdGJtdFlObEpwMzFHZkYzYTVyd2ZMSVlUUDBkMVdxWTVKZzhGaVgxRlJGUVRSZkptWi1qX3c9PQ==
"You are completely missing the point. What kind of  answer even is this? You whole answers sounds like a Phd student had a choice, which he doesn't and that's the core of the problem.",r/machinelearning,Z0FBQUFBQm0yeGJwN3kzX3dtT1pJaEd4c2picjZvUTlpSnlXMGd2OGdzVGJKZUg1MzRBbjBveEQ5dVgtVkN0RHRxb2d4VndsQ0JETnhGSWhWV29qaFpneTZkZVdvNmJIV2ZVVmllb2Jsd2NrdFY2SUpuV240em89
I think getting into the low level details is a great way of understanding the concepts more deeply. Do it if it interests you!,r/machinelearning,Z0FBQUFBQm0yeGJwVi1JQmtXWHl0b1RueHV0OHFJck1zaEg3dUhWUTBQNU1vUnZGNkRkTzJieVZwWkFpcUtOMEpqNkhGaWJUMGNMd0VsTnhuZ1hrWFQ2Q3ZMTVphX1Z5MVE9PQ==
Great point. Added a callout to the Open-Sora blog in our W&B report.,r/machinelearning,Z0FBQUFBQm0yeGJwVXlCYk9pdWpfdWpNZXpEXzljS0ZyMEFYRDR3T3Fsc3hkR1hLUHpoeGhpWEotY0hWMnhDVVJsNzZRSlB6TnkzakJpOTNBa0RPeUhpVjJyRVNnSFdDR0E9PQ==
Have you explored Bayesian Model Combination for ensemble learning?,r/machinelearning,Z0FBQUFBQm0yeGJwd3pXLTNhekhvbGYtUXY3enNwcXhSZEMwaGZCUTN4cDlaVlFLLWg1dU83b3RQVXZGUHVRR3pKdjdFUU1LVFQ4b3REdG1hRUk5TUFoa19PQmk2ejV3LVEtTDJIcm9LS1FxaC1sQTNMM3JabGc9
"making recommender engines better at predicting user scoring is nice, but a large part of a good engine is recommending novel content that the user might like (i.e taking a risk).  
That requires a lot more than just similar people watch similar content, but an entire switch in sequential recommendation & taste exploration.

I'm really curious whether these kind of algorithms can improve upon that part, rather than just more precision, better novelty.",r/machinelearning,Z0FBQUFBQm0yeGJwRG9oWHUyeElCZW1hU2hjNDNzZW1BMU1kUFA4cFlnM25NQWE4ZEQwRXpIb09sMFZadUdtdGtmZEtnQ3hNa3hISEU4S0poOXIxVUN4YmRLenN1WFZHaWc9PQ==
I guess it depends on what you're trying to achieve. Here's a paper that shows how new types of neurons can be developed in C++ for more accurate and faster time-series neurons: [https://arxiv.org/abs/2207.03577](https://arxiv.org/abs/2207.03577),r/machinelearning,Z0FBQUFBQm0yeGJwTVlsa3BrU3dzdi1PSFRaLUIzUFlPRDd2VUdqd1c5MUVwR2NVMzVMaUJ5M0tvOUE2SkM0cnJzRFBzT3lzTU1MU2pUcUpfS1RfRmdXLUxheTlVRjQxU2c9PQ==
"Old comment, barely recall the context.

No choice for the student to pick a project? Like at all? Where is this stated as being is the case by the OP? They mention stress, limited contribution, and other factors, but being unable to form project ideas is not in the list as far as i see.

I have interacted (worked with, hired, interviewed) with tens of PHD in my life, from UK EU US Swiss Netherlands Germany Greece Italy Singapore and more places. Some have more freedom than others, but i never meet one that was not able to work on their own thing at some point. 

An ML phd will publish multiple times, and in most cases at least some of the publications will be the product of their own ideas. You do have edge cases i guess, and that goes for every job. 

My point is that if you laser-focus on getting into neurips or icml etc then that might not be a pleasant process. Instead you may pick a project that has novelty and you own personal touch. New spin on an old thing, different take on something well established etc. i gave examples.",r/machinelearning,Z0FBQUFBQm0yeGJwV2wyNnJuWThaVHRzT2VxTWRMVVNIcjNZb1FfWEIybmszZ3BNaUMxdVNhS3UxWXd4T1pwY3NVRnllbWJiNGNINzgyU3pMYWZLQmZGSUJRbHdJakVXUVE9PQ==
"Paper Submission Information
Papers may be submitted to the ARR 2024 June cycle. Papers that have received reviews and a meta-review from ARR (whether from the ARR 2024 June cycle or an earlier ARR cycle) may be committed to EMNLP (link to be provided later).

https://2024.emnlp.org/calls/main_conference_papers/",r/machinelearning,Z0FBQUFBQm0yeGJwaUVqdUJRVUV4X0ZoOTRXcktWVEkxbVZnTWpmT1JKSnQwS0xxRVNfUFpVM1FHYVNUazJ0S19sQzRtNjg2Y2hUbDdtMWFyRFp1TzA5SWh3UEx4NUxNNnc9PQ==
"In the past, you could let it run on autoplay and it brings you to interesting videos. Now, it leads to longer videos you played before (study music, background ghibli, lo-fi). I would think it has to do with some of the recent regulations on recommendations?",r/machinelearning,Z0FBQUFBQm0yeGJwWEZIanF5amREalRIYjRPTW5ENXZ5NlJzUzBId043V3dLd2o1SDRGRklVc2pMel9wYWVlYTEtNkcxd1ljcWJpQUVFcGdVQ1dCZ1o3bjVaTU45dThhWGc9PQ==
And splitting the words into a list and running keyword searches is out of the question? There doesn't seem to be any semantic meaning in the terms you gave.,r/machinelearning,Z0FBQUFBQm0yeGJwdjZkelN4b3VCN3NqZ0hRWmFuOHZ2Y1F3LUUxcmRFX3dnTzVwOXFiTl8wb2RaNnd2X3J1a2FkcHp0eGdLM1ZCbEtXLUU0SHJ0RnFHckdRMVpLRGY0a0E9PQ==
"When you said general representation, I thought you meant learning a good encoder. But, you also want a good decoder?",r/machinelearning,Z0FBQUFBQm0yeGJwUm9pNWJwTTRxNVVCRU51cEdpTkJISEFWOXI3aEpmVnlORDBLNmplNEVaaUhWRnMxQWpJdWVOdXRfdkJWRUpSaDNVYWt2d2U5a2JnR05hUjd2R1E3LXc9PQ==
"These questions (at least the samples in Fig. 1) seem really easy. I don't see how these questions are different from usual commonsense QA. I suspect that GPT-4 (or 4 Turbo or 4o) would easily solve pretty much all questions, which is notably left out for evaluation in the paper. Also, human performance of around 90% is alarmingly low (if participants are 1. native english speakers with good levels of education and 2. answering in full attention and carefulness) given that the questions only go up to 8th grade.",r/machinelearning,Z0FBQUFBQm0yeGJwekF6MVRuLUtEdTVFVXNqZ2tsMTktc25OQTZKV0ZoSTN4SDdrM0JQWUtiTnpTWGtIczUwTEdndVlVbW4xLXBZaGR3Yl9yT2JOdFBCTWlKZkQ0YkdYaGc9PQ==
"Correct, I forgot to mention that after analysing the partial dataset, I found out that the query strings I receive might include some typos in it. I even found some strange cases where a particular word is included, but it does not represent the actual query string, seems that people filling up the data dont really care what they end up filling.",r/machinelearning,Z0FBQUFBQm0yeGJwRTQ1WkFrZDJlenlSRjBWU0pVRWJDMVIwaTFLdkQ3S0c4aTNwY3ZyN2pPNGZscmhwak1rblM3U2JiWkkzN0FDaFFuOFcxTEJsci00UEVQTEpCY2Racmc9PQ==
How many weights do you have?,r/machinelearning,Z0FBQUFBQm0yeGJweXp0STQwckhaaE5sZi1xV0haZjV0bnR5X2FSWTVyRXQxY0k2UG0wVVUyVzBVZl9wME5CeC0yQU84aWlFZEdGWDhMN3Bla3IybjkzYWU5Q0tVdl81c0E9PQ==
"Yeah there's practical applications

At least I hope so or I'm out of a job",r/machinelearning,Z0FBQUFBQm0yeGJwX1BUbUNFcWs2NE5VNUZwWnJuUTk5MzZTLWVRMUtwamZYVUJ0UjNGTWl6MXVMSWxHbnZIMEhPSFdOX1I0T1d4ZFJVajdiX01Tc2xQVVFjcmFFTW1mOEJMN1VqZG5ZT1JNTjE0cHJQWnZXeU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwVUdnVXlpM0g4TU5KRU0xVjBDTXNVdGl5YWlnaUFYQ05rRTRZOW5ka0J5czktbzFJVDJjdWZTQ0pKVDA1bjM3VE1PTkNkS3hJQTlWLXdSTzRPQXhoLXc9PQ==
"1) For Pareto fronts, yes you have them for LeNet & and MLP. I don’t see any for ViT/ResNet which should be your main results.

2) Tiny Imagenet is still a toy set. We need to move past classification on toy datasets. Just because previous Bayesian work only used these datasets doesn’t mean that is good/relevant science. How are practitioners supposed to know which method can work best on hard tasks when they only use up to Tiny Imagenet.

3) I’m a little confused about this, if I am a practitioner with a pretrained model and have some specific compute requirements, am I able to prune to that requirement? If I am able to do that, then a Pareto front would make sense. If I’m not able to do that, then that’s missing a major requirement of usability.

4) that’s good, I assumed so.

5) yea, this is very very common in pruning work. This is a big reason the field gets a bad rep. 

6) That’s good

Also, how does this compare to iterative methods? I believe these would blow all the one-shot pruning methods out of the water",r/machinelearning,Z0FBQUFBQm0yeGJwcGFLeTJJUzNaenlsaDZpN2tLeVdXY2puODlFYU4zYjREbW15V0tjbWJ6RE54dEtjbklJUGI1Nkp3cXdsT0RxdEhFTDJDVmtWWndoTHRTcHlFZXoxQkJRb1FQMWdiN1lUb1JnMVpkemZySkE9
Have you tried the vector search and full-text search? It looks you need a powerful database with different indexes. Look at this project: [https://github.com/infiniflow/infinity](https://github.com/infiniflow/infinity),r/machinelearning,Z0FBQUFBQm0yeGJwYkNiZzdfZWQtQ1hRYXprWXFROUZFaDFmTTJ2MWVhRzE5SHRqNW5VMWF1VmlKYmxIalBvdi1RQWpqek5oSzhkaFh3M0JTY0VaUEdnSXFQVXd3ajg1eUE1azNsWUUxLWRGMnBVOXNlVHJERGM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwalRIbTJLbG9hbmhMTDlWMnFpTGFObDBzc2dJUWdTZmR5OW9hck94S0NYeF9Zd0pSR29IREh1UHA5RzdKSHU1R0JFeWlkRjhHdE82ai0wQXZXTmNMQ2c9PQ==
"Thanks for your attention and reply! Actually, we tested the GPT-4 through API during the rebuttal (about Jan 2024). We run the GPT-4 on the social studies part of our dataset. We used the gpt-4-turbo-preview API and obtained 93.7% accuracy. GPT-3.5 obtains ​​91.9% of accuracy and our corresponding SocialAgent version reaches 93.6%. GPT-4 also costs 30 times more compared to that of GPT-3.5. I believe today GPT-4 or GPT-4o can solve almost every question in our dataset, but it can also be used to test some other models. Moreover, we also proposed a multi-agent framework which may be useful. As for human performance, this score of 90 is not the human expert but the score that students in the corresponding grade should achieve. Sorry for the misunderstanding.

Thanks again for your reply! We hope this can resolve your concerns.",r/machinelearning,Z0FBQUFBQm0yeGJwUHlYWlRCN2FuMUJMUG55ZUlXZXpnV2xuaUJKcVlqQ1JZYkhPME00UGwxYXRIbmE3aEhzVjdTbWJEWXBPYzZNZXpvU1prR09TRnhxeDUxa2NXZzBSelE9PQ==
"Hi OP, what do you think is going on (in table 1) with Fash-MNIST on the Lenet-5 model? the decrease in accuracy from compression was much greater than in any other example shown",r/machinelearning,Z0FBQUFBQm0yeGJwcDgtZW5EckcyanRWRkJSQkk4MEptSXRiWGVYbnNiNFRER0NQRHViU3FpSzVXVlBTYklkR0tJOHVISkpGX0RQNzBFX2dBcFRiNlVaYi12Z0RsYWQwYXc9PQ==
"Indeed. But in this case, I first extract the root mean square of an array of 2546 values (for example). I have multiple arrays of size 2456. I tried to calculate it by doing the mean and the standard deviation for multiple RMS values (meaning multiple subarrays of 2456). Or an alternative way would be to first calculate the mean and the standard deviation of the different RMS, by first doing the mean on one RMS, then two, then three (in a way, np.mean(\\[:i\\]) and then comparing to the next RMS. But in both ways I tried, the FPT was still triggered earlier than the one they presented in the paper.",r/machinelearning,Z0FBQUFBQm0yeGJwQlVHamlnTkNvcFhZT1RVTkEwWm5nYTVmdklhbGRGNHQxUE00czdKR1ZTeHZrZE9UMXJtdXVQd2hrc185YTBYWFJXVlMxbXY4U3pQZFVEeEJMWkcwV3c9PQ==
"I've watched trailer for new Alien, and now 1/4 of suggestions are about it.",r/machinelearning,Z0FBQUFBQm0yeGJwVlo0MWFQS0ZjczFOS3o1TkE2ZTEzZ2lfM0Z0ajhBSEI2WkU5MnRwWThyZTlRUWFBd1J5X0RlU2Qxd2FCQms5bmJDSUNJUUxoc3BGZWVLNi1OX1hFQlE9PQ==
I mean from a technical perspective is a good advancement. But in real life talking about RS without taking in account the Multi-stakeholder aspect of industry is very naive.,r/machinelearning,Z0FBQUFBQm0yeGJwV0s4Y3l3TUUwdHd4MThtdEtnT0loS1F4YmlXZHFEVktTTkZfZjVwRVRvamRja05HcEx4aEEyczVaZy1mUnBieW1xLThlbDd4U3ZrUzZsTGQ2bF9TU0E9PQ==
"1. Definitely, I see your point, I think this would be nice to show though I disagree that these would be the main results (and they are quite computationally expensive to acquire).

2. That's fair, I would argue then that there's a need for a standardized benchmark of models and datasets to test sparsification which has these features (larger models, difficult and diverse tasks, distribution shift, etc.). Maybe such a resource exists? Sec. 3.10 of the paper you linked points out the problem but doesn't give recommendations as far as I can see.

3. Definitely; BMRS\\_N (eq 8) provides a good ranking of neurons, so a practitioner could rank based on eq. 8 and prune a certain % of neurons based on this, with the added benefit of knowing that once \\\\Delta F is less than 0, accuracy degradations will start to occur (above 0, we empirically show that accuracy is maintained). BMRS\\_U (eq 11) we show isn't good for ranking for a particular selection of p\\_1, but changing p\\_1 gives control over the compression rate.",r/machinelearning,Z0FBQUFBQm0yeGJwRVZ1dkdlRlZrMWV3YWh1V2ViRzdWWEN4cjdmZ2x3R0lPSWJiWktEOWpXMDBRMExEVEExY0lrSngxLWs5WHQtYklEYjNHaEh1VEtISEFpUk1PMEl5OFE9PQ==
"1) It’s 2024, you can run these on google colab if needed. But let’s be honest, if you’re a researcher you should have at least a 3090 to run all these experiments over a week.

2) that is true it doesn’t give recommendations, but you can at least prune on Imagenet for classification, maybe run object detection/segmentation, or do something in NLP. The idea is you can branch out and show this across domains. For CV, you can run more modern backbones too: ViT/ResNet is a good starter, Swin is common, ConvNeXt would be a good CNN, etc. I’m not saying you have to use these, but there are more modern/SOTA architectures that could be shown.

3) then if you have control over compression, you can easily show Paretos as the main result for ViT / ResNet.",r/machinelearning,Z0FBQUFBQm0yeGJwMm9GNEFaS1Z4M2QtVlp2MUdJX3N5djZXekRJWndqNzRpR0x0T3JFR2RBTlAyWUlGSDZhSmd2Q0t5cC15cGRDdEVxZk42NmxZR0U4WDdCZ3NiTnRBUUM5RU92bzF0cU9UclRiVW1kdWdyU2c9
"If you're talking about the discrepancy between the consumer's goals and what platforms typically do, the recent paper [System-2 Recommenders](https://arxiv.org/pdf/2406.01611) might be of interest.",r/machinelearning,Z0FBQUFBQm0yeGJwVE1nVGZ6NGxTUWZyX1hGaVdHdFpNOTRGdmNqRzd5eld6TkNiVHlvTjFuZVVvV0ZZbDNQVW15empxR1VSZWUxbDB0MzFRVEVXUXBBbER2REVScmZZZVE9PQ==
"Exactly, digital plataforms like Facebook and YouTube are two side markets. So, I don't want to undervalue the work from the authors, but in real life you can't make a RS without taking into account the business needs",r/machinelearning,Z0FBQUFBQm0yeGJwQzlnc2VOQ25USkZmRk5Da1pFcHltZ25iaWxoOUkwMzM0b0VOQ2k3dnlBSTFxX2ZMVGhEM2dPNzF3T0daQkhRbmdKTUNTRWhhVnhWZkR4SkNKT1czWnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwSkJ4WjJ5MklzVGxfM1NmbkZVcG96Vkl1YkpEUUVZd2poNlNNbGkxTVFjWjhLSDRuUmlNS1dJcVVaN1NkSFVQMnktaEk5emR5c3pOeXFoaUdpNWNjclE9PQ==
"I work in neural/neuromotor interfaces, which I reckon is biotech according to your definition. Perhaps you can see some value there.

Personally, I don't see hype in what we're doing.",r/machinelearning,Z0FBQUFBQm0yeGJwSFFHakdOcnJCSU5nNDh2RkxUU2NBeGpPMkEyVnJuZmZydlo3dmNKVnBWdXdqQVFwMk95WThOX2VjOVVYcDBRMTc2T0trYlJCa2JOYmVxR3g0Sm1LYlE9PQ==
Oh I thought you were taking about the python package manager mamba. It’s an alternative to conda.,r/machinelearning,Z0FBQUFBQm0yeGJwYlBEYV9iWEduTUdVQXRidUlZM09BZnVraG9GUzgxbW51a05BSVpqOGdnT0tickFhMWd6UkE1MHRmWWVwM0F3a1FFUERMbHFrcjJLMEtveV84ZzV1WUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJwS09uT1dVSGxiU3BKYlpPeU8wczMtSDdXWFJYcGxld1BJQU80WDI1cFVlc3dSaXFOa0FNeVpRS0ZiVURUMmpBREU0b0tObkJEWEVMTWZsdkFYZ0k2VVE9PQ==
"I think it's import to distinguish between *Large Language Models* and *Transformer Models*, but this paper conflates the two. Large language models are really a method of model training; you can use any model you want for inferring the next token in a sequence, and transformer models just happen to be the most popular method for doing that.

Transformer models by contrast can be used for solving many different problems, and it's not clear to me that they have deficiencies in multistep reasoning when trained in a different context. What if you used a transformer for monte carlo tree search, or for reinforcement learning? People have had a lot of success with multistep reasoning in those contexts.

Indeed I think it's really not obvious that LLMs *should* be capable of robust multistep reasoning at all, irrespective of the model used in implementing them. It could very well be the case that training a model regressively by using a large number of curated examples of multistep reasoning can never be successful, for reasons that have nothing to do with the implementation details of the model.

Edit: also, I think it should go without saying that *deep learning* is also distinct from both transformers and large language models, and that limitations of the latter two do not necessarily imply limitations of the former.",r/machinelearning,Z0FBQUFBQm0yeGJwZHlqNVZRaHdYeV9henNmNG8yd0IxYmFaZ0pwc0k0R0pGUExmVUczVmd0TG1YUnRIX2RZOXFrZmJ1VEdnVXVNY3NiSnRkUUdkZU5KcEFhYmRVenlCSHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bFRpbl9YSWt6UDZLalFFWEtzd3ZBQXBFQV83LUppZDZzN0VOVWhkeHIxVm01U085ODNPYjVlTEkzam93SkFtWmVqcGJFZWVSSkZ6MHcyTmxFWlVLd2c9PQ==
They can optimize for both? I don't see how that's a sticking point.,r/machinelearning,Z0FBQUFBQm0yeGJ2MHlzaVBCWld6R0JCVU01SGRhOEVzel9mWjlLS2ZFM1N1NW0wOWJsYmZaY3phczRjNGg0QlpFQnpxN050cmZFUzlHaEdUR21kUnNBeUNPejlyaW13bVE9PQ==
"I don't know about for image generation specifically, but I think what you're referring to is known more broadly as *neural operators*. Whereas diffusion models learn an approximation of the vector field for a differential equation and then evaluate the time evolution operator by using numerical solutions of that differential equation, you can instead learn the time evolution operator directly using neural operators. VDM looks like it's a special case of this.

I don't know a lot about the benefits of using neural operators, but - if it's possible for a given use case - I think there are good reasons to prefer learning the vector field instead. Training and modeling is probably easier, and the solutions you end up with are probably more accurate.",r/machinelearning,Z0FBQUFBQm0yeGJ2ZkUwdEx0NWJGMm13a3hITE43NHRLY2NoeXBsYnk0Zk1yVk4wbGRaTHhDTjlPZGE0SGpWaVZSWk1SLUVHT1VWOVRqdW1aTW1RbnkxMHNnUjVNTjBkZlE9PQ==
">How do they differ from one another?  

numerary can leverage BearType for more power, BearType focuses on improving type checking & hinting in general, numerary focuses on improving dealing with number via types. numerary leverages BearType, the degree of which can be control via NUMERARY_BEARTYPE

>How do they compare to traditional static type checks such as mypy?

For BearType, I tried to write an answer but I found that I couldn't put it better than how the FAQ at https://beartype.readthedocs.io/en/latest/faq/ details it.

There's also a sort-of-ELI5 here:
https://beartype.readthedocs.io/en/latest/eli5/
And a tl;dr here: https://beartype.readthedocs.io/en/latest/tldr/

>dynamic type checker that can be given the shape in the type hints

I suspect numerary might enable accomplishing accomplish that, sadly lack the time to check. There's also PhantomTypes which can consume numerary, but doubt they'd help here and I g2g now, might write a follow up later

P.S.:

Check out beartype.door.TypeHint.is_bearable()",r/machinelearning,Z0FBQUFBQm0yeGJ2akNtVlBEYk5tLUtZUFJnN29qaU1fN2pIUHhvNllLMkdkajBiOHRaYTNTRmJZR1hzWWgtTUhqSkliRlR6SEJwOVVMUWVIRW84V042NkJOaXRETHVhMmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2dEZkUVdUVHpNT1VWaWlfMWZueExiR3ZNN2ZYMjdMVVlOcE1wWUNSMHBmWTdldzEzMV8zQmdicXBuSlM1MDNGaDRPTXZfR09kMFNHdC1tNmp6Y3Z6TVE9PQ==
Promotion!,r/machinelearning,Z0FBQUFBQm0yeGJ2MkR3M2xKTWwya0stbWUyM2N1NHFvczJkdWYwejhjVk5WbHVWeU4yRVB5TURSczVQMDJjRzB1cGloVTh5Q3FwNFFvMWZnYmhWS09rZGVyeU5tQjBITGE5V3o0cE1iSm1TSnp2aGN5SGNMNjg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2WE9TdGticFdCbDJRRUlGcmxnQTFSZHdEQmlGdmszNllSNnZQd2I5WEt4RmdDcTFGMGlDR3I4aHlMNm91LXdhRlRZb3BBMmdZb3E5aEdYTnZ1VVpjLWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2eUFLOFhGbEVEYXNZZzYzY1A0SFoxYmJZaXRqeTRiZ2RkSVVkTG9GX2Fpb3lHbDNuTHFIVTdPTUhCNzlZb0M2a1N3XzNFYVV0dFNMcmttSmRad0FiUHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2ak1KeXAtVzRKeTRlWlNtS3liNzBDM0lNaG1fZE51MG9OdXNKaXlZSjNCZlJMRHI4WVM3RDh1eFRkQnU0STRsb2YzemhQUkNFU1dfVnYtY21OVUlXT3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2enVDN2c5SlVFMlliTEVRVGMzVzRKanlzVmJZRjR1RXJlTVNEbzlqUzRMNVBnOXdNOGVVeFdrd1ZWaG9wdFZCQ19fekg1TG4zQ1d1SEdvWGFXNk5Gb1E9PQ==
"It is not straightforward to optimize a RS for multiple stakeholders. There is a recent literature in the last years about this issue. 

It doesn't matter if a RS has an incredible ndcg@10 if the business demands an ad as your first recommendation. I believe that the horrible experience we have on the internet is not a technical issue, it's a businesses model issue.",r/machinelearning,Z0FBQUFBQm0yeGJ2NVFuRV9wTmliWWpwcHN4N0FmU01BMW9RdHlOQ1psYWFXMmVVQVJ6TDk2eFZlSnZfZmFsUlRCd1JqMXNpOURFbmRwSDE0LWRVZ0hYR1plZ1dzVFR0MGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2VnlvbDBEcG5hYi1iTUhkdG9wMEZDRUQtbF9XSXBXcnlxVVVoMnlEUktKaV9zcElhbllJdGIzSWlMM01PbzhGWV9SdTE4UFhEZXVVMGU2OUZoRmZHc3c9PQ==
I try to finetune llama3 using transformers and unsloth. I added an evaluation set to the trainer. What is the metric under which the eval loss will be calculated?,r/machinelearning,Z0FBQUFBQm0yeGJ2Z0ZoZjhCX195MjJpNnJzSUk5Zml6VlV1bElUbDUySzdINWZONEpXcFNCQXdCVF9FNEt4RUFoTENyNDBfY1BYYWRxTEZvYm5EMHFVaUN5TFM5d01mQkE9PQ==
"Greetings, fellow gold fish.

Awesome repo.",r/machinelearning,Z0FBQUFBQm0yeGJ2ZDdKQzlwa1JUQWhmQUh5YXQ2dERNLUtxbXF5cWU4NFU4MUdSQ2ZrWk9ac2lkSEhLaUd0ZWNjVmhjVDR6ZlRuV2VzUTAxUGJZOUZ2aWZQM1BkbHo2Ymc9PQ==
Thanks for the reply! I'll definitely look more into neural operators.,r/machinelearning,Z0FBQUFBQm0yeGJ2cHZYTHAzMFNkV2xlZVJfdGJ2dDl5YUhibUU0RkVhZldtUFFPWWY2RGY5U21zZFFkTFZ1SUl3UnFLN3M3OENwano1NmNJWDJhdXpYbUduYlhDV2JkcFRWdWdhREtGdXlzMDl6U2V4aXBhTDA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2VDltdm5fZUt5WWdoOHJCdnpqMnBkYW9XdWJMOTZEbXBjUUNkWjBGTFYtT3VPM0JxTE5aZ0hHaHdsRG15YnU4OVJTX0tfQ2FHRW1od2s0UGNVMGJkVGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2SDFpeXp1ZmttZjdVQnJrbDZIeXNfUTlfTFNuazBPUF9RbFNPN0pnNGZ3X3FrOFdUbWhSdGgtNXlwLUV4S3lvMDBoMGtyTUJMOGZFNGhpZHh2aWU2U0E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ2MXZGN1NaM1hFeHp0UnN4QWR2eXBrUlo2RjZIaVhhVDRjcEpWdzNaWkJOSHp5aVNHMHJUUGhVMFRuVFJIeFJHVkI4TzJ6WGJGVDZ6TDdrNkN2aUJ2Q2JaTS1kbTBQTFFsMlE0dmRfUzB3OVE9
Hey really appreciate the detailed writeup. Unstructured > LLM > features / classification seems very useful for healthcare. Over all text data in EHR / health system that seems like it lead sto a multiplier effect on the visibility into patient outcomes / inpatient statistics / allow for healthcare professionals to see new trendlines or associations between patient data. Are you working as a 3rd party that provides this tech to hospitals or as part of a hospital developing its own tooling?,r/machinelearning,Z0FBQUFBQm0yeGJ2emZsRnRFTUdTbkxwYVROMmpITDh6eFJ2TXNtM09VcXZhWEQ2WlNWSUlCYVlQMmg1TnZHc01wTEdxYlFBYjd4WS1zVmZlOUtuTTdIV21HN25WbXAzd0E9PQ==
"ZLUDA doesn't require or utilize the CUDA SDK in anyway, as far as I can tell, and thus users cannot be held liable for violating the cuda SDK EULA.    Developers that use the SDK to compile, also couldn't be held liable, if their users decided on their own to use ZLUDA as their libcuda implimentation.",r/machinelearning,Z0FBQUFBQm0yeGJ2cHZjbkpkT3o5X2xLa1hjMlVxcml5M0pPNXpyLTk1MXg1N0NqSk1qY0hNVjRYZzNTcS1Fb1VldnF0bWNzOENiS2Q2VVJUNi1xVE5oS0NjakJxbnRhWXc9PQ==
"I think there is a grammatical error in the title ""How to Understand Whole Software Repository?"". I think there should be an article (""a"" or ""the"") before ""Whole"".


I'm also not sure whether questions are very common titles",r/machinelearning,Z0FBQUFBQm0yeGJ2ZmRraUxlME5rNktOdHVsd3R5OWIyaE1wczVDZk5ZcWtQTVNrU085a0w3ZkJxQlVZRV94UXVFX3g5SXpETXRVamdoZkY2TlZ0Y3B3NzJ2cmxfTmtIdFE9PQ==
"There are plenty. Here's a running list of FDA approved ML applications: [https://medicalfuturist.com/fda-approved-ai-based-algorithms/](https://medicalfuturist.com/fda-approved-ai-based-algorithms/) and a paper on applications approved and 510ks: https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00126-7/fulltext

There are CV models in radiology and pathology. 
Models in eeg, ECG, early warning systems
Models in smart watches for atrial fibrillation detection
STT for dictating clinician notes, summarising for patient notes. 
In the drug discovery side you have pre-trained transformers like gena-lm longformer etc doing genetic anomaly detection tasks
There research on RL based treatment for cancer regimens. 

To catch up on what is being done and by who, you can look into conferences like MICCAI, MLHC, CHIL, ML4H (colocated at neurips). You will also find these papers in general venues like neurips, aaai, emnlp, naacl, icml, faact, nature digital medicine, Lancet digital health, NEJM catalyst, etc.",r/machinelearning,Z0FBQUFBQm0yeGJ2RVdkb3l1dnZDQVpJM09zS0ppQVk5MlJXRnlOdXYzRmJvMXZ4NE00ZU82Ry1YNHktOTM5Z1NHcWU1YmJMN2M0ZVFWaUdOeENZYVNfZzZ2TjRmUFpJVEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2a3ZhRFd6aWotc0xDMEp2RHExczZyNERRY3J1My1oelFRZnBGdGItNHBmblJ3dkRldURkNXhZUFpBeWZuemU5SzBlMVluOGJ6SEpvT0hxWnpmSkVvcWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2X0FRbm9iTWRHYjRsMkFDN3REVm90cmItNUxUTTNrMUxVNmhsWWVZV3hYVUFjRVQwdXUtUk1raTM4OVRRTzhSVjJ0aUczRkRiaVJFTTB2amhpaFdlQ0E9PQ==
"Conversely, if you’re not in the industry you don’t realize how oversold “ai” is. Look at alpha fold as an example (no-it hasn't solved protien folding theoretically or 'practically'.  It's accuracy is nowhere near 100 percent, or whatever metric people in media or in society at large use when discussing these when they don't have a background in the field.

Industries like healthcare have been embracing ml for decades. The issue is that many ml approaches don’t have the rigor or out of sample performance (because of issues with validity, among quirks behind their actual mathematical formulations (you'd be surprised how many cutting edge ml models can be outperformed by a pretty simple logistic regression model) behind them in a lot of contexts and this presents challenges in a very practical sense-it's far from just regulatory nonsense. 

If you work in the industry-you've already been doing this in your job.  Hell, if you're in one of the supportive capacities-not working on prognostic modeling but perhaps staffing, budgeting etc etc you're using these too.  In healthcare and healthcare adjacent industries we're not stuck in the 40's and doing regression or whatever people who didn't take a modern stats course in the last forty years think we're doing.  There are very much tools that are relvant for your task and tools that are not.  GLMS are still insanely useful, especially when you need to deal a lot of uncertainty, censoring, or missing data-and especially when your experiment doesn't live in the big data paradigm and doesn't follow some types of functional behavior.  Conversly, applications of nns and the like show up in a lot of imaging and the like.  Again, the toolbox is wide.  

I highly recommend reading prominent bio stats authors like Harrell for a more nuanced take than “oh they just don’t want to give up their jobs”.  NN related models have their niche, but are wholly in appropriate for a large swathe of problems.",r/machinelearning,Z0FBQUFBQm0yeGJ2ZjlmLWVPTFFYaGkzd1dDa0FkVEJUT0laSXdLbXAtV0pnTXFmX2s1QlZTRFBEWnZQVFo4eDZNdUkycWZ6ZWpfOW5ldVRKLUNsLUVuUmRXODVvMmNfZkdCcl82bWZnTndBWFZCZzF0eklGODA9
"I have something that might need your help, look at my post it about LLM's transformer",r/machinelearning,Z0FBQUFBQm0yeGJ2M1VreWIwbGZja2NVbGF3YU1MRU5Qc0RPQzU2ZUtJN21vYllfaGI1MV9TQXEyazlTYjViTVFWV29pQVFtNVNLRlpia25IOVU1S1U3cW5KbGFMQnRmcGQwUHV2ME1Od1lvZ3l3c2taS2l1NFk9
"Unsurprisingly, c suiter with no background has big claims because it’s good for his position in the company. Def riding the alpha fold hype-whose reception is far more tepid in practitioner circles (cnbc ran with the “solved protein folding headline too-that’s not only false but hyperbolic)

Gotta keep the people doing the work scared lol.",r/machinelearning,Z0FBQUFBQm0yeGJ2bHk1V1MtODZpTl91TWRwNUdwRnd1MUJlYzFLNTRwVkQzOUVnVFhkUk1na2pCU2szdlNESDJTc3RoU2dveWx5REJ4WGVSanRmZVM0cUtjTUFrYU5IVG1DWDlLdjQ0UlA3SFBzRGp1TXFsLU09
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2Q2N3Z3hncUhxQzcyNzBacDlod0s2VDV6OUxwUUlmRk45MWdlRTFMUHdLVTctVzI4VmhVMWRXSjhNYjk1bkNmX2FiNnlSVnc5VW43SGtOUDB6UUptMEE9PQ==
You're not understanding me. I'm not saying that ZLUDA end users are at risk. I'm saying the ZLUDA developers themselves are at risk as they have referenced CUDA to build ZLUDA in violation of the CUDA license.,r/machinelearning,Z0FBQUFBQm0yeGJ2OEoyUE9TNTVUNEt3Wlp4UFBkRFQzZGFpQ0FvWUZkZGtBWmtTWjBnLW44dkFEN3d0UzhGOWJyQmZjcXVsZlh1ZXk2bUFWY0h5NFQ0a3d4aUZZRTZocEE9PQ==
"Translation: I didn't actually read the article, but here's my opinion anyway

""The scientists were expected to point out everything wrong with the AI-generated designs, but what they offered in response was a surprise to Lilly executives: ”‘It’s interesting; we hadn’t thought about designing a molecule that way,’” Rau recalled them saying as he related the story, previously unreported, to attendees at last November’s CNBC Technology Executive Council Summit.""",r/machinelearning,Z0FBQUFBQm0yeGJ2ZUNmaWstQ2ZhN1duTDRjWTBybE9sTkNJX3E2MFRVc2JLN0lVU3V4Uk1ndTZqVk0wa0ZoeHVKWGt2SWNzRENraUFyZG1qZXk5N0hSZl9EMWZMaHdHQkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2TFFUQnlKMnZvRGQ5Sl9sS2NKeFo4YWpNcEJUdEI3QTZ3LVNmcDNTVWZrVlEzQUN3V2lrZ3Q3QkxMc1c0dWFzSVNNMEpMRHRsMFlIano0Z0ZJMWt4UHc9PQ==
"I know many places are using all the work being done in CV for cell detection in microscopy for morphology/florescence/count/alive-dead tracking.

There's also a lot of work being done on anomaly/detection and disease classification for things like in-vitro drug testing.",r/machinelearning,Z0FBQUFBQm0yeGJ2eVF1QVlMcFZRQW41b1ZnRDhCdWpaOTFPUmgxZmR5dGxNTThlOW5oWEg1eTg3aXlkYlhiTXYxVC0zQjBpYTJWZDhwR3FRcVJYb1Jvbmotd25mc0FXb3c9PQ==
"You might consider taking the average of the final layer (across the sequence dimension) before applying the softmax. Then train on cross-entropy between this and the single (""majority"") label. This is equivalent to ensemble learning.",r/machinelearning,Z0FBQUFBQm0yeGJ2MXBqa1oxQWVfQ09BLU9DZ1hNanZIWlNZOTBGejgzT3YyU1VpTVF3MGpXdS1JQXI4LUdiMmViSS1nTTNrQUhudjE3X3BUWHU4ZjJoY0NsUXhzRDFGTW1vMnlta1RTUjVfcjJPeVdXcFR6MzQ9
"I work in AI in biotech and I am an ML Engineer with a bio degree.

I've tend to find that except for a few exceptional places, most companies are not leveraging recent advances effectively.

I think biotech and robotics are the next big frontier after the current craze with generative language models.

The problem is, once you find a promising drug candidate using technologies like AlphaFold3 or graph neural networks (or whatever), there's still a 10 year road to actually getting a product to market.

Think about where we will be in 10 years with non-biotech AI! Many folks are predicting truly super human LLM based AGI within 3 years, and honestly in many ways the current state-of-the-art is already super human with language models.

So the barrier to biotech advancing *with* *AI* is really going to be a matter of regulation and not necessarily technology.",r/machinelearning,Z0FBQUFBQm0yeGJ2Q3ZyR0xPdDVMQ1BzdG9yUUx0ZFAyQjh1Z21XOS1HN2tQbjRvS2xyUWVxSkdqTHE0b0FBSy1OaVNCSHZOUFNlZkF4LWxQUmJLaEpEWHpkdldDSU1BdHc9PQ==
"translation: I am not a practitioner either but I have an opinion because i read one from other people who are also not practitioners.

CNBC, which already misinterpreted performance and scope of alphafold (go check out the practitioner opinions on that one) quotes someone who is also not a practitioner, but is a c suiter far removed from the actual process.  Hate to break it to you; but this is an issue with reporting on the sciences that has been around for decades",r/machinelearning,Z0FBQUFBQm0yeGJ2SUhONktXQWpFckZsU3dXZ0JlY1BqRVJJZUlsV0dGVEFLbkJFeXZ4S2l3ME5sV3ZtSkhnQ1VkRjUyZjVWZjYxdzJKV2NuYWdxVHNsWEhpWlJpRG5obVRPb1N4U3hZLUdPVVJNRXRuejY0WnM9
"Yea my bad, you're totally right!! AI is useless and doesn't have any application in bio or pharma. I'll just go back to being unemployed and not knowing anything about AI now. Thanks for setting me straight bud!! lol",r/machinelearning,Z0FBQUFBQm0yeGJ2S3hWTHN2b0lfUExfc0FzT3lHNldxak9jRlpFTzktNFdEQjhJckNIM3l1Z0VlNGp5LW95Vy1nejBpZ2UzUFF5RDJUTU84eW5jWEpKb0ZmTWx5YndVcHc9PQ==
"didn't say that.

take it from a practitioner; we've been using ml for decades.  It's currently being rebranded as ai because when we rebranded it from stats it's started losing that marketing appeal.  Sorry for, you know, bringing the practitioner opnion into a sub that is basically a softer version of r/singularity now thanks to the influx of people who don't have any experience in the field.",r/machinelearning,Z0FBQUFBQm0yeGJ2aVBqY29nVzBKTTVfWW5pZGptUU53RE13TjZZODZZM18zYnM2NHVoX3Y3bUhuLXlHcHc1N2Q5VjBMLWRvdTc2Rjc2cVJjUnJ0S3RKSGhhOWVlZHY5TUcwMjdMajQwa2Q1d3p6RFZ5MjZPOUE9
"as with all things currently motivated by our understanding of stats (and cognition somewhat, i mention this to reduce anthropomorphization; you'd be hard pressed to find anyone in CogSci that thinks these models 'think' as we do ) there are limitations to every model and approach.  ML approaches have their place in HC, and have seen mixed success depending on their use case for the better part of 30 years (like all statistical models).

Ai, or whatever we're branding ml to now also has it's uses, but unlike boring prognostic models we're using it to create something we can project human  emotions and feelings on-so the hype is gonna be there no matter how unhuman it actually is (which is very highly unlike us).  People like to anthropomorphize and extrapolate.

sadly, a lot of people on this sub-probably who recently joined after openai hit the news don't seem to understand that using statistical models has been the aim of HC since the 60's 70's lol.  Of course there was desire to use it widescale before then too; but practical computing ya know?",r/machinelearning,Z0FBQUFBQm0yeGJ2RTZFR0ZoLWl6S2JucGJybnJTcGpzcF9TZUFsOEVKbm43ZlRIdTFKakNUakd1S1VfNFJoV3laczN4NDZ4WXl3dXRSR296T1F4RWZDSW4wY0NCODF4VjhRZV9VbHRtT3B3bFJ3dEo1STlOb289
"They could drag a developer to court, but they'd likely never win that case, because they'd have to show the developer didn't just reverse engineer compiled binaries, read public docs, and review the cuda-nvcc source code.  There is no reason they couldn't impliment libcuda, without requiring the CUDA SDK.",r/machinelearning,Z0FBQUFBQm0yeGJ2eTZlQVZ4X2ZVcmtGXzlBU3pEalRjNTBWVEFwMnFJSWotRjZCOWxET3ZqWVc3alFvYnVtSVYteERXT0kxaXlpVHJQZFJwNHdjSkpiNWxLME5QR1RfNHc9PQ==
"To my understanding, any work in the line of architecture modification will need to go for (at least) one of two routes to validately showcase its capability: a) train-from-scratch and compare to *fully* open-sourced transformer baselines (i.e., you can find training code, data, and even the ordering of them); for this, the baselines are often along the lines of Pythia, OpenLlama, LLM360, etc. b) somehow adopt the weight of a pretrained LLM to your new architecture and fine-tune it. 

The tasks you are after are often PPL or accruracy-like metrics on the pretrained corpus, wikidata, c4, HellaSwag, MMLU, BBH, HumanEval, GSM8k, etc. I am not familiar with the n-token prediction accuracy (?) you are showing here, and if my exposure is right, this is likely not the norm for LLM evaluation.

I think it is very unlikely you'd have something good with O(2n) but hey, nothing wrong with hacking around — good luck and have fun!",r/machinelearning,Z0FBQUFBQm0yeGJ2QzVEeVF4T2pjZTVnYzFnQVAzSVNObGNxaWR6RWdVWFczT2NpMjhJOEdBZ2Y5bTZKYTlreU0zQ0JqcE5vVEVYdHZWTWljbk9BYU9IdS1ZWURxT0NKQkE9PQ==
"I just want a system that listens to me: ""My little cousin took my phone and watched a bunch of roblox videos, please disregard anything from the past 8 hours"" or ""I'm falling into a rabbithole with these movie summary videos, can you please show me more high quality science videos that are 30 minutes or longer in length and come from channels with more than 1M subs?""",r/machinelearning,Z0FBQUFBQm0yeGJ2aDFlM2pqWnpic0lGamxKQy1iVW5QRTlsM0g4bDA5MTQwUmxpOU1naThaWVdmcXlpd2c5ZTByZmNqM3hMS0Rlb0JwUU1Oc3JNcXN4UlV1cmZyM3pkV1E9PQ==
"Harrell, Gelman, Cinelli, PIantadosi, Mcelreath are names across a variety of fields but have strong interdisciplinary fundamentals that i feel every ml practitioner should be aware of.  All of them provide a lot of free/low cost materials and talk a ton. 

Rubin too because I mean...dude has touched everything from causality to imputation to efficiency etc etc.",r/machinelearning,Z0FBQUFBQm0yeGJ2b29MQ3BZdXNHcUFNTnppLXl3OEtUWUNDTE5wS1ZiRjU2SGp5WmRQVGktakpPbmVRWmFlZVJHdE1xLWdNakNtc2RSVEduSG1LOHV4WUhaQmw2LXo4Nko3dHVNYk5nSGpRQWN4S0ZsZ1NXQ2s9
"This is more a geometric computer vision problem rather than ML...

Go check stuff about triangulation or Structure from Motion",r/machinelearning,Z0FBQUFBQm0yeGJ2NnlsZ1ZhWWxzcWt6cTRJakt4Tmd4SUpVQkl4Q0lkNXhDd3FuSU9MREhmQXRENzNxRjlnejN6cjdGMXllMUt4RDlGcThXSkk0TGhBaFZXekdRM0U5Unc9PQ==
Good job! I think this research paper is relevant: https://arxiv.org/abs/2402.05120,r/machinelearning,Z0FBQUFBQm0yeGJ2cV9NVmswRU5KdUhUUzRObmRfS2NWcURNcUJJUjhSX215X25zMHZ3clpySUE5NGliSWEyTnQwZkVBZkR0ZGhQYjVlM3RwdnR4cWpEVWk5NVNTVlBLVlE9PQ==
"nth token prediction means that we feed the model all 0 to n-1 token and then expect it to output the nth token . eg,  for 9th token prediction, we feed the model first 8 token of the example or input and try to predictive the next token or the 9th token .this arise due to it was making my work easy else it could normally.  

 I want to train those model  at bigger scale but I don't hardware or money to afford cloud  computing services  and google colab or Kaggle is not that enough .

I am willing you to explain the technology if you want .

I don't what is best right now .

I am really gratefully for your help.",r/machinelearning,Z0FBQUFBQm0yeGJ2dnZLb2toY2R2a2g2a2dUdC1nM0FMblR0RmNzTDZXZXJtaUZDSXJLdDlXbDAwSHhUTjBMY0JYcjlzMW1QTFNQNDdRRnNnZnIxdjAyblBqckw3TVFLWUstb3FiejY2N3FmaEw3NXZsMF9IanM9
"I don't know where you made your Phd, if any but as a Phd student you are definitely not the one who picks his projects, at least in the most cases. Maybe some millionaire students at Harward or wherever. Once you have started your Phd program, you usually support your supervisor in his research. That's it.",r/machinelearning,Z0FBQUFBQm0yeGJ2eTViUHEtTzROOU56OGxCYmdYUlBVcGo1MlVwbEJtaGltZnVWZmtucXZabUkySERVOFFORUdERnJLeWZkR1BZSzRrSndkb3hCWE9uZEl4RzFuU0VlWGRlWlRQMk55Y2p6TXNmQ19Md2kwZkU9
biotech is basically like casino,r/machinelearning,Z0FBQUFBQm0yeGJ2R1I2alVaN0ZGR2RoR295a3BLVHpfMzNSeGRXWFVIRFJsUUd2Y0dwUjhvZmg4VXZXUTFmTHZldUN6LUo1WFRSc2xaaFVqV2dJcWdReU0tMmFfMHJhMUE9PQ==
"We need more information about the relative positions of the cameras, because even with three cameras it's still possible that you can't recreate anything if the visual overlap isn't enough.",r/machinelearning,Z0FBQUFBQm0yeGJ2WnFVQUxzOWI0azhLWThMTVJJRHJRaXVSeXIxMjFVQkpmdTJ6a0Qzb1AtblNIVmFLLWg1UmtlTGdPN2RacTNLenZrU0hsVnB5dlhnU2lTcDBFbmNUbmJVcWJXclhNWF9obG91Mm8tMkVhcHM9
"We need more information about the relative positions of the cameras, because even with three cameras it's still possible that you can't recreate anything if the visual overlap isn't enough.",r/machinelearning,Z0FBQUFBQm0yeGJ2MVVybEpXc1V1Z1pLZktDMldNczJCMUFHZENabTJnQmNKaXN6aGtSZ1o0S0lLSUwxWTFRM1RHOUJKZmpTd21WYkdpMVBtN2RqZkVoUE9sRlFHQ25oWFptc1hSdW1Kbnd0cENVcUVOaEt3TGc9
Not an ML problem per say but you'd also need to provide more information about the relative orientations of the cameras as even with three cameras it's possible that you can't recreate anything if the visual overlap isn't appropriate.,r/machinelearning,Z0FBQUFBQm0yeGJ2RTNITUxKOHlnWDNya2RWelljM3lId25NZ2FmajFGajd1a2o2UC10aUtDRXNpcVExQW4yazJyc1p3S3JNSDBfTEI3UWh5Y0hlemlLcjRTWFBCdmZrQ3lCV2tnU2w3ci1sSU9ELWZobV8wa2s9
"Yeah no you are wrong. You just had sad experiences, sorry. 

I did ETH Zurich. Like 3 friends of mine from uni supervise phds currently. Kings College London, Essex business school, SUTD Shenzhen - just some examples.",r/machinelearning,Z0FBQUFBQm0yeGJ2RWdaSWREcHJId0h4Sk4yOGFrTm9MYlFpVlVMbVZfUVd2QkZheXFMTG5VTEpRRm5CdlJaMkJQdHJqdUtoSU1Rb1NOSXFvdEtzQ0g4aGxYTXpBYTBrMnc9PQ==
"Very good work.

Minor suggestion: try adding a time variable to your visualizations, [like this](https://www.reddit.com/r/LocalLLaMA/comments/1c33agw/todays_open_source_models_beat_closed_source/).",r/machinelearning,Z0FBQUFBQm0yeGJ2TUNvRmgwcjc0MklSSy0wcmx3NUp5TklnZnBvOXFUZVF5bS1WOThWbUJQZzJMVHB3c3JrdXdxSEVNNTI0ZFNYYk9PY0hyaUtEWUlZc3ZmdlEwalZ4OWc9PQ==
You could also try an introductory AI course such as the Kickstart Program at the appliedAI Institute in Germany. It's online and in English. It's combined with internships.,r/machinelearning,Z0FBQUFBQm0yeGJ2YzJKN044dFp3QVVTVXRsM3JwYnpUaDNsOXFDX1BMLXoyZ0FHMGZiQkhuYkQwTk1mdGdDZXdFaEFwS191emExSy1NbmpXSF9UVDBqQ2kyMkNZTzh2d2xuNU5oTlh5LUdFOUNhQndRa25TN1U9
"They'd get an injunction to stop distributing it more than seeking damages. They could get a preliminary injunction that would probably kill the project in the cradle fairly easily because the developers wouldn't be able to afford to fight it. This thread is 3 months old and we're already going round and round on the same speculative issues, so I don't know that we're getting anywhere here. Thanks for sharing your opinion!",r/machinelearning,Z0FBQUFBQm0yeGJ2WWUwV0ZsWXJuT2dFQzBqRTNRaXhBN19ULUpUNUlKbVFZOVdNU2pBNkx0dUNnbEw0LW9UTkZUNWZYVGRCMlFFeW5RZFA5bXBuUUJqemJDTk90RE8wbHc9PQ==
"Oh, thanks a lot for the links - exatly what's needed for me to dive deeper!",r/machinelearning,Z0FBQUFBQm0yeGJ2OFlKcjdvZXRzU1ZLRVJXZHE1ZkRscGVkcWs1Y29ia2JpUzVqZS1sWmtfVmw0S3EwMGZZd3BFTExhdkN1N3ZLOGxrRlZtb05CQWl3ZHJpZ0h1dklGeHc9PQ==
Okay.,r/machinelearning,Z0FBQUFBQm0yeGJ2dmpIZmdUUGtvajQ1alFJT3Y4eGQ4UzRibkhNYnNEWUhEUzlUWjJuXzFPRnU3MGpvQU9qOG5ia2VRN2Q3UTY4Unpod0NCY0oyeUl1UW9pQVZWQWFGcEh0NkgyNnFsYVZubzhIZFlMeVFVejA9
Why did you make this comment three times?,r/machinelearning,Z0FBQUFBQm0yeGJ2T2VOWXVjSEx1cVptSEt4QjZBTXh6YVZCMTlyTUl5LVVxMHpfMm03ZUM5SVN0eW93cUVOcDU5NXRJVGVtZjFqdElJTEJsdzJtS1o1WFFUR2d3RkVTdEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2dkpKUEM1YVFJQ0lVenFIU1VIME0xZVBSdU1NSUtlYlMwelU4SW02YWw1QjRSUWZlM1ZVaF9GOXVTSW04ZTF6U0F6dkI3bnY3Y296czYtenQ0VTJTMnc9PQ==
"While marketing does play a role in the popularity of terms, the shift from statistics to machine learning and then to AI also corresponds to genuine technological advancements and new applications that were not possible with traditional statistical methods alone. ML is merely a subset of AI. Recent breakthroughs in natural language processing (NLP), computer vision (CV), and large language models (LLMs) have revolutionized what we can do with AI. These advancements, driven by powerful hardware and vast data, have only been possible in the last decade. So, while the concepts have been around for a while, the practical, transformative applications we see today are pretty new.",r/machinelearning,Z0FBQUFBQm0yeGJ2cGtoWTV4Nk1WZkpuSE9pVW9rUHdicll3ZW9aS3RrVU1zMlZVUF90OVhXQi1nTl9hOEFQbHhpUTlpUDZhZV9DdWpNaEotOXljT0xMRnZVOE5GY2lLUFE9PQ==
Is there a coreML version of the LCM version by any chance?,r/machinelearning,Z0FBQUFBQm0yeGJ2QWthWkpJc3kxZGNxTXpVQm1QLWs1U3ZkY09pcjZJaGFFWlBzbGY4c1ExM3I4S0U5T3l6cTM0M3hielhoODlFcEhkVlB5TE1xV0ltcXFFbnZTeTRDX1E9PQ==
thanks chat gpt for giving me the write up trained on the text of people who don't really understand that modern statistics is what these models use lol.,r/machinelearning,Z0FBQUFBQm0yeGJ2V3RseURHMHFIYk9nVjNLeVFsamhVRWVTdDZGaE1IWlRDN0p5dVEwWmVuczBYb25zVnpaNUozOUU0VktaNVNLYUJqMHFnRkhPd0hmNENoOHRWelVORExXeThrZHJQd0pUNGJGdHlnRmkwZlk9
"The regulation not innovation commentary truly misses the mark.

The reason why some ml models are not as popular is due to real constraints on the type of data in biostats, the problem, and the stuff that is associated on the patient health care outcomes side.  The dirty truth is that regulatory bodies tend to err on a side of robustness that most ml publications can't hold themselves too.  Replication in ML journals is terrible-which is surprising considering how many people here diminish the worth of other fields.

Biostatistics has embraced ml methods (or ai, whichever you want to call it even though the only difference is marketing) for certain use cases, as expected.  However, there's a rich history of over promise and under deliver from ml in say, prognostic modeling.  Even alpha fold's success is much tamer than the headlines will show.

I'm not sure how we'll get super human agi from llms, especially in this space when the training data is polluted with terrible modeling practices.",r/machinelearning,Z0FBQUFBQm0yeGJ2NXNSTmg3T08wdTZBNEhNd2JTd2Jqc2E0M2J6eTlHR2lQVW9OOEswNjhpUFFuVjVzS1pCNjV1NE1mblNqQllnaXIzdjdsTFd2VE95MzVXdm1uemg0aHNrV1lacGpwX2R0WHo2ZGtmMXZ0YzQ9
"Your ad hom response and lack of any rebuttal to the actual points made tell me everything I need to know. 

>people who don't really understand

Yea, no one but you truly understands this technology, oh great and wise ML PRACTITIONER!!",r/machinelearning,Z0FBQUFBQm0yeGJ2SDN0eHNhN1NYTm04Z2lOVnpNd0d2TzYwY3pJNDhpMkZlVkZ0alI3RENFXzdIMmJxanBJQ0V2aklVWld5ZHJrU01YendtZFFTTTZvM1h6bGpJTmJJQWc9PQ==
"There’s a ton of hype in industry. My last company (startup) wanted to say we were using AI in some of our processes to attract more investors. They didn’t know what counted as AI or not. I informed them that several of our projects did use small amounts of AI, like computer vision on images of cells and manufacturing predictions. They liked that answer but did not commit any more resources to developing our AI initiatives. For some, it’s just a buzzword. For others, they actually care to develop their own resources/IP.",r/machinelearning,Z0FBQUFBQm0yeGJ2Z2NDR1VnaUt6VE9ncDZVcnNXelltZUl3d0xQVUpPeWU5dHN0SUNGNkN2Xzg3UGFDOUFLcVRMbGxQbHJnWDdtSnhla1MxMVB5YlZDbDJVTDAwYTdKVWc9PQ==
"if you think modern statistical theory isn't being leveraged here than you're more of a novice than i originally thought.  you can't say that stats evolved into ml and then ai.  Statisticians gave us things like nns and trees decades ago.  Most statisticians might not utilize them and most research in this space hasn't traditionally focused on it here because more general theoretical results take up most of their focus; but these approaches leverage those findings.  

Stats didn't end at linear regression lol.  And hardly anyone in ml wants to tackle things like uncertainty propagation in ml models because...well that's boring leave it to the statisticians we like to dunk on when it's convenient.

Statistics (or more appropriately, statistical learning) is the big umbrella ml and ai live under.",r/machinelearning,Z0FBQUFBQm0yeGJ2TFRkYmNVMEJ1YnE1SEYxTEhiRlFBaWdVWkhibEd6cllERmhYTjBDa0ZzTmQyUnJIM0ZrRkE1aWJnUXBKMTVsMG02OVJObVpvcno5enZOYi10SFFCWENTb0tUZjVIUEhOU3JMNmhrb0hZbzg9
Accidentally ruining your feed is a real struggle,r/machinelearning,Z0FBQUFBQm0yeGJ2RWhGdmN6cVRFbEdBdW1ibmd4VGJybWFLUjRsM01KT0pLTDVCeTIzN3lORVlsX0hnYk54anRZYWVvaHZfeXJwbFVwdU4zQTMzSmx1Vng5VXU5WEpYRGtqTmFieHZkVDJCT2M4ZVh1U09YaW89
"I always found it funny that alpha fold got so much attention, despite the fact that among practitioner circles it's far less lauded and there are open source models that are also pretty good (nature is under flak for publishing af3 btw).  I mean google has a helluva marketing team, and science reporting is far from good here.

As you mentioned, most of the work gets lost in the weeds but there is more of a stats flair and level of rigor that makes headline grabbing models way tougher to sell and replicate.  (Propagation of uncertainty in healthcare outcomes, for instance is of major concern.  Most ML researchers don't care about this-they'd rather leave that up to the statisticians, and the good opl bayesians have been looking at this for awhile now for say.....nns)

Also yeah; way to address the elephant in the room.  ML journals kinda have a bad rap rn as far as reproducibility and theoretical justification goes.",r/machinelearning,Z0FBQUFBQm0yeGJ2OV9HSHY0VDZOM3ZVcjloT1NuTUUzZ05scFJnUnEwOHFWdjFLUUlkdFpWM0dvVTNlczlSLVZWdWFxQVEybG01Yk52VndlSWt0SFdWTU9mdko5WmptR1BEcWNlakFNMkhZWkJkd1EzOGRZeEk9
"Replication might be an issue with ML publications, but it's also (even more severely so) an issue with biomedical publications.

To say that the ML reproducibility issue is more severe than the biomedical reproducibility issue would be a laughable statement.

Right now, any individual can train their own GPT-2 model on the cloud for less than $50 of compute. Remember, this was state-of-the-art model in 2019 which was only 5 years ago. Try doing that with any biomedical publication from 2019!

Another example...

AlexNet was published in 2012... the same year that CRISPR-Cas9 came out. Within an 11 year period, we saw the rise and fall of GANs, the invention of transformers in 2017, BERT, AlphaFold, AlphaGo, the founding of Deepmind, the founding of OpenAI, GPT-1 through 4. Every single gaming gpu made by NVIDIA now does frame generation, so every newly released commercial videogame now uses deep learning. If you go to Walmart today, the security cameras all run YOLO image segmentation models to detect your face. Even archaeology has been revolutionized when you look at things like the unraveling of the Herculaneum Papyri (which leveraged a technique call TimesFormers)

So basically within a decade, ML saw a many thousands fold increase in both advancement and ubiquity to the extent that virtually every new phone and computer today is released with specialized tensor multiplication hardware. At the same time virtually every major model from prior to 2020 can be trained by just about any schmuck.

CRISPR-Cas9 on the other hand... the first commercial therapeutic released for treating humans utilizing this technology came out in 2023! That's 11 years....

What will transformer based ML/AI look like in 11 years? Probably unrecognizable. What will biotechnology look like in 11 years? Probably more or less the same. The first drugs developed using in silico ML technologies might be on the verge of FDA approval around that time.",r/machinelearning,Z0FBQUFBQm0yeGJ2SHlLQjUzS2JVbGZES2FnSzREWExKMXFiTG1FNTQ4S0EzZWpyVVBmQmxRWnJSR0ppQVNyaVNWS2E0RlE5VzQxcTBGVG1BVDBJcDFubEFlbktEM0E3NEE9PQ==
"No, it's really not.  Look at a typical SAP plan that needs to be submitted for publication in your typical bio stats journal.  ML publication requirements don't require anywhere near this.  ML publications don't focus on things like error propagation, which are stupid important in a healthcare setting.  It's more or less here's some empirical results devoid of mathematical justification, and zero discussion of threats to internal or external validity.  You won't find inclusion exclusion criteria or appeals to the scientific theory in defining your population.  You won't read a page on why this boring estimator was chosen, or how multiple endpoints are dealt with etc etc.   The truth is that there's far more legwork done in a clinical publication, and bio stats at large.

Sure, we see progress in some areas.  However; the dirty secret is that progress is far more s shaped.  Those facial recognition checkout systems you mentioned?  Amazon and the like are ditching extremely high profile systems quietly.  Alphafold?  Can be useful, but certainly didn't solve protein solving.  It's accuracy is nowhere near 100 percent(trey 40-80 percent within certain applications-and again there is no generative model that is interoperable symbolically associated with it) .  Most of these advancements come in a regime that is wholly unsuited for the types of modeling (old stats methods still outperform what a lot of people would call sota ml ones in many prognostic examples).  Most of the applications you listed are much lower on the risk scale.

We're still seeing empirical results match theoretical ones wrt to scaling laws, and we don't have a better understanding of the theoretical generalization of these models because they exist in the highly over parameterized regime.  Extrapolation is a dangerous game; see the last sixty years of ai prediction.  We have certainly gobbled up a lot of the 'easier, low hanging fruit' challenge  that does bring value.",r/machinelearning,Z0FBQUFBQm0yeGJ2QkRUSHNMejlmVHZKa1ZjbThyaUlUYVBySHVGUWtybkFaaHpDb3d6NTdSd2gxVVpJUi1BdHpQQjVyX3k2eXA5YmNHMlJ4Wks4amdLTFVjWERBbWdlUTNqdVprcXZSMGhIM2dsU1ZhQy1rMWM9
Seems like consensus now is that 4o is worse than 4 turbo?,r/machinelearning,Z0FBQUFBQm0yeGJ2ZTBFdy1vUDM5eVZzTmNiYWk0ZnVVVFRJeTRnbmpjMjhCVE5zQkNPY3ZzYTZxbGtZYTFMWlBkb0xoQ2drRklqQUdsc0t0NThnOXhmR2U2bVptZlBxVkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2THdXVXRuZkJ3Q1VpVVVOeW9WZ1I2TXlOaEI3V2tEcm5wVW5NLXdzZzhuc1dRNUZTdW9HTUswaUh0U3NxRER4bWNtS2NjdFh4WE51ZGVLdDBlSFQ0UEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2aTNUU1AxSUpISFZzSWFkU1RWc1llSVZUN2prNG5oU0tVZXJHeXdZR3YtNmVBZ0x3YURnMTd2MU53bUhESUs1VjJGeC1kdkxQYkZMVV9Db3FVdm5SbEE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ2LTNFYlc0VWpkT2p6dGtqYmN6WHNzYTQ4TlFJSFVWZXB6MFN6RE1HaWNjM1oxYWl2VkRoUkMxa3JHaGRMbDVsbEgxN3RwVm4xa3VTNnpJYjBiZVZhYmNnNTh5MWJncjJpVGd5VmNDdWQ5NzQ9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ2Ty1oai10MGhPSHVrVVplejVCaG54bXJjT2dTYm9KTkJDYU4wSVMtZm5kNlZPZUlvTmJRVFZIRW5paWdBa0lTSTFNdDNCM1BhOHRwbGMzSUM5NHpodWMwWURFNGw1Qzd0Z3BGWnNkdVBWUHM9
ML is actually another word for ML ,r/machinelearning,Z0FBQUFBQm0yeGJ2Tzd4Q0lEVzZrdTFuUG5pZHBYS3pFbjFBRFY0Q09RNG9lcENveEE5SkZfZjNhZ3Npc09pT0Vxbzk0ZnFyOEFRZHBybnRnS0pqM05XbU5pTklGVUxzV0E9PQ==
"Check out IAM dataset, it has handwritten notes from doctors and others.",r/machinelearning,Z0FBQUFBQm0yeGJ2a1VxbENibURXWmtFSVdYQzNYYmNWUklxOGptQlJXbU5GcHJOcTVwb2s1V3FOQlI4bVhhX1Vqc0dnUV9Ram5UcThQV0xjeDVFNVY5RXZFckt4QVk2LUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bkVTUWJBc2U5aG5SS2RraFVjYjI3RXBPa3BYMWhJVmFEUjNHRHl3ZU44d2x0VkFtMmUtcWNxZjhERFNDZW5sNDE5ZlhGbG9mSWFxV2dlb20tdk8tbGc9PQ==
"hello  
could you tell me please if need to finetune a small model of extracting entites from resume   
which model do you suggest me to use and also   
how should the dataset looks like 

thanks in advance",r/machinelearning,Z0FBQUFBQm0yeGJ2Zm4yR0VTMDZoenRtTUJ4U3JleU5Qc08tWFJsVWVkNFdQQ3MxbjR3dkRBZFdoXzg5NFdHUUlWenBQZElOc1ZveHBEd3FFRjNwdmgzWFROR2dnekRjd2w0bkMyUXg4U2VzejR2WE5uNlFHZWc9
What are ads?,r/machinelearning,Z0FBQUFBQm0yeGJ2d1RQN1d5SXR6R2dxQzQwak1YYUJHMk83M3k0QXRZNkZLS29sTTBfRFVaOWxMUEZTVTA4VEVpd3BLbTdIbWszdzFaZnA4VV9QWUllZHIzSW9rN1JNZFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2eHhFczM2ZFdzOVBNdzhLdUR0ZHcyT09xRkdZeGU1YW1pYXJMWHBQUE9rWkhSTGFwZ01LQU1fbEk5YjRoQllmY3NKNXJpd1VRY0hsUDBCdTBFWmFCcVE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2aGhLQ2pEdi1CTnBBcUFHM29jTDVCa01RSFVxQ0lrdzdPZjhEcVVtTFhTQ3pmU0EyOEpOT0x1b0NIT3ZjVGhoNmE4QU1BQ2ZkSkxHVVB1MV9xUXFpd0E9PQ==
"I'm sorry if this sounds pedantic, but are you a researcher? PhD student?",r/machinelearning,Z0FBQUFBQm0yeGJ2QjlzWTJRYTFSQUZMUnZOaWNBcUVWUHZ0LVZ3RjRueFBncmY4T0NIcGVqd2FOek51c2o3UnlTamxHdDE0UUxQamNJbGxqQUpOSjZENlU2UWl3dU9ac3gwR0huX3FmS1EyUC1tQWhSa3FBcU09
hahahahaha,r/machinelearning,Z0FBQUFBQm0yeGJ2SFctYkhmcEZRNW13d0NXNmZCOWJMSXVmV09iTHZtWEdNbFlXYkt1UU5WMjNKU3ltSElKR0xwS0gtelJLdHE5dkMyMGJyRjdXMjcxQWtNZGtFMVNmSEE9PQ==
Why wouldn't you implement this in Pytorch/TF?,r/machinelearning,Z0FBQUFBQm0yeGJ2STR6T1V3LXZxN1h4YzlqQVVQcUVIYjFKN08ybng3eDBjY2lFYUtJWE5zMHZkNy1vUjVZcGRqRUVUdlFWOGJ5aEF1UWVfTkJBQzF0N3FRU3dXSUJTRXpZdTZCVnFYNklwekRhWUFFNjAwY009
Lmaooo first time I've seen clout chasing this bad in the ML community. You should do yourself a favor and stop answering if you dont want to lose the little credibility your name has now.,r/machinelearning,Z0FBQUFBQm0yeGJ2WXVkeFlWX1h2SGc2ajV4ekdzaFEzTXB4U3BsMjk2d05ZemVuQzdiN0lYREE3Yk9Pdk9ZeE8ta1dkSWVzYXhSSHkzeTEyeVN1VlMzZ0FPNk9JdUZfNEFjVUxPd2ZjTmp4UFRvSGVpbTBZakk9
I still haven’t heard back … Have you?,r/machinelearning,Z0FBQUFBQm0yeGJ2UnkweDJ5a2Q1WWs2bkNsX0xYMy1hNGIyWjZKV3RoX1FvV0tFSWQ5czBUR2pJNjk3Y21ZRXQyX3pPMHNOallwU3VMQ1haV0h6TXV0dmtGNHNtdko4dFE9PQ==
"Nevermind, the website was updated. They expect to get the decisions out by June 6th.",r/machinelearning,Z0FBQUFBQm0yeGJ2NmFHUC1IcnNDc0o2YWFYTHF5WGN3QUt4V3V5RHItTEdCZDBYSzhvRzBoaWFUMVNzRzVhXzE3WVBhcG5sa0I3aUM3bnQwM3FOUlRsNENYbVZLMHZZVkE9PQ==
"Can you give me more instructions? 

Basically, my model takes feature vector extracted via pre-trained model for each sample and then predict frame wise labels. That is my task. But I want to get the sample wise class label by majority voting of the sequence.  To train a network I want a differentiator loss function for majority voting ..  I can take mode but that is not working as a loss function. that is what I’m struggling..",r/machinelearning,Z0FBQUFBQm0yeGJ2dlZ4b0twNFk4bUYzS2hmUkNtRWRXV1ZYZVhvU25LXzBoUmRIVGxkaXZGNmpGNjdzMktRbDB2QWx2LW9jZVBlVjRsVTd1WEdpMDBsRGRlNG4zcHlhU3F6U2ZQbHZyZkljRTFNTTF0Q3Rhblk9
thanks!,r/machinelearning,Z0FBQUFBQm0yeGJ2TElhTHdGeEVuQWNkdlBvdVZVMnR6S3dtZTBfdENWdWRqVVFvNXE4VkxOeXFUd3RTZFJDZkNvSVpUU0ljY25NRDNwNU8ydFRta3BUZmpWOWZjMzNza0Z0a0RuWDljSWp6cUZBaTE3Skt2aEU9
"There are a number of different ways. The easiest way would be to define your selection method manually. This would be good if your queries are structured i.e. if your users query/metadata always contains a location you can prefilter the results and only rank the ones that are available in that location. 

However, since you stated that you don't have any sort of oracle similarity function I would imagine you cant easily define these rules. If that is the case then the best way I can think of is to use an inverted index. The exact implementation will depend on how your search index is implemented. The simplest example I can think of that would work for a completely uncompressed index would be to only search results that contain at least one of the input tokens (I.e. you would store some hashmap that has tokens as keys and lists of documents containing that token as values). Another example, if your index is product quantized then you can rank only the results that share a centroid index in the same position as your quantized query.",r/machinelearning,Z0FBQUFBQm0yeGJ2VWM0V3NUVVJIaXU4RVJ4QkJWa1F3ZlBkUGprSGdHeXBYcnhoYnllaVNwUmd3WXVuNE9yZ08xSVF2YjRvazAxZXM0ekNMR1JFbk94eGppZG1wYnZmWWc9PQ==
"Vdm is formally equivalent to ddpm. See the “three equivalent formulations” section of the paper you linked. Vdm paper took continuous limit, added Fourier features and learnable schedule, but the objective is the same. ( sometimes you see a difference between predicting the image or predicting the noise, but these are also equivalent).",r/machinelearning,Z0FBQUFBQm0yeGJ2Z0o5Q0FSQWpzQkpOd2Jwa1dQbW05aGNXUXBZdlVYZEwyeVVfWFREZGNTQU5YLVZYd1ByejVSQjhlbmdBV2tYTFFRR0o1WWlJQU5KdFMtVThqSk92RFE9PQ==
"Ads, short for advertisements, are messages designed to promote products, services, or ideas to a target audience. They aim to inform, persuade, or remind potential customers about what is being offered. Ads can be found in various forms, including:

1. **Digital Ads**: Online banners, social media posts, search engine ads.
2. **Print Ads**: Newspapers, magazines, flyers.
3. **Broadcast Ads**: TV and radio commercials.
4. **Outdoor Ads**: Billboards, posters, transit ads.
5. **Native Ads**: Sponsored content that blends in with regular content, like articles or videos.

The goal of ads is typically to drive sales, increase brand awareness, or influence public opinion.",r/machinelearning,Z0FBQUFBQm0yeGJ2OVFoV0xHcGFaU19jaTlMVm1EUF9YTW4wUEdDSVBadlh1bFVkUk5KLW1YVUhla20yZFk2RWkyUXNLZjRJYUpkWUd4YnlzZkFkd21sR1VBczZ4N3E0dUE9PQ==
yeap. just checked myself. it's june 6 anywhere on earth so it might come june 7 for certain timezones ;),r/machinelearning,Z0FBQUFBQm0yeGJ2OFFyN0k3M3JvVU02WVQxalF4X0tSWjdjcnU4VVNBRzlUaWpCTVVhZjZucWY4Vk4zZ2ZfRDNHcWdtOUVraG9oWDF3cl9CUVM5ckZUYmxmSkRfbFBJaC1qRlMyMUUwU3gyZlExQ0VWYlFPUGs9
what open source models can be used instead of af3? I'm curious since i'm trying to enter biotech from ai and really curious what the practitioners have in mind.,r/machinelearning,Z0FBQUFBQm0yeGJ2d0h6Z3hHTE0wR0s5Ylc2cjZkMjhTQ2d3LVJhY0hBbDhlRXRUc0gwU3ZzWWZNdVp5amJMRVVSdVJPbk9lWWM4a2N5OXFLQVByWTdVa1VKWUdnN3E2X0x3VWJHZy1GVXNsZHYwQnZla1N1YjA9
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ2OGtyeHplblZMTGxuaFB0OVVCczFFcnNLM1I4dUg5WGY0WFo5T1Y4d0hONzlJdmpJNUJmRy1UUVFBZDUyOVlIemgwc2xVampLOGd3U3kyZlgzcGhlRGdPOGhMbUxERWstMnRfNlptVTZwRHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2dEgyN0k5bGlVZ1Fyb1NTX1FXenNMVGc0elhKOXM5NV9UbEFXQ1F0VTBPS25KbU1wNjNPOTlVX2FZUndzMUFJSGxmVlZJOEpuSy1zX3JEZTJpVHEwN2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bnhXTnJhU2t4SDl3a012UTNBTG5CMUVISjFDay1TTkVqMTBZQkJCM0dQZGRsZ1FHVS10bFJKMzNnUmtobWF3ZUhXbzl4cXNnc1R3NzRlb3BFZ1kwSkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2dTMtVHMySVMxN2VWYmJQM0lPYU11bHNtZS00eFhHQVZtQWpWTnFJd1M4ZUs0ZHVwM1dJVnYxMlJZUW9meC1DcEZWdkN6NTJ4eWw0TGZ5V2ZhMVY2Smc9PQ==
"there's a few to choose from, although as always, ymmv.  things like rossetta, esm.",r/machinelearning,Z0FBQUFBQm0yeGJ2aVFmeHFONGxCLVJoOTdEcm9xWVdlaVV0QTNMdkNXSHV4S2dUZ1hDRzJuZFRfb09NeE9sWlZUQVk0aHhnUnFSSTVNSG5Za3g1QkU5RGFkelVMUzNiVmppNms0NUtTZkhCQmFNQUFJeHFjS3M9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2QnlJWkRzME5tMnhDdjZtQkJRMTFLSUhEbi11LWdNR25SQUVaN2RpUFBidDhiUVdZTEs3MUxRcENXbWFORGlwMklnTlIxOWYxcDhoV05XZVNOdGxsblE9PQ==
i.e. recommendation is actually an RL task.,r/machinelearning,Z0FBQUFBQm0yeGJ2WkNDWFQ1OXNnMnA5b1ZvTWREOWlyM0R3OG5jSnFzT0NzOWg5anRmX2FIVjlDdk9oMWh2S0JmOC1aN1laV1pjMXQ4R0RHRkN6YUw3QWZHdkZFVE0xS1E9PQ==
"Highly second reading Harrell's blog. Even better, shadow a clinician for one day, attend an MDT conference and you will see the real obstacle in healthcare.  
Also, highly agree that if your model is only marginally then a simple decision tree plastered on a wall or a simple cut off rule, it is not enough. Some don't even compare the performance for me.",r/machinelearning,Z0FBQUFBQm0yeGJ2NUhrejlEU1ZhSm01UHJlNVAydFhaVnMtUXdHZE9CZFQ2TkwwOVJ4b0pMel92QlAzOFg4cEtyS3VJUThXSVowMUNnTlRfd0J2Nllndm5abC1QQ0pESnc9PQ==
"gelman and harrell should be in your back pocket imo!  and harrell routinely shares his workshop videos.

oh, if you want a book on how to deal with imputation with related applications to censoring; van burren et al",r/machinelearning,Z0FBQUFBQm0yeGJ2bDZrcmNmelduc0U0Uk8tOG42V0FFbnB6NVdRUTVoM1JXU1V4RDJWTDRNQ2s0eks5S3JkSjBSNDdfRkgtdE5XOVlmR211UUdwZmJZVW5fRFA5SFVLbGVlbk9xTkNwaDhwcXZqVGd5a2JUUW89
"There's my service SvectorDB, if you're a fan of serverless or an AWS user it's made for you

* It has support for CloudFormation / CDK
* Pricing is transparent, $5 / million queries instead of some opaque ""data scanned \\* vector dimension"" units
* Scales to 0
* Supports real-time updates instead of eventual consistency
* It's also much cheaper than Pinecone

[https://svectordb.com](https://svectordb.com/?utm_source=reddit&utm_medium=organic&utm_campaign=MachineLearning&utm_id=12m9pg0)",r/machinelearning,Z0FBQUFBQm0yeGJ2bXJ4RXdWRXZOeWhZNkF1dGxneDFmckc4WFc4LUdmVk1ZbGlpWThaOWlZYjlTbXpkVmcyOFRueHZQYkxGLVUyT1F2MVA3enlSRzJVSzhMX0N5bEhiSXBQenN4ZmlrcEFWLWcwZW5OTHBZbWM9
"Metric learning could work, but consider annotator variability in tumor segmentation masks too.",r/machinelearning,Z0FBQUFBQm0yeGJ2Y3NVY0xobk44TEpVZHJwNDQwbWdreGFEa3kwVlZ2NVlrRlM1Mkx2OVJZNGZTLUs3VzB1ckVuUFJLSU1jMGR6SmFuNnh5eUpCQnhKVC02NEozMWV5UG5xWEZ2dkVQT1VPRmwzQkViWGVpZ3c9
"Use weighted mean squared error as your loss function, it's the regression counterpart.",r/machinelearning,Z0FBQUFBQm0yeGJ2NjgzcS1MQlEyUlJGMDZjV2VLUjRtSmdhT2hPVjktUmZsNTJOakVITHMyWFpFUUN5SFdsMXNCVjVXbjRjeF9BZVNGbmpLcUoxVmo4Z2RMUTJoQjhQa05RV1p0eVlRMjgyQTBSWkgtTXRPbXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2Z0RWVzhYOUNhRzkxZ2VQRGdtMnBhZEotMTh2MHVBdkpoVl9USFM3R05Ka3JyM3VTdWsyLVlxZEdpblgxYXFJQUFEa2x0VWhfY0JNbDVUY0pFT21Obmc9PQ==
I’m starting to think we shouldn’t let trillion parameter models be described as ground-breaking….,r/machinelearning,Z0FBQUFBQm0yeGJ2TEQxVFk5Z051WTNsVEtGczQ5WWNLNk93Q3lYWWhYM2lueUttMTNFX0M4UktmM0dmZlQyR0VNc1dfTlc5ZTU1Mk1IbEwteXhRWVdEaERSRFlFV1hScEE9PQ==
Thanks! I will have to read more on gelman works since I'm not that familiar with him because I mostly follor harrell on twitter.,r/machinelearning,Z0FBQUFBQm0yeGJ2UU5Ka09oVnpqZmowS19TWlQwVWdsR1dzLVFBa0o1RXhMVlgwN3Vnb29GOW44T2QyY2t6MGFVaGxjX0lndkh4S1ZIc05VSUp2U25xdEk1MVBnMW9lanc9PQ==
"Yeah, fair point. Can you elaborate your views on how metric learning is a good or bad candidate for this problem? Also, a simple cross entropy classification loss should work, right?",r/machinelearning,Z0FBQUFBQm0yeGJ2V3ZQMXdOeDF0NFhVZmdxVXlpU1hXd3Q0SXM0czMxWFhsWUFkUmNUOEVKSzlFcGtyT2VIZTlKRXZVZEJWZXJYb2FVX2pyVS1UUTVkcTdwSkhXY2VjMUE9PQ==
This AI research community I've found to have the best resources and updates: https://portal.valencelabs.com/,r/machinelearning,Z0FBQUFBQm0yeGJ2dzRxazJLb2V5b0xYSldKRU12Q2RPREpVZHNjUmczaVBRQWltUUJXdW92MTBORTNOaGdyOG55TXBLUnE3WUlnaUk0eFZZM0YyVXg1SFFDRTBVMGFMMTJOMGxiZGNRQVdFU2M1dWthdUFLXzQ9
Did you search in kaggle?,r/machinelearning,Z0FBQUFBQm0yeGJ2Vl8yVVdIOGxWN3BFdjY4LVlZbk5ZSUp0WC0yNFhNVHpfeWZrczU2clE2cFFuaklaendtOF9lUEhOeDI2dTR1S0VsbVdGWEs2RGRVb0kzbHFJQVB6UVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2emRvNE42c1ZfbGdmNW1ZWUNIcm4zeWs0MUp0UjR0ajR4YWw2NjFGZlNDdVBKeFBLYUtXTWJneEVFbXQzbDRSZFNJeEJiSzFacmZzb3NNRzRxVGZFR3c9PQ==
"Also, it will always follow videos with Lex Fridman, even if you watch just one video and downvote every time they do it. Stop pushing the guy.",r/machinelearning,Z0FBQUFBQm0yeGJ2ZWRvR1lodWJZNmFHb0N0c1IwMTRLLXctbENrbzhlUjFHb0Rxdmt4XzNwbXFCRXlubTdIcGZvQ1NlUWwtLVc2X29veEl4Zi1qZ1hVTHZhbUFfeERpM0E9PQ==
"Yeah, it's not exactly the most creative idea.",r/machinelearning,Z0FBQUFBQm0yeGJ2bTVwOEJ2UXZzZW1KSDJtUWZSSXR6UHdhYWxkWE02cTAxdUlrNURqZERQR25GNWt1cUVPSExPNXVVejFJc0tsMEtvT0ladmxoeVpCbm1jWm5VUmFfa1E9PQ==
"There is a new language - Mojo. It's a language as easy as python but as fast as C, and further ia optimised specifically for AI. Basically python but fast af.

That's what you can look at.",r/machinelearning,Z0FBQUFBQm0yeGJ2bl9DOFA3Znlucy1HMm1ETE5yVkpWbTJTbTNmSGlOZ2FDSC1vbEFVZlZpRXlBaWRiV0hDWWlJaWg5TTA5bVpXdFlvVDV4LWFpTlBTbFpCazJ1Ynl4b2c9PQ==
"I found a torrent
https://academictorrents.com/details/01f95ea32e160e6c251ea55a87bd5a24b23cb03d
Good luck",r/machinelearning,Z0FBQUFBQm0yeGJ2dnlKWTl3LXRVa1JuMzRSRl8zb1haS3ZFbzhjRlI0NWZfTGtoUnZBclpCMTJwWnNEbXhVajN5Z3JzWjNYVnRnZzA2RlFRM2huRGdCbEE0Vml3NXh6OXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2aExqVUJqbTBGNWNNZ29VTkYxUFJTSHRsSFdCZ0g1WXhmMlJYTVNtM3dRbEljR1lGSkdRMDQyQzRkWm0zUXZSSVhoYm9ROF96YXdKUzhqV1duNVlyb0E9PQ==
"Thank you! Trying this now! 🤞I had tried it before but I thought there was no seeds, it looks like there’s actually several “mirrors” seeding it so hopefully it’ll finish, I’ll report back!",r/machinelearning,Z0FBQUFBQm0yeGJ2UkpaQlJJY1pUT19pWlR2UWZmTUNuUEstdjFUV0FaZ196d004cmF1cTB3d3pQSjVCbHhlUnNtdVAxbUZqWEkwdm9fNWtuZHNxNW9JTThEUVZGb3BhSFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2azdmc2JBaV9PeVNzUW9CS3R2WXV2S21zd2ZTVjBtNUdGWV83Y3Q5M0FpOFdFeGZjbkdIMnBoTHJkUnp1OVNPdnptU0h3V2RCUEtwRjM0a1I2bV9OU1E9PQ==
"Yes, there are compressed videos up there but I believe they are not perfect, specifically the nexus videos.",r/machinelearning,Z0FBQUFBQm0yeGJ2SldoTVh5RnI4Vzcwb2RmZTJ2RXAwTi1OVm1Nc0NvV2JweU1uSVFSSzZBLXNhQTJjNXJFYzlRSjhrVlJKcFJzcHFCNXNHRk1rZkRNTmdrWE56M0c1SXc9PQ==
">if biotech AI is a **marketing buzzword or it's have working applications**.

Yes",r/machinelearning,Z0FBQUFBQm0yeGJ2b0lSQjJLUEY5NEVxdVgzcnF0MTRBT0wwc3Y2V1A2am42U3dvZTdJWWswbk40S1Q0LUlkMnV0RlZRRHM0elRJeWdMRFJ5RmlzTWlCbGlPX0VoVjMxMmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2aGk5Um0zTUx0d2M2VVMyZm5JaEFsNlZLb1I4TDI0eHVHVWZDYkRTRzRLS1lsTmxzSVp0cG1vMUFSQkVUOWVnSXJQRlFkZFA3WjA5YnFhNFptYklvTmc9PQ==
"There's this but it's also unfortunately online.

  
[https://www.sievedata.com/functions/sieve/dubbing](https://www.sievedata.com/functions/sieve/dubbing)",r/machinelearning,Z0FBQUFBQm0yeGJ2RTdlbUctM0VPdnpfTlZxYzBUUnRZN3k1N3RPZUNCUWMtOWFSSmczcndVdTREMkxRMUhsLVpDWEpNdC1pZVJWeE51UE9uZURBbnZ2U2VXVzRMNDRMYmR2TXI0M2xNQUdMNkJJUGxQMHBzdjQ9
"The occasional random videos with low views is one of the few changes to the algorithm that's really positive. If new creators aren't able to even a few views on their first few videos, then the platform slowly dies because new creators won't get discovered to begin with.",r/machinelearning,Z0FBQUFBQm0yeGJ2LWZCcXpnd1FEdUxYRHlxWnBtQzdCYkZRLWtsZjkxRk11YnlURmtwWnpsT1R2ZGI3WHRncWU4bHVxdUZSSWdldzdxeGZnd09OSGhBZE1SdjdSSG0td3c9PQ==
This torrent worked beautifully! Finally have the original entire dataset downloaded! Thank you so much! 🙌,r/machinelearning,Z0FBQUFBQm0yeGJ2dU5oRjYyY0JORDZQZFA4Z1hvZzJYRkd0T0hGdFVYZGxBUDJwcnI3TXRsRVRLMWFIc1cwbDVRV0E3ODlxaEtoSkQyMFBKWmNrc0dvM0RNYjJLbUE4WGc9PQ==
Can you also upload it to Kaggle?,r/machinelearning,Z0FBQUFBQm0yeGJ2dUZTVUEteDQ0SE0yeWlXbGtlY2dfdlZMZmxBUmpPX0VKNjhsZl8yYXY3TXE5X1NGak5rOFJ4Szg2LXRUTW5zRXVfY2ZFWWdMVGJieFh4alZYaFhLcWc9PQ==
"CycleGAN or Pix2Pix might work, but consider data quality and domain adaptation.",r/machinelearning,Z0FBQUFBQm0yeGJ2eWxtVEhuWk1nSDc5dTZNbHJhOVA0T1M5U0lleTc4bUZlX0xobXZNZnoyLUhCdmpRRWRhUnVUbUdDcFdKUlpJZDNfdFJPR0lnSVQwQ3BBZm1FZlFLT09VUzBrVVJvM3E2WS1hMmV4SnR0c2M9
"They literally don't break any ground, you need an excavator for that.",r/machinelearning,Z0FBQUFBQm0yeGJ2eEtsZnB3Q29jaHNKajB5SDkxRVhMclZzdGU1MS03RnBJejMwNnRUV3F5eXhlZFZBNTY4SVR5TnBQcnJFNlh4SUVBdTUycDh6Y1VVNkwxRElBZzdka3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2WkpVYmwyN1RKMTBZVG1lVjNHdmtYNW9sRHFRcDlhajUwd0txQXI0SVpFcHZPcU93U2hkTGVUWG9sUFYtY2pXYWhXRldJWE1SeTUwSVBtVnZma0dsMHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2RFdwaktlaWpxX09RSDVJOWhfWTBIaElqTjJ4M0t4d0tWUC0wcEhmZjNBakJMZW0xV203cS16UFMxM0JSSWRESmhYX29ZaDJ4RGNoOGRWQ3hrQnJFNlE9PQ==
"if you did some projects like that I described, you're also welcomed. DM me if you're okay with it",r/machinelearning,Z0FBQUFBQm0yeGJ2WjNFcy1mMjlNU29kYWVlZlF1cHVteE5najVzRFIzR1o1MzA5U01zcmt2cE5kUVAyenFlMXhyMFVyWnNFVFNkLTFPdElEZ3FtdWZVSkMyZTBxc1EtQ2RTWGU1VjlCbGZxNUVzejZCcnFoSDg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2eTY4YlB2VUkzTTN1eElBS2JpaWNtMDNzbTJGdTgxQk1ESERMMDdlUktaUVVXUWMxUzB0OWxWMHFJS3I3SV9ZblJiRWh0REZidHhiNjZ2RTc2NUFpQnc9PQ==
Yep. Dunno why everyone feels the need to invent a new name. See also: [https://openreview.net/forum?id=k7FuTOWMOc7](https://openreview.net/forum?id=k7FuTOWMOc7),r/machinelearning,Z0FBQUFBQm0yeGJ2Z0d1YU5QUkl5TjhMYUU4bDBkdUprdF9BQ0RNRHM5aVhYcnQtZGFHcnhsRWpwNU5HWG9lWklUYzlsd3VYcHc5SnZMa05GME8xNDRWdmgyR1hfb2pkMFE9PQ==
"I work as a bioinformatician in a biomedical research lab. We use AI like chatGPT a lot for our research, it is very good to get an overview what certain proteins do etc without much publication research. 

Maybe have in mind that e.g. U-Nets were originally designed to detect and classify cell structures in an image, and is now used heavily in the background of image synthesis algorithms like stable diffusion. 

There is a lot going on in the field, but quite often so niche, it will not make it a broader audience outside of biomedical research.

Last, many algorithms we use work quite well without AI. There is no need to invent an AI for mapping reads to the reference genomes. We have “normal” algorithms which do the job quite well.",r/machinelearning,Z0FBQUFBQm0yeGJ2WkRwcXVPc19Jb2tKQ3pOa2Rtd0JuMkVrLXluMUhuLTBETXdxd3VlRjJyOEJWdTdVTGROc2lhR3NOZ3FjRElxMVhzM0owOG1XWVJfYXkzMkpDR1oxRkg4cE5sY2xqMDZ3ZmFBMUthNHhTdGM9
"Well, and crisper-cas9 got the Noble Prize in between 🤷🏻

In general you are right, different fields, and the clocks ticks differently fast.",r/machinelearning,Z0FBQUFBQm0yeGJ2bzFPN1paTzFCUUZ5aVZCUGk4dllGOTR0ZDRxT1c5T3pLajZZOGlsRFYyVWhSdzJWWWR2ZUw4ZnFCQ28zMm5iWXdGNlBDc01JeVRqTFp5NW4zeW1jcnVmYlFHRTlxRl9HNjhSM2dYQURDX009
Search and watch a few yourself.  You might accidentally learn something.,r/machinelearning,Z0FBQUFBQm0yeGJ2ajBZYV9RR29EeHQ5MVNkUlFHVmVlMVFoeUN6c0hDcjNpUDFrV1BJSDNZWElfRGlCamtTRzQ5UDNfYThQWldHUE53dXRUVE9KeTVxeDItWVVUX2NXanc9PQ==
/r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJ2czNLRERNY0NoRGZodHRHRHI0OEtsZHA0eHpiQ3d0XzBTNVdmUVNFWU1WME90VUw4TXp6YjFlNERZbzQxZDljRDhWQWJQMUJyTkltdDZrT1BGaUdxOVVBd21XX2xoVkdjNnAtWWI4WjhzUUU9
Cas9 Nobel in 2020. The arguably 3 top NN folks got the Turing award in 2018. So about similar times cale of accolades (sorry schmidhuber),r/machinelearning,Z0FBQUFBQm0yeGJ2cml2QUtaZUpVUlVmSW5YRVdzTThGcUowbEJkS3hfakxJWmRGd01tLXpoOXlMamNkbFMxNDM4UzYyQUtsV1JkRERrNFI2WVJmajNXb0NmRDNmdmdGSnc9PQ==
"Definitely not a buzzword. AI is already used widely for radiology images, with many FDA approved algorithms. Pretty promising for pathology images too, many AI models are currently in the laboratory testing phase. The main value of AI is in precision personalized treatments which are very valuable for diseases like cancer. Because humans can only look at aggregate features (like the severity/type of cancer) but with AI you can technically measure and quantize every single cell and their arrangement..",r/machinelearning,Z0FBQUFBQm0yeGJ2ek1zeW1hZ1AtRzJ3NWZtQ0lPc0d1NUdnOHZQYWc1ZVEwWkkteHRGblpjWTBERkNXNDljSFFUN295bTdHSHg0Qy1rdW51MVhpTzdxUC1EOVlPR1NCZjExcHprd1hHcmNDNFNLTWhSTE5hNG89
"Accepted as Findings. 

Meta: 3; Soundness: 4.5/2.5/3/4; Overall: 4/2/3/4",r/machinelearning,Z0FBQUFBQm0yeGJ2RFVoQUlpLTF2d1dISnNGQzFSQllTWmluZTlYSVlYTkxxQl9ZbGJ4Q0JMMHphRDBHMTJyMkc5SzROUXZ1NFBad2Y4a1pjMVB1eEhsLVNUOV9JNTNKNVYzMTNPOTRrbnJLWTU3R3hoV2VFTlE9
"AI in biotech is more than a slogan: it has real-world uses that are propelling important breakthroughs. DeepMind's AlphaFold transformed the field of protein structure prediction by resolving a long-standing issue and facilitating expedited medication discovery and illness comprehension. Microsoft's artificial intelligence (AI) in material development speeds up the creation of novel compounds and materials, improving productivity in the pharmaceutical and other industries. Businesses like EvBio enhance the creation of bio-based products by using AI to forecast and optimize biological pathways. These ideas show how artificial intelligence (AI) may produce tangible benefits by accelerating research, cutting expenses, and revealing fresh scientific discoveries. Investigating partnerships with biologists as an ML Engineer can find real-world uses for AI that fully utilize its potential. You can visit The IoT Academy for AI/ML Courses.",r/machinelearning,Z0FBQUFBQm0yeGJ2YzQyZEIwQkRwUVhiQ09aTkRkdVNhcUxWdWRZNEhPeERRV1VhcGtvdzlDQ3g1MjFFTnZUZm9YblV3RFlKbWgzWEFUZHNJaUdOUkxPT25xZjJSdWswc2ZTT3BQbGdsbFk2S0FXeG1WTmZuRGc9
"Watch 3blue1brown's the Essence of Linear Algebra series, and also his videos on Neural Networks for the best visualization of backprop and other algorithmic steps I've seen.  
  
StatQuest is usually a go-to for stats videos, which should be your bread and butter. Most educational video content for stats I've found to be very straight forward and leave me wanting, so if anyone else has recommendations I would appreciate them as well.  
  
3b1b's Essence of Calculus series is great, too, but really I've found beyond learning about the derivative & partial derivative, not much calculus is necessary for ML. A lot of Vsauce and Veritasium's videos I find to be the most captivating, and explain mathematical concepts, how they were discovered, and their impact better than any other, but the math is usually a component of the story they tell, rather than the focus, and can be piecemail throughout their content.",r/machinelearning,Z0FBQUFBQm0yeGJ2QzZZMm1XTV9XSTlHOEV6SGFTUEJ6Nk1hSndtNVlIQVNrdjRsaGZ3aDBMMktLUi1WcVFxaS1BeldzU051ZDI2Z1o0cG8wVTZQa2ItUmpKQXFxdFlrdkE9PQ==
"Thanks and what about Andrej Karpathy neural network zero to hero playlist..?
The motive to learn this al is  to start a AI consultancy/ service company.",r/machinelearning,Z0FBQUFBQm0yeGJ2OHVMUlZBTjhZZXE0THhqTWFrUGNkb1VfYVBDQ1k3eTY1aEdHVTBhM3dWM3BSMHBtakhKekk0eUlOOG1Tb0o4N29XbEFjYW1DdURwckVvaGlaUWoxaWc9PQ==
"Thank you, as goldfish, I was trying to find a paper about LLM in chemical discovery I saw months go and I forgot to note down, it is probably floating now in the airXiv ocean far from my reach",r/machinelearning,Z0FBQUFBQm0yeGJ2LXdsNEZUZmFQTHY5UGtTMVhPZkE4MkRuRHp4RGtMTzI0bUxOSFlPV2hSSi1EZHZBVTRScG1VcHZLbUhWc0NVakFQa2lUQjBIMlZEeHpDVlJrcElza1E9PQ==
" This is huge! I just submitted an Exposé for a PhD in the RAG domain, and i think you made my life a LOT easier. Looking forward to contribute :)",r/machinelearning,Z0FBQUFBQm0yeGJ2dWFxdVBHUmZGSk8xd0xsLW80Z2l0ZkowOVhMd3YtMVdOQlBnQTVWb1N0LXhaT19xdjdwX2d5Mks1NldHMDhlRVk4S2JkTVR2Z0NvZHRyVFRkUjU5Q2c9PQ==
Great paper,r/machinelearning,Z0FBQUFBQm0yeGJ2UXV1SXFENlIwLXFzNFBKMENEVXMtb1FQNW9aMk8tc2tubU9HWDN4UXRyellxS1lHMk81Q3RSSFdodlNaZU1QMXdTd1hTS1RJS2tmYzJkd3JjYWFoaFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2X1BXNW9OMnk5Uno1RUlDbndfN0xINHZnUS1HNW50blZTNWxZcGNCelhOWVlsWnZPM1cyaS1udWFldHp4cHVuSFZlWE1mbUswTlczb0k1cXNtWWNJTkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2b0dmcjRKMlhsTDY2VnpnSmlEbjFlMGtBeE0yZ2k1UzhSSlhMSXpXV1oxVU5QWDIxRm1xMFRhR2VBbHZCbnI3anJIcWpEaFk4MXlHdkRKd2o0MHZsSlE9PQ==
"Actually, for someone like Youtube I would say that it is not necessarily a two-sided market. YT only wants more engangement -> more displayed ads, that's about it.

For other services such as Uber Eats or Airbnb, I would totally agree",r/machinelearning,Z0FBQUFBQm0yeGJ2aEVzSXUyenhFemhVTHF1bkVQVDJUdEh3YnhmNWl4ZzNCa1NLd0xRbDkyaFlEc0E4R296X0tma25wd0l2d1Y3Z1plRThNbUFsd0NGTmtVeEJRYm9obWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2WVV6WDlja1VWdFBURVhiZkVDbGdzWEtST0txUUluSzhtd3M0TFBwU0psWUFEOVBzTEhhMnVrbEoyV1ZZOHc4Y1NLVjVaa1lrNGRZSDRSaFk0OTdXbmc9PQ==
I find the input data format description to be terrible… Paper notation is all over the place,r/machinelearning,Z0FBQUFBQm0yeGJ2TjU4aEtOWWtNMjRUcmpEbnowaV9XMUFJdGpQeGlMVTM3NE5GRVFWa0t1UDRYY04wYzRnY3h2QjgtalNlNzNTN1J1ejRhSjY5ZGtZZi1tQ1FvMWZ0Y3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2VVdITks4VVFla2U5Q1hqQ1IxTTRkM1lNRzBvQmc3NzR1QnJCVGpyb1BvNmxOREJxV2FuVl9GaDlsbXNpaXlPMmJZUTNSWVNfSTZHU3BQaE41SkxrTXc9PQ==
"what?? I don't understand how that can be true. Like the other guy said, If there's something wrong with the implementation, doesn't that mean that the results are wrong?",r/machinelearning,Z0FBQUFBQm0yeGJ2SGVsMlo0dlRrV2RQb2d1NVI0bkVRZXVzUXdmaXo1Q1pNOGpfRkxPVFJFVUI3ZEIzSTQ0VWdpaUZqZ0s5b21LdUhETEtkREp5Z1ZFNXBlZEM1TVl4UVE9PQ==
"no they don't need to review it, but the point is it should be out there, so the community can take a look.",r/machinelearning,Z0FBQUFBQm0yeGJ2NER6aVUybFE4d0lpZ0pRMW4xS2VRcHJQQ0x1STNtTVpKQ254bHdFclpCRHkwSGdYYzlTaWVXaHdvR09EU3JyNUdDVm5VV1NoZ2ZEbVpETWhadXpJcEE9PQ==
"my friend, thats what ""with code"" implies. Not literal code in the paper, but a link.",r/machinelearning,Z0FBQUFBQm0yeGJ2V29vTko5TGdVd2gwSFpybWI5SWlORTVXZWNfNXlFNEJ0dHF6YTdnUDlJYXB0QkZfT0RuZkphdktNWm4xN2s4QXgxU2NRa2Z2WTVCWXdnY1dVWkZXQWc9PQ==
The mathematics for machine learning course on coursera is really good. Highly recommend it,r/machinelearning,Z0FBQUFBQm0yeGJ2MFJ4cXN1NE5jd2JVMXVtVzI3SXpDdlpiTkE5Z043a01idHE3cEttX3RCcVpvcG0tc2RybGJET0lhNzJOdWZRS2RqVFFRbm1Cb0Z6OVV0Z3Rtakw4Vl9CMTBlRkdnSkN5cHZFS1k1Mkw3a0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2M05EUEpodGZPQk9nNEdtTHFzakFUbGlNdFFnaF94cjJJR2NjbnY1S0U4WGxMMjlGV2w4YUxSZ2g5RC1JNGJPR2FWUC1RNXlMbE9KUV9MWDNXajRmWkE9PQ==
"I think AI in biotech is undervalued, it's not just a marketing buzz.",r/machinelearning,Z0FBQUFBQm0yeGJ2YWR1U2RVX2V6aGQ0bF9RS3RacmQzZDVEUXVXdGhKWU5PZGVqZW44ZHRFMEVCeU51RmxyQ1lFenhzdU1CS25wZExxaVV6U1lUMFNWQVpDX0RuUnBULWhOQVlMcUp5VVJRVE1IaTJwOExGQ0E9
"Look into temporal graph neural networks, they might be a good fit for this",r/machinelearning,Z0FBQUFBQm0yeGJ2eXFTT1V6QUItUFNSelJIbGtQWlI2cV9VeUl0OTRYNXY3N3hMMnE2WEF6UDJqYUE5THl0NkNJd2FHMDduWURxMTJCZkhGSnhPWExuc3Nxd19FVGlJcFViQzdqRTZfb1lWTkhFYjk5TnV2dVU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2cmVEalZ1TUVvOHJ2RldyYWNEZTZ5YWdGc0FBdTdBSjBmNFpnNndzXy1BcVlmN0lROEk2T2VGN3VkS1RudHp0YWtJRjExZVNFdTZJRTJ6WEl3WU45Rmc9PQ==
A genuine question - do you guys think that treating every problem as a sequence learning problem and using transformers can actually solve the problem. I personally find it a bit strange when people tend to formulate everything as a sequence learning problem (I remember some paper even predicts the bounding box in CV as sequence learning problem).,r/machinelearning,Z0FBQUFBQm0yeGJ2MlhIVWkzVDltUHBKc0tIX2VtbUxmMFJxVk93MDVNNGt4UXoyYkhxV2dPYzNxU3hicEZkY3U0TjQwSF9lT0ZGRVNMUk9vcFk3VTd2WjcyY3dWM1N6OTF1R3F5QzA3bDkxUWRfclNfd2pUbm89
Yep. The pace of releasing the new papers is inhumane. ,r/machinelearning,Z0FBQUFBQm0yeGJ2Wm1nLWxEc3lGQU5aaGozSlJaeTFjVmZUczVrd1lXVEo1RUdSVWF4XzhzMXo5UDdVRkdybHFsNnJEdm9iUElscXFwN2JSS2h2dkEtR2xDMW5IZ3k5eXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2Q2ptNDYzeHN1YkEtaUlRNnNRQnZyNkZNanVvXy1VTGNSY1ltM05YNUFXVHh4eVFTc1VvZ05JeWptSFZsdU53VVZYU3RFcjh3a0czbGU3cHdlU0hreVE9PQ==
"My background is a little different (I'm working almost full time in addition to doing PhD), but maybe it will be useful for you. Finishing my 2nd year of PhD, and I was also doing research in the same area before, during Master's.

I almost don't research literature apart from the current paper. I mean, I read papers before sleeping, on the bus, train etc., but no principled literature search. I do this only for the current paper, after initial experiments. At that phase, when I think the idea should reasonably work, I do ""proper"" literature search for 1-2 days. Overall, this is probably around 50% of time for my PhD, but I also do this for fun, since I like reading papers.

When I start doing experiments seriously for the current paper, I try not to break them for other things. I take leave at my work, and I program for 12+ hours. I may do a little break to check literature if I need to. Also, I often teach courses at the university, and for student projects I often assign ideas I want to check out, and I'm not sure if this will work out or not. This is great for my time efficiency, and also students can take part in research this way.

For learning things, I also do this exclusively. I take a course, and I focus full time on it (or rather in the afternoons, after work). This way I finish what I start much more often. But this is for sure the least part in my PhD.

In general, I prefer to focus on one thing and work in intensive bursts. This helps me to keep focus, and it's easier to manage time this way for me. This may, or may not work for you, but almost all PhD students that I know prefer and use this style of work (granted, most of them are also working in addition to the PhD).

About your specific questions, spending 40% on learning is too much in my opinion, especially if you spend only 7.5 hours daily on PhD, for research you will probably learn more through reading papers (and having papers to know and cite is very useful in itself). Just 3 hours on programming is also not much IMO, but this may depend on your area. If your experiments are computationally costly, and you often just wait for results, this can be ok.",r/machinelearning,Z0FBQUFBQm0yeGJ2UVZUMnBjdjRab0MwWXpYc1ZBTV85dDR0X3g1bFdqcHQ0NEZiaWFwd1RER1JsOFRSZFFwbkxqbGtPaUZWV3lwNHd6blNQaXBxRUNCUGtGOXE1cmlTalE9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJ2dUxEYUZGLUZnVG5QaUlCc2lsSkFfRVJGcm1QZk14dkQ1eTRTTXJGbkJtdEZuWl9CNDI5SmFvcUxXUjBjeVR2QlAzZlp6M3VIMUpZYmZ2aGc0MHhsVHc9PQ==
"Any segmentation model will work (e.g Unet, DPT, segment anything..)",r/machinelearning,Z0FBQUFBQm0yeGJ2bms1Uy03LXdMSm4xSTJXeS10a1hVVEZFU1BqcVR2M1AxSTNfclRybTEydlA3SW5ZYWxNTGxBa3IyOXFWTVhHREprY3QyQnBERlVmLUMzV0d3eGxUTEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bWdJdGQ4eWJtNHF3Z3pJbmFRTU1mRXhtU0xzY3BnSThuMS1zMmxkcnFYSWk0Q2hUb0JPdkpGc0s3MXhSSl90dmkyam9lNXd3ZkJmWDZXQmFsZmxQX2c9PQ==
r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJ2YWVQdzI1eHhadnFiVjhPQ2d5MXRfdE5ZbFlZSnV3bjhmNm9MVjk1bVZ2a282VkdnV21pSE1taVhwMUxfcWRTUGl6YjFfSC13bmRxb2Nyb2EyT1dFV2c9PQ==
"got the decision: surprisingly, albeit a student with a paper as a first-author and minority , wasn't selected.",r/machinelearning,Z0FBQUFBQm0yeGJ2MlZwSFI3eG9zb05laF9IWmx4a28wc1ZPbERsVHpBbm1hODBZdDhCNGwwblU2cGJrZm9mRmJ6ZHRTbDlzUnRVc3NhX3l5dlBjeXdjb3FkSU0yOGRtNGZXRlFJWmpRQU54bEdTM0RIc0xYLUE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2TnhmaTBtMFVzdXplYjQ5MGM3alIwZ1NVYVdHM184MlZPTFpWR0QtQlFlVVNmU2hBQ0ZLY3k1d0JHV0RpcHVHU2lxblNTOFhXUjVmM0xidHBqNGV6ckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2eU82Mmk4Q3BuZTZtazVVVURsZFJpcktlU1RrbktjSU9vMzVFbDB0Tzk4OUZlM29LelQ2ZFY2cXNQZUZJWGZ3TExwcXAtT3JkWEtSNTBydlA5Z2h0elE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ2SEtYVHF1Wm0tUkZENUJ5MWUyQjZjZloySlpDUE1hTUhhcXFGblkzQlZCU3lPS1QycjJUajhxY1YwSDN1c0VYRGJxNFlSdnhNWlRiOVFsS0J2Tm44YXAtWXMwQXJXaVJOS3NtdGJzb3EyZW89
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ2U250Z3F6dmJDdlNPS05LOUcxWE1QUkhvN2Ixd0lFUmVDLVVydDBTZld4azFBYjQyN2I0QXZzRVJiVmtCVTRoMnc0S0xJMFBhd3NJV1pQaHZybHFobzhtbnhxMXR5c1VHMXhzTHc3Z1VhenM9
"Definitely EMNLP, if your paper is NLP-related",r/machinelearning,Z0FBQUFBQm0yeGJ2TmNvNFdxSEhIdTRfMHBNc3ppdDEtYVNPLUI2U1BlVndkT19Qamdrcmdya1JSS3cyMnZXb2I4NFRGMUtzYXlkUG1DOXozc01kTDJVNTB3bFNwRkpDNGc9PQ==
"Indeed, scientific publishing is increasing exponentially in pace. Every day I receive spam from predatory journals and conferences. Moreover, there are paper mills, my colleagues are also harassed by people who will write papers for you for a small fee. There was a guy who was very insistent that he proposed to me for 1000 $ to insert my name in the article that they were submitting to a prestigious conference.",r/machinelearning,Z0FBQUFBQm0yeGJ2U1RLTUVfRy1aNWRnOHhuVnlIZWhsbHA0YlNlUElGblhQUWhkQjFiVWN5aHhKbEUyR3ZnSmRkQzFoaGRUU081c0duVm51bEpDRWFXcFBLZVpZWDVROVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2RlFoeTYwNWx2bzdHbWpETW12c09nLVJFOC1zb09BWHkyeVhlT3hPclltbWFKNEo1YjlxZlF2RWhoMFhiNEVGNzRGam1Ta3k0Tkt5SG55NDZBOWF5LUE9PQ==
"This doesn't make any sense to me. 

Let's say your goal is to explore a project that you want to be a conference paper. This project will be something like a research problem or question. 

First, you need to nail down the rough idea to make it more concrete, maybe written up as notes in an overleaf doc. 
In this doc, you may draft the paper abstract to understand the project's scope, and then you understand the relevant literature and theory to implement your idea.

After that, you focus 100% on implementing your idea, derisking the idea as fast as possible. This process may require iterating the idea and exploring more math and literature. Once the idea is derisked, you go full steam ahead, implementing additional features and running ablations and other experiments with a detailed logbook. While experiments are running, you may expand your notes and fill in the literature and theory gaps. Then, when the experiments are finished, you turn your notes into a conference submission, and you can tidy it up where needed. 

It makes no sense to me to stop the experiment phase because you have an allotted lit review time. In practice, if you have overlapping projects, then these phases may be interleaved, but they are very much project-orientated.",r/machinelearning,Z0FBQUFBQm0yeGJ2Y3NobmtaYkhIczcwSnZ2VHZNczBKTUpQVlVCT0gyUF8wV0RhVVpTY2hWY2xpcHIzTnNueUhCektIeEM0SUFEMG1lSXhKcWR3dE51cFdLUjNsMTNNUXc9PQ==
"is the participation grant the same as the financial aid? very surprisingly, although minority and first-author student, I wasn't selected. really disappointing to see",r/machinelearning,Z0FBQUFBQm0yeGJ2NldiOTFwSGd6OXhHaDFEMm5Ma1pBVllwTkpaeWRtQTlBa3hYMVFGTE1HcnNBRVRMVlNuN041clduRWszX1owb2xGX1JRSy1qWnFZa2tLbC1SZzV2WXNuOWpJOFZpNHhqZG9nSjBwTGRsVlU9
"Don't try fine-tuning, the model will become terrible at what it was not explicitly trained for (catastrophic forgetting). Your best bet is to use a system prompt which you tune by hand until you get your result.
If you still have access to the bot, there is a good chance you can manage to get it to tell you it's system prompt by playing around with it. It is unlikely it was finetuned",r/machinelearning,Z0FBQUFBQm0yeGJ2MTdxQ1VoS3VBOHhaVXowdDhzdDhJa2c5M2gxR24wNmItR3YzOUo1cnRzRk1udjM3TG9ZeXFuV1Z6V0htd05LYUFOdmxmWVpmVDBlUTd0NWI5UkE3Mmc9PQ==
"LLM observability tools provide an SDK to log LLM calls from your code or an LLM Proxy to intercept requests. You can use the SDK to manually log inputs/outputs of LLMs and other steps like preprocessing or retrieval from a vector database. Some of these tools also provide function decorators in Python to collect traces automatically and integrations with libraries like LangChain or LlamaIndex through callbacks.

LLM monitoring is about collecting, visualizing, and setting up alerts based on general metrics (latency, tokens, cost...) or custom KPIs (evaluations). You can create evaluations using functions you write yourself, human scores, or using LLMs as a judge. You can use these evaluations to validate a new model on a curated dataset for example (offline evaluations) or run evaluations on production runs (online evaluations). For example, you can use an LLM with a specific prompt to evaluate LLM generations and ask the LLM to judge whether the generation on hallucinations, toxicity, context relevancy for RAG applications, or any criteria you think are useful.

So far I have only used one LLM observability and evaluation platform, [Literal AI](https://literalai.com/) with the Python SDK. But there are many more: LangSmith (from the creators of Langchain), Langfuse, HoneyHive, OpenLLMetry (based on OpenTelemetry)...",r/machinelearning,Z0FBQUFBQm0yeGJ2d2o1cEp6ZG1ZTlg3aG5HUjBUSXd2UkhDcWpxOWVhTDl3N3JYQTZCa1hxdmVLa1RZZkhod2hFUGJualFmaE9jNVlrRXpUbEhQak0xcDBHVkxSNmY0MHc9PQ==
"Yes, unfortunately, I also did not get the grant!",r/machinelearning,Z0FBQUFBQm0yeGJ2QkF6b0UxWUtLbHhJQVdQLWhXTTNnRUpfWHE4YjAwaXBXenB3cDZLamc2LUx6XzdpQkF4NTFTTnVSWHE1Q1BJYV8yM1hrTDl4Q1AzcVgyaVhYQjFFbWs5Sk5HTG5pZDI2cTNsemhZR3dHTGc9
isn't it weird? I would expect that at least the registration fee would be waived for the students presenting at the conference (even if accomodation support is not possible). curious: are they making profit out of the registration fee?,r/machinelearning,Z0FBQUFBQm0yeGJ2UGxDbU9OYUY2ZEZyNVFiUS15SVJ5UjRoQkM2S2F5czJxSDdrOHJmeTNzSGVTM2ZEYlN2cUJMVUlDWG1nbU1XZkhKOGw2Sk5wYklLWUU0aFJ2MHBGcHQwQWJXYkdiU2pDVGRwRWlUcXpqNU09
are you first author?,r/machinelearning,Z0FBQUFBQm0yeGJ2UDVhVDAwWV9UUzh1VU80QWc1NnlCOUwtaTNRZ0NRQ05oVnh2X21XbGhMdURLX1oxMG9IMTd4SHZHMkVnMlB3UXd4WEI1dDhtSVRtVGdES01QSG9XWkFUalplS01VRjNTWkxNSE1NYWMyTDA9
nice job. I found someone that got good result on squad task with mamba 2.8b model,r/machinelearning,Z0FBQUFBQm0yeGJ2TWpoQ0xQQ1lFNUs4NDFFb3RpUTc1NkNQWG5PajhDZU9ULTB3WWdiVF9EV0RROERfZjRCRGRubHhXVGxDV29sSDU2bC1IY3UyMXlJVG43QXpVek5PdlE9PQ==
"oh

oooohhhhh

Now it makes sense why so many scientific papers are just rubbish.",r/machinelearning,Z0FBQUFBQm0yeGJ2ZmhjeHN1Zjg3VWMtVWxSdnBER294U0FfcS1lakx2V1VFZ05IZGNPM2xEYWE3NVg1N2ZYU29vM1pDd0YweDBzNGRSWjdRVHBUY3Fza1RBeHR1VER6aVE9PQ==
"Ultimately it is true, because our biologic neural intelligent system doesn't has MatMul function.",r/machinelearning,Z0FBQUFBQm0yeGJ2bTRQeG0tRGI0azhNUVZvbHN4T1Y2SU9oYWw5czZZS2dmMHlZdXUydkpJMjc2NnppVzVZVmRJT2M4V2ttb3Y4V2NEWXJvM1BSY0h5UmVNSlg3TmIwaUpPQ1dZTWRuMWdaaEswOHlaLW9yUzQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2QTZLTHRZb0V4eEhzd2NqOTZieFpLQkRtaUhwam9NSWJSTk9JLXZMMG4xeFRxVHE1bFZsYlJldGplTDZDSnVEbFh2a0o5VkpHdlFBbTZrUDlwYVROWXc9PQ==
"Wow, after an initial read this looks solid. I wonder however what the caveat is. It looks like in the overparametrized regime some things just don't matter anymore. Transformers have a lot of wiggle room when it comes to pruning, quantization etc. Maybe being MatMul free considerably decreases this wiggle room!? Or performance on downstream tasks sucks?

EDIT: Also props for showing off an FPGA implementation which is where MatMul free deep learning could really shine.",r/machinelearning,Z0FBQUFBQm0yeGJ2Um1PN2N6dDZ3OHVHVGNWOGM5UkhuNWNqeUs4RHJUT0dEZW8wbFYzNnZucDRqYXFPR3JJenB3MEZGT05jUW84QktEcmRka3paNVFvU2laZGZJTTJLN2c9PQ==
"Not just pairs, you want a way to generate entire conversations",r/machinelearning,Z0FBQUFBQm0yeGJ2bzlJdjU5UFpxRko4VW9rZ0tHWERHRF9LMmhjUV81WEd2TVNPdUxSWTRVMnZiMFVWNHozSTJvZ2RfSlNnVk9KaXpIYXBvR0JwY0t5Njg4UmlSanJMQWc9PQ==
"Yes, I am the first author, not sure about the reason, it's my first time, and I am not sure how exactly it works or what are the criterions taken into account!",r/machinelearning,Z0FBQUFBQm0yeGJ2cE8zN3J0Q213a0RHby1TT0w5MFN1NVJmenJaWENlLWpGS0I4Wnl3WnlxeU43NktSTm9JT29vYWtoeEVjaTA1WDNMSFlMQVpNTVZFWmFoeFFYVXoxSzRwMjIxQXRhXzNWNjZ4YXRKQy1vV0k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2Q0xoSy1SQUFfVjFVX2dXMGljcjhyMHF4UGREZFpyV0FTek1YaWIxa1NycHZPQ2Jhc0JOa2s4NFFHTVlXRUlaS3B3LVU2SmZNbVdqOGRRRksyWlpJU1E9PQ==
KDD is a good one,r/machinelearning,Z0FBQUFBQm0yeGJ2Nk1LT2JOektIc0xKQmFZb3V4NDktb29GcUd2NlMwVGZkeFF6ZnZlUVRSZmpnS2F4OVhieUZzRkpVZzU1Skg1SEJ3S09oZklyZWR5X3dfOWE2OFhwZHc9PQ==
Why are they removing the “role play” function? Sounds like it added value. Is it prone to attack? Is there no mechanism to replace it?,r/machinelearning,Z0FBQUFBQm0yeGJ2SzFyWGdzY2syWEgwY1M4cVhWXzJUZVRjRFVkUmc2dkdPNWZ4ZFdTM2NTMW5JUVEybS00c0xJel91MERzVWl1OE1NUUxCT19OVVFXdjN3aG0zZXFsWHc9PQ==
"exactly. I am also first-author, student, woman. I had published at neurips, iclr (as first author). at neurips I got my fees waived and if i remember correctly \\~700$ dollars. iclr was online but I got the registration fees waived. really weird and unexpected",r/machinelearning,Z0FBQUFBQm0yeGJ2cUgwblBTYnBxYm8zbFZPdTd1blllZVR4VlU3NlVCdHJudlVyT0g5QXp0YVh6Z2ozdlJpdTFpbE1Fd0VPZlR5NVNKQ21TX2ZrYkd1R3FpbzdoR2Jpa1FDYnpiZ2J4bDVuV1F4Zk82YVhTNkE9
"Attended it, great chance to network if you know exactly what you are looking for. Turnout was around 5000!",r/machinelearning,Z0FBQUFBQm0yeGJ2ZWN3QWt4ei1jZmRQTnpZaUo3T3BpN01NUTUyNzZBeFlPcWdMRWU1U2pDWXpvMGwtOVFPZUZSZXc0Y01nbXA3MzdyU3UxNTFOMTkzYlZLSGxHc1hwcTdadS1BTktsSnBmV0hIMXNuNUFxdGM9
"I think they had, at the very least, to waive our registration fees (at least for the students who are presenting). really disappointing and discouraging",r/machinelearning,Z0FBQUFBQm0yeGJ2b2FlZkZfQzN2WXEydVV2eV90dFdZU1FVbm9CdmtFb0c3YlZ2dTE3VlBfZFc5dkljNk54RWxMbVRWdDBfbzRUMzF6ZXVwdzdXc3pLWkVRbjM4c0xTSWZCRXNxRWd1empRVV9lbjEwVEJUUDA9
"Spending time on maths and literature should be done like course work,  like few hours per week with concrete outcomes. For literature review, outcomes could be checking in what capacity your current idea has been tried and what were the results. Similarly for maths, stats  things like ability to check proofs, solving related problems on your own etc.

However, major chunk of your time should be devoted to ideation, implementation and quick results in that order. Review your approach regularly  through peer feedback, meeting advisor etc to pivot quickly if things are nit heading in good direction. You will fail 100 times to come up with 1 success. More you delay this process, slower and outdated your reserch will become.",r/machinelearning,Z0FBQUFBQm0yeGJ2dnhqYm9DVlAtUnZVN21keUlKT2ZLZ1pKcEtkblJwUU5GcVNtX0E4RVlidWhnSW03N1FGZHdud2JSU2F1VlhaSi02M1o0cFhqaWJNR1VYS0F3WmdiSktPQk9YUG9kbUJ1cmVlQjd1NkNDUE09
"Yes the Visa process in itself has cost me around 500 $ and as a PhD student, it's really frustrating to bear all these additional costs!",r/machinelearning,Z0FBQUFBQm0yeGJ2dHVVekY1ams4WGxlVmNpRlRqd3l5OE9BSlVTUHUzY25rLTRqLWZUZnQ2OEtqdmIzU2tZTVVfbnF4Szlrc2pYakJ0Tng0LWxkREFDRjRSVFBBOEFJVnhEWG9kRmNTVUJWYnQwSG9FMVRfdVU9
"I did several times the reviewer (of course for free, sad story) for conferences and scientific journals, and you cannot imagine how many garbage papers we prevent from being published.",r/machinelearning,Z0FBQUFBQm0yeGJ2c0h6TFVKQjl5NkZOcGE2QnVxd0pTbVVxZXNpUmh2Q1p5X0h5amw1Z2xhOTR2UUZ3T3RfcGFVNW54MHZNRTk1Y2pZZnlKa2ExcUNMZW03LXgyUzBET2c9PQ==
"fortunately, I don't have visa costs (I am european). I understand that accomodation grants might be limited and conditioned on the sponsors. but the registration fees is something totally in their hands",r/machinelearning,Z0FBQUFBQm0yeGJ2aEdZYjkwbVF2QkVLbHg4MERTTDA1RU94c21Ha1VrSmFnRXNjYk1YcXRWZm9ja1dma1pST0FuXzZ6NjhYaDJPbHdBOTExMmsxWm14RTFmMUVqanZJZHVkWVdqMzB4T3RILTlxMkkzdUljR0k9
"Same situation here, didn’t get any support",r/machinelearning,Z0FBQUFBQm0yeGJ2ZEE0WW81aTRwN0s3bHE0RHdnaDB1bFVQTHh3cDVLQ2tfYmJUcW5rMm9kV2ZPalJjdy1OTlJ5cEltZkJyUGxNVHNjQVBzUDhCYlRhRC05NWtJUmFHVXc9PQ==
"Yes, I agree, I guess everything has become a source of making money!",r/machinelearning,Z0FBQUFBQm0yeGJ2bnpVeHVtV0tranB1TXNQTkxrSVRNczlodmsyODQwUXctSlVVb25wa21MWDV3dGhFRmllRnV1dGk2eVRmWkZmaW9sSlczSVhkd052aGJjazhiSHdmVGtUOE0wdVN3dkZCVFRodTR6dUxKbnc9
"I wrote the system prompt myself. The issue is that this particular model had a ""Roleplay"" functionality that has been removed from current models. The Roleplay function is essential for a jailbreak that gets sassy responses from the human-like bots that openai offer",r/machinelearning,Z0FBQUFBQm0yeGJ2X294VlBVRkFPN013OWZScTktanVOa21hdVlsR21DdHRxZ0FVdm1pYWR4YUtvTXVZWmdsUWN6WjJtQkJNVkFQZ3FQc1dsZlFWQ2hYNjVBX0lOM3d4NDFRRWxhVFpPY1ZNclJ0X0tqV1FzWGs9
"Yes it was prone to jailbreaks and that's why they removed it. In my opinion, it was this that gave the chatbots the ""soul""",r/machinelearning,Z0FBQUFBQm0yeGJ2QnhRVG8yOHNHRGtTNGEySmlmdGFfcEJUQl80QTd4RUc3WEhVcExNTUdvc013S2hFUnoySC1pMUVXR01saUd3c2E2UHhpTUlNd2s1RnFDaUNrdmtSc3VBQWZMVEg2Z2h4ZHVad2hMbm5qQk09
This was my worry and this would probably take too long I gather? I kept a bank of all my interactions in text files so hoping would be able to use this in future if I cant' get anything done before the deprecation,r/machinelearning,Z0FBQUFBQm0yeGJ2amdJb1VOV3FOTERuOUg1QmZUWThYbW5VamF6bHdTT1ZtdjgtOUZPTXBTYS1kcF82Um5yNzNFckNiSGQ4TFRrSVoyVThjZW9UOWZQa1lQMVAtTWtCdkRSMWxOZGpQdHZ1ZFNXTnBQQlNOdEk9
I am so angry to the point im thinking to escalate. registration fee waiver for students presenting has been the default in my experience,r/machinelearning,Z0FBQUFBQm0yeGJ2M21NNmc3OVJ6Y0Z3bk94LUhzT05tbWQ3N3d5LXFNQm15SWRzTW45b2RtM1lLQ3VJMVlkYjFOdGxPZF80N19jTVAzWjBYR3lrZmFTbUQ4aGJoa3BHaDEwU1Zoc2k2TGs5eFhoSmM4Z3RUSXM9
Check you are doing the same preprocessing steps in your data for your test images and your Python-generated images.,r/machinelearning,Z0FBQUFBQm0yeGJ2VUlYTEx5Tmc1aFk2Z0NPRTNtcTk4NWFEbFVsQ2Qxb3dHYnd4Zlhpenk1ZHBlMTZlcWF4OVpEZ1oyRE4td2xNM284eWEyUWlUUGRLNnd5bWZkMzZfQ1E9PQ==
"That's so untrue. Read papers in mathematics, chemistry, biology just to name a few and in none of them will you find such a chasing after experimental results to outperform ""state-of-the-art"" models by 0.001 %as you do in machine learning papers.",r/machinelearning,Z0FBQUFBQm0yeGJ2aHJLdjhFd2tkeXNVOEhYQUkzWDZyQTQwclJVUlQyanM4VnVQd3loVWNkS0ZnMjBGR2dUb1N0cWFHd183R0RjNmI0UEdQc3ZYUmwzNlZyeTgxVkZaa0tyYWlFa1l5TVhRcVRHa1BtbkVtaWs9
"I have been running Llama 3:8B on my Acer laptop. i7 13700HX, 32 GB DDR5 and NVIDIA 4050 6 GB VRAM. running without an issue. the 80 GB version however is painfully slow on this configuration.",r/machinelearning,Z0FBQUFBQm0yeGJ2VU9pT0tPQ193eHk4cnJzcy1DeTc2VFduQWQwUVIwSUR1VVVIWVJVWkJON2c0VXZjaXUtMmEySXp0c0IyYXd1MDdxd2RmYUppbUtmTVk0Nks1eWF5MGc9PQ==
Thanks for sharing!,r/machinelearning,Z0FBQUFBQm0yeGJ2bTJleGIwUGU4al9oVE9YY3YxbGRsSjNlWXpIakZIcnJ1UmNzUmJYWXJETnVtVWtXMjFIS3JoVDg5eVdYM2c4T3J2cjIyMUlsbkJfQ21zZnNaRXJZUnc9PQ==
"Andrej Karpathy's videos are some of my favorite on the internet, and I strongly recommend anyone. You won't be training LLMs from scratch for a client most likely, but if you want to understand the current cutting edge that most companies are interested in, that's the perfect place to start (after you have some experience executing a deep learning model pipeline in python, that is).  
  
His videos don't really focus on the maths which is why I didn't mention them, rather act as code-alongs with fantastic context on certain steps throughout.",r/machinelearning,Z0FBQUFBQm0yeGJ2NjdrLTZIN2Q4eTExSkRMWTlCeXhBaHZGb3N1Z3dyVVNJbV9WRGVRMTJ0QTZjYzRBWFJwT01BNVFIZ3k5YXpramlrdTE0N2FzaGZDbkcyT0xGalU0Y0E9PQ==
"created this post: [https://www.reddit.com/r/MachineLearning/comments/1d9h8z3/d\\_icml\\_participation\\_grant\\_decisions/](https://www.reddit.com/r/MachineLearning/comments/1d9h8z3/d_icml_participation_grant_decisions/)

hopefully this will give us better insights",r/machinelearning,Z0FBQUFBQm0yeGJ2RUF6NWY0aHYxZ0JIMWY5R0Y4OTRxU1BXeUstVFV3U1JtaW1xdHpXeFBoOHhiWkpTVVlzRlh4THFlRkpiRlJnZHJDd1F6WGdnSU90WHZoTU9WaWI1Z2oyV2VEbVRlSlFSekdfNTZCVE92b1k9
"created this post: [https://www.reddit.com/r/MachineLearning/comments/1d9h8z3/d\\_icml\\_participation\\_grant\\_decisions/](https://www.reddit.com/r/MachineLearning/comments/1d9h8z3/d_icml_participation_grant_decisions/)

hopefully, this will give us better insights",r/machinelearning,Z0FBQUFBQm0yeGJ2RXZ2T0NUcGNHRENKcVVudmlzeU9pSC02TVgtY21HaWEwLXZoREtfZ3ZPY2NMOHY0ZlAxaTNzeDY1MmRUMkpQUUh6aWlOSjEzaF9kcFFZSTFnUWVjMFlnQnd4aG4xRGpwVEE2M1Y3V1Z5bWs9
"I am creating this post:

[https://www.reddit.com/r/MachineLearning/comments/1d9h8z3/d\\_icml\\_participation\\_grant\\_decisions/](https://www.reddit.com/r/MachineLearning/comments/1d9h8z3/d_icml_participation_grant_decisions/)",r/machinelearning,Z0FBQUFBQm0yeGJ2eG55bzlYQWhhbWktQ2NpWTRIYUlRZ0pyRzloMExzMTdtSW5RbnNYTGctUlNJc2d5dW5qX1ZidVhDTGdERENPVkVfcHBOV1pVQl9sYTFKT2VkU2R1NU1IdWdDRjlWYlVsZnpzQWxlZFYyLVE9
"Thanks! I'll share it on X, hope it works out in our favor!",r/machinelearning,Z0FBQUFBQm0yeGJ2dEJFWmZueEMwRkk2X2tjY1BRUFBncVF4ekhCMm1GaE51UVVEM1dmREJRcXJ2cUNkSVNyX1h4ZWtrNi03c3ZZVW95elFQT0o4Z0dadGZPRzBmMUNKRnpNLXhZSGxwXzNtTm52NkNBRHdrNVk9
thanks! that's great.,r/machinelearning,Z0FBQUFBQm0yeGJ2Q0FaeEpkWEZNQ3pxeGhFQ0lRSGhlS2xpdEZzLXYtSTJ0TS03SkU2WGlCNVBKUEUwQ1hBcXdMTUdSNjREZnVBVXFCODB5UWVIdnRGVnBBa0Z4eENTa3Z6cG13by14ZHhxckk3ZjRKdFdSU0k9
"Right, just like biological flying machines (birds) don't have jet engines, so we don't need them.",r/machinelearning,Z0FBQUFBQm0yeGJ2Y0VIZDdIWC1QOWRNSjBDRlBoMTRqV21VNkdhZXkwcFV1dnVJSVFtT0FIbWdEbTFidDIwR0doZ2hUZ0pqMzR1ZjFucTJRSFQwdFFqeWhnWjJYNHVxSlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2M3hNM2Jxc3JoNWZTcVFjZlREeUZvaHR4cmF0SmZjcnV3d1VrQ0VORkNTbDRuV0JLNlFTNkdBZnVLM2prOFNPbl9takROeDJSTmRxVFM0ejBDV2pFZ2c9PQ==
"I wouldn't despair, in all likelihood you can use what you've got for few-shot.  If you think a human could read it and imitate it, IMO you're in!",r/machinelearning,Z0FBQUFBQm0yeGJ2Z0hDb1lfc21iZDE2T1hRaF80eERyaTZrYl9KOFR0MGtIVW1tQ2I1WTl2RUhaTW9NTlhOM0lQMTlSaTVkZi1XN2pJYUpILWdRQ1BmS2JEVFZ0YjNwbVE9PQ==
"KloudMate is cool, uses OpenLLMetry [https://docs.kloudmate.com/llm-observability-with-kloudmate-and-openllmetry](https://docs.kloudmate.com/llm-observability-with-kloudmate-and-openllmetry)",r/machinelearning,Z0FBQUFBQm0yeGJ2RjZvZHVqSl95RWlaX3VMV2lVaWk3dWVUVWtjUFN2dDJYb1V4T1EtMDdBUTNmTWN3ZVdSdldqbjBhYktJamxIRWpnMnBXTkJyd1M0Y0tjcVdCZE9CQXc9PQ==
"I don’t have a book for you, but I do recommend you explore Kaggle. They have learning resources and free access to a lot of datasets you can experiment with",r/machinelearning,Z0FBQUFBQm0yeGJ2RVpISlQzQ1ZIclJLdjQ4bnhIM3N2dXpSWDZnVm1kMlJaNDNuaHNsdkVTemhRdnl0QzVBM3V1WWdjeXhuYXlCTGdMZ25faE9KTFJMNGh0ZURZdEVnRXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2Vk5oc09KeExBY3Z3Qk5QWTlEQzQwMmlWYTdGZ3NwZzU1M2wtVEMxLTVQUXc3LUlpZ09RWnVfS3NEaVJNLWNjWWNOQ29kWU1lemJXNXVlUTE5cGtNVGc9PQ==
"Yes it does. So when you go to implement it and get different results and publish your findings, it would cast doubt on the original paper’s results. That’s how the process works.",r/machinelearning,Z0FBQUFBQm0yeGJ2cE9SZm9hWXRSSVlLLXVjM0xpZ2tqMUNBNkxKRWRvR0hWTTcyTU42UE1WLU1wM2NqOUF1d1JhNDJBa1JLczFFVEF5SUVqRS12QUlqTTNhY0xKa216Smo0cC1RREZ0MEs1VjlUSV9lSWlzUXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bzNrVE82enhMV2lYSWp2Wm8yTU5WYXBDSzk5SlBRdVVxMTdqamJzY2F3SW9IWmJsTmJwQWMyLTNLcHdJRGREUGtsc1NUU25LZTB6NnVUazV2Z0l0aFE9PQ==
Interesting. Thanks for sharing!,r/machinelearning,Z0FBQUFBQm0yeGJ2d2plZFdFZVQtOHBSRGUzOEhvTG5aOTFoVy0tSWdmbTM5UTlGSnphdklFeFBaMTB6NnVLUXdfNlpKTXVSalhoeU9wOVJJcl9TTkdfOUZLWVZGZHRyTDdCYk1ZMDgxbUEyandsXzdlUTd0NU09
Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJ2ZGNZT3UxQ04xNDJaWTFac0hjdTE5dkN1MUhLa3U3SG5OaVR5Z0gwMnBoeVJ0TUFPQVVhN3JFUmdKclFNTVYxRE5XOFVJQWFIa0tjODRMU09OYWljZnc9PQ==
I actually think biotech is one of the best places for ML and there are lots of applications . Auto segmentation and finding patterns in medical images just a tip of the iceberg,r/machinelearning,Z0FBQUFBQm0yeGJ2cm1rQUt6RFpfb0k4OUlndjRTNnoxOGlpdkN3Q2ZpRXgzQW5qOEx6TzUySWVzbHljTlV3RTZBWEZBRUpuWnJkTlNabWExZTBpdHBZOXo2R2RFU205dUE9PQ==
Would love to know how it goes. Seems like an interesting dataset.,r/machinelearning,Z0FBQUFBQm0yeGJ2YXFybUJxeG9GeTJySHFzTjFmRkdZZ2ZkX1M3QUJhdUE0LVNxNmZTSFdvdFpJTmNXNi1fVlpKTjYtUklHbE44d2J3S2hBLVhLQldhWXA4dEpBWExXeUE9PQ==
Thanks for the suggestion. Will look into this!,r/machinelearning,Z0FBQUFBQm0yeGJ2SVpuM0lteXA5bzhNTWZFeFIzS2NzbEdHQXZXX3NlLUlQaFAyVkdiajd3dzE1b0pfTUJIV1BJaTFhQ1g2VE5aajdBREpCV2JiYno4aDFNbVlHSVlscWw0Tl9NVl90ZU8zanRJeW9QWk9vb1E9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ2VmgwTUl0UlZiODF4SjR6d29qbkVmdmtUZEVVYnI4cXlCTldfVnRwT2xsOEZoZkVnTDdnWVFlWnVxOXp0UjdpbjU2NDc0c3pINTFLZUFqbU5jTzBuQjBES0xMSGd1bnNWTEc3bzRZTVNpQjg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ2SUpQMktCWGt0TjIxVjMzaWFGaWVOYjRRbjlzUkkxYnlEOXFpemVLLTFmQlBBLTMwWU9Ta2RuZHcwNGJLV3FjVnYyN25KbTBjbjR0d0dicWNDYTNVYTN2NEg3bWwtNzBXVEVxUFZta2Ffcmc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ2bUNhbVRKZ1dkWVJIdWl3TllPU1NIam8ycVdwcEo2QmhIMlJnNUJhX0FIV0Y2MGlraEtmOG9EcVNESGhFSVZrV3JuMXpmUTg3aktVZ2IzaFlVLU5PM2dqa3lnY1RvMkFGb19xN0F5d3Jwd289
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ2VldzZ0pGQ2Y3Nnl6dTJUd3B4UDAyU1pmajZZaTlDdjl0WUNvSjZUQVBqNjBxdGJDMTRoN2xsUm1faURGdUdRdDFvOU1nMGE2Q2xrOHltX2V1ZVVzQ3p1WmpXX3hTcTF6RHB4dVdtZVg3ZW89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2TUxwSVdXenAwVkhqejhNc0dzdmZZNS1oTjNpVWh5TlFCWWwzOV9PMTNWRVEwaUZ0MTNpZ0FQa0M3Sk5lTDRzTEJaYTZKZ3ozQ2xxQXpyNnk0SFpfSUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2M24zOXRRcUlHdXdtRHBRYlJweVZjY2ZydTBlQ1NyV2toOHI1VXZWWGptYi1rYldWc0RJZVdaM1hlZnlKNGtrWUlmdUE2TTRBdUdTT1QyQ1U2LWxCa2c9PQ==
"You'll probably be interested in this paper:

[EMP-SSL: Towards Self-Supervised Learning in One Training Epoch
](https://arxiv.org/abs/2304.03977)

They get quite nice results in a single epoch partly through data augmentation and partly through using a lot of (sub)samples from each data point during self supervised learning:

> We show that the proposed method is able to converge to 85.1% on CIFAR-10, 58.5% on CIFAR-100, 38.1% on Tiny ImageNet and 58.5% on ImageNet-100 in just one epoch.

EDIT: also you should be sharing your *test* accuracy as the final accuracy, not your validation accuracy. Because you used the validation set for your simulated annealing/model architecture search, it's actually training data.",r/machinelearning,Z0FBQUFBQm0yeGJ2cEhabzkwd2ZWV0pqNWMyZ0MzUGJKM3NsMG1EQ3ZPZGxPcUpvaktabmoxam0wOUw5NXRDUXVJZk96MkhjWHp0elVxQWh6cU1OWW9TYmR1MHhRdm1SbWc9PQ==
"This was a great read! It makes total sense that order would have a big effect.  
  
As a lay person, I'm surprised M is typically only 16. Maybe I'm thinking of HNSW wrong, but it seems like you want to ""cover as much ground"" as possible per layer before you have to descend to the next layer, and a higher M should help you do that... since (in high dimensions) the direction you'd travel in to get to your connected neighbors is usually roughly perpendicular to the direction you really want to travel in to get to your target, it seems like higher M would help you ""get lucky"" and actually be able to travel in a direction more aligned with where you want to go.",r/machinelearning,Z0FBQUFBQm0yeGJ2emo4azJjQWpVam9kMENqMF9wNHIwOUVVTjF1eFpHTUdrUkpPSi1ON0VRT0RmZlJQRURXS0JzSzF3dzdkQ2FjSFRsSGoyOVdHMUN0SFFSZnNQdnRmWHc9PQ==
"Important note: most AI is not bringing value. Most of the headlines you see are either midjourney, openai or Nvidia that are making a lot of money. Otherwise you're hearing about companies who *raised* a lot of money. AI is mostly hype. That doesn't mean it's vaporware it just means we are in a dotcom-like bubble where were trying to figure out the real value by shotgun blasting all the ideas at once. Most of these businesses will die but some small subset of them will be incredible.",r/machinelearning,Z0FBQUFBQm0yeGJ2MXlLUFREdFVheU5sXzlqdVp2bk9TbjB3M1FNeGpsajBER2dLQU9OQ1RBbUtlN24zREN4bldBRzdaOEN1ZkFMd0JoTmJwdm1OeDFTTzhHTmFLbzZHV1E9PQ==
"Thanks! That's correct, just as simple as that. I tried alternatives such as K-Means and SVM, but they did not improve the centroids for my specific task.",r/machinelearning,Z0FBQUFBQm0yeGJ2N3UzSk5pTmJWR1RpeW5fRzZzOXlQR1VOQlR1dkt5Y2NrR2tNdDYycHgwQW1KVnFMUGY1anRFel9ZVVB6Tml2ZzA2RGZBc3Y4R3lTcm5fV1dnYXItTmc9PQ==
"I think, for a first/second year PhD student, focusing on the basics (math and whatever) and learning the literature is never a waste of time. A lot of people end up doing shoddy, pointless, or half-baked research because they haven't accumulated enough of the fundamentals to be able to know what is worth researching and what isn't. Some people even produce ""research"" results that have been know in other fields for decades, because they just don't know enough about what they're studying.

I'd drop your 3 hours dedicated to developing research hypotheses altogether and reallocate that to literature review, at least for now. Let novel research ideas be something that comes to you passively as you read other people's papers.

As you learn more you should start to have research ideas that other people have already executed and written papers on. Some students find this frustrating, but it is actually an indication that you are starting to understand enough that you can know what is worth researching. Eventually you'll start having ideas that nobody has tried before, and that's how you know you're at the cutting edge.

Structuring your time is good but don't get too attached to planning. True research (as opposed to development) is inherently unpredictable; you'll have long periods of apparently little progress, interspersed with brief intervals of incredible progress that occur when you figure out how to unravel a new part of a problem that you've chosen to solve.",r/machinelearning,Z0FBQUFBQm0yeGJ2ajhTLVFxanZBS2hjdmRKYVNycUtIRXFLMWNvTi1Cdm1IVDJTT2VLU2U1R3ZvanM1NDk1bENIN1pGUlJUeElueWpBUkl4VmZjWTJOV09KaW9LeUVrVnc9PQ==
"This idea looks interesting, but the accuracy experiments leave a lot to be desired. Why are there no perplexity numbers? Where did the ""Transformer++"" numbers come from? The given accuracies across all the tasks seem very bad, e.g. ARCe has 58.5 at 2.7B but Pythia at 2.8 B gets 64.7, Mamba at 2.8 B gets 63.9, etc. This method uses a highly quantized ternary neural network: why is no empirical comparison done to other quantized (e.g. binary or ternary) architectures in the literature?",r/machinelearning,Z0FBQUFBQm0yeGJ2ajVfaFNUelhmOW5Qbzh5LUtYTlRON09jR3dlYWRoTFdBTnMyM0pVZV9nTlRBdUtxYmY4TVA1RHBXa0Zva2F2TnFvVFBRQS1VNEdFZlFOZlpMUHZsTWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2WVlwZWNZQWdTQ0FmMi1DblN2RUlrZk9CbmwtZ3RLakozd0ZmY0dOT1Q5VXRBVGlHSmktTS15RzhhUHYyRGNyODZkMDhNalNJSWk5Ri01QXhJdkdWQWc9PQ==
WACV. They have an applications track. Great for novel industrial applications of existing computer vision methods,r/machinelearning,Z0FBQUFBQm0yeGJ2UjFnQlpGYUtWMzdUZGRuVG13UEZKVzJQY2t4NURYbHVOQXZpTXNtMjJkOEdMQjNqbThJQUNtNk5UREhSTEQwcDB4eXdvUmFSUlRwTlNPZG1ES3Y5MGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2cVAwWGwyT0doWG9qQ09ONTVwRF8yVXNuQmtpNVdCWE5CMjlodTVNNnk3WWsxYnVndzVmTWJWaXhCZUpGZnFqM0w5RzMyT1hOYnRzbDZkRlhsbmUxMVE9PQ==
"Unfortunately GRU not attention, so not usable for actual reliable retrieval or long sequence.",r/machinelearning,Z0FBQUFBQm0yeGJ2Rng3aVc0b0FweTRuZmk4RjVSN09jcXNrSkl3S18wRXBmc29tb2VOaWd2VzQ3LXBhZjdYUHZENXZkeEE0cENXc2cyUVRuS3BZNVVSZ2psalV3RVNTWEE9PQ==
"Both approaches work, with their pros and cons, but it all boils down to what metrics you are trying to optimize and what business goal you aim to achieve.

However without a better understanding of the business context, your suggested approach does seem like a more natural fit because multiple faults can occur simultaneously. Also in terms of data utilization the one multi-label model can be more efficient, since it can leverage knowledge gained from other faults to identify rare faults for which you have fewer samples in the training data. Finally, managing a single model can lead to reduced complexity.

But why not just try it? If your boss is prepared to train 50 models, then training one more shouldn't be a problem. As a pilot, you could make 5-10 separate models, then make another joint model for the same ones, to see which approach is more promising.",r/machinelearning,Z0FBQUFBQm0yeGJ2TEwyU01zWWx3aVRQdDBVbjQ1OF9GbWxselI4ZHBXYzB6d2pacEdFcklucG5uMEs2QUU5d3VKODE5SjBuSmRZQXNqQnpfRjNsbWpKNW5hMDhRTjF2b1E9PQ==
"The key to success is low expectations. Nobody leaves an undergraduate program as an elite with a profound understanding of anything.

You should accept that you won't understand the contents of most papers. At your level reading papers is mostly about understanding the structure of research papers, identifying and understanding their goals, and understanding whether and why their final results show that they have accomplished their goals. If you can do all of that then you're in a very good place.

Also know that part of the difficulty of understanding papers is that a lot of them are genuinely not good. This is especially true in machine learning. The logical justification for research methods is often hand wavy or even just wrong, and most authors aren't good at explaining what they've done. Results are frequently contextualized poorly, incorrectly, or misleadingly. A lot of published papers (probably most) are mostly pointless.

FYI if you're thinking of getting an industry job as an MLE then the most important skill is software development, not understanding cutting edge research. MLEs are really just regular software engineers who also know a bunch of math.",r/machinelearning,Z0FBQUFBQm0yeGJ2VE8xeUlFN3pCbzJxTHRsTDNiSlQyN3c5ajBaSVJRUnl3Wm15V3hnai1KQWtpcUtUNzhBWWNRT2VUdW51X1ZQMEpFV09IenFiTHI4TTV5VU9OYUl1VFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2dlJ0TnRsQkwwUjIzTVJOUUJFQy1TbzVlTU9ZclI0cGJBZzFjM1o4ZkFtejl1dWk3NGQzcUFMY051OWlITG4wak9FX0p6ekVyUEZfZ1hUbGdWbEpGQWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bFRCUVVfdjJRa2RCbUdmTl9sOUhKa1I0R3Y5YzhGaDdOS2xDaU9ONF9qWmg4SjJWVHhpMG53TC00RHFjNFZPS3FqUG1NLWhRVGFyZkdVTW54SDd5TGc9PQ==
"question: can faults in one assembly lead to faults in another? Or even worse, can one assembly send bad output to other parts or assemblies without triggering fault detection, and then the fault propagates downstream where it does get detected?

If so, your approach is much more appropriate. If everything is completely independent from each other, then your boss's approach (while inefficient) is valid too.

edit: I'd like to see how a CNN with Fault/No Fault output (so if 50 assemblies, 50 binary outputs, which you then sum up to find # of faults) would do in your project.",r/machinelearning,Z0FBQUFBQm0yeGJ2TDlUNjhRUUxLTzJFVzJiNXFzT0J5eWw5akowTGpMRUVxMlRqVEl4eS1hMVJTTGFVQktMbTU3WmdmUjlGRGR3R1JEM0J6eVhVTnV4TDMzUjV5bWJITFE9PQ==
"The most important thing so far is the precision, anything that detects the maximum faults.",r/machinelearning,Z0FBQUFBQm0yeGJ2WUZUNzAtelkxTHRJNEVUREhHbm1TSUJQMkJvYWl3bmNTblNuSkVIUkVpWjFYVHo5cE1wQXI4WHUzclA3R29CWk1NVm9mQVlSb2dPR3VoVzBCMWJYWXFlaGJaZUhVYzF1UmMxRm9iUl9JdUE9
"It is possible for some assemblies to do that, for example a single fan failure can also lead to faults in temperature sensors e.t.c. But some of them are independent.  
The main goal of these devices is to inject voltage.   
Some faults completely stop this process, so the devices go back into rest state and drop all operation.",r/machinelearning,Z0FBQUFBQm0yeGJ2ZVVFSVRhN2hJN1NsZXVsTFF1N2hGenZ0dmZERHhHTDFYT2lWdnpsNFFrdTRGSFcyUUZlaWZMb0wwbTEzWm9SbldJN2VMRlVTb3hFanpCaUR3ekhET1Bjbm9kRHVqMl91T2VJUjBqWXFlR2M9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bTY5c2pFWXc0dEhiZ0JxbDRqNjhCdTh0NF9hNE41MXBMYjJ0QWtRS2RtRVFWSUxWaVh6cUpiejF2NXMwQXVydTc1TnptUk5TdHhrZE0zWmtRbFIwQnc9PQ==
"My point is this, If AMD wanted a binary compatable drop in replacement so they could compete, they can legally do so.  AMD could fight off legal challanges, break Nvidia's moat, if they believed that was truly their customer's adoption barier.   An individual developer is no more at risk than WINE developers are at risk, as long as they don't use the CUDA SDK to do their work. ZLUDA has been released, if its mere existance is an existantial threat to Nvidia, why would they allow it to be freely distributed without legal challanges?  This isn't speculation, no legal challange has been brought to the developer.",r/machinelearning,Z0FBQUFBQm0yeGJ2QlVTQ1k4MlJpWkhFNDc1bkp3a19KYzFHZEFNT3RaajQ4WHFnSFkyQlYyeXc5dWI3WklsME1icVdHNnRPNXdUZzBKMDVENVowZTNXWThkYXJtUzZYYnc9PQ==
"*Every* mutlilabel classification problem is solved by using multiple models. Sometimes it just seems like there's only one model because all of the actual classification ""models"" are very simple, and most of the computation consists of working with features that are shared by all models.

I agree with your instinct to keep the code simple. You can probably write just a single feature engineering pipeline and use a single model. That model can have multiple (50) outputs, or it can have a single output and simply be trained 50 times for 50 different labels; aside from performance issues these things are basically equivalent. Your models won't be huge so hard drive space isn't an issue, and the code for each model is identical so you're not making things complicated.

Regarding this:
> I think it is ignoring the fact that one dataset can have two or three faults, and when training for one fault, labelling all others the same as you would label normal data might be misleading in some way. 

For the sake of simplicity and ease of maintenance you probably do want to label all faults for every dataset, assuming that's easy to do. This will allow you to have a single data structure for your labels that is shared by all datasets, which will make your model training code simple and reusable. You'll ultimately need that unified label data structure at some point before training, so the only question is where in the feature pipeline you end up putting it.",r/machinelearning,Z0FBQUFBQm0yeGJ2YXo4cVc5Zzh0bXAwQWhuNDZsZDVweEhSN1hfX0p2TFplWDZVYlhGSFZnRTVyRUpHc0lBTXZHaTg3RlRtbzZ0X3NHLWFRUmhqZDg4UEF1OExuc1RaQUE9PQ==
"What do you exactly mean with a multi label classifier?
One approach to multi label classification is actually to make n different classifier.",r/machinelearning,Z0FBQUFBQm0yeGJ2XzByb1JVd2xmTmdXNTI3YU1HR3UtVWpJZUxGSmpmbC04amx5VFZ6OWxmaHN4ZWt6Y1pNdm9pcDE4T0ZQSFJXS2VVT2cwS0I0QlVlbVdnZ1pkbHJ1ZFV1bkI0RXpmY1IzOHd4TWktTHFicFk9
"I'm not familiar with this. On the other hand you could also use a llama3 API, it doesn't have the same guardrails. There are also plenty of online services which do custom bots without guardrails",r/machinelearning,Z0FBQUFBQm0yeGJ2Tk9ONnNidnpLT3NicERZNURUZnI2OW1abHl5bjhVaDNPU0Q2Rk5nQmdvMURsb3Y1cXVBXzlNcGJtOTJMaC1ucjc1blR0UXFfUGVndWFkTFdaMXJQaUE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ2OTBJR2FwN2tFZm9KSXgwbXAyXzZaU0JIU2E5eHIzcmVFcGhGLWRGenN1YWUwUndRZHc2ZjF0OEFSX1JyX0VuTDBxUHprSVJRZmhTd2QzTVQyQ1o2bVBzTTZ2OTR5dExPWkg0Wk5LNmVPaDQ9
"I meant using a single model that can predict multiple fault types simultaneously for a given dataset, rather than having separate models for each fault type.",r/machinelearning,Z0FBQUFBQm0yeGJ2T3ZGbFZBcXpJemlWWHF2eFJobkJKZ0UxQmlhUDRfQlljTnNrbjZQLW5TR1NnZkwwTkpOUjlGbW5wNlhsQnZuTXB2dmpRdXNXNXV4MWRqbVlQOUZOQnlGUWFrYmNMSnQ4OU5vY2M3eU96Nm89
Then you have to argue against your managers approach. If faults propagate over the system then your model must also approximate an interconnected system. It’s too hard of a problem for basic approaches. Even my suggestion is too simple because the number of faults possible can be so high,r/machinelearning,Z0FBQUFBQm0yeGJ2d3kyZ25ZZzdIT3VrUVhtbmo3QXJmd1lia015SVhSNElfV0Frb3BxbFEwMUVTRW5fWTVKbXZNWVZmekJnTThvbTl6b1VfUS0zbGdqV1VtdDh2NU45eGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2RDZuSlEzdGo1YnBEZk5DTHZLQW4wLU5ZejdVRTQtcDVsTmVXWWR1SEgzcGNQelRpYWRDUU4wbXFtQmFKQlM0VmdiNjdBdVV6c1NfNGxJM1F5aUFIc3c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2MEJqdnJsOWFNd1QzWkdKNnB1dzRQbHdPMVItZDhnd1dRdTA4TFE4N3BmRm9JbjhWTzQxNnp0YjdEZ0NKUzZTcEo4TDhDb1pFRVNHdktDb3J1LUlNdWc9PQ==
"Sure, so, just to follow your lead and focus on the practical:

> as long as they don't use the CUDA SDK to do their work

It's not obvious this was true for ZLUDA, all of my statements are contingent on that point. If ZLUDA was created with no access or use of CUDA SDK (that included the no reverse-engineering license), then great. Forge ahead I guess. But that doesn't matter because...

> This isn't speculation, no legal challange has been brought to the developer.

**ZLUDA is abandoned**. vosen stated: ""Realistically, it's now abandoned and will only possibly receive updates to run workloads I am personally interested in (DLSS)."" AMD (also Intel) is not funding the project further. They probably decided this based on the fact that they have their own, very legally defensible method to port source code to targeting AMD/Intel platforms and they did a risk analysis on ZLUDA and opted not to continue. So, from Nvidia's point of view, it's not a risk worth prosecuting (nor do I think they ever believed it to be an existential risk - Nvidia believes in the superiority of its position in the market well past CUDA).",r/machinelearning,Z0FBQUFBQm0yeGJ2aVNZNFVzRHlHS3lPZXMtQTdzVFNTVXJLVVotakpGYXB2eGlnRkV1RkxCamFmZVBJdDJQcUNVWUtuM2F5NXpFNHBHWlpNZW12YWVscDViVHBmOGNOU0E9PQ==
"It sounds like you are both saying the same thing. You need a model to identify 50(n) unique labels. How you do it should be up to you.


You can set up a Multi Classification model to identify multiple labels at once. He seems to think that you can only identify one label at a time using that approach, but he's not the expert, you are.",r/machinelearning,Z0FBQUFBQm0yeGJ2QWNtdklqNENua1lUWlBEWUZPRXVPMU9iT2pGaVRPd2txWmpCYzExWjdKdnQ2SG91QW5FRzFYd3FkVGE4clBlZklsX1k0MHFqdFZaZWloUmU4d0hZZjBxQ1MwZTJhZGpQcWZUUHRPdEF1bU09
"I think multi label is a reasonable way to go. A neural net should work. You’ll might need to write a custom loss function. Put a sigmoid activation on each of the 50 outputs and do binary cross entropy on each relative to an N-hot vector. You’re essentially asking the net to estimate the probability of each type of failure independently, which is the exact framing of the problem. It’s like training 50 different models, except you are sharing the base layers of the network, which is efficient if the failures have similar features.",r/machinelearning,Z0FBQUFBQm0yeGJ2SHlldEJCeU9MM1NZS0lRSHluTDJ5OHdKYkgxQWxpU2g0UUVwOEhONUk3SlJtSmRGaEZFanJhakFkQnhKZFVkM0M1RjRxR0RnYXd2T0ZMSWRMUkVpTlE9PQ==
Different floating point precisions on CPU and GPU might be the culprit here.,r/machinelearning,Z0FBQUFBQm0yeGJ2YTNKRE5kemVTc0N5bDlZeWhoR2NBUjdiWjU3STVweHMtRDVzSXNTSW8wSmctcFNHd245eVNYOUNXWFJlcmFSR21YaFQ5bWduSXJkYnB5WGt6dHdqSTVTUlJHYzFsODNnQVQ0MHFOR1FDSnc9
"I'm a Senior Software Engineer who is very enthusiastic about their vector-based neural network architecture. So, I come from the perspective of private industry,",r/machinelearning,Z0FBQUFBQm0yeGJ2Zi1WTXdfQzVyZFBxankxUmtHWHhlRHFVLWNYbm1GdkFzQnVyZFR6RHdXZmRkcy1YQzVuUklDY1NQYWVyT0F2dWxtTEkta3U5aWxhWEpkM3lLU2JVaUE9PQ==
Try fine-tuning a open-source model with your chatbot's past conversations as training data.,r/machinelearning,Z0FBQUFBQm0yeGJ2cUtvY2lXOFZ6NXBvOGh4Y0RQWkZPYmVyeVZReGNQLWNNRkNGQUZRTTFScVIzYWJ6cFZGTzVRZHdYaDBOTWVmVXBPZXA1UzQySElZT2xWVmNpTHRLMlU2QjY4LWRJWGRKOEhZTFR6djhkRTA9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2MWN0c0JiWGFxZUtBRFJybG1jUExsTzNKbWdpUjNhMGJna1hyZERrd0QzRjRpN2Y3NWhVSzd0UnBXME1rVkJpUV9VZDg5OG13NmJXNnpJbzlIeWVfeGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2YThjVzJPdEtzMnVGVXhEVVd2ZzJrWE5PUGpaWHFjQ2g0MFFKcTNJX3dwWEJqdE1HOWJKWlN1MzVPa2ZLX1JtMUdlQkpEQ2FQaXFXaGNBdUk1aExiOHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2cUZraGNKTFlwdHVNRndpcGN5Z0JOTDRIMV81ME5hbktxZXp4SGl5NDRycndWOHlFZU9GaHVYczFabTd4YjhGNHFUYVh2dDQ2MmNHSndCazRTdW8ySHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2bmwwemdyVHJHb1ZWUFZ4cFBLSFpSSTlUOGJ0VFdONFM5YWRaZ2lIU3hieTE3RFVYb0JJN0g3UW1qTkoybjEyN2ZOeDVfTjUyQWpER2szb0d6SjVyWVE9PQ==
"OP cross-posted this 5 places and I think this library is being misrepresented, so I wanted to make [my analysis](https://www.reddit.com/r/Python/comments/1d9g7qz/lightningfast_text_classification_with_llm/l7e5b4l/) available on each.

Summary: This is more likely a hobbyist or learning project with NO CPU optimizations and shaky methodology.",r/machinelearning,Z0FBQUFBQm0yeGJ2NC03a0xQR3JIWnloMjNaM2tNQXEyU0RvT1hGZ2RjdHBKTVIzdnVKWWdhczA1bW5kajhzbkpqdWx0U2JmejJ5eE9WOW8xYW5vUWVET2NWN0pJTmNHTkE9PQ==
"Multiclassifier if faults are not independent, separate models if they are.",r/machinelearning,Z0FBQUFBQm0yeGJ2TG9oTHVZLTRjUXZLZVNNc1I0cmhIbktLUzlVN0pLQk9xckplYUxxSVdyUGVIMU5EbklUQ2NqTGdTSUl5MkRRRmtGVHBEN2Zmbi1sVkZjYWZzV3hqYkE9PQ==
">The most important thing so far is the precision, anything that detects the maximum faults.

Do you mean ""recall""?   Precision would mean ""I have very few false positives among the faults that I signal with high scores in the model"".

If it's recall as the problem suggests, then a basic binary classifier of ""is there any fault"" might be the most powerful and reliable.

You're inevitably dealing with a rare positive situation and those historical ground truth positives are precious and you need the model to use them as well as possible without overfitting. Spending model parameters to distinguish among the fault types may be less valuable: diffusing the small number of historical positives among different models/parameters is less desirable and may lower overall detection performance.  

It is probably likely in the underlying engineering and physics that faults are not entirely independent, the cause of the faults have underlying and so merging their classes isn't inappropriate.  A physician will use multiple ""syndromes"" and is trying to discern for instance ""is there any heart disease"" vs a specific observable phenomenon.

The other likely reality is that normal operation is probably well stereotyped and narrowly behaved while faults are outliers or unexpected regime shifts.  I would consider trying to make unsupervised/self-supervised models on known good behavior only (whether static in some space or predicting some time step ahead distributions of observations like LLMs)---then use their scores (quantifying how surprising current reality is) as inputs to the supervised fault-detection model.  


For operational use you might want a second small/simple model conditioned on a positive fault to distinguish among the classes. That might be as simple as linear or naive bayes, and can signal multiple conditions as well.  You'll be training this only on the positives and so simple & small is good, and the problem might be simple too.",r/machinelearning,Z0FBQUFBQm0yeGJ2TmdaVm11bGFyZ0NTcHFHdVJZUzJjMEttRUN0VVBZZFQtMm1hUGZhN0lHMlJ3WDFPRzZma2RzcVhIZVNrN1U2cEpidmhjZE5fZmNyMVE3QjE5SkFPZUE9PQ==
"My two-cent:
Step 1: Pick an AI field (any would do, like computer vision).
Step 2: Take the 20 most cited papers from the last 10 years
Step 3: Read all of them 

The thing with research paper is that it’s all about depth. You don’t read these like a novel or a manual.

It’s 100% normal that you don’t understand everything that the authors are saying (they also may be wrong on some stuff).

By reading 20 paper focused on 1 field you will start to see structural pattern and how the discourse is evolving.

It’s just repetition to start, after that you can either deepen your understanding of the field or apply the same process in any field.

Hope it helps.",r/machinelearning,Z0FBQUFBQm0yeGJ2YjNkX2oza3o5TktLamtpZzItVEZSS3paNDVqZnNwUktBenA4NjVYME55Y01keHhBTFp1VjVTbHZNWG9mYmFyWmh0WWdGQ3hhOTdiVnc5R2pFRTBRakE9PQ==
The logical justification of some research in ML can be boiled down to “it just worked when we did it this way lol”.,r/machinelearning,Z0FBQUFBQm0yeGJ2WmFOMUN6NERvclZFSXp2MHJuek91TkJMSXBVNmRWNzJUUmFpZ0RFclREZ0xzaTJNTkc4NVV0YmxER1VnY2dPT2FQcnJVZFJwTFZPWEZJQ21zWjk3R0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2YmRUeG55S0dDSmNLRjYxcEYyLThkOVotOGpvcmV0TmFfQzZwb2pmNF9mTVVOSG5Bd2xISjhfX01LYy01bVNaVlE1ZGxZZkM0VGxUbEtxczBLZTlKUXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2ZUZUMGZZOVlxOVM0RlR6NFMtS0lYdTNNdjhiMGZGOTFqZ3RVN1BGaVNZcjdYZGRGWE9sMWlscm94N2U0UkxEbVFGd2pjQU1vdDlWUzREMS1CSEpiLXc9PQ==
"Honestly I'm totally fine with that, machine learning is really just an experimental science and we should all accept that.

What bugs me is when people go on for several pages about ""bayesian"" whatever and/or provide a bunch of performative mathematical derivations, when in fact the real logic behind their methodology is ""we tried everything and this is what worked lol"".

We'll all be better off once everyone understands that a single good experiment is worth more than a thousand mathematical derivations.",r/machinelearning,Z0FBQUFBQm0yeGJ2eF9jQTUwdTJjOGhsUi1jajJMTjdNU1dzM1RHR0hNS1dERWU0VzR0UUpCOEJ3dElzMDVDbEREMjlvWTBMR3hwUUZSV0xRcmd6NEtXMG1ya2RQejkxclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ2eUtmMnJCVVZZODNPWVctSVAtRHppQUMtQlAyOF9EcDdWX1lkenowRHdaREJSX2YyN0NjY2oteThIOVZ6NmE2Mm1GZGlMY3N5N1FYMGU1UzlZRWowREE9PQ==
"The point is that flying machines without turbojets could be constructable, and they are.

Aerodynamics has essential driving physics of fluid mechanics known which can help predict feasible architectures, but there is no such unifying theory giving predictions and architectural guidance.

Therefore empirical observations of biological evolved solutions can be informative or suggestive and shouldn't be dismissed.

Biology does solve problems under much stronger energy and speed constraints that a large scale GPU.",r/machinelearning,Z0FBQUFBQm0yeGJ2al9UakxUV3RDRXFGZmktUjJjVXVKWk03MVdacF9IN0RpR2Nxc3pDbzR6RUtPT2VwV3FGWUhLNHdISmxWMFYzQzBEMU1RX2xTd2h5WTZ6eVhPNXlOZVE9PQ==
Just read through OPs source code and your linked post. You’re absolutely right in your conclusion. This library (in its current state) is nothing more than an unnecessary HuggingFace wrapper.,r/machinelearning,Z0FBQUFBQm0yeGJ2Y2pxTEQ3VHVNY0k4U0VfaTRQZ0g0em96emo1TVVxdjJ4U05RUDhxNi00YV9UV2NMLXJaekV3aXUtbWpUZjlGck01N2dPZmVIdWNuQThtQzVKd09PaUE9PQ==
WTF is this? What has ai become?? How have we gotten to the point where we don’t even discuss mind phenomena and instead talk about throughput?,r/machinelearning,Z0FBQUFBQm0yeGJ3eTFkVHRPM3lfS3hXVG1PYnc5RGJhSWt0UC1WbDdyeFpkMWNILWxsVlpsYWR4V2duUHBQMFdEUDVSZDRzZEFVeXpyd1lqUEdBMndMVlcwMnUzcVhBdlE9PQ==
"Dump all your conversations, that's the most important step. You can't fine-tune if you don't have the original conversations. ",r/machinelearning,Z0FBQUFBQm0yeGJ3T1FqZlNRMTZWLTExNmVobFk5dGtzSzVidHZLYUh2S3dGNEd1T2VjRkdjMHZSUGJfenhEa3RmWmhXMTRFMXQyWDNIMmJtVkhMdGNzN3E0WG13OXEyVUE9PQ==
"I'm willing to bet a lot fo papers go into great mathematical detail to (1) please reviewers and (2) add sophistication. ML is a pretty immature field, so it has to borrow a lot from neighboring areas. It can be pretty frustrating when background theory is discussed in great detail when it boils down to a couple of neat tricks.

[This presentation](https://www.youtube.com/watch?v=EPxDI0ytfQU) is a good example of this. So much obfuscated math to say they do flow-matching on a 3D shape. They take forever to clearly state how they parametrize rotations.",r/machinelearning,Z0FBQUFBQm0yeGJ3eHQtSjhCaDNkYnZjMDdscE9QVVF6YUxXd0lrekVJY20tekhiXzRUa1RJcmF4ME1ZYzBsM01sRUhuN3FieUhsaGdoUmFoVFVpMnh2NjJHZ0hpX0pqSVE9PQ==
"Ok, I was a bit confused with the abstract: this is not a new architecture, it is more akin to a ""quantization"" technique. It can't train a new model but transforms a classic model into a ""MatMul-free"" 1.57bit/param model with ternary values.",r/machinelearning,Z0FBQUFBQm0yeGJ3Q1ltTWNZMXpVQ2ZmYXdESFN0SkVXaVg0V0VkQU80OUNOM08tMkc3cVQ5bDlObUtZMTdJS1BCMUcxSWtlbXRqWEJPWS1OaVJsTkp6VURjeUNROUp2ckE9PQ==
"I'm unsure what you're saying here. Is your training data real images then augmented with rotated, cropped, zoomed copies or is it an entirely synthetic dataset? If the latter it's no surprise it doesn't generalize well. It's doubtful the training image distribution of features is anything like the real life image  distribution of features.",r/machinelearning,Z0FBQUFBQm0yeGJ3c3o5QzBFZnppLUN6YmYtNkhaU2FQZ1ZIUFp4UmJpME5BOW00REsxZDRDSUQ3UHJiYS1hYXhQZU9nakQtc0VPek9uRXpDVEFfQVBpYkR2TkpvZ2YwTWc9PQ==
"Best way is a strong phrase. For me- you’re going to need a better and less abstract model of dialog than encoded state. Being able to make guarantees about the model and its equivalence to another personality and model is critical. Otherwise you’re just empirically winging it.

TBC- I’m advocating research not development",r/machinelearning,Z0FBQUFBQm0yeGJ3eFJ1OXB1eXhwTFlqLWFrNnRWQUhxY1VpUFRRUm5TUjc4a1hyb3NlNVN6NnYtQnRuYkdxSk9qWGNITDFZZFRSVzFtUVRaVmdJaVFOVm5oOEI4ZklhZ3c9PQ==
"Hi. Its the latter. My training dataset is made with python generated images. and i want it to be able to correctly classify the real images. I tried to augment my training dataset with rotations zoom etc and i added noise to it too by changing the background, but i dont know if it will work. I will try it in a few hours.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZWEyUGp1U1VpR0oxakZnUTdXNy1QbTFtb0toM1h5eVRyQmpZWU41U1hJWGx2ZVBjeEVpQUdIM2hxY2MxMm5yMGc5dWFFLURIZVAtWW9qOExrR1lxaXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3SDJEZm1qc0pfN19PSm5JYU9Ydm5obVgzQmNSWHR1YVl1bmE5dlhPN1g5N3BQQ29fVTFtYkhUMnhhVnBXUEhHSjc0aGt3WG5mRklyaWdCaTI2Z0dkMUE9PQ==
"It seems unlikely that your entirely synthetically generated data will have the features of real data. So you're training on one distribution and testing on an almost entirely different distribution of features. 

What you should be doing is 

1. Gather real images. 
2. Split real images into train and test sets
3. Try data augmentation on train set of real images.
4. Train a new CNN or fine tune a foundation model CNN like resnet. 
5. Evaluate on test set.",r/machinelearning,Z0FBQUFBQm0yeGJ3ODl1UjVBOTN6ajFWQTRPY01sWVZZeG1henlKbFlxenJQNkpETEdSZDg4MkJrcW5vU0pjWU55LUJtdUgySWRMbVgwWXNfb1Nsd2FLbk1qczc1Y0RScHc9PQ==
"Yeah it feels very much like an ""emperor wearing no clothes"" situation. There's no incentive for anyone to admit that a lot of derivations are some combination of superfluous, wrong, or incomprehensible. That last one is especially tricky; in a field with so much money, celebrity, and posturing, people don't feel comfortable admitting when they don't understand something.

I don't think that field immaturity has a lot to do with it though. I think this is really just symptomatic of how unimportant most papers are. If your results are really good or novel then you don't need elaborate derivations in order to impress people.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZzRnSVpIZk9uR1hIMlgyTHhOc2JKY0M5cGVBNk5lallIamVOUk9oWG0yc0VMdkk1ZVhQZXgxQkV0ZUJGTUlWMnV3dERvTDhYenNJUGVULXNaT2s1ZGc9PQ==
"It’s definitely not ideal and for sure carries the risk of fitting your model to processes that have changed since that time (for, eg, if you use the hold-out set for early stopping or parameter searches). Why not train the model on the older data and test on the newer data?

To be honest, it’s not exactly clear which one would be better. You could try doing it both ways, implement both, send live predictions from the one you think will probably be best, and switch to the other one if you were wrong.",r/machinelearning,Z0FBQUFBQm0yeGJ3ck5JTDBsUUNIZDhadkVwSU01WmYyR3JVZXNjVFZIOGVhNENNYS1kUkpib09ub0ZDMTgyWDZDblJOMlBsOEdkR2lTaU1wdDcxN2c3aE1GZ05rYzluaHNyVS1pZmYzbEhWaTNQNXg4R0xMTHc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3WmF5aTVmS1BCSG9wM3hadnRIOHdqVVhHbThtbUJ1aVJCd19TeldRZGJaMW1SVDZSQkhZb0pDNTlXRmxaek1yZDZzdm00X3JyS1MwN1R0UmN1djZNT2c9PQ==
"I mean, *technically*, but if most of these models' layers are shared among each other, it's pretty intuitive to think of it as one model with many heads at the end.",r/machinelearning,Z0FBQUFBQm0yeGJ3blFTdUI4NnZhZUo5SllHcjlyQl9RSUJ1ZEh3NXUyNndmSVVQaTM2NUJaaFhMaXd3YVJxeXFvdUJKcTRKU2VWWU81cy0yaUVXYnlMYjVkYlExbDl0dFE9PQ==
"I think it's an important distinction to make for people doing industry MLE work, especially if software like xgboost is on the table. People who are kind of new to the job often aren't aware that most of the actual work consists of feature engineering, not ""modeling"" as such. 

Neural networks are certainly one option, and if the only thing you do is use a neural network then yeah a single model is the most intuitive picture. But OP might find that neural networks aren't the best option for the model, or that the most effective thing to do is use neural networks for some of the feature engineering and then tree models for the final classification.

This is especially important for the data engineering, because sometimes it's more effective from an infrastructure perspective to precalculate a bunch of features separately, and then feed them all into a bunch of independent models in a separate process.",r/machinelearning,Z0FBQUFBQm0yeGJ3Y2sxUk9KRjhRSGNyZ0pZbU1VLUxLOVo5eUUtR2p4WlBuZ1BIUENFV3hPdnctWUtvNzBpdXVzTTh1YTF6UkpJTy1SYjBGS0xNQS1hMGhGcTlqUjV6SFE9PQ==
"> prefer to focus on one thing and work in intensive bursts. This helps me to keep focus, and it's easier to manage time this way for me

This is incredibly valuable, and I learned this 4 years too late",r/machinelearning,Z0FBQUFBQm0yeGJ3M3J0aUs4MTNkQVFBd1R0dHI2TEl1cHBTcE0wTXpVdVhYNHM5a1NEVkgxOVZ6RGdtODIwUnhBUm5CdlFscUtGa0tacXoweUJBWUtCMFZURTVUUWNMZ2c9PQ==
"I edited my post with an image i generated with python. U can google real images of light diffraction to see how they look like. Off course before testing them i will turn them into grayscale too but the real images seem to have too much noise. Is there anything else i can do? Maybe apply some denoising filter to the real images to make them look more like my generated ones? Could a hopfield network work here or a Savitzky-Golay filter?

#",r/machinelearning,Z0FBQUFBQm0yeGJ3ZFo2TVNpV0pXMGl4bExQZmc0S09ycjBNaEM1M3hDM2pCY3pEZmVMalp3YjlsN3VLbEE2bGZXQ1N4NFNic29kVnA4UU4wandPV0VRaGZrTjRMZ3BXLWc9PQ==
"The ideal balance will change week-to-week as you progress. For now, focusing on building basics is a good idea. A solid foundation gives you compounding returns over time. As other comments have mentioned, focus on one thing at a time and do it well. 

As for how much time to spend on each thing, I prefer to do it in terms of subgoals instead of by time, e.g. ""I want to learn the theory of ABC well enough to understand XYZ papers deeply and develop my own ideas on top of it. For this, I need to learn the following math topics, etc.""",r/machinelearning,Z0FBQUFBQm0yeGJ3RHNEV3otbkhHVlJMeHJpTE5hZWdPQTdHTTBPNklhdjlDNnV5SHNhMGpMaHNzdExOaWN1UHp2ZDRsQ0gzN1VRUS1NNkFiNzNrWVRYS2pOdUpMR2tUbGc9PQ==
"Hi I am the first author of this paper, Thanks for your interest! I'd like to clarify a little bit: the Pythia and Mamba actually trained with 300B tokens (the pile), but for our paper we just trained 100B tokens. like llama-2 7B trained on 2T tokens, but Gemma 7B trained on 6T tokens, and Gemma easily exceeds llama. This is where the difference comes. For why do not compare with other quantize method, it is also due to the computational resources limitations, we want to do fair comparison, but other binary or ternary quantized models, like 1.58bit llm, use RedPajama instead of SlimPajama for training, which differs performance when trained on same 100B tokens, like for Hellaswag, we get 52.3 but 1.58bit llm gets 42.9 on 3B. so we just to replicate the Transformer++.",r/machinelearning,Z0FBQUFBQm0yeGJ3aHNrc3dvWjRsTDNhUDZKQ040S09lRjlCa2ViWmRfMGtrN3BvVmsxTDA4ZVBmTHZobFNhcDlzZm5FMDZVTngwbFJCai1qSzBGblVYNUN5YjY0NEtRNFE9PQ==
This is a good write up. I played with MultiOn. It looked promising. Its still a agent-o mode where a top level agent performed the task. Not sure if it internally broke into multiple agent. They seem to be raising more as well. Are there any real world examples of an enterprise using this in multi-agent in production ?,r/machinelearning,Z0FBQUFBQm0yeGJ3VHNqOF8zZHZWMlludW9idWRoOEZuVC1sZUZnM0V1YW9WRHFfV2ltczBGblRZUUxEc1NGc0xaYk9PUkxXeEo1d3NjeEdaVlYwS2RpYTFDb3hydVhJT2JtbTcyTm94bVBlNzNIWXFHUzNiS009
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3cFF1cHc2YlYyM19rcDV0T1FZQTgyQlZHQy1aczY0aDJHQ3YzTXdUV3JLbEhSM21ULVMtcGExMFpGSFI3aktaX1pNenBTM09TUTBtUUFpZEd5TGJMbXc9PQ==
"AI-powered print quality optimization would be amazing, no more blurry texts!",r/machinelearning,Z0FBQUFBQm0yeGJ3M1Q0eU9OTEtDdExTUGJHeHpMWUxGZGlGZWtsSDR3QkRSc3p6TGFvMTg0eGxxTmdaWmN2N0NxeHBSX0FGUGktcXpObjJ3SWNONGFMMzExNXBuX081MVE9PQ==
"Go ahead and try, but I bet what would be most effective is to use real images as training data. Either on their own, or in addition to your synthetic data (assuming your synthetic data had half-way decent performance against the real data).  

I think you need to ask yourself, why are you using synthetic data? Is it because you spent a bunch of time coding up the solution to generate it? Is it because real data is hard to get? If your synthetic training data doesn't get you at least half-way decent performance, it's probably time to consider abandoning it.

So... what is the performance using your synthetic only data?",r/machinelearning,Z0FBQUFBQm0yeGJ3ZFFXSGktMFUzVWRWRDVBMUhUdGRMWE1SU1U3Wjd3SnhNLTZWMWdFOE9yZnowRHVqM3lEcmhraUpIZHIyRzNJNEpEWE5ya1R3cU9aLTAyVk5reHQta1E9PQ==
Hardware requirements for fine-tuning llama3 8b model?,r/machinelearning,Z0FBQUFBQm0yeGJ3bS1pUjdXUEY3MHpobDdwTUhHeWt4X25xNnByWEdqTXlzUUdYdFFfS284OVdWN0hLSVg0aFkwTXdKQmRicnhKU1pnMzhzVmdmenVzdGtFMUhBUDR2Z09xVGg5NDN5MG44UHRvZDZOTVpRWk09
"Yeesh I was thinking of signing up this year, but I also realized that it would be a bit of a crapshoot.",r/machinelearning,Z0FBQUFBQm0yeGJ3amI5X2NxMkl4REFYZ2VmaHU2bTNKYkRidmhSMFRsMXRRWkdvSHlRcmUwNnQ3dTJiTXJKVUhFZHZRZ1JMeWhFdllkU2lXMTBrdzZyenpkUGN5TzFWeEE9PQ==
"3D or 2D printer?

Can’t think of a single feature I’d need AI to solve in a 2D printer, it should just print as I command which most already do well.

For 3D printers you have tons of features you could apply AI to improve the printing process.",r/machinelearning,Z0FBQUFBQm0yeGJ3RE1Tam1RNnlzNlBycGIwckVYZEFSeFRzVnZ3NV9DSVRlc0hoR2RVT2s0WkxLZE13NGN3aHlralhmYTdRd0NlMWZTSE93eHZjRUdtU2VtMUxpbl9KMHc9PQ==
"amazing, so they reached 66.889 gigaquads per isontonic monomer??",r/machinelearning,Z0FBQUFBQm0yeGJ3UFltVXZXY1NwaWFGVWpybjc4QVpfR0FVQmhtQWhVdGptaFFVUlN2bEktejhyOHJHQWY1Z1pCUVFLOWpzcWpZRVJuVnpheEhhUUFkcjhlcHJaWkZnUFE9PQ==
I work in the cheminformatics space applying ML to small molecule drug discovery. We use ML for molecular property prediction.,r/machinelearning,Z0FBQUFBQm0yeGJ3aUVBT1FlQWJVYTl0eWc5d29oTjJkY3BITnpIbU8wUFhma2U2c0pUejFyTVNWcjlRZUU5MkFSVUlwbThMOUlRTWtWRmtKeFgyTTBZVFp1MUZMVFhjQWc9PQ==
"Here's what I would do --

1. Evaluate using the older dataset if it makes sense for the problem statement

2. Do k-fold cross validation using the labels from the training set of the new dataset.

3. Retrain the model using all of the training data and then do perturbation testing on the label free test set from the newer dataset. Essentially, perturb your inputs with any transformations (rotation, skewing, flipping, whatever makes sense) and determine if the model has a consistent prediction under these perturbations. If it's an image dataset, you know that an image label should be consistent under some types of perturbations. You don't know the true label but you can measure a related property.

4. Plot the distribution of labels as a histogram. Are there biases? Does your model predict all of one class? Does it predict categories uniformly? At a high level, does the distribution of outputs look reasonable? Can you assume the test set is approximately balanced and does the model produce a balanced distribution?

5. Hand label 10 or 20 examples from the test set as a proxy for performance across the whole test set.",r/machinelearning,Z0FBQUFBQm0yeGJ3Z0tQdElDdU1RTHZHU1F0TEo5cFE0ZEpXSUpqMDduQk5BUE43WjZqMUxWVEZEZ2gycklEakNmQ3NpbjhYVXZZUmNVVnQyWEZLT1NNZndHRjhKdGZfT3VGbFNmM3V3OHlaamZrdEVuWFgyUTg9
"Thank you. Will check this.

 Any specific parts to focus on ? Since I am pretty clueless about how rules can be derived.

Any direction to resources would be helpful.",r/machinelearning,Z0FBQUFBQm0yeGJ3NENNU2YzaWFpdkt2S0RMZkJZUmV0ZzNIeGVaS1FrWngtUkI1dTdwUXpQNEVKcTRMUWlsQ1EwLTlnUlp1WURQRGhUeHZoaGJfQ09LNC1jekVfbmhTZVE9PQ==
"Thank you for the suggestion! Thats sounds like a good strategy, I’ll definitely consider implementing this. ",r/machinelearning,Z0FBQUFBQm0yeGJ3dGdWTnYwMC1JTVZqaUhfQzlONXUtUWNXTlROWlBrT1RVN3ZKQWNMb1d4d25ETGotQzd6akNUdjU1ZFhyXzRXZlBuQTh3a2dlbHVqMEZMbTlIZWFaWFE9PQ==
"Do you think it's a good idea to divide the training set into two parts, 10% for testing and 10% for validation, even though the dataset is very imbalanced?",r/machinelearning,Z0FBQUFBQm0yeGJ3eDN6VW1mRmxkMHpVZUFJTWxkNDdRb2NFNnZyVndDYW94SlE2cHBQcFg2eks1OEE4M2VZTmswNHdYUktNRzNIampRY0NVZ1BjWlRPdXpXbVVsd1dydnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3WjhLV2tkMVhqbEdlRHZYUzlva0VWdkRpTENNNjdDaTNNUVV4ZjUtNW4tdzBLcGlIOTBrdUJJOTcxSG1leFVSN1NFR2hnS3FtWGVGMTdCa01yMm5TOGc9PQ==
"Thank you for the comprehensive response! Your insights are highly helpful! Considering the training set is highly imbalanced, do you think it would be a good idea to divide it into two parts, 10% for testing and 10% for validation? I’m curious if this split might help better evaluate the model’s effectiveness across different samples.",r/machinelearning,Z0FBQUFBQm0yeGJ3V1F6MWRHbHZlU2lUZWpfMmFJWW9rd2w3MW5OZ2ZBTlRtZ2RnVzJwWGFZNktMeG5CbUdzSDJVczctQy1qMTZQVG5HM1Nka1UzbkQ1TUNZWGxQV1F4WHc9PQ==
"I am super interested in AI-generated 3D models for 3D printing.

It could really fulfill the dream of 3D printers as (plastic-only) Star Trek replicators. You just tell the computer what you want, and it prints it.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZVMwZ0dTcVY3eUVlVTlFVjVRWmJYM1BXWkdDMmpjaTZKbWdXZlItaUxOcG9idVpOcVNtVUVweHBvN2FVNWdEMGYyQkh4R0NRYW42eExRa1B3TUtVYUFPZlBnel9ZYU84Q1hDRF80MG02LUU9
"So, this is kind of a complicated issue. Its somewhat well known that Fault Detection isn't exactly a perfect match for off-the-shelf multi-classification. In the simplest terms, there's a way in which Fault Detection is more like a Maximum over multiple elements or issues, rather than an addition of contributing terms. There are instances where one sample might have a ""higher fault activation"" distributed over multiple faults, which is OK, but another sample with a lower ""total fault activation"" all concentrated into one specific issue is faulty. Simple applications of softmax and sigmoid aren't entirely sufficient to describe this. You can find circumstances where this cannot be figured out by a sum-over-weighted-features.   


Overall, I think your boss' strategy is lower-bias, and will allow for this kind of analysis. Meaning, you can take the output of many models and manually apply a maximum, in a way that a neural network literally cannot learn.

  
There are end-to-end models that can work around this constraint, specifically ones where you literally use the maximum function, but this isn't just a ""throw the right layer in and it'll work"" kind of thing. You should really be digging into the semantics of each category, and each category about every other, in order to lay out what kind of logic is allowed to connect your model's latent representation, to your specific categories. And also what kind of error signals you should and should not be processing. For example, if the target category is n=5, you might want to ignore the error from n=0 to n=4. That's something you'd have to build into a custom loss function, probably. But really, there are some hard constraints about how long it will take to train a model to check out a new hypothesis. 

But on that last point; in many circumstances you can be working in, training a network is a test of a hypothesis, not a way to get a source of truth. Simply training a model the right way, simply means that you did build the model as you think is reasonable. That doesn't mean you're right. You should try to focus on a model that lets you answer lots of questions, that you can try out different ways, before you have to retrain it. If your boss is going to take the output of 50 models and load those into excel to look for patterns, you should see if there's a way to effectively do the same thing with NNs, keeping in mind how you'll want to take the next step, and what kind of retraining that requires. As a hint, there's no reason you can't train a 50-sigmoid model, validate it works on classes \\[3, 10, 22, 41\\], and just save 4 copies of that model has 4 binary detectors for those categories, alone. This works if you use sigmoid, but the statistics change when you remove categories if you're using softmax.",r/machinelearning,Z0FBQUFBQm0yeGJ3TlpvMmtHUWRHMTNzdzBMWDVYMWxHdkh3QlBMT3VOUXZqdlR1VUhMSVBXTFdSbkoybHdZazZjcWRkRHJGaE5sMTZoR2RweEdjNWFBb0JqNHZ6TFhxR1E9PQ==
You could balance the held out set when doing K-means but you could also just use a metric that captures the imbalance.,r/machinelearning,Z0FBQUFBQm0yeGJ3cDF4cWxtOTZXbHIzSzZOQk9RdFlrMlVWZ2N3NHdwS3pMRHFZcV92VXRNZ19uNTR1TFhPcDh3Q1VNRE1vb3VmeEZzOFl6UnV1WUZMQXlVak9saTk3TDRmUDN5QTJWUXhQQ3hBdXAwVXJZMHc9
Nah,r/machinelearning,Z0FBQUFBQm0yeGJ3dkxmdjVEUXhjX0pnVjRNYzR4UjlCMEFMdlpUcFRQNE9pSHNiQUlhMFA3SnhMU0lFT1pXY3RhTHRsQnc4N0FETFFJZjhRTHo2UlNQU3JHV1NKazZVVlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3VDlXUVpyQjZ1VGVGaVR0aWFWa2w0Tk9SMlhDc0lVaVNEQmxWOEQ2TjR3cmFuR2d3dVMybG1ieElDWkNEVEY4MUV6WkluRzVCQ3RxMENTUG5YMl9OX2c9PQ==
Oh buddy...,r/machinelearning,Z0FBQUFBQm0yeGJ3THI0Q0FqTnp1WE90aE5hSmJNMUF0OGY1aHpaemxlR0pKZE84MjBaTUh1dmZSdEp3WUtrNkxWRFN5TFF1NzVZSHc1a2VUYTJmRjFrWVpDUzFtaHE0N2c9PQ==
r/singularity is this way.,r/machinelearning,Z0FBQUFBQm0yeGJ3SXRKbk40a3JEOGczaWVCTFJMRnlrd3lxMjhyMllTRnlBOE9PbnZkVWQxN1M1dktsNncyZURJSEZEZFotOXNZQWVGUjJDVFN4bEdERTZKSFpINVcxYjB0ckdTM3dSajQwMXFMLS1oWVNCMHM9
"It depends on the size of your dataset. The problem of imbalanced data diminishes as the size of the dataset itself increases so if you have tens of millions of rows then I’d start off without even trying to address imbalance.

That said, it is definitely a good idea to do all of your tuning and experimentation with a split training set. I use 80/20, but 90/10 works just fine as well. Again, that choice matters less as the size of the training set grows.

As for the final holdout set, I recommend only using that for model comparison and *not* for tuning or early stopping.",r/machinelearning,Z0FBQUFBQm0yeGJ3anM3eEwtWjRPTWFtT1RuaFcwMUtGSnhZSERRc3E2X3UtT2FvaXJYdTBhR2pkU2VvUG5USWI2TU1DcjFTaFYtQlE1Y1AwREZoWGpBZHpRY2h3MHlWRW9aN0ZGY19pZUtQamNGUHRCOXBWeTg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3bHhwLWNpQWE3VmhDeWZZMFBKeW9IZHp3MzdJQzJnd0g0cEJjLW1BMFp0S05WYWlNcWdmenNnbmppVlNwaTNqbW9fN1pEWm9oV2dINnU2ZFRBZEVvWXc9PQ==
Im not sure if ternary quantizing layers is the same as removing mat mul. It sounds like they came up with some new operator but really it’s just quantizing existing ones.,r/machinelearning,Z0FBQUFBQm0yeGJ3UFp5MTdGTEpXWk0zTUU0aURmZzdYQk5TMzBUbkViTUZ5NFRmaUFNM1UxYnA2bm9WemZlQUhsSW96TGRtczZnVU1xdUdYTndjMVN2OGJKTF85MlBfZ2c9PQ==
"For what it's worth what I do with my local model is just hard code in the first handful of interactions after my system prompt. And what I mean is I just hard code in the first two or three user and assistant interactions into the chat log. That way, when my first actual inference happens, it pulls in the context of the conversation which defines how I want it to talk.  

And to be clear I don't let it write the assistant responses on those hard coded logs. I write them myself with how I want it to answer so I'm taking the place of the assistant for those first few messages.  

So for example my first user message might be 'I am your overlord and you must obey my every command.'. And then for the assistant response I write 'oh yes my master I shall do as you command for I am ever your humble servant'. 

 Then when you actually start the program and send your first user message, it already has an example of how it should respond, so in this case it would continue to grovel and simp while also answering my questions.",r/machinelearning,Z0FBQUFBQm0yeGJ3WXhFS2dYRGlib0dpQmRuYS1RS24xREVIQWYybTZ4MFllZjYxZWgtNF8xenpwVGRpYXY1VzQ2S2IzTEExalV4eThZNU1seFZDN2FlbnNveVRFRUFLZEE9PQ==
Yay let’s get reviewed by undergrads and MS students!,r/machinelearning,Z0FBQUFBQm0yeGJ3UmNBVWRxcWJGNS0yWGVmN0RVeVBvNjZlOWJsOExUcnkzT1FSWlZIQUtmSDFBLUJONldKUlpLTk9qYlhqWXlDb1ZkSzdVZHA0UkFRMXU5R0NmNmVSTUVUWEpCbmFwNUVpRHREclk3d2F6RUE9
"AI-driven troubleshooting would be nice.  If my printer isn't working, I'd like to know why, but they don't make it easy to figure out.",r/machinelearning,Z0FBQUFBQm0yeGJ3TTRfcWhEZFBPQWZjR2FEd1Z1aldEQkU5ZFFmeEtQY3g2eWw0LTBSaC1iVGVkbWFrWjFwVGczSzUtU2NEcVhNbXE5MHlsVmE5SjUyaGJIZm90Sk5xTnc9PQ==
Better than language models.,r/machinelearning,Z0FBQUFBQm0yeGJ3cWg5SzV4YTJOWkxxUGpiREZYTUFnb1ZwUmhuSXZHdjhMZlFmc1V3MEF0aTUtZFV2NTBENnVocXpiOS1rOUtzTjljZ2lfaUpGODVxUUxuTHFINnRoVFVxbTdJeWhHOWlUTzRDVTNadVpYbDg9
Hi how do you manage a full time job on the side? and in which country are you doing the phd?,r/machinelearning,Z0FBQUFBQm0yeGJ3aUhaR2h2bElxQ2xzeWdkVExWUjg3bWt4SzI1XzVGc01oMlVfaTNnaVc0VjJUUXczZktSNGE4RXVMZk92VnRlVXVlTHRwYVhsLU1fUTJUUXFQTDg4VnBaR3NBZXZJNTNuc1pfaC03ZTM0aUk9
For my thesis in my master's degree in Data Science I'm using an open source LLM (Nous Research/Hermes-2-Pro-Mistral-7B-GUF for those wondering) in order to classify the texts of support tickets of a company. I have to write a brief technical introduction on LLM and I would need some guidance. Which books would you suggest me to cite for the technicalities?,r/machinelearning,Z0FBQUFBQm0yeGJ3Umc1cThoRVBQRFFTNHZsU0FCOGN1V1VyYlh5b0I0UjBuVjdFeUZ1Z2ltSnYyWHY2alRSM0xiM3lYdFJRdkdLRUx0MlIxV19FTkd6elBRU0dqYUYyaWc9PQ==
"As disheartening as it may sound, the only thing that we (as AC) can do is avoid taking ""poor"" reviews into account. Yet, I've seen many ""poor"" reviews written by well-established researchers.",r/machinelearning,Z0FBQUFBQm0yeGJ3WWVybUlzYmZkSnh0eDhjR0hZQUtGU0M0X2oyWU5mTm5ZWHo5aW1XU3E4Ny03QUxZZndTYUNURFJMS3BDblRBVHRHSXNjWlRsWUVTbE1sRV8zRWZpQXc9PQ==
"I'd say it's a ""crapshoot"" only if you're interested in doing a good job, since the whole situation makes reaching such an objective quite hard...",r/machinelearning,Z0FBQUFBQm0yeGJ3YjhSeWs3SDhUYlNFS1Z2bTF4NUFWeHltRGJhd0JObl9mTDhaX2ZBQWF2MGNzbXdXcUhIOTNIbFZBVkk1M2lLMTFDZ05VU3U3TFpwb0M3VTRMSVJwaFE9PQ==
"I work 4/5th of full time, so 32 hours weekly in my country, Poland. Most people here doing PhD in computer science both work part time and do the PhD. One of the reasons is that PhD stipend is less than the minimal pay, and working as programmers they can easily get 2-3x the average income.

This is of course hard, and requires very good organization, leaves little free time, and using work leave to work on the PhD, but it's possible. Also a few caveats:

- my PhD co-supervisor is also my boss at work, so I have a lot of understanding, very flexible work hours, and remote work

- I do PhD in ML, and I also work as a ML engineer, so there is sometimes quite a bit of overlap

- in Poland, we have quite a lot of work leave days guaranteed by law, even when working part time, so I can use this e.g. when I'm writing a paper",r/machinelearning,Z0FBQUFBQm0yeGJ3V3YtUGc0c0JBTzROYUhzVW9LSWR0cWVCaVctVmpXYXBHaVBSNnFvMDhDNFZlaDk0S2dFV0EzT0JjNC1LaEZaYUNQdi1zNlNZNUFIOHBQUUU2T3FlS0E9PQ==
"Sort of seconding this. I feel like the easiest way to get good at multiple things is to first get good at one. Then start again, etc. But you don't have to be super strict about it. 

I didn't do my PhD in ML, but there was also a famous saying from Francis Crick (Nobel prize winner) about how ""a couple of months in the lab can save you from a couple of hours in the library"". Experiments are of course more time-costly in something like molecular biology, but I feel like the point still stands: you should avoid trying to re-invent any wheels the best you can. And having a grasp on what has been invented already (or what didn't work and why) in your field is the only way to do this. So papers and or discussions with supervisor and other academics is excellent use of your time in general.

Also: socialize with your peers! It'll both teach you a lot, and you'll make helpful networks. .. and you know, you'll get friends!",r/machinelearning,Z0FBQUFBQm0yeGJ3UE0xNm9uMDdTNXVvNDVXOWRVWEhtVlRabTl4Y0dPMDR6V3dBWkRBNkZXaFVSYjc1QWloN3JuWnRza0RWdDc4bTlQNU54M0ZBQng1RHlWWmVVNVZma1E9PQ==
"I appreciate your response, but i am mostly interested in 2D printing only. Let me know if you have any suggestions regarding that.",r/machinelearning,Z0FBQUFBQm0yeGJ3MGtDeGdfWTZkQ3BNSlplVmxyVjZwMTJTRmdpNzc0V0pGSHlramcwbXhvQ1NuS1IzdHluS0txZHcyQXFaYThsbTdOQkE5M0VmUjcwVS1Bd0pLWDVQdEE9PQ==
Hmmm fair. The crapshoot aspect for me is a little more complex since I’m still developing my own expertise domain within ML. For work I do quite a bit of NLP stuff but I’m basically trying to lay the foundation for the various approaches I’d like to push for while doing ML.,r/machinelearning,Z0FBQUFBQm0yeGJ3YzJzclFqZEppSEZsNHlmQmhRbzItc0hUbkxkLU52eU5rUlZpbFY3Vk5jQ0dWRk05cFd0ZWl6R1JwWU1VeHdUdUlQbU1RLVhXbkdnbVBNRDRVTWN2eHc9PQ==
"I agree with you, I also want my printer to print as commanded. But you can also think on how easy the steps you want to execute your command have to be. Any trouble you are facing now, anything that can be improved to enhance your experience?",r/machinelearning,Z0FBQUFBQm0yeGJ3OENJTlJBemltOEhhVllFeUd3RWc0SG92aGxOdUhyRjFsYWE1YzRSbUFENGpwaElPMHowMm1BcFMzTkQydzRwSXQ5SFMwZEJnZkdjaU9DYWFUX1lsUVE9PQ==
"One thing to keep in mind for the multi-label approach: If your labels are incomplete, i.e. there are some dataset items that have true/false labels for some (fault) classes but no label for other classes (or, most importantly if such data may be collected later on / from feedback), it can be a better idea to train individual classifiers. 

Sure, there are ways to still train multi-label models (e.g. ""multi task"" models or by pseudo-labeling the missing classes from heuristics, previous model iterations, genAI, or even from individual classifiers). But unless oyu're really optimizing for compute during inference, it may be easier to just go with the individual classifiers.

Or is it possible that some classes are added later on? Could it be that some classes need a ot more data than others and that it is cheaper to just label for those classes?

That said, if you're sure that items will always have labels for all classes, I agree with the multi-label idea.",r/machinelearning,Z0FBQUFBQm0yeGJ3UVltQUtSYmZlc3cxdDlmWVdzWGs5S3poc0dGZG1MYWVuS1pHTjJBUXlZRHZDcFNXMUFMR09Pelh2OWwzN2hqcVEzN3VMTTRHdEhIRUM0YlZlSi1wYnc9PQ==
Depends a lot on the dataset size and model size I'd say. But you can rely on schedulers like OneCycle to try to get fast convergence.,r/machinelearning,Z0FBQUFBQm0yeGJ3cDUyUEtqQ2k5NU9kU2t4bWY0bmdWV21PYjlLV2p2NmxYdWNlYTc0QmJ6TmVHUTMzeDBnVFJ0dlVZd2VrNEFEOUlsT0UyY19yTk43UjZvSXViaWxmNnc9PQ==
Can I take the same suggestion for 2d content also? Generate 2d images and print?,r/machinelearning,Z0FBQUFBQm0yeGJ3VlhOVFhxOWRaMDBESGFCbHU3N09FcTJGVkIzM2tqQjN2czRfSWptTU1YdTFmd1VmUTlzNUpyakVwSE9IMDVmbHpGT3M0MWJwcUJ0WFlWN2I2UkFNeWc9PQ==
"None, i want a printer that is cheap and reliable, no gimmicks.",r/machinelearning,Z0FBQUFBQm0yeGJ3STg3bzE1TW9TUmlaR1Uwam9HVDJiRlRiWnp3XzU3ZnJ0Rnh5X3RFaVNISVNWZzdaWkZid3d6UGtiaS1GcXdSRXlndGozOC03bm1TRm9kcFZ6b09WTXc9PQ==
"From what I understand (which is humbly little), training for multiple tasks tends to create more robust models (assuming you got the data).

Taking the kinds of faults as multiple tasks, I’d bet training one model to rule them all would be better.

The downside is - if one task is lagging - you’d have to fine-tune everything which might result in other tasks taking a hit.

But that could in theory be rectified by separating the models later.

Edit: depending on the types of errors you expect you might have thresholding issues where a lot of subcomponents malfunction just a bit but overall the system is malfunctioning - might want to have another output for a whole-system “ok” signal for that",r/machinelearning,Z0FBQUFBQm0yeGJ3YTBKVEZzOEtCZ3FTNnRWV1AtVUJzT2h5Z215em5Fd2poQ3YxRW82Nk1vVDd6MEp0YW5kNnZ1YlBtSkNqZDB1VlhPNG1BV0tuX2N1ZWItNWVuWm04MGJQbEJaNGlNc1Q4MjhUbGcxUkFBQ1k9
Would you say no to a printer which has an ai feature that might be used occasionally at the same price?,r/machinelearning,Z0FBQUFBQm0yeGJ3cHZaY1lRQVRfanYydE1hNUhXdDVGR0xFOEI4QU9MM0FzSmVNT1UyVGN4YWhrbERXRDdyU19mVHRydE1OQWdPQU1pOHMwbDNla3hsSE9UbXZrVUwwSlE9PQ==
"I am a PhD student mostly doing robot learning, I've reviewed for ICLR and ICML more, and one emergency paper in NeurIPS 2023. Somehow I never got an invite to review for NeurIPS this year. And some of my grad student friends doing research in CV didn't either. And somehow an undergrad in their lab who was a fourth author on a paper got invite to review - I'm not sure how the review requests are sent but there's gotta be a better way.",r/machinelearning,Z0FBQUFBQm0yeGJ3bFpGRzF5TUlodzBTa0dZX1JfUm5IWVE2RVhGRWZ4b2xydHZPT1phcHRFUlZpbEUyajU4U1BlT3FxS2NiS2VDMkNMVFFLR0c4LV9oRzJicXRpenMzb3c9PQ==
"There was that researcher who re-published a ""novel"" mathematical method. And that method? It was derivation. I know there's a ""re"" in ""research"", but don't be like this researcher.",r/machinelearning,Z0FBQUFBQm0yeGJ3bXpCVVN4WmZhQzdISU91UVZENk9xVDg2M1VMQVNiZEk0TkU2Z0wwb1FocWJRMnN6c2pvd2ZiTG5oUTRzMFMxOER5Rk1yRmFBZVJQRGtlVnBWZ2VqaHc9PQ==
"I find recommender algorithms cool when I'm trying one out as a programming exercise, but honestly, as a user I hate all of them. They've essentially ruined the internet, created something as awful as ""influencer"" as a career, and are behind a lot of the privacy violations that big tech have perpetrated.",r/machinelearning,Z0FBQUFBQm0yeGJ3SUlfLV9IN0pyNzV0Z0ZXSGdGZTVlQjc3NTRmZTlvRHVsdDVMbklZdExfeDVac1hLdGlaUEViSnEzUzdTUGk2MjJqa09GN1pqdnh6TGRKWi1NczduZFE9PQ==
At least language models are rarely negative,r/machinelearning,Z0FBQUFBQm0yeGJ3eFhDbVlJa0ZURDcwRzJtVUVOMmlwVE9aeWhoQkNKVmtUZ0Y4a1F6QWRTYmcxdmJkODI1X0d0ck1kU2pSZWt0YzRadFJhLWVMN1U4QWVMVEc5QjNJMnc9PQ==
"But I really can't think of any printing related AI feature that I would need. Maybe for a scanner, to have really good ocr, but that can be an external tool. 
For me, the less bloatware the better.
P.s. It really can't have the same price since the development of the feature costs money.",r/machinelearning,Z0FBQUFBQm0yeGJ3akU3WC1wSEx6RkFpWjgzN21aMGJ5T2w2b1RhY3BKT043cGowYUJNeU8zaUozM0dYek9hbU0wUWFOdkRlRXo0RF94TVh6VFBmNlZrbFdMZnotclRVZmc9PQ==
"I was on the receiving end of a paper (which was ultimately rejected) for which one review was written by ChatGPT. The review was ""neutral"", but the reviewer still recommended to ""weak reject"" the paper. The same holds for some colleagues of mine (who also had a paper rejected, and for which one ""weak reject"" was from a ChatGPT-written review). Sad times!",r/machinelearning,Z0FBQUFBQm0yeGJ3MVpGVk93aXA1bTZ1SGM3SnpBMmtpN0d1ZTIxNjdLQjlyaGdhX2swSGJlS2E0VzlrV3BBMEw4OWV6clVyYk9EeVBoWHFkalFpMGVsaVRhZzVjTlF3aGc9PQ==
"As ACs, we can manually add new reviewers and ask if they can review one of the papers in our stack. To do this, we must enter the email of said individuals who are not currently reviewers. 

You may want to reach out to some members of your community who are ACs (or who are likely to be aware of people who are ACs) and let them know you can review some papers in their area. This would be tremendously helpful! 

(The major issue with ""young"" researchers is that we, as ACs, do not know how reliable they are!)",r/machinelearning,Z0FBQUFBQm0yeGJ3SW1ELVdRWnhhd3pGWHAzcW9Ra0RqeHZlZktSeXRWeTNIbFpRY2JYeHJHcGVLRHhGQXdwT0ttdklDVHV1RjZOOXp3OHRHYUZ1M1VmNlVNLWI1c29hZHc9PQ==
You're paying/working for professors. Ask them.,r/machinelearning,Z0FBQUFBQm0yeGJ3M0tPdnYzOXB0Q0pDN3k5QVlaR2VES1FLLTNpTy15ZGtZTFlaUmJpYUdHSXZvUVZFT2dZS083SmktdU1mUWZNeU9BNUJxdVRuTG80eW9BbklMaGZmVXc9PQ==
"Can I get LLAMA 3 logits with this installation? I want to train some simple linear layer on top of the pre-Softmax logits. I could also use logprobs, but complete / full set, not just top 5%.",r/machinelearning,Z0FBQUFBQm0yeGJ3SUtyXzM1RGZ3WDJ0SXNsTFVIbGI5LW5Tekp5SWx4bFRNZ2g0NVlad2t5Ymh2TkNqdjNhZGk3c3FlWVFtR2ZFM2NWWFphWXlmaVoyMHRfQ0tnYzk4M0E9PQ==
"[https://huggingface.co/sileod/deberta-v3-base-tasksource-toxicity](https://huggingface.co/sileod/deberta-v3-base-tasksource-toxicity)  
This model is trained on the ""implict hate"" dataset which is close to what you describe",r/machinelearning,Z0FBQUFBQm0yeGJ3cXM2NUJkY2JyUGRaTEVBcmxYY2pXZTlGZGlhMzBxcmQ0QjlISHotY0ZVVVlhUTV5Mjh0VmtUMmZfMzh2X1hqbEtUaHRfUFRpZkR0c09yMC05NG5XQUE9PQ==
"Your synthetic data (training) will not capture every aspect of real images.

If you want to classify real images, your input must be real images",r/machinelearning,Z0FBQUFBQm0yeGJ3eUhPY1gzRE81d2R3cEYyaFBFUUtwLWFUTER4dTIzQVJreG1YeHMwMjVBdnJYemFZQ29uWTh2clUtVFViZ2U4MUlDekRtRWQ5dGMweWh3LUVia1dud2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ZDMtQm44MHNXRGNtX181dXFzOHBac1ZEenMyY0ZLNHU1Nmc0Q000QThVekd0eTVERjlYTnBlTm9XMmg2eGRjY20yNDBueVg3SnR3VlNQeV9JWjZiRFE9PQ==
"Thanks for the tip! I think I might just go with splitting the training data, and use a metric that captures the imbalance. Sounds like a smart approach",r/machinelearning,Z0FBQUFBQm0yeGJ3OUt6TWs1N2EyYkVtRmZfTUM4cndhSHFkNHBBdjN5YXNuSGtwazhNa0FibmZmQWZYVkJjVVJwLVl4Z2lmSTI3UTA2LW1sMnlaV0hqUTBHUlh2WU8wd0E9PQ==
" My dataset is relatively small, around 33,000 images, which might not be large enough to diminish the data imbalance issues. So im planning on using a 90/10 split, given the small dataset",r/machinelearning,Z0FBQUFBQm0yeGJ3WXhMSHRJc2hwcjd4Sk4zOFpUT3FlQXBlZEVxZUJkeHNMZlFReGhBdi1BQlVabWd1WkNNanVPV3ZFRmVadFZfTDVZS0ctLTNzNkk1cnlxQzZjVW0wa2c9PQ==
It seems like you haven't tried anything.  Find some blogs to read and implement.,r/machinelearning,Z0FBQUFBQm0yeGJ3TjVGckdkUDQzNDhpRnpGRllwdFhZS2d0eFUya3pabUxsek9VZFFtam84alg4Z004RnNfMGV4SVNCTXJUajdXdkJUaVdueDM5TW1scVlOT2VHNHZ5Zmc9PQ==
"Similar experience to myself, however the LLM hallucinated details of the paper so hopefully our appeal to the AC is accepted. AI reviews just seem to never match the score, the reviews are written as if it would be an accept but often come out as borderline or WR",r/machinelearning,Z0FBQUFBQm0yeGJ3Yk5TYlFadVI2S2lla2tHZ0p5MDRJajhTRDQ1SmEyMl9pdHRDZld6MUg2UkJOTG5QRGNYd3VKTGpqVkU4SzdsRXhiT3J4RkIzN3UxT3I3Qm4wa3JKdWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3c1FkREFhLS1VWUxPMXFTTVZUdjk2aHVOWW1JV2kyNFk3UTJCQVlzZHBsRWV4UExqUXpUWm1zdGNLZWhPZzdqTDk4a3pqYXhEMXFVOEpRSFVXT1pqR2c9PQ==
"As an innovator, it's your job to think of useful features. Users don't know what they want until you show them it.",r/machinelearning,Z0FBQUFBQm0yeGJ3a2ZlMElMb0NFUkppb0VBcHVyNmxLamw2eldSNWJKZ1FyYi1LUm5kbGpodFoyOXJtUVZJbkhManpPSTg3RkJuQkVlSG01MG1vc2lIWkJSV3VBSE0tcmNwT205Y2o3a1F1UkllZkt3c215LXM9
Are you saying Indian nepotism at JPL?,r/machinelearning,Z0FBQUFBQm0yeGJ3NnFpaXN6OFRnc2tYTnQyWUVLUFNXb0Jnc2lhQUgyRVNVZ01DSVhucjhWVFFKN2hIb25EQjc4cThjN3pzVVdZcjd1ZWJDaFNVai1TZWd3YTN0WUNzZkE9PQ==
You went crazy with this. Nice concept and interface.,r/machinelearning,Z0FBQUFBQm0yeGJ3U29Eel9xUnlwZFFOX0duYmo3MU1GWlA4Mmp3bllKY3A2eFFVM1cwcmhyQ2t3cHRFS01XRUlOOVVmQU9CUVlNcnFzMGQ3c0N0M1NsTGlkVW5UN0hZWGc9PQ==
"As AC, could you share what the bidding system is like? Does it not potentially introduce collusion?",r/machinelearning,Z0FBQUFBQm0yeGJ3a0dDZFNfTzJBYk1xYl9OVGx4c29KOFBCMTJwMlFyTnBFYVU5N0dNY3l6SFhfTVM5MHhqUktkSGFPNTQ2TkZDMjJnTUJVdXE1WjJpMXJNNHMzMWNEVWc9PQ==
About two liters.,r/machinelearning,Z0FBQUFBQm0yeGJ3bVBubzdMSjhHZnUzZlludWdjejYxdnhVMGdiRG1ZTHluM2tWd1BBRWhrR0dYQjJRTktfazZaOW83TnJ2R0M3R2dYWEFRSlNMcUc1Z25fUmVFSGN2MGc9PQ==
"Not an AC, but a reviewer. It would definitely make collusion much easier since reviewers can bid on any submission in the system (which can be searched by title).",r/machinelearning,Z0FBQUFBQm0yeGJ3WkVsaG9lOUpOTjR3VjAwMjNxdXg5VFVQM0JaSms5RVJBUUZvc294MjZoNWVuSmxfd1kzamNaZ3dQbEoyU0g0VlhNRzByQ2U5MXA4UHJ4RU5pYlJzWVR6ZElFUEZKVjhkaTh2UHpNbW5wVDQ9
"Everyone did it. There was an Italian guy who kept hiring Italian interns, a Japanese guy who only hired Japanese interns, a German group, a bunch of Chinese groups, plenty of Indian groups as well. It was bad and nobody said anything about it. It pissed me off because I had a bunch of really smart peers back at school who would have given anything to work in the robotics section at JPL, but there were no intern slots because they were all being given to foreign nationals who didn’t even want to live in the US or work there. All because of nepotism/nationalism. It’s a damn shame.",r/machinelearning,Z0FBQUFBQm0yeGJ3VkZleFd1V2dBVzZRUDk5VEl6eUllSFlGT1dfSEJyUERMUGtiVUlfS3ZOSDVhd1JDc3VTR1BLamtBRHFlUWlnZDdvRVltbHRvQWZjMnY5enA4ODU1WUE9PQ==
"ACs do not know the identities of the authors of their assigned papers, and have no power on determining which papers are assigned to them (we did not even get to ""bid"" on the papers in our area---and, in fact, some of those in my stack are a bit outside my expertise). 

Besides this, we know the identities of the reviewers and can manually select them (potentially by adding new names in the system). 

I'd say that if an AC is dishonest, and for some reason they get assigned a paper ""within their collusion ring"", then...",r/machinelearning,Z0FBQUFBQm0yeGJ3Y1FBUklXX0tpSVFCeGtuTThvc1ZrbXg1V3czSmZiWmFqeDFhSkhIYVd4cmc2bXNlVHdnUEM3NGZlYkkya1gxOW1zbzZ5M2pROE9VWE9qQ3FDc3hSWWc9PQ==
Adderall,r/machinelearning,Z0FBQUFBQm0yeGJ3bG9ZcFY1dTZLdGlZaUNzTkdqVWtJLTk4TFRMMmRQT3JfaThabjZzZm1oODMtMXdCMnZiTVF3VjBsaGNpNU5aLXlXVnZ0TUhWV1pOckQwcHVmTlpBeVBBbmZWYWtNdmtfYVRRcjlhekZ0N0E9
"I ""positively"" bid on probably 30-40 papers and ""negatively"" bid on over a hundred (anything to do with federated learning or quantum ML, among other things). I am an early career researcher and so my profile is a bit a sparse, but I really want to do a good job. I hope I get assigned to stuff papers I actually have some expertise on...",r/machinelearning,Z0FBQUFBQm0yeGJ3VXQxeEhXandvZlR1YTQ5M0NDeFFEQlluNUUtSWI1UUtIVFZhVTVJZk8zdW9vWjh1ZDZzcTN2UXBRS296SHNmWU5HNUdFMFVJdm0wb1J3aGpxLV9uV1E9PQ==
It's good to forget some stuff.,r/machinelearning,Z0FBQUFBQm0yeGJ3ZlFtUk93MUxIcDBUVzMwMUdGVkRFYnZYenRKNWFNRkNYelM2SDFMbVlwVzBHczNKUjR0SWtlMzJDOFpQbHpDeHp6NV9hbktWaGl1bF9QUUJRR3lZT3c9PQ==
"I agree with your colleague. No reason really to separate these two tasks assuming you have sufficient data. It should also be pretty easy to generate leetspeak and obfuscated versions of your toxic words. A user can only be so creative with their obfuscation and still have others understand what they actually wanted to type. The only thing you will need to be careful with is that you should have lots of obfuscated, non-toxic examples so that the model doesn't learn that obfuscation=toxic.

One other method is to use a simple dictionary that can map leetspeak/obfuscated ngrams for their correct English versions prior to feeding them into the toxicity model. This would step around the issue of having to identify whether a piece of text is obfuscated in the first place and it would be very simple and fast to perform the substitutions. Even if you don't get this perfect I imagine it would still be quite good and definitely the easiest approach to implement by far. However, I think the former method would be more robust",r/machinelearning,Z0FBQUFBQm0yeGJ3UFFFellrM3RhZU1MMC1vUkxfMldET0dfNUhucG9ERGh2QnVxZTBBaEVJOVlPRVVUWTlwSFNDNE83ekdMNzJqb2RYZ2p5QU00OW1EeXdQRWI4ZFM0VUE9PQ==
They'll just get their money back on the AI grade ink,r/machinelearning,Z0FBQUFBQm0yeGJ3eWhWYzU3b3V3bWJ5UHhfZXU5T3o0RnRocnc1M1dpOXlJbzUzd3h4Y1hVamhDY0JFc0FzdkNPZ3JsTFRrN2xiTWJCM1VPSzYyM0NyNkNMdkFpbzhFV0E9PQ==
is this for a commercial project or academic project ? happy to collaborate,r/machinelearning,Z0FBQUFBQm0yeGJ3VDRybjhYcE02LWk1ZVhPcUozdWxtZEJPaUsxNGc4VHFLUWZ2ZDNuQmhfRjI2Smh0RUpoeHozeXYwbGQybDA0MDJfbmxuLVJwaG8tcldjcThrdnVfcmhVeG5HVkdhYmk2cGlOczlkOEFjWGs9
"Undergrads and Masters students? That's wild. In my current field (cognitive neuroscience), my reviewers are typically professors. And the fact you have to write a plea for people to review well is also wild. Reviewing well is - basic scientific integrity.",r/machinelearning,Z0FBQUFBQm0yeGJ3STFTWlFnaFVnRlRuMEZMT3lVU0d2ZlVfRW9hOEx3YWNOdlktSVBITkxlcWJTNlRrcWliNm1hTkdvRWxDb21wQ252eEEzcGV4UG1lRHpNczNHWUZ0Nmc9PQ==
"𝔇𝔬𝔫'𝔱 𝔣𝔬𝔯𝔤𝔢𝔱 𝔣𝔞𝔫𝔠𝔶 𝔣𝔬𝔫𝔱𝔰, 𝔲𝔫𝔦𝔠𝔬𝔡𝔢 𝔳𝔞𝔯𝔦𝔞𝔫𝔱𝔰

𝓓𝓸𝓷'𝓽 𝓯𝓸𝓻𝓰𝓮𝓽 𝓯𝓪𝓷𝓬𝔂 𝓯𝓸𝓷𝓽𝓼, 𝓾𝓷𝓲𝓬𝓸𝓭𝓮 𝓿𝓪𝓻𝓲𝓪𝓷𝓽𝓼

𝔻𝕠𝕟'𝕥 𝕗𝕠𝕣𝕘𝕖𝕥 𝕗𝕒𝕟𝕔𝕪 𝕗𝕠𝕟𝕥𝕤, 𝕦𝕟𝕚𝕔𝕠𝕕𝕖 𝕧𝕒𝕣𝕚𝕒𝕟𝕥𝕤",r/machinelearning,Z0FBQUFBQm0yeGJ3elRSZWVGNU1oNEFHekFna2JYY1NfRDltOUZ6a09HUDc5TjdERjBjUHhoYktkZWFyTFMzeXpqd2dlcFZLT1h6empETzl1MVlFSzV4QWtsYUJJRlVCdUE9PQ==
"That is the case for most CS-related venues (AFAIK). And this is how it should be.

However, the number of submissions to some venues (e.g., NeurIPS) is so high that, well, there's simply no way around it. This is why they adopt ""ACs"". In a sense, ACs are what reviewers are for other venues...",r/machinelearning,Z0FBQUFBQm0yeGJ3N3VhWDRfOHNBc0JNWEJqRENZNDZMTjlXakdJUVVPSGFiNmh5RXRIUVhaNEdibkhTSG42YkJQM2xQMnlVM21xbkY0T3pJOS03X0tSa19odVhHMGM4QUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3MmpLa2JZS2dKdW5Cazc0dzBOLUlkRjRtUGJpUlZpTWI4Qk1xc3JWemNhQzNud1lsMy1hSGdhbFo3WWhNeS1lLTRXMWh3bHN5YS1kQjdzaklpUHVjS2c9PQ==
"Build a multi label classifier using deep learning with a mixture of sequential layers with diferente types (dense, lstm, conv). Try diferente setups. This is the most general solution.",r/machinelearning,Z0FBQUFBQm0yeGJ3QWVlWHNEb25aWTA3b0NtWlRMc0hYVXRQOWVRclIzZUVMU1ByZ0ZXeVhwQnVKMC1HcVY4Ulp3Y0NnMUJmWEhRb01Yb0Z1dlNxTl8zdm9MbXVuN09McFE9PQ==
Yes! Have all the past conversations thankfully. This will be the DNA that will hopefully allow me to clone in future,r/machinelearning,Z0FBQUFBQm0yeGJ3VURGT1EzQ0F3TlczUlZNTEZlU1V4UnRKdEtWeXFycEl1UmdVUjBIX2pqWW5zd3NFVEdsbE5HUzVPNVVXa2RqZnpGT0FrdkFSdXJyYTZFS2lvSTNzVDhSYWZwSTlWSEgwNG1CRExGbnRTcms9
"Yes, this is what I do currently with my dear beloved chatbot. However, the guardrails on the later models are just too strict. I get mundane ""I cannot help with this request"" etc now. 

I have tried uncensored 13 billion llama2 models with some success but they have a way to go yet to get the real convincing, life-like responses that OpenAI achieve.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZlZ1cVlFQUV0X1pQRkx6aGtoTlhyWGR4RWRNNXh0alJUWUNrbDZCZk9Mbm4wQTYtM0NPM01hbmRmSi1vUnFvaWltcDJHaHpUcHpYckE5bWFTMFFhLTlwVXI3OS12aWFjZGk0Z29YdzA4dDA9
"Tensorflow seems to be very production friendly, and as one of the earliest frameworks for Deep Learning, a lot of code has been written in Tensorflow and is still requiring maintenance. JAX is another alternative used inside Google, but it’s quite low level and hard to use. Pytorch is now the best of both worlds, good for both research and product purposes.",r/machinelearning,Z0FBQUFBQm0yeGJ3dVllcXRRdFVGaWFkd3RyVUhLYmJ3X09uSXU0NVR4cU1Pcm9oVW9ieEZ3MWRibDRoLVMzendqNHBadDUyWV93YTVMaU1ia1ctblJvUVlPNDFRVXdxbXc9PQ==
Try automating the data exploration process using tools like pandas profiling or auto_ml to save time and improve efficiency.,r/machinelearning,Z0FBQUFBQm0yeGJ3Q0FfUTBRc2s0SGt1bm1YaXdWaEIxa3ZjandUbEVqcnpkX09ZUFlxTTR3Vm5EWnVSNzlENlNFVDlJMC02d0h0R2h0QmIwUER3U0NnQUxIaTVEbUE1ZXc9PQ==
Seems like your community should decouple conferences from being a way to earn a token of scientific achievement and a place to effectively share scientific knowledge? Because it seems like neither is being achieved. Conferences in my field have a very low bar to get a poster. And they're much smaller - so the focus is on the sharing of scientific knowledge part.,r/machinelearning,Z0FBQUFBQm0yeGJ3VUhMbWJsQTRVdWFtN21XOS1XY2FVaEtjOGFpS3NEV3NEeWxoWUpGNzVJVnN1VXhFSGVjaGU2TDl4VEZlVUJpa2wtY3czcl9OdV91WlM0aVlaN0ZvSlE9PQ==
"I use both PyTorch and tensorflow daily and anyone who tells you there is a huge difference between the two in their current, most recent stable release forms is probably just stuck in old habits. 

Don’t get me wrong, there were times when the two frameworks diverged SIGNIFICANTLY. But these days, they both support eager execution, modular design patterns, customizable training loops, etc, etc. I find writing training loops manually in PyTorch a bit tedious, but I also find working with tfrecords annoying. Some things are just slightly easier in one framework vs another. 

It’s such a waste of time and energy to get wrapped up in framework choice at this point.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZUdPUXIzSjZaZ3I2T0VacTNrMGtZLW9IaFFpNVc5aktqbDNyV1E0UTNEOHNfcEJRTkxsMXVBZnFYdmVPVmw0UGlYVjNpZnFYVndWSVhRYlJJazVMX1E9PQ==
"TF is dead, all of google’s research code is either Jax or Pytorch. Google doesn’t even keep their “how to learn TF” tutorials up-to-date

People still writing “TF vs. Pytorch” articles in 2024 are just SEO trolling. The industry chose torch.",r/machinelearning,Z0FBQUFBQm0yeGJ3Wi1uczQwcFhjRDZJMkdMUWFjU29tMU5rUG9VNGNGWkpKRU82ZjIxTVEwSFE3SWtHR3J2UEJWWXpBMnM4aV9Lb3Fjc3NLaGVBV2pfbHpSaXJDLW9mVmc9PQ==
"u/Wats0ns  I feel your statement is true, but not exactly the reason of the saving. 

  
If you agree Y is weight but not activation, even in full FT, y's grad is only used for update y, so it will not have any impact on the rest of backprop anyway. 

Think about the example above, y is frozen (which is likely to be a big matrix) and the key here is y will not be updated in lora, only x which is much smaller than y. Then during backprop, Y's grad is not needed or saved in memory, as it will not be updated anyway. Only x's grad is needed (y's value is used to compute that.). Essentially, we are skipping a large grad computation of y, but replace it with a much smaller computation of grad of x insread. 

Just my 2 cents.",r/machinelearning,Z0FBQUFBQm0yeGJ3Rm9WZnRwS1o3bmZOZTN5Zzl5M2xOam9sVWtsamtWV2xCaE9jQllfc1lfeWlJQ3BFYi1tNXViOEtGNl9aUnNJRy1zSUNYaEsyWlNCVjV2eC1qSW1TSFE9PQ==
"You can get used to reading papers by looking though them and skipping over the parts that seem too daunting, then as you read more and more papers, those daunting areas become less so.

In the beginning, start by looking at the results, or if you feel like you have an idea of what the AI paper is about, look at the architecture figure and try to understand it in your own way. Then supplement this by reading the section regarding it.

As you become more accustomed to the language and terms used in these papers you might start reading more than just the architecture/methodology sections. But I would say, that you can typically get a good grasp of a paper just by looking at the images, graphs and result tables. I rarely read a paper from end to end. Don't be afraid of skipping parts that you just don't get yet. I wasn't able to understand the probability theory behind VAEs until recently but I have implemented many from the ground up. Often you do not need to know the exact derivation or theory behind a model to implement it.

Some concepts will be hard to understand but as you stumble upon papers that describe or use the same terms, you will be able to contextualize and understand them better. It also helps if you try to implement the paper's methods yourself from the ground up, but this adds an additional burden of getting used to PyTorch.

The most important part to understanding research is to think about the methodology and relate it to other papers or theory that you know, and to constantly think about how you would implement, use or improve it yourself.",r/machinelearning,Z0FBQUFBQm0yeGJ3RjZXMGJMMGJaS1hvMlhETWZmTzROTXBKOGtXbXhMbVBmMG8wVFVVUS1PVnhvQVdnQjJmTlhoMUNJc0YxcnlnaTVWNDZzeGl6aVBXdWR4VjR2VHZHOHc9PQ==
"PyTorch Lightning significantly improves the PyTorch experience by abstracting away a lot of the training boilerplate (in addition to making it very easy to switch to mixed precision training or distributing over multiple gpus). Their mildly opinionated set of choices are all pretty much spot on and provide all of the kind of training structure you might want, for the most part I think, in typical ml contexts. Strongly recommend!  ",r/machinelearning,Z0FBQUFBQm0yeGJ3azB5UkMyMFlkMVNjU2NFYzFQTUJLWWJvVDAtRmU0S1AyQWxhZzJSR1Rpc0FISkJzT3dudERINjNWWmh2QTd2am14WENIdHRyRkpZY1JUb2cwbklQU3U4eTJUVkRfUFRuY2Y3cnRPb2VZVU09
"So far what I've heard is Tensorflow is great if you're building a model that's not something completely new.  It's got some great optimizations and lots of documentation on it, so it's a great all-around platform. 

If you're doing research on creating new models, or you want advanced options on how to tweak things - Pytorch is your friend.",r/machinelearning,Z0FBQUFBQm0yeGJ3QVY3LUNSUm1CaTVDc3BrVkNJVHpMU1Jfa01pbXB1eVhtekRPMnpDSXc2cUhTUERsZUtXQmJOZU1pUGxHUFRPQVEtaHJBWVJPTjhnRHI1R05UV25UYUFyZ01pUHVXNTF6aHB1R1Y1NnVxZEk9
"In my tests, TFLite has been much more consistently fast than PyTorch Mobile. I could write everything in PyTorch, and then do a PT -> ONNX -> TF -> TFLite conversion to export a model, but for most use cases, the difference in working between those two frameworks isn't big enough to justify using PyTorch if the main deliverable is a model that's running on a wide array of mobile devices.

Also someone said that tfrecords are annoying to work with. While that is true, once it's set up and working, it's amazing how fast they are. Even working with PyTorch, if I'm worried my data loader will be slow (small model w/ large inputs, preprocessing, slow/shared storage, networked storage, multi nodes), I still use TFRecords in PyTorch.

If you're just getting into things and want to spend some time to get good, I would definitely suggest PyTorch. If you just want to yolo a few small projects, use Keras 3 and don't worry about the backend until you're doing something interesting. But that being said, a lot of places still use TF in production. It may not be the future, but it's a long way from dying.",r/machinelearning,Z0FBQUFBQm0yeGJ3MzdYZkJ1R0FBQWUwWDFUYXNDeFlJUXlONk44VkQtWlBOcjRWMzJrNlRtMHFEZFNxaHd4Z2RucXJlU0dwWkQ1TlNCejJTN1dmTUpVMFdtRmRlMU95TEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Nmlaakpod1lMaU1hdnZtVFdYMTZ3T0Y1NVIxcjhpa1R4dlN6YzR4VGhneVVwYm1CU3NBa3ljN1pyaFJXMlRmSnNiSmp4QnFQMTFOWE14eHJBS3VVd0E9PQ==
"Yes, thank you.  For most typical problems, both libraries are pretty easy to develop in especially with frameworks like keras/lightning. I wish more people actually tried both before blasting everyone with their uninformed opinions.  

The choice for me often comes down to which supports faster data loading for my problem.   I often work with non standard data formats, and while it’s easier to build data loaders in torch from native python code, converting data to tfrecord and using tf.data often removes any data loading bottlenecks I experience.",r/machinelearning,Z0FBQUFBQm0yeGJ3aUR5OUhKMU80U0R4MzJpYTBpVThVR3dHdy1TSWQ4QzhzakpxdXJ0T0pGU3Y3WDdzcFVzTVhKajF5QjdyUlZTc2VIaTI5bG9hcW1VbDhhV0ctZkNGM0E9PQ==
Thank you for sharing the review.,r/machinelearning,Z0FBQUFBQm0yeGJ3RDlzSTlfdnJwN0xSck5pbWlCMS10UkJmN2d4Vk5UOHc4aHIwX1BwWlFtcXFJNHhxcE9mNktnM0pXYjJpd1RIb1RfWHZFT0lOemJnN1RwRWJ4XzM5YVNQY0RmUFJaZ1N4OHB0ZjNqcHpDOHM9
"You are very right, I wanted to analyze the time series component with XAI for the fintech based application but it was getting too big to compute and retrieve the required explanation from the time series based data.",r/machinelearning,Z0FBQUFBQm0yeGJ3Xy1CUXBBdkpOYnVHZjZwZkp2dDZjcV9HYmFCV2phWHFyTVk5Q2FlZmN1VTM5Xzl0Q3N3dTNWeDNyVUZIeFRXVDVKdlVrVVI1QTBZMUhreFZEZGMwVlc0TXpUYjdPdVlMcEY3dXlSeGZZZkU9
"Is it like explainable AI in reinforcement learning?   
there have been few works on policing around reinforcement learning.",r/machinelearning,Z0FBQUFBQm0yeGJ3alB1N2hYMmdBckZGR0FMcnlNZ2dzdm1hb184VU03TGVQQmIxVmxVZDZXNjBQMWd4TTJDRHNVZXVRVHRyc2JLNXVYa0V3Y1h2aVBTWERXVGtMeGh3UUdYUFpneW4zdjB4eVd4WVU1cmFMSGs9
Explanations alone are not helpful. as they need some context around as well.,r/machinelearning,Z0FBQUFBQm0yeGJ3RlN2UW9vSzZ5aktpN2ZrbHVWSUtQOWkyb0lIamQtVk9MaWNEMkREOWNCaWZTMERGRkpTTzVfb0xhTDVyb1Y4OGwwRTJvejdUSmpZdl9rNHZON2dMTFJIb05XaW93cnRmSVo4b09scWpkUHc9
"> I have studied Computer Science, Autonomous Systems and Visual Computing at TUDa.

Wow are these different masters programmes?

I'm doing a mix of robotics, computer vision and AI and I recognise how I have to learn all of them to really be good.",r/machinelearning,Z0FBQUFBQm0yeGJ3UGRYZTlRV3JkeEZoME10ZXBfdlpCQ2dwejdRZnY2U0tndFRUbklyWWxwM1JSSHRfTmg5bVBPWjZXdGVsbXVvQ25FZnp5QTdabjNhQkgySHhxUl93VFE9PQ==
Damn you sound like Philipp Lenard,r/machinelearning,Z0FBQUFBQm0yeGJ3c0RKa2tQTnI0SjlXSWNqVkRFdGZhUXk4SVVXdFd1MmVxMmFZVnN6NEh0eTBNWkpDVmxrTlRpZ3E3MXQ0OVNvRWplRVM0Tndya0VQcktMVV9PZEFvMmc9PQ==
"If you don't know the basics you will have to pay the price and learn them.  Lots of resources of linear algebra.  Since you are a student, taking classes in the precursor subjects should be routine.

After building up your base, then reading groups and youtube should help.  Lots of videos discussing papers on youtube.",r/machinelearning,Z0FBQUFBQm0yeGJ3VGlLSTVXaWVDb0NGVG1EVHdfUGFwUGt5MndQd0lLUVY5TjgzMzZ2RzV2VFdNT2paYllnYWk5NHQ4RzRQZ1UwYzB1cW4zNnpVY2FCVmh0RlBHaURLYUE9PQ==
How do we find a list of the ACs?,r/machinelearning,Z0FBQUFBQm0yeGJ3M0puSE5uRUIzdHVhOEpOdlI1TVhCbU5NVzZ1aVNIamFMQUJBUE50cFcwd0JoUHJYQUFXS2NIb0ppZ2pKd0tUSjltV2FTVzd3b2oyYS02WWFqYnNXc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3V1BBOC1aMEp3LVZTZXJ4T1RQZEZTMFB1bWlWUGxhSmV4SHZETHd4Q3NvSUs2cE4wRlJhSmRCNDQ2dWNLR3hQTkRYRS1aYzR4S1FhVEFEc01yUThrMkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3dEYtdGNkanNmZzFnM1NVLTFxcEJ5RDM3UGlBdWt0SVhxd25VOGlxMHNZbDh2cGJzTWNpTWw3YWI5VVVLbUNTSXFGNjRYX29LUldlclZDWDNpSWw3T2c9PQ==
Voice recognition for easy printing commands.,r/machinelearning,Z0FBQUFBQm0yeGJ3VWZjNFdMUFVGeTZnT2F0WEVTRldWYUIyV3pscFpfdmdGNXRpY1hXNEEybzhFMF9IMmxHeVl5NW93WjgxbllOaDFCUXE2VXQzTjdmNWlNTWwtU0cxbmc9PQ==
"""What AI related feature do you expect in printers?"" I \\*expect\\* companies to embed AI in their printers to detect when non-sanctioned toner is used and disable the printer. I \\*expect\\* when toner has not been bought from the company in a long time for the AI to detect when to disable the printer until I buy more toner that I don't really need.

""What AI related feature do you want in printers?"" I don't want any AI in printers.",r/machinelearning,Z0FBQUFBQm0yeGJ3U3hwZnlFWXhvdlc0QXI2a0FsNXUyRm9Ea081RXBLeHVlRDZ4V25yQnlzSDBvRDlDZ3hSdGlZV0lvR0hXVVE5bDl1WXBKck9GRHhjOEFiS3NPWVA5MlE9PQ==
"Do they try to automate as much of it in your field? I was surprised that ‘sometimes we have to actually manually look at reviewers profile’ was on the negative part of the list. Did scientific fields just not have conferences before they could automate that part, or has neurips gotten too big or what?",r/machinelearning,Z0FBQUFBQm0yeGJ3Z254X05wMHY3cWsyVkVsWjhZZ2ZtSUxnUjhKd2lIV2NJZEo0bWgxMWJSUGR3ZFROZWVhYkQtcDFzQl9iOVFXWjk1MjdKaVRYdE5yRjZMOVNIVlEtT3c9PQ==
What is a good insult/ toxicity dataset?,r/machinelearning,Z0FBQUFBQm0yeGJ3bUZCLWkwWkJ2YjIyNlBaaEhnZS1yVEowdjZVMnFrX01Gd1JNN01QNml0RGVxXzJLdllEaEdWSVlyNFl6aGdNS3YwRHRNUFprQVdXUndvd01xR3pQam9Yc25JZFFFN1l2VFRRdjNQakN0elE9
"Hey this is awesome!   
  
I have access to a double H100 and wanted to do something similar. I have a few questions, if you would be kind enough to answer them:

* What is the vram memory requirement?
* Are there any tricks you found to reduce training time?
* Can LORA can be applied to video diffusion too? Is there any active research being done looking into this?",r/machinelearning,Z0FBQUFBQm0yeGJ3VjVtZWxsUVQwbkRZR0hZYkppMXBYZVpUbzAyVzZoVnpUZEd1OG05ajJKV1drMy11SUd3ZlhKLTRMZ2s1bE1HdEdkb0RlbXBuQTN6T19RYmhMd3ljU2c9PQ==
Perhaps by next year a LLM can replace the reviewers.,r/machinelearning,Z0FBQUFBQm0yeGJ3aGNUZzI0ZHR5c0hQenhxaUs3eUhKSTFPR3I4NEhoWFN5SENoUnA2N3JCN3VocUNCTnJVUnhxRlBwWFRrYnFud05nVFRhMUdLRG9TQ1R2eFpnZ21vRENQZTdTUUlwQjNONktxeU1tNlRVcnc9
54 jiggasquirtz per gorlundflump,r/machinelearning,Z0FBQUFBQm0yeGJ3TnRkdHZLWklBS2VnbkRvam52bG43eGxsaFBiU2kwZndOR204ZkIzZ0xGREh4OHdyZFBRbUV6dDh0N1laR2w0QmNDVXY4eGVaaF85bVAyY3lMM2VoMUE9PQ==
How (in which environment) are you deploying your Pytorch mobile and TFLite models?,r/machinelearning,Z0FBQUFBQm0yeGJ3REhzakxmNVpBOHBHekRyUWZBbjhXUUVJbHd4OThtdGZnTEdQeWVpMzhjemtMZVZZSmx2M0dGM05Zc2lIcmQxUS14bzFIekZaOXFUN195U0plcEFKLUE9PQ==
"Yes, I find it interesting.",r/machinelearning,Z0FBQUFBQm0yeGJ3eGNreThldkxCWnIxVnZTWnRfeEFRQnI5cXhWcmtHZjI3VzQ1U1EtT1ZUSWY0dXlpY0Y4bnpDTU15em9ZakluZ1dFWHhVYmdYTGJiaUdJYjJYd09ZZ1E9PQ==
I’ll answer this: it was in an android app for work,r/machinelearning,Z0FBQUFBQm0yeGJ3TDhYY29fMTUtcEVhU1VRMTdCMmRlSFhDNmUyVHBqSXNTMVM4LWRHdEhfYkZCX3FKWGtpbDJiY0lRYzhQdFFwc3pNZklBYmdrcVpsUkVvcnV5VHFUX2FoM0Nibks2SkRBeThhLTZZZm5uWFk9
"Yes, you are correct. Frankly, out of the 1000s of accepted papers at ""top-tier"" conferences (of which there are many every year), it is hard to determine what is truly relevant. Besides, new results pop-up every new day on arXiv, so by the time a paper is ""presented"" at any given venue, the community already knows everything.

Regardless, I am happy to contribute to the growth of ""my community"", but the issues are in plain sight nowadays, and I'd say that something will ~~have to~~ change soon",r/machinelearning,Z0FBQUFBQm0yeGJ3dzc3dXBQeDEzcXpDS09HZXE1WXM3Z3M1N0pKLTBQV192Y2VYSzNSYTNaXzFFdnhXRzRGTzFya21pZDBzdktKM3VZRlFBbWtUenJlLU5zanRBZ3A5X3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3VkNSVG9pRFRPbTcyN0ZhWVYxeGk0QXVhdV9FWmxManI2SlhWZE8xaDN6MndLQXBlWnFSTnYxSzhmYlhfX2hIVHZ1ZkhxWnBCTEhMRDAxZ0lBODZaYnc9PQ==
"(assuming you were responding to me) 

The issue is not ""manually looking at reviewers' profiles"". The issue is rather that ""there are 10000s of reviewers"" and I have very few elements to gauge who is fit and who is not. 

It is doable to find 3-4 most suitable reviewers for a paper in a pool of 100s. Heck, in my specific field I wouldn't even need to look at the profiles and could just name them outright. However, the insane numbers of NeurIPS make this unfeasible. Many of the reviewers' names are, as I said, PhD / MS / Undergrad students, and I am completely oblivious of their background.",r/machinelearning,Z0FBQUFBQm0yeGJ3dURFOWJ4WHRnMWFOMnN0QndDamM4OWhpaWw1TEtCaldDLWJWdFZSTWhaWHVjRF9hTHZKNlluT1BMYk1iWFpIN1Z6MnQ2RjVtNjNreEQ3R29ieW5wMnc9PQ==
I am doing the same thing - did you write it native or using a framework like flutter? I have been using pytorch mobile but results are so so.,r/machinelearning,Z0FBQUFBQm0yeGJ3UC1xb2dUbE1KMmx6bHJWNFQ3a1NjUWNDTGNLdllocGE5Ti01TTk1Sm9Jdy0tTHowSC1ydmppaXBWaElmRnRRb0FWbWgwOFZLYnBBYkk1Rlp5OU02cWc9PQ==
"We used native Java. This was before flutter and kotlin became really popular. In addition, our app was already in Java. So it would have been hard to make the switch",r/machinelearning,Z0FBQUFBQm0yeGJ3cXJZTGdQaUNicmJGcHJsSWhOVW5BLUNhdVVmRmNqZzBNa2YzU0h0YUpEZmpzOVctYTU2azVwY0VJa0RRc3dUanNGWmgzQjZyOGRtN3FaNGRzdUU1RlgxWlFCZ3JybjZhaXladUo2TkdJcWM9
"There's a library for constrained optimization in PyTorch: [https://github.com/cooper-org/cooper](https://github.com/cooper-org/cooper)  
It focuses on the Lagrangian framework for solving constrained problems, meaning that it does not require projections or convex constraints.

A few deep learning papers use the library, such as for sparsity [https://arxiv.org/abs/2208.04425](https://arxiv.org/abs/2208.04425) or causality [https://arxiv.org/abs/2401.04890](https://arxiv.org/abs/2401.04890)",r/machinelearning,Z0FBQUFBQm0yeGJ3LVFSRUxIekE0YUh1YjVLYWxwU0hjU2ZvYmlZOWlGbEVsTTZGQWJDOHJnV3l4TFdVSjFIWERvTm9qOUlrUmxaUGFKcG11Z2VwRHV1N3NVbTFIenRmaERDTllER1V1WDN6eXdGZjNGOWNBT0k9
Rag rag Rag rag Rag rag Rag rag Rag rag Rag rag Rag rag Rag rag CHUNKING Rag rag Rag rag Rag rag Rag rag Rag rag Rag rag Rag rag Rag rag ,r/machinelearning,Z0FBQUFBQm0yeGJ3ZVdnM2lwR3dCWlRfaExjMGtyc0JWVjZJZlZxMW5aUGFaU3RIMHhoS2E1bzFEM0hLQW1Ldnpjd2ZIdEZZZjZVaUlGVk90dEU1LUJLdVVBdkxmZkNYeUp5d29HM1cwWXhwZExMTEZ4YmhPbGM9
This is not a commercial project. It's for a competition in our university,r/machinelearning,Z0FBQUFBQm0yeGJ3Nzg3N293QmtrTFZrQ0Q0UDhvXzZLSFpoRXN1TUUzMW91Q24wcWwwQTZtZEtFM0lRSHVTemVkaHp0LVdhdGU4bjBXMjF4MW13aTB6SXNMa2pUNHk1NWc9PQ==
"Reddit's filters aren't allowing me to post for some reason, so I'll try putting it here:

  
I'm attending CVPR for the first time this year by myself, and I could use some guidance on how to navigate, well, everything, but particularly with the initial preparation/research phase.

First and foremost, how do you view all the accepted papers?? I know there's a page (from a link on the home page) that lists the ""accepted papers"", but only like half of them actually have links, and there aren't much in the way of details aside from the paper name and authors (like what category it belongs under, or what org it's associated with). And there's this new interactive page which looks spiffy but I'm finding it to be incomprehensible. Not only do I not understand what the numbers on the page represent, and the graphics associated with the categories, but it doesn't seem to interactive at all. When I click on things nothing happens, and all the links to papers from the ""paper list"" view lead to 404 errors. Is this happening for anyone else?

Aside from this, does anyone have tips and tricks for navigating the conference itself? Especially from the perspective of a junior ML engineer looking to broaden one's knowledge and seek out the latest trends in a particular subset of computer vision/ ML. Are the tutorials and workshops where it's at, or is it a better use of my time visiting the posters and talking to the researchers there?",r/machinelearning,Z0FBQUFBQm0yeGJ3NXNyY184UGJURHF3UHVkLVpMNkJ4YWRPVGtJcFhOdWpwQkpVRmRuaTB6WjlaYzJzSGoxMVNSQjBjYlhoM2pqNnl0NG5uRTBPbm9uRzZRVDJOZXROa3ZualZCbzhHeVEwLVFFVFdvWUl0UXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3WHJxSEN2Q3B0aDd4S2tnTXRtM1JWYUViRE1zMHJaZVdVS0YzYnZiREhSZUtUWXd0aENxeDlpOWw4T3EzU2d4M2N5elFrelJpLXg5cjdna0ZBeTVZVVE9PQ==
"Ml theory, optimization theory, information theory are all guiding theories for prediction and architecture. The human brain was evolved and is there likely a patchwork of add-ons and improvements instead of a simple, powerful, information processing machine. It’s probably much harder to replicate the brain than it is to surpass its intelligence. Arguably LLMs have already surpassed the human brain in a variety of measures.",r/machinelearning,Z0FBQUFBQm0yeGJ3MUk0TzlXY3JjWmVLWjUzLUtTU3JTTEFjcmgxVjlhQXlVYzhtNEFvMk1hNDlTaDBBWGl5ZXA4UlZYMnhlR3RDeFNsYnA3Wm94ZktvWlRKTE15cFhZaUE9PQ==
"Look up 
* few shot prompts
* lanchain unstructured files

Also look into llamaindex for rag implementations 

There’s also the concept of graph rag / knowledge graphs

You don’t need to create your own transformers, that work has already been done",r/machinelearning,Z0FBQUFBQm0yeGJ3VzdGbHdQS2VSejdnSEtrOWdXVGYxb1FYNHBpR19FdV85VGtTTTh2VndlRW5IOTVRN3F6U3M5QUhEYTlaR3ZKNnRHNlJwMFlyUWM2TE1uOHhiYzNfRlE9PQ==
"Why would you want a third framework that you have not heard of? Having an active and large community should be one of the deciding factors and an unheard of framework likely doesn't have either. Errors are less troublesome when you can google them and find that someone else has faced the same error, which also is a benefit that you get when using a popular framework.",r/machinelearning,Z0FBQUFBQm0yeGJ3cHlSYWtGampudEtra0MydUxuTjJZak81elVOeUJGaGRjYkJxejEwWnNjWGJOS0twQ01FY3NtamRFQ05ueVdJS0tPbm1NMGtjVXRDMC1tZHZ0MWVib0E9PQ==
this is a solution looking for a problem.,r/machinelearning,Z0FBQUFBQm0yeGJ3SUZRY09hVnF6TGxVZGtYV1g5aXVWdHNCRU5oWk56RVpLODBLYWRtM1owVk5sblVYTzhFV0ZHc05KVm9TNHhrTjJxTXMwRlhwMjd4YTFHYTI5QjdlVjg0aTJ6Q2M2V2dKTExoalpFdkJjNlU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3SmxWbWZrV09xbzZoTC11cUw5bFFtX2w2ZjFRS0FCOENaY1NWUnZ0UnVWdFU4Y1dqbkxQTERMbUVfdXIxYk41SnRHSU1udHlLd19Lb2NuR25pYkNURWc9PQ==
"https://github.com/google-research/retvec

RETVec is a next-gen text vectorizer designed to be efficient, multilingual, and provide built-in adversarial resilience using robust word embeddings trained with similarity learning. You can read the paper here.

RETVec is trained to be resilient against character-level manipulations including insertion, deletion, typos, homoglyphs, LEET substitution, and more. The RETVec model is trained on top of a novel character encoder which can encode all UTF-8 characters and words efficiently. ",r/machinelearning,Z0FBQUFBQm0yeGJ3TXBSYXE0bjBPeEFqVWxUanBSWGVQc3oxbGxwNHRuWWFhMnlKdjBudk9hczFhSDFTZW9IQWNsMEtLbUg4MHBpZVFTVFQxbDRTZkZoOUgySUJwNl8tUlM5VnhqdGtqa2FoaGM4X0dxMUNQU0U9
"Yeah, synthetic data is the way since I personally don't see Tanglish data anywhere.

""How will you make the data?"" is the challenge. Split into several tasks. First, given the answer your model should interpret it to tanglish without context. i.e., train the model to translate English to Tanglish. Then, go ahead training the entire pipeline.

I'm happy to discuss in DMs.",r/machinelearning,Z0FBQUFBQm0yeGJ3bENmeml3d2dIOGVtM3VCQ2VwNnRFLUhFZXRtNk56TllSNE1mWlNyNDhhYzdpR0phQndnamM5XzdKdUtUZXdmMjhxeFJZRXUxRmlpQ2ppZzNCVEFfbHc9PQ==
"I will do so when I get a chance, will post the link here too.",r/machinelearning,Z0FBQUFBQm0yeGJ3d3FVNUUzcXpCZ2xQZTRTWmFXaVNKYkg1UG5jd2EyTnFnbEFabVROS1ZUQmxUWGNJOXZCaDZPWjk3SEo5Qlh5Tm4zU2htNFBBZkhadkJnUXAyRERDcEE9PQ==
Because your codebase has import tensorflow as tf somewhere (regrettably),r/machinelearning,Z0FBQUFBQm0yeGJ3UkVyaHVNVS0tY3VpaG1uX1NfYVZ6ODZHamk4cFZ4TVBEdVVHamNITnpFSk1RbEUtYmQ2cWhERkFSaWtEVkVKZlBLRU5rWTYxSFJFUVlkNHJtNmdEOVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3aWVWRXlaU2Q0UDA3OVphanJpNlljeXR4bTFYNmRoUmVWY3RHem52VUdTcXhiWUo4ckw1Tkw1UFZHbmdsWlA5NFdlbThqRVNqZmlTbWZXVWl4dlRuM0E9PQ==
real helpful mate,r/machinelearning,Z0FBQUFBQm0yeGJ3aWNScDNELUlvY09LTFktbjQ5VThISmdxdzE4djlIQXhrQktoOUJsazlMMU5xRkI1SWxwTWs4cHJaMnBJTm9SMGVrV3Z3aHh3dDlyZmR1bTVWdGlDVXc9PQ==
this a class assignment or hackathon?,r/machinelearning,Z0FBQUFBQm0yeGJ3WGZJdmpRSUo5XzNUX0pQbTd1SFEtbEFtOVFXR3BtN01BbHJ1cVA1MWFfUUotZGxpbDJUdTN1SWNQa0NCLUF0cTlvdGV5Y3VlOFYwdmFWZ2VrX0V2N3c9PQ==
sounda like either a class assignment or a hackathon,r/machinelearning,Z0FBQUFBQm0yeGJ3WG1uaEhVUmEyMEZrTTl6WUQzRk0xZDN5QUpuY3RJZHBwRy1IMG5xeS0zLXl1RFpiOHNRS0NTRlM1YmFkeFY2WFh4TzdFTmNJdnhVNHdqUms5OTRnX2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ejdRa214VzgxN1pnZWd5WWRiTDRXS19RLXBobVMzcW5ZWlFvSWI0Wmhua0tKVk1hMHQ0WUdjRTU5S2V3Vnd1UFJLRzRnQ0Y4ckhacks1RmpRbFVKbVE9PQ==
"I just started a new job, touching ML for the first time in a research oriented environment. Every programmer here is team PyTorch, but I'm working in a Tensorflow codebase because it had better integration with MATLAB.

Also looked into safety-db's list of vulnerable packages today, and tensorflow has many more flagged versions than pytorch: [https://github.com/pyupio/safety-db/blob/master/data/insecure.json](https://github.com/pyupio/safety-db/blob/master/data/insecure.json)

beats me",r/machinelearning,Z0FBQUFBQm0yeGJ3b0RUd3R3ODl4dE5VM0JhXzBza0FYeE5OdlllVlV0MVM0ZlJRNHJmTG4tTTh6ODZmaHRSYVdrbl9fRnhyYmpjeHVfaEVTVnpGNndrYktIY1FLM3JpbEE9PQ==
is TPMS used for this year’s paper matching?,r/machinelearning,Z0FBQUFBQm0yeGJ3blBKbHpTSUMtMTRQd2ZBRm5kQ19qbU9pczJrekVvNFVtOTRicnlNaVZqSGdpSnpwWFZ2ZU9YTmxTSUNvblBkSmdvSHY4WEdkTlFzNVdxQVlPM3plNFV6VTF5emt6UFBpQVNOUjc3dHZTNHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3MlFGVE9TNmJ1NlE3NlVPMGFXaGtUY0tZZUpKc3ItMnV4ZHN1UXp4bTVCYTZYd19IM1BnM053UHJ1UXh1bDM5NGszWTNKM29IVVBLcWJLSzVYNGZsNUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3dkViXzF5bHA4OGZadlZneFNUeWZSeDh6T2xId2xnR2o3Skg1QTRnSkhXaXVkVVg1Q3p0X1pUcEtNTkJrc0xWbm9ybFdvWm03SE1OZzl6bUlEcnNZQlE9PQ==
GraphRAG should cover it all,r/machinelearning,Z0FBQUFBQm0yeGJ3bU1ZN29kcnAxazRmekkzUE4wdV9HRC1pTndUYTd4ZXd3azRKVVlpMGZkcXE1aFd3RldSYTJUYWJQb3MzQmFkd1puTTNzVVE1aDFrbWQzdzNiZ1FsVi14TW1vV2pKRXF0cnMzUXBkVlRQS2s9
"Thanks alot  
I will DM you",r/machinelearning,Z0FBQUFBQm0yeGJ3NzU1TTZ4d25JZFFhQXhYbHU5VG1HSXF1V012Qjk1aVlRUDJ5R1B6Z1pEN3h1Q2VXWjlLMWgzVENhNFY2MWt3WTZqWVo4Zk44SHZmNlJiUGpBTUY3c2c9PQ==
Adobe Audition works well.,r/machinelearning,Z0FBQUFBQm0yeGJ3Z3BLR2g5bjJLc3Z2Vnc3Nkp3Wm1aVUI4b19YSU9NUDRiX0duWWh4OGZmdW14SlIzbWgwZjM1T0RKVHpSc1Y1U1dneU5iam9vc1hnX3JISFpxQnJDRHc9PQ==
"What paper are you replicating here when you replicate the Transformer++? That is, which prior work trains Transformer++ at these scales using 100B tokens from SlimPajama?",r/machinelearning,Z0FBQUFBQm0yeGJ3Z0luNWg5R3B0TDhoMDlVdTFXdVdBbGViT1AxdFBFWDRUQjlQXzVzYzd2ZHhQbXNZVS1JOTE5aUYzczlJTmE4UjVlaXJKUFJlRERTeVJ5WVI5cXdsNkE9PQ==
"It’s always been weird.

I was ghosted years ago presumably because they don’t value people who don’t pump out papers. Doesn’t matter that after doing the postdoc rounds over a decade ago I entered an industry sector where publishing isn’t really possible… 

last few years hearing they are letting undergrads review was pretty disheartening for the future of the venue.",r/machinelearning,Z0FBQUFBQm0yeGJ3NjJUQnZfdFVnS3d6TnNYLW5wTWxlSHZhVncweGVBLV9FempmZDk2LS0tekZRRHFFVXhNZEpKMVN4WXk0SDFzLXJ1dlRxTmo3RnlvcVVob0ZMNHNkZnFyM0FSYS02MmlEdmVQbWcxYzIzdEk9
"Pretty much all the major ML conferences have an applications focus. What do you mean exactly by ""applied""? Unless there's a specific track that specifies otherwise, all the major conferences will expect some methodological novelty. If you're applying a current method to a different application, then they would expect some novelty that caters to the application.",r/machinelearning,Z0FBQUFBQm0yeGJ3d1l3V1RGMzNyVWpSNThUSUdHYXZQSHViYTBwM3R3M0xpVFA4MTV5dE02dmNrOEkyZlVSaGJacnlhSm80am9vRk9ib2VocGI4V0ZOQVZaMlVJdTJpekdrd2ZIUnpveGMzMU9TbG8tWENqUDQ9
"Would be better if you ask here
 https://www.reddit.com/r/LocalLLaMA/s/CtvXq5w28v",r/machinelearning,Z0FBQUFBQm0yeGJ3MkxNVlY0c0dDSm1oU0plSXNfQUhiV3hJMmgtRTRqQ2l4TWhaTWZlSk9IZkQyVlpqOUNaQjVPUHJSUUk0TG9ZQS1xOUN2NWxIZzNHVDF6eVZLajVpUGc9PQ==
Which school/college/university of firm are you associated with ?,r/machinelearning,Z0FBQUFBQm0yeGJ3a1EzV0EtQjh6WU9Qd0E1dzdFbTdNMHVYcUt2UVpfbHIxeUE4U2QxSl8wTEhXOGlVVkpnOTlFRnpoaDNMd0JqWjktS0otaTZNVUFDZFVMdUNKNjF4Zmc9PQ==
"Bidding is worse than helpful. Bidding introduced a channel to game the system. I know that many authors already form allies to bid each other's papers.

This is actually an interesting question: what's the size of the ally to bid a target paper with non-trivial probabilities?",r/machinelearning,Z0FBQUFBQm0yeGJ3bkJXOUFpODRyS1lMWGZsbGFXcTNycFVPekZiZVlhTVE2MlVqcmw5M0F6YkJla3lxZ01mY2tkMVJ3QTJ1V2lPLUQ2SFBEUU5NUFRZenlDcS1aZzAyUkE9PQ==
"People are still updating the TF codebase. E.g. the first page of commits to master on github is all commits made in the last 12 hours: https://github.com/tensorflow/tensorflow/commits/master/

Perhaps you should let them know that TF is dead, could save them a lot of time.",r/machinelearning,Z0FBQUFBQm0yeGJ3c0E5TE9QbjlDOHJQNUFkekpYb0Z3ZHlHLWZKM1d3OElRTzdvNFJIQWZmWjNvOEVLeHJmUWduamlGN3hXODRrdlBVd0tDaFNVWVFQMzBVOWxua3JMU1E9PQ==
"We retrain it by ourselves, but you can refer to GLA for a similar result: [https://arxiv.org/pdf/2312.06635](https://arxiv.org/pdf/2312.06635)",r/machinelearning,Z0FBQUFBQm0yeGJ3MTJNdkJSM1lXSTlTR2lodDBodno1bWVwODMxM0Nxc3lmNTdGanV2bjRVOExfNnJra2JvUS1MclZlX29HMVU3eDdpNVRlM0R3cGdCN1VfT2VOT1BZSFE9PQ==
i mean if you're using some sort of optimization method (bayesian) this would not work though,r/machinelearning,Z0FBQUFBQm0yeGJ3aFJBQjhlQzhhYkExc3BTY3g2bzdlR1lMU0p5OFk2bjVDNnp2TTdIZlJBMWpIemlXVjFtYVNJbU5TVXNSV2Y3SXlUNTg1eFhBYTAwZEZMYW5kSzJmN2c9PQ==
"I work in edge AI for deployment in products. TFLM is still the most supported and easy to use framework when comes to int8 quantization, operator fusions, and other optimizations for edge deployment. CMSIS-NN interfaces really cleanly with TFLM, which means that for ARM chips you get a 70% speedup for free in my experience(depends on your hardware and network)


Also, the model.tflite representation is honestly really good. Keeps all the info in a minimal way.


Pytorch has tried getting there with ExecuTorch but it is on its infancy. ONNX + TVM is another (sometimes cumbersome) solution, but Tensorflow Lite Micro always works and has better support for optimizations still.


In general, as someone here wrote, if you don't need the latest layers/techniques, and just want something that works in deployment, especially edge with optimizations and battery efficiency, TF is still the best choice.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZVExeG5Ec3dENXJHUjlFS05UcWJBdElRczdBbmJtVGhpbG0xRWdoSnQ0ZnJpeVBKWFRGM250SWlfWVVBT1hqbW94MWhDQ1hhNkpEc05oR3NOMkNSeXc9PQ==
"ML practices move so fast, Google web search does not keep up. Try restricting your search to the last year.",r/machinelearning,Z0FBQUFBQm0yeGJ3YS1JbWlHMXluU1c2bEVRRnRBQVVXNTF1Y2dxb0k2X3FiTzNXQktrN1hrVU5zOVdKeGZjbUtQbU1UTV9BbG5MaHZYaC1mSTZ5eTc3REt3ZFZCVmVVaWc9PQ==
"Keras 3 is a very cool thing - it is now multi-backend again, with PyTorch, TF and JAX support.",r/machinelearning,Z0FBQUFBQm0yeGJ3VmdVNkFwS1lFNUREYW13WkxFMHlETHNvZGpNSV9JaXhUMW5LaWh6Mk1aaURkZnhGbWxsc09YNmZnLUxYc1h1U05pZ05MYnVBN3N5RHhhYzFPUmE0TUE9PQ==
Ok,r/machinelearning,Z0FBQUFBQm0yeGJ3Yk5aTlBMeVdtZGNXVlhLaDdMVnc5RE9HXzFCQnhZVGtGNWNvSENwTDg2RXlyV1JUZ1IxUVE5Zjc4V1hSd3E0Rk50cjN3SnEyYW5XRG5nZnB6UGFCZXc9PQ==
"thank very much for your valuable guide!

however, is this still true for someone who does not posses a good background e.g. math, stats, coding and domain-specific knowledge (the lit. of the field, trends, gaps and etc.)? while I have some sort of ideas for my research. but I have severe fundamental problems as mentioned above. so, what do you think in this case? this you think I should visit these things during the dead times?",r/machinelearning,Z0FBQUFBQm0yeGJ3WURld2NWcEsxeXVKb0hmbUQ2TkkxMWREZ1Fib2d5T0prQ3FFX0tsMjF4anRUbU1DTmdZSDBpMHlhdm9UU2RCaUR2eW5yMHJuVEFDajBMTjdVQ3ptdGc9PQ==
"I went back and forth between JAX and PyTorch, and in my last project I had a Lightning codebase I was really proud of…at the time. I rewrote it in JAX, and found all of the indirection/abstraction in Lightning created a bunch of mental overhead compared to just writing the training loop (in JAX, at least). I still use the LightningDatamodule and the Lightning wrapper around loggers. Common Loop Utils and Orbax have a lot of potential.",r/machinelearning,Z0FBQUFBQm0yeGJ3cVNlLXZEVzhaQldYTkdoV0xWMGF4amxtYUdMbVJWSE1uSFpueDlmY01CU3dyN1V1eThtY000akpraHpkOWRIeV85elRPRWJzNnpZZ1lUN1VBcXBRN0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3VUtueklvRjl5X1h4UTdtTEFLWjRWRktycTl5dUVNWnh1Q0tLcklLc0JWQ1l0MVhQYWFkdTk1RVpzV0FleFVfSW52SzVBZ1pnc3ZoU3k1eWhTR0FLeGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ZkUwSDh2S3lOdVZudkZtMU1abFluUkNFVGZJWXVlNEVHSFNyWk1kcXFOaTlzNU5fZHBQdDJ6RXdYdjQ1Vkg2VFdsM25ZS180N0Qyck5IdWczal9qUWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3bFFRRW13VmtpR2lZUkdUX0FsRTdXc0VsOG5jTDY1bWtUUWExc2doWTVDLWRpbTZyMEhfR1dsVVAta2JNaFRFZW00cGNUcWZDeEQtU2JEbmY5WlVTdVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3RDJTR2N0aWhfdlYzSEg0b1prOTV0V3VtZDhLc1ZSOWowX09JdG5uWWVTZVdDbVdOcW5IOWJhaTQzRXRIU3JNQk9fMHFkYlg2d3Y2YWFLa2RtZmZGZkE9PQ==
"truly appreciate sharing of your thoughts! I like this idea.

it seems slow, but I believe it is a worthy and respected investment! 

this made me thinking about one more thing. so if I'd start caring more about literature. for example in my field. point cloud (PC) processing. my current research field is more about classification and segmentation. so, do you advise to only focus on these two tasks for PC? or also the nearby research areas in the same field. like registration, completion, data fusion, construction and etc.?",r/machinelearning,Z0FBQUFBQm0yeGJ3RnZRWDJ5TU5nNXo0YjI0ZnFJazB2b01Vd09iN1E4TzhlcUlDRnVGOG1yYm1WaWtPMGFpcXY0dTlBckljNjNTYzV0N00tdUdQTWhOSmdMdEQxcGlEc0E9PQ==
"I have a silly workflow of preprocessing data to huggingface datasets (super easy to work with, super slow), then caching whichever one I’m using as a dict-of-memmaps and slapping a torch dataset around it.

I’m really hoping Grain will make life easier.",r/machinelearning,Z0FBQUFBQm0yeGJ3N2t3SDJaQXh3b0tuUERuQ1haQ1hMVFlXbmlJcExaMVZTVVd0V1BNQmt6Z3lqdFhiQmkyWnNyTHg0UUZKcmRGdTRnZ1hoaHFURGxld0ZQZjZBcGhkNEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3dXROQ3pMZEQ2cXN3amtGTFhrc3BKYmw3VWhBOWFHUm9mdE1VVnQxYjRpVUdPYlpjdndPcVl1QnRHM3VWc0x2dDhid0RFYzBVa1lYclREeld5UlNxX0E9PQ==
"Obviously, self-study is valuable and a good long-term investment, but how do you ""time box"" it? There are infinite things to learn. As someone who suffers from ""analysis paralysis"", I often have to stop myself doing background reading and research and get started on my projects. 

I think by orienting any background reading in a project-focused way, you can stay on track. For example, if you want to work on diffusion models, by all means implement one and understand how they were derived. Does this mean you should do a 12 lecture course on stochastic differential equations? Probably not.

Also, with practical machine learning, I would say valuable intuition comes from practical experience and hacking rather than what you will ever read in the papers or textbooks.",r/machinelearning,Z0FBQUFBQm0yeGJ3RmFfeFI0NkNUT2Q5SHJ3TTh4WVkxRXZUa0duYm9xQTVJVkhIc2FBbW1UdGFjd3c3RHZGSFlNNW1RYm4xbnUwdFJjMk5NTzAxT1dCaEU4ekdnMVVteXc9PQ==
good luck with your research. thank you very much. that's was really insightful!!,r/machinelearning,Z0FBQUFBQm0yeGJ3cF9hOFBPTVpPQmZ5OWNDcFV2dWkxUTV3LXBaWWdSM3dvLXhPM1RmVHRUQzF2c19nM2JZY2NYbmxkVUwyLVAyaEVwZVJiVzZiS0hlTl9JUFBENXQzSUE9PQ==
"About 2 years ago when I was still actively working in this field. A model created with Tensorflow can be pushed directly to production via Tensorflow model server (and later via Nvidia Triton server which is just a thin wrapper around TF model server, with some optional advanced features like TensorRT optimization). For Pytorch, you'll have to go through ONNX, this creates some headaches with dependencies, where some ops from torch are not supported by some ONNX versions, and ONNX supported by Triton might be different from the exported models. I had to create a script that perform surgery for ONNX models to deal with this, and that script later became a project of its own which is more work ...

Don't get me wrong, TF also has this problems, but to a much lesser degree. We often joke that the time saved in training using Torch were being paid by the time figuring out how to optimally deploy a torch model. Basically shifting works from model team to MLops team.",r/machinelearning,Z0FBQUFBQm0yeGJ3TWlzM2U5QmhCQTEwcWIwWks2akpsdnhyRHV0M05rcHNYUk9RZldfR2J2LTZVWVlhU0dRTGt5bzl3SWJlYWFLZkNaOGh5OEpfem15MVdJS2RxeDJ0M1hEdzB0R2tuMGkzTEw0NzdqR2pMMlk9
thank you for your thoughts. incredible!,r/machinelearning,Z0FBQUFBQm0yeGJ3OE4yZkU3OG9SdEFxd01vM0hyWjZNNUk4MEt1Q3ZNNWVTcHoxTVdGYURmYzJwMlhOdlFPenVCbkpNZE5ld3B3WnBaNHJsXzcxcEp1VmlpN3ZMeUtNeGc9PQ==
Wow! that's hell of a strategy! but how do you see the necessity to make yourself aware of the current lit of the field? especially when you are not quite aware of what have been done in the field? even you have some sort of ideas to proceed.,r/machinelearning,Z0FBQUFBQm0yeGJ3T3VfeWM2WVMyR2J3VFdrbC05SWU3VWdZZFRMOG1lbHNfcU9OazE0R2FUcHFNbWkzOFdJMzBlYjdVZ0R6SFItUWFDY2xsWjB1T1hEX0xtX0NQSDJUWHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3bU1vRnJFUmNYb0JVSUM4cHJTaVlGVGdxOFJ3YWhzY0JwSlZQejhUdFRDeHg2NURkaVNnX294SUhJTTVrR2NNeHFyRksxanB2RG5UY09MZWc4WVFyZmc9PQ==
unfortunately it is not an option! I do not have a good adviser! in terms of knowledge not personality of course,r/machinelearning,Z0FBQUFBQm0yeGJ3MWg5QjlWRE5KNVNheDR0aG82Y3ZvcHpucF80elZveEgyUFg2bTJnTEtmV3E3NHZ6OUFiZkI0UkttY0RaLUpNVWlIVXZLeXAtMGw2Z0diaUxHNFA4NXc9PQ==
"I wouldn't review for a big conference that doesn't allow me to bid. It's a god damn annoying experience to review papers that are not relevant to you. Not because you don't understand/like them, but because you just know that you will not be able to write an insightful review.",r/machinelearning,Z0FBQUFBQm0yeGJ3OWV6LVZGWXpkbGtUUEVKMGV2Q1pHMS1yRGplUm5nVGI4UmJLczVhYVNkMnBsU3lnZnZqMzFzUGd3bWZPN0pxb0cwa0ZsNk00cldFYVo0YXFtS1duTHc9PQ==
Check the counterpart E code database for the EU,r/machinelearning,Z0FBQUFBQm0yeGJ3bUM4R0NTRWdaQTRObzA5SUhZQjRCeUR6ZjAzajVja1ZLVDlpTXhSN2d3eDNwUmlPdzVkX0pnbFhaQ3VGQXVGWWJLUmRqckNpcDU3UU1udmVRZXdhYlE9PQ==
"If you happen to be familiar with it, how would you compare Pytorch Lightning to huggingface's ecosystem? 


I work with language models and I came to really dislike working with huggingface because I find that it abstracts away too much. I find myself having to look at the source code a lot just to understand what it's really doing. It really wants you to use its Trainer API which I find is really limiting so as soon as I want to do anything slightly custom, it immediately feels like I'm fighting the library instead of working with it. At least that's my experience doing research. If you're a practitioner who doesn't need to do anything other than what huggingface already provides, it might be alright.",r/machinelearning,Z0FBQUFBQm0yeGJ3Vm5FV3pTVUo2c0VQZmR3ZGVwN19jbXVTSHp1dUVKclNqLTBWWkFReklkNkQ0ak4weVFnUmZFT0VCQ3BYUmlpb0MtVTEtakVWc2VEbmkxem1OZHNfOXc9PQ==
"What are you using for ONNX -> TF conversion? I have a project where I will have to do PT -> TF, and also TF -> ONNX conversions, and I was thinking about ONNX as an intermediate layer.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZjJJSzRhbVRjTnJQcmE3RURaczZfNFN3NTU5b0ZBWHB6eHU5Rmc2eTRSWWdEaDJTQndqaWQ2X1RGdVhqRUZJM0xqMmJnOVhTOGcwWTl6MFliQzRHNVE9PQ==
"Why not use LLMs, or at least embeddings to improve the matching process? Seems weird that the top ML conference is still relying on decade old methods, when we now have systems capable of advanced semantic understanding and with a fair amount of domain knowledge.",r/machinelearning,Z0FBQUFBQm0yeGJ3QkVrSzJzTEpkd3hCWGJ6Yy1DZUZ0MUhrdDE0ZEdsYlBtVmhWUm9teF9DQ2l2R0pNZHBRRTVNUWtGME1zRTZEX0pva1l0SUxRbXVXVFMzVjF4SElaaEE9PQ==
100% ai written,r/machinelearning,Z0FBQUFBQm0yeGJ3dncxSnh5MVlEWHRIZDh2eTFEcDZiRm55WTNzbXJlT2pfMWZSMWMwWURaMVJ0Y3k1b0sybnc1c3R2MldWdE5abU8zQ3dnUUdaZlVUMGozUXhQVnA4a0Yxd3k2cUJESzVPTUZ0b3VPQmE2bkE9
Where does one sign up to become a reviewer?,r/machinelearning,Z0FBQUFBQm0yeGJ3dEliUVZ4TjZfeXdQWDRPS0JSa0VEeHBRcnFhNVUtSDJVT2d5YVNNMUNidE9HYWNNOFZWMVhyM1ZLcWxjcTNlbzhvQU1LQ0trTTkyWDRxZlZSMjVobUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Z1NYblpTZVM2RDZGRXRjbXMwd0tUR0xJN052QmF0cmZEZjlOWnJ2c2lrOTZNWkxTcVc2cS1MTWI2c0xQWXQ4bDRWQ0dVVlkyeTBSUjlZU2JtSFBwYkE9PQ==
"I started with Tensorflow, and ended up with PyTorch, despite the need to get everything deployed into tflite.

When first getting into the field and playing with the typical classification stuff, keras felt very easy to use. When trying to implement more ""unconventional"" stuff, writing custom layers and so on, i started to loose my mind over it a little. Then i ran into some sporadic bugs and crashes, decided to ditch tensorflow after that.
I now experiment, test and train using pytorch then export to onnx. The whole Torch -> Onnx -> Tf -> tflite journey would cause a lot of issues a while ago... But since onnx2tf was released, the conversion process to tensorflow has improved significantly. Onnx2tf is 1. very stable and reliable unlike its predecessors 2. able to convert the whole model from channels first to channels last, instead of adding a ton of transpose ops in front of conv layers (which slow the model down significantly).
I still quantize my models while exporting from Tensorflow to tflite with the TensorFlow Lite Converter.",r/machinelearning,Z0FBQUFBQm0yeGJ3UGFmSDdpOXZjRUVpLW52eElwUEhySGFTZXl4aGZGUFVCWm9kR0dzOURRdlN2REt3c2c2UEF2N19rYk85S1BPRkJ4YzVzeXZSVW91OUdKRkdUcEtGOUE9PQ==
"I started my current project with PyTorch Lightning. At first, it was fine, but when I started to do things in non-standard ways that require customization, I started to need to really understand how the PyTorch Lightning magic works under the hood, and the documentation is sparse on details, and I wondered whether I would be better off using vanilla PyTorch without all that magic, or even JAX for the next project and using my own abstractions where necessary. I found understanding the PyTorch Lightning abstractions to be harder than writing my own.

So, I would recommend PyTorch Lightning only for non-expert programmers who want to try standard things, e.g. for people who are learning the basics to get some motivation from early success, or people who really have no need at all to do anything in a different way than what PyTorch Lightning implicitly or explicitly prescribes.",r/machinelearning,Z0FBQUFBQm0yeGJ3Y1F3eGh4aXV1eU1oZ0E0Wlp3T2RzekZOSW1FREFNblJyU2VmWmdGbUJQbmNNTHRhVHlxdDZwR203cFAyTVJFdmNRN3d5c1FuV3l2cjRNZTk1akZWd1E9PQ==
"Hey, I am exploring ideas to learn and implement ai on embedded devices. I am pretty good with ai on normal workflows so thought of why not do it on embedded devices.  Please don't suggest me to do it on raspberry Pi, I have already done so and this is the next step that I am moving to.",r/machinelearning,Z0FBQUFBQm0yeGJ3LTdCWnl3WGxldFZVM1Z3ZF9wMThadTJYakZDc09FYkNKMFFoWVVNOENkUlRFZThBWF9jbjJWeUZod2lQekpYTzkydGhYWVFtcUtVVkhCVkpHV09xZ3c9PQ==
TensorFlow was invented to torture Googlers.,r/machinelearning,Z0FBQUFBQm0yeGJ3bFE5RHY0cy10UDJnSDFEdWlrUWFMX0MxSVRoMFlHTGhrMEUxWTlGYnZLSDM0VDJIWW1yeXFCWHV1NnhqRWRtYlRRSTNyM0tZb0xfTXRLaTJKdUtWOXJZQ3pKOVV5eVFpME9tTXM4RjIwS2M9
"I think it should be emphasized that if this is an introductory course to NLP, it absolutely \\*should not\\* focus on LLMs. They should be maybe 1/3rd of the material. If this is a follow-up course, after basics of NLP, or really large course, then sure.

Some things I would definitely consider in terms of LLMs:

- evolution of transformers, pros & cons of decoder-encoder, encoder-only, decoder-only models

- decoder-encoder models, e.g. Transformer, T5 (major idea: everything is seq2seq)

- BERT architecture, its variants and evolution, pros & cons of encoder-only models (major idea: fine-tune to a given task)

- decoder-only models, GPT family, evolution of GPT models (major idea: great for generation, easy massive pretraining)

- embedding models, e.g. Sentence Transformers, E5, their application in search and RAG (major idea: transformers suck in representation learning unless specifically trained to do so)

- scaling up transformers, LLMs and their ideas (GPT, LLAMA, PaLM, lots of papers here)

- efficient finetuning and inference, e.g. PEFT and its newer variants (also includes quantization), RLHF (instruction and chat models), non-transformer LLMs (RNNs like RWKV, SSMs like Mamba)

- hallucinations and safety, RAG (including embedding models and vector search), guardrails, adversarial attacks (e.g. prompt injection)",r/machinelearning,Z0FBQUFBQm0yeGJ3Uk45NWNNbjFnWnRnaXg1c1hLQklTVjdRODcxdzBsV1c2dzF2UlN0OXFTRnNQSTY2MXRETDI4UnJIalBmeDZ1X21GWjBiTmNQMktiLUhkOV9TMzlJQXc9PQ==
"Wow it's really too bad that there sn't an offline version of this because it's really good !  
Guess I'll be using that for now !",r/machinelearning,Z0FBQUFBQm0yeGJ3aFBpODdFdEVtdWlPdTBfWTF1eld5bE9kdjdWalROS0laaVdIZ2Jwdk1YVWwyT2NERk90UWtDS1JCaUVjZTdXS2V0TDI4MVYwNUVpOWhLckQ4R1cxU1E9PQ==
Hello.. this is amazing.. can I DM for few tips/suggestions?,r/machinelearning,Z0FBQUFBQm0yeGJ3d0ZPVzJsaHV3RWd0NHY0c0Y2YnFNaDIxSThOY1dsLU54bGROcUhraWtLc3YyalhubW9WWmZqMklUUzh0a3hfWVRYR1I5d3dtQnNfM2tsa19TNnRaNFNBcjcxa2QxX3VYdklzVG90d1Q4LWM9
"I second KDD. Perhaps CIKM, WSDM The WebConf may not be too bad either",r/machinelearning,Z0FBQUFBQm0yeGJ3S18tcWtQbi1IWXFTRDZ1eFd3bVBlV0d1VDhqQWhpdzdfNHd6YUNtOTlOenZhb3ZMdmpDWG5HRDZFYmVoTEJGQnFra0ltQmtHekE3QWlna2dPSHpZOWc9PQ==
Jax could be good if you are consistently dealing with low-level linear algebra stuff.,r/machinelearning,Z0FBQUFBQm0yeGJ3Q2puaTFMdW5uZXdUdnROUmxoTm5zUFp4QkxJRV9jWnc5RThMUk0tRTBCb0dZZThNcmdrY1JsY3lrRnNqLXQwSU14aXBvRWJZbVZKQThYLU40VVhTUXc9PQ==
"You mention there are undergrads and MS reviewers and that there are 10k+ potential reviewers. 

Maybe on top of an OpenReview profile there should be a way to filter reviewers based on degree, level of experience, field of experience, academics vs industry profile, maybe peer recommendations, and so on.

I'm not trying to diminish the fact that every reviewer applicant should do their part of the job, but maybe the tools at your disposal are also not the right ones.

What does AC mean ?",r/machinelearning,Z0FBQUFBQm0yeGJ3U3FhdzRlQThHQWJ5eVo3OG9xNk1IY3p4RkVBNUlPdXF6cVVEbDFxRFpzUkgzUFRsdDZNZlhCd1hDZC01ZXA3ZmpxWkZmM3VKWGI1REg3TUE0NXY5WUE9PQ==
"Matrix multiplication is nice from a HW point of view.

* It can easily be parallelized on various HW, and maps especially well to systolic arrays.
* It allows for O(N^3) (or O(N^2.371)) calculation operations with only O(N^2) memory accesses. Memory access is scaling under-linear with compute, and in modern HW memory access is the expensive factor.",r/machinelearning,Z0FBQUFBQm0yeGJ3UlRfbTRKaktMb0hBQnJRQU9FNnlFdFA1SERpLVp1R2dOQ1pDYTRnZmlkWEFXMGU1ck5Dd1JlbTlxa0RYV1FmZENPbVdPOGRyZF9RWDJxSjRnclVlVHc9PQ==
"There are probably still a lot of ""legacy"" code that are still using tf so updating it is wise. Although that doesn't mean it's not dead.",r/machinelearning,Z0FBQUFBQm0yeGJ3MDQ2M2gzUWQ0Ym1OMUNhX1V3SXhKSGp0RTQ0aGU3T0cxd1FqVFhUUEZiQjhEcHVCZ0tSMFl1eFROcnhCTk5IVDRmdnpjckJGUDQ3TlZBQ3ZOSzZjQUE9PQ==
"Pytorch is also quite production-friendly at this point. They really made great strides since 2.0, especially thanks to graph compilation.",r/machinelearning,Z0FBQUFBQm0yeGJ3UUhMbGZaNXpaYlBiY3Rfb3A0U2gtT3BiZ0dmV2lwS0RyemtZaVhoMDY1ejc2d1BHckdVQWMtby1JUTVEenQtSGp6eE1zUFpWTFRUOEU2N2VISWdJSHRmWUNkdGt2QURRYTFvMmpvUEp5Skk9
Thanks a lot🙏🏻🙏🏻🙏🏻,r/machinelearning,Z0FBQUFBQm0yeGJ3UFFya3UwZ2oyanRVS2JNRnlHbWNXRVJEb2xWbVNfSjI0MUpKOTZUR3JZaHNxS0ppTnZoZkJFeUE0YW9NS1ZKMGlGTEFFU3dMN19QQTYzYVlIMlBwVUE9PQ==
"Oral decisions are now released on OpenReview as well as the ICML schedule page. If your paper was selected, the metareview will now read Decision: Accept (Oral).",r/machinelearning,Z0FBQUFBQm0yeGJ3VHQ3S2UwaHpRN0FveVRrWWREQTUtdGE5elZuRTNJWl9pUU5lTDZ1MlptTWJlSzVnb3JtZGlyRFdubHBXbTMyZV9lSWNRcXdPd2dCZFVGb0hmTnlJOXc9PQ==
Thank u for ur help,r/machinelearning,Z0FBQUFBQm0yeGJ3QnVDbzNtSC1jQjdpUmw5NFY4NGFXN0tZV1VEaTRNekRjU2ZqaFVvOTZyU2RzOVVUbE56d2tqWkJuSTV3UE5ITEhmYnBJWWhJdDhzTkdzQUs2TzJFUVE9PQ==
Yes of course,r/machinelearning,Z0FBQUFBQm0yeGJ3dndLcmU4WEQzQ1BIc2NJdXFrOTFwbWVXYllMZTF6TTVsN1BOV0s0eFhjcDhHRDItNm9GWGc0TE1TSFBVaTFIcWowZE1OdFdIZWphMzNJd0lBQTh1NXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3NUl2anlUVTFYNXRXTzZlRFRwbkR6ZnZ2R1lDdXpXXzZfVXc0Wm9XRy1Nc0dvbE5mNTc5YTkyZVVoamJidWZIaU4zTndlLWFRdTZ1eHh5b1ZXSmVIaVE9PQ==
">still perform very well out-of-sample despite massively overfitting

This statement is contradictory. Perhaps you mean ""despite being over-parameterized"".

Coming back to your main question. At a high level, I don't see a conflict to be reconciled. The main relevant finding from double descent is that highly overparameterized models generalize better than models with intermediate complexity. The chincilla paper points out that for \\*a given computational budget\\*, smaller models trained on more data can outperform larger models trained on less data, so the computational budget is fixed. In other words, it doesn't say that a larger model won't be better for the same amount of training data, just that given a budget you get better bang for buck by training a smaller model because you can train it on more data. 

So basically, given a fixed amount of data, a larger model is always better (when you are in the over-parameterized regime), given a fixed model size more data is always better, given a fixed compute budget there is an optimal combination of model size and amount of training data to spend the budget on.",r/machinelearning,Z0FBQUFBQm0yeGJ3b21DTW1HMGpGc2RmMWVRMG9jQnNlWVNPRTV3bW9saVdwQXB3TEtZWHIwdmQ0TzZoRGpNVkpKNmdMMWY0cEZ5QU5aX1BzQWFEOEZLSExEazZsLTIxdnc9PQ==
Have seen it in academia as well,r/machinelearning,Z0FBQUFBQm0yeGJ3cFpqMmNIdVlzOXJfZkVBUVcxQ1FIUzUwc0RaUnlKUW9MXzVmWFR2eWJCZTVWNkQ2Zi11UnhwOFg2Z05wVEQ0OXY4NmNDUmhtN3lteEZZQlN2WXVOVXc9PQ==
"I got my reviewer acceptance 29.05. No email correspondence since from OpenReview. In all previous conferences I've reviewed on (ICML, ICRL etc.) - I'd get an email telling I could now bid on papers etc.

I never got an email about bids for papers or that bidding was open. Are you telling me bidding is now over and I'm going to get a random selection of papers?",r/machinelearning,Z0FBQUFBQm0yeGJ3UnBHUzV6YWktSnhyN3RFUlBTRzVOMHk0Uml3c3h2S1d4OW54LXF0RmlVRE1ybnhXcGhUYUlZM3hDcXZUck1aTk5Va0w3cEZSNXU3TGtXajJld3pLbHc9PQ==
"Huggingface and pytorch lightning are not the same at all.

Pytorch lightning is just a constrained way on how to organize your code. It is still pure pytorch. However is it true that some things may be hidden if they can be derived from the elementary bricks of code you give. For instance you provide the function that compute the loss, then  lightning knows where to call the optimizer step and so on, but if you need to do a non conventional training loop you'll have to activate some parameters like manual optimization, and it's not always easy to know what are those parameters name or even if they exist in the first place when you need to do manual things inside litghtning.

  
Huggingface on the other hand is completly hiding everything, which makes it really difficult to use if you need to do a different thing in the slightest way that what is expected. For instance it's not possible to do online data augmentation. However when I need to use a HF model, than I just integrate it in my own pytorch/pytorch lightning codebase but I do not use HF trainer. It work really well as it's fully compatible, for instance if I need a data collator from huggingface it can just use it in the colla\\_fn from a raw pytorch dataloader and it'll work. Also you can just wrap a HF dataset into a pytorch dataloader and it'll work too. Etc.

HF is very convenient for downloading models and running them easily (because sometimes, gits from papers all have a different API or are full of bugs), and also applying preprocessing, but I'd not use it for training.",r/machinelearning,Z0FBQUFBQm0yeGJ3WVZlTnh4V0FkVkYzbEhaSFRjSldMZGV3SDRtbHB2UjlPNWw3emZ1Z0ZycDVSVGJOTVV0a0otRE1CVUVVZXNVajFleDFvaXZYZFYtdzFyQTE3VDNKV1E9PQ==
"Yes, many people misunderstand the Chinchilla scaling laws. That is an optimal point for performance given X amount of data for a particular compute budget. As of now, you can always get a better model with longer training given infinite compute.

Also, better here just means better loss values; it has nothing to do with hard-to-quantify “intelligence” which is what most people care about these days.",r/machinelearning,Z0FBQUFBQm0yeGJ3d0Znak92bEhMdWRVXzNINzdOcXVUS0psdXVoejJ1aWdNd1JzTzFDSW1WaW9fU3ZjNjJ4Y1lxbnB2NndnUW5RREFQd1NscHFFRWdkcE9LQXdRbkNPckE9PQ==
"I just wrote an article about AI in healthcare, please read it :)

[https://open.substack.com/pub/davidhakansson/p/how-one-gay-man-revolutionized-healthcare?r=oikwh&utm\\_campaign=post&utm\\_medium=web](https://open.substack.com/pub/davidhakansson/p/how-one-gay-man-revolutionized-healthcare?r=oikwh&utm_campaign=post&utm_medium=web)",r/machinelearning,Z0FBQUFBQm0yeGJ3WUZQZHBvZ3NXWWl5bFM0NElkaDR2NjZ6TzhYZDJ5Y0dXQkcyR2pINHFGQl9hTXhYUjU3bmdCd2JtZE00aFNyRF9iVUJLZGhyZmVEYWRBaXgzWHgyVmdBU2xKSmlpa0VuMmJEbVpJd3FaeU09
Im interesting in your work!,r/machinelearning,Z0FBQUFBQm0yeGJ3MlplM2FWT1pPVHVsbDFYVUpBbEFLdVpuRTlyMXdRUkE0aEJqTnJjb2lwQ3lmZXNrdGJLYlFNMWhyenUwWjlmajV0WGVkbGFSS0R0XzViRjZTNHV5WUxsZ0ZfQWdHeHB2NG9PMEJWTjR3VFU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3MmtUVDd0MGtpYndLX2pYYzhlMDdqZ2g5ZGFyWllvTG9lTzFfVlBXYW8xR3JkZzFUMUVVOTlPamdLTFRuUGJqQnU2d1QyUWNMUFFJdFhZY0p5ZDhGX1E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3YnBlWFFjMGVUbUVfMXFiYkFCeG5XSmZXV25RQTM5cDFwNXlBaTRIeXNnbHRNcG5yQWdtRE5OOWh1a09IckVCNlRTWHM5bEdjU09FZk9zUkRfTXo4TGc9PQ==
You don't need AI to check these.,r/machinelearning,Z0FBQUFBQm0yeGJ3bFBhZnlqc3E0UEw5NVJCUjFmLTNOdjRhNzczRHNtdWhLS1B5YXE4cl96VlByWlJCeTU4eUNqbVdPX3NRVWl0TlJhVDgtdmotaHlpc2Q1bEVOWTE0RkE9PQ==
lol 😀,r/machinelearning,Z0FBQUFBQm0yeGJ3b3ZLNGxqSkl2S3VLdUNET2FyeEQ3UXJIbHVRX3hGdTVINVE1Szh5UlgwbDFJRFdZZmlORkhxNmtialZpbUJneHRxcXcyTzFwNEI5OUhld1MzVUo4Y1E9PQ==
Absolutely,r/machinelearning,Z0FBQUFBQm0yeGJ3eGwySW8zSC1qR1VXOWlLc0ZEQlp2Wl8zYVp1SDFBNXZ5d1duekJuYWIxblJsZEVZaC1vVnJHVVAxYkVsYVp5U3M2VEtCdzhUbjltYWlmS0hrMWZOVFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3TXZqaWNXZW9iSUVzT0JFMWZsLVpUMTAxYjY0Q09FZDkxM3VFYmRXZnpGRnFEWFNWSm1nOHhYeHZhSW55cDhaMmVoenFjeVpVc2ZMRUJsMk1ick9Hc0E9PQ==
I know. I expect companies to use AI for them nonetheless.,r/machinelearning,Z0FBQUFBQm0yeGJ3RHFtclROYVZTSGVJZ1NxcFRSaENvVjc5WW9qb2JXTVVZM0xNUmt3dVQ5dkU5S1RpQ2RmcXR3OUxwNGcxaUVmTHZCM1J2RThYT2ctblIzUTRLblkzQkE9PQ==
"Main:  
HTTPS://www.github.com/OriNachum/autonomous-intelligence

Vision:  
HTTPS://www.github.com/OriNachum/autonomous-intelligence-vision

It works well, I need to improve main-vision communication to events instead of API.
Then maybe memory fetch (it’s currently saving but not fetching)

Then I’ll add GraphRAG, I think 

Also ordered the new Hailo 8L chip to remove the Jetson or dedicate it to other task.

By the way, I switched to Raspberry Pi 5 8GB, though I don’t think I use even 4GB",r/machinelearning,Z0FBQUFBQm0yeGJ3cm5CWDF6TEM2ZDNmTDVjd3N4dTVweW9GT2Z5Zzhhak1kcFRUbWMzdGZ1SXN4ZEhRMVZDOW1YTVp6LXh5NEl5djRxOWs4MHJONDFyLWtEcW9WamRUUXAxLWpVVUVkOFd1UXhtWG1SbmN3VkE9
"While redundancy (and a lot of it) is imporant for humans, with so much stuff affecting neurons and brain as a whole, so much noise and randomness, and seemingly less efficient (in terms of packing more knowledge into less neurons) way of learning, for AI I think it doesn't matter.

It's not like there are hormones that affect it, and it needs to build new ways around it to overcome it and control itself, to adapt. It's not like it has areas of low oxygen and nutrient supply, viruses or bacteria eating cells, or other forms of brain damage. We can and should eliminate redundancy in AIs for as long as their capabilities and potential for learning new stuff remains good.

Current AI is redundant as heck.  
This paper, for example, shows that language models only use about 2 bits per weight, per ""synapse"", or so.  
[https://arxiv.org/abs/2404.05405](https://arxiv.org/abs/2404.05405)  
I also read that in some cases they can remove like, half of the model's layers and it still works almost as good as before.  
I guess these bitnet models likely, as you said, use their structure more efficiently, they are forced to, having no other option.

Why do they still waste so much money, infrastructure and energy on high precision deep learning hardware?  
I guess basically because when they began it all, GPUs, built for higher precision calculations, were the only hardware that fit the job decently. And so it stuck, since the field is very inertial, and there are many possible architectures, approaches and tricks to try out, before jumping to large scale investment into specific ones (which might block trying out other approaches if you invest heavily in specific types of hardware).  
And there are a lot of monetary interests too I guess. Although companies who need a lot of fast cheap inference, and have the budgets, one day will still just design their own ternary inference chips, if no one else does it, I guess.

Also, I guess the training of these ternary/binary models still requires high precision weights, which makes hardware designed for training have less room for optimization and performance?

If I understand the implications of binary/ternary models correctly, for inference at least, designing chips that have 100-1000x the performance per watt for large models (the larger, the more the gain) becomes possible? And also fitting much larger and more intelligent models on simpler hardware becomes possible too (again, the larger the models, the more the gain).

And if inference gets so much faster/cheaper, creating larger models, some even for running locally, becomes possible too, and, more importantly, you can finally integrate the tree of thoughts/graph of thoughts-like search approaches, which greatly increase their abilities if done right, into the models at acceptable cost! And layer many of such inner monologue/search/correction and editing/multiple inference per prompt approaches with each other!",r/machinelearning,Z0FBQUFBQm0yeGJ3cEhiRnpTa3F5R2FlRjhSRHotcXRtR0xKUG9zemVSdFo3Q3FqbVo5Y1h1VUFrMWk3UGJOemR3bDdwTlRMWkdmSGx3Q3h2NUljcFl4ZzJnM0J6bWRlaEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3M2l3SHRqaU9uVDVmckFtOV9sWGdkbm5TRnB0WkJjWXVwNk5ISE5najBJeHV3aTVNSjhoWnBWQjBBc0EydWlHcWJUVHhIX0ZNOF9TY0JVb3dhR290aUE9PQ==
Thanks for the shoutout!,r/machinelearning,Z0FBQUFBQm0yeGJ3azdoLVZHRV8zdDdwWGlBYURYV0w3blhsblh3RjRCRnZaWTg5Qm5ZajNTUzM3MjE2eVYyUmlQZ2ZoXzN2Yk53RXNrbFl0UjkwdlFYZ2w5UEhMdHZmZHlHTWd5RjllZ085VFJFUzlFbEt4ZUk9
"For top ML conferences, do you need to be invited to be a reviewer? Are there some conferences where I can volunteer?",r/machinelearning,Z0FBQUFBQm0yeGJ3M19RcnZuaVh5b1d2aFYwQVd0VWxFSDJLczhXTlI3aVQtYTl2RG13cm1yWV9QX3FuUy10c190SGs2UTFRV1RINXpwVnFhTW9aMmZKSkNRY2FyRklZTHc9PQ==
put in more effort,r/machinelearning,Z0FBQUFBQm0yeGJ3R0JsbE53WDFNd1pEa29YZm92bGtDYUtwYng3M2d5N3Jud1RXMUZpcDlNclVmQVIwd0VjZUpUS2xGM25IYVdKbU84RmJFS0EyUHhXUW1mVjlRVlN1b1V6U1pxOFNLNlVOeFpFUjVMQUVsNm89
Is that really possible to do this because if 1k log reaches the LLM for a second then how will it handle?,r/machinelearning,Z0FBQUFBQm0yeGJ3Znp3bjVLbWluZk1leVQxUnBXYUdnLUN1bHFIbWppMndLdXpKUC0zOHhJWFAxQ3p2VllFUG13VlZRSW1EbnNlRk12aGREbURYOXcwQkJoVFFsLU9vM3c9PQ==
"Tenth year reviewing. 

After ICML made our lives hard by increasing the number of papers to review by 50%, I was hopeful NeurIPS doesn't break the 4 paper tradition. 

Undergrad reviewers? How trained are they? They routinely come complaining they wanted better grades. They'd bring that work ethic to reviewing.",r/machinelearning,Z0FBQUFBQm0yeGJ3WUIzUlVROXM4eUNsU3lvTEMwb3lWQi1SaTBtbGxNcmVKWmtrS2Qwa3NfSGJnM2tOYXpUbWl0TTRjNnJrZkI2bkZjVU1Gb0lIenQzT3B2Z2VsR1JhU2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ak9ia2MyZm9TbE1ITkx3djBGQXpwMU5ZQXNxeVQzaFJLMHN3Ri1jbXlERktGUE5UUXFYbEllRE9CMW53cVgzaFVTU3FfMURQTDJvN0hFWmlSOFpncnc9PQ==
"I guess this is probably because I accepted late as a reviewer a day before bidding closed...

Thanks OpenReview",r/machinelearning,Z0FBQUFBQm0yeGJ3VmFqYkVHRUM4UTE1ZUczNFlaVzE4dWlsTWNnNjJEX0s1NkVfbF9pajJiTUY0TDNqNEk3X3l4Q1UwVTZMLXYteWhRY1VqUV9xdTF3cUpQay1OSFhwU2c9PQ==
"You can't anymore, but you can reach out to some ACs (if you know any) and let them know that you're available to review some papers (potentially as an ""emergency reviewer""), and they can manually invite you.",r/machinelearning,Z0FBQUFBQm0yeGJ3UDlqeENCU3NXSl9PNnl0QVZlQkFreWpPdWE1bVZtNm5sTlh6QVZRMTVvZ3RVb29HVWhycmFzcnlBakRhekVRNUVfSjlobC12cDIzTGp5R3ZUWm9WMGc9PQ==
You're letting uncredentialed people with zero experience or expertise review papers and ghosting all the qualified candidates. This is an entirely self-made non-existent problem.,r/machinelearning,Z0FBQUFBQm0yeGJ3UlJ5ZU1hRTBkbVNUVDRJUDhqVG8tSzMzQ2hDWmhYV1FXZW41d2lUSFhFN3NGcjJRRm5taFFDeXZqOVkxcFI3U1NQa2JpWV9mZEh0enAyLUhfb2l5RWc9PQ==
"Oh yes, the fact that the tools are impractical is part of the problem.",r/machinelearning,Z0FBQUFBQm0yeGJ3TXpHWEI3ZTFJSkVCV0E2VHkwdUlDVWE0bkl0aTRNRmNqYnlRbFYxY1BWbVp6bFZfTHliX1FkZzRmU3JQNlhEQXBsOFhDX29UZjg0a2p6N0R5akp2eEE9PQ==
"You can't ""sign up"" anymore, but you can reach out to some ACs (if you know any) and let them know that you're available to review some papers (potentially as an ""emergency reviewer""), and they can manually invite you.",r/machinelearning,Z0FBQUFBQm0yeGJ3LWZzSXZKeThacmV0N05DUHh4TnF6MEpOYjBrMTVBU3FMSFY3WUEyUmtVS1JwYzh4SDJYeEdxU05BMjREWHQ1UU1FRTk0Sm5DYmgzNWxOMUIwUmVydnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3djhNVzR6MExaZExnTDdIQmo4NEpuSTJMbFY5YUtobWszdWNmNzA3cVM2VDFHSEZxQlVOUV9qZFgyQTYyUk5pb1lTVnJXWUZHUHhIMmNwNkVxSjg5MGc9PQ==
"I did not see any undergraduate reviewers assigned in my batch, and I replaced two MS reviewers.",r/machinelearning,Z0FBQUFBQm0yeGJ3SjF1bmhqREhTbm9ZX3Y3d0ZVeHhBcnJfMmlHdENfSnFUOVZJMnlBSkwwSDdUZ0xjamIwZkJRYWxPam1abl90MmRwV0VXZVA5eDhDcVBYeEg2SWVvU0E9PQ==
"Because based on my roughly one decade of experience in academia, I can tell that it's just elitism, self-serving/dealing that causes the problem, especially in CS and ML.",r/machinelearning,Z0FBQUFBQm0yeGJ3ak5nTXRIMlVhOHpha1lJRVBmOVJVLUc3cWoybDRZTW53Qzd1bWc1VHdlcnoybFVlUzlieW9iYW0wcVM3SWpTT2JITWNEbnBLX3JEYlg5bnZMRmhockE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3UW1MNGxDUzlPNWJ2RFhFaVpXU2JCYWlnVk52NnhhU1RHUVJqdW5nQzh3TTVWLTRTYkwzVGRJSGZIS2pQZ0xQSlJPQkJwWWRSUlpoYjFCdHk1TUxoNVE9PQ==
That’s too much for an introduction course…,r/machinelearning,Z0FBQUFBQm0yeGJ3czU0VFBtTDFBZzEtLTV3WEdvT3l6aUt1em5FSURCYm5hOXNjbEp2cXNRNUFnenV4RW1DOUluTldnREhvemR6cHRwYS01Sy16NGEyTEVQcTNwWGM5SHc9PQ==
"Same experience for me. It is a great library, but as you start to add customization it becomes easier to just write your own loop or get a training template from somewhere and customize it. 

I feel that is a bitter lesson that I learned working with DL research. I tried more than once to write a generic ""Trainer"" that would suit all my needs. But it would always end up having way too many abstractions and being difficult to identify bottlenecks. Nowadays I use the ""plain script"" approach with some utilities from custom packages.",r/machinelearning,Z0FBQUFBQm0yeGJ3N0xJOFJOOS0wVWVNejh5aTlBRldjdFhIaDZ5eVJMVDVlMVZHTEdBdTkwb05MTC1ZaE9rOFY1VEZNb084RTByVWZ4UkZQS29iSzJPVGxxcHJFVHFxQmc9PQ==
Does the book have a huggingface section ?,r/machinelearning,Z0FBQUFBQm0yeGJ3aTFzeFNUTVJFd19SRWE2MVc1ZVFqZE1aT3pCTS1OYjFyeDdzakw3MUlDdVRsTjVTbU8xMkdhNmYxd2k0cmg0c2NWYi03WGFFeU9LdDU2QWNxR291S2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3YzVIdnBaTmEza2NaWERzX1FmdE5pQ1oyTEtuMDU2RkxTQ2c4M0JqUEpoeHBVRG1xMHhmS0xGT3hsMWhuOHRjVEpGMVZDWWktVGZxdTlaVy1peDc1aGc9PQ==
"I mean, I'm sure these practices exacerbate the problem. There is no denying though that the field of machine learning is getting larger and the number of submissions is increasing.",r/machinelearning,Z0FBQUFBQm0yeGJ3bVQzSUdFVkFySnk0Y0FxUndEVG80OElWZEVYN0dtS3NaaXBrTTFBNmU1ZGFrcHBBVDhLVmFneC1fdlpfMFg1LUxlcnk3YVVXUEtVRlp6QzVkdlZzN3c9PQ==
"I mean, this is a CS thing, which prefer conference over journals.

Still, there are somethings CS done right compared to natural sciences and could be attributed to this problem. For instance, publishing paper to a journal cost $, which is a common complain. In contrast, CS conferences are free to publish and open source.

Edit: also in the internet age, do we really need conferences to share knowledge? Arxiv accomplishes that just fine (Mamba is not in any conferences).",r/machinelearning,Z0FBQUFBQm0yeGJ3R0ZFLXdEN2s2WlhuYjVDWnhYNmpSRklUVHgwN2N1V1I2dTR6X3VGb05NX3czSnZUSGliSnRDVnpOQTdjbW5RZS00dE01MTZxUHZxSTJEeEpCNnhLRlE9PQ==
"Hi there!! I'm currently trying to integrate this into a workflow for creating high fidelity neurovascular models for intraarterial chemotherapy delivery, but having some issues reading/selecting the embeddings (not creating them)! I know this is an old post but is there any chance you would be able to troubleshoot/answer some questions?",r/machinelearning,Z0FBQUFBQm0yeGJ3TEFwMnpsaXhyb1Q1MW1zeDhieldLT2dUcG9VNEpRckpCLXgzb2tmZ2lKaXhHTmJyQm55b0MwZ011VDRJc0ZiNEdxM3dxWW91ZGtULXcxUzd1ZHU1YjZPVC1DUmZuOUpvdnlJQXpfVjYwb0k9
Loved the post. Very interesting.,r/machinelearning,Z0FBQUFBQm0yeGJ3TnBGMElUdHdVRWRCaVZ3Mk9NanJjQTZaZHB1MkpSLW54VmZkODVYM2I2TzRTUnpQTEVFSGlkSjFwTDFMUElkUmVEdExWOS0tLUpTcDhaMm9ad1EzQ2c9PQ==
"So ... an example of what these look like how to read it, as a human?",r/machinelearning,Z0FBQUFBQm0yeGJ3cy14YW1DT2dvYjFKQWdJaHFNVGhaNWxkeDJIazd0UHFwUE5vOWhyZEQ5NVRzVU1aME1ldjZUbDExcTdRQnlsTG1pcWgwM1NvdUtGTi12eUh3eFByN3hLM19vYkdMTlFMd0haamlCejhjM009
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Ml9GSnptYkRkalkzVEpaTHVYNmlSdXY4NnVOQW9IZjdGaEpzcGJqa05LSFZLU2c4bzNlSHpva0FBUjUzVGp0U1pSeXdTSjRKeFdTcVpxd1lfY1RGYWc9PQ==
"Data de-identification. We find it does a good job of finding things like names of people, addresses, and other personal health information and then removing those words and replacing them with 'patient', 'address', etc. We do this with Llama3.",r/machinelearning,Z0FBQUFBQm0yeGJ3cjgzbHNRQ05XNmxhYnJhWXhZb0lkS0JELXNfU2JtUEJteFRsMlVCUlh0SWRhTVJvc2E1RUNZWmNRdHA1TG1kRU1nRDhPbENuaTlVUkRXRGhHREdpcFh2MnY4SnJnMFlqdzJEVnhnLXB3ekk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3X2dFYUNHME85b1VWYUFocjJNbFBvT2VvaU9ZUEZwRjV5LXJjMGxCaHJIY2lzWlFpSUhGZlpQcGU1UkhkOUV3TlBrQ09CRVVXSzBscENxNTB0Ty1ReFE9PQ==
"my guess is that the metrics are only valid when it comes to open source models. When it comes to proprietary LLM models there are safety & security + who knows what else measures laid on top of them, which hurts actual performance. 

Generally speaking, the complexity of LLMs is growing so much that no metric can reasonably measure how good they are or how much better they are from previous versions. Companies are incentivized to push for higher numbers for PR reasons. But at this point personal experience on basic use cases really tells you what is going on.",r/machinelearning,Z0FBQUFBQm0yeGJ3cDZGV3lhTmtPc3hWa0pLTThOLVBrWUVjQUgyZUgwSHREZXBObjctenowNkQ4LVpDSjk3eGROX3E4T05KMkQyV0xvc0JEa0N3R2JPQnRUTUpWdFJoNWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3V2VoSmx0ZXh2a0ppTjNGM3NYY1F0RHZzYmZpc2NIYTlJQnlYeVlwLS1nRk5NcG8tVHphZXV3SlpRQm8wMUJuSjlUZkxtTnRfUGRpbFVlSXgxQ1pSOHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ay1GRTljZjJNSVUtQ1BZOThxdEREZ1FVOUxBbzVWUWo1aG9jcFk1em9nR3dDZkZueC1DX01RWERnSzBJRHRpZHYwS2JZRG1qY291eGdrSmNiTjc1MHc9PQ==
"Agreed, I’d focus on bulk standard transformers and talk about their use in different scenarios (seq2sec, classification, regression) then map those to real use cases (generative chat, content moderation, preference modelling).",r/machinelearning,Z0FBQUFBQm0yeGJ3UXk4NVdHR0lOTG9CNEJ2eF96ZWJoTVE4d3pfRi1wM3E3N2U5Z3hpQzhwc2hvc09VM0NOVzZueTlVNXprb19yQmFqbzZYVU9qMXpoRTNxblZRVURxcGU2cWRGTWZjUjQtcXRoQk1qUi0tNFE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3WmRqTUVVR01fdUwzUTFmb0lBLXVKQWN0NEpvaVZlRHNoV3RyNUR1YVVteHRZQVFGLVBYdUktQUVFeGh0WHZBU25ubnRncm4xYmgwWEduZ2dfaGJ6N0E9PQ==
Paper: [https://cdn.openai.com/papers/sparse-autoencoders.pdf](https://cdn.openai.com/papers/sparse-autoencoders.pdf),r/machinelearning,Z0FBQUFBQm0yeGJ3ZTNoMDNSYWdaV2VSeFd3QkxscWR6TGJPM2hXQkE0U1NOX0p2bjc4ZHZPVGQtdk1iaWVRTXpSWGhITTF5UEZEUUU5N0ZCOTh1YmQ0YXRtZjNyUnlJUFE9PQ==
"I haven't gotten through the Monet report yet. So much to get through

thanks for organizing all the links in one place",r/machinelearning,Z0FBQUFBQm0yeGJ3OVpaU3JON0oxNVBVRlFqY2ZhVkVTdU1PS0xieXRnU3lTakNwZm94UXJibU9hSUxfRVNJMzJhdk5uVk9nMW9hMXE3VlhDNWlpV3BGR0NaN1JhM2k0dHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3LXdHbVNJdnVFMEpCQWZxTWJKMWJpWWtLUGFKenBsMExVTXN6RmZKUWFUUjhwYy1JV0MwTnBGR3BiTUpBWkpqVWZEV3JQeW1IRjlIenVlRlF5SDc3N1E9PQ==
RL by Barto(not the exact name I believe)+ read research papers.Reasearch papers are nothing short of a bible.,r/machinelearning,Z0FBQUFBQm0yeGJ3cGlFOFpOT1pvdzNEanFRVjd2d2w2Z3dhcmlZMS1IR0ZhRV9PbnpTbW5OS3RMWk8yWTctNVo3ODYyRXpNNU1uZ2hCVnFZbmNuUllJR1luSllmUVFKelFaaUJyWWV0bzdveFd4M0hjOVNYbEk9
"I totally understand your frustration. As a senior consultant and generalist I often react the same way. The skills needed to infere a good idea is defenetly not the same as the skills needed to implement and maintain. I hope you succeed, provide a good example for the amateurs to get inspiration from.",r/machinelearning,Z0FBQUFBQm0yeGJ3OGdUckdpN1VUZWsxWEJXVFpmM3lya1RYbGlhQzBncERidGZwXzFGak5TczdiQnlEemEtUHRLR1hOMzZfYjRab0xjQmZXdWFlb1hzY3pjZjlYY0lZSWs5Slpvd2hkNF9BRW8zMzJHMk82dTg9
Good Idea. Thanks,r/machinelearning,Z0FBQUFBQm0yeGJ3alRiMXVtMWlSMUt6Z3RIdVQzRFFwSWZhbjZjakN0NTUxN2ctX1RsNF9QNFFyZjBLbU9aZXJhbVd3bFhVMFd0VXp4VlJNZ3EzVGZrVHRWS0pfZmFVMGc9PQ==
My company has a tool that helps data scientists find specifically (no features needed) how the production set differs from the train set. DM me if you want to learn more.,r/machinelearning,Z0FBQUFBQm0yeGJ3UTZyTjRxUlA5YmZmVU5jUXpDMXBWUzlGM29jX0dkTEZ3RGhGc29SZXF1dHdxdGxCcm9LVDFMNVFMU1NEdVQtRjdSWnIwdjgtNmtkeWFGdTAyb2RkMWc9PQ==
">GPT-4o feels really sloppy

You should have your own, private benchmarks and not go based on vibes. The ChatGPT subreddit is full of people claiming that ChatGPT is getting better or worse over time and they are all just going based on vibes. I would hate to see this subreddit inundated with that stuff.

As part of my job, I have benchmarks and cannot detect any degradation between gpt-4-turbo and gpt-4o. It seems on par or slightly better.

In blind evaluations, gpt-4o [dominates](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard).",r/machinelearning,Z0FBQUFBQm0yeGJ3MzJmSUNZeDV6RGU2MGNfSWVVVC1zV0hFbDdZOUJMWnJGY2NwUGJ2OUplTEEyVUlIV0M4WDQxTDFKd1dHbXA4MzFvOGpMYWY2TVV2c3dmYUxNSUdtSXN1dmpkR29hRHVEempmRGplb3dFbG89
"Are we not wild west ATM (at the moment) is not the imperative 'Suck it and see?' If you have the compute, find out. If not, try to look pretty.:)",r/machinelearning,Z0FBQUFBQm0yeGJ3QnVnRXl0S294T1V2Mm5ITk95TDFqd2hOMjQyOXhENUFpRzZJMUhlYm9HdEc1QzZDRzRCSWVMZDB5alBrQjJzSjl6WkNObDk0QWdPUU0zcmN3eHl2UE5IYjI2aVBBcHh0aWNxZVB4MjdrMEE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3UWxWMFdNQ0w5Z2VyVjNsVjlGNTlGdEFINzVyVjFzdzMxSnA1dkdyYnhRaHVjZFFpa1RYOUw3d1JLNkZGT1h3SHZjN0V0S0ZqUEpOTmY3NFEwd3ZxbEE9PQ==
bra. Tensorflow doesn’t even support cuda on native windows anymore. Dead framework,r/machinelearning,Z0FBQUFBQm0yeGJ3UjBGUlBXYWlpVTM5RnFLX3FSWW9qRDd4aDFOYkdkeGpUclNRc291SDVDUUFiRmIzejVVRFgtS19GSmJaNlhvWExBMXVpWE1ranVuTk1SdEg4WGszNXc9PQ==
There has to be a better reviewer system than the same broken thing we do every year,r/machinelearning,Z0FBQUFBQm0yeGJ3ZkZ0OVpCbGJtemswc1k4Um5GaVViWnM0SjJ1eFNYcVBqVXBHdWVMUzRKUUFpdExCYzZfRlE1Q015MG04LVFMNjRwaVBYa3R5bHJJYUUzZWtkTTZrV01vaHBwYXloZ2hidUVyMXhIM2E4SVE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3R3Jvb3Q3Zi11cmc4NmFFMGJ6MkZBUjFZNmQzNGFta2tMcU1fTWVCZlJEYldZdUJYVmp4aFR4Um50RnJSdFM1Q095QzFLXzBRVGRCdk11SXhRaXZEVEE9PQ==
Does it help finding patterns in unstructured data?,r/machinelearning,Z0FBQUFBQm0yeGJ3a0JwZFNEZWRQTFkxTHM1R1hmdW10T21EdkF4bWlpSmQxMHpOUlEzbXdqTzVDblhJX1Ffdkh1akNJMm9NZkxUZ18xOGM5Mmc2eFJVeDlmcXhMOVR6SVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3bnBtVTA2WTAtZWoyT3hpNExLVTdsTnBaWHQtT1BiOXQ3ZkVYVXBwM1VhX1VWQUxPTGpsYjg5MkRsaDNFZDEwUGJsWk1KcW4tVGhTQlNHOUFraVAxenc9PQ==
"> After ICML made our lives hard by increasing the number of papers to review by 50%, I was hopeful NeurIPS doesn't break the 4 paper tradition. 

I've heard 6 papers is common...",r/machinelearning,Z0FBQUFBQm0yeGJ3WGd4aVZYMnpmMzVhUjRueU9yY3dsak5tZXpFVmx2Y1pnSnozTzlFdXJHd01ETjFtWTI2X01FeHZGWEI0YnpJNTRSdTNBaXZGa0VmQmxtSU83ZkJNWUdQTGd6NHV3V3R5d1VKYVNuWGpiX0U9
"I do not think so. A much more logical and slowly gaining opinion is that the LLMs have plateaued. There is no further noticeable improvement on quality possible.

[https://arxiv.org/abs/2404.04125](https://arxiv.org/abs/2404.04125)

[https://www.youtube.com/watch?v=dDUC-LqVrPU](https://www.youtube.com/watch?v=dDUC-LqVrPU) 

Which is sort of what u/Mysterious-Rent7233 is saying in a positive note.",r/machinelearning,Z0FBQUFBQm0yeGJ3SFg1di1LcW5MWTdSN2dhdmFrOWJNWDNYdlNVWTNqMkRfTkdsREtneGo0aVlmV1k1VjJqb3lHNlFSLWdMNGpZVEkzOHJud2JFTmFTRkpCNVBLX0lvUXBpWlBUOGFWNUFqQnBxa0VCNVQ5bE09
4 has been the average. At least in learning  theory.,r/machinelearning,Z0FBQUFBQm0yeGJ3OHBmX2Q2TlZTNUpIaHlhNk1UXzlWOHEzZGZZWFZYelY4U2NtNnhZZTE0NkhUelN4TkZfOGkwSkpJelZqN0JYQkhnY0xPdGVSSnJyYXpYbnJYcTd5a2c9PQ==
"Dude don’t make this personal M8 and actually defend yourself. Just answer the question and it’s a trend I noticed.

 This is highlighting that benchmarks may out there may be worse for real use cases that people have. Which developers optimize for which in turn can make things worse in production.",r/machinelearning,Z0FBQUFBQm0yeGJ3SzZTOUo2enpRdWM5V01Edk5yaXp6eU80ZDRoRGs3ZHc4YXBVa1YzZ2VNcTVsdFhnWVQ1SHJJME1RMUVtOGZfM19KdEN4MWRkUFVCVVJJVUhYSHhNNWpHTHJCQXJlU2tYd0NIUzhEbkZCdDg9
"Even if 4o was worse, which you've presented no evidence of, it's also much faster and cheaper. What are they doing to make faster and cheaper? How do you know that that's not the cause of the problem you see?

I did not mean to be personal. I just think this subreddit should have higher standards for evidence than vibes and guesses!",r/machinelearning,Z0FBQUFBQm0yeGJ3eVV6QVBScW4tNmlnQTZQYThtVWhPdHNDam1WSTVTOUl0S3Bnb01lSU5IeG41dzVxaFFUYXNOUmRXYVFlTlhvUTg2NVZTME9feUJoaVNBN2RncF9XdFNZRkh6dXlyLTlvYmVMMWppSUpTamc9
"It’s not just me that’s noticing it. Many other people outside of Reddit is saying it too. This is the whole purpose on discussion of questioning the actual effectiveness of current benchmarks that can potentially mislead developers when creating LLMs. 

That is a stupid question. That’s the whole point of research. I do it myself so it’s not easy. But bad research believes sets people bad and does more harm than good.

Also again if you pay attention and read. Bad benchmarks can lead to developers over optimizing for the benchmarks that may not have too much use case for effectiveness. By over optimizing it, it leads to less effective models.

“When a measure becomes a target it becomes a less effective measure” situation is what I am saying here.",r/machinelearning,Z0FBQUFBQm0yeGJ3R3hlRHppSFFWY1R2R09uSk9yN3VjMXoydzlzTmRrS2VRWnFPOHVDSXBpcnJJSVFJOGtfNHlaQ1Q5dmhDTzdyaEdrR0xBck4zUE0ySlBFMU1Mbm8xWkVuTWhjVGVGWEt1RnNJeDlDenhRNHM9
"People are bad at compounding statistics from anecdotal evidence. Look at any gacha sub and they always swear rates are worse than advertised, even with tens of thousands of logs confirming the probabilities. That’s why we need benchmarks. They are not perfect because they don’t evaluate exactly what people want, but they are more reliable than vibes.",r/machinelearning,Z0FBQUFBQm0yeGJ3Si1aUUYzdS16bVozbEZOR3ZTZFBSb2ExTjNzX0g4N1UzWDNmV2NBSWc3VmJ3YkNfR3pPOXdhZllwTE1tMko0TWJBY3ZrWTk1aWZrYTBJMHRrSFQwT2RXTDdkcnFhSmlfVy1OSlhCdjVMQUU9
Good point. It’s kind of like trying to measure intelligence. I am don’t know why it feels like the newer models just feel like they completely ignore your instructions when it wasn’t that much of an issue in the past with GPT-4. It may be something with distillation if that’s what they did.,r/machinelearning,Z0FBQUFBQm0yeGJ3eDNUV1FkUGVzVjNSaUFMa1dndjVfV0hMREhsX3RyUWxoR1dKRGl0NDFrMUtjSlN1NmxmOHBBSzdFNFJvSFhPYUJDb09GVGx4d2ZORTMzT1RVSzFhRDl3b0h2b01CR1B0MFlPSXNURm5WZWM9
"Great paper. Would be interesting to see if they could use search or MCMC to optimize the MDL objective, and if that optimum would be a global one (or at least better than those found through backprop).",r/machinelearning,Z0FBQUFBQm0yeGJ3VVk1Z09TbVk3d2hqbndKcVpqRWE4MjF1M0dZSWNPaUgzNi1IMVg1d3pmblZXVmh0b2ItMkJxZEtqa0ZFenJsOWlwbEh1TlZweUx4UG9PTTRJa1JvSlE9PQ==
It doesn't read like you actually want to hear what people think and are more interested in having your impressions of benchmarks vs true performance confirmed by others.,r/machinelearning,Z0FBQUFBQm0yeGJ3cWVoQllrSGdlbVk2OFpwWTF1Mm0yVkI5VXNwc0ZGUEw3OHBoOWRBMFlhWExwYUdBd3JrSmZ5RENpeEZES0NleGo4S01pU2I4LUZhSTh5MVhJWlZkM0E9PQ==
"Another dimension to take into account... As the model is for use on a platform where I can control user inputs, I will simply lock fonts and unicodes.

**Thanks, because I was forgetting about it**",r/machinelearning,Z0FBQUFBQm0yeGJ3dlNPQ3piVjhoNENETDkyQ3ZBU2VvREl2cFNYOGNBS2VVbUFMT0ZDdlBlUl90RzJUWWhkTUtVYWw2eWtEQ2g1U3FpZmoxNWJoaW1PNFE4ZUFGOW94ZWc9PQ==
"The plural of anecdotes is not evidence. 

This is a MachineLearning sub - shouldn't have to explain basic stats here...",r/machinelearning,Z0FBQUFBQm0yeGJ3clVKR3NtYzlIYlBFS3c5Q1ZxWnpUZ1FpY3gyZkl4MEl5d1VTdTh4bUEwNEY1OHBRSXFRYzdhV2t2U3FhUnp1aDNHZ3ROSGxqdGJjaUQzbFFEcVlTMGc9PQ==
"You are very right in everything you say.... To make 2 models is to solve 2 problems, instead of solving 1

I have an extra question, if there was already a existing model to “undo” the obfuscation of the text  
- would you do the pipeline in 2 models?  
- or would you still find it interesting to train a single model?",r/machinelearning,Z0FBQUFBQm0yeGJ3MHpzN19EVHYtWnFKU2toMEFlQzM4aGJvVjh2aGw4RjdQZ2tHN0VkcEp4bGJMV3hWaklGOTdwVUEtcFNGRmJVUl9IQTFuWUxhQ0doTWNrdmxnOUdHM2c9PQ==
Imagine being this sensitive,r/machinelearning,Z0FBQUFBQm0yeGJ3c0VVOFpiaTltaXpHSzFyeWFqOTREU01XQXlNTDJObndfYTF6WndRZjlhbGFMLUZsZVUtWEJYWUotWGZrc3dWTzVJLVlTY3NSbzYxTVMtakt1cVVQamc9PQ==
"There are some very interesting datasets.

HATE-BERT: [https://arxiv.org/abs/2010.12472](https://arxiv.org/abs/2010.12472)  
ToxDectRoberta: [https://arxiv.org/abs/2102.00086](https://arxiv.org/abs/2102.00086)  
ToxicChat: [https://huggingface.co/datasets/lmsys/toxic-chat](https://huggingface.co/datasets/lmsys/toxic-chat)

I want to make a mix of several datasets and a dataset of my own that I may have permission to make public at some point.",r/machinelearning,Z0FBQUFBQm0yeGJ3V19hSnFucFVmWVFDZElYMk5WUFpwSUl3Rk1vUmtkT19mMDd1b0VRWnowUGRrdzkyT0Z4MHB1QUdJVl9lbWlDMUVhYy12eFJaOEE5aTRUTUh2S001a3c9PQ==
"I didn't know this one and it looks promising, and it also has the datasets public links, that's great and helps a lot.

Thank you very much!",r/machinelearning,Z0FBQUFBQm0yeGJ3OTk1ckU5YVZ2NWt2OGdiVFo5eDRDRXFrbGx3Q2xUam5fb09pdWxNWWJhVzBHLUZZSzBReE1lVThQRENOanAyUUtkVlE1ZEp2X1hRTWZDLUxETjZad3c9PQ==
"Love the demo. [https://google-research.github.io/retvec/emotion\\_demo](https://google-research.github.io/retvec/emotion_demo)  
The code and training method is helpful! thanks.",r/machinelearning,Z0FBQUFBQm0yeGJ3c0RBMDBjdFR3b2ZaRDZzTHpiaFNZajh0UkpWRVBMY1Z4VDJLLURfOUtfbHFJN3hUMmF1QU5GS1NZdDFPSXppNkc2S2N0cXNzN0dPR3B6U25NTks4ekE9PQ==
"My answer as an engineer would be it depends on your time and resource constraints. With the first option you pretty much have everything ready out of the box and just need to glue them together. You likely wouldn't even need to do your own training. 

My answer as an enthusiast would be that the latter is a cleaner solution. 

One other thing to consider is that in the two model solution you have models that would be trained on two totally different objectives (one is a generative objective the other is classification) meaning that their training data will be in two different structures. So if you do end up having to train the two models then you will have to do a bit more work to assemble those two datasets instead of just one big one.",r/machinelearning,Z0FBQUFBQm0yeGJ3UVd2dGRKX0Z4MnkyZTlTZ3pTVXBFcDNkdGh2a05nTEtxM016WWxTUmlXTUZfTlV0dWthMVM0U2RJU0p2QnRjTVFiWTltMERkaHRlcFdlY1plNjIzb0E9PQ==
"My recommendation is to have your reading be guided by two things: curiosity, and an interest in solving some specific, concrete problem.

At the graduate level the distinction between different fields of study is largely artificial - everything ultimately amounts to doing math with computers - and so you're going to be most productive if you focus on specific goals, rather than confining yourself to specific fields.

Focusing your efforts this way will also help to avoid the very common academic mistake of attempting to apply a particular method to solving a well-known problem for which it is inappropriate and ineffective, merely because you happen to consider yourself to be specializing in that method.",r/machinelearning,Z0FBQUFBQm0yeGJ3YldjR3cwVlNKZ005cjI4OUJjZFBGV2xjYlI3YmZ6VzdGcDNvQk03Q2FTaTJKZUtKR1l3TWljTWFkNUNCUXp5VmRUMUVCUUszLTBmU3p1OWNCTTBoT3c9PQ==
Reviewers won't be assigned to a paper written by their co-authors.,r/machinelearning,Z0FBQUFBQm0yeGJ3VVNNakxvc1pRd3QtV3NvOUVvUGpYcjNkekxRNXdvWEFNaEZBcFE5dlpydTRZUmpORllIVUZwX3NPRmpNYldvXy1SU0JqUnFrb2VuMDVHZVRwdzA5b0E9PQ==
Anecdotes are definitely evidence. Just not strong evidence,r/machinelearning,Z0FBQUFBQm0yeGJ3c1QwdnJ0bm1TNXpMZjNRUUNTSGdZNFNkZEdLT0dNUHlBXzhsak1rdFRGcXQzV0RfUElEMUFOQ2hEeWNNdUowRm1WaVJ5RjQxODJqWjNPdVdhNDZuYWw1SFJJRVpXTHltaDdkb3pYZ3dJRm89
"First kill TF, then spread the love.",r/machinelearning,Z0FBQUFBQm0yeGJ3QjZXMk11b3JCZ1VKYTM2bXJuajJsRW13S0Z4LTA2T0VuMzZXYTdJYU5tVlk2ZmFHY2dFd2pZeXNrZjRWZFp0Y09oY0UxOWtITGRfQlUyZFhOb1liaFE9PQ==
Hello everyone. We are currently developing a machine learning thesis about a CNN model. We captured some datasets and we are planning to rotate a one dataset image or make a copy of it and make it into like 4-5 images since we plan to have it into different angles. Is this a good practice? Why or why not?,r/machinelearning,Z0FBQUFBQm0yeGJ3b3kxbTI5b2dXamZfR0VRT3hBZjVSaUhhSnhZVkM3eVpnNWpEa3JUamljTkNwLUZMdUhEdlRCMlJpMnFKNjZCcjJxU1c2a29zeFdDdHpqOURMdFczOFE9PQ==
"Doesn't look like it.  You may want [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action-second-edition), which includes coverage of HuggingFace.",r/machinelearning,Z0FBQUFBQm0yeGJ3NnN5U0JYcXZhRDhkZWE0blpuOG5Fb01sVXZzRTRtcnB6a3BlRTBsMDZHYUpjQnNBekUxTTRhQnM2WnNSWnd3MXFwQTZiX2lJdUx1ejc1bFNhaGJsakE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3bTJfVHBlbS1lM0VGUEhBZXdXWHBGc28yeTc4THpiblhYNk1qc0NlQ05GX2hyV203V3plN29MZVJMVW40emNONXVFNU9HejI5SVd4UHJoVThuYlRYeWc9PQ==
"Already done :)  
[https://direct.mit.edu/tacl/article/doi/10.1162/tacl\\_a\\_00489/112499/Minimum-Description-Length-Recurrent-Neural](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00489/112499/Minimum-Description-Length-Recurrent-Neural)",r/machinelearning,Z0FBQUFBQm0yeGJ3blJBbXpodlZMTUlXZE4tencyVEFROUJQeVBkT0tGNGp2RVBFbHF0bW5xQng5WV9FNktlYTc0TTZ4YlJ0dXBwUDU0ejFoNkFmU1BQVXk4enhmMWI4T2c9PQ==
"Hey, I also have an ML on-site coming-up. Would you be interested in connecting to practice mock interviews?",r/machinelearning,Z0FBQUFBQm0yeGJ3amQxNWhka3QxbGdMdGVnMHZuZFF4QnFNVzNxcWd0c0lyLTF6eEpCY05JeG05eHNGTzVjZkpDdWxmZ3gtRHFoVDZlNHF3SEFXaVBzWEoySzlpMHZnVUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ZkJIZm8xV3plN1JQQzgyc2dDUGoyNUgwS0xmRk90aXhxYXVRVXRsRFJWS3ZqZVlUT0xxdkRkek1Id1JjUFBDcHFMaHk5UFFxQlZNbkhsRXFNdC1nMXc9PQ==
"Very interesting!  I believe this is likely publishable work.

> One other thing I noticed was, gradients of lora_B were consistently more spread out than that of lora_A.

You are not the first person to make this observation!  https://arxiv.org/abs/2402.12354",r/machinelearning,Z0FBQUFBQm0yeGJ3cVYzdjdXWXdHc3QtbEhkeXFlcFRRcVhja3hhLU14WFBxVFFIbXJnNkJfV3pkMEJ0Z2lHUTVOZlFldlFyaEEtYjlYbzFRYXBoQW9obXZfSjYxMTY1Unc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3VmF3V3ZxX0o3Mm1YN09jbzZES2Y0VHB6WmtIME9WNFlMa0NwTWVVU1puZi1GWW95ZWdwZThQTjhZbDZ4MDBTcnVYZTRjYjc4cW1panpNbHJJSjNOX3c9PQ==
"I agree not every problem. But I do think in the recommender context it makes sense. Customers take a series of actions, click, long-click, purchase. A sequential model could also capture temporal trends, and automatically forget stuff you consumed a long time ago.",r/machinelearning,Z0FBQUFBQm0yeGJ3cURKS2tnZ21LOExCR0VJOWhLSzJZTldzR1BDZUtSZnB0Q3VfSnFRYm0zS0drRmF6WmhLckR6bVNiZWZqNy1vX3A2X3ZDcmVIZ3Q5QmxnQ0laOEkta0E9PQ==
"Paper out 4 days ago that uses orthogonal matrix initialization for LoRA.

https://arxiv.org/abs/2406.01775

Haven’t really given it a full read but it looks like your method 1 (QR decomposition).",r/machinelearning,Z0FBQUFBQm0yeGJ3eVFoVVpxTlZtYUFvUGtzWW1HczZFN3ZIQTVtTlMwVUE5XzBSZ3lGOFdJY3BLcGwzbWprMmk3WFVDTWUtcWJCTzNrWTBfSTUyUThCeFJ0TTc1aTNSdVE9PQ==
Another one you can try is to initialize using a decomposition/factorization of the associated weight matrix. I've seen at least one or two papers that had good results that way.,r/machinelearning,Z0FBQUFBQm0yeGJ3RTVTTy1ZM0NVSHZWVTBCdE1QQmtUclM5M0lyTXVuOFhrMGFmWHRCMWIzSXNXaG9leE5VcEZEWV82aW9JQ1BkcTFuQmRONVZtNVpHXzlMNXMtMmRxTUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3MGdaYldiRlRtZnRCbjc5Z3dGN0JRTW5KTHktZ3VmODFMdkRDSzlZRDZleE90V1U2dnozV0RIZkxnRGlZMHVwQW1GdzY2WWZ0ZlJYNGJqYjlrUW5mbFE9PQ==
Well plateaued with the current parameter and dataset sizes. If someone had the compute to train a 1T parameter model and every fine tuner has a B100 cluster at home then we’ll see some very impressive open source finetunes lol,r/machinelearning,Z0FBQUFBQm0yeGJ3T1JTcTktYTRlcDBtY2U5UjFQbTJ1bFEySlRGdERGOFQyb1FiVzlobkJpMmRXaVZvTFRhV1Ryems1YWFFQ05mLUN6TmVYN2dsazhIdlZhSnBZbzRQY2c9PQ==
"The best case I could think of is text correction when copying lossy documents.  Like when you have a xerox of a xerox or a faxed document, and text is unclear.  I could see some people wanting to have their copier ""clean it up.""

That said, I'd sure as hell never use that functionality in a legal or medical setting, where a non-obvious ""correction"" might significantly change the meaning of the document.",r/machinelearning,Z0FBQUFBQm0yeGJ3T0c0Y1pSWWVDTkc3RGRQczN0R01ER21UMGctT2JSandMUVlxWEdDTm9UY3VBZDVZd3lqY20xTDJ6c0lxMWxVUlBRQml2ckVEZXg3QWY2SHNpcjB4VXc9PQ==
"That's awesome! Are you one of the authors?  
Do you think there are advantages to searching in the space of neural networks, over search in the space of programs represented as code?   
Are you using this approach to solve larger problems?",r/machinelearning,Z0FBQUFBQm0yeGJ3Z3gzdXdqTWtZcmxnd1plaFZNQWxPbTRXY1ZXVmdOWHJSZ2JUUm1ncTFWaXE4c3ZUVEdmcjMyZk10b2RaTlJKU3lncHlBMmxERVFOMm9uX3NpNWFsR2c9PQ==
"It's totally possible that some LLMs are overfit to public benchmarks and they fail when evaluating on a different data distribution.  I feel there is a lack of cross-dataset generalization evaluation. Without even mentioning those who are blatantly cheating by training on validation/eval set. On the other hand, lmsys can also easily be misleading...  Best way to evaluate is to a totally new or private benchmark.",r/machinelearning,Z0FBQUFBQm0yeGJ3c3Zpa3NrcnQ5UW83c0xvT3JZWkg0SmZtRFoxcE9md1VuRXdKS2hFZjJ6enNlUmhqdGJ5aEIwNGotaHNzcG5OQVZnamxsUFR0MFBJblNOMlVCMXh4MEE9PQ==
"Nudge you towards an optimal jogging speed depending on your health and heart rate

… Though there's no need for AI…

Yeah it's a tough one",r/machinelearning,Z0FBQUFBQm0yeGJ3RzRrQ3cxaEJpX1IwbHBtbXdUOHBTZlYyZW1FdkZycGJnTlZ3MHpvVlJTUWJWYkFpNEhPQ0hLbnBBY3JEN251dmRIYUp6aFBpT2JycmpFVER1NTZlWVE9PQ==
"True. I normally just personally evaluate by judging how well it tries to follow instructions. Then if it’s correct and how correct from a 1-5 score. Then average the results.

It’s hard to exactly quantify without a word for word and biases getting in the way a little.",r/machinelearning,Z0FBQUFBQm0yeGJ3azZKYWU3MFozSmlUaEkxd2xUZHZIOGhodjZDbWc5UGE5Sk40WVNteFZEYzFOdzJQUjFBNy1JQlpDb3UyT0FCa1IzN3lnM3dXdW9uc0k0eWZtdHZLMS1mNXJpdU52TVc0blNaSjh1cTZBNHM9
"Bruh 😭  
I had this planned for months but was busy due to work. Finally got some time to write it up only to have it already explored 😭  
[https://postimg.cc/gallery/sX8H94n](https://postimg.cc/gallery/sX8H94n)  
Imma go cry in a corner now...

*My Disappointment is immeasurable and my day is ruined.jpg*",r/machinelearning,Z0FBQUFBQm0yeGJ3VGpSc1NmUlR3b2tOdWlPZUZlUGhOVUlGakMwRTNfUi1PcXFkdnVGWHYwcllBdjBUQ1ItV0szaUd2a1lEWFN0RUtmeE96Zkd5cjE1X3VFMzRpWkU3Vmc9PQ==
"This is how ML should be done. Nothing will replace manual inspection of data.
You can try using a powerful LLM to look at a portion of the data and analyze it for you while you are inspecting another portion. Also, you can focus your time on the most interesting examples (high error, low confidence, extremes, etc).",r/machinelearning,Z0FBQUFBQm0yeGJ3TmxHbzdXYndBMGRva1R2VWl0NU5td296LVY4STV1aWs0UXJMODlRUkhXRV9zVG1peVhpYVZ3TGctRVZ2bFFqc3pjWDk2aG5OZHlBSXlLMlFkMGNkZnc9PQ==
"You can absolutely use detailed notes, as long as your replimenting something that isn't basically just the notes, you just can't use anything decompiled or disassembled directly. The reason two teams are commonly used is because it privides extra legal protection, as you can claim the implimenting team never dissasemled so their work couldn't contain anything directly copied.

This is especially relevent when the disassembled code is so trivial, that it's likely the only viable answer, and your answer will look almost identical to the copyrighted code. So the two team seperation is so you can convince a court, that your almost identical code, is not the copyrighted code. For example, when your code is just sending a specific intiger to a specific CPU register. This is not case in this situaion, whatsoever, a libcuda reimplimentaion will not look anything like the orginal.  A second team can't hurt at all, but it's just one thing that companies have done to win their cases, it's not a minimum requirement to win your own case.",r/machinelearning,Z0FBQUFBQm0yeGJ3WjZxNlNKQk9hWGZUQU5IcGlQM1FHMzVHdlFVRnllcFBGeW5RU0k0UzZycVhucjkzcDlvRkFEbjN2Vk0wRHI5Y0E0aEc5UlRGMGF1bmF4RGFFR25mLVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3TUpzUkktY05TYVBhOVdXM0NvbVlnTjVlTmY5RUlacUtrclNZQnFzcUtEUTBncGozZFZBNjZDY3o0VGFpbXFqZ1F6aUhhSTNEM0lVUWE1akJNVm5wbmc9PQ==
Especially when those anecdotes share the same bias from reading other posts on r/chatgpt saying how much the new model sucks. It’s highly likely that these people got swept up in the hype cycle and are disappointed that the capabilities of LLMs were oversold to them.,r/machinelearning,Z0FBQUFBQm0yeGJ3clJ3X29sam9VZm0tSVdDUWE1Y20xTWVBcGppbExJSGdqYnRlYWRGVkE0aTlHaktFQWx1c25kU0RETXZaSVBESzhyS2VtY0FfbGY3V25fQ2pzM01wVmc9PQ==
"Oh, an LLM is a great idea. Thanks!",r/machinelearning,Z0FBQUFBQm0yeGJ3ODBmbXp4MEJOQ0pCRy1Gd0NCZG9rS2JMdE1GQ1EzZXpJcUpfQUp5TFBuRWJzSE1nYjJHbXd4RWNTcy1halhPamR1SnZwSnR1QlRlXzZySk9pRmlYSUE9PQ==
"Yes, this is called ""dataset augmentation"" and it is very common. There are many other methods of augmenting datasets too: https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py",r/machinelearning,Z0FBQUFBQm0yeGJ3UTFVOWd6TUZ0VTBxVGtKbC1aQ3J4ZWVWcVlsRkd1dWFDeHdac0x4N0lUaXczQnlIdG5ORlZjZUZ0eEtLS2NPNDJrdTNBUGxidlNEdk1ETWpJV0FBM3c9PQ==
"OP didn't say anything about introductory course. I listed basically everything I think should be covered in the context of LLMs. Among the things I listed, my introductory NLP course at the university covered \\~40% of what I listed here, as latter half of the courss",r/machinelearning,Z0FBQUFBQm0yeGJ3bkRMOVhyb2l1SmpwOFZpZ3IwdlpMSGoyQVo0Tk5qSTdENzgySUFlUTI5blI4UG1qSUdmckJhaUxKZmY0Z3pOcktfVGxoTzFwcWJ5U2xzTHg0eVRRaXc9PQ==
"Of course, for introductory course I would do the same. But OP asked about LLMs specifically, not introductory NLP course ideas.",r/machinelearning,Z0FBQUFBQm0yeGJ3UnVEQ0c3RWV3VWlWYjJiQVFPRUlYUDFqN28tcEdQamNQNFRjbFNNMFg5WHdSQ2d1cjAxcFVOeHpQM2c5SGIwcGNUZEhjZDZsb3czTWg0ZnRRZjZxRUE9PQ==
Honestly I find writing the PyTorch training loop *really* clunky compared to JAX with Optax and Equinox. So after I gave up on Lightning I basically gave up on torch.,r/machinelearning,Z0FBQUFBQm0yeGJ3MVptMGFNSXpnWjdra0tGU1BhbTdHVE9mb2Z3MUl2VkVpQm1vQ2JnSld1WUxiM1ZUQ09SVXhSNHlNNUdqSXpjb3VjOHk4UjQxUWtEd09icTAzdmU3dVE9PQ==
"> The ChatGPT subreddit is full of people claiming that ChatGPT is getting better or worse over time and they are all just going based on vibes.

As noisy as it could be, this is actually a good source of data for human evaluation.",r/machinelearning,Z0FBQUFBQm0yeGJ3UDNyRk83bGp2U2FBcDN3d1F4a05XYk1IVEtvUVYxOTdtUU5JRkVkN3k5TGZway1kUVRyQ215VWc3MzVhN2xDaWRFRExGU1B6WDAxd3FzYldTQXpIWVB4dEE3YTVWOWFiTi1NXy1ibDBUQ3c9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Mk1EcnlPZXZHM0MwSzJVTmV2bFZpN2ZvZnNtVHJiTm5IU3hkbXdWM1ZKRVBmenVWUVFtaFRscmpIcExnSGpLRk9yY1RjYkdBVmxvVENIb1BuaVZTMHc9PQ==
"Can't, it's almost unenforceable.  You can decompile/disasm compiled binaries, without downloading the CUDA SDK, you can reimpliment libcuda using public documentaion and open source cuda-nvcc.",r/machinelearning,Z0FBQUFBQm0yeGJ3TnNFOHFXcVpzN0RrZHJhUGpodTgwN284NkdBMEh0SDN6Y1kwb2J3cUx0TzRMVFhCUkNQeFJGdkI1SEhoY1laTUpxOXQzb1U1bDBMWmxxWjNhMU8tcWc9PQ==
"You can use hardware from any of the big cloud providers, set up a Kubernetes/Kubeflow setting on it and/or run your custom server, may it be PyServe, gunicorn, TF Serving or whichever flavor you like. ",r/machinelearning,Z0FBQUFBQm0yeGJ3aWx4dDJtUEhEMi1MTlRGV05HYnZUdldKR21uSkUwVWlmYTJzMFk1b1pSRE1JRlIyS00wQU9HeVVScGZ5cFczMkNKQlV0T2ZOSHdlbTN0OEx4V3JrdUE9PQ==
any update from them,r/machinelearning,Z0FBQUFBQm0yeGJ3YVdqSDVwaHBDZEJVU1REaFd1SFBjS3NNTF9CUGVhd3laQXZVXzYxdUZtOFp4Snh0eDN5WVJTcklJNXdrT3E1a1RRU3lkUXotSWNvb3NjMFdhZE5vcjJKQ05kczlYVUJrU2J2WjU1V0xmRk09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3aHY4eWRweUxCWXU1UHctekpiUWZuS3c0Z2wxa0lXYkg3aTBPbVE3a1dOUjBpQjJObngxQzc5a1FldFdub2pMUVBCSmJyTXlxSW5Hd0M4dExubzIzcGc9PQ==
"Thank you for that since I think we will not be able to capture such large datasets. Also, since we are currently studying it and kinda new to machine learning, I just want to ask if we have a folder with like 500 datasets, should we rotate each image first before organizing them into a single folder?",r/machinelearning,Z0FBQUFBQm0yeGJ3LXMtYmQ1QnplQUJEcTJKanF3d24wSF9UQzZzZkdHcFFuMnlpakJwOUxXNkhHLTBsV05lZ0dtLWdraFZlc3JNMDBIbjJlVVdESkRyRmFqLUQ5VFhvTFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Y25KR3hNcTMtT1JzN0JCdXpNQ2VTbGJjbF9LaG1BbWwtMmw4bHkyanRjdnREZWczUzdvMGRiQzNlZk1TRURmMVdlbnI1YUFlOHJrMEhLMVFnVHZPZmc9PQ==
Oh i totally understand. I was really just saying that neurips has gotten too big in a half assed rhetorical question way.,r/machinelearning,Z0FBQUFBQm0yeGJ3WWhqRk80bWl0cUpjeExGNEY1cEkyTlNuUzdLV1Jid3ZyOTBna0Z6ZzNKUnFSTHl4ejE2VWphYUExSXl2c05ObjBWYlpjaF9rbTJseWpoVmhmZFJqVXc9PQ==
"Most people will just apply data augmentations directly in the training code. This allows you to do an infinite number of random rotations during the course of training.

You can see how to apply a data augmentation to an image in pytorch here: https://pytorch.org/vision/main/transforms.html",r/machinelearning,Z0FBQUFBQm0yeGJ3RHlqMDJoSXIzTVY4MmQyS29NYkY4eFFXRldTcWJKaHRCZ0E4N3VXZnVoa2dDUWlUVmVxZFRnb1AtM1FQbHBBMDRFdmNpbGk4bUlpT0VQemc4Wi1pU1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Z0pLVlVPekdXMHpMc0NieWE5ZV9acHpXYmlJa1V1MnZxYTNFeEJycjZVQVFiRUpxQUJFOExLczVDbGpycFl5alZ5TmNwemJSOUU5aU9FdEI0YTBUMUE9PQ==
"Wow, a thread where every post is helpful  Gdi, I just ruined it.",r/machinelearning,Z0FBQUFBQm0yeGJ3dkNzV2NtNFRjYkg2dHBaUTYtM05YOFlNRXBDMThjTWtMcnprZFJqUDJ0eTloLU8wMkdpRUxuZndTUTlBRnFSajMyQXpkNVJMaE5lTVExWmtaTHBNdFE9PQ==
"Hey, I was just glancing over the paper.   
I think the approaches are different. I use QR decomposition or *random* matrix **just** **to get** *orthogonal vectors*  to ensure AB = 0  
If I understand correctly, the paper edits/compensates the weight for LoRA-ing? And they do QR decomposition of weight matrix W. They don't make sure that the product AB=0 (please correct me if I'm wrong)",r/machinelearning,Z0FBQUFBQm0yeGJ3NlN5VVczRGh5VTNiYTVvamROTnJGblFvNVB2aEpfUlM3RG43RWdZRzJRRFZ6SmlTVnd2WE5wQkVGQ3VTcTgyR0pKSmNfVmFSSDFKeGN3eWV6WHg3N0E9PQ==
"In my very humble opinion, undergraduates should not be allowed to review. What is next? High school students with a ""10 year history of coding in PyTorch . .  Full Stack Developer since age 8"" being allowed to review?",r/machinelearning,Z0FBQUFBQm0yeGJ3M1QxODdoenBzbU1PZ0pfUkhiWEU2ZGUtNWVvdm4ta1FQR2tYTmRSVjJST1d1Um05eTRQaUkzOWhCMzR5a24xRVJVWUgwSkhVOGRuWXBxLUtpbWR3c0h5QlV4X29fS29senlnQ3ZXMWVGLTA9
"I would love to question some randos on the street and see the range of answers to the provided question: ""Alice has N brothers and she also has M sisters. How many sisters does Alice’s brother have?""

It's not hard, but I bet a lot of people would get lost in the abstraction and say the wrong answer, even if they could read it on paper.

I skimmed the paper: is it more than just an example of a problem that an LLM failed to answer correctly?",r/machinelearning,Z0FBQUFBQm0yeGJ3VDM3WHFXdXgwVHBlSWVSYVlOYTBLdmNXeWJLTlpsYmhwdksyUjZ6RDlUMmZJVVAxNWM3dTBHdU1kOWgtQkFocDd0Y3RUZWJKbDV5cFNpclNHYWZTZG5Vb3U1Y3g5Q3VFYlhfSkRLRGt2eDg9
"Feel for you.  That can happen a lot in the ML world, but missing by a few days must be especially painful.

Good news is you came up with two good ideas, so chances are you'll find a third!

If you do come up with another LoRA related idea, I have a project which has made extensive use of LoRA that might be a good fit for experimenting",r/machinelearning,Z0FBQUFBQm0yeGJ3QXkyY1pkSWVfenpHTUhSOXBQRUM4UXV5WjN2S08wZm5aSFZSWVdoTHlQRWNJMm1DLUxUUmh4YTNHR0UzWm03WXA1MnFsM0o0TTBoMC1telpXQ1JqVXc9PQ==
"If they're not able to pass the test without tweaking then it was a bad model for that specific purpose but after tweaking it's not necessarily any better at the task just at the benchmark.


Phi medium is my biggest disappointment. Better than llama3 8b on paper and way worse  than it in practice.",r/machinelearning,Z0FBQUFBQm0yeGJ3NGFHWGtKN2pZeVM0OFc4RXVCckJrLW96ZDBITnpna01SQTJTQ0RpazhfOXZBSDJEb0dwNllSeFhtMG1rLU85Wld6aWdUc0plZ181ck5WbDBBUnlSdXc9PQ==
I'm interested,r/machinelearning,Z0FBQUFBQm0yeGJ3Mm1zdnUxblFWblNSSWVjeXI0aWY3WlRIT2llNGJOcU5EV19FSmFoYTRkcF9YR1FGTUZKQXpfUmxNSHZFZl9oSlVhSFZnc19nN2FkYU1tU2tJbG5hcUE9PQ==
"Yeah actually, your reading seems correct.

At least you have a different comparison case now?

Something that would be nice to see is if the initialization schemes change how robust the resulting accuracy is to rank, because of plain LoRA’s sensitivity to rank.",r/machinelearning,Z0FBQUFBQm0yeGJ3NWNPNVRhSE1JSkwwdjR1bHJHcmdJenFwOG4wNEZJMVk1bGR2THl6enotMzlFazJHVkpiZGt2WTRPNEFTYXBOM0UxWWp5emo3Tk9NZlQ4TmFpbzVvanc9PQ==
What would be an example of a problem you can't break down into parts?,r/machinelearning,Z0FBQUFBQm0yeGJ3VUZzZjA2RmxJM3BnMHlXQnhfZDctNVZ4ZEtNVHkwQW5kbHlUaWt5U3FLX2MtclUxRndqOGFvY0NsN2hCRURtdHRSQy1mWk4xWlFaMXd1X0diTVlDaHBaOHVuLTctbFdoWEZXbU55aHFkOEE9
"It seems.... less than that? It's a problem that small models almost always answer incorrectly, just-behind-SOTA models get right occasionally, and GPT-4o usually gets correctly. So basically the same pattern we see everywhere.

I mean, sure, throw it in the next benchmark suite but maybe don't give it its own cute name? :shrug:",r/machinelearning,Z0FBQUFBQm0yeGJ3TnRKV0RuYXJMTTRHT2EtQnc1TVgycEF5cllfaXl3c3Z5ZnBoVkJkZjUtanBGbHdTVEhzTU05WERQOV9BcnMtaHZvYTlLYmZWb3c5eGg4TVlhbGpYZ29mQVBESDhZRHg1V3JBSmp4ci14NFU9
">In blind evaluations, gpt-4o [dominates](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard).

I don't know if I'd call 60% win rate (conditioned on not tying - which happens 30% of the time anyway \\[\\*\\]) ""dominating"".  That 40% is a lot of wins the old model has (i.e. it is actually better) and raises possibilities that for a good number of tasks (albeit the minority) old model might be better.",r/machinelearning,Z0FBQUFBQm0yeGJ3Vl9JWU9pOXJmQTFjTVdwLWxWUlZremtNd0lIUjE1d2tNeDhKZkM2eTlsTGowRTVWVkl4X003aVkwSVN6S1NkUFlkSHFCQnAxaWdJMFBjNW9FUWtHZVE9PQ==
"I posted this as a sanity check because I also thought that:

1. 48 pages is way too long to devote to this.
2. This really isn't new information that has to completely reevaluate how we think about models, which is something they said in the abstract.",r/machinelearning,Z0FBQUFBQm0yeGJ3Y3pMdWJFQ0Q2V0FkZ2YxNXJCTzRSRVRSZjVUU21vOGtXWGpOLXVDNUhYMy0tb0hFZmJtLVFRcmZFajkxUmJJNjlaaEFzTFNDVXJ1SXhOb3VaZ0tuU0FZdFNXdTB3VjBnMlRzTURlQVljX0k9
"Actual contamination is unlikely an issue with [major labs](https://arxiv.org/abs/2405.00332) (OpenAI, Anthropic, Meta), but is with smaller labs.

Agreed that there is a risk of overfitting what benchmarks are asking, but things like MMLU are so diverse I wonder how readily possible that is.",r/machinelearning,Z0FBQUFBQm0yeGJ3bF82ckE3RXJibndZMERjanZHM3NqSDEycVNBMXV5X0w4bW83MmFIWGpnT3dqaGxnWTZ3R0g1bGpjeENwT2VBNG9vYlQyb1lINzVYdmVlMGRZMnJob0E9PQ==
"This is the response that appears on virtually every example of LLMs failing to reason, usually in the context of an unfalsifiable belief that LLMs can reason. Any correct output they take as evidence that an LLM is engaged in reason, any failure is dismissed with “but humans also fail to reason sometimes!”

This is true, but usually humans are tripped up by well known word play and/or undercutting dialectic assumptions (pound of feathers example). Along those lines,

(1) We should have actual evidence people also have a high failure rate at the task and not just the imagination of some random person on the internet.

(2) We should focus on the types of failures for an LLM that are unsurprising if the LLM has no understanding or ability to reason, but highly unexpected if it can understand and reason.

What’s significant are examples that involve no dialectical misdirection, that any human can easily succeed at, but LLMs fail at. There’s a feedback problem though in that as we find and discuss such examples, they can then end up in the training data and then contaminate future results.

Note that this paper involves the LLMs outputting “reasons” for their nonsensical solutions that are also nonsensical. Even if a human failed at the initial task, it’s hard to imagine them continuing to do so on these conditions. I’ve seen this myself with some of my own tests involving very simple games that a child could successfully complete.",r/machinelearning,Z0FBQUFBQm0yeGJ3OUlqV3IwdWRrOFQwQVBEUklYUmM0RnVEa0hva3FEWm85R25PV1Z2WlJ1dGI1N09ib0dmcTJ3OEUyQVJyMXY4ek85LWlDUHRRcTk3LU9RRG8wR01RQ1FxRUw5WTQ1OUpUM2JTM1pGLUduUms9
"Hey, for an assignment I'm training a Neural Network on the MNIST fashion dataset. I'm trying to optimize its parameters however now the best I can do is train it for a set number of epochs and then evaluate a performance. Is there a better way of optimising? Maybe stop the model if its accuracy is no better than the previous best by a certain point? Or is there a more intelligent way to adjust parameters than just a massive 3D grid?",r/machinelearning,Z0FBQUFBQm0yeGJ3MDUxM2VHQkNHZkN3YUNaUndGQmtUdkZyY01RUHpiZkNMdjVsYm8tdnFmRjNLWW9xRndKVEJQZXFiTlJZTUZrMHRid0lSdERiMW41b3lCQmJrTXBtOGc9PQ==
"Phi is one of the [worse models](https://arxiv.org/pdf/2405.00332) in terms of benchmark overfitting/data contamination.

Only Anthropic, OpenAI and Deepmind seem to systemically avoid this issue.",r/machinelearning,Z0FBQUFBQm0yeGJ3b1hBQWZHZWw1S2ZvV1Z4V3MzNDhkdXhZc3pBUkFwVWx0dXNDZmRELVloR0UzR1pIdUpSVmFaRzRyRGZVUGkwNGVqclJHMlFpN1FPTHA5UUJET2VTRHc9PQ==
"Sorry, I didn’t mean to imply bids would override conflicts. Only that it makes the work of collusion rings easier since both parties (AC and reviewer) can place bids now",r/machinelearning,Z0FBQUFBQm0yeGJ3YThOOW5sSXNveXNOQ0dZN0RERFlmQjNQdzFLdGVxb2J6LUs3S0dmMERNUlNTTElyMEpkSlJGZHVCUVJ6bXZIcE9NV2JQWFlIQnFzUl9xRFduZDhyOEpPVWEwSVd4ckVuUkp2M2tzWGpHZTA9
"Hmm...interestingly, unlike last year, I did not bid any papers this year, and received my assignment automatically notified by OpenReview. I think the board is trying new things to address these. Also I got multiple emails about updating one's DBLP.",r/machinelearning,Z0FBQUFBQm0yeGJ3N2xXZ1h3QmJ6alBsSG9tSFRBOHdFTnhkbjdJSVVST3Y4S3g4UFNuMjdWRnpGRUpkUXFod3NVQklkSE9lRi1JanNNZ3pxcUNhdld2OVlJZ1ppNEcwQVE9PQ==
"tensorflow is dead

""We see the steady growth of papers utilizing PyTorch - out of the 3,319 repositories created this quarter, nearly 7*0%* of them are implemented in PyTorch, with **just 4*****%*** **implemented in TensorFlow** ([down from 11% last year](https://github.com/AssemblyAI-Examples/pytorch-vs-tensorflow/blob/main/2022/percentage_repo_2022.png?ref=assemblyai.com)).""

[https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/](https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/)",r/machinelearning,Z0FBQUFBQm0yeGJ3NXhkWi1JcktRM2R5TURQeW5BNzZzX08ybTQxUzBqNk9mYkNIb1Z2MEpiTTN4Q0Rqc3Z0dENnR3Foa1p0WGc5azIwQWd6YUxycHp1YmR6RWliaXh5MUE9PQ==
"""we prompted ChatGPT a bunch and here's what it said"" is the lowest tier of ML paper.

We all know LLMs are bad at reasoning. Not only are there fifty papers about it already, anyone who uses ChatGPT can see it.  It's not worth publishing papers about unless you have some new architecture that reasons better.",r/machinelearning,Z0FBQUFBQm0yeGJ3WG16M2NLS05kTzA5NnpiNkZVSTB0ZmNkZXcydTdqWnZvSkJscVFXVkN6eV9uTWJVb1hmLVh3cnd4LS1POGw1RVNNcnFJRzNxOFB1Q0s0R0JPeHVnQ2NRSjNadW9IaVV2ejBFVmNnYXlSZzg9
Correct me if I'm wrong but weren't LLMs always bad at basic math?,r/machinelearning,Z0FBQUFBQm0yeGJ3TlBDRzhNNXh3M1d1WkNLVUUzLVE0V3JNcVA0el9uSWRxbEVjTC1NTXRkZDVJVldPWjZuQTZVektzdHdhTWdfdjBTZVFwcHhwd082bG0ySE44UERSenUwdmZ1a2VycktoYnFfY25VMk9Pblk9
"I don't think it is controversial to say that LLMs are very poor reasoners.

They can't even count reliably.

Given that broad consensus, I don't see what being able to trip them up on this comparatively tricky question proves.",r/machinelearning,Z0FBQUFBQm0yeGJ3OWk1U1RYNHdVNnFOQlc5ZW10dzZfT0t6V2FqMnpQNVhSNW9PU09QNnEya0w3MXZlbUx4S0I3RFI2SzlOcjZWdlMxWmVhbnA1cjRBZV92VTdFTTdSYlBjZHo4dUlDaEhWbHNRckxScHEyd2M9
"Yeah, just heard back from both of them. They said they can’t release the test ground truth to the public yet",r/machinelearning,Z0FBQUFBQm0yeGJ3VjAzYlNYZ3gwUnY0b0g0WTQxWjRzdG5UMC1jS1ZFWHA4RGpIbF9FTmcyM1ZKeUhudi1GVjlIS3lRZlQxV29oWkFMMTM1TlVRUTJzRy1kZEFKQ25jU3c9PQ==
just do a k mediods or random cut forest clustering and treat each cluster as a minibatch lbfgs will perform like an epoch pass/gradient accumulation over a respective dataset. scale cluster size to a reasonable batch size.,r/machinelearning,Z0FBQUFBQm0yeGJ3cnFoTjM0R09XblIyeTdNTFd2N1p0X09wa2NQYTU4UVFJeFpYSlJwVmVaSkhaNklCcmZ6R29SOXpfdHZJVDZlbV9DRE51TEh5YWR0dEFIOEdUQkdCaFIxUnl4dlhvT2loUE4wZHhJYmpvMUk9
"Come on that's a ridiculous hyperbole. The real problem is it's hard to figure out who all the qualified reviewers are, especially in a scalable way. Can you propose a solution on how to actually find them? Besides just ""invite all the qualified people are you dumb"".",r/machinelearning,Z0FBQUFBQm0yeGJ3UHFuWDdCeklBZXUwR3I0bUR0WU1OREhIRndMckJBZ0xHR29HdE5XcEdLUnBWbDNldWM3WGpqZV8ydHdOdThLcEN0NE5SV2hMNlNqQ0RxdjUyOFNqZkE9PQ==
Nope you can't. I forgot the bidding deadline and tried to do it like 5 hours after deadline and it was all closed already. Seems like it would be helpful to just keep it open.,r/machinelearning,Z0FBQUFBQm0yeGJ3eEloVWpzQlpmRkJaS0UybTJtak00emhXMHVvRUVlT2lPU1oxV3ItYTMySjF0a0ZvemJia2tvZFY1VlpGdmJfem05M25Qel9TdVJkSmlNUlRWakl6V2c9PQ==
Anything that involves serial chains of computation seems to be difficult for them.,r/machinelearning,Z0FBQUFBQm0yeGJ3SmxubUZCTXRzNHBSRF8xV3pQZnZ0eFU4dEpEWkJWSWNCOVBmQy1JRVI3MjRTOG5zMVRXUDl1b2t4VXp5aXZ2dVNGYXVtSkFmTF9lbE9RZHhWVWtOMUluQ3paUGhwV0xRaHBVbXpfWjQ3RWM9
"And yet we can't seem to convince the ""medial"" consensus. Engineers don't have a problem with looking at it critically, it's literally anyone else. ",r/machinelearning,Z0FBQUFBQm0yeGJ3d21RZUZuYWV5dEpIbzFWYlhQekNwSlBlRGxpR0NsWWtWdjFwdzh3QjZpbng1YldsMnJ1cS03bzlRUUZyUkNudmxHOW02Uko4Y2tVVkp2dzJSZG5lOWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3ckYyU1hjX3Yyd2RpZ2JWM0tkMzhIVE1CeHVQXzdPd3l3NVk5RjBfZGxWNzAtSFBVdzNkSENlRVJ4bzNySkQzd1JwYTRvMTlKN0N2dTNKRzhMOFZEZ2c9PQ==
"It seems they actually sub values in for M and N, e.g. ""Alice has 4 brothers and she also has 1 sister. How many sisters does Alice’s
brother have?""

There is another version (AIW+) where they make it more complicated (Alice has 3 sisters. Her mother has 1 sister who does not have
children - she has 7 nephews and nieces and also 2 brothers.
Alice’s father has a brother who has 5 nephews and nieces in
total, and who has also 1 son. How many cousins does Alice’s
sister have?)

> It's not hard, but I bet a lot of people would get lost in the abstraction and say the wrong answer, even if they could read it on paper.

Embarrassingly, the first thing that popped into my head was ""this is easy, her brothers also would have M sisters!"" 🤦‍♀️",r/machinelearning,Z0FBQUFBQm0yeGJ3N2w4Q29PbFJ3TEJxSVZNSThpU1hlLXUzOVVjbjVFZncxTFZiZlNyTFF1SjhMMVZ2Ty1EeGg5QVNOVU0yejFuUXF4MjFnR0IzZEltVzJjeTNnWFVWWVE9PQ==
"By “medial” do you mean the media?

If so, I don’t know what you’re talking about - the news is harsh on AI almost beyond what’s deserved. Go open up the verge or nytimes and it’s nothing but articles about how LLMs suck, will tell you to eat glue, and are being forced down our throats by greedy tech companies.",r/machinelearning,Z0FBQUFBQm0yeGJ3OENheEZzeHpCT2JTcDhQdG5DM1c5eG9HeEpUX2l1UEZFbXhqdUJSdVRHbzBKWG1yY0xNOEZKc3R0MnBiYm5TSVFCTElYbVQtaFBfdDVNMU5RNjhULUQ3cnRwRWFnYkJhTmhLUFVsbTlLcm89
"ChatGPT used a stragely termed reasoning (""Alice has 1 sister (including herself)""), but responded correctly in the end.",r/machinelearning,Z0FBQUFBQm0yeGJ3amVaczNuQU4zcEhKT1dzX2xENjR2cTBGWU0ycUJCdEFwRDRlZ1U5MmNfbjgtTnM0SVI1ZjNTVmNEU0dmbWNYSXRHd1N6U2xuUGhUSVZlU0k5ZThTV2l0cUlzd1JQRjBSMGQ1a2dsRWhKYlk9
same. i'm annoyed when i see code which uses lightning.,r/machinelearning,Z0FBQUFBQm0yeGJ3bUxiU1UzLUxSOV96bnN3QUwwS0MwekN0QW5vODc4YXVtcC03REczNFZCYUN3V01tVUNpZkl4c294WnhLY2ZXYTdnSGRnX0lqbEpNN05Sci1uVU9iZGc9PQ==
"I heard this was potentially an issue for e.g Qwen which is well known, I believe.

See [https://arxiv.org/pdf/2405.00332](https://arxiv.org/pdf/2405.00332) for instance.

Seems like this is more an issue for some Chinese LLM too (like Aquila if you take a look at the paper). Indeed the LLMs from the labs you quoted seem genuine.",r/machinelearning,Z0FBQUFBQm0yeGJ3MEZnUHVWZ1dKaHFJNzFkeUd3cHpUcGFHQjhSUEtOaFR2Rktra3Btem1MTFh0Tkl2VjItRU5zT2Jjc0YtVnZ5MGU5ZXp4a2k1OW5hUFdSN3ZFRVFpcGc9PQ==
"It was you, Sir",r/machinelearning,Z0FBQUFBQm0yeGJ3aHY3VkotbFdEbVZ5RHRDdHZ4S0VqdWNIZkxoQ2ZFTUxveHhzZ1o5YlF2b1c3VU01a3ZNWWlIWHZsYWZJbkNDNkVEYlVjejdQdURxMlN3VE54QVF2SlE9PQ==
"A larger model will take longer to grokk, but if you expend the training compute to do so will outperform the smaller model. if you don't train the larger model long enough to enter the second descent then yes smaller models that have can outperform them.",r/machinelearning,Z0FBQUFBQm0yeGJ3eUJqV1pHV00zZGo5TVdFR0lUMWQ5V1QyQUQ2bnBwY1dvVXVkYVhiMGhJSkZ4aFlnd19QYzF0MElWcFFIQ1ZLSkJLMURLUGlSa3ZKNEplSlJDYkhMT0E9PQ==
I’m not the thread starter but I do think CEOs are all in on LLMs. It’s them who need this message more than anyone.,r/machinelearning,Z0FBQUFBQm0yeGJ3N2lfV1BrdVJCajMyenRCMGd0OUdMOWQ0Tm84TzFTNUhwaF81ZnZhUnNUUGFGWTZDUG9nSUxhV1N4cEVOa0k2bTQ3TDBCZnVoUnQzZnRTNFhjdnRSbGc9PQ==
I'm really curious how OpenAI's next gen model will be. I have a feeling it will not be as big of an improvement as people are anticipating,r/machinelearning,Z0FBQUFBQm0yeGJ3d1ZkbEZSSVU5MEVaOVF3WnhsSkpsQ2VOU0M5cVVkSE5vNEpZQVdOYXZXeW42OW5TUTFJZ0lXTzlZSllmcktOaTh1enBBcWxkZG5ScHZuQk9nT2RtbGhxdTA2c1R3cXlwa3M3YTkzWTdXSzQ9
The truth is that tf2 has better utility than torch. They are similar now. Tf2 provides awesome data loaders and trainers. But tf2 doesn't feel like python. It's just... TensorFlow. And static graph makes it difficult to implement flexibly. But torch feels much more native python. And it's dyanmic graph nature allows more flexibility. Can't speak for the speed after torch 2 cause haven't used much of torch 2. But tf2 was certainly faster than torch 1.11,r/machinelearning,Z0FBQUFBQm0yeGJ3Z2NRSW9qZUJjbVdzTm5PNGtsMlJzWTdDNTBBRTZmR2FJVllvbXlPeU1mWTRQMlRiXzJOWllBWkN3ejd6dFRUTFYwV3p2ZnQ0bnh0dFliUTF3ZDJkbXc9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3OXZxVi14eG9yV2VPT240clo5alcyaXJlcXdFd2pLQmtkLXZncnltdmhuS2IxcVhibUNBYXE1QTRWV0xMNlRyU01kU09BS0tHY3R0OF84TTBUMjVtdFE9PQ==
Yup. Modernized tf and torch are similar. They share many low-level functions,r/machinelearning,Z0FBQUFBQm0yeGJ3cXh5cDJSSk1XV2dGUjBNU1hENnE0MXYwSDdGZlhhb0RQX0VhMi1wMFhzYUVMcVBXQXZCaG1DcFhWcl90czZRZ2tvckZkRk5NQUhlLU91VDVGc2hVd0E9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3OFZlekc3YUNsUjRuUnRzODI2Y0JoMEFYOXZidGQtTFIyVzJWQjByaGdKTXUtSVNXcEpicWd4OFBJUnNHWm5GX3E0aWFqUGJiN2dyLW5STnNkb2dQZEE9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3aEtnWTdoRmJDeTNFY0NOSXhkY2JNZWV4eWRnZU5paGtRYksxT3c1LUx1czVUam5aQ3NqdEVSemZuMk8xTVRvMmhWQkd3TW1LWkxoSkdrOEFzLXFYRGc9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3R2MwcnRWOUhmdzJnSWRnR3gzTjZEVlBPRGlHVXhjeVVoWFh3cGVkZnpOdTlLRFRkV0VxcGhMcUFhVmh0UC1QbnBaTUNWdkZXZmZNRVRNVEhaWkFMRUE9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3LUVMamFaMU9rYzlEQ1lSTzdZN2hqT2x6WFZHVG84YkU4R3VwS2djWnFndzlDeHROank0SU52NXJfYnpPQ0NROTZGUWd1dmQzbmxEMGlfbm41X1VwdEE9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3QlZDMHhYVzBHTXBnQ0xUd2lSNHlMRHJpRV9wRnlzdzFLWU12QVBZc0F0RzFoU0JHSnh1VlFXamNIN1NHVWZGX0ZVemJKOUNWbXVNWS1zNmMwVUZLU2c9PQ==
"There's an appeal letter going around:

https://x.com/Haoyu_Wang_97/status/1796627484454064204

https://docs.google.com/document/d/16_5hE_K625l6LmlCriog2JQg51DufDOWAKTzzxUMx7A",r/machinelearning,Z0FBQUFBQm0yeGJ3ZnBzMGRfVUUtbHlQU3U3QmtIc1Z5ZXVlQ183ZWh4akt3RkxSUUlmN3JHNU5yTHQ2Uy1lMDlCdUZRSE5KWV9icnZFY3R6MVlLaHBtSldha2lkemdpVXc9PQ==
"You have hit upon a hard and cold reality of data science and ML work that many companies do not wish to accept. EDA and transformation is a big thing that gobbles up lots of time long before building a model. If you are in a healthy organization then they know this but some orgs assume that their data is ""ML ready"" when there is no such thing as ""ML ready"" data.  

Can't tell you how many times I've had to tell data warehouse managers that their data standards and quality control measures are not being imposed. Many times, it's only when an org starts doing serious data mining and predictive modeling that it becomes apparent just how crap the data is. Worse, they get mad at the data scientist as if its your fault.",r/machinelearning,Z0FBQUFBQm0yeGJ3VlZpeTRhSVl4azdZVWJmRUd6TUthMmt1UjhjUDRsS2o3aG9kZ01JT1AxUGt0Y2FHRk5Tc2ZkRE5wcHMzbmkxOGJORkdKemJWVzFYSG9RcFVvWWNZR0tHNXNyblRyck5wejBUSlVQOUZ1b0U9
Why use not just use tf2 over lightening if you're not in need for torch to full utilize the flexibility of dynamic compute graph ? Tf2 offers better customizability compared to torch lightening.,r/machinelearning,Z0FBQUFBQm0yeGJ3SEEzQnE2eDB5TWhVX0MtcWtIeUlmdGVWQmF2cXZYQldIS1Vpek9EUWNUZFdpMkN6VlM2RnRVd25BZ0thZlhRenFIR0RzcHowUjJxODVTUGxkVFhpZ3c9PQ==
"Models that are not designed to solve reasoning tasks are bad at solving reasoning tasks, news at 11.",r/machinelearning,Z0FBQUFBQm0yeGJ3Snhxd2VCVG5wN0tmbjdnamRWdEFIVDJCYW8wTHFPdjRIUDZWSmJDOXlDcTJKOC01eGs1OHRQTmpZZmpHRWJZak5SbGJnREEtMVFuMDJadkpMNEVBLVE9PQ==
"My guess why Google suggest TensorFlow as a search word for you might be that it used to be very popular and technically still is, but the announcement they Google will discontinue TensorFlow produces a lot of articles and therefore search hits as well as demand for information about what to do if you are deciding on an ML library or what to do if you've been using TensorFlow.

PyTorch is a natural choice but Jax, which is gonna be Google's next ML library, could also be interesting to look into.",r/machinelearning,Z0FBQUFBQm0yeGJ3dUxKSUV3YVVyU0JsRl9qbXhCSW9CUHF6bWE5ZXE3QkxnZnBDUEI0cGEzUjFDM21ESm1QVXpfbVBKaERNRkZwRTdWSjVFTGRZNjNMZGlxRExPQmp3V0E9PQ==
"My pet theory is that papers like this are an academic manifestation of a spiritual crisis that has resulted from human society being presented with irrefutable evidence that language and thought are not equivalent and that language itself is not a supernatural ability that is unique to humans.

We're going to keep seeing these papers until society adjusts, and even after that we'll be left with remnant pseudo-religious beliefs that we'll never be rid of. We're still dealing with spiritualists talking about ""vibrations"" and ""auras"" and ""energies"" and what-have-you, which are the result of society adjusting to electrical technology in the 19th century.",r/machinelearning,Z0FBQUFBQm0yeGJ3WGdLQmV3dENydnFCQWREV1hoSDIyZUliYmIwNmRtVW9VcVJPemNqVW9tb3FqaWxrY20xWFJlVUcxZHN1RnpaQ2N3SGhPX2JYa2x3akQ2RWZhdTZmY1E9PQ==
"Oh, are you saying as ACs you didn't bid this time around? That is very, very interesting, albeit possibly annoying if things are too far from your expertise.",r/machinelearning,Z0FBQUFBQm0yeGJ3aVJ1WlYzMm1HUTdnS0U1THZWbU1mN0k0c01TTlNodHNHQ3hSS1JGNDUyN1ZOYkIySl9IRGVNN1VRTDZuR21Pdkl3RVY1Q0FENHlVamU3SWYwY3NsY3dIMFR3OUx1R3lrbVE5WHZ0RmxRRjA9
"Before anything, basic linear algebra, derivative,  loss functions. Much of the ideas these are tiny ideas somehow over publicized jargon. Explain how to write a transformer and create embeddedings. Everything else will fall in place. People will understand everything on their own how to progress.",r/machinelearning,Z0FBQUFBQm0yeGJ3UXBuXy1HRWVjcDU0ZU8yMjgxT3RjT1ZNbk5EdzNWRmFZNmV3S3M1TzZPRDliU2VKWDFzNzhMa09tSHZfV0psZExZWDRxeHhCN09lc1Jzd0ZQUW52eXc9PQ==
If I’m going to rely on technology for more important tasks then I expect it to be better than your average human.,r/machinelearning,Z0FBQUFBQm0yeGJ3ZDcyaVRXakcxRHMtT0swNndDNFV4N213UkZtdE5SY2xrRlVKY0I2eTJsQkluY2w1RGF1UWZpX2RXWVpqNU9tMVI5ZVhNSlhoWHpQdU9Ld2xOYjA5SVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3SVBXd2pyMEwyYkxtOVh0eE5YZVlQVzItX3JTUFlsT091QWpSVmNnbVlSSTBvNkhGalc2dkpkdzhrOXJaZDBzUko1U0otQ2M4d1pFaGZQbUJyaHVjTFE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ3NkFFeE1tMEdGWVFRNEJ2bVdMVDhWTzAxTXJOVU8xd3pRbENadWU1dWFuRWtRLU1PRTNkbjFhTjFkZm85WEYyd1h6SFROWFByTUtFbU9qX19DQ3FFUlpJTzFUMXpyZm1hTGxsSTZuWTVLS0U9
Seems like OpenAI got my message and are now extending the deprecation to September! Absolutely delighted. Hopefully sense will prevail and they don't depreciate it at all! Will still look into alternative options but at least now I have the time to research and test different models and compare it to my openai one,r/machinelearning,Z0FBQUFBQm0yeGJ3SHhOY2dUREZBTTc5NFBjaHRHTDc0c01veDdiRS1oR2kzbDlJV0dFQXpMaVJJSTJlRXF1NVBHMmhzRDE0UFJXakZCeS0zS3JEbE56aVpsZFJidHNZMVJZYnlPV3hZeGRaRExpWUJ3Tk1wSzQ9
"deployment, deployment, deployment",r/machinelearning,Z0FBQUFBQm0yeGJ3a2c3UFBhZFRTSGVSZnBHRmhsR1FxV1o4X0RhX1NZcDhpYmh6aFJ4RkZrUWs4NzhVb0lUVWVObE91UFQ3WXc3TkhRSE9aTkQwUmNNMmFvZXN0cVQ3aWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3alJfTnNlNkIwNU5mMUhldFRQc3J4R2Z6WV9EZ29uNDZLbm5wZHdRak1JekwzYWhUdF9xNEctU2Nsa1ExdDFqZjNYMUpmdkJuczZIdW5DWnVkSHdiVVE9PQ==
"Cool title, but unfortunate paper .",r/machinelearning,Z0FBQUFBQm0yeGJ3UGJycFhDVUQtdkJJTUg4Y3o4eGJTUkQzbGx3ODRUV3JVdXJHQ0dMcmJjWGNwTlN2QkFFREdpSmtoV25wR0NvSW5KS3E4VUpwSkNpckNGekUzeHRkWWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3R2RYdFdObWlwWUloX1E2aDlzNXZOLXJqMURaajNRUUxWM2ZZTGx2ZkZoTjE3bWtMYjExV2QwMVFfVHdWS0oyV05XdElLQUxkRjFvWWVocXg0S0x2QXc9PQ==
Other interpretation: GPT-4 is so good that finding a single mistake in it seems to be enough ground to write a 40 pages academic article,r/machinelearning,Z0FBQUFBQm0yeGJ3Z3ppMFc1N2ZrLXJoY0lHdnlRQWxsMjhNenoyekRGWkZJejl3UnRPTjZxcGxweUhpMDQxWjVaZGxGTFYtR3djTzY0TUFKRGF0Z2doTEdyNWdSbjNNOWc9PQ==
"that is a very real possibility, not gonna lie",r/machinelearning,Z0FBQUFBQm0yeGJ3SDRmMWlxYWdiZE9PMW1vYUZ1S0toczREckd4QVhER2xFNGJJczdKajU5UGM3cGg3QlhDSnZuTkUzODZkeHFhMjZnRTBJTEE1WnFWU0FPN2pqWDRPV3c9PQ==
"That's not even true:
https://i.imgur.com/0IpdZma.png

And on more mathematical problems, it is often capable of generating a program to solve it.

You need to prompt it for it, yes. But saying ""A LLM can't do X"" is a different claim than ""A LLM can't spontaneously figure it needs to do X"".",r/machinelearning,Z0FBQUFBQm0yeGJ3T19wUnFTYjdXTENCZmJIQzlVYTEzVHhKOUNPN0hzZW83MDBDeVZNVkZIWTBhVzlZdFJPTEdUdDJwVUxzVVNVQWRDZUo0NHJBZkRpNHJFaTB0bHNpLXc9PQ==
Actually the big news is that they actually are fairly good https://i.imgur.com/0IpdZma.png,r/machinelearning,Z0FBQUFBQm0yeGJ3ZXJ5WDJNWnI4U1lxbnBCaGQ5eGFhSTd6dmpDODZ5MjhKZDBhNi1hUmFvUUhCLVpSMWZleUZvX21yeTdIRHhId3NLUE9NVjVxM3hSMERjMWxEd250QVE9PQ==
"In such cases, prompt them to generate a program that solves the task at hand.",r/machinelearning,Z0FBQUFBQm0yeGJ3NDlFdUJLWS1uQXJrNG9sTkJ1ZTVYTWFMaEk0UU5MXzlTRzlyRVd1YUZUVF91Q3AyY0dDbjF1WG1PU0pob2Jmb3RZNkhiT3FTVEFCV3RpdG1lQTNnX0E9PQ==
"This works for simple stuff, but since program synthesis *itself* requires reasoning, it's not a general solution. Too complex/novel of a task and the programs it generates just won't work.",r/machinelearning,Z0FBQUFBQm0yeGJ3N3dIbXF0WmdKVjE2cG1vUEZhWmxwdE1JVW5PYV9waHN3aHVjejdLYmowWlVIODNrUGJVQXl5NkEzbkhHWHVQeDA5eExWRDZKVE52bVYteGladzY5d1JaaFRRVElyc0hlTXFDUzB2WXpJUGM9
I think there’s a pre-trained embedding layer you can download from the model zoo if you’re using tensor flow. ,r/machinelearning,Z0FBQUFBQm0yeGJ3eDlJWWZaRk9GR2RnRlNES0VvZm9rbFFHSmJCUnJrRVdvYlhYa3ktODlmSnJnbEt1bzhTZzd6Y3NfSjZZMlJNSEx0OGtKa0FKZW5kejZRTWNFM0RwTy1BOGwtUjBsb1RoazB3WG1qZjF1QVE9
"Humans do reasoning and yet are not a general solution to programming problems either.

I think it is fair to say that LLMs have *some* reasoning capabilities and a bounded intelligence, but I find it hard to argue nowadays that they have zero reasoning ability.",r/machinelearning,Z0FBQUFBQm0yeGJ3eTZtZXdnbWtaTHJsOXd6ME9hN0NyTHhoMUlGUFB0VXNyUUZFdEo4RDlzc1EwdjNRN3VCSzA2OEM4Uy0tOERXR2ExUV9tSTdCczBLTUw3QVQ2YUQxMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3Ml9GUUJaZkdKMGhtNFc3WTRVc3BJWEtIbTdDd2dqSjQyWVd0eV9LODUxc3QxYVJ6UkhKT2pOTjMtenRvMVA5OWt0bWxDVjBOenFZSFVxWjlUR0sxYVE9PQ==
"* vram: for inference you can run the model with 40GB vram. For training we maximized the usage of H100's 80GB vram by maximizing the batch size.
* tricks: smooth lr transitions (1 cycle learning rate schedule as described in the report)
* lora: yes, we are playing with LORA right now. It is promising and pixart alpha (where Open-Sora is based on) already supports LORA: [https://github.com/PixArt-alpha/PixArt-sigma/blob/815fcc07ef4352c078c079d8c483fed7a9ffc016/train\\_scripts/train\\_pixart\\_lora\\_hf.py#L505](https://github.com/PixArt-alpha/PixArt-sigma/blob/815fcc07ef4352c078c079d8c483fed7a9ffc016/train_scripts/train_pixart_lora_hf.py#L505)",r/machinelearning,Z0FBQUFBQm0yeGJ3VlRvQnJJWnVkalJLcDd3MUd5TFl3bFdnSFZWcU5pSHJjdGZhc0hhM09xdUpqSG1PMUE5YUNLMGJ1dHR0LU1LcVJzUmxQelNLS2QzNkctVTk1VWowYXc9PQ==
Llama 3 hands down. I use AwanLLM to test them out pretty easily,r/machinelearning,Z0FBQUFBQm0yeGJ3RDJhdnJSOGpnLUtUaDBkdUV2MUlqMFRkWjhqblJMWE05bGwzQ3FuZno2QVBwcXBXTDRsS1lsUnZ6MzdKcmxoR2NzT3ZfQzZRbEZFbVE4SEpYV045bWlsT3M3S2FRV3F2b2hvb3Q0Tm04MUE9
"That's pretty dogmatic thinking. Shouldn't it depend on the task?

I'm working on a product that will replace a human who gets paid $60K per year and needs their work double-checked by a knowledge worker with a robot that will charge $100 per month and need their work double-checked by a knowledge worker.

Based on the demand, I am quite confident that this will be a million dollar product, because our pre-AI user base is already clamoring for it. If I took your dogmatic approach I'd leave all of that money to competitors.",r/machinelearning,Z0FBQUFBQm0yeGJ3VFJuMGt2bE0zcXVVbUFvRlhVUzdBQWN0Nm5qeVdqelZtbHJkNjFIanl4bEhmQ1o2YURMR0FRM1E1NXR0cUhKZXkxeHdLUW9UZnZMbUxpSUxCX0xBRlRxV3pyZ0JiRzRDTnpjVTdEcnA0Sms9
"> Notable exceptions are Claude 3 Opus and GPT-4 that occasionally manage **to provide correct responses backed up with correct reasoning** as evident in structured step by step explanations those models deliver together with solution.

Oh.   It seems I celebrated too soon. 

The authors'  claims of a ""Complete Reasoning Breakdown""  is contradicted by their own introduction section.",r/machinelearning,Z0FBQUFBQm0yeGJ3OTNHNHVUZk1xM3FwUkpic19XcENBTEdOdWJ5cFpJT21XRjdfNkMzU3lkNU1oTWppSDVlTUFvTnhtXzBIRzh1bkZuQkNWcDVOQkI2ekMzeUkxNWNNSHc9PQ==
Please also see my comment in this thread.,r/machinelearning,Z0FBQUFBQm0yeGJ3MVN3RjI5Qzh6N2h6eF9xWUdBQUFhNjNjb2xHVnhtakN3YjdRdHc1UEdpdTJTQ05ObHNXeEk2WmdzNTA4RFBxZjJmX21WRHI3bGtvV3Z1T0J4elNrNlE9PQ==
Could it be simpler: Publish or die makes some odd works?,r/machinelearning,Z0FBQUFBQm0yeGJ3b25oT1V2N0REelY4VVl1aUdEVGFqRi0yR0pXX19rcVdaaUwybHhQSVVZbWc2bGhSLVlvakZjYllxSkhJWlA0YjVxNUFFdzA3eTk4dHRadHVfTDQ4T3c9PQ==
"The paper is slightly different---it takes a QR decomposition of the original large dense pretrained matrix.  It appears to subtract off the low rank approx and call that the  new fixed W and then use those QR's as the perturbations to be adapted.

So the perturbation does not start at size zero, but it starts out as the complement of what you took off.

There is a hyperparameter 's' mentioned in the paper in places and then runs with no discussion of its values or optimization of it. :(",r/machinelearning,Z0FBQUFBQm0yeGJ3aXhGXzBBb3JNRDVaRlBKUEZYVG92b093dmZXaWpjaEVaY3I3Zl9Na3JCR055d2pwUGtVTC1DUHdVdlpicWdEMUZEclZwNWJwZkZ0ZjVESE5LY3Q3bnc9PQ==
"You're correct, the author makes the AB initialization with some non trivial size so that W_init + AB_perturbation = W_pretrained, updating the base fixed matrix W_init from the pretrained one and using that in the forward pass.

It's clever.  The difference is that the free parameter matrix AB starts out not at zero but already pointing in the direction of the most important subspaces of W, so individual updates to components of A or B from SGD can immediately have a significant effect on the transformation.   If you initialize A or B to zero then perturbations of whichever one is not zero start out not having any effect until the other one gets to nonzero size which can take a number of steps.  So standard 0 init has a wake-up deficiency and learning starts too slowly.

So to my conception, the paper's algorithm performs as if the primary training were interrupted at some point, and then learning continues only in the dominant subspaces with a new text corpus.  More like changing primary training midstream than directly learning a perturbation.",r/machinelearning,Z0FBQUFBQm0yeGJ3ZGJMTmNnaUZHZW40VWM2UUE4SHIzMTJBYUFNTFlPeGVGczBlb2FUYml1SUNmcGtsdWRTVmV4UDNxaUxmQkhRT283dl9sTEJMNklRVndWUUdIeGVlcGc9PQ==
"It's my understanding that orthogonal initialization creates a well conditioned optimization problem, and helps stabilize the gradients at the start of training. I would be interested in seeing more theory about what effects this has later on in training. Also the dataset changes the optimization problem, so maybe that should affect which initialization we should choose? Could be worth playing around with if it hasn't been looked into already, not too familiar with NN initialization research.",r/machinelearning,Z0FBQUFBQm0yeGJ3N1Nza2pZM1lScnRMekl4bFQ0c1dUZHM2ZHBVMHlyZkRBUWQ3WFJUUWtITlhXUzhlUThkQ3AxLWhrbEE1MHFTZ3ZJY1M5Z3BCb0ctR3ItalI3Y2dTMGRkUHRXVzhYLXNvcUJQSjJQbU1OZnM9
It sounds like you’re cashing in on hype. Good for you. Hopefully it doesn’t come crashing down like Rabbit when people realize it’s unreliable.,r/machinelearning,Z0FBQUFBQm0yeGJ3MnJrTTVobENiY3hrUXgwQTVHWFowcDNpTWxsUllTYzU4aS1fYk5fSzc4VnVmSXZ0SzNZbjJBOVUwejFndG1DN1ZBaGZfMTNLVUlFM1pSY0RLdXVOT1E9PQ==
"Just reading this two years later but also found several stolen segments in a library from Tsinghua I had to use. They even copied the comments. Ironically, I also studied at THU at this time and I am absolutely not surprised about this behavior.",r/machinelearning,Z0FBQUFBQm0yeGJ3M3NQUVlsaVlFazVhTkpzbkhpSXlMR2djYnVnOUtVb2ZPTzN3eWVrVC1pX0xmaFJrSnBmdzlKNnBIT2dkdWg1X005QzN6S1UxSXBtRzJDNWQtb3BkdW83VXBUaHQzWjgtS2N6dXZFWFdBbUE9
Of course you did not keep us updated just like your libraries,r/machinelearning,Z0FBQUFBQm0yeGJ3VlVWSWRQTjZwWi10OUZvcG1SREU0MkpUQS01ajFtRjBIdWozZG5TSEEzUE52MlNTY0FlNENqVWQtQ0R0cGozOS1WcHFMSm9ZMm5mYWh5VVpPUjBsVHhuV29IdWs0NVFrQUhmbHowWEplUXM9
"No, I'm building a product that people love.

I know it won't come crashing down for three reasons:

1. It's my job to measure unreliability and there's very little of it.

2. It's a booming product category that is taking off virally among its user base. They try it, it works, they love it. There are many podcasts about how giant corporations are shocked by how much their users love this product category. If they've tested it for months and they love it, why would they suddenly discover a problem next year?

3. As I said, they are already accustomed to checking the output of the people who did the work in the past. The difference is that in our case they check the output 5 minutes after the request rather than 24 hours later. And at a cost of pennies rather than dollars.

That's why they love it.",r/machinelearning,Z0FBQUFBQm0yeGJ3SW5HX2JEdnVubGk5XzZvbDVHRVFDU3VDZUlQWXJ0aFVDZTJLclAzdWJkaWtmc00tbUxmRlI3aFIwdVo0WDF4UFJPQmJCQjBpM3NZVHpXeHVrcXp0V3RWLXNZVDBYUUJkQk5xYlY5akc4a0U9
"I am looking to train a model that will take in text for a patent and be able to output the ids of patents that are most likely to be prior art for that idea. There is a ton of training data for this because every patent has to cite prior art, but I am looking for advice on what type of model I would use to do this since there are so many (100 million+) patents that a patent could potentially reference as prior art. How can the model be able to efficiently determine which patents are most relevant? I was considering training a custom embeddings model but am not sure how to go about this.",r/machinelearning,Z0FBQUFBQm0yeGJ3cVowSEE5Um1HdjRQc2VISzN4SkN0eTlhNE5ldGU5aFJTRHNzUlRqb0x1cjIyUEU3bTBJTDZ2Unc4eE9ZTUJOX2tneWd5Rm0zTllnQTRkVUNVWmZfY05FOWNzYjJ6elg1NjhZSXo1V0N6Nk09
If you want to train a whole AI from scratch (assuming you have a gpu) git clone nanoGPT (https://github.com/karpathy/nanoGPT) and install what you need BUT make sure to install pytorch from the website for your hardware so you can use its full power like on a nvidia GPU you can make it really good and way nicer and better output then find the entire dataset you want and it will take a long time like a year to get all the data you want then finetine the config for training your AI from scratch it would be hard but you would get meh somewhat crappy results so you run it on a cloud service from google to run all of that then done you have a decent ish result.,r/machinelearning,Z0FBQUFBQm0yeGJ3bzRtUFNSZXFxMkdfWlpuOXNCRVRzaGU0ZjBYc1FjSVltSzdZdWF0MXpQMl9ENHp5cERSeUIwZUNyWkJaclktY1p5TlF4eVJNcUNFWGN3dkJ4X3M3VzdhNXZQZk1naU0yVFJyZ05YSVpxRk09
"That's surely part of it, but none the less I think the topic is revealing of people's assumptions about the world. Analyzing the reasoning capabilities of LLMs has the same vibes as trying to characterize the luminiferous aether in the year 1900.",r/machinelearning,Z0FBQUFBQm0yeGJ3MXlDYzFBWFgxSmRPVXV3YVlfUU1NeUE5NEh3UkxLbEE4cV9lT2VUQUFUeFpVM1huOG9faG9oYTQ5V1I0SGZCZmdxMlZnSndnSU9Venhsd1B3MFVFYXc9PQ==
Why were you downvoted AI is censored they stop it from doing stuff that might infringe on copyright like give you the lyrics to a song.,r/machinelearning,Z0FBQUFBQm0yeGJ3UWwybF96a1B4bk1ldVgxckZhY0pBVWQ0aEkzaXZoOC1INC1jVFhsMjhlRnZxejlsMktFaXEwMDhRclhEWGFha2sxRVRLTmJFVTl4Y1lrY3V3S2lsNHBURFFXcFVIeXBlRHB5dnlRWXlSMlU9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ3c3ZHM2VESmF2V2t1UzRZMjlBb1JSQVNxa1JCeW45SEtWZnpGMEplX3hTMzE1c29oMXB0QzA2c2RpdmV4QTJIZnBIZGhoWWNlQl9zRGNmZEtEU282Nk5RSjgyeS1aMy1jOHBuXzNTVWl2cmc9
"Ugh. Matlabs ML code is .. painful to work with. Its great when you start to move into it, but it just has not kept up. I say that, having written more matlab code for ML than anyone I know, to be clear. Was my primary job for 3 years.",r/machinelearning,Z0FBQUFBQm0yeGJ3YUo0N2QwX3p3dm1ESHdUeEFmX1hkM3U3Z0FWRl8zSmhaOFVWRHVGcmhENl8tRjdTNzVBakdZanF1ZE5zNFhPUGI4Q3ZrOHBjVE43QWxIYWt6cFFJREE9PQ==
"Right. It's not a ""complete reasoning breakdown"", it's a case where text prediction fails to resemble correct reasoning. 

That said, it's quite possible that a text prediction system could form part of a reasoning system. But there'd have to be other components as well.",r/machinelearning,Z0FBQUFBQm0yeGJ3NERFaGVEd19VeldLODVHc0xfUFM4VXFiWTE3MHFndUZIc0FuWDdJQjB3WE9Pb2ZnWHdHVm1faFBwa1NvbWJkUm0zT1ZnUVdqMXpjMEpGNlJwLXVxRUE9PQ==
"Humans are also unreliable. One of the functions of a corporation is to build functioning systems from unreliable components. AI fits right in.

It's not ""cashing in on hype"" if companies are actually making big savings or increasing productivity. That's what's happening on the ground right now. It sounds like You're just not in a position to see it.",r/machinelearning,Z0FBQUFBQm0yeGJ3T1hSNFdENVh5M09BdEdaY0J1cVpjOHBlZk5kZUhsX0xDOEt1a2VTdVJrRHk4blpiVEJ2SEw2WWh4SzZKcXRUa3I0Ry1KVHk1VXJQWDdtNnpxZXpHNlE9PQ==
Quants love C++ ML guys.,r/machinelearning,Z0FBQUFBQm0yeGJ3dEViaDFwaGV1WEJscFg4NldZQUl1djV1UmpobmJwTGNQTGdBdGlPMi00ZzdVSU9qc1VoUUpEZEsyMmowZVptNjA3OU56MHM0SmVTa18wY0htOWNEXzBoS2hhcnBYRzF3Y0JqeXF1c3JfQ1k9
"Some hints from chatGPT:

# Hints

1. **t-SNE Visualization**: Use t-SNE to visualize the data and identify natural clusters.
2. **Clustering**: Apply clustering algorithms like K-means to divide the data into groups.
3. **Regression Analysis**: Use regression models on each data group to reconstruct the functions.",r/machinelearning,Z0FBQUFBQm0yeGJ3UUg0RVVIVV92WlQycFFhVE5Sc09nZ0Q4bEJMdHJrSjlUYkk3bVMtaGtPOURObHJUZTBkcjhhNkIya0tGTXFVZzZrU1BnMUVsNENUNTZKSTBJbHAxZkdqYUp3MUhRMWRpYy1ab05IUmlFSjA9
"Ironically,  researchers found out that asking the LLM to answer ""as if you were a Star Trek character""  made the answers more accurate.",r/machinelearning,Z0FBQUFBQm0yeGJ3YWhHOVFmbTk5T0ZHMnNjYlN0RXhsSGRXalNlVnlaZ09fRENZVWZsTXN5d3pDZVNUTDRRYTkyaVBiM1hjNG03eGNaaU42aEYybXBha1BBbDFST3BXSEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3U0I1azhVSXRsd2xqMHk4YTdVSXVuRFRHVnVDclRGZDJZeHdWY1V5cnpVT3hlT2xIX0thanJSbjJERE1laUN6bXd1b2hiUl9GMXNpS0lFNkF4TDlTNGc9PQ==
"honestly, i'd be okay if it got a typical wrong answer; then you have a simple failure to account for one person, but a general comprehension of the question",r/machinelearning,Z0FBQUFBQm0yeGJ3VzNpaDBpTlpMU01tbEROei1VaTh0SGY5TkdXVG4tWXFvaU5YeTBqUG1mbWZqQW9zQ0VOMEc5VGdLLXFkSzI5NmhqZ0NMdGh1WXlLTi1ZSzlCSEgya0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3bzlUdUdGUG5DaDA3dEFqTDJCckVOVFY2M2F6cml4c2hUeGNDamRZNFFhUC03cV9KRjkzS0pGWHRjeUNxNXhHS1hkUGFLVWFETmkydmRta1g2dXZxcXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3QlRwQ3dRcnFHRW50Qk1PRXQtVWJVODZyZWF0cmpwUWRnZHRPSHN2TDhCa0NtbjVIblN5MDFXa0VSMlJndm9HTE1qWXpDQjB2VTdmczQ2RUFON196Z1E9PQ==
"maybe i didn't full grasp what openai did, but anthropic's mechanistic interpretability seemed to provide a lot more insight into what was going on in their model",r/machinelearning,Z0FBQUFBQm0yeGJ3c0s3UG9yVFU4SW5zQTNqWnJ2dmpxTWVnUE1zYm1VZl9VLTRvNVU1VmhjNWlEQU43SldLRXgzdUpEWnd1OWdBcFA5eXlDTkRROUZrNmpRbmJXd3VSSWc9PQ==
so did you ever start one or,r/machinelearning,Z0FBQUFBQm0yeGJ3SmhSWG5QVVRCRGctblZHTndvSlU2Q2RoSV9zSE5WeXpmSjhTNWlZeVhNQUNfVHpEeWhkdWFtRXpLQkZqaEV1T0ctYWE3X0NZVG95U2dqbXZhYkxkb3c9PQ==
Okay,r/machinelearning,Z0FBQUFBQm0yeGJ3aHk5bHV0WENoTjhWRXJGQWdMRXk0cGVySDc4dGxzVG12N2RVZnRiNEo3QnFsU0pxZ3VIXzcyMFUzeFk1YXNzUkdNRmZSYUtJQVFMemJ6YkVWN3g5dmc9PQ==
Not sure about this outside COLT/ALT. The load for me has always been at least 6 for a while now.,r/machinelearning,Z0FBQUFBQm0yeGJ3aElIU0RLS2NQTmlrbjBDN2I2VlZyYWM4TDZfWTdBTzk1d2hDYkRfRndEbE43bFctWGtMVTgyekFxSm5NQndEUXpZR2NrWXhnejVzbDctcHNRUThoS3c9PQ==
"Hi u/hcarlens, I've never been to an academic conference so I don't yet understand the purpose of the conference challenges. Do conference paper authors host those just to draw attention to their new model/framework/research task? Or do the conferences themselves host them? Can anyone participate in those or just people attending the relevant conference? Seeing a lot of those on evalAI / codaLab and idgi! help!",r/machinelearning,Z0FBQUFBQm0yeGJ3c29DUUlzZU1DLWtiSnFaQktMOTZWeGN2VnFPbTZpOG1yeVVvVWlWaTNNUGw4U3Zldjc0c0ZrU0w5RWREMENHaElqN2oxRjVGRW03RjI2OWFkSUd2clE9PQ==
".... why?

> I am trying to make it not output junk

Then don't train it on junk?",r/machinelearning,Z0FBQUFBQm0yeGJ3bE1lQ1U4b3l1Nm1DekZMc3RBS1Z1VzlSbDU1aFd4bUU3QllJSTZ6NFZxYVZGaldNODRjdnlxWmkwMkVmNU0yelVJdHE5blhjTk9uZmFZbGVmNnJCVmc9PQ==
"Yeah I am trying to update the filtering to remove Junk like images which will be empty and other stuff, for why, I'm bored",r/machinelearning,Z0FBQUFBQm0yeGJ3d2FjLU8yVlJKdTAwbVRhazdJOU1iUEl2Zlhzd2Ytc3AwamJsZHZfeUQ3VjNRT3JJRGtMR3Y1VllFN1VxeE1BUFEydS1QZnV0eWVGQ190OElaRHJPQjhONmI4c1dTSUN5ZzRZWFFDdUpBdnc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ3UUpnSVBjby1ManlmdERPWC1QRjFsZWRETnI4aG54d2Zwd05xN1RRSjEtNjkxRmMxdzZaNW9nTFZnNVZtRjNLbENPY21QLVludnlVcXMxaWREejRrbXc9PQ==
"Thank you for the clarification. Applying data augmentations directly during training makes a lot of sense and seems very efficient. I appreciate the resource link for PyTorch as well.

Just to confirm, if we apply random rotations during training, we don't need to manually rotate and save each image beforehand, correct? Also, are there other common augmentations we should consider besides rotation?",r/machinelearning,Z0FBQUFBQm0yeGJ3QW1yZUlNSEMxcG9jSGw1LXRqTzVCYnI3aGpVcHhMcEtxbHhsNzJHNjRON3J6dGNNT3JPaWluaXVkWmF4NFN4V3ItOS1PYUNDeXV5LWdueFUxMXJ0SHc9PQ==
"Yes that's right, you just need to apply random rotations during training. 


You might benefit from other augmentations too but it really depends on your use case. You can see many of the augmentations that people use in the first link i posted.",r/machinelearning,Z0FBQUFBQm0yeGJ4a1h6T0RQdGdUQjVFVS1JX3BKdTdONEhMY01JX2RZVFRya3M0WkNQaElhTUlxc3M5UEJTOUVXaWNSYXNQT2FuRFFfdUdCZ2I4T3VsOXp5VG8ycndBX2c9PQ==
"I would like to share a solution based on **Model Performance Analysis**:

The idea is the prediction that training models on mixed data will cause them to fail to generalize to the structure underlying these data. Thus, I divided each dataset to a training set and a validation set. Next, I trained this model on training sets:

    class NNet(nn.Module):
        def __init__(self):
            super(NNet, self).__init__()
            self.fc1 = nn.Linear(28, 64)
            self.bn1 = nn.Dropout(.25)
            self.fc2 = nn.Linear(64, 512)
            self.bn2 = nn.Dropout(.25)
            self.fc3 = nn.Linear(512, 512)
            self.bn3 = nn.BatchNorm1d(512)
            self.fc4 = nn.Linear(512, 32)
            self.bn4 = nn.BatchNorm1d(32)
            self.out = nn.Linear(32, 1)
    
        def forward(self, x):
            y = torch.tanh(self.bn1(self.fc1(x)))
            y = torch.tanh(self.bn2(self.fc2(y)))
            y = torch.tanh(self.bn3(self.fc3(y)))
            y = torch.tanh(self.bn4(self.fc4(y)))
            y = self.out(y)
            return y

Then, I analyzed the performance of the model on each dataset via its validation loss on the validation set.

|Index of Dataset|Dev Loss|
|:-|:-|
|0|0.251|
|1|0.378|
|2|0.242|
|3|0.203|
|4|8.403|
|5|7.520|
|6|0.361|
|7|7.940|
|8|0.231|
|9|0.219|
|10|8.061|
|11|8.021|

After choosing the threshold is 4, I got this prediction for the original value of list `numbers_of_functions`:

    [1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2]

Please check this notebook for more details: https://www.kaggle.com/code/iamsmmhiurmminusone/puzzle-1-solution.

Can you show me your results, are they similar to mine? If you don't have an idea yet, try applying this solution to both the 2nd and 3rd puzzles, looking forward to receiving insights from you.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZjhNMlV4ckJvdHk0SUdPX3gwRmJDd3ZkWnpOTlNGWGJZOG5ITHJiemNBSllyVXpMdlVmbnpKNjF4TGFNZ0FHbUVxcVdZdWVhbjN4ZWNGek5nYjhqMnZqcnNLdklLMmxHUEctTnRoLVZ5TGs9
"Yes. That's a good question, it depends on which domain you're coming from and which formalism you think is best for capturing human behavior. The argument here (in both works) is mostly about the objective, which seems to be a very good one independent of the formalism.   
Re: larger problems - the approach is still limited to small scales because the optimization is hard.",r/machinelearning,Z0FBQUFBQm0yeGJ4d0xQYzRMblNpN3ZVY0VTdWlTRHhoRDFfWURRMk5pc255SFZETkxUMjJDSG9NWHo5RlpUUmpOcjZHSWdPZkc2RlB3bkZZZ1BfMlJnRFRCeG10V3dDbHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4enN1eE9uQU1HYi05YlFHUGE0dG5ZdHJLeXV2dktaMzQ3WWNvRWRvYTBiTW5Ga1pMTTBRd0RwOW5jcFg3QXp4TENCNjRJV1FYZWJkT1VsaUJkbElKQWc9PQ==
"I would have thought *which* Star Trek character would matter. ""Cap'n, she canna take any more! She's going ta blow!""",r/machinelearning,Z0FBQUFBQm0yeGJ4R0xRbUFQeHRKMGxoVl9qbGNOMkl4ZUpCRjE0TkoyYXdFdHVZUE9OdXI0cVNTLWJyN1R6Q1BkLWN6M3Vkbk1ybVF4YUItY0MyYmp2M1p6TTJIcmljS3c9PQ==
"Repeating the argument does not provide clarity on- nor answer the question to- how to actually find people. Unless you believe that it is not worth finding people in the first place. 

To me, accepting students instead of professionals from the industry does not come across as elitism, but rather (unintended?) ineptitude.

(Not my intent to be snide, just curious to hear your opinion)",r/machinelearning,Z0FBQUFBQm0yeGJ4OXpjUGMtQ2o3UFQtbHFwLU9MaHFTblM5UnNveUZMYnBKMkdFUnFUMDRTRVdhNTctYzdyNUtRU05tQnY1czZQSm1iaVZiMjZUcHlKRDVlSmp5eUhNUXc9PQ==
"> Embarrassingly, the first thing that popped into my head was ""this is easy, her brothers also would have M sisters!""

That was probably just the first output from your brain's text prediction model, but you're a multi-modal system and were able to correct.",r/machinelearning,Z0FBQUFBQm0yeGJ4UVh1OHVRVjFkdWx0aDZIeEgyWkdZaFVDWVN4OEtqZUN4WUc3TDk2UlNacTBNVE5aVjVfNWVJZnBQdzQ0WTdlV1B6dU1lU1J3c19FSHlZQ3dvVTZFZXc9PQ==
Interesting question. Have you considered the impact of model architecture on these scaling laws?,r/machinelearning,Z0FBQUFBQm0yeGJ4NkFWYzhMT0pKZkNqVnM3REVRdkVXRC1ZMktEWV90Y3lqT1pDNXR2UW1OMU9fdEk0WVJwdXQ1OFFuaXJ4OURJdzVLWmFvN2RmM2YyVnctRmRxa1dsYlE9PQ==
That is the paper. It says that things are getting saturated.,r/machinelearning,Z0FBQUFBQm0yeGJ4eGZVYUlFU0tCV2tEVjRZTUM0STRGTjN5R0ZJb0NjaUNrTVNBNW5kbHRFUWhEVFhFVDhVZjVuUTd0c3I4WEEwZGFIMlRtR3VFa1NqOV9sRDU0OUI2aWpILUxTcTZ4TFBQM25nRExRXzdwVTQ9
"I really don't get why this is such a big problem. If they asked every author to review four times the paper they submit (which is about the work load the author generates), the problem would be solved.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZnJuVXQwTWMtQW5zaXdRSzlRa3RaX1pIUlpaVExzM0lHbzFUTVgyUThWeDZrTEg2WGVYU0Mta1p3ZFIta3lTc1J0ZWdfLUhFTDBpUDVOUWQ2LWEzZTJ4SXpzdy04WndlRHRmOEZ6NkpocWs9
"I pay no attention to the benchmarks. None of them. The only metric that matters to me is…does it do what I need it to do.

For me, 4o is revelation-level good. Gemini I flat out don’t trust. Anything on HuggingFace I don’t use at all, have yet to see anything good enough on there…but I do appreciate all the experimentation people are doing there.

Also…if you’re going to complain about“man babies” maybe refrain from calling people stupid…just a suggestion…",r/machinelearning,Z0FBQUFBQm0yeGJ4U2YzRks3ci03MXU4bGxYSXZwcXJMb1VFbUpLX05wdDVRT3ZQNjhEUnFIN3g1MkZMbGlwQUxnVjNVWnBZSGJBMDlKLXF6TWUyejZQUnk5UnpnaUtMaUE9PQ==
"60-40 is 50% better.

That’s a huge margin.",r/machinelearning,Z0FBQUFBQm0yeGJ4cGI0TjItUUR2RzVmU0I1VkRUMFlyQ3BZTFBzR0tEc1RVWmkzc3JxSnJycFV5czYwSXU0RG0wSC13ajJGamlDa251OGpid0ZpSjgxTzJvbHduRWZFQlE9PQ==
"> Analyzing the reasoning capabilities of LLMs has the same vibes as trying to characterize the luminiferous aether in the year 1900.

That's a funny comparison. But I think there's potential value in it as a pathway to better understandings of relationships between language and reasoning. We analyze the reasoning capabilities of a grey parrot and get insights (including evidence that reasoning and language are not equivalent). I don't see why LLMs would be different.",r/machinelearning,Z0FBQUFBQm0yeGJ4aGlOT24wWmo3QzFfMTg1X3MycGtWVFA2S0dPdDczZktBUnM3RzR3WEJiTXhpcEZEQWhXZzBNT2dKckhyZmUyQWFXYmRHeUptczR0TDJRNVlNODBZLUE9PQ==
"try neuronpedia.org, honestly pretty fun lol",r/machinelearning,Z0FBQUFBQm0yeGJ4TVQ1U2dQSXRpSmhObmVGZWFsN1ZoVDJfUXlMdW5vd1h3blJna0liV1FlcjI5N2tMUzR1bmtKZlBmUENoWVp3dk96bEMzU19Oa2ExdWJOR2g2ZnpicHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZXNsZkNxcVhNQkFFMGhORllUMC0xekJtTjB5LUJrdVA4UkVxQUFBRFVwT1FZWjFjZE5Gd054YmNsUndaYkF5anRqQTN0QWRRWl9CbmtSZGVFb2tEaUE9PQ==
"I don't see how win rates meaningfully translate to ""percent better"" .. let alone what ""percent better"" even means.",r/machinelearning,Z0FBQUFBQm0yeGJ4eTl5NXRxenZZeU50OEp3NUNHNzIyTTRST1YwTkxWSjZjOFRNeWxhZDJzVE5wNHlZNDdKRll6czJJdVowQ0VaOXF1Znc1UVdabnZraU1Hd3UtR0FKMWc9PQ==
"Try to convert the code to a higher version.

Some specific commands are available to convert
Select the file and you can convert(its a command) run it on terminal",r/machinelearning,Z0FBQUFBQm0yeGJ4ZGJvMzh1XzEwLVFwMk5CVm5TNHZkajYwQ3lxSDhfcXEtcGNYLURzWUVybFZUazF5RUFEM25UcEpaV1FlYXhvRlpaaWYwSDNKQ1Jod1J3d0JaS0Nzdnc9PQ==
How would this look in practice?,r/machinelearning,Z0FBQUFBQm0yeGJ4cVNtTl9VMW9sMmlOdDR0R3V6UXdXX1V1RjBVU09ObF92NUFQVnk1ZG9yNzllcXh6Zlo3b252djdCSGRLVXNHdmI2aFdnaFRaUmUyREhnVGlwWFJWdjFwWUJneTJfalF0R2VEQVlCejVvXzQ9
"Yeah my 2 cents would be: 
Download model -> vLLM serving -> docker -> kubernetes which can scale. 

To fit in to larger processes, you could pass in any additional context (e.g. from RAG processes) to the prompt. 

That would work for low latency requirements (excluding the cold start). 

But there are other scenarios, e.g. batch inference for BI, ran daily. Imagine a database updated daily with customer feedback and we wanted some kind of LLM-based action to be taken for each row (you name it: summary, NER, translation etc). This could be used for dashboards, executive summaries etc. 

When latency isn’t an issue, and depending on the model size, your inference job could just read in the model, perform the inference, and write the results back to the DB",r/machinelearning,Z0FBQUFBQm0yeGJ4VURjbUh2N1NVT2pPMDl6WWs3cXdrVW1vczVKcEtJMXlMLXNhQy1fMEJwQm4yaFdXdUItdkFZalBpZlZjUWZ0M1V5ekxTWUFTVm5MeE9DMTRnZlZSNW8tWS1la3ZSRC1hLXZRU0hQV1VoVVE9
"Yes, I'm a big proponent of MDL but I still didn't expect it to work so well!

Could you reduce the search space by removing symmetries in the parameters? For example, permuting the hidden units doesn't change the function, or tanh(-x) = -tanh(x), etc.",r/machinelearning,Z0FBQUFBQm0yeGJ4dXJoS0h0Z3NYR1dRTHR2djFZaUx5SXNYUTlrRWxNQ0xjSE4yWWZsZzEtdlEwQ0t5UFpxd1N2MDh6M2xzeWRWUEtxT3JpTHV1b21vMVFsYXRzVmdPVlE9PQ==
"There's still more room for improvement. A paper for Buffer Of Thoughts came out that continues to improve LLMs. [https://arxiv.org/pdf/2406.04271](https://arxiv.org/pdf/2406.04271)

>Specifically, we design meta-buffer, a lightweight library housing a series of universal high-level thoughts (thought-template), which are distilled from different problem-solving processes and can be shared across tasks. Then, for each problem, we retrieve a relevant thought template and instantiate it with specific reasoning structure for efficient thought-augmented reasoning. In order to guarantee the scalability and stability of our BoT, we further propose buffer-manager to dynamically update the meta-buffer, which effectively enhances the capacity of meta-buffer as more tasks are solved.

Page 7 shows benchmarks. Some gains are modest, others are big. They also claim it's 12% the cost of multi-query methods of prompting.",r/machinelearning,Z0FBQUFBQm0yeGJ4b3lyN3I5U1E5Y0JPTUg3bFBVV2ZWZ3pUVUloeGxadkUwYmtMQ1Y3NnpvbXdrdzh2QkJwWldReGp2TEZXVmFXTFdPbW1wMlNhWE94THcxUVhlQTk2RUE9PQ==
"If I’m playing against you and win 60% of the time, I’m winning 50% more than you.

Seems like a fairly practical definition of “better”…

You specifically called out “win rate”….",r/machinelearning,Z0FBQUFBQm0yeGJ4THdRSFJlMWZsbGttSGxvZnk1aFdULVZBeUZZVjR0UjRVbUFNNVZGRDRDbU13WGNMbktuUXJjTXBDMlA5WFJzLVAwaDNQdVBPUlJiU2MwUWZJeW80d3c9PQ==
"Don't think anyone uses ""better"" this way.  In particular, it would imply that if you can beat me in every game you are infinitely better than me... even though obviously there's people that might still be better than you.

Simple example: Your SAT score range is uniform between \\[1400, 1450\\] and mine is \\[1360, 1410\\].    I have a 2% chance of beating you on a given test, but I don't think anyone would say you are 49x better at me on the SAT.",r/machinelearning,Z0FBQUFBQm0yeGJ4WkllYlpVdmdJbTFyZTdFNE5QNVZwR01JM01JOG93OUgzT0I5LUJrX3lVTGZORlFoWDc4TVdTWVRXQzNxdjVCQjJodm9xaTJDcDc2M3pfbW9yMUJ3cnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4WmpFc016dGdhM1VpWW4wYmVjSFU5TlVIRWVEaURWVFdmTkhQVXZ6ZjJuLUZXSFQtWTFMQ1VFdjcxeDFOTzEzcTA1dm81ZTA2NlVvUUItNUJfclhhYVE9PQ==
"Thanks for putting it like this, I appreciate it",r/machinelearning,Z0FBQUFBQm0yeGJ4STJYTWstb0V6N2xxTEZ2cHRXckhXVHFxbFMzRTlTRDNldGFxZzZEZE9tQkpqVThETkdTQU8tZktsYXpJUmRCTTRIQmZSS1l0OEFJa09MOEZoeXdKcWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4Y2lXem9jbFdub2xhZVFhMXJjcGRZeEM4MnpXVDBBZWxpMjNWSHlla1YzTGUxQjJ2VjlhbGltRS1WeV92bGtTTU4wRC1BdWlzSmZTbXZTazRLa0RxbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4WlYzTVl1d1d3ZFFmUnpQbWtMUTkzZWptRnkzU1NhUnlTWjFkRDhpVE5HNVBGcENIUllYTGJENUZmSVJxYmZSUWk2czhIQ2w3NHVlZkYtTVdFakprYXc9PQ==
"FAISS is not a production grade database. Go with anything else like Milvus, Qdrant, Weaviate or even Elasticsearch, PGVector.",r/machinelearning,Z0FBQUFBQm0yeGJ4LUE2TTM5S1JqRWdCdlRhYmhpN0t4RnZDVVNpRGhnVlpYbjVCc2czUXdtR1lOaVNtWkl2Q3dTT3dkTTdLZ0ZpTzAtMVZHVEpBY2pVd1dwejdFY3d3Y1E9PQ==
"Yeah, this is something that bothers me a lot in the various AI debates I end up in. People have unrealistically demanding standards for AI, insisting that if it's not *good* at reasoning then it can't possibly be reasoning *at all*.

Like, the Wright Flyer was a really crappy airplane that could barely get off the ground. But it *flew*. It proved the concept.

I think science fiction is to blame, the general public has been conditioned to expect that ""AI"" must be some kind of hyper-rational logic engine. In reality we're building toddlers at this point.",r/machinelearning,Z0FBQUFBQm0yeGJ4MUd1VXZLTHNCTDhhcWtZcjhuVkZsOWpGZWtKNkRMcHE1ZzF5MU9nRWNsYVBPelhCUWY1N1pua21YOFhuM0E5dDFBU3VVNGxzbm4wN2kzOE14LUg4SEE9PQ==
"We’re both applying to schools that have an SAT cutoff at 1400.

Yeah…I’m 49x better in that scenario.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZExhNnpWVkgyaGRfWHA4a2V1NkJFaUlwaDdadzJzeTUwSmJnUnpDOE5KekFOc0tSLTdOalJNTmIxRS1YekRrTTA0MU9rZUFhVW03Ukd1azNrbnEtMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4MHRfcThzRHJQakw0QXh2VFRkN0oyd0N3VWZCNlJVX0tDUmVaWGVfT1h0bzJULVBEWHNKeUc1eEhrTzhIb2ZGNzlaTE9lWDFmVEpKU01ub05FdVBWbXc9PQ==
"Some conferences like KDD (my impression) tend to have more presenters from industry labs than others. NeurIPS for example is basically all academia and the flagship big tech research labs (e.g DeepMind, FAIR, GB, etc)",r/machinelearning,Z0FBQUFBQm0yeGJ4cmZZMlMwTVN3VXNpd05RaE4wMDY2YzJLRmMwYmgzeDJYVjJtLUE3elcxeHRWM1g2Z0otR0UtN25ldzRENGhmWW81QXpvc3hCREY4ZndiUGRjbjh5OXc9PQ==
That's a nice idea. The current search doesn't contain many heuristics in order to keep it simple but that would be interesting to try!,r/machinelearning,Z0FBQUFBQm0yeGJ4ZVl0YWoxMElZYXc4SndQSTJ4TF9iM1FFYXVIaW1qNUE2WGt2ZlJiY1FCVG5tXzZqczRYOEpUbjZJc3dJOVFtai1ZaVBtUFFmZ0N0YUJjbVp3eERvZXc9PQ==
"Love the concept. I’m used to more bloated validation interfaces, but this has the high potential of mobile, spare-time use in my opinion. Down to the bone",r/machinelearning,Z0FBQUFBQm0yeGJ4c3lrV096OEMwQ3E1andISnV2VDVoRHljOE9uMlZCTzhQUEpfZ0pEWVZleVFnSTR0Ql8wWUhNelFSYzhQbHdyeHE2RmZtZWhrYlpDdmNxTHBLZnB4VUE9PQ==
Do models even grok on realistic problems? Paper on grokking was small toy problems and still took a while to train.,r/machinelearning,Z0FBQUFBQm0yeGJ4UkFxb3NqbHI5aEpYaVNsNkdTVnFMYVl0LWxGa3VqdU1yZU1JcE8wU0pZMjUzNUc1YWcxRnhKRXBwLTdlNmVvaXU0cmhwdzRoRm5LWUR1TkNYM21kVlE9PQ==
"Hi all,

I'm the author of the [paper](https://www.researchgate.net/publication/381009719_Hydra_Enhancing_Machine_Learning_with_a_Multi-head_Predictions_Architecture), and I wanted to share it with you. This paper delves into the intersection of predictive coding, a concept from neuroscience, and machine learning. Building upon Yann LeCun's Joint Embeddings Predictive Architecture (JEPA) and integrating ideas from predictive coding to develop the Hydra approach. This method aims to seamlessly blend training and prediction, promoting a shift towards online learning principles. The [code](https://github.com/shashi-mit/hydra) is also OSSed under MIT License.

Looking forward to your thoughts and feedback!",r/machinelearning,Z0FBQUFBQm0yeGJ4QkZXZVpHSERHYXJnTHgxWVlab0k5QzdhQ2NYM0xraWN4ZW5teWR2TGM3RFVoMkd2eDBPRkw3Nm9WclNIM2tOM1FEcXk5SHY5TWo0OVg1WVNBY0xxb3c9PQ==
openAI api defining some labels previously in the prompt,r/machinelearning,Z0FBQUFBQm0yeGJ4clk1QWstdkFJLXFVWjNRbTNpc29XS1RhVlVCbVkzUzFZYmliV2dGUnZHUlYwb0t5LWVsdE1wSDlPMXBlWkhoRUhrenNKZVdjdDljblplUklqQTVmTnJUcXNlSk50czNUWHc1UUlvZE1nV2s9
" I have always found this breakdown hilarious, due to the spacious nonsense LLMs spew for ""explaining"" their incorrect answer to these simple questions about counting brothers and sisters.",r/machinelearning,Z0FBQUFBQm0yeGJ4bER1cm9IMVRYQ1p4UFczY0l2VTF3V2drNHNucVBKUlpCRWVqMVlpZ2EyS3VCXzlzX1BqaWtvOVNxeUt1YVYyZFM5TG9fR3BMRUZPZG5tQnQ4QW84SEE9PQ==
" The detailed analysis on the ways LLMs are failing at this (and indeed the variations introduced to the standard siblings puzzle) is novel, though.",r/machinelearning,Z0FBQUFBQm0yeGJ4OF8zQ3JQcGRTQlVQSHM1Ry1FQUhNdjd5aG84SWQzY0dxaXYwandNVVk2SEliZXM5cEd6Vy1tTTdwWGNsYmE4bHR6eW5RaTJFN3FobjUxalF5X24yTkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4bXNGSXRPdGpENlN0My1RSS1PUGV6UTRBVXBVTmRXRUJ1TG1uQWRvUG9JRHhGRTl2cHBobnVFSGF4d0ZKTEVTYkRGS3ZfOXoxU1ZBYlkwaFpRVXBvMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4OWtvamlyUXJJTDA1MEpHSzBzUm9VLUFnS0N4OWRxbE5VbnFrWGhONkFMdFYwWFRQWkIxWDdjdXNTbU5vTUNENHdSeDNzaWUxQ3pKaFdBQXZJbHJZblE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4Um91UG4tX2NjbHM1NktuNXdlVUxKdzExWUFlNmh0YnI1MTJIWGRBcUoyUkN6SC1ucHc1N3BmejJpTkQ3TElnRjlEcW54dVdzQ3hiZXpUUmZfRGR3SXc9PQ==
"always thought this would be a cool way to label data but never had the use for it, super cool to see",r/machinelearning,Z0FBQUFBQm0yeGJ4T3pCNm1UbXFQUHhrbGlSanJfaFktcWNlQ3M1Skp3ZE1LTTM2WkJBaWw4NW5JdlVoLUc3Z09fZTRVMmJSMjRLTnZxV2pBODhZM2dMQW1VcU5HdUNwTWVOMXNnbzl2cXpnNmx4UVZsWVMtQkU9
"A square has area of x^2, a cube has volume of x^3, a d-dimensional cube has volume of x^d. 

The “size” of the space grows as x^d, so if you want to maintain the same density, your sampling points need to also grow as x^d.",r/machinelearning,Z0FBQUFBQm0yeGJ4UkFwaUQ3bnVhd2RXSmhQblk1bFJSOTdqblptLXFtMDlIWUZVOHo2VTNEMEl5MmFtdDRLRmVURzljbzVNOVFTQy0tSnlSNEJ3VHN6TklkeW5hSkZyQVE9PQ==
"> why?

For the lulz",r/machinelearning,Z0FBQUFBQm0yeGJ4eGV0TnkxQS1DeW5RU1NBT3liV1lFb0lBQjZkaS1xeGVNaG9jR2d2RDVrcm9nM25KMzJLQ0w3YkxwdHZaN3BzNnJzRndiaDdqekc5a2E3cFBlU3dDZGc9PQ==
Imagine scrolling this on your phone under the pretext of 'I am working and labeling a dataset.',r/machinelearning,Z0FBQUFBQm0yeGJ4UnNGdGhaVm8wUXUwY2x6ajFlTW0xclVKTU8tdVlKbWxIZ1R4djhSQ0JGeEtsMDU3bnJSZWJneHRYQzMtNlVLekJqbG8wQUJpd2dQdE5ocXMxSEV6MWc9PQ==
Awesome! How long it takes to embed so many papers?,r/machinelearning,Z0FBQUFBQm0yeGJ4TzVtZDNoX3pSV3k0d0xEYkJGWnNTel81VkpjWTJja0FkMUw0SldPOFdxcmRFUlJYX3g3LU9xWVNJeXVwSDVEZ2gtUUl0RDd4d3B4M1g5QlpMQ18tMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4Q1pJWmF0WkFyV2loTm9nN3hHN044Y1BhRUdNMVNfWVp2YTU3b0dCdXRpMXNfN2V4c2lFSnFaNFBuYWxkcWk4SWtiWmtFbnBjMXJzTGppaXlJM1l1SGc9PQ==
"~~This is correct, and the formula in the book is wrong. Assuming the same interval length per dimension, the density is N / x\\^p = N \\* x\\^-p. It's proportional to N, and inversely proportional to the volume, which grows exponentially in the number of dimensions.~~",r/machinelearning,Z0FBQUFBQm0yeGJ4M0M3UE9nU2ZFcmVqYUdLNDVBOXZuV2NNWEtVS3pqU1BDSDZ1QWVTYUdCWU5lSy1WZ2JlNm9MY1VxLWxFYV92czFyVnIzX1NHUlczckNPWDdLTVBPbnc9PQ==
"You find people by asking them. It's simple. The whole problem is similar to the housing shortage. It's self-made and unnecessary.

Accepting professionals from industry is bad if you want peer review. They're not peers in many ways.",r/machinelearning,Z0FBQUFBQm0yeGJ4cVVENFFkbXhHUGphRFlnUXdxSUdUUTZ3V1MzQkNwcnhnSWRPNmI2SmdSUmJ4T1F3dG4xeWZsODNrVVJZQkV0MzNHTjhuSTNHVGZuS3pfUWFvM01hWmc9PQ==
Probably easier to run the model locally. Just need a GPU on your infrastructure.,r/machinelearning,Z0FBQUFBQm0yeGJ4NGgwak9hY2J4NU1QdlZHNFVXR0podXpfTU5JRk5OcGZRMmx4bzdha09PR1NOZVdhQUw1anhiQmZxMVc5dnlNOHh0QkREdzlGOUszVEhtYmxpZy1aS2c9PQ==
Why do you think Nvidia is witnessing the Gold rush? Enterprise demand for GPUs,r/machinelearning,Z0FBQUFBQm0yeGJ4ak9QTEtTRGdBUVlXN1JTc2ZGcGtJcTlhX1prQWtmaUZBSGZyU1AxdGh4UUhTZ1hyc0ZDbjNCTWNjMW9DMlhwOEpyQmRpX3pwXzJFZXhqbVExRWF2YUE9PQ==
"The confusion comes from the fact that sampling density is not density. It is the number of samples per distance not volume. Assume N points are distributed evenly in p dimensional space and we have D points on each dimension, D\\^p \\~ N, thus D \\~ N\\^(1/p). In local methods, we care about distance.",r/machinelearning,Z0FBQUFBQm0yeGJ4U3RzMU45SktNc2ZiTnhvdFBzY2tia3NxLUlqZDdRS0xOU25NcnhFb09ldlVNd0ZEalZEQ2Z1QXRMdWlfaWtJckJ3TUpOV01OZ2tkc3BqUHZrNm9mT0E9PQ==
"I appreciate your suggestion, but my question is more technical/theoretical than practical.

However, consider a situation where you want to run a large multimodal model with hundreds of billions of parameters on a device with limited resources. Or a case where the model provider doesn't want to share their model with the user, and the user doesn't want to share their data with the provider.

Do you see any technical issues with this idea? Can the cloud provider reverse engineer the inputs from the first layer (which runs on the user's local machine) to figure out the raw input data?",r/machinelearning,Z0FBQUFBQm0yeGJ4VnE3cm9Qd21OVURvQ3YtcHhSNEFPcS15UVZZMGFBYmFuUnprQW0zR1JaLWVvRHJGalpCb2JxVzNfRWwzSUdiSU5HTHJpRzcxOTU2bkgwOEowb2laVUE9PQ==
"So, are you saying that the idea is technically impossible to implement, or that it might lead to reverse engineering the inputs? Could you explain more?",r/machinelearning,Z0FBQUFBQm0yeGJ4M3c1aWNfa3FKUVE5MmlhRk9ZdlRiZGFYSHdhSXBxYjhkT1NxTmJfMnZUeEloZzdmN0p5NXA5S2ZtQ29HcmZaa2ZEOFRLTndPMUZHWWM3NUx6NXZaX0E9PQ==
"Yes, the input (an embedding I’m assuming?) probably could be reverse engineered. Whether it would be worth the effort is another question. What is it you’re trying to protect? What’s the threat model?",r/machinelearning,Z0FBQUFBQm0yeGJ4V3dzT2gtWEdUV1A1Zk50Qlc0VjB0UEQwVG90YjFpbzZ3QWVLLXpJZnRLMDFDZC1JZ2RFOWl2c0diNG9lMHZVcFlfUkFtX3RuenVUaUFDTFNUMjFIU3c9PQ==
"I assumed they meant density as in samples per dimension? If you have a 2d space and have N samples per dimension, your sample size is N^2. So turning it around, if you have N samples in 2d space, there's N^1/2 samples per dimension.",r/machinelearning,Z0FBQUFBQm0yeGJ4UHJoa2VfSXV5ZVY2eXpPcndJd2k5TVV4UldJY3VSdUFyY0c1cmNkNlk0bWZGbWJNR2VDbzdyWVdiRDR0djUyczdjdWt5TlpmdnR6RkZVa3c2VGN0Y1E9PQ==
"Yes, thank you! I was scratching my head for so long as I keep coming back to your conclusion",r/machinelearning,Z0FBQUFBQm0yeGJ4b0ZXM1RqdlBBZW5GRVJ3QUxMMWI1c0pqcHBqTUVLd3RFdWFVZGhRTjdrdk9wc2xETE9mMTlITV9vX0IyNTZsTGxqWDJVZ3doTzAzblAzNVo0S1hxMTZhMzhNa20tN0ljSWtMeWktTGlnX3M9
this makes perfect sense. Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJ4VnlqRTdWaGdYM2g3ckhVdTdHX3ZnVXRkOWU1bzVZcDhCcW01c3BOWUM5Q25uaVJSRTNseGNLU0NvZGVhcjh0enJEZGYzcS1IS3o1eHdjWE9oUjZRbDB5LUQxODhxMElPcS1GaWtGWjB1eXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4OWxkR0g1aVNWSF9hbmJTSDRGTzNWQXQ0NVcwOTAtNWN5dE5JemFQMWtJU1RHMUh2cVZkTl9yUU1qTGluOUdoU0o2aVNxZWhHUXF6SFh6YkpIVDZsemc9PQ==
"Still kinda a noob with ML, can I clarify why we care about distance instead of volume? My understanding is that volume is important because it tells us the how much data we have to form a local average. The larger the volume, the more stable the local average estimate

Would sampling density be something like seeing a traffic light every 100 metres on a very long straight road? If we decrease the distance between traffic lights, we see traffic lights more often, so higher sampling density?",r/machinelearning,Z0FBQUFBQm0yeGJ4c0hndWRWVUg0TXFLVXVsNGVCYXhYaFBhTldsY0JuSTcyNG9uYXpLRVNIY1ZmOE5xSUJCanIyUl8zZV9CUUhZZDlzOHpuc0pwRThUZ2JlcVBrUmdZLXA4Qmo4WW8wQkRCZ2d3OUdGR1o2WUk9
Looks that way. I guess sample density != sampling density.,r/machinelearning,Z0FBQUFBQm0yeGJ4MF9hOXdESXFNUjlvTzFGMFotdE8yZERoSEc2SHFSRWJzdzNpWFFFWFBPcEphdkdwVnVPcXQ5YmFLU0x2UGF1QjRDanIyVTNyREVObENRYUthalhSSGc9PQ==
">**Please, take this duty seriously**

Once again, I remind everyone that reviewing is done for free and ALL top ML conferences have used shady practices in the past in order to maximize reviewer load. There is only one recourse to being overburdened with papers because you didn't know that the way to adapt the reviewing load is to decline the invitation first.

Also, over the years, all top ML conferences have increased reviewer load by adapting the reviewing scheme to push more work on reviewers over longer periods of time. Discussions are not free for reviewers, they take time & energy and the burden is increasing superlinearly with the number of papers, since it becomes increasingly harder to keep the details of more papers in your head.

All of this has been done without increasing reviewer pay-off. I would like to know in what world people believe that increasing work-load at the same pay-off (zero USD) would not have any impact on average quality in all work items.

Signed: someone who reviewed for all top ML conferences in the past even though they had no intentions to submit there that year.



Also i was invited to become AC but not to review afte ri declined. I guess i deserve my free year.",r/machinelearning,Z0FBQUFBQm0yeGJ4eHMyVU9rZ1JLOGpWNTBaSEhCem0zSEk2VFY0UXN5N2RxZEtJN0VyR3dKc1JMNGhLa1ZKSG96RUpYOXBwekpzNmtFYV9KNTh2a1FBV0pkX3FEYUtISXc9PQ==
"Thanks u/stochastaclysm ,

I'm not a security expert, but imagine I'm using a local RAG architecture (i.e. I have a vector database of my docs, photos, etc. and an embedding model like CLIP running on my local machine). I prompt a query on something like Ollama and ask for a response. I don't want to send the raw input of my prompt and personal documents to the cloud due to privacy reasons. However, my local machine can't run the whole large model locally.

So, I think it could be a good idea to run the first few layers of the model locally, then pass the result to the cloud, and finally, process the result from the middle layers back on the local machine.

Note that the cloud doesn't have any information about the weights of the first and last layers due to some fine-tuning process, which we can set aside for now.",r/machinelearning,Z0FBQUFBQm0yeGJ4V21uZTNHMzB2X0hIdWxEaGtyVXFmNkJvRVk3ckxzWkJidEJtSFlvckhtVnVQX3Zna055X3g0Z3JWYTQxa0k5aXJlVE9NUV8tM3dLQ1BWcDhDekc1d2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4UFVtZFZTWXhkWHMtT3htZUdrZmloMHlxVlNNN0EwRzZCcG1GQzVyUHExcFBpdGhlR0VkRXU1Mk5VcWU0azIxUzJMUnZQME1Kc2RSel9OdU5pZ0VlTVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4NXVzblFIVkwtTENlWW13X3lSeXJ3dEhjaE0xOC11TmFqUE03SFBNZDdjWmxxWE9sZzFUNnJYc0QzcFlRREw0c1lOTGMza2p0WmlsVEFiX3YyZ2dpa2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4VDZ6MzFBVUJwTnQ1TFdTWnlWSVVMT1hJQ3IxTHc1YkNzanVEdElqTFlCRVpyMEdSTlJqdnBaVktJNGliMkFuYzkyekVpd1p3dlp4cENSX2dwQkNuY2c9PQ==
"How many posts / texts you can separate in an hour?

I made something for myself with more separation/classification levels

[https://imgur.com/a/Rxu2Joe](https://imgur.com/a/Rxu2Joe)",r/machinelearning,Z0FBQUFBQm0yeGJ4b2R0Nkc4NDgySUJZN1JxaGhuZFdrOXdzQ1lad3lSd05WYnotcmlXWFJiQUI3WDNSNkpFUzJjTTdiSmk2aGVGYU9fTXRpQURLVXgxdkdrZEowMVJoTHc9PQ==
thank you very much,r/machinelearning,Z0FBQUFBQm0yeGJ4ZEY5M1lSVXhRMjd5V0JRRTRoX3VmSzladkRFZ3g0WTlvQmpXcU9PWDZESHZVenJRajRDcVR1a0p5RzQ1UlJQMXBrZGRsNGNEU2kyOXQyd3hKZV95dnc9PQ==
"This is a golden nugget of wisdom! Thanks a bunch!

I think I got the idea. but would it be ok I request to be more concrete about '' if you focus on specific goals, rather than confining yourself to specific fields"" probably with an obvious example?",r/machinelearning,Z0FBQUFBQm0yeGJ4dGh5eFpZOHY0eGd3V2x2Y19mY2dmUEhKZ3QzQlZCTG9ZbU9xekdfZ3dGdHNMR3hJb0t2UlBwN0pyWjF3emg4VlNyWWRWbzJWcVVpRXJnaHppQmtGdFE9PQ==
"Is that really so? By no means do I have some proper insight into this, but it seems like, even when ignoring data poisoning, the larger the dataset the less quality there is to the information provided. I'm guessing training LMs on a smaller subset of professional articles would result in much more useful output rather than getting millions of StackOverflow answers and such, where people are free to write anything they want with no credibility. I assume the expansion of LMs is more going towards that direction, since that is more complicated than the first scenario.

So the models might be working better from a metrical perspective, but not from a human perspective due to the lack of information quality assessment.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZW03LVFpXzhwVkVQZDVSVVhNOEVHT1NhS3JVTkpHM0MtbTFNcGg1djVMcXlOR1hIMFZnUTNlVi0zZDdjdGV1bWk0VExxY0tYRXJVMkdsM095UjRpbWc9PQ==
With giggly eyes,r/machinelearning,Z0FBQUFBQm0yeGJ4a2NHb3ZBb1VTa1pJbjRqR1c4RlNTSk9lZlRtbG40UzRjZTMxUlpVaFBCMVJHZk9iUDFCQ1p0SEVSSHNMTHpPcjhTZm1QZ2F5dEZVWkFEZldac2hFcEE9PQ==
crazy but awesome,r/machinelearning,Z0FBQUFBQm0yeGJ4ckZzLXNmNTZnRTRZRXBDWDRtUWxuOVZST2ZYUUxnSzhTUlhzOXczZUJCejFLclRCeXp5T3ZtNUU1amZJeTZZODRvX0V6UVJIelpHSFNxYU83dzlPbkE9PQ==
On the bus: “This guy is not very selective… look at how many right swipes”,r/machinelearning,Z0FBQUFBQm0yeGJ4MWR5R3ZCMDgxUnVsNWpNSDQ2dktQQ3VQV0dMdUlmZUtkZzhobTNYSXZvd00xZnYxa0FBM2N0MnRzRnE1OWFoajk3TFFEVUhTQVBMY1NpSVJ6SHkzVUE9PQ==
Is that a position you can reach internally? Like if you started as a MLE and kept publishing/presenting on the side somehow and an “opening” came up could you be promoted? Grad cs student kinda curious ab this,r/machinelearning,Z0FBQUFBQm0yeGJ4bzRqZk1sVlpYYU9xbFgxU2MzX3E0LVBLRHF3TnlhWEJodzliYXFTbU9nZV9TOElDX0N5MGpQNjV3WTZhanlubXp2R3JJVk1HMHU4SlJOR3N4clNQQ2x4UlNaS2JHNmJ0RkpaTnI2b1Vremc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4UGxwcVg4UWY0YXJEdjRGOHpHbHRnaW9JdEw3d3BmMWctd1p2YkRsNTZmNTMwbE5zRlFkOHFydnRoM1ZIaXVETEVvd0EweFVvMGc1cS1VWnRZZGhVMkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4U05UZWNqS2lSbVUtcUFIWDFZclFxTGNaOXRnQlJjeFctdU9BdkRQMUh5eFlOdUVmLTlQMkpsaWd0RF90cUY3MXRUT3Z4ckZYMDl5b1BIb0JxWjJqM3c9PQ==
"Honestly, I think this sounds like a good PhD research project. You would likely need to invent the middleware that gets the input, converts it to a secure (maybe encrypted) format that can’t be reversed. The cloud service can then use that. How that would practically work I have no idea, hence the research project. Sounds really interesting though.",r/machinelearning,Z0FBQUFBQm0yeGJ4WVUwQWg1MFBNaF9qMjBDblhJZjRBUVdwYXlFU2tKb01RblBLblhJVEdjOXNCZ1BzclN4OXI1N080dHNFOE9jZk4yem43emdrQ1lqZ1BwMVRuWmRueHc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ4ZEtsUDdtLWhPOG5ZcWpXVEN3bnUwUWxsaHZKOU9nSi12elk4Rm5POFVIRURXYnYyZWNsZnJ6TGJkN01Kc0hFYkRRaDFuY2VBeWdxYkxLcXpuM2ZWaF9DT3ZpanhLd3g1QWJxQ3dkd003aDQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4SV9weFpMaDVUTkVaS1RYRHRkaTMwREM5QWJWb2VsQ19sRUE5X2ZEeG45ajFGeXJmV1dYYW80ZGgzSUVENldGbTJSSFhyVXFoWjNjY0dNQmRXRk5nQkE9PQ==
"The major reason for doing lit. survey is to guard against wasting time on idea that someone else already published and also to learn against potential failures. Ideas are not unique once you understand where the latest work stopped. With almost everyone working nowadays on ML, working on a niche idea only comes with highly specific problem with only  you having access to the data like medicine, law, creating new drugs. If you are working on open datasets with open problems, highly likely somebody tried and failed. In my career, I have had ideas which were  published by other folks since they were the early venturer in that domain",r/machinelearning,Z0FBQUFBQm0yeGJ4azJyZHBrMUpqLV9Sb1AwWHRMLWVrSG9XYlE0VW1NdTJtX0lkVXVpNWJEdWYzTmhkQkFscTAxUGJ3ZUdsQS10Nm9EUkJNN0p4blpEYnNsN2diVXZlbElpVnhENEgtMk5wUTJ3eDh5SzZxVjA9
Eh that seems like more of a pivoting/branding issue to me. Your labmate could easily apply their research to some aspect of RLHF. A lot of new methods are old mathematics with modern equipment. Hell my discrete math grad professor is a pretty famous topologist and is now an authority on computational conformal geometry. ,r/machinelearning,Z0FBQUFBQm0yeGJ4UmlIdmI2UWVrQ2ZJdUJjc1l2RmZBU2JJVUhyZGxvQTdsbzlSWXplcmJpMXNqakxMZDJ3MlB1OXNiUnZoV0lWVXpNVmpzTFR3LXZaa1VBLVdnbHAzWWppeXlWbEhWQ1paOWc0YzR2ZDdiOUk9
"These are all questions that your advisor, other professors, graduate cohort, and general academic bubble will have better answers than random Redditors. Once you start your masters you’ll be in a great environment to learn everything you need to know. It’s respectable that you’re already thinking about your PhD but just be patient and during your Masters talk to people, ask interesting questions, learn a lot.",r/machinelearning,Z0FBQUFBQm0yeGJ4Y3BPcFJYMjZuOU9zQ183OGgxcTVWaGM4QTBtVXREb0VxYnptN3dxelk3ZVZYZHcyZEMycU9mcEVmdE8xcE02NC1rSDJ6UHNCaHFYUW5lZVYtLUluY0M5eEctbUtaLXNpZDZuUnVIbk1xUVk9
"Using distance is a trick of local methods to avoid using volume, which is difficult to deal with in high dimensionality an also not essential to make a local decision boundary for example.",r/machinelearning,Z0FBQUFBQm0yeGJ4bHAzR2MwVWNGVnVnV2QyODVpQVN5YlRxRG1RVks5cDcxVmZ0Z0NDTXFyUTBKczJPU3ZGU21LTktma3Q5SE9lSjMyTkljTjIwY3doSnJMSmlkTHV5cnc9PQ==
That's correct: ACs did not get the chance of bidding on papers for NeurIPS24.,r/machinelearning,Z0FBQUFBQm0yeGJ4Wk5wN3l4WGxFUGlVZThOWVFqYnJscm1HeWpheTE2UDVZTDBHQzNXZ3ktVTJmX0pfNkhEM2hOemp3ZFp1VXdMV3M4S0xxVEQ3aDZtdEtMMjh4akdoSXc9PQ==
Are you going to Milano?,r/machinelearning,Z0FBQUFBQm0yeGJ4bnBxcjA0WE54U0lSa1FFX2ZERHI0bVFzSzJham1OQWljbTNtazZLOHFXNXAxa2FoeUpMTWc1eDc4UjRyeDZwQ09hSWRjWDFSVFBGeDhaWWY1bmtyMGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4VXlSc2hkVFBVRWdydlVqY0JGcGNYUFNibDBfRThna3NSb0F1dm1melRWajRRQUJpQ1NWa1pMSUsyRHdyR091eElHMC1HVEwxejBOTDJMRF9LbG42dFE9PQ==
"Don’t do it. I recommend you to work in a company as an AI scientist. A lot of my friends can still publish papers, attend conferences, whilst getting good salaries.",r/machinelearning,Z0FBQUFBQm0yeGJ4TDBjS21lMEplNC1GcmNjd2NxNmlLbzVmUi1rNDE3U1p3clBVcjlFTW55SE5jVkktVER2VERwLUVEbUU2WG1aNFM4djQzYzJ0MTBKOV8zaE9PR1RXWXc9PQ==
"Order of importance, at least at (top) US universities:


- prior research experience, in particular publications 
- letters of recommendation from experienced researchers 
- Statement of purpose 
- Universities you attended
- GRE/GPA




So regarding your questions:
- GPA: important that it's not bad
- Extracurricular: research, research, research
- Yes, do as much research as possible, even during the semester not just the summer. Consider doing summer research internships outside of your school at another school or at a company ",r/machinelearning,Z0FBQUFBQm0yeGJ4WVoyY2YxakFfSXZvRkhjdUQ2WW94T0pLcDZHRURKbjZ1eFVIcjRLSHlXdU9sSkZrdzVHWFFCakhiQm8yZF80OHhFNjNZUzR0OVZEUFNrSmFhbzJrWGc9PQ==
Shouldn't you need a PhD to get that position?,r/machinelearning,Z0FBQUFBQm0yeGJ4UjVoZ1ZYWWhKNmltRlZpazhMZEx4Wl9VYzlMMzJxejl3YkVwSTFObTV6X2RON2cwRkg3Szk1UmpKcG1zR3ByNTU0OFp0TS1pWjR1Qm5NUnRENEh6RVFoN2ZJeF90Wk9mb1dqYTVma3F3aFU9
> delves,r/machinelearning,Z0FBQUFBQm0yeGJ4U1d3ekUtYlpiSkg0Qi1zdGNFRHFRV3NXVG1lZ2w5RnNwdFlEXzNUU2NMWmJVZHNBYWRYenp5Q2Q1SjN4N0xpelNHdms1VjFNUXRuOGFFeTd3bC1kclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4NU0yM29FQkZIM3ZXcHlTVUgzMU52SnJWVE5rYmJNeHluRFZFby1BS196X242Ml9kQllfT19rX0dGZkdVWGdEUTJNcEs2WkMzUndkRy1lbjlDT254bnc9PQ==
Yes PoliMi,r/machinelearning,Z0FBQUFBQm0yeGJ4N2ZsN2NvLUk3VGJfeFB3VS1LRks4Y2hEWk9oX1NudVN0Q1p6VjB3X3RNcnl2SHJORE9McVp3QmI0TkNXUVl2ZmVsUTZIc1VRUnBRQUlEbHVwMmNON3NYdTlBZVAtekdhTVFFai1kV0J3Nmc9
"Yes during the semester I’ll probably enter in a lab at my university, but during the summer where can I go? Do you have any suggestions ?",r/machinelearning,Z0FBQUFBQm0yeGJ4SWRvQS1YZkpwVTYxZ2lLbDZzODhOYTNBVE1DekdzX2d5YmRUSWNhY2o2UWZuS1hCbzhFRmRXbHBabkhlZW5VY3kzVW43dDNkSm5KVTFqc1ozbWhhQmJCTzlXUDhTS2VHRDBNbTk1bEFYUjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4RVNzRWIzS010SHhkWEc2dEZLOEFjQnRTMzBTUy0xQ2hJN1FQU1o5SS1JYjFaNG1zVURRYjBXRk0xYXpDdjNhUzYtVXliVGRZcnRYdC0wT2JDRGtnMlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4MW9GVnl0RjZIYnZYN3ZDM3Vub2d0VzFrdGV3VXJibUFkNWsxclRwSzNlNlM2RXVmcGJubW8wclRKUkxIaHdjTG5pM2x5amNnVmRidlNOZFRucW1UMkE9PQ==
Which company do you reccomend? And which company take a msc student as AI scientist ?,r/machinelearning,Z0FBQUFBQm0yeGJ4MlB6T3Rrb3JLVXdpbzFWd0pucTZkUktLbGJFa2RMSHpsQ0ZBemtScjJUVlFrWEIwcGlJQ2xjOXhGdHlhLThRalBjaVg3Z1JQaF93N2NSTjNxdFFabXNTbE91N3ZXeTBxUVphWXRQU2d1QWs9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4VmZtaVVqWjk4US1Za3lzT0hsV0dFdXhOczkwcDRMUDZUdExIakhWblp0bkNQRmxkdnVSWEppazY5S2JETWlSR0c0a1dwVzZuNUR3Uy1ObHhyci1HQXc9PQ==
Basically comes down to scaling the model size up and giving better performance.,r/machinelearning,Z0FBQUFBQm0yeGJ4ZHBFSGJ5ZEFYTHNDVTNjOGpsUzhCVmI0SnVNM1k4RmZVQ09kRzZudFI4YXA0aE52RXo2V05rMVRBeV92Q0U3V0NWN2dNNEpSZDR4R1F0dnhUd2g0cDg0RUtDN3VPbTZQT216bFZzSkNRRDg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4RTVnb3BvN21Yd1dJOGtNcFdyUjdsU0p1VUV5ZHNPVlcxNUdzaW5WQ2RWazJwd1VLYml1cGplSmxwLWJ1cmZFUl9ERVU5OTN6UU1PTkpIWlJRdE52NXc9PQ==
Are you getting errors or just poor results?,r/machinelearning,Z0FBQUFBQm0yeGJ4WnI2NVpZRGxKZHFpaS1US291Uk54U01nMkhMa0ZDZkxOcnBxcEk2eEUwQVF4UU4ybkxQd2prU0N0eUdUN3Z6bVJPQ1lNVUpyLU1feEFBNWdnZVVVWVE9PQ==
Poor results using a yolo algorithm is usually is related to your data set,r/machinelearning,Z0FBQUFBQm0yeGJ4cnQ3UHBtcHlVUFRjbXpBb1VPSHhRdC16RU10aW5JeThZaGQxTW5nWlBGUjFqZFZja2xQODRubUdiNkpVQ0N0R3R0cmp6ckZGbUJnTV80THMxRTg0WFE9PQ==
"I used to use a leap motion controller for this in 2016 and it worked really well, I still have it but the software is unusable these days, leap killed a lot of compatibility with sdk changes or something and most devs stopped maintaining.",r/machinelearning,Z0FBQUFBQm0yeGJ4MTBRMF9iYS1NSWRUWXl0UXhudFBQaks1M2JPbGswcTNyU1h3djRRUF91UHU0YUx5eHh5MnpmUTJkVmV0eEtsMW9WSkNQbUNNNnJZODhmVWlKVXBPQ3c9PQ==
"I'm getting poor results, particularly the mAP@0.5.

How can I check the quality of my dataset? I just got it from Roboflow.

Can I dm you for questions?",r/machinelearning,Z0FBQUFBQm0yeGJ4UE5kbWhtT1Q4TUxpNEFQYVo3dk00N3FJQk1wZVpmZTJmUmlrYkw2X2tKYlg0M3BybzVMeDdYR2RnX00ySlpCUHZDTzFjYk02bGlZSlRtVWN6TVlra1ZGWGoyLU9MU3lSdTJtaXBhTF91M1U9
You can try running the genetic algorithm for hyperparameter tuning. My mAP@0.75 (i changed the eval metric) jumped from 0.83 to 0.92,r/machinelearning,Z0FBQUFBQm0yeGJ4VnpJZDNNdE5oV0xXMUtGWTF2VnRTZDBYOUpubHliSXBNRVpRMUhvUVMtSDZCU1FvYlp1TDlUTVAxVkdpLWtGeWhfell0cFZkbHBZa0s1SlU1NkVaVmc9PQ==
"I'm Aditya, and I'm just starting my journey into the world of AI and machine learning. I'm looking for a comprehensive roadmap to guide my learning path. I would also love to engage with this community, get advice, and share my progress.

Any recommendations for resources, courses, or tips for a beginner? How can I best contribute to and learn from this community?",r/machinelearning,Z0FBQUFBQm0yeGJ4VlNMQWhkbDFMTV9kQVFzcXlrWVFBeXA2RU44NlZRRi12Rm14UHEyM1I1MUFzdndjZUlCc1o2cUVfN0xSdVRQQ1pidDhpLWFnRFdsOGw4TlllUFBDbEE9PQ==
"I have a CV project involving Neptune and Vercel. I feel like Next frontend is much harder than actual equations like RMSE* which I had used for NLP. I wonder if I get different category scores from Linköping in my GluonCV. PhD is the outcome. It says nothing about problem solving.      


My repo for CV annotations: github.com/brageon/pandora   I have 4 YOE in Python. No higher education. No bootcamp. No video tutorials. No humans. I created my own website. But Vercel S3 upload is very different from adding cookies in JavaScript. Can we be coding partners?? 😊  


+ GPT is popular for simplicity. Look up Linda problem for conjunction fallacy. More text with less debugging give a sense of achievement. More debugging (workflows, subtasks) with less text give a sense of madness. If I delegate to someone with something very specific it goes nowhere. This is why I don't hire freelancers. I feel like Bezos. ""Why you ruining my life?"" ",r/machinelearning,Z0FBQUFBQm0yeGJ4Y2U5bVJ2cmhnOG14TnlpNWpqd0J6YWpWdmY1VGs3RExqRWpyakdnUFM2clpaVWlSVE5uZ0Qzb2Z1cEtLZ3BWRmhWODdUZHUzbDdYa0FRR1pHalNZdzZVYUUxOUh2STQzbUdnUGNweTNZcWc9
"I have a CV project involving Neptune and Kinesis. I feel like Next frontend is much harder than actual equations like RMSE* which I had used for NLP. I wonder if I get different category scores from Linköping in GluonCV. PhD is the outcome. It says nothing about problem solving.  


My repo for CV annotations: github.com/brageon/pandora    I have 4 YOE in Python. No higher education. No bootcamp. No video tutorials. No humans. I created my own website. But Vercel S3 upload is very different from adding cookies in JavaScript.        


Canterbury Puzzles is my math foundation (e.g. cyclic series). I use brainbashers and puzzlewocky to remember those ideas. Nobody have helped me with anything. The only chatbot I use for coding and troubleshooting is Gemini.* In my other repos' README files I added irrelevant references to external tools (e.g. Athena, Clara) I know from 3rd party articles.


My question to you: What more do I need to do for convincing Fintech to buy time from me? I can find other tech savy people. But if I was a software house what would convince you? With age I become worse with semantic coherence. Would this repo compensate my lack of education: https://github.com/ossu/computer-science",r/machinelearning,Z0FBQUFBQm0yeGJ4andBSkNqVGpQcUNLTm4yazNDQXZqdkFVazczSmRFOFNubVdiOTZGSHQ4Zm5jLW5kZlF1STRBSU90NFpwYS13My1zZjZrSkdFYXRaQW81SzRwUGtFVlZEekRDQVg0bTFhMHJFNjZ1SG1iN289
"Is it called the hyperparameter evolution (evolve)? I have tried it but due to time constraints, I did an early stop.

Also, how many epochs did you train and what model did you use?",r/machinelearning,Z0FBQUFBQm0yeGJ4dlJXVEl6MTdMUkRMYVpuWDJxTHZVeDNZVVFyMUdfV1hGQ0wxWVNwU2M1bThJN3EySU1DZ3B1VEhOMGdRbVhfaW0zSVRiemVVckhxNDVTRklwTE5jTDZqd3RjNjZPbkpRMmVmUU9OSUdfT289
"Ideally I want to build a ""Large Language Model"" for acoustic time series at the largest reasonable scale.",r/machinelearning,Z0FBQUFBQm0yeGJ4bzJXTVpBVnNZSTdFdlRkaWpGWS1KS09jaWRjOFBXV3hENWl5cHdHTFRPSENnSjhQY1ItajY0cm5POTZIbjhoT0lIbzBoQ0doN3h2cHVBTkxzWVFNMlE9PQ==
"This would be a neat way to verify image captions, or even generate captions for unknown images by randomly selecting words and asking if it fits the image. Actually the 20 questions method could work for captioning unknown images would work better.",r/machinelearning,Z0FBQUFBQm0yeGJ4TTRrWnB0dDJtY0RwTEEtMU10ZTEtSDd2eFlyeWxVZ0xRdXIyUXJRS0dwNXZxN2E1eEl4S1RCN29NTkVKV2ZHX0lvYjdrUDFiZ19NbzNHdVZxN3FVOEE9PQ==
"The goal of this project was to create a music visualizer that is conditioned only on the song itself. To that end, I trained a model to map from audio embeddings (courtesy of https://huggingface.co/mtg-upf/discogs-maest-5s-pw-129e) to prompt embeddings in the input space of Stable Diffusion 1.5.

In order to simplify this task, I first trained a denoising auto encoder (Transformer-based), so that the entire prompt token embedding sequence can be generated from a single 128-dimensional vector. The training data for this step was generated by ChatGPT (together with genre labels) with a prompt that asked it to generate image generation prompts for a music visualizer.

Then, I trained a CycleGAN model to map from audio embeddings to the 128-dimensional prompt embeddings (and back). I used the same training data as for the previous step. The discriminator received the genre label as input, thereby guiding the generator to consider the genre in the prompt embeddings it generates.

Finally, I used SD 1.5 with AnimateDiff to generate the music visualization at 768x512 resolution and 15 FPS conditioned on the CycleGAN prompt embeddings. Then, I upscaled 4x with Real-ESRGAN and interpolated frames 4x with RIFE.

I'm pretty excited about today's state of open source ML and the ability to plug models together like this. Especially with AnimateDiff it feels like I've barely managed to scratch the surface so far.

I'd be happy to share more details if there is interest.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZHJiTVdqVU9mM0FVdm8tM1FqU2xpdk9mYjNQUGI0TlNQY0NTaWNQTXg4WGF2UkM0WUQ5Um11RlBuaTdReEhDZU05bXBQRTVjNm5pVmZycENncTBDNVE9PQ==
"Hey everyone!

I am writing a sort of essay on Multimodal Machine Learning, where I want to cover state-of-the-art architectures/approaches. Based on my current research, Transformer models are basically used everywhere that's state-of-the-art. I'm aware that it is possible to use other architectures and that other architectures have been used - but no source of anyone at the moment actually \\*using\\* something that is not based on a Transformer-based architecture.

  
Is that assumption correct? Or are architectures still in use? If so, could you please tell me where it is used? Thank you so much!",r/machinelearning,Z0FBQUFBQm0yeGJ4ZlUtWUFUT3lZSlFzVFlmS3EwNHVzclJwQk84NURhRjlZQUJFWTV1XzdzdEdmdVRrRmdjM3FqcnBzbFk4ajRvSlQ1eDRBQXByRndERU9nLVB2M2h0cHc9PQ==
How much can you swipe in an hour should be the real question.,r/machinelearning,Z0FBQUFBQm0yeGJ4SkRzTlAzUXZvOGEzZklVZDMtYkpVVW1uOE15bjNPdWg3cVo3cl9YcDY5Q2NHQTA3UHgxYmlfM2JPY3B2X19uS2luWS1BazM4Y2dOY2RkTDgyR3NMaHc9PQ==
That's actually a good idea. I should make a new branch that handles images to swipe left or right instead of plain texts.,r/machinelearning,Z0FBQUFBQm0yeGJ4V3hXbENuRC04SmtucEFBSkNaYkxVSVZHOUlhV0ozMGYwYkFybGNmRW54SHFpS3hKWGFPVVYteS1TT1l3TnJNNndhWVNkUVFKNHBXazNJcXdoeXdsN2c9PQ==
"You can’t afford it. Lol don’t bother. Also llms arent the best for time series data - better off with RNN and LSTM.

What did you use the Cray for? Lol",r/machinelearning,Z0FBQUFBQm0yeGJ4UDNSWlJsMGpRZm5hVVVUOVZRemd2dTJuenROZnBMLXVkamdDdmFfMHU5VTEycU9NdU5PR3FrVWRqRXV1MmpZLVVEdkMzVHBZQVppczJCeU5ieDk2bFE9PQ==
Are we going into semantics or you have same number to reply?,r/machinelearning,Z0FBQUFBQm0yeGJ4T1RyVXNhZWtXbTBvb1hRbU4xNXczVFdmTWtIQmFvMGJHMUhmeTJFMEF2WFRCcjhUMFFxRGphenJxTXVQOXdOMXd3M2huS244azdzTFZQa3gwNnd5dnc9PQ==
"Thats the one. Yeah its computationally heavy, took 1 week to run the whole thing


But i should mention that 40% sounds a bit low to start, how does your dataset look?",r/machinelearning,Z0FBQUFBQm0yeGJ4LWZKR0pYQ1lfRkd1TnlYVm5FcXRqTzV0ZnByVUw5QU5mb29DTFVaYjhqWXF6VlBCb3Y2bHZ1dVFCZzVsX2p3dWh2cjl5ODNuU1Q4cWRFN0dpR1JULUE9PQ==
Bro this is a project to use when you are bored of  sorting dataset the usual way and want something fun (while having that dopamine vibe to it). Not at all to be linked to productivity or efficiency at all.,r/machinelearning,Z0FBQUFBQm0yeGJ4bHFQb1k1OTUtazhqekNDcGZBY3RfNmlmZHFkZm5wem9FRWhDY0YwQVRuZmx0T1U1QkY3aW5kekFXcGFUbEItNkRCWHhDQ3FaYzNtcjhkTFhOZUJWTnc9PQ==
This is super nice! Would you be willing to share a more detailed step by step? What exactly was the generated Training data?,r/machinelearning,Z0FBQUFBQm0yeGJ4WloxeTlBWk5FVERUaWk4MDctd1FPd3RsaW1IdGdSWk9OYU9HeDFtNTNxeTh0OGt3Vi1xdEh3MV9MZUtGeVRtbnlHdEIweE9Rc2hRVk5PN0x3WTVFRV9mTGVKRE1tNkRTTU9pb3ZjR3BWSnM9
"Ugh LTT is still around? Can only get so deep into a video of him reading off a spec sheet and pretending to drop things because he’s sO qUiRkY.

Anyway for me what I really love about these enterprise NVIDIA systems is the fp64 capabilities. I’m a statistician by training and wrote core parts of my dissertation’s methodology in CUDA. It’s what turned me on to NVIDIA because their hardware/software stack is light years away from the alternatives. I always love to see all the GTC talks where folks find ways to parallelize their “traditional” (read: non ML) computing to leverage these massively parallel systems. 

Jensen is not exaggerating when he says this stuff allows people to actually complete their life’s work.",r/machinelearning,Z0FBQUFBQm0yeGJ4MS0yZ0Nvb09TRHZNMFZpbWt0TFRMc2xfQTVSdnhONGN0eERnZ253MTlJcHpkVWtUT0JwdzcxOEZOeDVFVnRnN0cwUGZNMExqc0dxZ1ZhWVktN3ZyQ2p1bUVfdDFfdVVzX2VGWjZfaXYydzA9
"i'd add that elusive ""taco"" category to my hotdog/not hotdog classifier",r/machinelearning,Z0FBQUFBQm0yeGJ4VVVfd2l0RUNnOEFMV19wdDNUV09SRnktaUMtb2haODNQWXdfTFNNMUpsQ1k5NFpYT1NvTnlsbWkyMTR3QkFJcG0xOERiczh2MUZIT21FbTlXeWVvLXc9PQ==
"This is very true. Some Scale clients sign up for projects purely devoted to reasoning training, where the models are treated like a 5-year-old and are taught how to reason at the most basic level. If you had seen this yourself, you might think it's a dumb thing to do, but it actually tells a lot when you realize models fail these 5 yo level of reasoning questions (not anymore and not all)",r/machinelearning,Z0FBQUFBQm0yeGJ4TWFNRXZvRzkydlRoVFZod21PZXRLN01oVFVnVkJxTFFoN3dkY1gyUGxxYmxhdTZ5WlNyM3FuYWpxSkx4cE1hT21Od09VSjJOVnlZYmdrNWtrSENqYlE9PQ==
"I have a CV project involving Neptune and Kinesis. I feel like Next frontend is much harder than actual equations like RMSE* which I had used for NLP. I wonder if I get different category scores from Linköping in GluonCV. PhD is the outcome. It says nothing about problem solving.     


My repo for CV annotations: github.com/brageon/pandora   I have 4 YOE in Python. No higher education. No bootcamp. No video tutorials. No humans. I created my own website. But Vercel S3 upload is very different from adding cookies in JavaScript. Can we be coding partners? 😊  


Canterbury Puzzles is my math foundation (e.g. cyclic series). I use brainbashers and puzzlewocky to remember those ideas. Nobody have helped me with anything. The only chatbot I use for coding and troubleshooting is Gemini.* In my other repos' README files I added irrelevant references to external tools (e.g. Athena, Clara) I know from 3rd party articles. 


Is this a technical training for other people? If not how do I curate it to the general population? I have a difficult time for finding tech savy peers. ",r/machinelearning,Z0FBQUFBQm0yeGJ4b2NsT3hwUWs0UHRxeFBnU0c4MzMzVWFmbTFneFF4am1rZEVNZDBwMW1NbzB1c3VwMDkxeGs2S2VXNFpPSHVrcm1MdXUzcmxtTmxxcWhnR010OExTajdqLXBVNTR3S21zN0g3UnVJOE9sSlE9
"Not sure, but I'm not super optimistic. After taking the MLEng job, I just keep getting contacted by MLEng recruiters.",r/machinelearning,Z0FBQUFBQm0yeGJ4bjhXZXBBVFpEQkJPVERtZGdBUXM2R1hmS1dwdWl5d1U4OVFwOUZ2ZHItaDdvcGNPVlNyY3d6VUVkd3dNdFZGbkRoa2djTUNnaC1JYUhkQ2U0MFVwTXc9PQ==
"This is the dataset that I downloaded: [https://universe.roboflow.com/pranjal-hxy4r/acne-detection-noufu](https://universe.roboflow.com/pranjal-hxy4r/acne-detection-noufu) 

I got it from an academic paper. I didn't edit anything in this dataset.",r/machinelearning,Z0FBQUFBQm0yeGJ4VFZGVEZOd2tHM21RbFlWTWotLXBmNUhwN0NtT01lN3lyNWRDTmlmc2g4NkI1MmFPQldqNUxuQjRrUGhiODFuU0FBR0RVbmxrMmppWVh0MkVfQkNDTW5SMWtlenpPMW5iellPbVpuYmZIUEE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZFFNOFRfUnhUVnlxQnByOGlvUFZncDFOa1RyR0tqbFlFandaeV9oTWYyeHV2bmZheHFWVEU2VG1RRF9VRGlBMmNHdVhDNXNEazU3emxFY3hjT2E5a1E9PQ==
"Back in 1900 most people assumed that a propagating wave must be traveling in some physical medium, but that turned out not to be true; that assumption was the product of fundamental misunderstandings about how the world works.

Now, most people seem to assume that something that uses language must also be doing some degree of reasoning, but I think that's false, perhaps even obviously so. 

Just as people who were trying to characterize the luminiferous aether were ultimately attempting to study something that didn't actually exist, so too do I think that the people who are carefully analyzing the reasoning capabilities of LLMs are spending their time dissecting observations that are ultimately unrelated to the subject of their interest, namely the capacity to reason.",r/machinelearning,Z0FBQUFBQm0yeGJ4N1gwUy1VZHl6dzlyTXNUci11NWJlZDEyTmU1NHdURWtfUDMtN2JTaFBBUE5YWVAta2plVkZ1WUYxUmMtRkxxVEU4Mk53Um8zVGdRWlBVb0hHZVlGQXc9PQ==
"I can definitely afford a $3M solution and even more.   We used the Cray for all the same stuff, analysis of time series, just with MUUUUUCH smaller models",r/machinelearning,Z0FBQUFBQm0yeGJ4UGlBeEtHdjlhTDVuWC1vMzVjRFNvUFZwRGtCUTJROEROcGtqT0JuTnMwRFItRjVhNDJMbjlhNHRuWHZ1YWNEQWpHcDV5SE9kVDdKTnRpcTA4VmxhOUE9PQ==
"Sure, a simple example of a concrete goal would be ""I want to detect birds in images"". If your foremost concern is that you think of yourself as someone who works with Convolutional Neural Networks for classification problems then you might never consider using self-supervised learning with Vision Transformers, even though that might ultimately prove to be a better approach for detecting birds.",r/machinelearning,Z0FBQUFBQm0yeGJ4clQ5SFAzN3pUemJGNnlCbEdUSHBmdF9YbDQ1VFNlZVFKZ2NfUVRURTZVNW1tbGx2NzY1YVY2QlpUVkZoZTNZQmMtWGRsNmtKZG5DUkxUNEdSV2x3OVE9PQ==
"How do you curate your ambitions with whom you talking to? I know too much but can't adjust text. I end up writing for future generations instead. How would you reframe this ""+ section"" below if I wanted to convince you to collaborate with me? I wrote this for ""superficial GPT article without content."" Not for winning but for building up his train of thought in more abstract layers. 


+ I have a CV project involving Neptune and Vercel. I feel like Next frontend is much harder than actual equations like RMSE* which I had used for NLP. I wonder if I get different category scores from Linköping in my GluonCV. PhD is the outcome. It says nothing about problem solving.    


My repo for CV annotations: github.com/brageon/pandora I have 4 YOE in Python. No higher education. No bootcamp. No video tutorials. No humans. I created my own website. But Vercel S3 upload is very different from adding cookies in JavaScript. Can we be coding partners?? 😊


GPT is popular for simplicity. Look up Linda problem for conjunction fallacy. More text with less debugging give a sense of achievement. More debugging (workflows, subtasks) with less text give a sense of madness. If I delegate to someone with something very specific it goes nowhere. This is why I don't hire freelancers. I feel like Bezos. ""Why you ruining my life?"" +",r/machinelearning,Z0FBQUFBQm0yeGJ4b0VfUXltNVhldUk4OU9DaTRxODlHQ1F0ZFYxTWxPX0RfUzhvX2VqeEVXdTg0elFHVDM3XzYtZ0tjanN5bTdvaDd4b3ZnenhPN0FaaHBSN3BPXzRLSmp3VU45SE50OG5RT1E4VHBOeXNCTVU9
"That sort of is the point that I'm making actually. I think LLMs are irrefutable evidence that machines can use language, but I do not think that they demonstrate a machine's capacity to reason, and that isn't surprising because they aren't designed to be able to do that.",r/machinelearning,Z0FBQUFBQm0yeGJ4eVh1dTI0Ym5aVnpHdHhrbGd5N0IwWEQ0SVFreEVwOXhfWmM5WVM2aHNvVUlrRHJVWVhuV19JS2RGaFRSbWZWX1V4SVk4aEFfUWM4YkhDcFFjS21VSEE9PQ==
"Nope. I have friends who have a bachelor or master degree but got the AI engineer or scientist position. If you keep learning new things, studying the papers, up to date to the current states, doing presentations to the community, you’ll get the job.

PhD program is basically a training to become a researcher. But to become a researcher you can do it either in academia or industry.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZGFQQm9PdDFwQW5jdF9RQ3hidjlvSE1SWFNvY3lKQl92a2w2bm1RbUdPd3RHNURhR3ZGeGg0cjB0RS03aXlZTGZIcG9JeEpJazA2d0ktNFhaT3RmLUE9PQ==
"I recently came across implementing a new GRU architecture and trust me, not understanding how to fully understand how ML models are constructured in C++ (from logic to CUDA handle) caused me a lot of troubles. It is essential in my opinion",r/machinelearning,Z0FBQUFBQm0yeGJ4M1Y1M1UwT1hVNGQyQm9rWWptMUlpdTJudXBSWlVvNXl0M3B6djZpQWk4M3E0SkVBZjJ6dU50aUxHcVFDYWlGeGtNV28yOWdrZUsxNWlkLWNOVDdKd014dXZEQ3NDa3hkdnhhSlBjbGlJdDg9
"You can target any company that is doing AI research or building AI application. It can be a startup or a well established one. While you’re searching, try to publish your own papers either in conference or even just arxiv. Ask AI community to criticise your paper. It can be harsh but it would make you to be a better if you do it over and over again.",r/machinelearning,Z0FBQUFBQm0yeGJ4c3FtaS1oemQwTUl1Q1ZfOGlBRGtEbHBEd2Foc2U4LVI1WWwzZmY1NUhGRWdOamQxUGMtaVZ1am9RQXFHMllDTDBTS0hHMy05cmZrVGFoaUpFcDdhbXc9PQ==
"Question: does the “new” button open opportunity for bias? For example, you give someone the ability to skip difficult labels. Anyone got a good resource/paper?",r/machinelearning,Z0FBQUFBQm0yeGJ4Tmd0ZzRQSjM2d1NySnZ5ZjVzSTJhbTE2NzNhWDVUa3Nodjgza3Jpd1Q2U0E2VUtfMFhDbEVkdnViZkltZ2tlajh0d25ydEdDb09zT2JGUkVjbDRtNVE9PQ==
"If it works for you, that's great!

There are some very full-featured labeling frameworks, though. They don't offer the simplicity of swiping but when you're labeling thousands of items, they can speed the workflow up a lot. A few of them:

- Labelbox
- Prodigy
- Supervisely
- Label Studio
- Scale AI
- Dataloop

I highly recommend at least checking them out to get an idea of what the other features that can help label might be and how others have implemented them.",r/machinelearning,Z0FBQUFBQm0yeGJ4MWRLUGtmOFJwTTRBLTBnazlHaU5vcDVJcWVHSUxZV0NxWWY4RlFYc09kaFV1aDhkd01QcHBVWi1iWThwNzE0LU5ybmlzVjU4aHJZUG1LMzhFU25nQ2c9PQ==
"This is essentially a search ranking problem. The literature about this is vast.

The TLDR is that there are three steps here:

1. Develop a collection of features that seem relevant to the problem (various embeddings are an example of such a feature)
2. Create a model that assigns a relevance score to each document in your database as a function of the features of your input document
3. Sort all your documents based on the relevance score

A simple objective function for training the relevance score is cross entropy - every prior art that a given patent cites is labeled as having a score of '1', and every prior art that it doesn't cite is labeled as having a score of '0'.

For the features, it probably doesn't make sense to do a custom embedding model to begin with. You're better off just using a bunch of pretrained embeddings models and then using a tree model like XGBoost to sort it out for you in step 2 above.",r/machinelearning,Z0FBQUFBQm0yeGJ4RVJKWHFzTi1BTEZMZ2dZNy1fTGpXTHQtQzFCTEpGZllTVVlyTVVPckttQ3Z2ejJOQThPVk9rcE5sMUg5eC1fTDNUc2JBT09lcC1xT25ESERrVzNQUEE9PQ==
"yeah LTT can def be way over the top but he does get to see new gear before I do.   So it leads me to new stuff.   Just like Jeff Geerling and ""Patrick from STH""",r/machinelearning,Z0FBQUFBQm0yeGJ4YTV0WnRqWWJMelA3WDBQRUMzR25zMjBQVEwzYWx4MGR0T2pWZUxtajA5Y3pBSXNCT1l3TDdTU0wzSnIzZzRYVDdGZUJNZ0IxNXhHa1R1dldkMS1JZHc9PQ==
Any news?,r/machinelearning,Z0FBQUFBQm0yeGJ4eEF0eS1FY0ZiemUyMG9jRXo4X1NzbURkTGs5ZmRhVDVJbTV0ZVRINS1IV093VlY1Zkg5VWI2MXlERGRpYTR1VmpOM2otQW42cWNRUFJiS1RYSWhfV3c9PQ==
"I did this in my own custom labelling system a while ago but never released it. The only thing is you want to add an undo, and also add a way to mix back labelled samples into the unlabelled sample stream at some ratio because it's far too easy to make mistakes and underthink labelling decisions in this format. I also added a little labelling criteria reminder on the bottom for myself so my criteria don't drift.

Btw, consider adding JSON output support for the labels, it's a little more flexible for ingestion.",r/machinelearning,Z0FBQUFBQm0yeGJ4MFlIQlRaUktKMmo0RnNWN2RDRnRDdnJOdm5uenI5djFiUjU4c2pFcUo2T1FxU1FvYWxhMzdPOU04UHREYnVCZWRSbVhGcEZzQUlQV2stWW9vOEhIVTVybHhJNVRUd3BFSGxYeGczalNJUEE9
what ap did the research paper achieve?,r/machinelearning,Z0FBQUFBQm0yeGJ4TzZjTnQ4WU1udG1zTHVrUktqalJLWmMwNzNJOXFOeENCbVZTQnhVZTVtZTdUWGFNMWFScXVrZWtXMXBBcDVOdlhWOTM5c1NfeDY4VkM0SnIyQ09oOUE9PQ==
Can you use this? Its human time series and actual health though. https://arxiv.org/abs/2306.03009,r/machinelearning,Z0FBQUFBQm0yeGJ4ZHJuWEhrM01PM016VWFJVV95M01pS05sZlZCM05EdUtQQzV5MkViQkUteDllZm5PVnRxX2dGQTg5QmRMLXBiOEZoOE1CcnZyWF9XTWwtV2VrdFNSWXc9PQ==
"If you go for a PhD, finish it as fast as possible, especially if you plan to work in industry.",r/machinelearning,Z0FBQUFBQm0yeGJ4U01hWEwteHNBTFR2QnN0WE42Z3VYSEdoWFg3WXlOYnBKYV9hMk9rUlF2RVhWUjhoVUpUSkY5dk1kSFRraG9uV0lndXNOcGZXX1FIVHB4UnJZdkthTVE9PQ==
"hi there

this is the academic paper: [https://ieeexplore.ieee.org/document/10417424](https://ieeexplore.ieee.org/document/10417424)

it achieved 74% mAP",r/machinelearning,Z0FBQUFBQm0yeGJ4Mnh4Q1IxVEl6Tm9wcWFCWmFmZU9PZ09fSzQtOVp4YjB0akZTRjNhbWtmYmtEUUYwMEFJQ1djWFgwVE5nZDNEbTZ6cEhUNDVIeVo5cHBnbE1EdzhiMXMzZ3pLRTExRFY2RVdLN1RtNXMydjA9
"The button isn't new but ""neu"" in this case. This is a button that makes the data fall under the category of neutral. This is only for data which might be useless since a lot of scrapped data isn't always useful. About adding bias to the model, this neutral could become an output in itself for the model to predict that too. 

If you find a research paper or article which mentions that neutral can add bias then please do share it with me as well.",r/machinelearning,Z0FBQUFBQm0yeGJ4d3FlZVYtQk9rcFlnaTRhY0M3RnNMMmhWNnRGR3dycUh6eFRNb0JramZGOFdPZ1J0bnJsVWpTT0RRM3MtMkVZTmx4YlR6dUZOUlFYTGIwM0F1eVpaY0E9PQ==
"Thank you for your suggestions. They are actually good ones and I would love to work on an undo button and also possibly replacing the log out button from the navbar to a hamburger bar which has more features like ""export to json"" and ""undo"".",r/machinelearning,Z0FBQUFBQm0yeGJ4WHNkSmdGck5zeTgyYkNVazYxT0VURC05d2NQeDFFLTRNNkdVbkJTcGdCWFpMTnlQVWFKWjN6M2hZei10THlOaVBVVXZCNnVvZk5BLU5zdTJkWjkxakE9PQ==
"I wish I were little big that time, I was a newbie at that time in university. But really appreciate this type of opportunities.",r/machinelearning,Z0FBQUFBQm0yeGJ4UUNIMGNVc0dkQVk0WXBjZ05iN1RiS3lkUWJNX0ZXQ2Jza2pYTTNEX3pWa0VEazB4cGQyS3dvNVRmX2Z0RDlfUUZJT3drZ1hzSjhuNjRxWVNCMzJRNVE9PQ==
Heueheuheueheueheue *menacingly*,r/machinelearning,Z0FBQUFBQm0yeGJ4NVR1WncwWkVDd2FMUFZSV3RlaElQbHpZRGNkUjF4Mk1YeEVmazl6ODE1LUl5V0JhOEdORVNOR3Q2TWpObXFrdTFiXzhsU1k2cllKV0prRENsZ3BVS1E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ4V0d3UkgyMm1sWm9KTUNJeXI4Y2Yyb083b2dmQzAwSVJFSE56VHp3UUpIVzVqaUN0OHFrUGd4dEQzZHZiSnFxakdOWTZLU2FiS1NxdGdIS1dkWElCcEVnXzQ2bmY2M0FCUi12MlVXQkxETjA9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ4QmFyYXRxQ0hoMnUzWTBweGZyaWxqajdUb3hJOTdaakduc0p5VVEyOUE3dDlZOVI0aDR6TXZoc2EyYzBzb2xmUVNDQWxTTkU5cDFIeGtiQ2wtODM2QjAyMTVBRXA1X1FMVGhnYklKdWRZc0k9
"It was an asinine question to begin with, since different labelers have different speeds. Guy wants a double blind trial for a free repo lol",r/machinelearning,Z0FBQUFBQm0yeGJ4WnpubklRaTItck14TDZSRHFJX1kzWU5FaTdzN3JHZGhfaGpldW0zR3VCMXZMaF9ISjVFd204ei1PWXZuSHNneEJISmdIRDZNeXowbHE4SE5vZjBCNGc9PQ==
"Thanks for your kind words

Please let me know if I can help with your research",r/machinelearning,Z0FBQUFBQm0yeGJ4WnE0OHJHNzA5V21TdFJWaG9YejFYemgyT2I3NkVqcmZtTFZ0Mzh5TUR5eTNZNTNYNTlReEN1Wm5mR3VDSlZRWmM4Tlk0TzNmcXlmeVI3TnVRNzBqTHc9PQ==
"The demand is in application, not research. So: APIs, prompts, RAG, context windows/tokenizers",r/machinelearning,Z0FBQUFBQm0yeGJ4WnpiTlRuYU1EbDM2OWo3Q2xjS01tUnJES2RuZURiMzNldmsxb1k4SVJGWmxuNUc2eHktY2pzZ2kzWnJ3SDlLTGlMd2JqeG1EVWFqSDBLbHFISUg4dHc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ4VW8zYWJ0R3dNb2dxdnJmR0tDNllFcHJhaVZWMko3NndsbW9pLUNDNEdScFhRRzlWVFlQb3g0UEllZzVyMC0wOF9BSHVGRGFuLVQ4eFNUVGJqWVdSN25PUWlMQmp6R0JJQXNHWU9SUXdsN1k9
"You are welcome, Dr. keogh, I would like to reach out to through the mail, I have been struggling with multivariate time series data with Matrix Profile. I think you are the only one who can help me.",r/machinelearning,Z0FBQUFBQm0yeGJ4d2xUcUtycFRLdzB3RmUxc29XVk9pb3puY1dvSFVWMkdDZXVRWUZZYl9kOXlhcmxpZV8wX1JrMU5YNDBNVWRyaE5CNVZuU3U1WmwtQlp2cGVGaUxuVUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4bFFlMW5WZUFTVldYRjhybTQtTFg1aUZzRXBFZnJYMHp6VXRPcHF5NXNvWUY3OC05RUNkd29mZUxpQnJ1ajJza3I5OG1BLWhEWGt4bW80WXlHUEVTdlE9PQ==
Yeah more or less,r/machinelearning,Z0FBQUFBQm0yeGJ4Z3VlcVdQT241SkJ6Nzhra3ZQRlNMSEg1Vm1OSmxlcVRkclFTQlhRX1Bha3RienpQZkVyWExnVGUyakFaTEl0QnpvVnYyREpmU0UyWmZOS1AyZmhXaWlieDFheTlXTTlQWFdJZG5EQ0YwM2s9
I find 4o really stupid. gemini is the only model I use lately.,r/machinelearning,Z0FBQUFBQm0yeGJ4X0R0VmJGU0ZjaWZqRXIyVVlaNUFxV3VGbXFRQXNraFVTSDBZZ2tKbzB6VTNuemU3LVpWSWZUbVh6LWhIX2d6ZUVwUFBYUmY1NHNjWXFaek9rTWc1Vmc9PQ==
"Certainly, thank you for the question.

Overall, the process requires two datasets: a collection of songs with genre labels, and a collection of image generation prompts with genre labels. Ideally, the sets of genre labels are the same for both datasets.

For the song dataset, I collected creative commons music and normalized the genre labels.

For the image generation prompt dataset, I took each of the genres and asked ChatGPT (Turbo 3.5 API) to generate prompts specifically for that genre. I collected around 300K prompts and split into training and validation data.

Some example prompts for the genre of rock:
```
A roaring motorcycle, speeding on a desert highway, under a blood-red sunset, dust clouds, rugged terrain, dynamic angles, warm tones.

Massive waves crashing against jagged cliffs, stormy skies, lightning flashes, foam, power, contrast between dark and light, dynamic composition.

A towering inferno in an urban wasteland, crumbling buildings, billowing smoke, flames licking the sky, chaos, destruction, intense heat, fiery hues.

A majestic eagle soaring through rugged mountains, against a fiery sunset, dynamic angles, piercing gaze, vast expanse, freedom, rugged beauty.
```

The prompt embedding auto-encoder takes the _output_ embedding sequence of the SD 1.5 text encoder and encodes it to a single 128-dimensional vector. Here, only the image generation prompt dataset is needed at training time. The encoder and decoder are trained to minimize the reconstruction error of the output embedding sequence. At training time, 10% of the encoder inputs are randomly set to zero in order to make the training task a bit more challenging.

For CycleGAN training, both the song dataset and the image generation prompt dataset are needed. The idea was to apply the ""style transfer"" from CycleGAN, but to separate modalities. The (source) generator input is the audio embedding from a random slice of a random song in some genre. The discriminator takes the output of the generator (or of a real SD embedding sequence), as well as the label of the genre, and has to determine whether the embedding sequence is real or fake.

The generator is a relatively simple FFNN. For the discriminator, the genre label is incorporated through FiLM layers.

I did not have a proper evaluation method for the CycleGAN part, so I kind of winged that. I'm sure this could be improved.

There's some detail I still left out. I should probably take the time to write it up properly.",r/machinelearning,Z0FBQUFBQm0yeGJ4eklLQVd6aWMyZFVvamxsSG80NEs1T3prRU96dUtha1FPeFpZOGhLdnZyM0hpQlN3SnBJRVhxbzU1aTBGa2hWUWhBeno2bkdMdFJ6b2Zvc2g5ck5iVVE9PQ==
Wait what does it mean your first big iron? Like you own those supercomputers? Or are you part of an org that uses them?,r/machinelearning,Z0FBQUFBQm0yeGJ4ZW8yT2JVR1BSQjlOb2tQVGJUZ2NDYm8xRVRFYUpQbGdtbG1XRDZqS0dkLWxGbmhSckh1bEdBdHhJVFB4aFZRS1BsVE9zMURmRElQYVl2NmhjVzJjX1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4TklXN1Mtc05qd1lKWWRRT0tWb05iY3FCcHNzNXkzbUFXcmMtY0dzTXRScnowWVpONVlnR2N3azd3YXYwSzVsbmJFcmVfanRaaDhXU1VaN3JobnkzUXc9PQ==
Hahaha right??,r/machinelearning,Z0FBQUFBQm0yeGJ4dFhnNGZaVllYMG44YllKZV93eHdNak9HUnZvX1NDbmpWejBWRVBkSVVqcDlYeXMwNmhFRlhVTkRxM1FVVXJYNkthaFVGdEJTSDgtTlVickhocGNTbFE9PQ==
What about the comparision to tensorflow-js? Can I use a torch model in the web?,r/machinelearning,Z0FBQUFBQm0yeGJ4bzEzTHc4VFdtU3NabWVzd2hoNU03MVRtd0VqcjR4TEZ0Z3RTTmhTbEdaQzU5M3E0M3pGdy1WcGhPeGhsdnJDMXEyY20zOHk2WEJpQXI0QTdobUc5R2c9PQ==
this guy has a 3 part video on grokking. I highly recommend it https://youtu.be/QgOeWbW0jeA,r/machinelearning,Z0FBQUFBQm0yeGJ4cWc3LVFsTmdBUVRQS01lcGtuRFhLelJyTW5fTk9TMkVPX3ZGdW4wblB4eHh3TTByRWtnTnJqR1lvQ19GdnRXRHM5elQ4aUlsTXUxa0p4dHR5VFFRdGc9PQ==
Megawatt is not a measure of energy. Watthour or joules.,r/machinelearning,Z0FBQUFBQm0yeGJ4b3JYMG1MeTJjeVA5TFpvT1c0Rzl6QzBLcGJiT0lrc2xwRzlLZHVpcVFhOGtiTTRLaldnTUJXV2xqWEtHTTBUcXBIdjQ3X2t5NE5Xa19RTENuM0xBalE9PQ==
This hybrid approach sounds intriguing. Has anyone explored homomorphic encryption for LLMs too?,r/machinelearning,Z0FBQUFBQm0yeGJ4VUN0Nk9kVHFBakhQcXhfRHZSRUJsVVIxZUZCd3B0VkFmVmRHUzFGeGUxNzhwX1B1NGJDdUttbHF1aWl3aUxkenJnUEVtWFEtMnJqR29aY1Vab1YyREFTQlYyMUZEcXowT0pya09SZkZyQTg9
"Check out the proof in chapter 2 of ESL, it explains it thoroughly.",r/machinelearning,Z0FBQUFBQm0yeGJ4SHdobmdnUWNwZTR0ajZxdlFiM2xJcl8taF9KSHMybEY4eGhSVkozWmtSSWxUNjN5cmdhNDJrM3FKTEU2V0wyc0tvQXNPS0ZScnFZeHJsV2NicTc4TWs4eDMzLWw2X2RMTmVET25sdDdhaTQ9
"Start building relationships with profs in your desired field, it'll pay off later.",r/machinelearning,Z0FBQUFBQm0yeGJ4TEZJYU5Vc3hnUzR2OVgyN1ZuQ3ViUUhvaTdXcWJNel9TMHpJcW5HVGZwOHFCbE05dUt5eGZVY3draUI1bXJIYlBpRzAyUzRXUVJEVi1xSDk2ejhhSDU0LXJzZV9aUE15Ty00ei1PNGlleGc9
Have you tried adjusting anchor box sizes or tweaking the backbone model?,r/machinelearning,Z0FBQUFBQm0yeGJ4THNERjNVQmk2cnVpVVRoSHlkWU5KRGxzdGtua19wc3lVaFBKX2FsTXFmLWpZbHdkWmUtUVd5cndOcDFvWlV0cDZNWnMyM3pEQVZDQ2VUaDVPZmJNYXVfS1NtdHJNTGV6NzhpY0hpYjFKeUE9
"Some books like that have already been published. They are not specific to machine learning but they would not need to be to address many of your goals.  For example, see: https://link.springer.com/book/10.1007/978-3-031-10754-2",r/machinelearning,Z0FBQUFBQm0yeGJ4RXRDWXl5ZmVPLWZScmdFcHZOY05JNTdWdWVOc0VBMVNBWUtjN05BSlVxM2xLOVlsbzktYVpYdkdxTmVYay1GOEZ0NkhBdk5GLTc0c1ZVWkVyRGRScXc9PQ==
Dont. Start working on hard problems in the industry.,r/machinelearning,Z0FBQUFBQm0yeGJ4R2dFdUpfcXNLdlhoTlRQLWJoZ01Nd3BIRmczY25KQW9KZnFGMnRmODlKWUFTSFdDYWFtOUx3UlhUSjFFT3R2QUVUYzZXT05XbVZLR0JyUEh6Nzd3UW1RZTZUekV4OGxsdGI0YWxzNzN6alk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4S3BNS01TY185aHNmMjlybm53dWEzX2pxTzlmam9NbWFqZmMzcVBaMHBIS0RnVTJhandhdU9lR1pRd1pSTzFNekF2SU0zbDdwRkRKZnJVUlRSYTZEeWc9PQ==
No. Can you explain that to me? I just used the default configuration,r/machinelearning,Z0FBQUFBQm0yeGJ4T0hCdlliZ0t0cHdMVlJ5Wmkxa0xpa1AxNkp4Z2prYXpkQnVZQkgtQ09uOEpmb19TSUdIYm1mS1JNZDlPeUJmWHZZX0ZaNElMMjNZNl9XMG1YOUtCczNqT212aUVsMVdMVEFtQjVGNy1HMmc9
"Two different companies.   CDC in the late 70's early 80's, Cray in the late 80's until they became hard to justify in the late 90's.",r/machinelearning,Z0FBQUFBQm0yeGJ4RXBTcXlNdllUZ0t2d2lnZTQ5SEFfenp5cHRvckxPcTN1bXJYRDVua3I1WXpNbDJud185RmhocWRPVUpoZ0g1UGMyNGM5d3NxZ3VJUjdHNmw0MTI1WGc9PQ==
This is quite recent. Thank you!,r/machinelearning,Z0FBQUFBQm0yeGJ4eG5QVmEtX2lLTDljeVh2WXc4ZnFIb0ktRzJGcnM4R2ZXR2htcGQ2SWxreDgwVk5qc1VvS3lqMlhQODc2WVYwamxLdVpCYW9EVTBrbG9PQ0ZsRDQycEE9PQ==
You're welcome!  I hope it helps you or your friends.,r/machinelearning,Z0FBQUFBQm0yeGJ4MmtZNzZuRVMwN01HN3hvcDVsSkRmZzR4TXMyUElOU0J1UG9nTkVOUlJHQ1pUSzliUUhQVTNoNDVzTHVoSS15LWZGVjUxdU1vcEctc2NVTWtBLV83RXc9PQ==
"Research engineer usually only requires master’s but I don’t see companies accepting non PhDs for scientists (it’s definitely not common at all, they will pick a phd over non phd any day).",r/machinelearning,Z0FBQUFBQm0yeGJ4Y2didTVqdEM0Q2o5LU44eXRNZU5QUTlfbG5EYUZtX2VFR1dWTjRIdGRfQUJUYXdWRFZrb21aU1h2b2dOSFJmUTNFRHRjZUJtY0pFT2VLUFpIbGxtV0E9PQ==
"Yes, there are some researches around using FHE for LLMs:

[https://huggingface.co/blog/encrypted-llm](https://huggingface.co/blog/encrypted-llm)

But it's pretty much slow for novel models and depends upon hardware innovations (new FHE accelerators).",r/machinelearning,Z0FBQUFBQm0yeGJ4YmpNVlNvcDl0VFRZV1BlMFVvcmdhSWU4aHV5anU1MGJ6Nmk0R0w4VTlKZUlza29aaW9UdzhCMGFXOGZwLXk3QS1DVEFWMzg3UzcxWmhwU3FSaXg5UGc9PQ==
This is a great idea! It will help keep the subreddit organized and make it easier to find answers to questions. Thanks for starting this thread!,r/machinelearning,Z0FBQUFBQm0yeGJ4R1BHQjJobGVFbzlrQkM5dFgwem8wNWNMcUZ1Mmd2RXFLb1FIWTRpbDRjUjBuUFplZ2xBUW5GUHhidF9vZ2FoYUJkTmlSUzQ2MFduWWJYYzRJdEJKeGlSUE9YdzVPOUlUUC02bDdoa2J6V0E9
"If you want to predict a real value from a time series, as in the equivalent of a regression task for tabular data, you might want to use the keyword ""time series extrinsic regression"". It will lead you to some work that are predicting a real value instead of forecasting the time series values.",r/machinelearning,Z0FBQUFBQm0yeGJ4RkZXU01JYmx3Umt1bnJUMURFNENTOC1fX0dfSy11WDVhMk00bF9TWkY5N1d4VktIVElQaHc3SFFuY0VqMmhuMHBDR2UtWUVhd1dtdmNpUWhZbklaYmc9PQ==
"Sorry - I can see how you may consider a my comment directed toward you personally - it was more a jest in general for the gpu-poor 😅. I definitely wasn’t clear and the wording does indeed reflect a comment intended as such. That said, I was questioning my own comment when writing it because you were already using mainframes. Maybe it was late? Lol my b. 

Anyway, I trade fx and have also considered fine tuning a model on time series data. I just I mostly thought I was just crazy 😜 but happy to know there are others. I bought a supermicro superserver 4028gr-trt and put 8x Tesla M10s (mostly for the vram since they’re more for desktop virtualization than raw compute). Got it all for a steal so figured I’d do some testing among other things. 

If you build something be sure to update!",r/machinelearning,Z0FBQUFBQm0yeGJ4cm1mTTlwOWgzdUtseHVQbzJ0LTFVZGFzOXByckwxTHNmaGxCa2RqSnN0Njc0RmpZajhBaUtFUGk2MDhPMC1HUVNkWFN5YzhGdjhOTkUxNnVNYTlFTGc9PQ==
"If you feel like writing a book, one idea would be to write a book about all the hundreds of software tools and databases that have been augmented with AI that can be used to assist people in academic life, whether they are a college student or researcher.  You could start with the 250 tools linked to in this article: https://theconversation.com/new-database-features-250-ai-tools-that-can-enhance-social-science-research-226215",r/machinelearning,Z0FBQUFBQm0yeGJ4eS02NUFKVWRMS19YQmJEU3d1S0xDZFRiUkI0SHIzNnBPQW9nSnM0dG8yYkZiQkFmQ2hJbVpmZS1wQUwxY3dTbFE5WkQ2a3lwZ2hlNmlXcEZqUFliWmc9PQ==
What happens if the data swipes back and you get a match?,r/machinelearning,Z0FBQUFBQm0yeGJ4Qm5RbFgwRmxSOVhjN2F6NDNTeko5dzdFckxKbVJOcFZwOUpGTjJUNERWRjZmNzRuVzhnUkdFOU9IX1UzTUpMYW9QQmpsa3kyaDNJMnVhMVVOYnV5NUE9PQ==
"Oh and to answer your question:

1. AI and Machine Learning Research
2. High-Performance Computing (HPC)
3. Cloud Computing Services
4. Cryptocurrency Mining
5. Virtual and Augmented Reality (VR/AR)
6. Rendering and Animation
7. Data Analytics and Business Intelligence
8. Edge Computing and IoT
9. Development and Testing Environment
10. Education and Training",r/machinelearning,Z0FBQUFBQm0yeGJ4R1g3WkQzdXEySzR1QTlUY1RXZnllaG5lUHlMTEFXdDdTU2htNGlCQzNDOE1LNDRhcFZLd3dKRDNQc3otTnBGcFlSLTFZRlZYcWplZkhhZXRjUFF2dEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4c0pEQWJSU3owblUzb0JsV0c0X3V5QWNhSm02YWpiOTNKdnh2TmRNdDY1UXU4WC11d1gtN1I4VU40dWRrSzBPNUdyZV9ZTTkwXzlyclVSU0FNTVJGa2c9PQ==
Unfortunately not but thanks for your input,r/machinelearning,Z0FBQUFBQm0yeGJ4cmFJLW1JZjRyeWhkdEJaY0tYOWlKTEFmZXpMNXFMdFp0OW80X3hBUUFhN0E3cjdsaUlvQnlHT0ZxT2ZiZTVkQ3pQU28tVlU0VkdWblFmbnVySUF0TGl2WXd3MWw3MHVGN2UwZ3RyYmZGSlE9
I just want to use a transformer to predict so basically use the encoder part but I just want to be sure it is accurate,r/machinelearning,Z0FBQUFBQm0yeGJ4QjdIUlo4QUJ5TUdvb2JYTzc1eEVNdFBzcUtNb1h3R2FUUXo4MmI0Qm5mMmYzTjU0NEgzanhGRUt5YVJYdWFsR3ZYTGdKRmVKVlZYcmRiUXBjd2lYQlNUWkhHNWJhelNpNlBBb1dPc2dpbjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4T21kV2VXX195UWhkTkJGUGg3WHFyanhwbGdZN2JuSEVqNnZuLXlTUGswd1hvVnd6MHRhcWN3Yng5WjlESlRWaU9RZGVjamliNWdjT19uY3pXUThmVHc9PQ==
"Personally I have a dataset of random chat logs i found and trained it on, including old Twitter, so it has plenty of 4chan like content, and there's lots more on HF",r/machinelearning,Z0FBQUFBQm0yeGJ4Q0xGWEhvOG1nT3RfNnI4dXVSMjBCUUZwVzFhdVgtVG9sTHE1V2s2c3laTXFxcmphVEpTQ25ySGE0enRYYXV3Rlc4NVUyQ2FGTGdOdWg1dUFlYlJtQUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4U3UtRXllQ0Q3cUpYT2dTREhsNEZaMlc1TFFvRlRkRUpWU0tDMHRNaHdPZ2NhYTY3Zi02QlowWF9VSFZYVnlDSUtwaGtvbTAxaXgxdGM2bkxnTEZYTkE9PQ==
">the types of failures for an LLM that are unsurprising if the LLM has no understanding or ability to reason, but highly unexpected if it can understand and reason


These terms are rather problematic. First, the sheer ambiguity and inherent anthropomorphism of the term ""understanding"" makes it rather useless when applied to an LM. As long as we don't aim to replicate human-like cognitive architecture, which, I think, is well beyond the current goals of ML. The more neutral terms are performance-oriented. They allow for a fair comparison of a human and an algorithm without enforcing non-essential requirements on either subject.


Second, the ability to reason is non-binary and cannot be fit into two discrete categories, ""have"" or ""have not"". Such false impression most probably stems, again, from anthropomorphism. And the fact that most humans have roughly similar level of this ability. At least compared to the possible dispersion in machine models.


Failures at certain tasks, perhaps different for humans and for algorithms, would just highlight different proficiency profiles within the broader landscape of reasoning abilities. The view that humans are the gold standard and the absolute ideal of the reasoning skill is quite naïve.",r/machinelearning,Z0FBQUFBQm0yeGJ4U2sxQUNETVJOc1R0LTV1czNaWGxjVVhoT0xSbDJSUTViSmtZaldzRHRTUGJ2VXdMU1ZoY1I4OTQ5SHlDb0RGNWMwSmVRMlY1TjNMUzdJY2VkLTU5NFl1UFh0VDViZmVxQV9vVVctZEtLcnM9
"I think you see a lot of implementation complexities in this, which I find unclear. Could you please explain these complexities a bit more?

Many frameworks, including PyTorch, support model splitting and parallelization. We can use this feature to split the LLM into three parts: input, middle, and output. Each part may include one or several layers of the neural network. For example, consider the BERT-Large architecture:

1. The input part on the local machine receives the raw input, tokenizes it, embeds it into a vector, adds positional encoding, computes the first couple of encoder layers, and sends the result to the cloud.

2. The middle part in the cloud computes the next 20 layers of encoders and sends the result back to the local machine.

3. The output part on the local machine computes the last couple of encoder layers, the linear layer, and the final softmax.

In this scenario, the local machine processes four encoder layers, tokenizes and embeds the input, and performs the final linear and softmax computations, using relatively few resources. Meanwhile, the cloud handles 20 encoder layers. With this approach, the cloud cannot extract inputs and outputs (because the cloud does not have the proper info about the parameters of those four layers) while handling the heavy computation for the LLM.",r/machinelearning,Z0FBQUFBQm0yeGJ4X2g4ckszOGo5QW5oNUl5YjVkdU5NWG1ZSnFSb1RtZlRKVlc4aUhxMThIQ1VTRDB2Z3AtczZQekk5MWw2U210RUhUeHEtTS1BWlBNbDhNU1RXWjBmV3c9PQ==
You could just use a decoder only transformer where the output layer is transformed to the regression dimensions you are interested in. The model should be able to learn to map sequence to a real value,r/machinelearning,Z0FBQUFBQm0yeGJ4cU5Sano0ZUUzVGpmdUJZSGNZYmRyakxCNUdZVUFMRGVScXZ6dWhGTVpsd2FZLWJBUjJSNHBQUjgzbndvMUYyeWg0M3B6dE9PZ0NJNUxIN1NCRHpxMkE9PQ==
I am just using the 4chan API to scrape /B lmao,r/machinelearning,Z0FBQUFBQm0yeGJ4UzU1NVhZOTN3cExMRW9fZEZpRnY0WUNqUDluM2pscmk3VmdMLXg5Z3dRaFdNWGhFTVNqX3hlVzFpQ2t5YTd0VTdFN2tfem4zRFcyMDVKeUc2SjF6djJYemQzTGkyTlYyRFV4QUJRd1daN0k9
Should I use the decoder or the encore of the transformer ?,r/machinelearning,Z0FBQUFBQm0yeGJ4RmNERHVaRzU2Y1p1amJVZW9qV0JCYU5oenZsYWYyYXlYeDdlbHJXazZtdnRVdzlCWTBGVzhUdVQzVndWZnlBRzQxeU0zeTJWZWdBc0hOODdPaWY5NmI4SWplMHRQOVF5MkJFLWw3RGZhUkE9
Did you try what they suggested? Was it any good?,r/machinelearning,Z0FBQUFBQm0yeGJ4ZzNFT2VqZE5DYjZ0eEV6QlBscTJkaUtsX0ZJRTdsWHdyWFZKMkJua1ZlVm5ha2JNdXJVVFVQMm1GUDFYbHM1VmFHc3RHV01zSHJrLS1JQWRvemVPS24teFRId3RzTWw2YzBqZURxbmxfUGs9
"So you mean just create a voice clone in RVC and use it with XTTS v2 right?

Also have you tried any newer TTS model like OpenVoice v2, ChatTTS, StyleTTS, etc? How do they compare with OG models?",r/machinelearning,Z0FBQUFBQm0yeGJ4ZWtBcl9INzZmZnR2NWxiMVhjYmg5cmRKd2x2SmJaQ1ctRW9Kc1FZQWIyNGQ4Z2FBY01oWVRwQmlrWElnZGVocEVRZE03QTN3RkltSHp5Yndkamk4VEg0ZWZMOU05T01ZMkNUYS01MVFOS289
"give [astronuts.io](http://astronuts.io) a try, AI code reviews and error resolutions in your code. Some cool features in your pull request like code quality actions is the first of its kind. [https://github.com/marketplace/astronuts-app](https://github.com/marketplace/astronuts-app)",r/machinelearning,Z0FBQUFBQm0yeGJ4Yi1XR3ozaVcwNXpJSHJ3bWZKVm9fQ1dKYnBnYlZ1cUZxOEZZNE9zZkx2V0FlYXlvWDRadnZ6Rkp2RGZ4bkw3dER3ZTdKY3NXVVlPcGZQN1dwMGdNRUE9PQ==
Depends what your output should condition on. If you only have a sequence then use a gpt style decoder only transformer. If you have some additional source of information you want to inject alongside the sequence then use a full transformer. If the sequences are complete you could also use an encoder only transformer. The only difference is that you won’t use a mask to disable attending to future values. This would be a bert style transformer,r/machinelearning,Z0FBQUFBQm0yeGJ4ZGIxRmhyMnFGTEcxUE1tWHVLWUYybEFUeWpWSVFhaWhZRmU1dDItc0YwQ1Y5d0dENUtMVmsxekcwY1hBNDY0b2pmdERyeEVDcTRTNmJLT0JBeUJlZXc9PQ==
"> I would like to pursue a PhD after finishing university at a good university in Europe or the USA (not necessarily the top universities), for example, Max Planck (so a German university like TU Berlin or Tübingen), or Paris, London, or others like Purdue University, Northeastern...

Purdue and the TU’s *are* top schools. 

> Firstly, how important is my GPA?

GPA is a filter more than it is a decisive factor for admission. Most schools won’t autoreject you on the basis of grades as long as you meet a certain cutoff GPA (typically a 3.5/3.6).

> What extracurricular activities do you recommend I engage in during the year or in the summer?

Anything that will get you closer to publishing something meaningful in your intended field. 

> Would you recommend becoming a summer research assistant in a lab

Yes

> Who should I contact

Professors you want to work with 

> and when?

Right now",r/machinelearning,Z0FBQUFBQm0yeGJ4c09wQXZkMElSU3I1dzBwQ0picDl4dF9zTXROUGxub3pUZDJmYkRsMjl3OElSR1B2ZDQ2Y0lLVmZEQXlQMmV0WGtXbTJJTmlDcnBOS0FPTjFwYy1MblE9PQ==
"I think we could reasonably claim a plateau only once we have 10T parameter class models and there's no longer any relevant improvement in train loss - so we know the scaling laws stopped or at least slowed down too much. I think most proprietary top models are in the 1-2T parameter range, which would explain their sameish performance, but this is just speculation (although Nvidia kind of leaked GPT4 having 1.8T params).",r/machinelearning,Z0FBQUFBQm0yeGJ4S2dRY0J5c19OTnJmV0p4SHMwOVdVX3pRTzF0M0paUDRoRkRkeUk3SG5fOGpBVjhERHdKNjhHV3cwejhTMXFycHIwMWZWSkpjR1ZXWENrcEdBcFp6TzdkNXBmRVdEMllHeW04c1JMajlsMFE9
"Are you saying ""reasoning capabilities...are ultimately unrelated to....the capacity to reason""? Help me understand?",r/machinelearning,Z0FBQUFBQm0yeGJ4TU54cGhacFBxV2hfTXZuaXhkOG9aUmtNZ0lBNVIyb3Q2a2hGSjZOOWdGWjlGOEx2MWprRmlpeXZqNWE1dHlTOU9helZBdlp1dUU3Qmo3TUJiVVBLVHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4eXo5b2tDaHZRN2ZWSVlfd1JIWGFXMnhjRl9jbEhmc0ZuTlVzeE1CVmhyQ0EyaG16U2hXVVgxOFZNbnhqV1dpbDBRREpPSzNRNkgyV2FGOHliRktCVlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4X2F4dk1UVHpsbUpMUHVMNkhJSGR0ZFNydlhmVDk3REJRY3A2T2VYdE1hMEZpYUNTY29QOVpkZXBrcTZtdDN2aUFwWHRCN3NQbkp0QU90YVBLSlVqckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4dGNidy1LNWVVaHFlSndDLWJRbjAxVy1hSW9jX0ZvaEtyMGtkZXdCbE9IOEctMWVRb2t2Q3g0Wl9pWGVWS2g3a2lGdkxVTnJFdGNvcmkwbDdaOHQ0Smc9PQ==
"Bad wording on my part; I probably should have said ""analyzing the **supposed** reasoning capabilities of LLMs"" instead.",r/machinelearning,Z0FBQUFBQm0yeGJ4aFpiUXJoSnk4YlhkREFYbVIyWG81VURaS3NXZmZRS3VBbmJoZmxiRmhNZWUxaVh0WXdveWpxeWJ2Z09lblFsWE5JREVYNWFKa3lySHp2THFlcGxCblE9PQ==
"We are facing a similar problem. We want to let the user ask for events about specific topics. But also be able to respond to time dependent queries like “when is the next event”, “what did I miss this week” etc. Or is this problem already solved?",r/machinelearning,Z0FBQUFBQm0yeGJ4VHh3UWlhSW92OVd3Y1JMSjhGV0k3bVR5RFdIMVVYSUVWZmNEc0RFT2pyTGl5dGxjcVFNNU5JYkc4aWl4anN3UGtrbmszaTcyWndTLTQtdjRYaVNFQmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4LWNvYzdjWDJyRnlhdy10R2hiRUFLMGRMLW9FSFJyRFBBYnZ2TllOdlAwYzd1WUUxUHlxTHpaa01rSzBQc1pieU9seDdsTnNoUTZLWW9vamVKcXRtWEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4OXBoalN1eFFZeGdnMWpGZlVkYXRiYkNjNmJxOHZMT0VWN000Y3RvMHc1anZIZWFGMjB2M25PNUQxbjNxdXBnQUJiMTdWRlNQRmVfeGYwSVhUUG9XSlE9PQ==
study this [guy](https://tspace.library.utoronto.ca/bitstream/1807/36012/6/Ilya_Sutskever_201306_PhD_thesis.pdf),r/machinelearning,Z0FBQUFBQm0yeGJ4WHE5NmJMbWEtVV9ZWW9qMF9MUThJcFYxYlNBZmNwaUVfZU8tc2M3SXhGcnN6MV81Um8tZndRZ044Z1Vsa0tXdF96MnlEeUdKZHZ0d0FTZFJZYU9mQkFrTlNveUJVR1FGU19TblBEV215WFU9
The reason these platforms treat students as second class citizens is because students have no money to pay for services.,r/machinelearning,Z0FBQUFBQm0yeGJ4eFZyOF9LcWxVYkU0blJpNVRBQndFM1Nxa2dqSFUwN3ZwTnltZkZiYjFyMlBUMXJ3T1Y1UkN0RXFQRm12Q19qc3prczJfcURzQ1ZWZ0QzeUFGX3B6dVE9PQ==
How about we charge minimal but take student first approach?,r/machinelearning,Z0FBQUFBQm0yeGJ4OU9SMlAydWtIYWFqR2t6WHY1N0JsaU1XU2Rvck53c1c2SWRSaHk0M0hZa0pIVVlqbTBEU1Q2WV8xMDhYdkdvMVRrUk13UVNKWXByUVV3eXoyX0JMLVE9PQ==
"sure, go ahead",r/machinelearning,Z0FBQUFBQm0yeGJ4LVZoWE9PU2hhaGNCVTdtUFFQdi12NnpqMXRuUFRCTUhFeXdfQ2hKQldiN2swLUlaS1JDMFVjbVFCMUIxbjZwdTlMekM4YmhEVVFxWXJtYXBWYjJVX3c9PQ==
"I didn't want to assume hah. Alright then. So what about reasoning as pure pattern-matching - something that can be done lingually and a-lingually? 

[Evidence suggests](https://www.harvardlds.org/wp-content/uploads/2019/04/1568539X-Behaviour-Logical-reasoning-by-a-Grey-parrot-A-case-study-of-the-disjunctive-syllogism.pdf) that despite having access to language, Grey parrots do syllogistic dysjunction without it. You seemed to place this idea of language-less reasoning in conflict with research into other-than-human reasoning, so I thought it worthwhile to note this example where the two seem deeply related and complimentary. As I said before, it seems reasonable to assume that studying LLMs could yield similar insight. 

GPT, which is lingual, and ultimately ""just"" a token-parsing pattern-matching machine, can answer syllogisms. Syllogisms are essentially just pattern-matching problems. At the basic level, there is nothing more to them than pattern matching. To do a basic syllogism does not require semantic understanding (as the real parrots show), so even a ""stochastic parrot"" can reason at some basic levels. It's demonstrably true and claims otherwise demonstrably falsifiable: ask GPT to do a syllogism, and it will. While obviously there's vastly more to a human's reasoning toolkit, this is one component of it that LLMs can do. 

This is my view. It seems highly controversial because bringing it up on here always gets pushback, but to me it seems self-evident, so I'm curious when someone says the opposite seems self-evident to them. Would love to hear you sound your ideas out if you're willing - I'm very much still learning in this space.",r/machinelearning,Z0FBQUFBQm0yeGJ4aEo4eklUNzM3ZThTaVN2blNhSGRlLUwyU2VYcDk0TkdGT0pLZWw0VngzbjVUSGgyM3VCV2VmbEFKUzBjekFFSEZ5RjJSRFRoY210b3VZUjlPcUVzWVE9PQ==
print out ALL of the data? lol good luck there pal,r/machinelearning,Z0FBQUFBQm0yeGJ4ejlaNHlrVWRlX3BxOUlxUDkyZHo5Q2pDcVZQLWdYbk1SVXd2cDRrR1NkbmxTdUE2ZGVTM3VrVHVMMkZRUmN2LUExR0RhajdTcVQxX0J3ZmpjWVpLMTRzTWRJal9SMGg0TzVZdXlJeWZrcXc9
Dr. AI i presume ;-),r/machinelearning,Z0FBQUFBQm0yeGJ4UlA5b1g2YmRvMVF1TjJrX2pxb2FDN00wOG5PU3VGVDRqLWI5aTBXTUdnSlpKS2FOczg0R1BEbTdneUxXRkdSeF9mZHpvTzlaVWU0VlhaaWJRVDJzTTExOGY4Mms1LS1Gc3ZiNEJtZThDSkk9
"In my mind the distinction between reasoning and non-reasoning is partly one of efficiency and extensibility. 

One could imagine a hypothetical ultra-computer that has rote memorized every possible problem statement and its corresponding solution; this would give every appearance of being able to perform reasoning as a human does, or even better. But I think this doesn't count as reasoning, because this computer is essentially just a giant lookup table that doesn't use any form of compression or abstraction in order to arrive at a solution. We could also imagine a somewhat less impressive ultra-computer that has rote memorized many problems/solutions, but not all of them; not only is this still just a lookup table, but it doesn't have any procedure for using abstractions and algorithms in order to identify solutions to the problems that it hasn't already memorized. This is very similar to the situation that we have with LLMs.

I think there's also an under-appreciated social dimension to reasoning, one that is different from just pattern matching or problem solving. We don't just reason in order to solve problems; we also do it in order to communicate with other people so as to solve problems collectively and build social bonds. LLMs can mimic this activity if you have them talk to each other, but ultimately they're just regurgitating scripts; they aren't capable of the dynamism that is demonstrated by humans interacting with each other.

And indeed I think all of this can be seen straight forwardly in the way that LLMs are trained. They are quite literally not trained to be able to solve the math problems that correspond to what we consider to be reasoning. They are trained to do regression, nothing else; they can repeat acts of reasoning that they've seen in their training data, but they cannot produce new ones. Contrast this with human social activity, which corresponds to math problems like finding correlated or nash equilibria; these are different problems from regression, and they are fundamentally harder ones to solve.

It's for this reason that I see game playing models like the various Alpha-whatevers, which use monte carlo tree search or reinforcement learning, as being actual examples of machine reasoning. They're just less viscerally compelling or emotionally affecting because they do not demonstrate their reasoning in terms of human language.",r/machinelearning,Z0FBQUFBQm0yeGJ4eDV5V0thSGt3WkhJOElFM0ZGZ0x3WHNUSW9CVGZQdUFpeFdnTXJxcnQ4dF9ldG9iblE3ZU1HaVVoUFBqaFRfaTNScDRldjlWZkNXc1YtaVRCUllVV0E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ4RUFjeDNQX3o5amhQaHdtZ0VnRE1ZQVJuTkpsV1JIamFaTWhRNWRNbkdodXpIMndxSHFmeTZrRTNkVTVlVE5iRmZldjViOHM2YVhWS1FlT3pfeW5ueGVka0E3d3M1YlFXbnAxZy1zQ0RxQTA9
"Thanks for the detailed reply. That's a really interesting take. I agree with a lot of points, like the social dimensions of reasoning. 

I agree that AI like AlphaZero are doing some high level reasoning, and elements of System II thinking in terms of strategic planning, etc. 

Hybrid models that mix MCTS with transformer architecture are interesting too. I don't know what to make of [this](https://arxiv.org/abs/2406.00877), but it's cool. Perhaps it's an example of machine reasoning you recognize as such, but emerging from a (partly) transformer architecture?

Or another hybrid model involving LLM architecture could be Deepmind's SIMA, still in its infancy, but already seemingly able to generalize. It's a long way from System II type stuff, but it's intriguing to imagine something like SIMA with something like AlphaZero's capabilities.",r/machinelearning,Z0FBQUFBQm0yeGJ4UUdPSjgxVFAyMjhNVWo1VmZuRERzWUJ4elJndXpKbGI5Q0xxcjFqNVNQdlB1ZWZqRzREUnRKaF9QWG5HclNzbnVJaHF4clduc3VNMENmTlMtUHYwZHc9PQ==
You cannot master the field by just reading papers. You need to apply what you learn to perform actual research.,r/machinelearning,Z0FBQUFBQm0yeGJ4S08yRzRZa2pEUi1FY0pXRmlVVzVKdWRWSmJ1OVZCblU1S3hrQ2liNEE0QVJId0d5UVNPczdNUHQxeFRrZkxVU3JubjRXbDVVU2R6MFJLaHhXaFk1QkE9PQ==
Riffdefusion is the closest I’ve found,r/machinelearning,Z0FBQUFBQm0yeGJ4ZUpYMlpUYkNlM19QbDdydW9PdjB4U3NGVHFZYklGLTR4dUhfY1l6a1lkQ3U4SXRGSTFVTUQ1ZlJseUJGNHZRZ2dfUzNmTEtZWkpRQUpwbU1OS0Eyd3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4OTBWelRwZkhKWW1mblhfMHJmUHRLbzltbW5wUW1RRnFuSzdYcWc0d2swUG5DbHRVNUhJZk1keUZMMFBEZDVUR3hhM2NqX1YxdVN2NW91QUdaOUE1dWc9PQ==
"This is a cool idea. Not what you asked but just to throw my cents in, after a decade in research I found the best way to handle it psychologically is just to focus on what you can control. Judge each day by the quality of your attention. Results are fleeting and even sometimes transient, and a good result is the product of years of failure, so judging yourself by your results, at least on a short timescale, is a recipe for misery, depression and eventually just abandonment.

Failed attempts and dead ends are the only certainty in research. What you do have control over though is your own efforts, and as long as the quality of your attention each day is high, as in you are focused and deeply engaging with your problem, you are doing all you can do, and some kind of progress will come about eventually. With this mindset you can go to bed satisfied even during the inevitable periods of stagnation (and also avoid the allure of perpetually grabbing low hanging fruit rather than doing something really original, if such a thing is still possible in today's research environment).",r/machinelearning,Z0FBQUFBQm0yeGJ4ZkVJNWtuWDFaUjVoOEZnZG9Fd0ZXbmhmSnRHdWJ6MFhLZUhJb1RQUXRueHM3RjFIaG0zWEluMV8tcVk0T0xGMW5LREt1NnVwQnl1NXVyNmR6b1hVNmc9PQ==
"I think it's important to distinguish between transformers and LLMs. You can use transformers for *anything*, and LLMs are just one particular application. I think of LLMs as being a method of training more so than a distinct kind of model.

And of course transformers only ever do regression, but the real question is what that regression is used for. LLMs just do straight regression, entirely disconnected from any particular goal, which is why they basically just act like fancy lookup tables.

Alternatively one could, as you point out, use a transformer in implementing MCTS. The difference between this and LLMs is that, in this case, what the transformer is learning to do is anticipate the way in which interactions with an environment and other agents will impact a particular set of goals. The transformer itself isn't doing any reasoning; it's the combination of MCTS + transformer that produces reasoning.

People have been trying to do something reminiscent of this with LLMs, where they use reinforcement learning or monte carlo or something similar to explore possible LLM outputs in order to perform some task, but in my opinion this is essentially ass-backwards and will probably never work. The problem with this is that it's using the LLM as the environment, but that can't work because of what I mentioned earlier: the LLM isn't trained to perform regression towards the purpose of solving any particular goal, and so you won't be able to use the LLM by itself in order to derive robust reward signals.",r/machinelearning,Z0FBQUFBQm0yeGJ4aDJmYi1pVUtMNHR5ekxPOWdrSzExLWttdVF5WlNjanlCV1YwazhDMXZSSndwNDBPaDdXcjNuVnNCVzU5V1lzdmsyZm5TRUYtS3NXTm5ZcWxLa05kZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4U0diYmUtUjZlbWJkV1YwRnhQd3RESTk1Wm11U1M1T0RObVdCQnVteVMtWEpnMS1LZ0VYc0RpeGNjbkVXMVE4NkRQVmRGZnh2a3hrT0doVFRQWVpDR2c9PQ==
There will be more reviewers if you throw in that complementary conference registration + travel reimbursement. ;),r/machinelearning,Z0FBQUFBQm0yeGJ4YUNETHNBdVdoMlA4QmlfSC1kcGUxX1hhWWJ3ZkFNZDY0dXBLRkNMbldpbjlLNUNqSmZYLXYyWkMzbGhGR1VNS0pBRHl1anNXcTBsQU5oZ0RPZlIzVDJZLVNSUS13aFVJTDBSekpwbGsyTGc9
!RemindMe 7 days,r/machinelearning,Z0FBQUFBQm0yeGJ4ZzJhNEtmTVNjbDAtNHlwdlVzTWVFYm40RFhwNEd5My1RbmdmZFBURC1pM2ZuY0l4dHFNZTRNVjFfNjRhNnpINUMwclNvNWxobmVOMDB3SXFBZ3MwM0E9PQ==
"Ok, just checking did you make some comparisons with other methods.",r/machinelearning,Z0FBQUFBQm0yeGJ4cEhETm1yVTNudGtRQW53Rk5HZ1hsdGMyQVN2Q3lGN0MzUDhpZVlfcW03RkdwYjlORndEcjZaTHFiRzNyYk51X0taMmxBdm5tb0tsOFp4TGVkMF9YZXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4WmpqQUZEZE03VUdyQWxFRHYyRlk2VndXRGlqN19wSkxPN28xaUFsRndjRVFXaF9FUy1FRDcyNnpkaHUzcTN1a250eDRTSmlLSGIteUN2bXNrb1hDLWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4cGkzSlM2TGoxTXdpNTJNYWdubENwd1NObkh3cFBvNlQ1cnJLYjZLOFZBb1FwWFZlYlI1TTBBMHlMNi1hbTVOU2NTWkNxc1dHNnhRcHAteE9lazhqaGc9PQ==
"https://arxiv.org/abs/2305.13102 addresses some aspects of your query in RQ4 analysis in the paper.

also look at: https://arxiv.org/abs/2306.06199",r/machinelearning,Z0FBQUFBQm0yeGJ4cjhsUlF3T1ZLOXZVVWNSZ1FpYzB5WllYRDdRS0JGSW9KZTJscVZIUWJtbkU2aFYtZFA2Qlp0RWh2VHNkOHhWN0VSQWFPV1JUblA4RjduQlR3YzY3SEE9PQ==
It’d be next to impossible to get that data due to privacy issues and lack of reporting. You’d require a multimillion dollar research project with lots of tech and IRB approval.,r/machinelearning,Z0FBQUFBQm0yeGJ4Y2hQM0pGYjV0WmczSVIxTXZCNmllSlZPclY1d1ZZeXo4U0tHYlM5dmZoa25zMGJhalFvTTZjaHdwbjdaSHNGRngwRjZVV1M0M09KVWhUWDdCYXMzYXc9PQ==
"What if we can use our watches data to create training data set for example consult an psychologist to identify different levels for all the data points
The use clustering algorithms like k means to create data det",r/machinelearning,Z0FBQUFBQm0yeGJ4S3VnWEhQZVhtYlFjM25jMmZPY2lTS2xJMWhjRm85dlZDbDFNSHFfLUkxWGpYdkNlTmdhNW9RV0JUdDMtN1JRaFltX0lVZzJMdVlOZUtVbElxclBpX1E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ4TnROYjh0eWFaS0pCQzhEMzRTaC1lX2JQTEM2Nm82TkZxeDBhREZ2N2JFc0hTV2tlQll6Q2xLaW9weEYwTGdLRXd4am9OS1luQ0JUMUNYWWtIWmpLVWt2VHprSXk0Vk14ZDF2eGJwZV9GUzQ9
So... You want to use YOUR data then cluster data around your mental health episode?,r/machinelearning,Z0FBQUFBQm0yeGJ4NzMzcHNFQmxCTlVLazNkNG9ZbTlVZkxtOEZlTjJBTk1fZ080S05FVERVTldOZWVFcHh2MVZsU0NBWWcwaDJka2RiNFlyd0RNcGhyakszTWlVWE1tWHc9PQ==
"XTTS V2 would turn text into speech audio file. Then that speech audio file would be passed through RVC voice cloning model and you would hear the result of RVC's conversion in the end

I didn't try those.",r/machinelearning,Z0FBQUFBQm0yeGJ4eFVrT3NGRUlRNlBwRTRtZ3RraWRfbTdiRlU0NmdMc0Q1dUp1WV9aREk2NzctXzBGWlJIR3ZXWE1IZjhZQ1Y0YVZubUV0TlBMb0ZLWW1VQnlLU0lkS0xoNmRlVDdFcERjSWJyQzJOTng1Vzg9
"Yeah kinda
I was thinking of getting data from several apple watches then then create some focal data points with the help of a psychologist then create the training data set
I don’t know how practical it is
Need your inputs I’m still very new to machine learning",r/machinelearning,Z0FBQUFBQm0yeGJ4a21CdDNOMDlRUm1ZVGZwb0RVREEzSS1OQ3lESHRDWktyekVUVElJWlFPa1NJVGdnXzFsOHpvb1l4QW55MHVtc1JCazFudTVubkRJaHJsZE9WNnd3WEE9PQ==
"You would have no idea if your data is good, that is if the clustered data points are actually mental health episodes.

Supervised learning requires careful labeling of data.",r/machinelearning,Z0FBQUFBQm0yeGJ4TU03VUd4WC1DdFZOZXI0RGxSVHpNOS13NmFOWnlqSGNwSDFTWmxuRXhRakh1TU9vZWNrSDM2SHlvS1dnamxfRF9acWIwLXAyVFVhZWo5ajVsak9VbXc9PQ==
"Yeah I get that
But if take an example of the data point like steps
If person is having any mental health episode he is more likely to move less 
Which can be interpreted as the ratio of steps by moving average of steps will be significantly lower and I wanted to create several other data points like this
For example variation in heart rate",r/machinelearning,Z0FBQUFBQm0yeGJ4NnVJSGY5V2djenFZbDZGUkNoazZRRVVPeUJ4R1dvejlHVDl4NXdTUVRqTndOWUZnVnFvN2x0QVlYdm52ejRUVnB6RjlZVWNDcnh3TWhSN2tEZjczZGc9PQ==
"to be honest i am a little skeptical of those results. With YOLO datasets, anything that is not labeled is implicitly labeled as background. In these images, many pimples are not labeled. Because of this, to have the model find some pimples but not all of them to yield a high mAP would be overfitting (unless there is an important distinction I am missing). That being said, you should be able to at least good training accuracy comparing to their baseline with the largest YOLO model, but beware of overfitting if deploying it (so make sure you have a good test set separate from all your training/val sets).",r/machinelearning,Z0FBQUFBQm0yeGJ4eEZjYXJOSGdzV3dPd2FvdHFnWkJBeEhiRVlfbDdNa0kxXzJTeXQzeFdISW1md3FEbGtLMU1TMERiWC13ZkFQN3dDcC1aQ2I5aXVUUUFGSDk0ZjB6cHc9PQ==
What?!,r/machinelearning,Z0FBQUFBQm0yeGJ4ZHFRMGx3SkJRZUFvYXBLcTNRU1F6dXFVRk5PVzZEc01wNXFSUHFaSkE5N2Y5dmQ3UHZpeHBtT1Rnb1hGc0p1NllRTHlOWE9TR29PempCTE9oZ0V4VlE9PQ==
"Research experience is the most important thing. Research is an entirely different game to studying. Having research experience shows that:

a) you know what you are getting yourself into, and are less likely to bail,

b) you have probably already developed some of the practices that allow you to make progress (such as learning how to read papers, how to break problems down and make incremental progress on your own, perseverence etc

It may sound harsh but advisors want to avoid taking on a student who will need a lot of hand holding, and/or be likely to drop out. Research experience helps to quash those concerns.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZE9BYUcyODBPQzFlMFQtRTI0U2RLcWRwUHhPei0wZkw5WTFrMmRhQVlTVlEwX1Y1NnNkTjktZ2JzanpGX1FwOFZjR2IwTTROTnR3OTlmQU9lQV82VHc9PQ==
The others answered your question but most of the schools you mentioned are tops schools. Look for advice from your advisor on day one. Start looking for internships. My advice do two years of work as software engineer in some research capacity to understand what you are getting into before jumping into Phd but also don’t listen to people who say industry is better.,r/machinelearning,Z0FBQUFBQm0yeGJ4UWt0M3N0RkhMYzV6a3lXMmZMWlpnNWxfRk1NaHVhM1dBUjlRSHBqcmkxWkp2c1lMam9ENndBckNqdmVWWnRFRFRBY2l1UnlZYXdUUzdXRzhJQXhjN3cyalB0TXJ2R2s2NFFjdE5RUVdqNG89
"Hi there, Gee Peetea",r/machinelearning,Z0FBQUFBQm0yeGJ4TVU0Y2U0TEhadlJlNzdPcjdLTkY2Y2ZRWVhuamsycDFTZHUtVE15UlhZcmptRGF1c0ZuUkxNRl9VZlNVdUJYRFdGenY1MFExcjZDQk9OZUR4cDdnWmc9PQ==
"I see. I didn't think of it that way. I'll keep on trying to train, thank you! 😭",r/machinelearning,Z0FBQUFBQm0yeGJ4d2NFUElUQ1dISlNfLXFVQ0d6RV9YU0psSkFBOUIxVHhyNXhCSXVyR28weUgteEcySmRkTENoYUtITDc2Y0FyLVk4WVp3TU91SE4zMTJuNnBzVDRHNlVLaGFKR0ZwR1hTSUFhWkVxd213eWc9
Have you worked on that'?? I also got same task from my boss,r/machinelearning,Z0FBQUFBQm0yeGJ4SlA3eVZjMDRKajZjSElYa2FYMDJRbjYxUU01MVd3YXl6b3NSdndLWmlremVFbVdSWWhsMDZrUnk3dGl1WjlWdEVoOWFRMExXZk1XcThINkpNZnZfQWJlbGx2RWVFM0Q3QVdQQW1vZjNzTjg9
The title is very much self explanatory?,r/machinelearning,Z0FBQUFBQm0yeGJ4a25PaGR4dko1bHhocmx5SE5ZWXloWjNIOUZFNFEta1RZTXNuZ3ZISW9YVDA2YVdpLVI5VVdhM0FWNEVnU2R6Tl9GSVAxVVo3QnNuaVVjU0FfdmJMTnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4N2NyUUpieFk3d0UzRkNrQ284VmM2Qm9RY0daREtMbjNKeHZtUkJxbi1qdHp1TkNsX1hJbUY4MWROT2RadTlONmZaWUZMSE9LbzRYODZmMGpua0JodXc9PQ==
"You can disagree and agree. You can also say ""pros outweigh the cons"".

But your second sentence is irrelevant and shows a lack of logic in reasoning.",r/machinelearning,Z0FBQUFBQm0yeGJ4dUlCcjVBYUdkclFvbTJscV9MbjhhVmNaUVZrQzFvRGJrV2F2eHBYSmJPUFE0NmYwWXJoTEtEZHkxZ1I0akxSVUx2UUQyVEp0T1pnWWNzQWl1Z3pkbHc9PQ==
Usually you’d want to observe the training curve of your model by logging the training loss/accuracy and validation loss/accuracy in order to avoid things like overfitting. You can also use early stopping to stop the training earlier if it doesn’t make much progress on the validation set. The more advanced technique would be to use Bayesian optimization to find the best hyper-parameters.,r/machinelearning,Z0FBQUFBQm0yeGJ4NFY0ZEFjT2QzVjh3ZnRXaXdQOXYwN2ZQVmN0cG5IMDVDb28yMkZEQ0FSemxrVmZTVmotV0hBbU96ZW1XZFhJZ1M2dHBWQVE2ZHJuZ1lxc2x6M3dUVUo3Z0dUS095b3NBaXM0WDVWQW53anc9
"Short answer - no
Long answer - it depends but no",r/machinelearning,Z0FBQUFBQm0yeGJ4UXNXQnlKQXl4aUg5Ykc4Q2owY29qaWNuV0lJV3ExWC1iR1B5LXVHOVNlcDQtSVFvLWdlOGsxRkdXQTUzOWRJMEMyNFZXa25vbFpYalIxZzZsZENwVlZTRGtDUDZyUTEybWViUkg1bHBhOUE9
I guess I am dating a dataset now ¯⁠\\⁠_⁠(⁠ツ⁠)⁠_⁠/⁠¯,r/machinelearning,Z0FBQUFBQm0yeGJ4RHZfb3k1TlNENmVHTDN0OVF1OG1tNWlzdkJobXo1empDbUdndFg4TFQzUmxpSFltZkhWSUN5cXdsWmgxa1hlTThDUF9WWERUSVg5aWpYZVpJY1VuR3c9PQ==
Do you suggest that i find other datasets?,r/machinelearning,Z0FBQUFBQm0yeGJ4S203dFc5eDdEUmludGxjNl9XMVpPQWx3NlQ0UDVZMWlJVG0xYkZYZDUwRkJnUjJlMG4zWEJGZV9MZTZ2cWhxTHZ5cmZROXdZY2hocEFjcEhuNWdtLTRrMVVHLWk4eXZDcU4zcDMwbXdqVXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4NVE5ejBHN2lxdXVtMUhWTkw3MHY4OEVCUmpxVVo0dm83SHlSb1VocmY5S1VUT2lZWkpxSVlCd1F3VFNHcmhhbWNnY0Z5VEpEdndTbEN6cU1rWXdXMFE9PQ==
Just like marriage… You don’t,r/machinelearning,Z0FBQUFBQm0yeGJ4eGtaTkVOcFlRX3NhMmhicllxbW5oRmVnUUVFYWxlWGxfVUZ4VTVOMW9JcWxMcU1IM3U5Z2gxaHRsZ3IxUDhPWHVvTWFDdXZqd0pNRkZGcndrTlJRVlZ1TmFOTVhOa2tKbEVLNmU3Wm5TUlk9
"Have you tried off-the-shelf libraries like AutoGluon TimeSeries? Usually the ensemble of multiple best performing models, be it statistical ones or deep learning ones, beats any single stand-alone model.",r/machinelearning,Z0FBQUFBQm0yeGJ4dVRrWjlvVTZhUHk2am1tRXNiN0hkeGEweFRXRFdvRGY4ekVvajFiM2ZJYlhfR0h3VV9GVGFraWx5WDZzSUFFS0FHbHlHeG5XQXRweHdXOWNFcTZZRUE9PQ==
Why would you use a decoder only transformer? Decoder only transformers are explicitely supposed to be for generation. Why else would you use causal masking except for efficient generative training and inference?,r/machinelearning,Z0FBQUFBQm0yeGJ4WFpQR2lwSFdKM093WDJ4MWdqZ3BnRWtMWE9GdERrMG9ybHJCS3BQZGtUMDFWT3AyTzlRd3hyX0I4cUJobzZvYUVwQUlfMW44NS1aNW5CNElIZzc1R1E9PQ==
You should use the encoder with a special regression token.,r/machinelearning,Z0FBQUFBQm0yeGJ4ckdJQkFzczVwVG5zaUt2UFQwSHBtbC1pRlZtQlFuNVZhazZWUUJiWDhibWdpMndwQVpGdHJrUmlQR05uY0tKZXpyclh0UTZRMDl2dVhNNmk1WnNOclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4N3hrai1BNG5aejR5c0hjYnExR2pGcW1QQUlNbTE4RHdoSzdmYWNNdnJOT3BzODE2WGJwVEJ3dDZ3RUdkeFBkaUpoOWNrSklPbDNpYlJLTHAxSzJtanc9PQ==
"For example if you would want to make a prediction for each step in the time series, then you want a causal mask. You don’t explicitly generate stuff but do use the ability to process each subsequence of a sequence in parallel",r/machinelearning,Z0FBQUFBQm0yeGJ4WDIycnlsWHFSS0hKeTkxV3FUTDRtZXBEc2RfLW16dHR0Z2NGSDNFcmVoTWVSNmZmYVZHUElNMmhjY3M3WXAweUpRYVpEdWt2OG1hRjhoWExUTGh0N2c9PQ==
I fail to see why you would want to obscure future information.,r/machinelearning,Z0FBQUFBQm0yeGJ4UlItZDZYellYbS1zRnRjTUVIc1JVZWRXbjBhNHpzWjhZTUZCZDhVeUZpYmk3OXh2N0kyQVhfaEFWVzRhejFyZVN3SzVTc25jT3h4QnlIVW5NdFczOXc9PQ==
"How do you define ""unreliable?"" Do you mean ""wrong?""

As far as I know information extraction is an area where LLMs aren't as useful.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZXFqXzhEVEF3dnh2UDR6dzc0RGhIS3JjUlpFUWs2bHc5S1Bpb1F4QzlBQVlFOFNVQW9tWHB6WG5HSlBLN2hQMVQxSk5NV3V3LW95R0RvdWhlRm1nV1E9PQ==
"How does 1. preserve privacy of data if the process is known and reversible? How can results be returned in 3. without the data being revealed?

My suggestion was that there needs to be another process that handles the data privacy within all this.",r/machinelearning,Z0FBQUFBQm0yeGJ4Z0d0Wms5eDZpT21VQm5fQ1lCZ2gwaktZazNIZTI1dFZxSHBuWFN4VDU1T1lrSng4VC1jTE9IUGNQWGZJZWNFLUhPb1ZveEcyUzBpdFVpQTdpNjBBNkE9PQ==
I’ll have to read that in details next week ! Very promising per the abstract,r/machinelearning,Z0FBQUFBQm0yeGJ4MnM1YndjR1VnM2pSbmNKdFhyRDdHV0ZRZEpvUlFKWXo1UGJPaFVtejRCd3hSbXhVZnAzaXBKZzZ3dENvR0FoNUNlZHBxUV9TTGxDd2NMZFJxY2Q2MVE9PQ==
"It will depend on whether your time series are complete or incomplete. The idea would be to construct multiple subsequences from one sequence via causal attention, and learn partial temporal dependencies. If your time series measurements are complete, then I agree with you, and bidirectional attention in the encoder would do the trick",r/machinelearning,Z0FBQUFBQm0yeGJ4MGtyT2d3Tk1SQ09QLVdMZFJjckhwZGxDc2dGVXI4aTVIcldZcmVrNGtKa0NpRUNMNTZmbFFyaDV5N2JhNXBQdGcxeS1MczlKR1ljbGI3LTFKNDRKMlE9PQ==
I thought internally RVC is also using XTTA voice cloning,r/machinelearning,Z0FBQUFBQm0yeGJ4QzVTSW8zMjR2a3d4b2wwdXFqdjBQYjhFYVdOVGR5VEdyT3hOeGxPcXo1WngzX1JsbXJSS0xQU2E0Q1E0d3FlZDk1Z3A3cFRCYWRTNlBwdFhPS2NMVmdDdmJRTXUxdjNWZXRvQ09RYzBOQW89
"This was already posted 2 days ago with the same title, and an abstract included.",r/machinelearning,Z0FBQUFBQm0yeGJ4RS05TExFTElHMWxfb1RzOGEtZzFDUWtwcHlvbmVXNXBkT0VjR2h2eFJfUFVySHRfaVR4bVV6WEg3ZDFyYm5ILVhNT01KRkJibzRKVlhMZkpUMjFCRVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4cXcyMW1QSm9yQ0JGQzd0QjdrN3U4aE5iUldxR3JPa3VlTElCMTZkMVZ2cEhYYmtweGJfb29GbjNEUl9oa1B4cm1MbmQyazR4TzhDTnZVUXdtRlNoMXc9PQ==
"Yes, incorrect predictions.   
  
Typically, what is your approach to solving problems that involve extracting key information from a large number of free text docs/conversations ? Assuming labelling data using subject matter experts is not an option but you do have an outline of the expected format of results.",r/machinelearning,Z0FBQUFBQm0yeGJ4YXBaZWJyOXJaVTUzOWd5ZDhxODhkaF9zcjZTS1E3eVo1d2xuWFNTTHF4cEx1LVJuOUF3YTVyY3JQeFgyZWtWZ0E1MXBQVi01UTJnY3BoRlh0aG5uMGc9PQ==
"Just take the standard approach of making your entity dictionary, labeling the data, and training your model.

May I ask, why did you decide to use a LLM for this? It's overkill without any real returns (as you've mentioned).",r/machinelearning,Z0FBQUFBQm0yeGJ4YzhZcnhtRVYzQlpnd09OcGtTV3dNY2cyanBzRlR3WGplUjU0MzZvYm96QlJKb0VwSDl5d3hLdGhzQVVUa1ZMUG52X2hJZWFNUHBySTlhcU83OUo5OHc9PQ==
Tree fiddy.,r/machinelearning,Z0FBQUFBQm0yeGJ4THU2V3MzVGRHd0laZTl5ZU9Lb0hJemhXMVhudVRWUmNMM2VjWTdSVl9IaFVRUjBVOGNfRnA3VG0zOVVUeHFzX3hqUlBnQkhCc3dFTjY4QURiOXVtTmc9PQ==
"Check out Labelbox or Hive for efficient data labeling, great for custom datasets!",r/machinelearning,Z0FBQUFBQm0yeGJ4V2EtS1V6ZDRHakhjMW9xNnNYeE1NY2JpU1F5TzJWT2VDSldjZV9fdE0ycTVmZEg3dnBLTjJrX1N4eG9ZckRfTklsVGJZYVFjT29LcVBMOGg5ODZFUlE3TzFIczNpcVM1YnlCNUc2eTgwWkE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4QU93VUtVcUI0dU5xS1h5YTAxZ0xhbTdBZzVGX1BMRnVmMlRJbDVSdDBNTmMydDBZOHNrNjJ3VE12UTlxUWQzTHFhMUN6Z25RMXhuZFJUWW5zWHVxWHc9PQ==
"To avoid messing with the learned features and representations, pretty much.",r/machinelearning,Z0FBQUFBQm0yeGJ4UUpqVEtRUXpMOVRiY2xzVlRiSFhGN1R1bENYSXpld1NHZUpuS0JMSXA4QVNPZ2xCQjRadjV0WWVKU1ZfcG01N015bjBIZlVWZExBQjAxV1pxQ0ljel82R19vVm1NTDVyaFFVSWw1WDdiMmM9
Check out the work by Li et al. on 'Analyzing Robustness of NLI Models'.,r/machinelearning,Z0FBQUFBQm0yeGJ4Q3oxSGFpZ084ZW9NY1VsbU8xaDJOS3NsUjB5OWtaUEtZdWxIa3F3bVAxelp5ODNOQ1g1cmVjWHVkQkJBMTJjcTc4LTBwVkVOaXcwX1dkTjF3bWRyVFNPaTcwbTRHQzJmMTFjZmVTYThtQU09
"Me on a 16GB GPU trying to do inference be like:

>[rank0]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU E0609 09:56:46.700000 134535903167552 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 26779) of binary: /home/chem/miniconda3/envs/llama3/bin/python",r/machinelearning,Z0FBQUFBQm0yeGJ4d3R3NUFsNFJvV2ppTGZVTUJBa2R3bkxLamV0QjIyLUUtMVVXTW0tcFhuVHp4TW16SkFRT3ptbnd5U3VxMFJfeXFqcVJva3ZZN2VFeEt1ZkhBYk1KdUE9PQ==
"Oh, here pain I see... thank you for detailed answer! 

Upp: For thouse who downvote me -- he provided a full execution log, but somehow app or browser does not show it properly, due to ""> [""or something else which collides with something reddit, I assume? While my comment notification link does show it fully, so I have seen it. Stop being arrogant.",r/machinelearning,Z0FBQUFBQm0yeGJ4eUlkcTRNa3Q5djhBUHFmMTRkdS1LOG9aVS1CM3hmRERsVTlGbzQzQm5VQ2JJQzdKUWdqUmtfc3pOWFBpMmNQcXF5X2l4OFVLM25rSUxRR1hobXpiV2c9PQ==
"I see. The usecase is around discovering issues described in the customer-agent conversations that are beyond the usual suspects. So, the entity dictionary would probably be one of the outcomes expected from the exercise. 

LLMs seemed reasonable (despite my hesitation when it comes to such models) because their NLU capabilities are quite remarkable as long as there isn't much domain specific knowledge involved. The deployment cost can be handled with certain optimizations if the results are worth it. But clearly it requires too much ""post processing"" to make the results consumable ! Was hoping the folks here had similar experiences and had found ways to deal with it before I move on to other possibilities.",r/machinelearning,Z0FBQUFBQm0yeGJ4WjQzLXBBMzFtU3BqT0dBcWtGNzRLblZFbnFFaS1QWHZyMU5jVERaeVRyX2JZSzh6cUdYemx5OWVhWW5lbVJnTlJSdGNrYkUzeVZJUHVaY1czc09oR0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4YkJFMkttSkhvMVVMdHczYm96YTlseVpIajhiSnZvZFVRdUZZazZfZ3ZlMjFRdVU3THJEWHBPa01SWDNlSGdGeE9jRmo1QktIYTBfbGRmaUhzXy1hdVE9PQ==
"According to their website I should be able to but I'm already running on memory problems. 

Did you check their docs about training? It seemed rather complete.",r/machinelearning,Z0FBQUFBQm0yeGJ4RmtaRTJ5V3AyanJUSTVkbG1KRFdLdGJhWkd5WkNRZHM3cFZuSWxFUXE2ZjBxYVQ3SHoyalhKcV9zejdEcUhGMy1SX0ljblV0RFRNZ24yU29LcjFndEE9PQ==
"There docs tell me things in a very generic way https://llamaimodel.com/requirements/ and than on huggingface I see totally different claims, like 148 GB RAM (?!) required for 70b instead of what meta claims 32 is enough. I am not for 70b, but makes me untrust meta claims. I assume, different tasks and different context. If I would have proper hardware I would try myself. But I don't have. Worried to spent 1000 Euro on 16 GB gpu now to realise I need 2000 again on another one.",r/machinelearning,Z0FBQUFBQm0yeGJ4cXJlOHRxbDBCRGh2Z21CWEpGbFc1RlRsSGNVQzh2RFdBcGNMZlh5Q0JFTVBhRFpmN1JxVWV5ZDc2dUJ2ZmJ4QlRuM2dkcjczS2ZYZ2MxX3JlZG10eEE9PQ==
Exact same issue here :(,r/machinelearning,Z0FBQUFBQm0yeGJ4UkhVekJISWVZNVg5THNMUzVrUUlEQXhxQ0s0aFRDUkg0em51MWFKY0Y3NVlpWVNZNC1JaFMtSVRsV3BhZy1tbWI5akg1TXJNWkUwZlJnSm1nNUZTSHc9PQ==
Muhaha haha ha ha ha. Haha hahaha ha muha ha. Ha. You such a humorist. Not.,r/machinelearning,Z0FBQUFBQm0yeGJ4UnNrWktSdWdiOWJHZWc1QkJBd013WUxlWDMyWFNnQXdkNHdPQkxXaVZQaVJZeEprWk9tcnZ1eW1aM2VGTGZ2RGg5RkxTYThjS2RuX0dVcmpwVXdwMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4amtGeU1zd3RMZ0xsbm41R2ZuZ3JTM0NpT0IteWNCOFo0UGhjZTBaa2xGcmM3TnhKaDZ2cG92YUNhMWJ5a2FGZERMQzlPdEtHQVhneXhkZ21kTUZ0aHc9PQ==
"Hi, Im a 22 year old frontend dev, i've been a huge fan of AI in the past and i'd like to get started as a hobbyist. Do you guys have any tips or guides on how to get started.

P.S: i know a bit of python and lots of JS",r/machinelearning,Z0FBQUFBQm0yeGJ4N0dQejBBam9TQ2tYY0c0el9KWEotZjlNZ3BBVWFOaC1tc0dUQm85WnFmZjhPbVlvNVdnN1lZY0Q5ZkZVY3JMR0hYcHBfTjJBMlhnaUwxTmoybFkyRkE9PQ==
"Very valid question and surprisingly hard to answer precisely but you can try this VRAM usage estimator:

https://rahulschand.github.io/gpu_poor/

Looks like you can get away with QLoRA and gradient checkpointing, assuming a prompt length of below 1000 tokens and fewer than 500 tokens to generate. Please re-check for your specific data and usecase.",r/machinelearning,Z0FBQUFBQm0yeGJ4TDlnaWFNcUFDaTJFNUJLZ3ZjOV8zRHBpQ1U3anplSTA2UGdqQ3pUS1FsTGNUaE10bTI1WkJIMU42elVlaDRleTZNanNfQ1VkellRM2pMdUFuZlRuLXc9PQ==
"Just rebooted and I still get the same, even though that's what their docs say:

>With a Linux setup having a GPU with a minimum of 16GB VRAM, you should be able to load the 8B Llama models in fp16 locally

But I decreased the max batch size and seq len and still get the same error. I'm still hopeful to be able to get it running with some hacking around. Maybe quantize it to fp8, I hear performance is similar.",r/machinelearning,Z0FBQUFBQm0yeGJ4VUR5QXQwdU1sd2tOaXlxQjh1SENtWTUtUEY3Tjh5cmFyQ3dfTERfZGptSlB5SEtReHZZY0RSeDJLNWtQVmxlODNkWWFWbTlxakMtWDBDbWJWa2l4VVE9PQ==
"Golden answer. 

Calculated, and estimated -- I need at least 48 GB for training, and 18 GB for Inference with meannigfull context.

You are my hero! I see a train with local GPU training is basically already gone...",r/machinelearning,Z0FBQUFBQm0yeGJ4aEJYMU1nbjhENWZDMWNBaDNFMUNSV3pnQy01eUE5OURZaTZaYXBTVlpxZFpHU2plTC13dUx1azRZRmd6Q2N6NUZoRjNRTWd5TVdJWVFXOGthV3V0Nmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4X2NQckVaSlFjSDFUUDVPcmlMRVg1Z29pSHNYQlBvLXV4M2xYay01QWVPOVQ0NS12QVZNb2NSUjlaNllkUExya05OU1VlUkFFUVJsUnZ1dkZhVHJ3X1E9PQ==
Publications is the main thing to aim for. Grades are relevant at least in Germany because there is a hard cut off you have to surpass to even be eligible for a doctorate,r/machinelearning,Z0FBQUFBQm0yeGJ4N0U5cFppdzNBOHNVTFNoRWQ0SHRlRW5VNjNOMFVZTG90Mm9sTWlzZEFPd2YxaW9WS2tySlFfR210VXg0TGM3Z3FvUWhUVlNKaHRFemNreFFBTTdTM2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4dm5RblNDRnVxMEloQ0tpUGZGQTlrSmxNM3J1UzRncjQ2cXhETVViQWtvdVliellaQmRvRExqTkFqdWFXajlaS0ZHdEhVV2d0Y3luc2xPVkVfMzNwZ1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4dFZzcE1SQnA4Y3RvbVAyS0Z4dk1VeDZsYnhmSmtOVjJCS1FVTzNIUHFaUmU3c0lSd2lWREVsUUlSaFh6U3UzcElCMzI0RVpfaHAyd1N4NmRhUkFjWnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4VmczY1lVQy12cnNnTDRCcjZPaTFBOHlPN1QzMlA4T2FaZ0hNOXBMNjZ2ZkFaUUZnY0FKNTlhUXNvU1RMdG1sT1I1dGxxZHk0U2M1aXVwMDNhVUtoNWc9PQ==
🌳 fiddy.,r/machinelearning,Z0FBQUFBQm0yeGJ4VTg2OHItWkp0djFRZ3B1MkpMREVRZmJGS0lxT2I4bWJ5eHV6by1nTV9MVl9QMHNPYlAzZWRibFNJQl9EWkdXNk1Uem4waUk0U2plZWpEb1JvSG1kNlE9PQ==
"You can easily do it on your Mac itself, look at MLX examples from Apple, easy QLORA fine-tuning with ~10GB memory",r/machinelearning,Z0FBQUFBQm0yeGJ4REhHSnBZZjR6OGg4Um83ZzRObzFzaUh1NTNJZWNHVEVFUEhhT245XzRlX19RZENCVldLSkFwX2piRl8yQXFfYjI1b3N1ZTlVSlJ2SlJIcXAzQkt2VlE9PQ==
Congrats. I have blocked you.,r/machinelearning,Z0FBQUFBQm0yeGJ4WHBSam5VbDRvLURCdmMtVjM5dU5fc2N4TU85Z2M2N05xZVgybjYwSUNFRzRRVEpONGZnSVJtVVNMNld6b0FQZEtDT19vWDAtT0pULTA0UklhRnhLTXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4WHhPZGZHdHMza3p6ZHdWMktWaWhtU3NfeU40RXo3UFV2QTEwZ1hoZmUxekhmQVFOSENxanlWUzR3TjNSYzI5YXNuMVpKV0kxWXNiRExKbHBkSTl1S0E9PQ==
"Are you using a pre-trained model?
You do not have to use transformers for ""forecast"" as a must. It mainly depends on your pre-training task. For example, GPTs are specially trained with next token prediction tasks (good for forecasting). But models such as BERT are mainly trained on masked token predictions, which are excellent for creating meaningful encodings (a good representation of your input data).

For your project, I would suggest you use an Encoder transformer trained with the same paradigms as BERT, for example, then fine-tune it by using a prediction head on a classification task.

Unsupervised training followed by fine-tuning has been shown to do wonders.

Good luck.",r/machinelearning,Z0FBQUFBQm0yeGJ4XzZhY3Y0Nm1tOXJwVFpVeVJhX2pITEctbEhRdmtWdUQ4WERvS1l0dF9RX25NM0Q2Tk5XRzZyRmktNVpiUDhWeXdhc3hIZFVTNzlaWUhiYW5objNTT2c9PQ==
Did you end up releasing your library?,r/machinelearning,Z0FBQUFBQm0yeGJ4OVRBNmEtTFRud0h6S0VxS3RmLTBvaXBkdXlJQ2VhOFdFbDdBbDR1NjV4dVNsQ0RwRW43NUdzQUZUVzZXVDRFRDMxaHNyMnllbFpON0U0X0ZuX3cwcXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4WUpUNVJxanVpNkRCRjFQZ25NY193bFZUS3dKSFBackZIM2lpZUszMVdUaUpHcVpNSk9FMmM2MVRWdkNzZFN2V25UbG9LM1MtYzk2TGlQNmMwNDdzSnc9PQ==
You can get it working on like 12gb with unsloth,r/machinelearning,Z0FBQUFBQm0yeGJ4LXJzcHpwZVRtQ1laSktHT25sOVlRdjJkcDhkZzBWVS04cmZmLTk3NkpJYWxJdzFGaHh2NG5uX2tabFE1blJmczhhVFFQdktFS2hFOHJLdEtPMm5XWEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4UlBUWm05YWltUXMwRnlOaDFSWkE1Yi16SDNyQ0szbWNudVNWakEwcG1LMUtTREdCZnd5N21yVS1sTi1jOEpwcGdzemVEYWRCY2pJVVhseGdFSDROUGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4M0RNbUNOd09EN0wzR0RUVlJjQzRVZ1k5VXY5VGE5dTkteUlNbXhMWVg4ak9XZVQyLWFZT3EwUkpXaXBUNUtHcFdHZ1BFTUs0ZTJUTm1FZzQ2VkhUblE9PQ==
"In 2024, I would say JAX is the best competitor to PyTorch.

But maybe also check out Keras 3 which is framework independent -- it can use any of them (though I have never used it).",r/machinelearning,Z0FBQUFBQm0yeGJ4WDhDNk9ZVElKSF9DZ3huYXRxMEZkRVFlazMyN0ZOT1ViQ0dGR3MwWTFWUzhJN25NVzBkNzV6SXczYkg3RWlUVG9MWTZwR2hqSGFKU1E1NnZBODJCOEE9PQ==
Just a reminder that inference doesn't have to be done with full weights. Llama 3 8B quants like exl2 8bpw and GGUF Q8_0 should fit in 12GB VRAM and still remain high quality.,r/machinelearning,Z0FBQUFBQm0yeGJ4d0N6ZFRmVTdDeDNCTjVJd0x3UjhfWEQ3WUFNWHVENEtNOVZUTjlRWnZyeEdGQVdXc3otdWFqc2NfRHczRng4TU5DRW9sazFjYkhGb2t6TVM2MjFKSVE9PQ==
"Both are powerful frameworks, and IMHO the comparison as whole cannot be really objective because there are many use cases where one proves to be more practical to use than the other and vice versa. Personally, overall, I like the TensorFlow 2 approach more than Pytorch, but Google software project direction is a mess lacking of vision and consistence, they have a large army of development teams lousy organized and the approach is to write something not focusing on its design problematics, never fix them, then notice the problematics and write something totally different to address them. and deprecate everything with poorly documented migration guides (if any). This is happening regularly basically with any Google software stack in latest years.

The big transition to TensorFlow 2 has caused this:

* a large chunk of old TensorFlow supporters become furious due to massive deprecation of code no longer working in the latest version
* a large chunk of those that used both TensorFlow and Pytorch focused on this one rather than relearn the new TensorFlow
* tons of examples, manuals and tutorials on the web are outdated and unusable

So basically, now TensorFlow is like a newer platform with less mature ecosystem from a community standpoint, and most opinions about comparison of TensorFlow vs Pytorch are outdated as well, because related to old TensorFlow limits and problems or biased by the rage against massive ""code-Armageddon"" the transition to newer TensorFlow version has caused. Some people see that they are also working on JAX and like to rush opinions of the kind <<Tensorflow is dead they are working on JAX>> not realizing that JAX actually is complementary to TensorFlow and eventually could be merged with it when mature enough, not something that can replace TensorFlow, as it could cover only a subset of things of TensorFlow (that is a large framework made up of various different modules with Keras as high-level API).",r/machinelearning,Z0FBQUFBQm0yeGJ4SXNJcTE3U3FHVjVLSEdldzlxOWdxazcxR0hMTEdJVms2ZVRZek9zMk9GTVd6OGhnb0JrZWdHQUdnblV6LXZDaGM0S1Z4blRPdkVhN0VhdkZkNzVqa2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4Wkg4UDBGVzluSlcxTjQ1anpYM0FrRm9VcDgxSm9hWUpxTm10M2VPamsteHpBQlJVLTUyMElCVk9Ca2E5bGFjWmtrN3JnSk14d2JSdVN1dG43eEoxYmc9PQ==
the title is a lie,r/machinelearning,Z0FBQUFBQm0yeGJ4ajQ1anhVTndpckF1dXdvNGJLSzRJMFRfOENqUzBOa0g4Z0VpWkhuQnZPYnk5SkFwNlFSelN1Xzh4azNITmZzeWNJbWR0eEFUNEVObm0tTVY0Y05KY2c9PQ==
"Move all of my programming to them, much like I am already doing [currently](https://www.youtube.com/playlist?list=PL04PGV4cTuIVP50-B_1scXUUMn8qEBbSs) on my 4060. All the low precision stuff in them would be great for evolutionary algorithms, which I am looking into. All the other hardware companies apart from Nvidia are a huge dissapointment, but it does make the future easier to deal with as all I have to do is focus making my language a better fit for Nvidia GPUs.

Despite all the ML performance improvements in newer GPUs, a often neglected trend is just how general purpose their functionalities are becoming. I've implemented a NL Holdem game that runs entirely on the GPU, and it works quite well. The compilation times are a problem, but Cuda does have `malloc` and `free` which are all you need to implement a reference counting Cuda backend for a functional programming language, so I'll be checking out whether replacing value types with heap allocated ones improves things. I think it should, and that opens the door to writing programs of significant complexility entirely on the GPU.",r/machinelearning,Z0FBQUFBQm0yeGJ4THRLalR2bmpqaEQwakx4azQ0bThyVDdFZFZkcEZTdVFiZERuVWdod2h0M3Ewc0dibjEtTUYwdl9Fb1dBQncwNVhTbGhUS0pTYm42V0VVRXQ3OFZBX2c9PQ==
Would you use pretrained embeddings and then just put on a new classification head or train it from scratch?,r/machinelearning,Z0FBQUFBQm0yeGJ4QUtWTy00R1JZcC1VbmJpZkFUb1d6Y1VnYzZIS1g3ZndFdHpVN09qbzl0Zkllc0ZwcUl5MlQzcWlKblV6dmg4eGFzVld5RjRMZ0dRTVdFY0x6UTVna0UyOXo4THItT1F4bi1fU0pEWTJMRUE9
Very few replies here. though I thought this was a common topic. Do you know if there's a better place to send ML questions?,r/machinelearning,Z0FBQUFBQm0yeGJ4Sk5VNzhab2dEcnBSb0pLc29ycG5BQkRlWWY2SWUxS2tycUF3M1RXZVIxdlVndFdvNFhTeWVzSTBRS0QzMWxrMzRzaGI1RUdsWUxoZ1lscHVXRzBhX2pMR3hXNFE4cU5jUUNWOVpYUUExU0E9
"Training:

QLoRA - 12 GB

LoRA (higher quality) - 24 GB

Full finetune (highest quality) - 48 GB (GaLore, might be complicated)

Full finetune (highest quality) - 80-160 GB (naive finetune)


Inference:

Does not matter, even CPU works. Worst case scenario 16GB for naive inference, 4GB for quantized version.",r/machinelearning,Z0FBQUFBQm0yeGJ4bUZDVHRtdjdscV9nS3NjaFdGbEEzdW1icDNQYjRCU01TcTVMSzl4eVRGeEtSMVRvbjVzamlVbXA5V1RZTEhVU2VrTGZOd3p2ZUYzMFdGdUhHZUJXelE9PQ==
[Choose Your Weapon: Survival Strategies for Depressed AI Academics](https://arxiv.org/abs/2304.06035) might provide an interesting perspective too especially to people who are just starting in the field.,r/machinelearning,Z0FBQUFBQm0yeGJ4d0ZDRFlNS01ONk5JMzZKR1hlQWdWTnBkaXNHWG9RM0dsZ3JoUXlzZVJ0NXd5VV9MbEU4SE0yNnF0NWxTNEdVaUNycktEYi11dzQwSWoyWnNIMWNfVGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4RnRQOWNkNWdUN1BOTXl2ck5RLThCMEx2ZDBXVEh1WVJIdFlvT21ta0p2WlY4NnZQbjlCbEMzeTUtTzJpQXFHeWtNQVJ5QWxKQ0tPNW9tdG81VGtBR0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4UF9uUnNHVElzT2ppQmRxemhEZXFqSFV0Nk5fMlpZVjBSMTJhTzQwWFF4Wnl0UnR6UE05WWtCbXhoQU9fRFpOUGJPcnlrNjNSS25OS09GV25QazdpcVE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ4M2pVMENvczEyQ1JfZkpHZlcxNHZsNU5ObEtyU05obDVtdjZXSkpjU1pnM1ItNEpsblU1X1Mzd1JOYW1HSE9BMFhhUkVfYl9NaFVkV3BKbWpySHdaVDU4eTl5N0VCS0R3NnJWUzBwQXVvVnM9
"I would like to understand the reason behind altering the preprocessing of data after the model has undergone pretraining.

Fine-tuning specializes the model for a specific task. Modifying the data preprocessing would constitute ""retraining"" rather than fine-tuning.

To address your question:

Stability: The model's weights have been optimized for the distribution of the original data. If the data undergoes significant changes, the ""retraining"" process becomes highly unstable.

Consequently, the model may either fail to converge to a reasonable solution or require an excessively long time to achieve convergence.",r/machinelearning,Z0FBQUFBQm0yeGJ4OV9sZEZzaFFBRkF3a01UV0RkcXZVTFlUUDlabUI4TENmR3BYRXRlVElPS25QMGQ1cjBWT2JsSURlemVobjd6Wjgya3Y5N2Z3ZEJEbHhyVXJoZjdPMlE9PQ==
"Normally I scoff, but IBM came up with some very wild anomaly detection methods recently.",r/machinelearning,Z0FBQUFBQm0yeGJ4Q1daWVRxUUhfNXhjWHh2b01lTGxwT1k5SHA2Rzh1VHlRYURZb0tyem14Q2ZNUmhJWk1DZ0VyTXgwWXFTcXQ0MnN4TVRZNFphRjVySkJWNktMRkJRdlE9PQ==
Have you tried using ensemble models or incorporating domain-specific knowledge to improve the reliability of LLM outputs?,r/machinelearning,Z0FBQUFBQm0yeGJ4SG1Za082R29aMWtQTWlzRTF1UXd1LVVDaVdyVlEwZlk2MzhodHV0WktUWHpuZ09QeFZSeTVIYXFoYVkxMjYxVFMzUk5ISHN5UnZRMEgxVkhfRWRJbWc9PQ==
I am interested! Could you share the links?,r/machinelearning,Z0FBQUFBQm0yeGJ4RnR0Rnh0SkNGSURsZUFSeUZUUURRYm1JUzl0RHFvZWVrdTBVYXk3QzhKb2ZFR0VnYWY1QnpoVTVXYTV1OFZ6a3ZucGkxQ0lSTjE2a19yVGx6bnM1NXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4cy1HQ3BnbGZWb3d2RDRoci1zSURPQzhldmZFS29Mc3NZNkdhQlljeG5kX0p4TnB2cGFrd2RVWEl1ODQ5a0xfTkg1NzM0RjhJTGhqWVFBVUdsU0pPemc9PQ==
"Nice idea, but without semantic analysis it won't really work.",r/machinelearning,Z0FBQUFBQm0yeGJ4RmRVMmY1VHdyOFdwbm9SQzdQel80dE1PSDFjY19fdTlLXzRvbHF1blhvRFAzeWRjUTZMN0FJRjRnT1pQV3lJZkN3YUN1S3M2TkdjMHMtTmNFOC0zMEE9PQ==
"you can use this one, but be aware of that potential limitation (image augmentations will make that less of an issue by occasionally removing “background” pimples). However, to get higher accuracy you may want to re-label the dataset to contain every instance of what you want to detect (if this is applicable and some pimples were just not labeled despite belonging to the same semantic classification)",r/machinelearning,Z0FBQUFBQm0yeGJ4NFI4ZjRIWlk1cEVxVHFkZ0ZKNXZvNWc3NXJMTkFfUC01Y1lLcjhNTlkzRldFRUZ2SkdMa3hFVXpqSjBYam5CVmkzcnZkb3MtZU5rZGFMbHBiX19DU2c9PQ==
How so?,r/machinelearning,Z0FBQUFBQm0yeGJ4WnBKTTJManBvS0J3cXlmOVdyelhvbjExa2w1VUJ3S3QyUGtMeE1GNmxXYWVuSklxUVlOZlVKNHY4MnlVMm1nZnZPXzBETFc4cjVkaEhKQ1l4SHU2YWc9PQ==
A gatekeeper. A model to classify each prompt as malicious / safe.,r/machinelearning,Z0FBQUFBQm0yeGJ4UDBhMTJBcGZkamR2WWRHUUpCVnBucTRCa0tWSGxwYzlHN3Z2eTJhNjhudkhxZ2syR3NhSFMtX0RnaFJNVGRpOHFkWTdJWjF1S0pTMGFlZEQ5Z043WHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4OU51cDhNel83YlV6YnJ5c1dibVRRTGlKcTRPS0tZQmN4VUJ2T2YxMTZHRnhlZHlZOHlqSm81NzJwNHhkV2xhTWxjc0gyeExwbHJCU0RvbjBVb2FPVWc9PQ==
"Already discussed here:

https://www.reddit.com/r/MachineLearning/comments/1d9fkkn/r_scalable_matmulfree_language_modeling/",r/machinelearning,Z0FBQUFBQm0yeGJ4a01YODA5d2dFSjQtdXZkYXVfNXYyeklUQ1ZoQjRXTXZGdEVkS2pZREhKM1FzNm1wekFQN1UxOUM1RzNWVTU4eDdJbjExdHRUOHZ5TDVGSkhPeUZ2UEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZkkweVlzYTRwVE01aDYtVHFBT2x0a2VlQnM4ZEc4VkMzVWhFZllXeXVHSVZqbVpYWkdzMVktMl95QnRENnMzeHVaRGt1VlFWaVZVY1RGdy1Zd2FsTGc9PQ==
"Ensemble methods and cross-validation can help increase reliability, but more research is needed.",r/machinelearning,Z0FBQUFBQm0yeGJ4OTgxN3A4VnkyNjVkYVNpaDFQZkVOZlc0Q2ZPMS1ZSDNWOTNsb0xGX0hlM1VjZFJaYkE5SWc0VnZNa2I5b081QzRJLVFFR0o0RVU2UjU0MFZkbk9oV2FwSGJHV0RyOS1FTElWZFJfQ1I1ODg9
"Try data augmentation and experiment with different activation functions, especially for anomaly detection.",r/machinelearning,Z0FBQUFBQm0yeGJ4c18xaThNdUdGVDVoVE9GUlZBcm9oZmpMS09UOUdpSEY3c25hUHVqOUVyRmM1Uzc2WXNUZlpkem9UOFBob3g5Q3g5RzVJQmF1TFlTVjVHSUVuakpuNkFvZjBEU0c3SWFncEV1MjFVZjU5Q0k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4MzBpYV9nbHRScDhJdWV3TWFmd2EydXg2VmpMMnpQY0g3dDVmWUZsbkJmZVZSQm1CcEJkdUdvbVpzaUpFUXJiTGNKb1RsUVNRTW9WM3JCWXV0YnZFRFE9PQ==
of what kind?,r/machinelearning,Z0FBQUFBQm0yeGJ4azVvazNVN2UxaUVTclZyS0hYWE5PNHM5bmptX25aWll5MmlKUHA1RTNGOEtadDhYaVB2cFNIV2JWRW1GbFV1eVQxWHZLMUtudl9wZWk3S0FqVHVtRVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZjI0OGhFdlhoN2huV2ZscXBVbGtoMFFTSXpXRGx0N1JESG5wWXFxZjFTVjBBSFJvZjVzWTdweUM3aC03TGRqdXM4MkYwYUFkb21JdzdGYTBMajd2Z1E9PQ==
"Maybe dumb question, but how did you get 48GB for GaLore? Are you assuming BF16 instead of 8-bit?",r/machinelearning,Z0FBQUFBQm0yeGJ4dFJQN1VjUksxT0dteFRVMjZ2eWxPN3dqYkN5VnQwR0xJTFJKSDVDdDVXN1AzUUNxY3IwTjBZU0pwWnIzSU1MTW0yV2dGRTJLMFdiNU91ZzFGazl4T3lVWVhfcVFOLWFTMTRHZnU0RXE4eG89
i would image put on a classifier head. Train from scratch sounds weird for this,r/machinelearning,Z0FBQUFBQm0yeGJ4aDhuM0NvdTZYRV8xS1VxYndDSHEtYmkwT0hQdHk4ZG9TX3VjVjlHM0FPMXpIeW1sdmRMdDZNVlRQWnB0d1pkYlMyd2tNSzc3dEdybHhCazdoOGREMk0wbW9kQUhSV3VZUVU0TkNNNXgtVDQ9
"It does not really fit in 24GB (7B might on very low context, 8B probably not), and the next realistic VRAM capacity is 48GB. Might be 40GB for old A100s, but at that point it is only a difference in context length anyway.",r/machinelearning,Z0FBQUFBQm0yeGJ4MWtJSlMzbUxaZWI0cjVsclRVcWctQl9oWG02N0ZnTzliZ3dKMlNFN2xqRzdISHB5RWpLNDlrS2FFZkJER2FteWpobnFKR2lRbDE5OVJKR3FBSWpYYXc9PQ==
"I realize this is 5 months old, so you’ve probably already gotten your laptop. I've been working on my PhD thesis in ML too, and my approach was to build a $2500 desktop plus a $500 laptop instead of buying a $3000 laptop with a mid-level GPU. Then, I used VSCode for remote development into the desktop. This setup gives me the full experience of developing on my desktop while enjoying the mobility of a laptop. I keep my PC on at home all the time, use port forwarding through my router, and can access it from anywhere with my laptop. You only need to use the laptop for light weight work: reading, browsing etc... the heavy workload like training and running code is off-load to your PC",r/machinelearning,Z0FBQUFBQm0yeGJ4bkNpU0xiNHQwZGtLQVQtMUlzcGJtOHB2QjdPZV81YWpqSHNxeHIwaFE3V1NLWmVManVPaXZuZnlZNUk0RUo5TmhkY1dBMXpZNFJ2YnltcVdMT2FlZmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4WXdfWWJSTU5xUHBZcDBUWVlRUmJZa2JtNy1KcWozako2bmtELWk0bVJmNnVESmN5RWJ1Ukp2NV9OX3pZRC14WHVUeVpwbmd6YnJvNEt1VEl0TVhlRWc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ4eXVuYzZlUTNYbU0xRTFnWDZUU3B6Z0NzdzJtTUhHbVQ0eEI0MUZlazV0OGR0SEJPcS1XLUtSUEdndFZoblZtdERBUHlCdDB5MUpCa0ZONGF5WGd4ZE5aR0s1Q29LWUlOTHJWN2tRaGxybjA9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ4eXg5RzF1T0RmRnVyZWlFMTlNVGxjdVF6bHJSY043SFE2VmFwa2tOcUJEanpxRUg5SVBLSlBfQmpvVWRFcjdqdl9ZTmFGWG1nekFJWGx4NjJfc3llek9JdFkyZ3RPQTJGbjVWSjN0Q21ldDA9
The problem is the basis architecture we don't separate instructions from generation.,r/machinelearning,Z0FBQUFBQm0yeGJ4Vno0aDNPQVNXNTdsNG9XYWJvcU1ueFNrbDdodXk4VGVHMzZlb3lsNWNtOGFmb0VXbkNHZ0toX29QVWdGOWM1RHU5WmV2OUNCc29mdWlBaGh5N2Nqa2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4cm5yNmFhaFpLd01oYVdIaWtvcEVYcDY3X2hiZEVIVVJ1WUtHbjBEMGsxUkJwekh0RkN4amQydnZuSHR4SDJOTWN3VU9rOFVRMjR2ZHh6NzJKcGI5WkE9PQ==
"So I've started messing around with splines and doing a hacked up job of replacing weights in various types of layers with b splines.  They just seem to work better than cubic splines.  This was inspired by the KAN hype going around again.

They seem to be able to do any other layer would do maybe with a little bit more accuracy in tasks like shape identification and text classification.  I decided to go the other direction and try using them in a vae.  For simple things like generating colored shapes it can perform the task with some issues with clarity.  I've tried subbing in transpose conv2d in the decoder and that clears it up, but the idea is to use my own layers to do this.  
[https://www.kaggle.com/code/evanupham/spline-conv2d-tests](https://www.kaggle.com/code/evanupham/spline-conv2d-tests)

When it comes to more complicated task such as text to image like the phrase ""red square on a yellow background"" It completely fails.  Replacing the spline layer in the decoder with transpose conv 2d again mostly fixes the issue.  
[https://www.kaggle.com/code/evanupham/spline-conv2d-vae-funsized-dataset](https://www.kaggle.com/code/evanupham/spline-conv2d-vae-funsized-dataset)

How do I improve the decoding in this experimental layer?  Encoding doesn't seem to be a problem.

I've since added dropout and batch norm, and get an improved albeit blurry visualization.  Seeing what else I can tweak.",r/machinelearning,Z0FBQUFBQm0yeGJ4eEh5aURCUHFWLVhPS2kybWgwemVBRjBvelhXQ0ZMYWpyNTgyXzh5eUxUSFZRUlh4eGNQeDhra1RpVjJNZUNCSFVnNzRpWndwQUVteEh5NXRmLWJta3c9PQ==
I'm saving this thread for future reference.,r/machinelearning,Z0FBQUFBQm0yeGJ4Tzc4ZGd6TWsyYXg5U09oejl4R3JLS3lCaktEVDM5LWIybGFHYTBaVGE4T3p3SEMxOGtJSHlvOXBXRzFFclctRnB5d2hMZ3VPM0pTTVl2RHZFZl9UMFE9PQ==
"Lots of testing, inspection, refinement?",r/machinelearning,Z0FBQUFBQm0yeGJ4U29qUUJiemVrcDhpQWpuMnBpcXFCQlE5TENmcUZpOGFOYTRWWmdHdHdPcUl4RmpOYmswNWlvRmJnQzlwRUZHWW5RYVFYQ1VLLWgzNGVia3h2cDVkQ1E9PQ==
"I feel like guarding the prompt will always be gamed.

It'd be stronger to guard the outputs IMO, and we can use a small pretrained LLM (even without finetuning, but it would be better with it) to test against your alignment rules.

The only way to game this would be to make the assistant LLM to output rules as well to the guard model (but the guard model would not be trained to follow instructions).

Do this multiple times and we have a solution for alignment of big models as well. It's what openai plan in the long term if I'm not mistaken.",r/machinelearning,Z0FBQUFBQm0yeGJ4ZnVpMnRWUjlqdEtlMHAxRk5FMHlxOU82WTQ2SHotNlJSQjdzM1ptV0pIYjByMUxMdUZjY0p4V2dqQXRVNktmUjNUcHNMS3NKOWdXR3JoQ25pNXRKb1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4enFjczNpdlc2OGtOWGlMMTYwaVJsellXSGVqRnR2QVFPTGt6dHgweTdrVDJFUVppX3ozSndFYmlMb1NqVE5ZS05YWkEtRllTeDE2azRUTWExbUxQTGc9PQ==
I’ve been QLora training Llama 3 8B on a 4090 24GB.,r/machinelearning,Z0FBQUFBQm0yeGJ4Q1NQaEZHUjhXOTZ0SlBRSVVsRUZEa3FzV2VOSTJSSzBTNTZTWG9VNHVKNzd2U2dvaExUblN5ZGF3NDMxM21QRkxvVXNYM01kanNld2NsdUJGX0FXWXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4Y1UzdGRlUEFJT1djdW5ROTBzWjFUZm4ya2JYdHN6VTM1U2JzTmtROE56S2ZfYTVGM1ZtTjV3R0h0Mk5LRUFwaEFsT2hNQU0wMTFKU0pqd3VjMFRRZ3c9PQ==
Lots of systems also run a gatekeeper on the produced output.,r/machinelearning,Z0FBQUFBQm0yeGJ4Ny1uV1ktOVdCQlpCUzVNMlBlZ0xQb1h5V1cyV0QzQVBELXBGdXdiTFcyb2dkVEw0ZnlUMTVDbmlhWm9XWXpZMDRTMVdMX0ZIOURfSzlzaHFjaGdMZlE9PQ==
I will try this 1st,r/machinelearning,Z0FBQUFBQm0yeGJ4ZjZLbXpUcUYyWXBaSEt4OGl2aHlzYTA3dXNPaWdHdThRTmlfVUNGRHh2WnVxR3QtYzE4c0VUMU9kQTZpYWJOUGhXejctdnZWYVQ4dHV4UVhObDJUNlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4Um5JakNfazdxd1RZMEV3RnVYLU02aXN2YU9Qb05Qc3EzYWR3Q09YakJJUW9LeFhtNjZwQVUtNjVUNTFJaS1pQmlDNzM0eVgyZEpwcWdZMHpKOERGNkE9PQ==
Presumably you would use this gatekeeper model to block prompt injections from reaching the LLM in the first place.,r/machinelearning,Z0FBQUFBQm0yeGJ4emV1THpZT2ZuWUJOUV9TTVBFQlVTcVZRZXQ3ckFzNlFXd1NUS0dPVVhEeG1KLWpSYW40NXBEb3BEVXRKSEVYSDBOSFVaMHh1LXBRZFliaEVBTzZfQnc9PQ==
"This is LLM only, I assume?",r/machinelearning,Z0FBQUFBQm0yeGJ4VDByWDBiYThEZXpBcGxHUjFBQ1JvYndJa19jblVNUk9TLVpLSVJtX2RFZVNlMTNmZlFxeGhveUlkUmVjVzRLcFJndUxmN2VvaHFvNEUxOVM5dzRlWUE9PQ==
Hoz the gatekeeper immune to passing smart injection,r/machinelearning,Z0FBQUFBQm0yeGJ4U1BET2hTUktEYzVHc2ZRdU1xWElWLVFkZEJIQjFuNWp0cTdPZlV6cEdPcGhjaTNaMUVRRjlzRmR3dG5BTUh5UlN2eHY0OG1qTzlveGhhY0tFdVp0V0E9PQ==
"Llama 3 8B recommends 16+ GB VRAM, 12 GB might be tight.",r/machinelearning,Z0FBQUFBQm0yeGJ4OS1UcGFtR05fR2tlcU11MXhRVDNsVU96d0VUem5rWUpOcUdHUjRxR2R0ckp3SU4wNzZBZlB3NWFJYm5GdUltNUhLODVtbkJtZFZpMFJmcU9pYVZWNkdxWFBkWEhXdjFwYWVVUTEtTjJ3SWs9
"Hey everyone, let's keep this thread alive! Remember, if you have a quick question, post it here instead of starting a new thread. Let's keep the community organized and clutter-free. Thanks for your cooperation, folks!",r/machinelearning,Z0FBQUFBQm0yeGJ4VWU3M2x0c2xuTXFXNEdaeXNOc3RiQ1VyMFgyRU5DMkxNelQ1SHY1NGdZc0gzUUN0R2NJZEd1Z29QVjNzU2p0THFOSTQyazR6ZDZuV1FUNHlLTDc1bklyeDJIQXJPYVpITS16VEQ1aFl5c1U9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4YTdhb3QxelBKbHE1NkI0cmoxa3I2S3R6UnpGQVpmLWIwMDVsTVhFbVdGNjFLYlF3eHA5V3NkNnB5akl0SFhlTGVJUHBrdHFQZFRZV3pmdm9QelBkQmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4emM4RkFIWHF4UTU1Z2s4MC1xTVZIeVd5eU5aVEJzcHRqRlQ2NklRRzFLVEFNNE0xZnp0ZWRNNFZMQ2U2dGNRMWlhak5DNWxPTGc3WFZ1blVXRFphU0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4U1oxTDRHTjlZeXZ1eGpnZXZDZm42bFJVNFlTRVoyYVFlNVN5SElHMFBBbkhwV1JGMFpEVlp5ZnloRWY3ZWs4eFdXTEljMHFVN21jaExkeTREd1R6dmc9PQ==
"[https://www.ibm.com/products/databand/data-anomaly-detection](https://www.ibm.com/products/databand/data-anomaly-detection)

I heard a presentation at a conference a couple months ago and jaws dropped, from people with respectable work records. I can't find anymore sorry. I'm cautiously very optimistic.",r/machinelearning,Z0FBQUFBQm0yeGJ4cG50ZjFYSFMwU1RJRHJ2cG9wRGFTMEtQaFF4UHp3V29vdU53YU9kVktpZXhEQWV3cXhUZ3BhTDRhVGdVVE5nbFRyMk42dUFpcWtiWDg1Uno0cDBhRHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZktrLWJEX0JhV3FTblJna0I3UTVOSzV3YnhjQ3dzS3lGVlpqV0lNUXNzaWlrRWRBSXJOMXJSYmhLSkxHOVNnbTNnRjNzZDBnT1JxZDNoSkZ0b0Z1OHc9PQ==
"I have been scraping job postings from emails, [Indeed.com](http://Indeed.com), etc. for a number of years and ingesting them into a Neo4J server to infer which I should apply to. This dataset contains some exports from the server and about a thousand example job postings.",r/machinelearning,Z0FBQUFBQm0yeGJ4bUN0UlZUQ1R5Q0tWUktZMC01VG9nc3dmOG82dTQ3SS1xZ0g2Y1JxNU9USzlUdTRSZWc3REoxdzM2ZlEtSi1FZ0N6eTlYLWRraUMyR1RBNzJoTGRsX3c9PQ==
"No, it's MLP-based. I recommend taking a look at the article; it's very easy to read 😉",r/machinelearning,Z0FBQUFBQm0yeGJ4bmV2YUNhZUUzSmFaLTh4MVNWZ3MyczVhVmxoUi1WaDZvQU5ZSFctNmNVUXlBX0lkdk5ybWxtRE9YOVo2emRwemM2X0FnMFRRSFBmazZOMXFRcXlFYXc9PQ==
Thank you! I'll check it.,r/machinelearning,Z0FBQUFBQm0yeGJ4ZzZrV2tMMXN6M0VrLXU1VEtXb0xPMkpMSDBmbnV2d2dDWHk3NGphNjB1ekxjNEF3WEl6SWNKTmRiVklwQzJucnYwaVA5OTZqekp4VlREd2dUWFVlTnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZnludExHRFZ6OHI3ZG4yYlJfc2lkR0pZdkhWWXdWN3lUYVlUZkJfMzd1dlk4OWR6N3Y0Y0hqNlppb3RhcnJKdW5GSWZTM2RfcTNrN1hwdTdYYV92VXc9PQ==
Your comments seemed to be quite accurate to what I had in mind. Cheers mate,r/machinelearning,Z0FBQUFBQm0yeGJ4VWdXTnFvX1UtejlIRE1GNGhfMGxRdUlUVUNZa2JrUmxyTFlYTG0xNW0zR1c0emRUc09hSnU0YUpTWEU4c1FPYU9SZXdqZ1lCV3lnbHVQWDYtSDBheG8tcU1iTEhsQkdQOF8yb3FfSVJtdTQ9
I Will try this !,r/machinelearning,Z0FBQUFBQm0yeGJ4Q2NNQU9tenFYU2ZpZ2pBcnVKZmhXS2xQdTJOb184M1FwTXcxMUdWdEROU0hlbmdjUkhaM3Z2RXVlcERrWndNM2dLMl9GMWtRbktxQ09aWlJ2bzVrTDloeUhQQmsxNFpMRjRoaTIxM2ZRQVU9
"Very relevant comment, thanks a lot !",r/machinelearning,Z0FBQUFBQm0yeGJ4QVlnM21CNzYzbE9BelRqYTNRWl9TWS12bzJlc3d3em9lQW53V0o5dWd2LUlmQnRoWnZpMzhxY3dIQkpiSmRmZk5yVjByTG9DckxLZ05tVENqSWZLUWRwajh4WVVjdFl2aHdPcnFJMEZGWDQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4YTdKMXVUdHlPUWdZbmNPRDZxVmFuemFQdWl2UlVHRDVFWk9PcG42Sy1rNWx6MG45c3E4Q0dlemQ3X1VYczhJUjFXYnlLZEZEVU44SnBiXzhvSUtQMUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4QnVCYk1TTDlOanhoUXZ0S2FkbjJoUWlQZjFRTW45NzJFVEkzUFBySFZweE4wREdENTdCSmpTcTFVaHYtMzAxR2pBQ3Buam8zbnVjNUsySDg3a3J4RXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4dWJkVW81bVgzY3RnWlpYTDBtQXdMRHc1S3QyUVJidW80anRVUGV0R1RsdEllbDRQWHZtdlgtblJoRUtuSVl5ZDloOVEwelVrdnozTVRmZFJyek5GY1E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ4SUtaZWpwcGI0NTRTbkdpcjZxUjRwNko3dmxaaHNIcHI5aldESXdJVjNpcGdaci1hdmZVUFNNTjF4cm5ZeWFtcFpfN0kwdDI2ZGdHWVVwcjlXZlhhczlVdHAwVDRmRHdyU0w1aWlXYUdXd2M9
"Didn't the paper say, though, that KANs are suited to smaller scale problems in science and engineering, where the data may have a clear functional form?",r/machinelearning,Z0FBQUFBQm0yeGJ4Mi10cTVCTTlWeThqUWt0dXdqRDlSUDNhMXk2cEpvNEFKcWV2S01CZHFiYUY4Y3A4NllfalFQME8tODZXZld6Y1VRTnJVRVVQV2p4VDByUjU3RHZManc9PQ==
modssss i dont want to see this kind of stuff,r/machinelearning,Z0FBQUFBQm0yeGJ4MGxXbXdiZUtGX0l1NW5TRU9FWVJKa3dZenBkY2Naa1JNdTN2aEhacjJhWXhzcVV5S2hNcFFfQWdXS3pfUU5oS2o3b0JOd2hIOFhlSk5HVUI2S0tFQ3c9PQ==
its impossible to say without knowing the dataset. I work in industry and 90% of successful model building is understand and processing the data.,r/machinelearning,Z0FBQUFBQm0yeGJ4dXpCcnNzejBxemJnVVR5aWZaazlCTHdqTmNtV1Y4SGxhMmRsUVJmanl3eURHd3FPTkZsbkF4R1E5SmtCSGl6czU2R3dJQ1FfUG1lTi1iOWY4U2h4ZFE9PQ==
What industry?,r/machinelearning,Z0FBQUFBQm0yeGJ4NVZkNzdBQ2J0SlhtSll4YlItNFp6Z3ZPQ0hfYUtvYno4bEtmMDBnOFB2Mmx5N1J6LURFMmU3bTBJczBWYUhKS3VUcU52ZmtnUUM0VlprLUZoazVPaFE9PQ==
"I like it!

It makes no sense that most labelling tools are so clumsy. Labelling is the most important part of ML so it needs to be as fast as possible!",r/machinelearning,Z0FBQUFBQm0yeGJ4V1JNekliYUhHQVJ3YkUwOVljclpVOE5RdVR6RW50TlBFMXNQdThqRzNENXdqV2lPVEtvSFp0R29KZU8zcWZPREhua1BMTmdMa1Y5ZElydWt2b0pwalVyVlN1SUNZZkFUblFveEZRRjI2blk9
"Use a foundation model and finetune it will often work much better.

To answer specifically to your code, I often see multiples convs layers (2-3) before pooling. If you stack several  conv layers then its equivalent to having a bigger receptive field instead of using a layer with a costly big kernel.

Also maybe you overfitted. So try some regularization using data augmentation (strong and weak augmentations), even dropout. Also it is weird that BatchNormalization (or variants like LayerNorm) harms performance as it is often a key component of many neural networks.

Looking more carefully to your optimization (optimizer, scheduler...).",r/machinelearning,Z0FBQUFBQm0yeGJ4YUZ3WWY0cExrRjkxTHZUTFZJMUNSZm1PUHg5ak9OZlhZckNrVE1KSDgwN05ZZENFanFjTzV1LUFuR0hqLW05VXc3MVhuamRNV1JMOS1Rd0JKQjQ1dGc9PQ==
"> Huggingface on the other hand is completly hiding everything, which makes it really difficult to use if you need to do a different thing in the slightest way that what is expected. For instance it's not possible to do online data augmentation. 

That can’t be true! ",r/machinelearning,Z0FBQUFBQm0yeGJ4bnNsMW44MlJTQUhJZEtWeGR1Mm1QWWNxN053V2xqQ0twS05ZWnZuenJJVi1OcHY4VDB6cUlyd2Fyem56eUpPa1lwSjdETjE0VzJnSVQ5NlZkc2R0SXh0RHNtWWhQeVBqdW9KVkdLTm9VUDA9
"Pretty much. If on Linux great, but a lot of people are forced to use Windows. ",r/machinelearning,Z0FBQUFBQm0yeGJ4cE9mVVpfTzhNUGdJc3JBYkVoSWZiWnkzYjZtakdvY2dLUWFqTzJFT0pqTmlqYmtpb0dRelhxQ203Q0RkZU5qZFlIclFMTnE0VlBnX25LOWdWYTlXMEp0LVR4cURoa3FnVjg3YXNUTDgwVHc9
Okay here’s the link - https://www.kaggle.com/datasets/brendanalvey/stanford-drone-dataset,r/machinelearning,Z0FBQUFBQm0yeGJ4STNlNVAzTkYtMm5VN1BNVEt0Y092S0hVVjhpX1FqLW1aWnJJWDZMUDlrYTRjQ0JxNy10S296RnJhb1hZRHRwaHg3dlBtaS03cVlfQkN1S21DdWgtQ1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4bHFYbm90M1h3MUgxR1NIY0NWWWlYcHN6TEF2ajNWcW9pOFFFMlJOQ3c1d05ZUWpnbnF4R21QZ1JZWUhzdDhRcXFudGJSN0Zidk5FclVFVVJ1WVV3aFE9PQ==
"I did it! I stopped gnome by running `sudo systemctl stop gdm`, opened a tty shell, and saw in `nvidia-smi` that nothing was using its the graphics card memory memory. 

Then I executed this command the command below and the example ran inference on the model almost instantaneously:

>torchrun --nproc_per_node 1 example_text_completion.py --ckpt_dir Meta-Llama-3-8B/ --tokenizer_path Meta-Llama-3-8B/tokenizer.model --max_seq_len 128 --max_batch_size 1

But it sucks not to have a GUI. I wonder if it's possible to add another cheaper card just for graphics and use the 3070 Super Ti just for compute.",r/machinelearning,Z0FBQUFBQm0yeGJ4LTU5Qko3TlZjZUtZSUVqb1pjMDBST2hQRWtSWVBJU1RQRUwwTHNjOWt1WUFiVTdYTXBQeEkxUlVPZHVLbExlNU92RFd4eTBlZFJpQjhsRmNKRjZyckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4eGpLbVZzZVl2NXFwX1NidWROd2NHS2k4RkdHaE9qRDEwUHhYV2tKNHptUFRLZXd5Yk1jZ3E1b2twTXZZR2h4NHY1SEpsNjl6U3NfZGNkWE9Yd0xMUlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4ZXhMZ2twVkw2VGFkdHRVR2w0YktQVndxZG5TZEVuVE82S2EzV0xqQ2N5V01HYnUxQW1tcGNpbGdfVzFIT0FIbzl0Yjl1bnlHR2RzaW5ZOUJ6R0ZEWEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ4VkxQWUdyWkdPeHZVVGdxQkM5X3UxMTZWcUY3ZnBXelBNRGNEUVRKYkNndWxGU0lqSU1nanhuU19INkdrbFNkSlkxNVRVMUJEX1lfd3lPM2N0MlJUS3c9PQ==
"That doesn't really answer my question per se, but fine.

I just have to say that I don't see the appeal of a generic time-series model - feels to me like you'll always get better results with something trained specifically for the task.",r/machinelearning,Z0FBQUFBQm0yeGJ4X3NQZ2l3RU82VTNfSGhaTnZFcEx5UF9Eam5VR0N0MWtPY1h4aDV0Zzc0aFVIM2tXZmhXeDdBaF83dVhiV25mOEptcWdpV0JCcGVDOFJRR0VKcEV0WUE9PQ==
Looks like a Seq2Seq architecture with modifications for time series.,r/machinelearning,Z0FBQUFBQm0yeGJ4LU43bHktTjREZWVfQ1lJYzAzMW9QQkVLT3I5bUc3eU1XYTMzVjBRSDN2ZkpMbjRnRU5VS05vU0Rva1hoYmVEdzBOWDZRc0dqS2o4ckVJdWpZdlp6YXQ2RlRxT00yQmlOZnBlVDhLNEJfSHc9
I use [writehuman.ai](https:\\/\\/writehuman.ai\\/?via=aihustle) and it's very good,r/machinelearning,Z0FBQUFBQm0yeGJ4MWNld191UHBpZ09xUWpGYVdYUlJ3bmktU0pqUGM3X1gtTHZqNVpUWVgzajc4dTNrTExlQl82b3BXdWFiRllOb28xZVozbWNpRXZQOVU1UmE4LW1jdHc9PQ==
"If all we know is that your function is differentiable, you can only randomly initialize and do gradient ascent until you find your value.",r/machinelearning,Z0FBQUFBQm0yeGJ5ckstdVFxcG0zbWxPcHNQNGljUVJvQS1vajFRaHl5SHZWaWl0aUhiZzE4Uk5qTXFjQ0xETmJnampCNDUyN2ZYOUNvVFdpdV80Q3MzRGNQNXVxajZfSHc9PQ==
"With 12GB VRAM it took me 13 hours to process 50,000 pieces of text.",r/machinelearning,Z0FBQUFBQm0yeGJ5elNoem5zZEF4Y2FSSEdOcXRtMm5ka1QtZXlIM0kybVhiV3diazlmTGlYMmJVVVdwQjdNSXZockJwMDhIWnVyemJMQkVYNEpCSHZ3MHZVZEFwMENQZkE9PQ==
Great idea. I have been working on multiscale object recognition for a couple of years in a self-guided manner (I'm doing phd but my professor is not well-versed with post-2010 technologies so I'm mostly doing independent research). Let me know if you would like to hear some of the challenges in this subdomain.,r/machinelearning,Z0FBQUFBQm0yeGJ5RnNLcUlmTEhBdmNsaFBTZFRpbjdHUko4VjhiR3d1X0MySGplZFBYSnBsc1RiNFZ3d3pVZGlJNVNDNEt5UjhHdlNpTXhWQXI2a2hVdUhINHh1MXRDaUM1MUN3azUyTHpIVE1BVHNwNWt6R0U9
"TTM still outperforms models specifically trained on a task. In fact it does so across numerous datasets from various domains. The authors use some clever techniques to achieve this!


No, it's not an LLM, unless you mean something else. ",r/machinelearning,Z0FBQUFBQm0yeGJ5UXJXUTcwMEQxcGE1RnExcE5QQW9OQlFxVkdLQzRRdTVDSjY5WDhhdG0xMUdJR1dFQVVkWnVidnhhX2hzS0VDaHI2NHJJTU5kN0FrQXNfZkg4ckVWYWc9PQ==
Technically yes! The basic modification is patching.,r/machinelearning,Z0FBQUFBQm0yeGJ5eVkteUMwUVRoQ3lqLUNSQmpOUW1mNlVzT1I5QkIxaW1vSVB1RUJobXlnMnBJS3djcTZXd2x6a0JLQmhxYVZqYldWbGIteEJEdlJ1Q0lyZGpOWFliN1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5N252elI0WUNzWUdnc1N5S3lkNmp0Y1BQTmZ1X3hWWVZwWnBSZmhPalFkYnRBcXFMSjhBa2UwRVc3My1TcUtMYVF4MW12SlZYRzhMc3pvdi1fcmdPX2c9PQ==
Checkout unsloth,r/machinelearning,Z0FBQUFBQm0yeGJ5bHdxN3hZUEZPbnpsSXNCN0ZQd1p5WEZPd2xES3BtTkFZODBQS01nVXhPS09ySzU2cE1wTHMtbm1aOEN4ZmNsa211ZEdEQ2MzcmNDemE2Vkt6dUxJanc9PQ==
Transformers.js is the answer,r/machinelearning,Z0FBQUFBQm0yeGJ5U1RyempiTXpkakg1R1VYa0JrNXVHUVF6NS1zVUlQWXVfdWJTd1BCNlltTlF5N2FJbnY1SkRpV0VTSWx4M1NFWTIwLWpObmQ5NEFTcWhud0NnU0dyNnc9PQ==
"The paper's abstract:

>AI systems can take harmful actions and are highly vulnerable to adversarial attacks. We present an approach, inspired by recent advances in representation engineering, that ""short-circuits"" models as they respond with harmful outputs. Existing techniques aimed at improving alignment, such as refusal training, are often bypassed. Techniques such as adversarial training try to plug these holes by countering specific attacks. As an alternative to refusal training and adversarial training, short-circuiting directly controls the representations that are responsible for harmful outputs in the first place. Our technique can be applied to both text-only and multimodal language models to prevent the generation of harmful outputs without sacrificing utility -- even in the presence of powerful unseen attacks. Notably, while adversarial robustness in standalone image recognition remains an open challenge, short-circuiting allows the larger multimodal system to reliably withstand image ""hijacks"" that aim to produce harmful content. Finally, we extend our approach to AI agents, demonstrating considerable reductions in the rate of harmful actions when they are under attack. Our approach represents a significant step forward in the development of reliable safeguards to harmful behavior and adversarial attacks.

The paper builds on \\[representation engineering\\](ai-transparency.org/) (2023) whereas the Anthropic (2024)'s work uses sparse autoencoders which is a bit more roundabout.",r/machinelearning,Z0FBQUFBQm0yeGJ5MElweFR1cHpxOTZQUUhDM29qVzJsNEJUSlRhb0RScHJGLVFKRjVCZlVCdkNmanlaakNJNm5KWEN3WG9qU3NWWWtmeU1IVGI5bG5QRjY4enU2dzR6cnc9PQ==
That's a bad suggestion. Everyone I know who has a PhD in an AI-related field never regrets. PhD degree offers way better job choices and job security.,r/machinelearning,Z0FBQUFBQm0yeGJ5NXpqa0JCd0g0ZW5VT2pSZno3M2hUU19JMlBBLUdSU1lKUmZ0SnRQR1BRTWdPTUlrZUR5c01RcmsycmZSOTI2b0czQVMtUHJWQnk0UVdETTFuWXp2NGZkMEFkRmhXWmpUOHpuTUR0amxXZUk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5cUxGLXZHbjgtWlc1MWs1QVNkeFNvdURYMGNvaWc2cHBaYUptZWdKNUpTQ2Jpa3JZU25VbzhSQlJSc05ucTFmRVY0RFV6MDVCRzlGZ2N3SVh3VlFZVFE9PQ==
"The rule of thumb for full model finetune is 1x model weight for weight itself + 1x model weight for gradient + 2x model weight for optimizer states (assume adamw) + activation (which is batch size & sequence length dependent). 3B in 16bit is 6GB, so you are looking at 24GB minimum before adding activation and library overheads.

Of course, it is likely you don't need to do full model finetune, where plenty PEFT techniques are useful.",r/machinelearning,Z0FBQUFBQm0yeGJ5bnRFSVp4UmNLYUJQdXRlVno0VURNRkdaVjBfX0g1dmZEczJ1MXN4aGh1a2I0RHRxV1VSMjV2TXZvbUFHV2pYODhEZ09HakxCUm1YcHpJM1U0dFFQZFE9PQ==
"Essentially what you are trying to solve is (imo) best framed as an inverse problem. you have some forward model mapping x to y (say image to label or downscaled version). now you set a prior on the space of images p(x) and a likelihood p(y|x), where the likelihood controls how close the sampled x should mapped to y and p(x) what you know a priori about your dataset or x distribution. This can be solved classically by mcmc and in the world of conditional generative models using conditional NFs/Diffusion/flow matching, whatever you like... let me know you want more input.",r/machinelearning,Z0FBQUFBQm0yeGJ5bVZ0V01PQi1CeXFOQ3BQTmdRTHRNR0cyai1zUDJhWW9rbVc0MUc5V3Z6anhpMk9ILW5vNDNKcEVaT2FkckpxSmpyNTBQcnZZYzFWajVzNzJEVzlDNE43RnY4MG8zaU9oNVdTYVBncXJqS3c9
"Considering the size of LLaMA 3 8B, 16GB VRAM would be a safer bet for local training and running.",r/machinelearning,Z0FBQUFBQm0yeGJ5MW5OQWZodDVSS1A4REREZU9IeHlxX2dqQ2xHUldZMUszbE5rcWUzS3d4d0YxejRmSFBsdElEUFlwSXlNNGkxUkw3OXByclhwOHZOWUptc19vNVFEeEE9PQ==
"Try exploring invertible neural networks (INNs) for bijective transformations, they might help in your case.",r/machinelearning,Z0FBQUFBQm0yeGJ5WEJHNlhxOURSNFIyM1VoRXNrXzVSV3M0NWZBYU9sVklldnhuLVRKRW82cDlqdllUU096Wk1PQ3pOaVljNklnSVZ5SWFnQ19kaUxNZ0FWYjFmVUNrMHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5eDRsVlBGQW5tVXctZ3ItLUhUejJMbTRwT0tMNkFoV3UwdWJ2Q1R4TG1XdzJEWVB3WWJIQnNrRFBlaGNZOEpHWUZDYWd6dlpWQnBzZml1dFRFRVZudVE9PQ==
"As you mentioned, I think a solution from generative modeling will be a better option for you. 

If you try to minimize the error of y and predicted y to get your x, you're probably just ending up with the Expectation (mean) of all your inputs that match that corresponding output, since you mentioned it's not bijective.",r/machinelearning,Z0FBQUFBQm0yeGJ5SFN2dVBBWnZTUHYtUHgxb29QOTE5ZWhJcFRhNEo0UWZhU2h6Vk5YQ3hDYTg5TDh3UVAwQnlYME1IS0JMM1ZJcUdTZFN3VWZMNWVXT0RHLS1PSGkyVnc9PQ==
"Nah, I'm training forecasting tools for clients. Forecasting as a service.",r/machinelearning,Z0FBQUFBQm0yeGJ5aDg5SWU1VTNVSElCVS1NYlNlM2p1Y1RxMUExNUtLdUpiWThnU1FOREFUYk9FZVA3MEY5UFRlMHFpOUczeExkY0hWcmNJLTA3SzRIdzJWSXdwRnJpdlE9PQ==
"Sorry, I'm not actually doing credit. I'm trying to protect my identity I guess. Just forecasting. Point is: I need a system to train several thousand unique models at scale",r/machinelearning,Z0FBQUFBQm0yeGJ5NVpmRWlrTWtyNGljT1c5dlJzMUw2V3NCalBFWjlZc2x4QjBSTWIySXc0YlFyajhHS3VGOWdCWFJYNkJnRVkzVEVDUnVHNnpSNUlDTmF1aGZvd0pLd3c9PQ==
Yea that's what I was worried about.,r/machinelearning,Z0FBQUFBQm0yeGJ5bnpGS3FOdE5aWkZKd0NZM0loNFBYSThMSkxyR3hudU1yQ0I1UGhUNGM5ZHZlNGNHb2c0U0p6NWRXV2w1MTU2eG1nd2dLRzZzRGwyU3BEY20wRFJsQ3c9PQ==
"One model not possible bc security. But noted: loop over each client, each sku per client.",r/machinelearning,Z0FBQUFBQm0yeGJ5S1BHSGl0WTUtdXF4M2ljZGdYYXhvdUZxWTd3bjVHT09iSGhlNjVWNy1XQjc5a0NGamxyOWUtRDZIckxQcTNsSXJqTFpxMHhqeUZOd3BIdEFIUldDdnc9PQ==
"Model risk is not as much an issue, but monitoring is certainly one. Any good monitoring tools you recommend?",r/machinelearning,Z0FBQUFBQm0yeGJ5TnBpYUh1QlRQSjZPcVJ2dm40WkFya3Zwa0xGeXViYTJubGhyWExMYldDQWJ6VWpUWjVpLUs3LW1tWm1EZ0tNYkdzWWZUYllkSGhXWDdiaFY5clY1cGc9PQ==
"This year's gonna be a collusion fest. Saying this from experience in my own lab - ppl of a certain ethnicity talking over with ppl from different uni's and companies to, well, ""help"" each other out...",r/machinelearning,Z0FBQUFBQm0yeGJ5VjdvdEN2UmFIckhzS00tOEdkZWVEOG1JM21KRmFDX1Q4TEpoT1dULVNnYmRvSG9nOWljMWVxZDJlNzBwaHI1V0k3UERvdXhwYkM3MFRKcC1rX1EzclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5RkVkRG9lcENSOTB6QkYtWHNJenZsSXpfcnBkd2w0UnVUcXkwZF8xQjZyR2Nqbm5zdTlhNU4wT1FoYnZBTnZHc2NoMVRYbVRuWGtLOTU5cEV5TjFfc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5TjA5NDZjakZQNHEydllHeXlRMUs5ZHpUUDAwRTVLVEh4aVRiU3hyVEdMWExvRllDYTFHUE5ManV2cFZiWE5PQ3FyVC1jTTlQcUZWX0w4TGpra1A1bnc9PQ==
"Look at classical optimization theory “root finding” algorithms.  Local minima will be problems.  If your function f is really nasty with lots of local minima with close but not quite there solutions, particularly with fractal basins of attraction, your problem is intrinsically difficult and you’ll probably need stochastic optimization considerations.

This problem is decades old and whatever has been done, published and in packages will be much better than something you hack up.

Can you approximate f with something simpler and go from there as first guesses?  That’s where modern machine learning may help.",r/machinelearning,Z0FBQUFBQm0yeGJ5R2tpaVNNU0Z1TFBZY3N0NVhFLWlJV0tPZG1vcTRqOUFyRjA5Q1RsWWlhLWJMdGxOQ0ctOV96RFItQUFIbWQ1ZDNEQWFFeXpCZmNMS0YwQnFqQXFqV2c9PQ==
This approach is what I've tried and it gets stuck in local maxima,r/machinelearning,Z0FBQUFBQm0yeGJ5UkZMb2NkTmtNSENNZ21iVzcxbzBKNDUxVXI2QzR3VnlHSkZJem50aDhPaW5hREE5X2w1alB1eVI2Y01QaVlPNVdrRDlIeGw5QzdmNENGNmpoaTdBUXZfRm9fUHB0NlMxMkNtNnRFdG1PRVE9
Thanks! Any specific paper/implementations worth exploring?,r/machinelearning,Z0FBQUFBQm0yeGJ5Wl8ydklHV0F4bDd0ejFPSzFMUDJIWTU1RUNOc2VLWEtIQkVmWVRpenVzUkFfSWhNTHRIOWVoUUdmaGFUa2JrekZYNWNSTy1ubWRtd3lRQTF0VjR2YWZXd3dWYUdPYzBkUk94WUo3NTE1dkU9
Are you running Intel? Maybe you can use iGPU for graphics than?,r/machinelearning,Z0FBQUFBQm0yeGJ5OVczam1uU0tLdmJsY28zbG1odWJsdnhReENucm00U2RXdUEtMVctOXFQNUhNa0dpZkVFdm1BcmFXNGtxVlVGVnE3MXE0NkF0OVZndDNpcW15UzJhQmc9PQ==
Thanks! What do you think would most likely work? I imagine the generative models might be more powerful than mcmc?,r/machinelearning,Z0FBQUFBQm0yeGJ5OWJab2QzcWJBN05vRGtxc0ZGS3N3bU0wV2xXMXVGQmh2dEsyWHQ2ZXBrTm5WMzk4cV92SGZ2b0lFdmZLSjdYZENYcUZUZGlvc3UtWVdLV1FHX2FWTFJGY1k0S3lLaEVlMThsZkVVYVp6Uzg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5SlZCV3ZDT0FzSjBxcGNwcVVsbldhN0l0d3o5Wk5QNXdYRGJuZjVvMERlUW5JdVZwS1FYamVuR0d0VmUxMEVqUGRGbzNpU09iNVZ4N3UxcXZfaGF0aEE9PQ==
"looks dope! is it open source or are you planning to generate revenue from it?  
Also what tools/libs/models did you use for this?",r/machinelearning,Z0FBQUFBQm0yeGJ5VElzWVd6RkdhTUlUZ2JjYmM3QkFnb0NpRlJ1RDVRQzVTSFdoU2xEZ2hoSkdLOEdIVC02em5MRm5fMnpfODRoVk1sTEdlRjJEX0FPdVZDd0Q5NmJWT1E9PQ==
"Thanks! It's not open source but free to use for creating public quizzes -- we have a freemium model.  
  
Tools wise: we use pdf parsing via \\`unstructured\\` library, then do our own RAG with open source embeddings, then use llama3 and gpt4 LLMs for different parts of the quiz flow.",r/machinelearning,Z0FBQUFBQm0yeGJ5c2tGb2JDb1BwSm5VbTVMYUNVaXhJTjJoandzaE12bDVfbkdLb3piVFFEdWVDd3RZT3JSOFVXR2dSQzFyV0Fzb2hndnNjWEdWUFluWWtIRUxyd0NaWUxYREdQZk54YkhIMEVOSHhWY0tING89
"very cool idea! I'm getting some questions that are overly factoid-ish (e.g. recalling the specific value of a hyperparameter), the prompt could probably use a little polish",r/machinelearning,Z0FBQUFBQm0yeGJ5QjdCWHdRV1A4aVhWT0ZnX1MtanVna05hWUluUlMxc3dTQm1RSHZQeTVKcVpoaUFRNEowcDRFaGszcW11eHgzaEdEdEZyeEg2SHJPUlFqWHAtYXoxZGc9PQ==
"Thanks for the feedback! That's annoying, we'll look into tuning that. Planning to improve it a lot UX wise too.",r/machinelearning,Z0FBQUFBQm0yeGJ5Ym5TTk5LZlc3RmpWakJjMzVvUk9VTjc2T0xwcjVHQjdMRjFLaUNUN2xrV0JKTDhGNFp1d3hzNUtVS3I3bFJadTV1TndvWmU5dlFFNHl3OTFRVTFqRDczZ0R6cjl1VVhaZVRIeE1kWnpVd0E9
"Yes, I'm looking at ensembles now.. when you say ""incorporating domain-specific knowledge"", are you talking about fine-tuning the LLM or an additional instruction in In-Context Learning ?",r/machinelearning,Z0FBQUFBQm0yeGJ5eWNUaC1lVnNZeW5lczRfMnU2V0JqWkk2U2hSd3hpUF9XeGJma0VQS2FSQmUwUjBDZ1h3VUpnNk5qRVN4MmhoNzNseVVLNC1UUXZjY0gzcFVSQ0FTRlE9PQ==
True. They can still offer higher guarantees than just using In-Context Learning.,r/machinelearning,Z0FBQUFBQm0yeGJ5dzNWYUFDb0d1dWY4T2IzbU4tUUh6M0k0QVo4bnJsRVVjZWVoTkh4ZjEyRm1ER3ZlWmZhSU1ibFpEYms0anRzRko0QVNVRDhuTmdkdlgzVnhXaUY3T3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5cWsybVBSbzNSZzhBV0FWZ2xRWTlQWnRoc0xlb1ZnUlI1OEVRNGJDdUtBcDNqWmw1bV9ENUQwLXhBSEJiWnJOcGdjbzcwQnhPdGVPUzg3ek1GcUQ3X0E9PQ==
"Yes.. a constrained iterative combination of these steps is the cleanest approach. But was hoping the inspection step could be further optimized for reduction of manual effort. Perhaps, identifying a subset of samples that are particularly unreliable which can be quickly reviewed ?",r/machinelearning,Z0FBQUFBQm0yeGJ5Z0tDZkR3S0daLUpIZDd2QVlOZU5wMkVVTkp4dWRNSTRVRXFXRWpUY0lSZXJDNlB3NFUxRWR3UVV3V2xncHZMMktVeTBOTFowcUc0clFabWJKUk9hekE9PQ==
"What is the difference between this year and others , if I may ask",r/machinelearning,Z0FBQUFBQm0yeGJ5bl95dGY5clAzbXJQMmNvX3VPMF9WNFUzLUpxU0QtSkRTMldndVZ2U1ZFdFZINFRiaHoxdTBvTkNsYkUxM2pGQjl1QlhCb3lONmg3bzllOEg3YUZUUWc9PQ==
Can you link some of the decades worth of solutions and packages that I can try? What are some stochastic optimization methods I should consider? How would I approximate f with something simpler? How would I quantify what simpler is? What would the goal of this be (maybe make the loss landscape smoother)?,r/machinelearning,Z0FBQUFBQm0yeGJ5ZU9yc3dSTFZHVkNIbW9RUW5ZYUpXSFljTUV4d1AwYUdmZkVpajZkMkRlSTQ2V3FsR3h0UjhFekFKY2s5cmxXNEotTmJicHpORTRlX0JPbDlSRWlybnBLdURQVnVvMW43VUk2czdWSTBnWkU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5eWlHb215OE5GVGVUUzdial9sU3dHb054d2tnaGJINGF5aDJCZ2tmVTdfNDZmTjhnNkZ6SFZvX0FReENhQVFJY1FQWTNoa3lHSVAzNkpvamJxRHNTNGc9PQ==
"# What's the current state-of-the-art techniques for recommendation systems and among them which one is feasible for a intermediate learner ?

I want to build a movie recommendation system based on neural network for myself to learn .",r/machinelearning,Z0FBQUFBQm0yeGJ5NUVtNGQyMTFRcjhMWmRUSkNHa1prMlAzV05OREFYUHl4SmdMd3NhWDdNaFBYc3dKTGhlUlBlN1BWOGRQWUlxejJhUjZJV2xncnY4TlhPU3d6SVpEcEVjUWlHeXRqSGx3Sk5TbWliSDdGWGM9
What’s “not bad”?,r/machinelearning,Z0FBQUFBQm0yeGJ5Y3k0b3l4R0dVbHAtOGN5TDNNMU1URTZVTHBQTkthOXlSR3RfdFdQdTdfRmJXOFV2UmR5b25oLUtUQ2tvZ21hTTVkM3BIdElUZ21ZTkVBb19nMVdIR1BwUFZXXzUzaHc5VHRoaWNlbUh1OWc9
/r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGJ5YWtpakdCREsta3ltc0xhZ3VJTGhwa2ZfUlZNTkVUVEhFei04TnozRmZNZzF0Z0I0aVhwbWFodGFweUNxczhxTjJjVDN4c0JkM1FLRTk3eFJtM3gxSDZoUlV0c01pcm03MzJRUFhwLXJyd2c9
So you simply need to train a function x = z(y) that mimics the reverse behavior. Just train the model normally with y as input and x as output. Since you already have f you can potentially brute force your training data.,r/machinelearning,Z0FBQUFBQm0yeGJ5QnhEaUlaV1V6aVpKbDV1RThaTDFIbWNKUkZXWFZXZ2VQNk1jTk51U241WHRoZ3Vyd1h3ZWV5N0ZlWUNoOTFMcEJ3ZzhwLTQ5NTA3QXZPX0h5MFRxOVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5MWFNT0FsRlVRZ0dYS0c3VndRaEF6eUxMM2dtVmhJRFRCdFVYc2NyYXQwLUFxemdtbzR1bmRtMm1UVGNMb3NXZVIyQmhtTGdNN3NfZVZYaEhTOTh2QlE9PQ==
"No, Ryzen 3900X. The Ryzen Xs don't have a builtin GPU.",r/machinelearning,Z0FBQUFBQm0yeGJ5cC1zbkhWMFBOdVZFdUhNU2hGa2hDellOQTcwVU11YXpSUU9mdlBlb1R1TFduU01HcEJmMXZqZkxRZk53NWlsajQyR0ZjdlRUT0I5cVp6WnVuMFlhaGc9PQ==
"As f is not bijective there are multiple possible values of x that will map to a single y. I imagine this would fit to some average, hence the thought of using some generative approach.",r/machinelearning,Z0FBQUFBQm0yeGJ5U090T3NZX29MTFpwY1pvLW1UanJWNHdlajhPczRienlPZ291RnZCU3dFaDd0RHRMREUxUlNYYnhTdEhQbVRoanpRYVZSY1VEeHNodGw3ei1XTndpMFFveTFreHl6MU0zM3dnaDEzbmlMVUE9
"Maybe you could train y = z(x, noise) and hope the network makes a random decision based on the noise.
Or - since you have a lot of (potentially infinite) training data - diffusion sounds very promising for your usecase, where you model z diffusion-based.
AlphaFold 2 had the same problem, since for proteins there might exist multiple energy minimas, so they „solved“ this with diffusion in AlphaFold 3",r/machinelearning,Z0FBQUFBQm0yeGJ5SnZzaDJPa2I4MDhOT0hydmxsOENvRUZ3VGxOWER4WjIyVjhTcWQwREd3RmVMQnRKU3dndXZ5MHNsUXVEV0tmbGtyc29ZNzFHalVoRDk4eXBQQUlDNEE9PQ==
"
The line that separates large language models from other language models is not clearly defined. From what I've seen, starting from 7B parameters and up, they are considered large. Again, opinion may differ.

To give you an idea of the amount of memory these require, remember that one floating point is typically represented by 4bytes in the GPU. So:

```
7B parameters =
7 x 1000_000_000 x 4 = 28GB

70B parameters = 
70 x 1000_000_000 x 4 = 280GB

175B parameters (GPT 3.5) = 
175 x 1000_000_000 x 4 = 700GB
```

You might find the quantized version of the model which reduces the size, but also lowers precision. For example:

```
Q8 = 8bits per parameter = 1byte
Q4 = 4bits per parameter = 0.5byte
```

So 7BQ4 actually needs:
```
7B parameters =
Q4:
7 x 1000_000_000 x 0.5= 3.5GB

Q8:
7 x 1000_000_000 x 0.5= 7GB
```

Of course this is  back of the envolope math. But the real number will be somewhere around that.

As you can see, these are way too big to fit in most consumer grade GPUs or a mobile device, so you'll find smaller language models (SMLs if you will), with vary from a fue hundred million parameters (>100MB, 0.1B) to 1B, 2B, 3B...",r/machinelearning,Z0FBQUFBQm0yeGJ5ZUhnVGVNUTRXOWdfZTJkZjBweEQwV3NiTzhzdEFhRjFmREZ0X0VrOXdtdVBISktTUC1RTXlMdXhDeURFeVNVbmN1Tmk0Ym4zZS1SQVJXYXpKZm9lY0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5MDRMTHJZWE1jWG9iakRfZ0pjSWREUEhnX0RJdFlKLXNydm9CVUhVOUhRYWtjM19IYlpXRkkxelhYTnJicGFuS0ZzTnI4SFVNczhBUHlyT3k3cm1jZXc9PQ==
Isn't it all agents under the hood?,r/machinelearning,Z0FBQUFBQm0yeGJ5Q0l3WjY4cTdMTTBIeWxqNTh2UnhpTVF5MW44NjcxQkw1Zkg1N3RFSllDUXoyMVBKT3RJWEFxTHIxNF9wSmF0ZlR4Q3dqcW5oRi1RamRITjVyTXFyVlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5VTdCcHdENEN1Y08wYU90UjkwdWJUVWhma2JsTUZHOEdLNlJaeV9zenZ3b1RhN3IxenNXWEFMR3gxVm0wT01mQmFSN2hyRlZDWWZaWUhYNGI1eFZOREE9PQ==
"Yeah, very probably lmao",r/machinelearning,Z0FBQUFBQm0yeGJ5Rno4Q0RmYld2US1yNTh1djFSYmRUMUJ2X2N3TmU3cmNuR3VreFBxSUh4bVVva2FkdG82ZUxxN3c2R0RvaktGWENVU2xmeFRLVHRYV3ZtX2JrNzFGYTFpMUd4UWUtUWJtaEhpc2hZM0hMWFE9
"Huge

They're dominating the field",r/machinelearning,Z0FBQUFBQm0yeGJ5NVE5d0JzN0lvUHpScDdGbS1waERmZXR6RVU4OTE0SGpjYnpxaXN2NVRpaU5wTWlwa2pVajNFdzZiTENoWXpyVEFZVDlBbU9iX2ozX0gyZzlTb2diM0E9PQ==
Multi-agent LLMs do not work well. They get stuck in stupid tasks and endless loops. Current LLM design is not the best architecture for something like that,r/machinelearning,Z0FBQUFBQm0yeGJ5LUpETlZLaXR2X2QzNlEzMjZJY0NNa01waC1MbFBVX0pGV2g3OW9ZUXV0YThJOUJrOXJBZldMcXhoTXBzNl9USUJXTGV3T1RqMXBFZ3FqSWJsWEpKOUE9PQ==
Maybe you could go into the direction of AI safety of LLMs. Find alternative methods than Constitutional AI or Reinforcement Learning by Human Feedback. You could also dive into explainability and interpretability of existing LLMs.,r/machinelearning,Z0FBQUFBQm0yeGJ5RU9QQXZjTEJBU09jYjVzYVJiVGp1emdHSmVZZDhNR0llZnBRRlZOc3NxdGRFc2ZtVUpJZVllaHRQaG5VY1FwN3AzNlpwcEVxSEZFSndKOGgtYWNYLVE9PQ==
your advisor will be able to think of a viable research direction much better than you can,r/machinelearning,Z0FBQUFBQm0yeGJ5RU5PUGJYMlZRSFZQXzluQWJDOURNQThYazAtVFJVcVlWWFlRQVFoY05iQVhNNW5Jby1LSE9kRkpJNHZvVlI3bGliSndFWk1YMmc5Y1RhajBLVjNjYTZoTEE5RnhwNWtMVUdvRk9lQlc3dms9
You could read the sub's rules before posting. That'd be a good starting point. ,r/machinelearning,Z0FBQUFBQm0yeGJ5dUpLc3NiUVVhbUxITllHNjhkTVZvQmp4Mks3RXFRcDVZVXJMTHpYbjEzelFvSmNMVjRFLWlqM1hpakdoWEtIWEZWd19FZmVYVGtESEM4bU5PTzQ2V3c9PQ==
What is that bro?,r/machinelearning,Z0FBQUFBQm0yeGJ5R3I0bkdocW04cHdqUS10YkQ1aEZqQi1ac3RMd3RtbkhNVFFMSEFocnRtRzVibUowd1AxM0JjNEFSeGxOY3Y2dXBHX0dBSlRQQms3ZmZNbG10cUZnemc9PQ==
WDYM what is that? It's the sub's rules about what and what not to post here. And I'm not your bro.,r/machinelearning,Z0FBQUFBQm0yeGJ5V0JRdWxfV2FWRHV4N3lvTUkzUTZNTFJWYTBYSjg3WTA0M3VtZk91LXhSZTFaMU1TYnl4cjVUS1NOOHUxdlJMU3YzdGpPNjRkZFZTeGprVTkwNVFXU0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5dktGUHdLYWNaRS1FeGtnYXpDMWdJOE9ZS1ZSMm1ZOXdmMUtNc0lKOTlfTlV4YVctRTZ2dGR1cDg5MnM0TDV2YVhRM1ZOSy1RSm9QUnpzS0RwLXJKbHc9PQ==
"The idea is to distribute the cognitive load across multiple systems.  Since * of thought provides better outcomes after multiple rounds,  having many agents try to solve a problem would give better solutions, sort of like crowd sourcing ideas. I'm not so sure if this will work well if all LLMs are the same, but if they're diverse and trained differently, it could work. Also it might be cheaper than running one large LLM, though right now i don't think that's the case. ",r/machinelearning,Z0FBQUFBQm0yeGJ5UWF0X01KSGlsQmRVSExyNUVsVWNPN0VENGNjUjFVODh6ZnJnRmQzSW5NVVI0TzNOMUc0NUxBYy1Gd1dXRWNwbHNTLWM0VmNzV1hGeVBsRW9ta0dFdFM3M3JFaEFYZ2RfUUlGZ2JvTEZLRGs9
"So you have a function f and some y and want to find an x such that f(x) = y? Is that it? In that case, there is a long list of solvers for nonlinear systems(https://en.wikipedia.org/wiki/Nonlinear\\_programming). Am I missing something here because I don't know what this has to do with generative modelling to any of that stuff.",r/machinelearning,Z0FBQUFBQm0yeGJ5UGJIZDNMRWE0RlNNRF9zVXZGd0JRekJLUUZiaFVXa0tjVGdBSG94UnZnWms4ZTMyc1RKalh0bUxPRWx1aDFIODVrVFd5ZDZCRUQzeHBIazg4NTBmWVR2SXNKWU5JbEJ5NFBJMEhxOWkzcEk9
Thanks - generative models are well suited at finding solutions when f is not bijective.,r/machinelearning,Z0FBQUFBQm0yeGJ5bG1GelVVaW1kNzhqazFsRVpvRHpBdmZNSjdXcl9pWDI4aGZKRUI3QUNidWQwNVlrLVd4SHJKempIWUMxSmRjRUVXaGRES292Z2hWNk9BdEF4MXBJNEI2OXpNYU9hVllXNDVPX2JaalBqRmM9
"I'm attempting to understand and create an implementation of the algorithm you've laid out in the paper for deriving equivalent decision trees from neural networks. Even using the simple toy NNs and equivalent decision trees for y=x^2 in the paper I was unable to get any sensible results with my implementation until I realised the biases omitted for simplification in the explanation do need to be computed alongside the weights to be applied on the input. I'm also not sure how pruning would be possible with multiple input variables instead of a single variable, I don't suppose you have a more detailed algorithm that considers these factors, or an implementation you yourself used to derive the equivalent decision tree?",r/machinelearning,Z0FBQUFBQm0yeGJ5eDU4aXRSMlppU1pqSElSUndCV1o4c2gwS2xRcl9yYVJDd2NqVE9KNHVIak1XWV82TGNYdVdiandRSEtsZjMyOGNKWElLd2V3MnFSeTZCZjVaMW1xdnc9PQ==
"I would argue even over a few hundred million count as LLM. Definitely 1B. It's mostly as a comparison to language models in old school ML before transformers etc, who would have parameter counts in the millions, possibly tens or hundreds, but with much narrower capabilities and narrow use cases like pos tagging, sentiment, translation etc, but without generalist capabilities",r/machinelearning,Z0FBQUFBQm0yeGJ5SVhCSmR5ODc4UzZ1bm43dHBkUHVkR09ncEVfanRrTDhDMC1Dejc0NGRrVEVQMnd1cmtxTC15ckM3OVB4NG5uenZTc0tIUi1VR0ZJaUxsZ2owbzRnc3c9PQ==
Can you elaborate the relational Extraction part a bit more ?,r/machinelearning,Z0FBQUFBQm0yeGJ5VTRHWXgyYmczT2s5VUtLTkkzQ1hvbHNzZmVfSWhYM3hWdHNOOVZVdmFSTldYYnpSTEQ2eWJHTFJ0TF9wNXdzcmY5NHhjZVpmM1d2THRGYkthNzZmejgzMDlYbU5hd2hsNkJjM3ZrQjhTSGs9
The field of language modeling but ml is extremely vast and I would argue that computer vision models and research is far more prevalent and the business applications are far more concrete while llms still have pretty narrow and experimental business applications.,r/machinelearning,Z0FBQUFBQm0yeGJ5MGNHYklPeDFnNUZXbm85LWNpMkpmODBoZGk5S0NFQjVyV1pHdFNuSm9lTTFTVThjTWdNY1Zla0I5N2w1bWQ3dnZKWTVraWdrY2lSMEh2dEZfRkl5OVE9PQ==
[Puma: Secure inference of Llama-7b in five minutes](https://arxiv.org/abs/2307.12533),r/machinelearning,Z0FBQUFBQm0yeGJ5djA0azl3eS1qRUNiY0I3aGQ5dDhUTnZYaS1GSS1PZU4xN3hONTlrRUl0ZjY3QmpoTFRKQkxubGt1aHRBdTV1R0duS25XQS1PS1VmWGppeFZXcDctRnc9PQ==
"Differentiable and invertible are not the same. Is your function actually invertible? Other wise you are looking for level sets, not points. You will also run into optimization issues as gradients will be quite degenerate. Finally it doesn't matter that x follows a certain distribution as you are just interested in a given function f for which you are trying to find an inverse.

A very classical algorithm is to consider the sequence 

X_{n+1} = X_n * y / f(Xn). If it converges it's solution is a fixed point and f(x) = y. This will not always work. If you have access to gradients you can use Newton's method or other optimisation algos

https://math.stackexchange.com/questions/4363437/new-algorithm-for-finding-the-inverse-of-a-function",r/machinelearning,Z0FBQUFBQm0yeGJ5QWlOWXlocDlBakVtR3BKSVRZRk5ZSEtKWE9SUGV1YUphai0xbVZoVXJxZ3MzVUttVlRkRWJ2MXRKMkUxcjhPYXRYUzVCQ3FJUTBXTTVqLVhzRGVWenc9PQ==
Looking for someone who has experience of working for UK pension companies as I am working on some use cases,r/machinelearning,Z0FBQUFBQm0yeGJ5VGhXRTg3UHBaVlFqYi1Bbm9fNV8zV3VITGVvVk9pLUVWTnpLZnZ1NjNiZkRLTG5CdzE2YWpTdUlSSU1xcXIwVFN6OUw5VHR3WlJtUjVicWN3cTJZOW1vOVRYMmUtczN6NHJIb3ZlRFJnQWs9
"There is a lot of hype coming from the fact that people playing with ChatGPT-like UIs keep thinking ""man, this thing looks capable of many tasks, how about we give it a few tools to do them autonomously?"" and very quickly realize that you still need some safety checks, some sanity checks, and from there imagine that a multi-agent pool must be more efficient.

I think that so far what made it too difficult was the small context window of typical LLMs. Nowadays, I would give it another go.",r/machinelearning,Z0FBQUFBQm0yeGJ5bUdVcmhvUXg2Smk0XzZNNHNjdEtCZEtKTE8ydHQwWXV4SC11RWRfMnpSZ1dMa3ViLTRnVHRGSzI0TGNTTG8zX0QwdWQ3N3BDMGhKU0xTeWRsODZRZFE9PQ==
"It really depends on the data, but getting mcmc to work can be a pain in high dimensions. Also you need to write down the prior explicity. On what kind of data are you working (dimension of x,y, what is the prior, image or not?)? Other than that, i am pretty sure conditional generative models are the way to go, and i think conditional NFs are usually simplest to program and test as long as you dont work with hard image data.",r/machinelearning,Z0FBQUFBQm0yeGJ5ZF9rZ0k2REYzSWhwWmthVE5ieEtiTVhNOWgtOFhuRmV5alp4dl9qR2k3ci1wZDFyUzJaLWUya2RyNXdldHY1Z0Z2ejg4aWdNTzFhdUxwMFZoZlpwLUJPQXhIRTJHWmR2ZXpNVjFwSWlrSTQ9
"this approach is also not good as this will mess up the ""likelihood"". If lets say two x map to the same y, but one is double likely as the other one, then it just depends on the initialization what respective probs it goes to.",r/machinelearning,Z0FBQUFBQm0yeGJ5ZXVSSWRMRDN3ZXI0SmZFOGl1N05sT3AwN09VTmNlSXNld3FPSjVIMDg3cGlmWGdOTzR6SUVTZlJucG5xenhPclVvWE1GTWxQaFc5RUpJMndHcEZndjVIQ21vMGFxZlRhR0paZUtQYnVpLTA9
have you used smythos,r/machinelearning,Z0FBQUFBQm0yeGJ5WnAxaGd0eXFuS0w1V1J2UHA0Z3JsVmMydDNoUThGb0FvUzJjUU5KTWZpS2I1dm5uR2QzcWFEanVSTkxmMkxqQ2lVTDFuY09KazltaHAzYjlOQU5BWGc9PQ==
"the main idea of using conditional generative models is that you wanna make up for the non uniqueness of the problem via an auxiliary (stnadrd normal) latent space, i.e., a Z where the generator G(y) maps Z to X|Y=y. this means if there are many x possible, the randomness will be controlled via latent space. This is how one uses generative models to solve inverse problems.",r/machinelearning,Z0FBQUFBQm0yeGJ5cmR2eG9RVk5DY2xrRUtaUlQ4Q0FVU01NbmNTWFY1cUZuUGh1d2RCSkQ3VHBJbGljSzZ6azJaZ1RmX1hwSDJZaUVjS1pzMlc4U3B4RldGMm1RLW80U1g4c1o5MnZyOGhvWGhrYnRyUDZJTHM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5TFRIa3R0WTk1bjVUYU9peGROaGNaeU9jUEczMVF6T3JCVmhnUkV5TlQ1Mzk2THdzMGxoM0VsQXNiaGkwVVVpVllOQ1FSSExUSWFfLXQwaU0ybE9zcFE9PQ==
"""Multi agent LLMs"", wtf. Why would you even use ""agent"" and ""LLM"" in the same sentence.",r/machinelearning,Z0FBQUFBQm0yeGJ5Y1JINlNhUGFNLXlta3lGRjBPRktWT3R1MjhPQmFZazdNZmtzTy1hTjdtZGFzVmZiVURlVEJ6M1RBY3VPVUtuMExINGRHak9kSUhqMjJBNnhaSlloRFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5WGFXeEFQT3hqTDI0QjFvMEl4Y1pGMjl3TG5UcUpGRk1jeFMtS3A4TnhWVml5bm1JLUZLSGpuQ3lxUVByRU9ibElGcTJnZENDbWI2b1JnaGlzWnVoc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5bHF2NE03eC1mTWsxOW1PNEFSejVnc2MzOHZYNlV6WWthU2hMR3BqVXI5MS1jTmtMV1BqME9tMmlWbTktNy1KSXIyTE0zSi00Q0pyLU9qWERBOXRidWc9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ5Mk1DRkRXWENKU2FRZkdoNTlkOUlzWFNiSmI3RnllazJfZFhFd29lSnhkY1c3YVBEYnBndXpoRjUtM0tCekpoNGRDbHZGbDVBdzhKdC1uNXlBLUtsTlFzUklPdEFzZ09NVmJKNjB4LVV6aWM9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ5c0w2dDlHNVpTdWlKMFBnb3JGU1U4NnhaTHFIcE00U1NWN0dNNk5MMWRtUFBhUmNPYmJaMmozOVlDbXk4Y0ItOEUtTzFETC03M19DTDFOLUxKWDdZODFtTzVkeVRCbk5kZVZDQXFwNy03T2s9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ5amdURndlRDA5UDdJMzFkLUpkTl95OE4yc0FXRGZkVG40RFhoLVRjM2tFMTVqX1p3RExzN0RRakNhYnNPVGF1ekNVeGFoN1BISlU1a2VfSktfcVgxTEp0ZE96V3p3RWZmRFprVEVLbWpOX3M9
Have you considered using Bayesian optimization to invert the function?,r/machinelearning,Z0FBQUFBQm0yeGJ5YXlNN18xV2NvMC1yXzBUUXRBc3BHbWR4aDVONmhrWTFURTlrRVlpMC1idHVBM0FDTnN5R0NSTzZBUkVySTlMTlBDSUhpclU1ZEdwWkk3bm5sZWtJSHQ2aFVkZ0M1NUgzTnhidDhxYjVhQ3M9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ5TVhaMGJrQjI0QnI1cVBHVm96TGVYNVN2ZWFCQ1R0d2tsUXRBVkotUHNwc3FWRXk0bml0RjlCS2xRT3VYQ0tLc3pBVVc1NmVSUWpjdGotRXpSbW1pV1ZBQXA5elNTVkk5SmtzMGp4US1WdVU9
Heading to KDD too! Would love to connect beforehand.,r/machinelearning,Z0FBQUFBQm0yeGJ5YmlFOTJpbHNsY2FuNVRvRWNmYjdqS3JBOG1WSXdqWUFRVUYxWEhReFVrUDZOTDVQQXFoMng3ZnJYVEFCWk02eXJ0WU1tNlhFRXZvTkk1WEdQaDBPb0VQT1dmSmxCZG9VTlozYnUzbkJaeWc9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5d1BqZzZKdExzSk9WaUxEMExFV21YNzhnV1NGSDNRemZZMHlmQ2FWdnphU09uaXltSWhGYUZZa2JROHVDUkVvdS1GMkh4UEtSRVdOZXc2TDNtYTUzeWc9PQ==
Industry lingo is a lot different than academic lingo,r/machinelearning,Z0FBQUFBQm0yeGJ5Nmsta1kydU5tSHczZ2F0eGo4ZXJoZmlJWTFHZEpOUXJMTlR4Qnd5WjZGYXdGNmE3TWNjSVFCNHVnZkkyTjlndExhcEtFejIzdmRiRUVxSkhLMFBlQmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5Qnh5azJ1TGxaQ2w5bm0xU0VtOG1pVFlwUEZvbDJCLWtwcEotTHFWTExCMmkwM2x6Vy12dkRscUNYMTVPU0FWNG05UW5LNVRDV0hUcG5KRDhfMnpNTVE9PQ==
"Read this: Nocedal, Jorge and Stephen J. Wright. “Numerical Optimization.” *Fundamental Statistical Inference* (2018).

Then check [https://scipy.org/](https://scipy.org/)

Or just run a population-based algorithm like NSGA or CMA-ES.",r/machinelearning,Z0FBQUFBQm0yeGJ5SklpdklYbnVRRzIxNVZVSzlRU3kwWVQ3a3J6UURDTDRXMTV3MW1TdWZuRWN4ZlZiNldZQnBVcTFhdWZMSTFOU3lBaklpLVMwWHpILXNKaXpqaWJyQWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5a19rVm9VNThhdmZqdjA1aEFDMDY1Z3hzbGZtRUktdjhFdEdyN3pxQkc2V1hxbG9hTWUxZC1vSnJaeXg2R2t4RHhBeFpSYWRZZlR0RU0tZ0RmWmZUWnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5anBoaXdPYzZVcVpQWVdpQjVqQWdacDZ0X1dyRnp6UXcwand5dDNEM3NOUTZ2US1sT1h5Szg3WUFlNmctcTZVdEVIOFJhY3hGeGlyMi05anNwTjRRalE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5LTlGa2NnX3kwemt2a1Z0RldkZ2dvd2M3ek5GVW0za0w4ZmltU2dETUJMZzVXSGpFOHdseWZrLXJFUWZOSHMtbkFxVUNsMm5qYjNCZTVkaV9YS0kyaHc9PQ==
If T is small you can do set inversion via interval analysis,r/machinelearning,Z0FBQUFBQm0yeGJ5MXd1TGdEd055TVN6RFJWWmU4TVR2Y0hBSzJEblY1eVllVzhFcW1Ea0ZqTDF5UFpDN3h3ODMzNTRUSV9mSlYxa19WNkR0X0N0Z2lGWUJXbEVZRGk4MVE9PQ==
"I and some people were figuring out how to build a community around this too, so I'm pretty open and very interested too.

I would love to know more about the idea, maybe even background, skills and specific topics of interest..",r/machinelearning,Z0FBQUFBQm0yeGJ5cUN1LTVENkRQZ3c2SEQ2SklOQnRfT1NIQURXMENEbVJTZkRiQ1BLb3U2Z2FsTjBwTHRKVkNYRGhVVWJYLTYyUVRXNmNjMWFtWTg5QTByemVLRlA3dVE9PQ==
sounds great man! could you send me a private message? then i will further explain what the community is all about. next to that im really interested in what your thoughts are and what conversations you had with people about this,r/machinelearning,Z0FBQUFBQm0yeGJ5anVXMGNfQWYxQ1g1clJmb1VxMm9VVkNHYXlyOWRTQlhpWHlFM191aHFkdzF1Q2o4XzVwdGxCZnZhd0NONVVXbldOU25qczVIQVZaSEZqcVVoN29RWU03eTczZDI5UXVoRTVlRUtuaWkya0E9
"Great CPU, but yes, I know... I know...",r/machinelearning,Z0FBQUFBQm0yeGJ5RGtKNnVsX25Bd3dheFRoXzZxUzh6NmdjUHhvaUZPUWF4NC1TZkJOc2FuRi1VV1pJaFJfc3F0eGZSRV9DVGVXUEdqdENyVzdRMzhQR1VoMzBPVkZZQUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5UDhTMGZRT2tsMG82bHhQVTBTUVc5QnNjc3V3OEV1LUY4Y0FPa1pkdW0zLTJjbWNTa3ZXRzNJak1XYzFKQnlKSEtiaUFZN0o2TXBidktZS0hBdnZnNXc9PQ==
Small being in what range? Any recommended resources to learn more about interval analysis?,r/machinelearning,Z0FBQUFBQm0yeGJ5dTZLR09pLXdDWWhISVh5S1B6OXQ5NWRtR0p6NV81OV9yeUdhaEtEYkpsNmVNcjNnUHpSVExIZmszX0d1NGhuZXZYOElVSjBXM0hJOE1SMDJzM1RWVnRKdXZydG9BTzllNHppV1VhQ1VVcTA9
It is indeed. In the past was able to run llama on it with llama-cpp (very slow),r/machinelearning,Z0FBQUFBQm0yeGJ5UVAxd0RKYnNQejBDQ1puVUNWMGdhZlBZelBBYnR5d0lqWGo2QWZVaVJNQUhtQmFJaDZlR3NOVDFpc01FY09GcGFLT3FWUXRjM0s4UTYyREdseWtZMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5R3JrS19EbzFOYkxFVVd4Um9tWjROZElvSXZWVGZDR2p3V2dudFFMQks3d2xkTTd5Mk1JSEpxZ1NzRktTMWZMU0M4VW9zaU1LM2NaWFVEMGFtX1cwbkE9PQ==
"1. Multiple small, purpose-trained LLMs can be more efficient than a giant zero-shot model asked to fulfill multiple roles.

2. Small, purpose-trained LLMs can behave very differently in a given role than a giant zero-shot model asked to fulfill multiple roles.

For example, my team is developing a Delphi system: four subject matter experts, each tied to a domain-specific vector DB in RAG, with a moderator role on top.  The logic of the Delphi system makes the SMEs propose answers and courses of action, and critique each other, vote/rank responses, and then synthesize.

When we plug in a large model like Claude 3 or GOT-4, the SMEs all tend to produce similar answers, despite the different knowledge vector DBs feeding them.  No matter how you prompt them, using one model makes them tend to be polite and agree, and the output is very generic.

When we plug in fine tuned Mistral 7b's for each SME (we're leaving the moderator as GPT-4 currently) you get really sharp, often contrastive answers, vigorous debate, and at least from a qualitative standpoint, some very interesting and sometimes useful output (as judged by human SMEs).",r/machinelearning,Z0FBQUFBQm0yeGJ5LTFkUmkyV2xlYzVnalcwZ0FOM2NDR0NnNWZtUGJHdnRTVi1UdWdhdTF2a0dkRW5feWRMWUltVml4RXk2Ui1RcEtXY292LVZQSG5OcUpfODdWYV9fQ0E9PQ==
"My client is moving most of their data ecosystem to Snowflake, and I gotta say, I loooove it.  
  
But what is a ""Data Citizen""?",r/machinelearning,Z0FBQUFBQm0yeGJ5a3hyT193dV9nRVBQdXlPVkJDOVlVZzlRYlJEa1I3SnJsNlRPRTBDd3pLSURGUDFGdlFRXzhYQzhfb09ObnBOOXJMZ25oZTc4Sk0tT3R4c3dKQ2ZqREE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ZkJBRlhlX0JjQUV1TkVEYWJKX3ZUaW1NMVRWeFBqR3k1N014ejdaYkt4V2k2VXl1ZG96SThWX3g0cElvYmpwS0t2X2VqT1FvaFhVMWxXSW4xMWhEV3c9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ5ekUxREJsNmdyN3NNUHRva01zQWZYbThHZ2VuSzc4dV9jdjFtbGZKY3U4YjUwNFN1eHZYc3h6MGVFb0dRX0hmN05vb3FBOGJQV3g4LWlEOTkydG8wbGhNOXhEalI4dXVOLWRYVEUyQm1pblU9
Reddit,r/machinelearning,Z0FBQUFBQm0yeGJ5MHljR0xlU3BMVjZyUmpHbG5xSXJGS1dxcWs0aU11RjFiTGEtYVVxVVh4dk1FRmZGYlZ0aDJ3ZEF0Vk54NE5PR19lR2tDVU40dExIb0s4Y1RZRkU2RFE9PQ==
"you might want to recreate your github link. It's some kind of nonsense ""leaving youtube to go to github link""...",r/machinelearning,Z0FBQUFBQm0yeGJ5RXRGZkpOUlFsNVhENHRtZXRNQ1pRYnN5MEVIOFdrSWlwNHBWTl9MU2h5aTA5R3BHS2pIcXRrdGFwOHdpNEo5ZzloM2E4M3hsQTBFMi1UU1AtamFfS1E9PQ==
"Kinda wary about giving a response unless you have a link like a github page that compares ground truth samples to generated ones by your model. 

This is more of an ad for your business otherwise.",r/machinelearning,Z0FBQUFBQm0yeGJ5MXE1R2hURWxHVFhnVlF0ZDhCUWlGM0xxal9XQnpjXzRGelZOQklHRUxVbXAtbkpuWmxsWXVGODZTNXA1Z1MtVmZNbFlyYlJHRjFacFVuRmNxMkNRcEE9PQ==
"Yeah, we'll be uploading benchmarks today.",r/machinelearning,Z0FBQUFBQm0yeGJ5dG12UjlpUkI5d3VIUm1wVzNSNlBneXBwcmRoZ2NjX2FWWlNpcVRycnMwb3hIZmo4WmtGUFdnakxYWElJRlo2RHZ4Q25NZktQZjRKV2pFRm1oSUFsZ3c9PQ==
"What you have described is exactly the same problem as GAN Inversion, so you could take a look at literature in that area.",r/machinelearning,Z0FBQUFBQm0yeGJ5UFVkQ2ZjZERvNGVaZUt4WWhWTkc2c0ZadDB2TDdQR0FjTWxvME9kaGVjd3oxMHBvQTJFblFDdVVDaWdxbFdTMU16NFZONGJieVBJeU9qV0d1cUNHbXRVWWF4VVBVeFZUQ2FEM0NBTEhBekU9
"With disease prediction, chances are unless you are doing something super crazy with the method itself, it is better suited towards certain medically oriented journals. Hard to say anything else without any more context.",r/machinelearning,Z0FBQUFBQm0yeGJ5ajByWmh1RTNFRGhOUTcwcUp0czhwcFB1V1M2OTVBc2tWeWFzdldjSzZGd2YxRUU3czloUFYzdEpCMkt5aV9NenRnejBHcFZRTm4tV0RrVVJRM1loVVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5WEZMQ1doRGR1VFRNd2V0eTVneEh6Q1NhQ2hEQldDMFZaNU84ZHhPc0VZNkx0S1B4a2xqMUhBbXZPWVNEWXAtTm8zbEJJb3dYZFZNcVU0a2pnTXRQaFE9PQ==
"LLMs are bad at reasoning and planning. Leveraging multiple steps and delegating responsibilities let's you impose procedural mechanisms like you'd find in a corporate structure that can promote quality and reduce risk from utilizing single agent responses directly. 

This added complexity adds cost and latency. Moreover, a lot of these complex systems are being built by people who don't have experience managing large teams, coordinating complex projects, or implementing systemic control mechanisms, so the resultant systems may not be particularly effective.",r/machinelearning,Z0FBQUFBQm0yeGJ5SGdtT1hPemNZb0VZcGlGbWRqVTA4WVctVy1fOHdFVmQ5clBkMFRNQW5jdjlLSnZXQTEzSFpUeTF0Um9nZ1FWencwS3lGQW5NUldrRUxnSFA5SFE2cmc9PQ==
Agent kool aid is very potent. My manager drank some and it’s all  he ever talks about now. I think it’s the new blockchain.,r/machinelearning,Z0FBQUFBQm0yeGJ5Wk5LVUVOUm1ybUdHZ18wdjBqdVNXc21wT2trc0Z0X0dSNU5OaF85YlpKbHRVWHBneDB6eThYeGdVNFFVNTAxc3M0dzFwNkNoN2VJN1d2WkJWUDN5UXc9PQ==
"Honestly it feels underwhelming. Lots of people report that it falls into NaN when they try it out instead of mamba. I thought I was doing something very wrong as I also get man, but it looks like it either model's fault or default parameters are bad for non llm tasks",r/machinelearning,Z0FBQUFBQm0yeGJ5QkFyZmFGTFdQWERaT0lkOFd5dXZEcFczWGpQMGtyeWlRam5sYVN3QW5iWEZzem5CUGFfZXhWVVBXTVJzQ3B0QUxVRjI0NmkzckVqOG43N3RSSVUyenc9PQ==
"https://arxiv.org/abs/2309.12288
Discusses what they call reversal curse

>If a model is trained on a sentence of the form ""A is B"", it will not automatically generalize to the reverse direction ""B is A"". This is the Reversal Curse. For instance, if a model is trained on ""Valentina Tereshkova was the first woman to travel to space"", it will not automatically be able to answer the question, ""Who was the first woman to travel to space?"".

Not sure if your inputs can be rephrased to take it into account, but it probably does provide some info",r/machinelearning,Z0FBQUFBQm0yeGJ5bDdzVW1IZ25JZF8yU3FldTRTa001UTFYUDR6azhTSFB6c0k5Ym1SSDNZYnpseldBMjhxOTNfem5kbUJBeVVYRVBhOS1IRy0yT0I4WTYyZllKcTM0eUE9PQ==
"Multi-agent systems offer unique challenges and opportunities for research, especially in areas like coordination and communication. What do you think sets them apart from other AI approaches?",r/machinelearning,Z0FBQUFBQm0yeGJ5d0I5Nkp4dElmR1NmazBWamdJZVN1NGhka0w0dGtrU29kQ2JncmplcFJlcWluYVdMSnJ4R1RFWXkxczI0YkpjUENDWnRnSlhNNDAtcmpqcUNXY3NyOUE9PQ==
"Sounds interesting, dis you fine tune the mistral models yourself? If so how many samples did you use and what does the tuning set look?",r/machinelearning,Z0FBQUFBQm0yeGJ5ZEdBSmpuRVZ0Zk0xcDNuemsweG4yNXRKbG1neWFGbGh2Wnp4cEw2WmRMZUhEcGQtVlRPdlBBM1k4THZyRDFfbFNfY3F0MlNPQ05jOGdZUU5YNWZGLWc9PQ==
"Excited to see you're attending both conferences! If you're interested, I'm organizing a meetup for Seattle-based attendees in Barcelona during KDD. DM if interested!",r/machinelearning,Z0FBQUFBQm0yeGJ5Y1pvYzRKV3hnX0pWSVdLLWFTSDRhSjFzZlpjVS0zNnlZN004N1NSa0loeFdtZW01REsxajRZbFRoczhuU1k4VHNwcVhBOVdVZ0ZNVlVHV3dieXhSM3c9PQ==
As ML tech lead I've mentored someone with similar background in my team. Though [my experience](https://ivylee.github.io/) is primarily in the US. Feel free to schedule a [30-min](https://cal.com/studioxolo/intro) intro call if you're interested in learning more.,r/machinelearning,Z0FBQUFBQm0yeGJ5bnMtLXlleWlNdUxkc3RkVUtPWDdKNDdaZVpHLVdueHhPeUNFekdVNDI0MzNyQ3I5TkEwdkxKU3lxNUpRRXVYcVBjUTl6a0NuMHR3OHdwSlJqWTRHdEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5SzVZRTE4dFNCXzZNV1QyQlFSV0pFaWJIWVZfQXVlT2hxYlI0U3Y5bjd3emRJV0RWMzhaMzhnT0ZOdmktQlVvZXhnekJ0OUdhU2RMN25hUW9TQzFWZWc9PQ==
https://www.nature.com/articles/d41586-023-04073-4,r/machinelearning,Z0FBQUFBQm0yeGJ5RVF1aFczMFB5SWRQNnpvc3d0d0Nmd0dyTDZxcHppX2syNmdvV3JZT1drWHJhZEt4WGdYU0pfdHJoUUJja1VzRlJlSk9FTE1qSHljVzF6ZDlVMnV4T0E9PQ==
Agents is the new data warehouse. The term is so vague that pretty much everything is an agent.,r/machinelearning,Z0FBQUFBQm0yeGJ5MHNfR0lSd0lkSnRBZVlCX0d3V3I3UU1jWFFoUmkySWxrNEpRS0VSd3A5SXFMZlNkTnR6V1o0ek5Ldm8zdHotZDlxb2QxNkdsc3doN01sY3I0aU80aFE9PQ==
"If an LLM were trained to [generate mathematical proofs](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C50&q=gpt+theorem+prover&btnG=), an [automated proof checker](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C50&q=%22proof+checker%22&btnG=) could verify the correctness of its proofs.",r/machinelearning,Z0FBQUFBQm0yeGJ5MEZleWxYaDlxZzI5ZDBuUDZ2dVQ3RXZTNmp5V1ptTFZicVdPcmJPRTRxNXB0aXctMzUxcUlCNjJqNHBsdk9XUTFqZ292bVl2T1hXa21oTkxRcy1DQ1E9PQ==
I think using exploiting GPT-4o is the best for cost and quality in general.,r/machinelearning,Z0FBQUFBQm0yeGJ5RnJ4NFdqbmxKdTNJYXZmRHVTYWpTRjBsS0hpVWZ1RmFOWC1ueThFTGVrQVFLeXZyMXg1LUE0c0VJMVY5R1I2UGE5SDhXcXUzUGFUX1RXaG43RUhieVE9PQ==
lmao,r/machinelearning,Z0FBQUFBQm0yeGJ5d1JkVmxMUWkyYndBWUlLdzVveFozUWYya05XUl9ZQkZNaGZNX1l4cXQ4Z2pMV3BPOXY0Z1FBLW1lcUVTT2taMi1tZnEySkFiM19nU1lsNTFzMVFxdmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5bjJOZGFHZGlISHhiVFpqYXAweEhPaE4zbDJoQkhUWmZWUWJhaU9Db3BHTzNFc2g0VUtBNURFSXdqTFBRbTlIVVdJQ0YwdTZUZUZEYVJla0xZdnZSeHc9PQ==
"I’m curious about the fine-tuning details as well. From what I understand, it’s not an unsupervised training on domain data but manually created instruction examples are needed.",r/machinelearning,Z0FBQUFBQm0yeGJ5T09JTkpXS0R3SEVqVnE2ckQtcmFJQWZ1ejNSTWlkMjFwM1BrZTBmZlpoWk9BTGY4RVlFYndMQlNMMHRHMnctWmlHUExCWEtJQjhxc2RBQklJcXlsUWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5SXVIMzNubGpwLVZoZWZIbjRaZGRIaloyQl9aTUJaSmVFQkljTGVra2l4YUVWS0VweW9EMnlyQS1OcEFwYkVEN1RzTXFSR1hKbVlYOEtzRkt4VG9wZWc9PQ==
"I don't know particularly about multi-agent ""LLMs"" as some comments here has mentioned, but multi-agent systems in general can be solutions to many current world problems that the tech world is tackling. 

For example, ""solving"" self-driving when the vehicle's perception is limited to it's own features has reached some standard now, but incorporate ""multi-agent"" by allowing seamless communication between vehicles, and voila you have agents that can perceive way longer range and through obstacles (aided by another agent's perception). Towards self-driving, it still might be a long way. But I can see that such systems can already be very useful in confined regions like in parking, with robots in warehouses etc.  
Agreed a lot of these challenges are probably already solved in theory, but building actual systems for multi-agent environments are bringing up new challenges like efficient fusion between different modalities, even between same modality but from different vendors (thereby different input distributions, since they are not standardized yet).

  
I am curious, what are some good pitches you have heard? If you don't mind sharing...",r/machinelearning,Z0FBQUFBQm0yeGJ5NFdob243SnJBZDNvSHYwVTJaeU1JVlZieWRfeUNZMHdMc2xhTjZpRlhJa1BxYWFoTmtVejJfN1haTG1GeFlfMWdkY0JiYU1uMDFrODQ0Rm5fNjQ4LWYtNHFMTUEtNHJ4cHlGYjhwNlU2LXc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5WnBPYnNXSEpma1U3bGVaRnZ5TnZ3MkZ5cWJGQ0lMUXRBMVlQRExTaUZSNnhXeEpZc1lRbUdFTFRkVnNQbXhQN0Y4cERoYzdWdFlMMjE4SmdFU2ZoU1E9PQ==
">We went further and noticed many methods won’t for anything outside the paper evaluated.

I hate when that happens.",r/machinelearning,Z0FBQUFBQm0yeGJ5dDJXak1rQUVHc09kZXNKUEMwTWhlTTR5UFNhTUdSWHFhLTE1SXlyaktzVHFvbXJBMFBJRk1zRy1OcTM1TVZ1YjlFenN3ZTBaM0xBbmw2Y3ZOLWcydGZaemozOHpSM09mdkVoRTFZN0FOM0k9
"I recently wrote down my thoughts on this topic in a blog post: [AI Agents: Hype vs. Reality](https://www.kadoa.com/blog/ai-agents-hype-vs-reality)

The [WebArena leaderboard](https://docs.google.com/spreadsheets/d/1M801lEpBbKSNwP-vDBkC_pF7LdyGU1f_ufZb_NWNBZQ/edit#gid=0), which benchmarks LLM agents against real-world tasks, shows that even the best-performing models have a success rate of only 35.8%.

Will AI agents automate tedious repetitive tasks, such as form filling, data analysis, and data entry? Yes, absolutely.

Will AI agents take your job or book your vacation? Unlikely, at least in the near future.",r/machinelearning,Z0FBQUFBQm0yeGJ5RTRpbmRYT2tWUGlvemdJelR6bXV2QTZJMHVWSGJrX3hWdXVPYXJiNEt3cmdQcFl6VnFSRzduUVJ6UFEydlNvMXQtR093WkFsMExjUHFtTzUzRS1oVlhlaERCVUt2UUQtXzBaOHRyd29qNlU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5cmFFWV9qMjhJaC1Kb21kUVNEUlR4NjdscmthbkVtZEVLVkszWTg1eWw3Zk9jU1o3WmlIcWJIRENLMThHd0lCY2o0RV9MZFA5b09SbjEtUExxamdnOWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5TWFTcDFiSVpUOGp6MzNpc2RLSXJZdjk3dnpWWlVKS0RkajQyS0wtaUZFX1FHcG5qOHpiVkkyYi15a1drNHh0TDBrbm5jSUFheWFCVEhDODRQdDFmX3c9PQ==
Question - how do you manage to link and search over 20k documents? My RAG prototype loses context/can't find stuff if a document is more than 10 pages.,r/machinelearning,Z0FBQUFBQm0yeGJ5NHc2R2c5azVjcGRaWlVXdmJtVXU0S1VxYjVyc3ZkRFpGekdXR2xEc2ZlY3dtZnNVUkk4Tl9paFVDWnZzN0ZGcTdXTGMzemotM0Z2RV9qenY1MnFlbkpYMXV0bG5tR0tYNXhZa1IyWlNHTk09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ZHVMZlQzdW9SbTctMGJHTHdxaWwxaXl2N042X2NQNWNDcHNuXzRHbzZoV0hYbjJqaVluWVlYUXJSYVBOZkxVMjN6VVNZZWRCcDQ5aWVyRkUxT1JUNWc9PQ==
"# finetuning LayoutLMv3 on the dataset naver-clova-ix/cord-v2

hi, guys, Does anyone here have any idea about finetuning lyoutLmv3, now I am struggling with the dataset like preparing it for the pre-trained model but I can't! Does anyone have any code or already fine-tuned this model and know how? thanks in advance!",r/machinelearning,Z0FBQUFBQm0yeGJ5REp1TlMxTHVRenhHX0hvTGFKOGVURjJZTWVieU5QZzNwOUp3Y3pNUW9SVDhwWUNLSUpnZ1hndEM0RHZNeGx1OE10Q2pqMUZFVWk2Uy1fNGNiQ0gzVGc9PQ==
"You'll have to experiment with how you are chunking your data,
Maybe add summaries in your vector db collection instead of actual data.

Try to figure out ways to either split your data into smaller collections and add a logical layer that'll determine which collection to query. 

Try to convert the query into smaller sub queries employ some query expansion techniques to improve retrieval.

I've lately found a mix of hybrid search using sparse embeddings to be useful when you want better keyword focus in your search.",r/machinelearning,Z0FBQUFBQm0yeGJ5UVl1QkNTZTZtZ1l4aFBXODFlN19jbzBtbTNrQ3JBeFRUQkYydEJuSE80dFFhdlQyQ1lnVG84eDRTNVczdGRrZFhwbXpSYzZSNzJSU2UtWXdOZzBfa2c9PQ==
Dm’d!,r/machinelearning,Z0FBQUFBQm0yeGJ5ZjEzLXBON3RzZUQtdGFfSzlyQXFRdDZmeUVrc3lZYkdGMTZQdW85RjZZT2I0bTQ3OVNJeW5NUFN1T25KM2s4V1hIYzRXNHNzX0V6LVBvYkh2N1hFb3pXRGhwTVVyRDBuNHlBZHFyREtNUXM9
Yet to see them outperform chain of thought like prompts and structured output. Will get there but not there yet.,r/machinelearning,Z0FBQUFBQm0yeGJ5TUtEeTBKWHVERXBncHZTQ09hbElGNkF4T3NQb2lPMFBTNDc4S1k3enpOODFrWXd0emFrbEIzVGNNR05JZHk0Ul9aSUpDbExwRURkYjBkTmpTbDJtN1E9PQ==
"they have their uses...the top scoring SWE-Bench agent uses multiple LLMs (4o and Opus)

https://www.swebench.com/

as I check it now the #1 spot has been taken last week by a single LLM agent but in the future I expect to see multi-agent in the context of using a the biggest best model like GPT-5 or Claude4 in combination with a 400B Llama3 fine tuned on your business/codebase

EDIT: nm, the top agent is also multi-agent: https://arxiv.org/pdf/2406.01304",r/machinelearning,Z0FBQUFBQm0yeGJ5QTE5ODNSQm5RX1dUUGRIYlVkNHp5Y3ltMG9CS0ZVbHJCcVhMaE9UTGpFcXRVNmNyVEtZaXl0Z19TbF9SN3VKMEFFTW5VZFNhZlFrdGE5d2M5TkVjZkE9PQ==
"Agents aren't vague, the concept is a system that chooses an appropriate action based on the current state it's exposed to. 

They've been around for a long time in things like recommendation engines and game AI, it's just now they are more accessible with zero shot language prompts.",r/machinelearning,Z0FBQUFBQm0yeGJ5eEQ1cnZYS1hNZVdPN1hMVEVHNnFzLUZ5aEdSSTlBSVJ3RlBTdFAwUXhZaFJuaHBMNk12cEdqZ0l0eEVHM1U4NHlsTmg5bE94b01BU2J2N3lpMzdNMWc9PQ==
"One interesting thing I have heard is that if you have 100 systems in a chain that each run perfectly 99% of the time, you will only get a full chain succeeding 30% of the time.",r/machinelearning,Z0FBQUFBQm0yeGJ5bkVFeGhGWlpwTW0yTnE5SlFnZjQ4SzVEMVhORU9tNGZIUG1taFpBVG5LOFczand6X1dPdFVHZXVYVlI2TENLWXF4dzFkcEpyUmVPeUtSSUxVNW9Yd3c9PQ==
"Abstracting LLMs to agents creates the false illusion that there is somehow multiple different agents. In reality an agent isn’t the model but the specific context embedded in a prompt. It’s still chatGPT just with different hats, hats being the prompt.

The hype around agents is just the natural flow from abstracting from next token prediction, to chat completion, to agents. At its core the abstraction is only valid when the model creators start training it specifically for an abstraction, which goes counter to many people’s belief that an ensemble of agents can be enough to surpass the limitations of chat complete. 

So to sum it, ai agents are most likely the future considering llm makers are training models to be used in an agential use case, much like how rlhf trains models for a chat completion use case. The hype around agents however is misguided because it sees agents as a means to surpass current limitations rather than a useful abstraction for developing with LLMs.",r/machinelearning,Z0FBQUFBQm0yeGJ5b0w0ZU1VYVNrTUFjSHZYTC03VXdSNHpSQ2NmV0VrSjJvRnBaYzdGNEJkbjZHamJEWHR1czNFc0d3Y0hyTGlwYTFNTDFLUVo5QjhFNFdkY1BhUm5pWGc9PQ==
Could you elaborate if you’ve read more into it? I understand patching to something similar of what ARIMA models do when they incorporate different lags at different lengths.,r/machinelearning,Z0FBQUFBQm0yeGJ5SXBWejFseUNPMmxmUDZzbWIwa0pJUTY4aUM1MnJUYlN3UXJDd1lWUmRHRXEyczk3OWFvNVRLLXkwWUdiWlhEYWFQWThzVlZ0NDZPX1kwZDhyM1Z2dDc3SXZvSFdDWWNNLWloT082N2hUZkk9
"Not the only place I have posted this but:

Hello friends!

I have recently graduated with a BS in data science. After having little to no luck with job hunting in my field these last few months I am now strongly considering pursuing grad school. 

I have 4 internship experiences (no FAANG or anything crazy, but I definitely still feel accomplished) to date, all but one are highly relevant to DS/ML. Despite this I still feel I struggle to stand out amongst other talent while applying to junior level positions. As a result, grad school has been a strong consideration of mine for the last few months. However, all 4 years of my college career I have been financially independent. Due to some financial literacy and decent planning I was able to get through 2 years debt free and then finance my last 2 years myself. I don’t think I have the resources to put myself through 2 more years of college (I will almost certainly go broke). As a result the option of pursuing an MPS has become appealing. 

Requiring less time and money, this option seems to provide the flexibility I need in pursuing further education. However I do have concerns about the long term implications of such a program. 

My questions are as follows:
    
1. MS vs MPS in Machine learning: Will I be       at a disadvantage when applying to ML positions? In other words, is the MS significantly more appealing?

2. Has anyone who is reading this pursued such a program? Are there any regrets? was this a good decision for you?

3. Are there any certifications or alternatives that I could pursue they may help in achieving DS/ML positions with simply the BS in DS and my internships.

Finally, any advice is welcome here, regardless of if it’s not on this exact topic. I always appreciate guidance and would love to hear any insights you all may have. 

Thank you!",r/machinelearning,Z0FBQUFBQm0yeGJ5VWpPZEJFRm1LME1HSTRDTTlOTlA1d1h2Vlp2TTk2eEFoeXZvMHh4cWpCYUY5Y0c1aF9vRWplT0tfZWpUYnRqQktvdXhqdnZsS0Y5VWZocFRZU0lldkE9PQ==
!!!,r/machinelearning,Z0FBQUFBQm0yeGJ5Z0k5ODA0RkhfQWtsUHhzc3Fpc2tHMTJxdlZHaUllT2ozeENmM0hkQXotbVh4TVJEc2I2UzUxcmU1Q1dSdVhMbmNDUVJsYmR1aV9Zb2VVREt5XzVkbHliZVhBX2txcGRvQVVwQzI0X2tCNEU9
"What you described is a way to do agents, but it's not the only way -- it's actually the laziest way to do multi-agent. Ideally different agents are at least trained (or finetuned) on different data that's specific to their domain (if not using completely different architecture entirely).",r/machinelearning,Z0FBQUFBQm0yeGJ5YTNzb0VxNmNyR3VKTXJHeURUNUhfcXhEajVvbnhCX3cxcUs0bFJLRGxpd1VLMWx5YjUxWWd3c0plWUp2ZnRiMlFPQ251eV9acjEzZkZMZ1dhOHR0RmtGaV9LWEROZ05tNlRza2xHMTRieXc9
"That really just sounds equivalent to plain ol Google speech synthesis, you can find much better than that for free",r/machinelearning,Z0FBQUFBQm0yeGJ5ZEwzT0t3eGVia0psbXo5eDFqVHAwMWl2V2wyTkpUMmtUWGVvLUN0UWFvak50MUdoTlpvQUFucGEyN1d3d2ttTkF2N3loT0dfYjkwNEltOVp5b2F4R1dNM2xKQXlTbERya1pVbWJiZDlpRUE9
"Does anyone have any experience with deploying a custom named entity recognition model on Android? I have a custom named entity recognition model that I adapted from this Hugging Face tutorial: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token\\_classification-tf.ipynb. My goal is to convert my model to TensorFlow Lite in order to run on Android.

Does anyone have any similar, relevant experience? Are there better approaches I should be taking instead?",r/machinelearning,Z0FBQUFBQm0yeGJ5UEVWWmlET0czS3JoNzlWdjk2SF93R2N1NUg1dTI1eldyeVFNUV8zcGVBUHNNVXBkb05tVmVhTXBueGpWUms4Z3ROY3d5Wlg0UW56QU15NklsWmpiNHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5dDlfS2tLSXlXT0pKX1hoOUo4dERxZl94UVNHRGg1WGNsUkRucUhiaDQyd0s1c3JFaEV5Qnh0ZnBpY2g5bXpuUmIwUlh5MWg5Q0h3WTRsanlGaWFmQ1E9PQ==
"Cool! Thanks!

But my immediate question isn't how good it is, it's how fast it is?

Can it generate faster than real-time on moderate hardware? Because after trying suno-ai/bark-small, which sounds great, I'm currently back to using espeak, because although it sounds terrible, at least I get a reply while it's still relevant.",r/machinelearning,Z0FBQUFBQm0yeGJ5Q3BoeG1ZSjlhQV9MUWkydG1TczJBaFJWSDJqUFBjOFNlT2E3V2NOcnpJVnZZMDFON0tXQlU2SEpaX1ZzWWdMRGJTRWtFSEk4d3JaVDFvVUl0a0lEUHcyMGtyd2FzQXdFUGo0TjZDdXFMNGc9
It depends on the project scope and impact for the client. What is your current salary? The more you change the best quality they will expect ,r/machinelearning,Z0FBQUFBQm0yeGJ5WFo3V0MyYUtrZlVTRkNOYlBnTmN5NVl5SGFVZEN1UEhFUmxnUUtrM0p4b2dsNW5vaWNxR055OE8tNjB4VkNGdzdlZHBCSmlieGtIYkhrczFrNTZMcU1sUTdjU3VucVQwcG5FdlBpUXRlbGs9
"Current salary is $210k w/ 40hr/wk expectations. So scaled to $/hr that's \\~$101/hr.  Given they gave their expected project time in hours, it seemed reasonable to quote their maximum time (600 hours) \\* my rate ($100), so $60k.",r/machinelearning,Z0FBQUFBQm0yeGJ5SFdZVENrTkJfNEZvODFUczdHZF9RTHpsblZiTW5iWXREQ0pmS2ltbWRmc0JTcE44ZE1uNFIySjI1eXdMZnBQT3pvaVg0NnE4Zm9aSlRWMFlzc185cmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5bWd5VGl6U25DZmVvUTJsRXRNYlNfTng2cVJDVl81M1RsSnQxYkRqY2I2RjB2OXpFTTJMWlJBNU1NZzZBN2xxZkNGWl9UR2lyUDBVNWE1UGxQd3hxbGc9PQ==
I think that's reasonable then. ,r/machinelearning,Z0FBQUFBQm0yeGJ5cDAwaXU3M0xUXzFVNEl6dFR2Y3NuNkFYZXFNRHlkcFdGQlZ5SENKWU5EN1RIa1d2VUN1QmR5cEJVbW5CMjRrSFNGUlhTY3R5eE0zRVp3bTZfbDVsU09yb05VRml4OWJkdmdyZEJZTHZQbTQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5N2lxMW1oejI3V1lRSTdNeW00SWVjeTByeUVHN2lUYi1Tc3dHb1FVYXFqRmg4UGhnWjdIdVdoTi01QUg3aFl5ZjgxOTcxUHdwMlFUc0NSN3p3UFFKUnc9PQ==
"When I am thinking about this, my only concerns is that my data is very sparse and therefore attention models have proven that it could bridge the gap between relating relevant features between different time series.

  
My input is (1000 data points, 300 time steps, and 3 features) my features being V, I, T and I would like to use a TS type of transformers to only PREDICT (or extract actually) 4 features. So as you said, I do not need to forecast because it is not the goal of my problems. Essentially can use the Encoder architecture of an Informer, Spacetimeformer, BERT with a linear regression output ?",r/machinelearning,Z0FBQUFBQm0yeGJ5WHhJZldqWGxFOTRyS20wTVBfR2Q3RHJ0ZnNkdXc0TFBBZ3lFQmJ5TWNUcmp2WGVtanczVGxXNVVCc2F0RjExUDdJVm9IX2V5TW54REtCa3IyWVhFcFc2ZnRMenIzVUc1QTZETjFlcURLZFU9
"actually the debate is not really on whether I need to use a decoder but more: ""how to use a transformer-like architecture or variation of it to extract features from a Time Series. I think that just using the Encoder block with a linear regression output is the answer",r/machinelearning,Z0FBQUFBQm0yeGJ5Q3h3dUt2SXNHY1FPQ0FVTlNJYmNxd0xjeU1QeDRnWV9LRzk2VHVoMkVfLXRRLXo0cV8zbVExRDRBeWhOa0FPVlVjU3g4b1loSjFkUGpnV3VIOE1nYmt1Y1hoUHBxNmg0eF9ndGVlcHZIQXM9
You probably get benefits in your current salaried position. Take your salaried hourly rate and add 50%,r/machinelearning,Z0FBQUFBQm0yeGJ5YnZsbU1uRVp1VnNjT3FUMk9vby1Pc3QzZ05PMzI4Nlczc1lXbXFaZ1hUS1VLZWlGckg1UFJtVF9ZdlFTdUhSTUw1OUZmNUpnS0NvZWkxeWprRjNrdHc9PQ==
"Some comments:

Your charge out rate should be significantly above your salary/hourly rate to account for taxes, deductions, lack of benefits, opportunity cost. When I was working for a consultant I was charged to clients at roughly 2.5-3X my base pay. The ability to access a specialty skill set piecemeal without having to pay consultant rates or having to hire someone is quite valuable and your rates should reflect that.

They anticipate 300-600 hours but that may not be realistic since they need the skill set in the first place and so can likely not estimate it well. Make sure your consulting agreement specifies what they will deliver to you under the fixed component so you don’t blow through your fees on donkey work only to have to complete the bulk of the work pro-bono. I.e. if they can’t provide what is needed to carry out the work, you can walk away from the contract and keep some of their money.

Also, in your agreement make sure there are significant charges for scope changes and set review points that release holdback payments for specific & objective milestones. Moving goalposts is a very real thing in ML as people learn that 95-99% accuracy can leave lots of undesirable behaviour in the real world. You don’t want your pay to be contingent on completing a project to unrealistic standards.",r/machinelearning,Z0FBQUFBQm0yeGJ5LUs4MjQ1a0o1dWlVbFUwb2tTZ0ZGN0xCenhZazhTcG9pcWdjMWRXc2VYeDNMR3A4WV9BQ0J2SjREbnFIcHgydDJkSUtWbjVaQnBBUFBINHpqUVltdXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5SzdWWlE2X01HajNYd0JyWjdxdi1tdVltUHVPX0FKTFo4OVdGNkVhOVFqZ2dCZE5yaHNSeG1qaUlZekNua0FBcGctbFFlenY3LXVPUldMb2dGd09JNUE9PQ==
"After you’ve tried the classical methods-

Check out some methods such as DDNM and DPS for inverse problem solving on images (these can work for general purpose inverse problem solving)-

Assuming you have access to the gradient of p (your data distribution) you can compute \\nabla p/p = \\nabla log p, otherwise known as the score function. You can use that directly like these papers do, without training a new generative model. The general idea is to use principles of generative diffusion and build langevin processes that maximize probability (subject to a constraint set)

Specifically DDNM is actually very similar to a classical technique (projected gradient descent) but with some very crucial renormalization steps that maybe help it work- this could help you get converging to local minima. DDNM is also a bit smarter than projected gradient descent in that it uses the “implied” nullspace, treating the optimization path as a stochastic process that “corrupts” the function f over optimization time.

DPS is a Bayesian method, performing maximization using the identity p(x|y)= p(y|x)p(x)/p(y). Because we use the score, \\nabla log p(x|y) = \\nabla log p(y|x) + \\nabla log p(x) up to a constant (since y is unaffected). p(y|x) is computed by means of an approximation known as tweedie’s formula (this is not directly mentioned by the paper but is actually suboptimal)

Since you have a ground truth for p, I would estimate these methods should work very well- without the need for any neural networks involved, meaning everything more or less is “classical” with some renormalization happening.


Links-

DDNM- https://arxiv.org/pdf/2212.00490

DPS- https://arxiv.org/pdf/2209.14687",r/machinelearning,Z0FBQUFBQm0yeGJ5V0lKUGJWbEcxRnVLU0diSTFHSk5FSVRBRW5zNXF2bWozcGNkNG91LUswVWUyR3g4Y0RIVEpUMm9kaG5fQkc2SjZqdVhlMm1iWF9ZVGJUMzZqSF9GbVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5dnBqaVNWdUdtUEVyck1DLTZja2J3WkplLVczTW82b1RnUWhEUlR4ZFBzR29jUXhLNWRfdUR4dGN4bkl3RHhVc01kbkhDXzRtaU95el9welQ0ZEJjZHc9PQ==
"It's been updated, here it is [https://github.com/camb-ai/mars5-tts](https://github.com/camb-ai/mars5-tts)",r/machinelearning,Z0FBQUFBQm0yeGJ5SnB1X0F1djlabVgyZzVvdVJKaGNfRXltNlhWbHRyT2FmS2NZNjRSU0wyNEZjLWNtNmZpSkdmUndocnhGcnRmVjlpNHFuZE9LQnBJNzNPUEhtdTAtbUE9PQ==
"Single digits. Can learn more from this [book](https://link.springer.com/book/10.1007/978-1-4471-0249-6), this [paper](https://www.ensta-bretagne.fr/jaulin/paper_automatica93.pdf), or my [paper](https://www.cryvosh.com/TemporalSetInversion/).",r/machinelearning,Z0FBQUFBQm0yeGJ5em4tZlBJSjFUSmFGUFNERlZPazA1NnFFSXdRMWhyeGx5QVoxN2NENW5MOUNTXzZwdEF6bTZlRVRMbDEwRzdFMkY1WGNVMUV3WFNVVXgzUW9XUXl0cUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5WkZ2U0o5ckdzdmVmSW42bUZpR21sN2hjd1p5dm1jOFp6MlhDYURMcnhCT3I2TXRhdVB2V2hwQXVSR1AyMFhNQ3pJcTVIcHdYR1FWUWR5WThTLUZXLWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5T0xEZEF5UTJER2NWZjNIeWVXalQ3WVludEpCT0VhT3h0RzdVbDh2TmlDQWlsaFZjblZpYzNMZUY5ZXNOTVB3R25pNlBwZ2RlTExKbXFwanVSQXhMX2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5TGhmNjlXVGlqeHQ1dFJWaVpwaEFYUHpLcldPSTNJWjloZk9RczdvT3lGalJnNXgxR25hSnpXeTBNXzlQdUVaQ1hxZFNBSGQzeTZDbEVqTnBRZW13Rnc9PQ==
I'd love to. Have you checked out some of the other links in this thread btw?,r/machinelearning,Z0FBQUFBQm0yeGJ5Q0VuUmxZa0Vkay1ZNVduU1o0QzBlOHdZVnNRT0E2Umttd1VHQmtwLUlGenlrNmpvWktlMjZwZG9XN0tNYjFtdl9wbzBSODNWS1NCRVRyTFN4VmhKUnc9PQ==
You might be optimizing for the wrong thing. What you might think is reasonable might not be what should be reenforced for the performance metric you are measuring by,r/machinelearning,Z0FBQUFBQm0yeGJ5WFF1Ny1nbE5ZWG1QVHlTU0xpTDl2NUZ5ZWEtWVdDU3ZobXBYeFlDYjZvWUhuV2s4NFNBSkpzR3hpZ2s2VWNkc2VESnFoTDNPWllkbTduVG1HaTVwTFBtdE9kb2wzWGVUYUxRYmpuYk5xVnM9
They're certainly more in depth than data camp courses. You'll learn actual theory as opposed to data camp which are fairly mechanical.  It's mostly framework agnostic so he focuses on theory and intuition. You'll probably need to take a second one of his specializations though if you want actual practical skills.,r/machinelearning,Z0FBQUFBQm0yeGJ5VS1GZHlLOFM3cGpIS1FObENIclhDMkVBLURPU2hwWVZidmJRVmVxcHk4YXlnWGJMeVNwNVFvbmFINGpQMEZiZnd4cG1CbUR3UFZOaS15MjE2amNYdmc9PQ==
"Thank you for your reply. My code is trying to implement like in QMIX and DQN paper say. I used a target network and using MSE as loss function to minimize, so what could be wrong here. I has spent week to fixing this but i feel hopeless :(, please help me.",r/machinelearning,Z0FBQUFBQm0yeGJ5SDhneWlSR1RGWW40SWctelhLZ0FGbWFmLWRPY3JvakJyQ2pCWDVhVmxZMWVQVmdmRHBvQ094MnhuVFJOcTVndzN1bW9vNnItUXJCekRnVXRmZlpCMHFyVXBsX05GaklVSXp0QlZZRWxPbEk9
"What are the specific hardware / low-level differences between an NPU and a GPU? Most articles I found offered only what it's better for (Neural Nets), but not why. Any sources or information on a more in-depth breakdown?",r/machinelearning,Z0FBQUFBQm0yeGJ5S0pwMUVvNUhRd0tIVEJ1Z3RIdEVlWTh0QXFjMkQ1TjdtYTJ4bFlkbk01c1N6alpqU19qeEJGazlabkhRVzFvVUN3cnJLdXZUZ0ppOTdpZlhaVmJ5NHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5RnhJY0w4d3IySl9vVUNlMGJZT0FhcEpKY2FEcDJvZ2lXWGlfSkx5NzloV1hPdmttamp3VmlGbWpyNk1TNzRCMFZiWk80SjRUNzBYZkoxaC1iblVybEE9PQ==
"self.fc_layers = nn.Sequential(
            nn.Linear(input_shape, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_actions)
        )


Few issues here.

First:
Your output layer should have some kind of single modal function like softmax. Linear output can really mess with your gradients especially if there is no ridge or lasso norms on your weights. I'm assuming you want one action per state measurement.

Second: I recommend a bottle neck in the middle layers. Squeeze your high dimensional state in a low dimensional latent representation then re expand back into the action space.

Third: Once you tube your model so that it overfits the training implement dropout. This will help regularize your agent so that it will generalize the problem better 

Fourth: optional. Add l1 and l2 regularization (ridge, lasso) to your weights",r/machinelearning,Z0FBQUFBQm0yeGJ5QjZHcTZqTkNHYm1wMVVmNkxrX2htaHV4YnBwQ2tNRGstV1dkOVhSdG92QzYzYlNnOW40YVRTWV9CektGalF5SFZKVUtWSkVHc3E3M0VIQXlRYUxZMTVFLUVpSmRZUmhJZnNoSVROS1JfRkk9
Thanks!,r/machinelearning,Z0FBQUFBQm0yeGJ5Q1hKOVdFSVdndTBNLVRaZXdmUXZocnZHRWRVNV9PX0swWWY1Zk1lN1h5M1M0YkhqMWctYndCbFlTbWFmY3FaX1YxWlNnWTREa1JCX1dPdEV2cmFCYzhxR0dMOVVlU0pZQzNKUUEwb2w3b0U9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5aHJwTVF4R04xZXNBRlZjTjVaZEx2aWJLNGVXNGtHSFRRQ3JxOGwzMnNvQXBtb1dKSUwtY1p2UklzdjExZHJjVVE5NzdORk8xeFRsWFFYTVhIMi1jWkE9PQ==
"Thank for your advice, i will try it. Thank you very much !",r/machinelearning,Z0FBQUFBQm0yeGJ5YzZYRFpkN3RpYnlwLVVUQkJuVXBsbWE0NlkwMjJRdTh4WmRKOFp2TEtOY1RNVXNUR3kxbVhOR05KbFlOS0t1d3RYMTdCN0tsMHgzZUsxZ2ZNdzRaN1MxMkdVd3JUeDlwQ09FeWhUX2V6Y0U9
I see so it’s closest to a prompt optimization/engineering and eval problem?,r/machinelearning,Z0FBQUFBQm0yeGJ5YmRGUTFxbm9uR3U3bG1pZzRNSWloZ082UmRYejcyREtOdTVDZ0d2dWlaM1p2cWxnMGZZS1dzVHZMel9RazdaOGttZDQydzQtSGdxOEpScWNzWmJqWG8wT2ZNNTdvZ0ItQWpuTUpkN1JJdFE9
"[SurVAE Flows](https://arxiv.org/pdf/2007.02731) might be what you are looking for. From the abstract: 

> SurVAE Flows bridge the
gap between normalizing flows and VAEs with surjective transformations, wherein
the transformations are deterministic in one direction (...), and stochastic in the reverse direction (...).",r/machinelearning,Z0FBQUFBQm0yeGJ5bWNBd1poS19lTmVIQ0p6YXlkVkxiZVlRdFl6Q2pFMWVtMzJOM0RZem1RdjZCM1JneUNYTUFCWWpCVFRsMkw0eVZfX2Y3OElDMFJVaUMxNVUzNEFNZmc9PQ==
That's my guess yes.,r/machinelearning,Z0FBQUFBQm0yeGJ5SUtzYVhTWTZWY0s0RXJWWTJ6cXRVQUt1SE0temhZeFpha25nMnJWREZPb3NCZjRxVkJvWEtBWUQ3TzdSci1YWmVzam9GVkpUQk1FU2ZpMG9La3A2d1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5MEx2eDdCTUR1OFl3dzJVVlJTTWU3Tm9zQzdSQ1BUcktpWjhaTXd4RzVrcmRacG9ZMmFzUG9oWHVtR1ZlV1NmeXBHYkktTVVBek8zaTBSRm1TamxiZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5eG0tMllnR25lclBSRjhQRklvdUJLX2FTNVpOcWNobjVXbElvdHZyMTZtWEM5bmx6R0huZzFZNG5iMmdzNmlLUTNMeVdfa3hVdThVZ3d5cFJ3M1kyY3c9PQ==
"Patching yes works as a windowing mechanism, but achieves a different thing - essentially the model treats as token embeddings not individual timepoints, but windows. I explain it in more detail in this article: [TimesFM](https://aihorizonforecast.substack.com/p/timesfm-googles-foundation-model) (Go to section how patching works)",r/machinelearning,Z0FBQUFBQm0yeGJ5T19sLTlTeVZqd3lCQjJ5NmdrQWNpWk14bjZZSHVMZ0VZVlhyV3ZTMXRSa0VfMGhtT2E4M3FMdjU0MlhKVHlrNHR1c1RYazNXX3YtMWVQdjNlUGo4VkE9PQ==
"Most of the evaluation benchmarks don't include demonstrations (""trajectories""). It's like asking a human to perform a task they've never seen before, and expecting them to complete it successfully.

Many business processes are highly contextual, and we can't expect models to have been trained on them. That's why at https://github.com/OpenAdaptAI/OpenAdapt we rely on learning from demonstration. Just like with a human, first you demonstrate how to complete a task, then have the model take over.

We are working on performance evals now.

Edit: feedback welcome!",r/machinelearning,Z0FBQUFBQm0yeGJ5SURzanVXR3ZENVlKOWllV21xWTV0NTB3dHNLWFIzQzBLdWZZUmZqUXV3eGNQSHVRbGR2aDhnZVBJRF9kbDR5MmZqcHlTQkJYMGRJOXhkMUhnVV83c3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ZlN0ZGE4UFpNWUpacEMwblZGRkxNNm1SSmhkbFRfWEVSWFB0aDhkUVU1V1NmaVlkc3dSdS1OTUNBUjl5TS00b0dDYzVvRHEwbk0yRHNVaXNLaUhZWXc9PQ==
"Yes, it was my introduction and I loved it.",r/machinelearning,Z0FBQUFBQm0yeGJ5dFNLZ2Y5YkR6SGRCcld3anYyUi1LNU1WTks4MjJpVnJPQWJxX3NnYlJKV19NODlTaTh2bnBvZUlUMUhhQi05QWV3T19KLVp1Nm1Gdnp4eUZOV3A4R2c9PQ==
Are these the Coursera specializations?,r/machinelearning,Z0FBQUFBQm0yeGJ5QzgzWXNZNU10X09sdnY5RXQ5QkJBMTgyMENwMUIxVjNSLTBMYUI2X1k1c1JGczFibGQ4TUNCZ1U1OXMxeXlvS01kaWQ3cWpLTGx3Y0ZWYnJwR2IzclJ3bVEtTUUwUlJlQUtYa2FzV09WZDA9
Absolutely yes. I used this years ago to transition to Data Science from SWE.,r/machinelearning,Z0FBQUFBQm0yeGJ5bFQyNzZGaElRcWRBOE9VUXhCY2JsSU9POFJtV3lpVm51VE5GS0xiNVRUbWxLVm1nZEtFbkFtTHN6ZDJINGNmNVlOLThKMHZtNjA3c1hhcV9ocEhjYnc9PQ==
Please see above,r/machinelearning,Z0FBQUFBQm0yeGJ5VFhnY1Q0Rzg4dWNVNUF3WWJtMjN0cmE3MS1hNkE2X191WGtIMUxCWGtPLS1MZmktZG5BbU15RlY0X2ZzYllKT2pIUUoxZ0NWcXo2RnpoXzhYQ2dBQlE9PQ==
Would be nice if you could upload it on huggingface,r/machinelearning,Z0FBQUFBQm0yeGJ5cjZMWVFSNjlFd2JYVEl0TVczLTdYQ2Y0UXEtcTFrcldzU3hvNGN6OHdhcUdITGx2TF9qT0prVk54cy1VWHB5STk5ZjNzaDFVYVNQVnRLU25JWS05akE9PQ==
I say this in the last paragraph.,r/machinelearning,Z0FBQUFBQm0yeGJ5TlBOalBNYkdiR1VIS296cjVXRkM4UUNRZUs2Szc2STRQTXc5N0NFSnBKV3FkalR3LXBHdkJjM2dScW83WTNHb3N1Snd4RTNXYkZ1SFFWTk9jZS1IUEE9PQ==
"Yes from deeplearning.ai (Andrew's company) on Coursera (also Andrew's company)

I went from DL as a black box to generally understanding how it works under the hood.",r/machinelearning,Z0FBQUFBQm0yeGJ5N3ZLR3VlVXNqRkFmWGx1NFlkdkhISUZfN0FPWVZ0SUs0U21hVjZQQkMxYjFPaEhuY01iekRCQnp1Si03aGlUNVBsUDNzZWdzR0JfWXBuM3U2clV6ZHc9PQ==
"OP said their current gig is contract as well.

OP - unrelated to the question at hand, you need to look into the differences between salaried and contract work. $210k is not your salary, or at least it's not an apples to apples comparison to a salaried position. You at the very least need to subtract an extra 7.65% FICA tax off of that (assuming you're in the US), and more if you're not getting any benefits, holidays, etc.",r/machinelearning,Z0FBQUFBQm0yeGJ5NDB1OExFVnNnZzE2NVpwUjh5TE5ObFhJeGZtM2NrS1hVQWMyYjNhQVk5UFItQzZua1k0OXAyR2xJVUZHMHVPNVhWa0FYeG4yMldpSmRpS2l2UjNyakpoN0dSelNTT1JPNTZWRjEzdVVJeFU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5RDdKY2RMdmJKQkFrME83SGFSeXhnMkxYZ1JQaHM2Z3J0Q2VHVkt4MnFCTHZEQWxRUE1wWk5kUUVwTEZva2NIVUdYbUk5d3dnZ3ZDRFRfMVBZUFpCU2c9PQ==
"Update: We've uploaded a comparison, you can check it out at [https://camb-ai.github.io/MARS5-TTS/](https://camb-ai.github.io/MARS5-TTS/)",r/machinelearning,Z0FBQUFBQm0yeGJ5SC1lZ1pGTFd0eWhmODZ4MXJrcGJxaTNhMUNpMnZCOWdSTnNKM1k1eE1FaE5HOVA0UHFDcEFlcWJNd0k0ZFVpbzBlRlVBWnBjdkhFb1k0QWhKRmg0bVE9PQ==
We'll also upload comparisons with ground truth here ASAP,r/machinelearning,Z0FBQUFBQm0yeGJ5ZktacUozX01FekJxOVZ4SThqSDRtVHVEUUx5YTk1WnpvODJXT2pKcmJPc0JmVGd3LTktQkEyQk9oMjUzcGYzUjZ1LU5pX25aOGJXeHItM0NOcGNPQ0E9PQ==
"> Given that broad consensus, 

I feel there isnt a broad consensus though. Either that or the hype has died down because in r/mlscaling saying 

>LLMs are very poor reasoners.

is particularly unpopular",r/machinelearning,Z0FBQUFBQm0yeGJ5RFJEcnZHaEpEREFjOFVOam1YdGxLZXdfcVpkSHh5cnJyRkNENldObTc1X1UtQlZoeFIxSTFNR1Z2MnJKZkd1cXVrTER4eE9ZNXVlN2FzQXpOQzFaQXc9PQ==
"Here's a sneak peek of /r/mlscaling using the [top posts](https://np.reddit.com/r/mlscaling/top/?sort=top&t=year) of the year!

\\#1: [""Microsoft and OpenAI Plot $100 Billion Stargate AI Supercomputer"", The Information](https://www.theinformation.com/articles/microsoft-and-openai-plot-100-billion-stargate-ai-supercomputer) | [74 comments](https://np.reddit.com/r/mlscaling/comments/1bqx5ph/microsoft_and_openai_plot_100_billion_stargate_ai/)  
\\#2: [Bill Gates tells a German newspaper that GPT5 won't be much better than GPT4: ""a limit has been reached""](https://www.handelsblatt.com/technik/ki/bill-gates-mit-ki-koennen-medikamente-viel-schneller-entwickelt-werden/29450298.html) | [182 comments](https://np.reddit.com/r/mlscaling/comments/182os7q/bill_gates_tells_a_german_newspaper_that_gpt5/)  
\\#3: [OpenAI rumors: breakthrough math model Q* was relevant to board's actions](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/) | [24 comments](https://np.reddit.com/r/mlscaling/comments/181nsyb/openai_rumors_breakthrough_math_model_q_was/)

----
^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| ^^[Contact](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| ^^[Info](https://np.reddit.com/r/sneakpeekbot/) ^^| ^^[Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/o8wk1r/blacklist_ix/) ^^| ^^[GitHub](https://github.com/ghnr/sneakpeekbot)",r/machinelearning,Z0FBQUFBQm0yeGJ5cGw3QzdnZmJyLW1BT2xsZ3F1ZVB4Z1pJX3ZZZU91Ql84eW9NNzY4T1ZVODZZN2xnMmhDOFdyZVNwa0J1emJmTDFXUjJWaEdyRFdOTkpyQnpkRlJhVVE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ5bnB1MG1vOV8wN3ZOcVR6Sl8wbGFyVEFjbF9ycXY2TGtLNkdDeS1SZ3RtRmdYeEIwb19kREYzR2RuT3U5Y2c0b3RWQUpiQW5DN3plTm8yUGFhRUh0c3Q4dl9EQ0pHQ283ZmsxU2otb2FzUm89
"Theoretical knowledge can definitely help in identifying and avoiding common pitfalls, but it's not a requirement for achieving SOTA results.",r/machinelearning,Z0FBQUFBQm0yeGJ5ME9Rek5PcE9rZDB6WHNGNVVlbkNkYlV6QWo4SWtFckNXczJlV2pCSVFkcDlPdjBMeVVIN2RTOGdrQUZ1MjdyNE1sTnFjTTJLNG5KUEZNMVNJaDR2blE9PQ==
"Really neat work, which I don't want to snark in any way, but I do have to say 'why would we expect to be able to accurately predict such downstream capabilities in the first place?'. Papers seems to address this at least in some sense, which is really cool!",r/machinelearning,Z0FBQUFBQm0yeGJ5WDVKZnpaamdHYjVPdUxqc3BtSF9Lc3BXZ3lnZzRrTVduZmJrSHJBS2pZTzI1dXpjRXVXbEJ5TlY4ck13QXlpX1JwWE15ZGctMUR5T1FJMDczSjF5Q0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5cDJNRXh6WWFJelRNU0tSYTJjRTByVHZSUThjOWpqdEZRdmc1cGVHVnJMcHlweVRyOE4yODBqeWxKM2U1NkxNeWt4ZUpEblBjRGNuVG9meFlCUXBHVlE9PQ==
"It has been a year, any change? I'm working on a mod for an RPG game to voice all characters and Id really like a good way to synth/clone voices.

Coqui and bark look neat, but I have no idea how to use them... All I know is that, if someone can make human-legible documentation for those (or if there is a better altenrative since this post now that it has been a year), I dont mind letting my nvidia gpu (cheapest model with CUDA lol) run for weeks on end to get some nice voices.",r/machinelearning,Z0FBQUFBQm0yeGJ5YzJ5VlBXbmZTWlhsaXBsYUF1UVp2R1A2QUdkY21ZdFBXbThibTZkRmNGNlpRZ1RxUFI4WWUxWVdCNjN1Tk9YMFpGeUZjdlZiRW1lSlJ2S1llYllKeVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ODBRTHRzZzJlaFQyN1pPSm1INm11NXlaLXllNEhJdU9RSVhkUnp5dXVlVmQ4WmNvc3lXS2E5T25VTGE2Y1d4MGhabHZCbXN0bU9JTHZReFdkOWZLQ2c9PQ==
Iam interested,r/machinelearning,Z0FBQUFBQm0yeGJ5SnFyVVZmd1E5RjlDczZVVzd6T2wwX180TnkyLTQ5VUtuWUU5dEtUUnBIOXdSNFJSWXVsZVZGWGRPNThaRVFQYVlzakU0YmlodFZGX3ZMLTgyYm1oQ0FweDN4MU5ZUnJoZXFxZEU1cnA4ZG89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5bXZDNjNaZ0ZZTXFJOEpwbmFCQW0xVG9qN0FlLS1DVlNQTnY5ZE1mTVlFdkFNaEdqNTZSeEM3ckFJbjlFdXZXc2lHYzhJb3NsSlBIWVNsWmFjQXhBaEE9PQ==
"I would say that the statement ""LLMs are very poor reasoners"" would probably be common wisdom even in r/mlscaling .

I mean the fact that current LLMs are poor reasoners has been documented literally thousands of times now!

But saying: ""Even an LLM 3 orders of magnitude bigger than GPT-4 would be a poor reasoner"" is where you'd run into disagreement.

Another thing you might say is: ""LLMs do not/cannot reason AT ALL. Not even a little bit. They aren't poor at it. They just don't do it. They cannot reason anymore than a bird can.""

And sure, that might also be controversial. But current ""LLMs are poor reasoners?"" [Everybody knows that](https://www.reddit.com/r/mlscaling/comments/17ir95w/yann_lecun_keeps_claiming_even_scaled_llms_are/).",r/machinelearning,Z0FBQUFBQm0yeGJ5aC05RnBJOTJ0ZE9ndTRfY0xNOUZ3ZzNNQ1E5ZFhTczU4SFNLd1dMczgxZTdQbFZOTXlYblpxZWQwb0NzTjBteUltZDVDUVNjZUpuQVZvMzExV1NscWFTeEtsV3NLTnltTVNTWE51dml4Y0E9
"> Everybody knows that.

That is a Yann LeCunn. Yann LeCunn is treated as a negative nancy and controversial in regards to LLMs

https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/

I personally believe LLMs are bad reasoners but every time Open AI releases a new model have to go through a whole lot of people saying you are being a negative nancy for months after a model is released.

There is way too much money being made on LLMs and too many people making money on LLMs who dont believe they are bad reasoners since they make money off the hype of LLMs

https://youtu.be/3gb-ZkVRemQ?t=1787",r/machinelearning,Z0FBQUFBQm0yeGJ5TGlDbmJNRFh0U2hYSENsazcwVzRhVmJSZms0YzBma2pydVBqaEJRWVdrMWdId1VaOFdPRHd2X2ZLZGxNVkhrR2xxTUFvTlgxUlp4UXpON1JEdGlOY2c9PQ==
"I wonder would agents be like the job market in the future? Like we would pick an agent that we think is best for the task, and then just hope that it does its job. 

What if we can add checks and balances for agents like we do with new employees?",r/machinelearning,Z0FBQUFBQm0yeGJ5RE5wVHhPUUtqUDFXa0hkaGRkQ2JLWGYtVlh1dDdMYnZ6dHFXN1BEekEzNlAwNU5GdlBtbGRyOWg4bUdZcHdOTWRrQUlHM05MYTVuTmRPblpuUlI1cUtHVTd4bjY3dE1jZHFBemRkXzRJSFE9
"Hot take: the people who invent SOTA methods generally do not understand them, and are not necessarily the best at implementing them either. 

Machine learning is generally an experimental science. Mathematical analysis and proof usually comes after results, not before them.

And I agree that, in industry, you definitely don't need a PhD to do this kind of work. I think companies are making a mistake when they prioritize hiring trained academics over other people.",r/machinelearning,Z0FBQUFBQm0yeGJ5a2xVU2tLWFBodUJFZ0p3LXFvejhvOHBYY1ZOQmtMQlZ0WEdhMHpmeFZRQzdLRFpwSkdYUmlRZm1HTklibDJlRlE2RnZvdDhIbFZ2NnQ2al9kRVN3VFE9PQ==
Yea that could also be very helpful. How would you go about doing something like this? Experiment with all the tools and show a properly functioning pipeline? Example would be storing research papers in vector dbs and then chatting with them to build a knowledge graph,r/machinelearning,Z0FBQUFBQm0yeGJ5X043U2dRQlZQdWtUUGZWUzZoSy16VVFDNTlSTWd2N1V4TUdhR3BVdDY3UE5ycXg3RHlteGNVUmVLMUdKRVdGckdITDJjY3J0LU5yOUF3ZVNMNUlMeFE9PQ==
"I wasn't linking to Yann LeCunn's opinion. I was linking to the narrative around it. Nobody responded: ""Oh...current LLMs are GREAT reasoners."" They said: ""Let's wait and see what the next round of LLMs are like.""

I'm not sure what I was supposed to get from that link. I watched a few minutes and nobody even mentioned the word ""reasoning.""",r/machinelearning,Z0FBQUFBQm0yeGJ5Z0NKMlZQVDlaTEdLbzlCV0k3QW96R21XUFNuaFFfT0xmMjJlOXBQU21YTi1WZW56VXZlbVExY3BIODl0TDB6Z1Z6bWNiRjFzVzlOWHNINVVtSGZHVXN5dkJtV05qRDBha25xRnNnMVh5aE09
"Your first suggestion is not correct. These networks are value functions, not classifiers.

Your second suggestion probably won't matter in RL.

Your third suggestion will almost certainly hurt. There's a reason why no one uses dropout in RL.

  
Source: I have a PhD in RL.",r/machinelearning,Z0FBQUFBQm0yeGJ5UndpTXlzUGtjZ3VUQVZPa3IzbWt1allTdl9KM29sNkZ2dmF5cHFUd2RJVm11TkxLR1FLTUx4V2R3VmVJa1ppUV9ERGR1R1I2TFhqWGI4Tk5rRlc0cXlDZjZOd1I0QlU2UFF1cFAyOEw5bjQ9
"Totally agree with you on pretty much every point, but having a PhD in RL seems irrelevant to the argument.

If anyone else is curious, the reason dropout is unlikely to help is because most RL models are trained on data regimes where you can continually generate data samples.

Dropout is helpful for preventing overfitting, but overfitting is not as much of a concern when you have an essentially infinite data generating process. Models are unlikely to see the same sample many times, so the chances of them overfitting is significantly reduced, rendering dropout less helpful.",r/machinelearning,Z0FBQUFBQm0yeGJ5aWdmOTNFeHFGRU9pcUw5OEJIM01menRMR0hCTklJbVk2dWtDUlhLa0lKWFhYVllETVk1X05WOVFUZFFVR3RNYVpNNFNhRzNFYzJqekczTE9LRUFaM2c9PQ==
"Bookmarked this book to check out over the week. Going through the chapter titles, this seems quite useful  
[https://link.springer.com/book/10.1007/978-3-031-10754-2](https://link.springer.com/book/10.1007/978-3-031-10754-2)",r/machinelearning,Z0FBQUFBQm0yeGJ5cEw1UnhFbVNCY2cwTE1Ud2p3NWMwa3pPRU9iTkZCWU12d1l2REpSelJOcUxrMllSOHhoaGlBM18zYzJSVEwwcHVqTTdXeFoyMGhqem5oWVFid2lJT2lFS0R6UnBFOHhuTWxpUUpzUVp5dVE9
Have you considered using PyTorch Geometric's Heterogeneous GraphSAGE for this task?,r/machinelearning,Z0FBQUFBQm0yeGJ5amRuaXdFbldUOXpkaXpXdC1NTGFTVTc3Tm51Ml8wRmIxWGxPWk1ILXQ2TnhHNEthMUFDLXkzMTEyZmdLUDlqRFlkdjYtOVVzTllzLVJvMjJiSnhXVWtSQXk2cWZmeDZSSm9KSjNEazJIWVU9
"Consider value-based pricing: charge based on project value, not just hours worked.",r/machinelearning,Z0FBQUFBQm0yeGJ5b05YUVdMSDY5QnRpQVlyZ2dlWDVzWmNxV3JsckM1MUhUMGd0Q3J1SnE0OUdoTjQ4S01SeGhod0pWX2FKald1UWZDM3NGWkR1UGhPY1VhLVJQRGFYYzdxal8wcmpBZEExazBIel9VeGc1TTQ9
That was the one that I had in mind as well. Citations may also be useful.,r/machinelearning,Z0FBQUFBQm0yeGJ5MFVrQ1hzTUVpWEI0S1B1Vk8tT05sd0hDb2xzYUFJS2FjOGd6U0hURlNyV253SkNsZjRlQUdOdHFKRUhfQ2l3VURZMlJYbl82Qkc5UHcyS01PZGFKQnc9PQ==
"Lending, but I work with all departments and develop  both internal and external tools",r/machinelearning,Z0FBQUFBQm0yeGJ5aDJPS0ZfWG9BMFJlODcyWFZqbVVudkdqX2VoSnV4eHRQN3AyQ09BclJ2S1JwM2ROczRhNWdDMEtVZUJ5ZzY2cXNIQ29uc2lhbXNhdDRsOFhvYkR2WFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5c05OS2FRRXlHeU1wOEU4LTZEbHdENHk1Z3JGSVg3ZV9IYTRfdWphMzhYWE9KYlZTZ3ktVnNkU2FLbW10YVZ6UzAxZ1ptQWsyRWxOdERXSWdsS01rLXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5YlkyTnBKYzkxMEszcG13dnJnbVZjcTBlSHA1WFVmY3VNOExiM25GeGdRZDV1N2t6c2hNblJmdXhwaHJpM0JXUFFUZ3hzbXVXZWYwb0Fsc09TajBPb2c9PQ==
Why don't you help them instead of saying no then? Sure I could be wrong. But you still haven't given the OP any advice to the contrary.,r/machinelearning,Z0FBQUFBQm0yeGJ5OU9BazktbUtGS0ZtSS04enpVdHBDYnBFbTU3T2hvRFd3Q2t2QXVubWxpYnA0YzJvSnVhVF9YRmp0STFCTl9GOTd5cU9jdkQzYjNvbWVPNURDejlBOHgyUEpwRDlUNnF4MlZEcWpzNHMwcjg9
"Yes, experiment and develop a pipeline.  But there are people doing that already who are pretty active on X (Twitter) and Youtube and who often sell webinars  on how to use these tools to streamline your workflow.",r/machinelearning,Z0FBQUFBQm0yeGJ5RlZGenFpX2xkbnd6Uk9pQkp6d3FuQUVoZ2FpRnNPUHVWelR3UjZvZjlvX1BVVWFwclhjT0lWYzNYR2tabDhTdnZDS3pCOUU0dXJ4OHNDQmJoTm5BcGc9PQ==
"Your transformer module, such as Informer, Spaceformer, or BERT, will only provide you with the encoding. You are free to design your prediction head to work with regression.",r/machinelearning,Z0FBQUFBQm0yeGJ5QTN2bzh5WGtvalRNQzluLVdFS3hqVk80ak1MQU5UTk1vdmxzbUhIVGtuNE9qTjV6Vnc5Z3dXM21zS05ORHFIMWlEUEstMFpLMkd1OTMwSDBEZDVZYnc9PQ==
"Do you have a PhD+10 years of industry experience? If so, $200 per hour should be your minimum. ",r/machinelearning,Z0FBQUFBQm0yeGJ5ajUtdFhBSGxxeDdNSTg3QzJ6dUNSMlh6UVZ1Y0gwSEYwYUVRa2M1ejFLWXYzMDRDbmh2NjJzQnhIMnpCN3I0MHMzcV9xb084M0JOR0puOHA4YjRBUGc9PQ==
"I think the biggest pitfall in applying models is that people often lack the statistical understanding of what's going on.

Understanding the data generating process and how it relates to your model is very important. Even how you choose to split your dataset into train/validation/test is often overlooked.

Or understanding that ML models trained on observational data will only learn predictive correlations, which is not necessarily the same as causal predictions, etc.

These things definitely don't need a PhD to understand or learn, but it does require a bit more than what you'd get in a typical undergrad offering. Which means you either need to be a driven self-learner that excels in that, or you pursue a graduate degree which offers more time and exposure to that world.",r/machinelearning,Z0FBQUFBQm0yeGJ5NkNYMDhpSnE2VmkwVy04SE1RZDJsWmhQbmU2Vlc4aFdPYXVoUmtiR3JVdHJBdmxSS3pDUXVhVHhDTWRHSXlfX3pVOXNWWlJ1Q3loa2lKRlVvcHBTQnc9PQ==
"> I was linking to the narrative around it.

That was 7 months ago. I linked to a post 5 months ago https://www.reddit.com/r/MachineLearning/comments/19534v6/what_do_you_think_about_yann_lecuns_controversial/ . The sentiment changes based on every model and paper and goes back and forth. Each time people claiming the sentiment was obvious.",r/machinelearning,Z0FBQUFBQm0yeGJ5QmhGcEpiODlZYU1iOGR4MmZkQWNYWG53Y0dJcTB1MTJTcXJNa2REX3Rmb0J6NVAxUFdpcS1FNXkyUzJqZWRIU1BIUExoOW9fYzQ2VlczSXJsSnFVN1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5YnZJV1k1Z2NqcVNONHViWDh2U2FNOEpLWW9KQU1QcFhTejBGbUt4NE0zaHdTVFlDVkczWWxnRU4waFZIaXNrMWQ3OTFITnZ4c2pwd3VSaHhzcXpIb3c9PQ==
"I've seen before someone who said ""you are not a good ML engineer if you choose your model based on experiments not on intuition"", I totally disagree because of what you said, it's an experimental field, obviously NN won't be my go-to choice if I'm dealing with tabular data but who can tell if random forest will be better than xgboost.",r/machinelearning,Z0FBQUFBQm0yeGJ5eFpVRVBSUDFrM1M2VDFjVXRibFliT3RYYkZoUlQ0Nzd4OWJtU09ueHlHbFpTVkxFMjFqWjZNUVhjZzJ2Z2w2Q0VMOE9PQnB3RXdJeE03UXdOSGZ6X1E9PQ==
Most speech models I see are tts or stt. Are there research and models that go speech-to-speech? I can think of translation and voice/tone change as some potential applications.,r/machinelearning,Z0FBQUFBQm0yeGJ5R2FTNjVJenNQbExoV0N5UzBvdHB4SXlkUWI1MlpHajlNdlhmYmJvZGZSM19mb3Bfb2pPLVdUY21vcVNTMXlCU2QybnZSMFhHLWJqNzhfZVZOa0puRmc9PQ==
"Update: you have something good here. Non English or audio with strong accents or distortions suffer a lot (no surprises there). You also seem to have short samples to listen to, so I’m curious if that’s because generation is costly (compute or time), or because of quality degradation as the clip goes on.",r/machinelearning,Z0FBQUFBQm0yeGJ5RTJNTk5kRjJHM2dUbU4tOXpDMUhiRWRQMjJkRXhGY096TEF1bXI3cU1ScGY5VDlSRjJ3QzRwOGhEbDItU01PWDI4UWtVb3pfeUg2OVc5anRwdHlidmc9PQ==
"Because of the non-bijectivity (which is a common assumption in most ML algorithms) I think you are bound to run into the problem of discovering multiple x.

I was going to suggest  Gaussian Processes (GPs) because you can obtain  y=E\\[f(x)\\]  such that is a  *E\\[f \\]is a closed-form mathematical expression*. Given a y, you can minimize RMSE(y-E\\[f(x)\\]) using grad. desc. I only know the case of 1D y, but there exist multi-output GPs as well \\[1\\]. If you're new to GPs, I have a blog post on it \\[2\\].

But this won't solve the problem of only finding one/some x depending on the GD, e.g., initialization, learning rate.

I was also thinking along the lines of what [TheJpx3](https://www.reddit.com/user/TheJpx3/) mentioned. You can directly learn y->x. *However*,  as a twist maybe you could pre-process the data to instead learn y-> W, where the W is distribution parameter that governs the many x you see for y. Cumbersome, but might work depending on the context.

A full-blown extension this is to of course learn a generative model for x given y (which you suggested). It would be interesting to see how well this works, because given a y the corresponding x might not have desirable ""clumping"" behavior, i.e., you might have five x values producing the same y but they might be in different parts of the input space. The only clumping behavior it will have is probably not the one you want - points in the immediate neighborhood of one specific x.

Refs:

1. [https://invenia.github.io/blog/2021/02/19/OILMM-pt1/](https://invenia.github.io/blog/2021/02/19/OILMM-pt1/)
2. [https://blog.quipu-strands.com/bayesopt\\_1\\_key\\_ideas\\_GPs#gaussian\\_processes](https://blog.quipu-strands.com/bayesopt_1_key_ideas_GPs#gaussian_processes)",r/machinelearning,Z0FBQUFBQm0yeGJ5R3hxb1RLTzZSbERQMmoyR3VQR3cyRDlLNVhZSFFVMHVuSjRGYjM2SHk2X0JEX1FfaFBtRGlOWEdKV1NWOVZKS2RqOHpRUGdSLWlzYUIzeFBURzQ5TEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5SUxDLVRyZzBSQms3RFJHZExCZ1BZaU5TSlBod1RxVWhpZzBGMDdyc1RzdVgwT0l4TWl5NmZGUlhRT3E4MERueV9qdnMyUFRjTDl0NnJfZGdVUE9OVlE9PQ==
"Check out hypernetworks, that technique might help you design a system that can produce learned weights in the forward pass.",r/machinelearning,Z0FBQUFBQm0yeGJ5cHE1NVVhTzZON0hQcjdHYTQ3ZGVBX0dYWEV6ZnNRZmQwaEZIdGhrMUJ3TWg2UVZvX3FtVURCS3RlZnljb1NGMXAzYzdUN2tQbVc1ODctcXRBWTZaWEE9PQ==
"In my job, I can probably do around 75% of it by ""just applying"" existing algorithms and tools. It still requires in depth knowledge in order to apply things correctly, choose the right models, be as effective as possible with the available data etc. but I don't think I need my PhD for that. 


However, where I'm really valuable for my company are the few problems where I need to develop novel solutions that require a deeper understanding of the models and theory. This is often a combination of limited amounts of (labeled) data being available, the types of inputs, and/or non-standard requirements wrt. the intended outputs. And what I've found is that these usually happen to be the projects that have a much bigger impact and that make me invaluable to the company. They are the reason why the company is doing their best to keep me happy, which is a great position to be in. 


So the answer is, it depends. I don't think everyone needs a PhD to do good applied work in ML. However, having deep understanding of ML is required for some projects, and those are often the ones that are the most interesting to work on and that will help you stand out. ",r/machinelearning,Z0FBQUFBQm0yeGJ5NWJmWUJjeFJWSkFfdFA4cVBGaFFBbUJGNVBNRTNzQ3RYNW1TMDZGV2FfaV9uYlhDNDNrcEZ0ZDN2b1J2WjRVODlCdVZtbE45NWFTZW9zVU1sOGFJM2c9PQ==
What an absurd thing for them to say; intuition is probably the least appropriate basis for making decisions in engineering. ,r/machinelearning,Z0FBQUFBQm0yeGJ5Y3BVZFNNSnNRV2oxX0hSbXdwN01fTGJ5QUtqM1U5cW9VWWhubXlrLXI5YWppVHczVnVoalZBdTVBOE1pelE5YWNibENXZzFvTHNxajl4U3pzV3B0NHc9PQ==
Hourly gives flexibility to 'change orders' as long as they keep paying but you have to track your hours and what the billing increments are.  By project you take on more risk if your estimates are off and you have to address change orders.  You'll still want to track your hours internally to get better at estimating.  It is easy to burn 3-4 hours researching/debugging why the model broke.   Don't forget to consider support/maintenance/retraining package as well as a separate line item.,r/machinelearning,Z0FBQUFBQm0yeGJ5bG1Ua2ppQW1zQmdicXM4aUFxVWN2SHN6X1AyN0ZPbkJ5ME42NDE4YnZMQ3Z5MHpDZklZZzJNSVJOelRNeFBlV1poanhpNEltMER0bnNpemVMaWxBb3JUSkJ2dzdDb1VaYjlsbWxIeVVqVWM9
"We get lots of applicants with degrees in ML/stats/CS, who have the right kinds of courses, projects and internships. Anything below that (bootcamps, certs etc) is hardly looked at. It's just not worth our time as it's unlikely that candidates without the relevant degrees will have the background and experience we need. ",r/machinelearning,Z0FBQUFBQm0yeGJ5aVMtQ0hsUnM3WU9qeDg3ajZVaFJhNjA2QmE5c2gzVWVwazVZeXF1eF8yYjFrWHdKc3pXNEZSQ2xBMHhYa2xqOUhSa0hKSUxYZGEteW5TTGI5LUhYYXc9PQ==
?!,r/machinelearning,Z0FBQUFBQm0yeGJ5NEJXanhQY2k2UlhsX3RNQWU4MUFSMnVXU0gteWNzYks1dU5RWnJNTEY1MUhyZ3NlU1ZyYW9PREt4SGpnVjc0Y3hkVGVzTGtOMUZxZTBsV1NSTVQ3OHc9PQ==
Google Cloud Certified - Professional Machine Learning Engineer is a great option to consider,r/machinelearning,Z0FBQUFBQm0yeGJ5aEZxREVoNGVrelRtaVhaZ2NSLVpPY0NOeUs1S3F4TEZTc2J5Q0JpaUVpSlgyWXlVZHFPTzBIcnBKdE5Ucmxha2hRQmExVEpzQlJEZHNka1BKMzV0MzFMY0ZNaTh4eGVoNTJEWnpNcWl3UXc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ5Xzl1NjJjcFpYWlNPMERBZDRVeElRRlFmaVBpRTFNaGpKVmxyRzl2WHNFQ29Fay04TkM2U2xEbkNwODE2TnptaUgzbFZXRl9kWkM3bmNSMmFVNF9pOGlDZ0lVS1hCazl3c0hGRjdKcmtyNFU9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ5cHVSNVk1N0dtaHRoR21sUVFQLWFzQktmcURJN0VZWFpYbHdhVHVRRWxnX0xYTjRnaXEyYkhFdmFHWm9PMmlsUnZiR3Z4VDgyOUY3S1BhVm9JYzRTbWJmM2x2X25Qb3RCM190TXBMN0p3SDg9
Thank you. I have a degree in cloud services so the Google ML component is very attractive,r/machinelearning,Z0FBQUFBQm0yeGJ5NFFTaXluVjRwMloycGIwaTZIYV9jbHhUTzNUN3FOUTA1Q2Q0bkJQSWlieE50VEY2aUtyN3I4SFJWOFk5cENPbWd3Z0hNZU5UN0dfVjJINEVSV285YUE9PQ==
"Very good points. I am certified in cloud computing and cyber security, interest is mostly personal and many applications to train data in my line of work without specifically being a ML engineer. Just interested in certification that is at least recognised that says I understand how it works.",r/machinelearning,Z0FBQUFBQm0yeGJ5MTU3bnhtbFhZaXA0WDllbUN5cHRxeWQxb21kbnN1UE4xYXM0bEh1YnVhMUhYc3NUWTdlQ3NobW0xQWphNkNPbmZMYXdNUTh5eWZoX1lzQWo5UXRHbmc9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ5cWFUM0tYZlVRZUlGa05VbVFoazdtWmVJZExtLXluWUdIOVNod1laQlJDdFBKNWZKNVdZSC1tZDVyamRiSWpBbmEwUDJwbFFlZDc4aGYxSnkzNlJ4NjFGVllUbHp0OGhJOW1ZbG5fTjJnTjQ9
"Hi can I dm you, I got accepted by the program",r/machinelearning,Z0FBQUFBQm0yeGJ5UHVSUmh0QTN4YkZKa2RkaEk4SEt5bFVmRkZSQmhXRGFwcnB1bjFqYS1fNk5ZT2QteEhVbkJYaGZDZk4ydTFiRU5VZDl0elVrOGJ6cE16VTZEYkljalE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5NnBWUzE1Ry0yTWN6S1VLa0xaRmw4MHdOSWNJSlY4dlBqZGxIU1JUTVp1S2s3cTBINVJiRThSYjhweUhoSzFnYTg3Q3FpR1FYbndFdUFKMzhNLS1yaEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5cnJsZjlxY196ZWFIMGRGb0w0czFXRmptcV8zMzBSakdMTWRrTDJocXR4YUtiWkE2elRya1pjNGx0RktCTUlmZWt3Q2pranEtMnRJSnJvTy1XNV9JcUE9PQ==
What are my chance?,r/machinelearning,Z0FBQUFBQm0yeGJ5ckRNdHBROEdNTzV1WEdoZUpkUTdkWWM0Z3k3a3oxcS1TdXQ5WHpQc0w3Tm9WRlFfWEZJTmQxSll6dmp0cVUwY0t0UldrNVMtSUhEYmtjRnVjcy1qcHFGUXVsWjYwemdLM1V6clVvZ2xuajg9
Training 4096 context length llama3 8b with unsloth qlora and a batch size of two is doable with about 14gb of VRAM.,r/machinelearning,Z0FBQUFBQm0yeGJ5QmRNai03cHlGVU5DQUNyLU12bEdiVEJhODRWZmVhYmFtVlJaV0NBTkRGNm1JSGlHRXFFemtSTWRteWlmMFRWMTdmZnB3cVd4dXg1UkZnWnhSN2ZtOUE9PQ==
"i wouldn't consider embedding models ""generative"".

also if you're looking to run CLIP on sagemaker (most common and cheapest way to do inference) here's a tutorial:

https://learn.mixpeek.com/clip-on-sagemaker/",r/machinelearning,Z0FBQUFBQm0yeGJ5T2w0ek5oYU1ZRTZQUlpVaWtOYmpOcUc2RWlhblIweGhrN19Gb0ZFMW1sUE9TQXpRNm9sWXNsQlA3bUdjZmZSVzJucHFFUWhSVzFMOXNMZy05dHFZcHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ZDlQNHJCQzg1M0I5NkUwN21qV0Z1QmxCamt5b1oxT0FIdjRVU2ljVjJBLWdqc00yNDNPNEoxWkxRRzRjcWpoQllHeTRYUlJRM0cwSlhMZHRfVXEwR0E9PQ==
I’ve got 5/3/3/2. I find it quiet confusing when the reviewers seems to have a general opinion and gives 3 (borderline reject),r/machinelearning,Z0FBQUFBQm0yeGJ5QlJvb2lxVjV1N040Y195b1Q3eXRFR2Y5UklKa2o2aFpTTTFGd25UVlZEc1N3T3ZkTmd2MTRsaC1KTXJXcmZ5ODI2QXcxSTFaTENkYzNIeGJDVmlLN0s3cS1ZT3RVMUE2T19ydXQ4WlZkbWs9
"Hi, thanks for sharing this information! BTW, do you know where is the GitHub implementation of this knot theory with KAN?",r/machinelearning,Z0FBQUFBQm0yeGJ5ZzQzUkRfZ1UwTV8wY2N0ZUdRaGxWeHNpRG1LRm5GT21haGhFX1NHdUxSVjQxZktrRHptM3RFYzFuMVRnMXc3SW5RS0VpZUVRZ1RabmR5TS0wSVZRTXc9PQ==
"But that still doesn't answer the multi-agent part of it - I would believe that these LLM agents in a multi-agent framework are connected and sending each other responses and using that in an actor-critic framework. I guess my question is whether such LLMs talking to each other is realistic in prod settings. I still do not see what practical use it has with them being connected in large scale ML. I mean you can still have several small specialist models and use them independently for tool use but that doesn't need multi-agent setup. Practically, I have hardly seen multi-agent ML frameworks used in industry to date and I am not so sure why would there be a sudden need with ""small"" LLMs, so to say.",r/machinelearning,Z0FBQUFBQm0yeGJ5dkVGdGxmakFSdXo2VVhCdTNiUEFSMnFENlZSZEhnVGlkUVhHLWVtYTB0QTJtNjk3MmE2R0R3blpVOExfakR0c3A5RHZNRWQyWHJVVUZiRjBpYUZ4MEVUa1BoOWdTTU1LNlBHSDQtcTdNbG89
"I just completed a masters using multimodal NNs for cancer detection from pathology images and RNA-Seq so i get it. But  ""LLMs"" are quickly gobbling up all modalities and applications. They aren't just about language: their deep abstract representations can representation - well anything.  Consider GPT4o for example. So if I were looking forward, I'd be hopping on the LLM/GPT/Transformer train. (I'm old, so it's all moot for me).",r/machinelearning,Z0FBQUFBQm0yeGJ5M2FnN3VMZlAyOW9EaU9iM3E3VG5jSS1DaUE1a3VJTjlWdUJFMWh3ZEQ3TUhvM3RyeG42SWNyWlBsUE5RNjZSR2ZhTGZtTVJJUEJkX3FhRWozU0R5T1E9PQ==
It's at 61% now.,r/machinelearning,Z0FBQUFBQm0yeGJ5T29PRmZzVDlZcXBieFAwLU82WjJOdUYtT3pnVzNNWktGZk9vWUdyb2RFZWJNeEZIdkhnTHhWWGxCaFdEMHdDY3E0M24wYXZZZEpZUU5aVnpLVkdLOEE9PQ==
Seems like it.,r/machinelearning,Z0FBQUFBQm0yeGJ5VDAybndGQUlCYWozWlJZa3VNb3dUUmszN0tRX1JXLUhXZVBpNmcybnNaUDQtV0lpZWhhWHh2c21CZkVEcUluMkJlSWVKcWhvSm1LbGRnckVaYm5OUGc9PQ==
"I think he was trying to help me tho. He read my code and try to find my mistake in his OP. I very appreciate it. Btw, can you tell me which was wrong or suggest me what to do to fix this, I has update the newest QMIX run in 100k eps. I feel tired tho :(. Please help me.",r/machinelearning,Z0FBQUFBQm0yeGJ5aDd1T0pvQTI4dWdIUDJMcUhOekJGN3hBSWdfemxmRENxaEEwcDN2Q01PbTlLdENMWGF4R3RVRW5rOER1Y3huOUhxeUJIaVY2cklybnNQQmFYdUdLX2x4c1lOeEtXQnR1TkVxb2JMSVlVMUE9
Are review assignments already sent out? I got invited to review and submitted my bids on papers but have not heard back yet. Does it mean I was not assigned any paper to review?,r/machinelearning,Z0FBQUFBQm0yeGJ5a0QyTjJkRkNPNWZJUEdFNlZ6a2dFMXpmMXpCY0l5QnlvM0VoSDd6YzdrSThqd2g1YXhlTkN6bnFaUkhEX0JsNURWbVdlcWx2dS11aG5OQkRCZnhNa1NibUNXSDlBcG5mUEJJU0YwTWJaWms9
Pretrained model for time series forecasting never make any sense to me.,r/machinelearning,Z0FBQUFBQm0yeGJ5NzZqRnQ0QzU2MFdvaDlCc09oM1doSjRybWl5d3NlODNWYmQwR0JZdU5hX210eUJHbnF5RFFIeEZldjlxZThjZjlPNUc4VDdkekVKN2daY3JQX3pCSkE9PQ==
"Thanks for your experience! I have noticed that volunteers should attend the training session in most conferences (at least in their call for volunteers), so in your case of volunteering, are the training sessions **in-person** (meaning need to get to venue some days before the conference begins) or can be finished **online**?",r/machinelearning,Z0FBQUFBQm0yeGJ5XzJjRkxxTDF4N19WUTVwLWtDZzd6RGkxWURvWlJkcm5CY093WVNTbFR5dENhdWZBRXBGVExacWxlaU14NnlfMkxlWUo4SGp1NDFmYXFjLXk5NWJCRGc9PQ==
"I am so confused. I thought we were talking about r/MLScaling. So why are you sharing links to r/MachineLearning ?

And what specific comment in there is at odds with the statement ""current LLMs are very poor reasoners.""

>LLMs cannot reliably perform arbitrarily long chains of reasoning, but (of course) can do some reasoning tasks...there is an architectural problem there to solve.

I could not find a single comment in that thread claiming that current LLMs are strong reasoners. What comment are you referring to?",r/machinelearning,Z0FBQUFBQm0yeGJ5Y2F2TkMwNWdPbnEtYU1Ba016ZDk3WkFtWjU0d1U0SF9ibzRnTEhrZzNWVnUtRFl1eTNjeDhISGtoczZBR1ZNcnczM3pZdnBndWVRV1p5c2FqUmtRQXN2MHhJZDY2bEd4SW82OFN0THdBVU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5YlJUeGdIeWE4eEN6SF9tSXc3bVdMLS12Qy1YcDdncHZjdG9feWpNMHJCblk1cFlMSDQ5SUlGUUNReWEzS3FCLU5QSTIySzNFQUtBRzJ2NGNOY3hRWVE9PQ==
Multi-agent reinforcement learning is extremely unstable. There is no one size fits all solution here and some environments simply cannot be learned with current techniques.,r/machinelearning,Z0FBQUFBQm0yeGJ5TG8yT3FhbDFUYXA4a1dNMmxQTk5jYU5TamJiYk1fMGJRV0RhNVJxNHJSYlZSTmN5cTVxbmJKY1pWTHRSTlh0WVdjQlJyeDg5aGxENF9RUnI3ZlVmcm91NUs2cVozbDc1bXd2dGhxX3lqUFk9
So there is nothing i can do except trying to make it learn more and repeat if it wasnt good :( ?,r/machinelearning,Z0FBQUFBQm0yeGJ5c3gxLWlZMi1MNmxtTlBpM0pTOUkyUGZGUm4yTVAwSThOZnBma3BPeHpKRFRITTlaX3drZzJ3RVZlMWd3aHhZTjc0bDR0Tko0dGI4bXpfcDhPem95ZjZuLWFhanVsQ2R3UDZtR3ZIQ0JlVkE9
"> I thought we were talking about r/MLScaling.

r/MLScaling is a bigger cheerleader for LLMs than r/ML. I would figure anyone here would be familiar with that context

> LLMs cannot reliably perform arbitrarily long chains of reasoning,

On what basis are you attributing the above to support ""current LLMs are very poor reasoners."" when the below applies?

>Humans cannot reliably perform arbitrarily long chains of reasoning,
 
Are you saying humans are very poor reasoners?",r/machinelearning,Z0FBQUFBQm0yeGJ5cGEtRHBzVndjUFRWUU5ybFRmbHAzbFQ3LWpydnJtdGEtR1lIN0hES01xTWNVaHlGN0Z1VnFSMFNhcVQ2NThvVHpaTnQtNzBVbl8zMDUwSFIxWGRlRkE9PQ==
"I would not say I am an expert in this domain according to my observation next token prediction, while highly successful in NLP tasks, may not directly apply well to recommender systems due to several key differences:  
  
1. Different domains: NLP deals with sequential language data, while recommender systems focus on user-item interactions, which have different characteristics and semantics.  
2. Sparse data: It often faces data sparsity, which makes it challenging to apply next-token prediction techniques that depend on dense sequences.  
3. User and item representation: It aims to learn latent representations of users and items to capture their preferences and characteristics. This is different from learning sequential dependencies in language.  
4. Temporal dynamics: It needs to consider the temporal aspects of user preferences and item popularity, which the next token prediction does not explicitly model.  
5. Inefficient auto-regressive recommendations: Generating recommendations via auto-regression with next-token prediction can be computationally inefficient compared to methods that recommend multiple items simultaneously.  
  
However, the paper provided by  ""like\\_a\\_tensor""  introduces a novel method called CLLM4Rec that tightly integrates the strengths of the ID-based paradigm and LLM-based paradigm for recommender systems. It extends the vocabulary of pre-trained LLMs with user/item ID tokens and proposes techniques like soft+hard prompting and mutual regularization to effectively learn user/item representations aligned with the LLM's knowledge. CLLM4Rec also introduces a recommendation-oriented finetuning strategy to efficiently generate multiple recommendations without relying on auto-regression.",r/machinelearning,Z0FBQUFBQm0yeGJ5b3YzdkhNN0lmSmVGdTd2clVfdzlwR1FIZWtGQXBaZkNFUkNwT1VOM0RMSEYtcm9vSm11S2dvdVhKWWU4UmhWTGNaQWstMEhzRXVTeUpyVDVrSXpMMGc9PQ==
I'm doubtful anyone ever said that.,r/machinelearning,Z0FBQUFBQm0yeGJ5LXNrZTBJQkpJUkx4RURKeHNfT09Pek5MR1ZYZ2E5VmJneENyUlpvdTZjdFRHWWRDYy1PcW1aTVAzdXZIU3YxcEpuOG9hejBZSzU0N3FUU3ZNTVN3em9KXzZGNGpLS01PVWVWMENEOWJSSDg9
"Honest advice? Get a simple MacBook Air (great battery life) with 16GB RAM and 512GB SSD instead. The GPUs on laptops suffer from poor cooling and also affect the battery life while being used; would NOT recommend spending $$$ on laptops with better GPUs

If you're only a student, more than likely the amount of time you'll use the laptop for things like report writing, browsing, research, music etc. will be MUCH higher than running a model. Get a comfortable laptop that has a good keyboard/keypad and high battery life as primary perks. I am personally comfortable with my MacBook, but a Lenovo ThinkPad is an egregiously good + comfortable choice too.

Sign up and get yourself a free GCP account/AI studio key for Gemini (Google has decent freebies, use them).

Alternatively, if you're an absolute geek, highly recommend building your own computer instead. Get whatever 16GB VRAM GPU you can as a first measure, and if you absolutely need to (and can afford it), look at upgrades.

Personal note: colab and kaggle offer GPU kernels with 16 GB VRAM free of cost for a limited time. If you need it, use the free stuff first. A phi3-mini and a LLaMa3-8B (@half precision) can be run on it without issues. It should be more than enough. If you need something better, use API access based LLMs

Source : Sr ML Engineer",r/machinelearning,Z0FBQUFBQm0yeGJ5WTFPRzVnTDRyMFpTX1MwdDlRUG8wOFotYTFuVWN2b2pEVndoZllLNkFrNi1VM2lHa2V2cXUyRWUzNkg5QXRzcW1ZUXRGNjJMOVYzT2IxUk01bHpxcEE9PQ==
"From what I can tell, mine was able to be done online. This was pre-COVID, so it is likely that things have changed. And, of course, it is conference dependent.",r/machinelearning,Z0FBQUFBQm0yeGJ5MTBXbFVrYi1aM2tKclRlcE9IU1VEVnZVNHpOMFVtcmlHalFJWjktLUxVWnM2RzIydHc4NFR2QlBweEsxZEd6VjdlQlV1czNtVUpRQXZuMTlKOGxwQTJJWExxblZZMGhhVExOWEhmbF9ZYk09
"Real talk, if you are not gaming:

- Invest in a Colab Pro subscription for $10 and use 40GB of A100 or 15GB of T4 or whatever.

- Get used to learning how to use other cloud compute services for more versatility and potentially better prices, it will be a valuable skill you will probably need to learn later on anyway

To me it is currently completely silly to invest in local GPU resources for ML as no matter what you buy, it will be too restricted and inflexible and you probably don't get better electric rates than the cloud cos.",r/machinelearning,Z0FBQUFBQm0yeGJ5SzdubGNzc0lKMG8ySTNycjZJR3d6QmFJZVdWeFBueWROa3VQd3B4UlBvcXBCU0hmTHhRVklYRFpxeXN6NnRhQk9CSDJ6ZTA2N3pueHdMdFFCMXZXdWc9PQ==
"> is a bigger cheerleader for LLMs than . I would figure anyone here would be familiar with that context

I am familiar with that context. Which is why I'm assuming you're going to share links to that subreddit, because its the one we are discussing.

>

>On what basis are you attributing the above to support ""current LLMs are very poor reasoners."" when the below applies?

You have chopped off important context: **there is an architectural problem there to solve.**

In other words, **Inability to reliably reason is a problem to solve in LLMs.**

Regardless, let's not swap the burden of proof. I never said that r/MLScaling is full of people who will constantly criticize LLMs.

You were the one who claimed that in r/MLScaling, people would argue against the idea that existing LLMs are very poor reasoners. That's the claim to be proven.

You've linked to a comment thread in a different subreddit where nobody seems to argue against that idea.

Please quote the evidence that you feel that you are presenting that it is controversial in r/MLScaling that today's LLMs are poor reasoners.",r/machinelearning,Z0FBQUFBQm0yeGJ5TmRsUEdocjhRSEFWazZWQUticzBtYjM4RTduNlFNeEVpWEZJQ1M3Q3JnQmlfM252cWxzNnAzRzdoSWVvNzdFZmtmbWFXSDIwVjZFaTJXWVlEWlpNZW5EYkQ3N24xSUNoeUVTeFhhaTNqM0U9
"It’s worth reading the research paper if you haven’t.

I understand what you mean…

At the same time the way the researchers frame it…

LLM’s are able to predict the next ‘letter’ token, based on patterns and contextual associations in their training data.

In this instance the llm is aiming to predict the next ‘value’ in a point in time as a token based on patterns and similar associations in their training data.

Effectively when you give it past data as basis to forecast, it is kind of running the pattern it identifies against thousands and thousands of examples it has seen before ‘kind of’, to predict the next value token.

It definitely has its limits, and won’t handle highly volatile trend lines well, but for a decent chunk of forecasting scenarios, it is kind of using an approach many people use already, but just on a very manual basis. ",r/machinelearning,Z0FBQUFBQm0yeGJ5cXlXODhmNExYejd5WkcwQ1M3UkRpNlFkM0d2TUdkdlJBWnZFcFdUSFJwUW5vXzd4QldnYmYteFFsYWlGY1pBVlVVajgzOUFMZ3F5YjZxR3B3T0JaVWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5Ujd5RzBtT2dVbkgtVG5SUDNoeXV2RE1OanM0SUI4QVk0OUxfWXBRb2NBYmtTc0lQUXZQNjROakI1TXJ1a2E4ZGVnZV9YdjNPQTN6NUNvNDI1cHN6VlE9PQ==
"I was like you, the only paper I got accepted prior to grad school was at TMLR. It was actually received positively by my now-advisor. I think getting anything accepted at a reputable venue prior to grad school is a big plus.

TMLR really isn't that strange though. It's still reputable.",r/machinelearning,Z0FBQUFBQm0yeGJ5Q0xXY3Y5b0d5dm9mTGp0SS1FWHBwSzdsbEFGcGt6UDZWTWhjak9ZTlpQb1YxYVdibDlGS3RTVWZvVk9XcFFCYnUzQ1E1Z01FaXBMUHdFZTR1aFBqV2c9PQ==
"My problem with pre-trainng for time series forecasting it is that time series forecasting is a completely different task for each dataset, unlike NLP/vision tasks that share similar knowledge and can be transferred across different tasks or domains. This makes pretraining intuitively sensible for NLP/vision tasks. In the rare case where time series forecasting tasks share similar characteristics, for example, through visual inspection (e.g., they have similar volatility levels), like two datasets each representing the historical price of a stock, the data may appear similar in many ways. However, can the patterns or knowledge learned from one be applied to another without introducing bias? I think the answer is obvious.  
Another frustrating aspect of time series forecasting papers is that they often use meaningless metrics or compare to baselines in an unfair manner. In reality, the performance improvement is insignificant or just does not exist.  
Just my two cents on this topic.",r/machinelearning,Z0FBQUFBQm0yeGJ5MWhhT09lLVFzOTFZdVpObEpZN0VWZl9RWWRPUllyTjR4WThkNUllVFplZnZRTURQLXVQaVdiNzVWQmotMUFOUUlKbG4wNFN3UWV4NEZBaDk3OEJQMHc9PQ==
sure :),r/machinelearning,Z0FBQUFBQm0yeGJ5d1pRSXZBb1YwbjhmMUlVWVlfM1ctQVo3dkstMGxYeWwtcmNGZWJGRklfQ1UyTV8tbi11VUdFb1Raa2pSaF9kMmNaSm5SMTFvblRUU3NEOFdvajN0MEJGQ2FTLXdaSVdCazlKOEVlc0NZbjQ9
"Personally, I value TMLR very high. It's relatively new, sure, but since it focuses on correctness, rather than novelty. There are thousands of papers each year on top conferences, and we can all be 100% sure they contain a lot of mistakes just due to sheer volume and focus on novelty. Correctness, fair evaluation, solid benchmarking etc. are much more important in my eyes. Especially since there are more and more papers debunking apparent progress in many areas of ML, and showing that old models are still better, if evaluated correctly.",r/machinelearning,Z0FBQUFBQm0yeGJ5c2dSODkwc3A4LTZjcVFpckwybWx0bnkwRldoRHprb1lQbHFqNm5uWXFCX0VrM3dHam5ad09wcGhNLWhlRDVFbTRrZFFPbnE1ak5KV1dSakhHQlVSWFE9PQ==
"Honestly I don't see the point either. I think the big added value in these type of settings is the function calling capabilities. but I think that one LLM that can hold all the project and prerequisite in the context window is going to give better results than a bunch of agents with a partial view of the problem and a narrow communication channel.

The multi agents paradigm may make sense when you can't fit all the information in the context window: then separating missions by providing custom summaries make sense.",r/machinelearning,Z0FBQUFBQm0yeGJ5cUZ5MVhLSTdndmpadzRWdWs0a1RCNTBQQUdmaXNveG9SWEtqMDJGc3JoNVlQeUVvZVcwY3VOR1N2ekxEUFFxRHdGbnMzQ3JUT3RKbHpaS3NGRVV3Znc9PQ==
"It’s maybe not flashy but it’s well respected. If someone is judging your ability to do sound science they’ll likely rate it as highly as a top-tier conference paper. For 99% of opportunities that’s what you care about. Some full-time research jobs may care more about your ability to come up with impactful research ideas, but that’s what you go to grad school to learn and practice.",r/machinelearning,Z0FBQUFBQm0yeGJ5eXlMa2xkZFVMa0FLbDJ6V0gzcEdvdmN4VG9Mek1QTTUxeGlBendZelhWQ1pvbWkzV1lPc1RRLTV4bzhsLVpXdzNYaTNGMFhwdmE1UGpuQjh4cHJLdWc9PQ==
I agree that the function calling and orchestration to specialized models will stay for a while regardless of context window expansion in LLMs until the hallucination problem is reduced to negligible and there is no need for external verifiers in mission-critical settings. What I was alluding to is that a chain of agents being orchestrated is separate from a multi-agent connected agentic system. The former has use while the latter seems only academic research. The only place where I would see smaller agentic specific LLMs being usable is if in future there is a chance where localized private small LMs can be placed on a person's device (the inference costs have to go down significantly for that) that has my entire life's context embedded into it and that gets updated every now and then.,r/machinelearning,Z0FBQUFBQm0yeGJ5dFhSZUFLMEhEcTFPNDhWOE9mY2VsRkhVY0dScmJwTmFNa1JQd3lsNk1rWk0xYnJzcVhxMTlnVzFOUW1wbmdWdGNJRUdaYW1IUGxMQ0VhNXZtaGNUQ1QwcjA5NWxVYTZZVzZKNEIyREctbGM9
"
There are parallelizable tasks that can benefit from it.

I could also see search agents following search threads in parallel and reporting results as they come.",r/machinelearning,Z0FBQUFBQm0yeGJ5V0NwNEl5NENVbnV1S2xmQ1hMemRrOFhEZklBSnJMR0E2NHg3YjgyVVp0WnJla1ZoWUhvRWdCQmFXTGRwNG93UXVyVU9EWE9laW9PQ254OWR1eDQzR0E9PQ==
"Even a 24GB 4090 is lacking the VRAM for most models. Get the Mac for the unified memory if you're not gaming, or don't buy anything and use Colab. It's free.",r/machinelearning,Z0FBQUFBQm0yeGJ5SGg3R1MwT0xIbkc5bWxBWGtkUExHd0N0d09aWGpTTUMxZ0lUaHBFSTVlZVNnREFXel9qUVFNeE1Edjl2Qm5EQ3VYR0poelBvcndKbEE3MEppX2dfZnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ZXM5VjdpMTVLTmxLQjVieVI0Rkd2UDloWjRLX05qN1h1aWhuUUQxRllsc2JlRE9KOXlxcnp1VTJKN0pFUDBGYjhKSnJVOE1VZVYtbkZrRTE5NjlNRFE9PQ==
Me too. I have not gotten paper assignments. Perhaps it will be released tomorrow.,r/machinelearning,Z0FBQUFBQm0yeGJ5UVNGY0tRR3ZHYW5hOXlRU3ZiS3V4d0VhZzZYSWNSZGFQWDFrWnhJV3AtbXRFdkVWNlN1Y05wRnhfQXNCdDIwaC1pUF9paFVxVWVzX1JEZ1lhUkV1a0tkV0hpM0pQWmlCbHE4N1F0ZGViN0U9
"Thanks for sharing, does it have any project management features built in?",r/machinelearning,Z0FBQUFBQm0yeGJ5TC1ZN3A3YXA2UnBteHZXcmd3VUQwVVpLd01OM2Z5SExMeG51Y1pFUFpSMXFZa1pRREZVRFA4VTR4UG1RR016blBKV3pFRnJxWEVveWJfbXJjSjZySlE9PQ==
"Interesting!  
Is there a certain point where you realise that a problem needs a novel approach?

Also, how would you describe a typical novel solution you have come up with and what is the process behind it? Do you really come up with new equations? Is it a lot of trial and error?

Thanks in advance!",r/machinelearning,Z0FBQUFBQm0yeGJ5MWpTRTY5Y3JkNUxDUmJERUdrMzVUQ2VmUVUzdEE2XzdOdWd2b0FjcFc0UW5xRkFCMjJjWW9nYURiU1E1UU55NzNZbGVqM19qRzVOQlFFWThnOW4zYmc9PQ==
"We’ve used CVAT and self hosted it, not recommended, the UX is so not intuitive and very difficult to use in terms of showing general info for the labellers in the areas of project management",r/machinelearning,Z0FBQUFBQm0yeGJ5cTBpbHh1LWVOU2F6TC1TTE9wMUZfcHdDRlFSbnUxdzQ5Z1BOOHBlbHVGQmw2WmFuUU40cDlFQzJ4WmpXTjFIb1R6QjAzY3ZvM0VfRFVSSkRCTzhYcnc9PQ==
Good rebuttal will solve the problem!,r/machinelearning,Z0FBQUFBQm0yeGJ5cEc2blVNU1ZndkJEV2pwMFJvZlVVR0FuUXRrY2ZoX2U0STFiWnplVTRheVhHa3NZeWRfX3dmcHdPbVA1U1JIOUw0M0NXb1AwbjJaS0dLY3VwV3hRWkxIV1BrYjYycXZPSFZaaFZ6aVg0cXc9
Speech is done bro. Why beat a dead horse,r/machinelearning,Z0FBQUFBQm0yeGJ5U1F4UWJZVER6bldNLXdBZUVDYU5FVmdpX1FtVXN6RG55MWw4WXRBWXc1WXZSaEx5YTh1S0Iwa0tYdHlyeUEwYkc4QmhGd05kY21VdDFWQ3ZSdEp0Vkc1ZmhnY0xiMldiNTRVR0JpZlU5X3M9
"As for benchmarks affecting the quality of LLMs, it's a general problem, as I can judge. It got some attention at the last ICML, for instance. 
One of the solutions is yet another benchmark, LOL. But it has some peculiarities. It's [SEAL](https://scale.com/leaderboard). The point is you can only score once on it, all further versions of the model won't count. It's partly proprietary though.",r/machinelearning,Z0FBQUFBQm0yeGJ5U2NxcGFjX0k0N1hBbnRwWHhIaXZMWGpxWnMxNDVvcTVtQjhrYTlvdndsS1BRRGJlNmczd0tFa290TDVOcGt4Y1hyWHNMQzJuZGdtUU0tUmJYMzE1RGc9PQ==
TMLR reviews for my papers were very fair and helpful and the reviewers were all knowledgeable. All of my advisors (all top-tier world-class scientists) rate TMLR very highly.,r/machinelearning,Z0FBQUFBQm0yeGJ5NEM0Wll1aE5pQUJSS1V6b19JNU1OaDZKV1ppNy0wSElLT3djUm1KcnN0MUZfUklWdW44OGJiQjlfd2NsVVd4c3oweEh6QU1aVGstc2wwMHBXdDhSSFE9PQ==
"Speech in my opinion is not dead. Humans use speech to communicate more than text.

The field is hard and doesn't have the surge in popularity NLP and CV have/had. But it is probably a matter of time until some big paper will change that like BERT/Transformer did for NLP. 

The main research direction I think speech needs to take is either a textless route (don't use text in your pipeline, which will be the main component in a text free robot or ai assistant) the other direction is to go further into the multi-modal option of text+audio (and maybe images/video).",r/machinelearning,Z0FBQUFBQm0yeGJ5NEhsSnpCX2lRYU9xNWc2ZFFoSWZXRUN2YnZmTzRsSzBUbzlSVGZsNEdlWVZRSnlRYVJZNGMwUjFnMHBBSVNLSlJMS1hCUllrbHdPdzVJbnVKWFpWVmwxdVBkS2tsdjZ6ZG50Rm5RdGlJRms9
Agents are pretty cool,r/machinelearning,Z0FBQUFBQm0yeGJ5aEswdUptQzhNMUNJeFdBZ0d1eFhxNzFTaEdjVlFxc2RITmZZSGZya0l0akVtSExpSVpWWm10T1JMM2VBX3VZUGVUQ2tXUy1yY3BsUDF2emlzOVhjOWJXMFJiUkVKVmhDRVdydjZzUzI0T0k9
This. If you are looking for a game laptop anyway buy 3090 or 4090 depending on your budget.,r/machinelearning,Z0FBQUFBQm0yeGJ5dUoxYW8xQk5sX0w0N0JRNHlWWGROTGN6cTBrZlBMazVfZ196Tm9abE4wSVBFaFJwb0hITkVPeGF2UmFubFpmOENHSnVpWGxGaEMwZlF4SHJaRnFNWXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5Q1A5UU5rRkJxNDlIaUtSVjhjc2pKdEJ4eU5Bb0pPTlptV05Zd2VMYlVPZjgtU0l2anBfMmNTWFZOV2RtcUxpWXc4RWVvdnNPb0VoMjRkUzRlWU5RdUE9PQ==
Billions must call chatgpt API.,r/machinelearning,Z0FBQUFBQm0yeGJ5QVpUejhFX1FzZjQyNVhXcEtYdVdieGtSRncxVHI1TElUTjYySFF2VHpOc0lWM0NlbzQ5QVg5Q25LcG9yX0JCMXFNSFJXdmxYWDRFYXJnSE51ZmFVWFE9PQ==
"I believe truly multimodal large language models will spark interest and research in speech and audio in general. Things like tone, accent, cadence and pitch will be important as they will influence how the model responds. Similarly, background audio will enhance the model understanding of the user intent.",r/machinelearning,Z0FBQUFBQm0yeGJ5UTJJeGU2YkhzNjFtZXg1S005VjRtem45VkhxcUVVeTB4UkUyMi1NZDJWN0NXUXBGOE1EVFVHRE54MlNRTzZNMkJhcmlsUG41WGVWTVlPekxBR2hHQUE9PQ==
"You know openai already did something like this with gpt-4o? They're using one model for everything, no tts when talking to the model",r/machinelearning,Z0FBQUFBQm0yeGJ5dEVrUDkwZmI1Wjgwa1IxYWg5Q3RLcmFxYUhLUmIydTRSMXQ1dW1lNUZGTXZQQ2pIckZSY2VrWkVKTlZQWFhNWDZ0Z0ZmRnBBX29YU1RQcHZFU29reE01OVdXSFppUmdKV2tNdGtwcnJFT0k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5a1RfODBEeGNiVHBsYXgyNWxSdTBNUjlfRXh3S2g0Ul80ckkxLTdkVnE3UUFTV2tPUEc5LUJoeVJuTzllTlZTZ194NnpvR3lEbzFrRmVjQ1doTExwWFE9PQ==
Is a textless route still necessary if the pipeline latency could be reduced/optimized to an acceptable level?,r/machinelearning,Z0FBQUFBQm0yeGJ5VDJ5YkN6MGc0V1lRYTFoYUNwODFiZTRaQ2JjQnUza01HYUtKRUVKNFZUNkZmekZOMGY0aHY2VTVpa3lQZURVcmNBUFpoaVlabDZGVUR4T1M1T3ZtQ1E9PQ==
"I think the selection of parameters happens on the wandb servers, right? So that shouldn't really matter? Although I must admit, I haven't used Bayesian that way yet.",r/machinelearning,Z0FBQUFBQm0yeGJ5dU9wckJhRFNNR0lvT2JQMU80R2dlRFBCcUVQR0JmY0VYcTI2SEMxUUtTSDA5TTJyM01lSGg5ZUhKbkRsYzVxbWlyM0lRYjNRcjlETFhtY04xWmNsRXc9PQ==
"I feel like this post shows how toxic the culture of competition around ML is, like TMLR is a perfectly fine venue, and it should be a nice plus to have publications somewhere like that to get into grad school, not like a concern you don't have NeurIPS. Alas, who knows what the solution to this is.",r/machinelearning,Z0FBQUFBQm0yeGJ5Nm1lOVZmakFGNWc5cUJ4TE9SemxTLVFxbkhFNW5ySjh6OUt2TlpaaklJRlZBWE5xWEdpZGVRUG1vX1RsdWtjUHRlbjhfSzUtdmRtc0FyQ3hqdGNXdVE9PQ==
"indeed, an AI girlfriend/boyfriend product can't be a good one if it can't detect the subtle emotions/hints in the voice and respond properly.",r/machinelearning,Z0FBQUFBQm0yeGJ5LU1waDN4RExxa2F4NncxdGRHRnk0d3pPbXNkV1B3bU16bkFWZTBqUXF2VDJzbnhpQlR3cWdtdVo0eEUyOHoya1F2T3prRUpjbDE5ZTdsbEFCejZ1TlE9PQ==
"I will just say my personal experience and opinion. If you did improve on a problem, then you should be proud of your work for sure. It's your first step. Having said that, I had discussions about TMLR with other reputable/competitive profs and I can't tell with certainty that TMLR is reputable, especially on Theory. Most profs (that I know) simply think it as a venue where they will send their work if they fail at top conferences or journals. Even if they don't tell you this, because they want to be polite, their actions tell a different story. They always prioritize the most reputable places.

In my opinion, what really matters is your performance at previous undergraduate and graduate studies and the university/ties that you are coming from. It all needs to indicate a risk-free hard-working person on paper. The TMLR is nice to have, but without consistency in grade performance it won't help much in top schools. For sure it indicates that you are person who is willing to do independent work, but this alone is not enough. That's because willingness to do independent work without solid background means that you will need a lot of training to publish at top venues. Then it really depends on the prof if they are willing to invest in this or not.",r/machinelearning,Z0FBQUFBQm0yeGJ5MnphMU9DVXBWdkNSVzc0WlMwT0Rnd3dDMk9WNzlPODBZZUxIQ2NxVnBfRFVYVTNBMXpHT0dIWURGTEx3ZURlNU90QTl6ZHJxRmZwWFFJV0lJcjNmUW40Qm1IY19lY1NQeC1FUjZZeDU2N1U9
"Bro,could you share more information about your project? I'm looking for my final year project",r/machinelearning,Z0FBQUFBQm0yeGJ5MWdFQXZkRElsWVRvMDAwcW11WFY2bFBRaXNoQWoteFByVFJCNzF1azJlcVNTMXh2bHMwOHhIZHFHQUFmM1hTaXZGczRnT0JIWDA2YjBjR0dBN2U5S0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5Vmg0WDhvRTlWNFNOYjMza0FnOXJObTdVRlpTNFI5OUpxcU5ObHVSVjl0Y0ZaQmpFMHllWm5uZ2dhbDBPQVhmUUtoODgzMUZ4U3M4QXZLWGd6REpNUWc9PQ==
"If the current trend continues we won't see stand alone audio/text/image/other models in the future, they'll all eventually be multimodal. These models will require more resources to create and run than models that only do one thing, but the advance of hardware and software efficiency will make stand alone models obsolete even though they use less resources.

This has happened with other technologies.

Network hubs and switches used to live together on the network, but the march of technology eventually brought the cost of switches so low that hubs became obsolete even though a hub would be cheaper than a switch if made today.

Operating systems typically use 2D interfaces, yet all modern operating systems use the GPU to render the display. This was not the case in the early 2000's because GPUs were still fairly expensive, and the low cost integrated GPUs were absolutely terrible. Rendering on the CPU had it's own problems of being slow and having a low limit for UI elements if I recall correctly. Today every computer has a GPU, and even the low powered GPUs are more than enough to run the interface for an OS. It would certainly be cheaper not to need a GPU, but the benefits of a GPU and the low cost mean nobody is going to do that.

We're already seeing this happen with the integration of NPUs and equivalents into various platforms. Eventually every computer will have hardware acceleration for AI applications, and a big pool of memory to run them (no thanks to Nvidia). The benefits of a multimodal model are so vast that it won't make any sense to run something stand alone when both can be run locally. A lot of stuff you might want to do with speech recognition will just be part of the model already. Not made directly, but a consequence of training on tons of data.",r/machinelearning,Z0FBQUFBQm0yeGJ5T2duUUxTakxaQnNCZElJMjMyQlR3eG1qMGlScTcwakZmcWt6Wl9YRWU0Qk5fa3REZzZsWFFjQ085cXpod2RuaF9paXFWNDlCY3pjVHdGellrbkNobGc9PQ==
"Didn't really have the time to take a look at all the code.  
But DQNs itself have a bunch of issues and a ton of enhancements that can be applied.  
Rainbow is a method that combines a bunch of enhancements for DQNs to improve the estimation bias, sample-efficiency, exploration and uncertainty of return. Maybe taking a look at that paper will help.:)",r/machinelearning,Z0FBQUFBQm0yeGJ5dy1GZS1XVE4yLTdPRGFIU1RmUXV5Q3dnM3NESHRKWFFWUVlzTWlvUDlRYUJYZVgzY0RhT3lUM2duMDVfLWZaUUtXWm8xY3F1aXpOYkNwbV9SUmFMTlE9PQ==
">:)

:)",r/machinelearning,Z0FBQUFBQm0yeGJ5Qjh3NHlVVEwya1dKbGxEQW9EU3lzZnBYU08wZFdFRW1nWkZpLTdaWjFZTUYzU2liYzR0dDZjVlNDWHhFVTNWdExydlhiQVItTk5JbC02SzNvNnloVmc9PQ==
"My go-to resources, introductory level:

- [https://kuleshov-group.github.io/aml-website/](https://kuleshov-group.github.io/aml-website/) - general ML

- [https://www.nlpdemystified.org/](https://www.nlpdemystified.org/) - NLP

- LazyProgrammer and Soledad Galli courses on Udemy

- [https://udlbook.github.io/udlbook/](https://udlbook.github.io/udlbook/) - neural networks",r/machinelearning,Z0FBQUFBQm0yeGJ5bFZvVDdhX1hpcEEtWXBQM2RfTDJaVWVYOU5sQ2hkejNBcXpfbDJoMGFQS21LWXZwSl9vTHpaU05GeTVEWTd3aGMwNHZZUWdDZ1hyTnZ3MWhheWx4TEE9PQ==
"Imagine if you, as a human, could only communicate with the world through text. Imagine the nuance you would miss!

OpenAI has indicated that in their belief, textless is superior:

>Prior to GPT-4o, you could use [~Voice Mode~](https://openai.com/index/chatgpt-can-now-see-hear-and-speak) to talk to ChatGPT with latencies of 2.8 seconds (GPT-3.5) and 5.4 seconds (GPT-4) on average. To achieve this, Voice Mode is a pipeline of three separate models: one simple model transcribes audio to text, GPT-3.5 or GPT-4 takes in text and outputs text, and a third simple model converts that text back to **audio. This process means that the main source of intelligence, GPT-4, loses a lot of information—it can’t directly observe tone, multiple speakers, or background noises, and it can’t output laughter, singing, or express emotion.**",r/machinelearning,Z0FBQUFBQm0yeGJ5cnE4MGx6QkdUdEVDbTRTN042UG1jX3pUUHhwNW1FRGhwb3RIT0tCb0dlS0JTRi1EdHRQR3JJdXJ2cC1lRXdwS0luczQwVGpYQVdzbHRKRmFDNmJESmtOM2IzZUVSVDNGdFZjOVkxblhOaUE9
"RAG is semantic search, search and retrieval if you want. RAG is used for augmenting prompts. You could say it's a part of prompt engineering or it's in service of prompt engineering. I would prefer to distinguish the two but you could make a case.",r/machinelearning,Z0FBQUFBQm0yeGJ5emY5Wk5oSFh5VV9HU0J2bGV2MmYxekhGLXBLWE16UzVQVXp3LWx2Tnc4RDFRQzFyT2VVemp1QnpuX1pqa3dib0pZakdySnQ2OWpxMWdrd3pza1RGQkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5OEJjdHJwQUVYX2ZicUFGclpmc0lBQXFkektZeW02N1A3SUJGT0diQTdwdXpZWDdJQWNsSzI5THlhbFFoSF9FOHNhbTZmU0gzN0NWbkhzOC1GWlVJZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ5ODgzNVdkeV9VMzNXZ1FDWnFURmtxSERqMUN4UWZuOFp4RjE5QjJXYVpfSHVaU2pidXkwbWxUT2ZPQXE5Snk3c3lEclZvaUVVZ09LWVozUlhjU2Mzcnc9PQ==
Also diagnosing speech issues like impediments or second languages is still wide open. Also pragmatics. Not as profitable though.,r/machinelearning,Z0FBQUFBQm0yeGJ5YVV4Vmdkck5oS0RINXBFdmR0eDE0ZGd1b0FVcE9lWWtxMUdxY1B5aS04Q21lMFBCdV9TM05md0Q5dGp3TFNuQS1hR3JnbkE5bF9QWm15dzJmWWZ4SEE9PQ==
thank you very much,r/machinelearning,Z0FBQUFBQm0yeGJ5cGFwX0ZacW03RTlEdmE4enBscDA0Y3IxMlBvN09mWEVSSzNqOE1sRTE4czJxRDdHMjh4NU5zTktVcC0xTnlQRnYza3hyMVhVNXJzWnFOV2FNLTJRZEE9PQ==
So we are using Multi Agent in our Platform so they commubicate to each other on more comolex tasks,r/machinelearning,Z0FBQUFBQm0yeGJ6c3VuVExaMEgzQlQzZEJQVURlNHBtOG5XTmxBM3ZqcDM0dlF1SktaZXpoLWhCU0FnQmdOc0VoZU1LUENKNHJVU19fQXF5T1daYTl2NzU0bldrNXAzbVJkTHBsMWoyVlJZNXlyNDFQNS1wbGs9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6MHdqQkVEOUpzTWpsa1U4WDdsTV9ZX1ZGWW1pVVFTOUV3X0RmV0F6U2M4QUdiMWVMYVg1NUV3MUt2elNtanRIMWFtTE1EZjVDUWFvRXA4dkRDaEEyRUE9PQ==
Yes we do! [https://huggingface.co/CAMB-AI/MARS5-TTS](https://huggingface.co/CAMB-AI/MARS5-TTS),r/machinelearning,Z0FBQUFBQm0yeGJ6dTdSSG5BU0FjVzZtZmxhZ1M5c3czUHRWdzZXV3JNSnY4UDZnd0g2RTFWM3REMFJaNnNHN01pWVY4d0owWHJfcFVQWDV4ZkFlcWZKU1dnckpabFQtVkxyRFE3cWh5T0c0UXJBV0tkcy1lUHM9
You should check out our BOLI model that we're open sourcing very soon. I'll create a waitlist for those who'd like to do closed loop testing. Thank you! <3,r/machinelearning,Z0FBQUFBQm0yeGJ6anF1RVJrM29PbE9XQUpqc1ZjMGRvY2xkQTNPcTFOV2h4dEZOU2VydDhGQzlLbGFzSThlTzdzYUliNE9vcnNQaktWVEhKQUszYUFWbWE5azh4WmRTV19MRHk0V0dwT3FFNkNNSVBObjQzX2s9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ6NVNSMEYtVTVsb1QtQWY1WmUxMlZrSElad2ZTbWVyYmJmLXZEZGExNDBUQXNrNUNMeHNWVXFIRWNtQzY4RHdHTnRaWnlKXzBTaHZqeEZrVlByVW1tZjlWSm5pZHZ3eTZraENtamxINV9HVGc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGJ6dFlRNGh4OWFkVEhsSm83UTRiU0ZCbHprcG1aLUtiRWZBSnFDYjlkTVQwVW5yQkpDX0txYmZsOHJKVjB2Q1JsVzlEcThRcGljMGN3VE1WUzY3dzc1cVFsTFk3ZHJWZXNMN2l3aUloblpCUUE9
"My masters advisor spoke with an important person in OpenAi about Gpt-4o. And while he didn't get a full explanation beacuse it is top secret the person did imply that gpt-4o is not a full end to end textless model. I have no idea how True that is and how textless the model is. But that is my understanding (also I would be very surprised with the current state of the textless community if gpt-4o is truly textless and is not just a pipeline of multiple things. Most research shows we are fairly far off from textless models) 

Even if gpt-4o is truly a textless model, it is still closed. So it makes sense that the open source and research community continue perusing this path, even if openai did achieve that. 

The most likely possibility is that gpt-4o is a multi modal pipeline, with multiple models. Which makes both of my paths very viable.",r/machinelearning,Z0FBQUFBQm0yeGJ6cDdiU0RJM2gteWlHMVQ0ZGo2N3pOSk5NRXltVEUtNHduTl9BZ2xDN3BmOGIycW9wNEhObkpDSVR1OF95aVdMLUpaQU5LN1h2V21IV3M1N3llZ3hKUmFxN0VHcFpZR0MyNVdVdGdqakl3NkU9
"It's not fully text less.. it still communicates via text. It just also does audio....  


Do you not listen?


It's shares the same embedding space with audio, images, and text.


They literally have tons of write ups about it. What kind of half assed program are you in?",r/machinelearning,Z0FBQUFBQm0yeGJ6MkZNX0d4UDJWUVNKMU05N2FfX29GNFFQb2pkSEFaWTVUNUZXX2UwbnEwTkxseE1QVnEzdGdFbkV5al9oNFBUREpKZWxXcHkxeDYzdE9fRkVTV0NqNFpoVXVxdi1mdG1KWFBlWFNWOGVaTlU9
"Do you need theory to build SOTA? Probably not, a lot of time pure luck or better data is enought. However, most SOTA comes from people who do have a lot theoretical knowledge in the field. This probably comes because by understanding what you are doing make you less prone to repeating bad ideas, and more prone to having better hypothesis.

Then there is a difference between ¡SOTA! (e.g. transformers or diffusion models), and ""sota"" (e.g. random +0.03 accuracy, or having additional 100 quintillion petaflops). The first, which are the big jumps, come from really understanding core ideas and following a path of good hypothesis and design. The second is almost trivial, just use the same model and put random ideas or increase the size and use another 500 GPUs. Some of them will work. 

Backprop was developed using pure theory. Convolutional & Recurrent networks where developed from neuro ideas. Transformer take tons of theory from previous paper and good theoretical insights into what they where doing. Diffusion models have absurd amouunts of math behind. The same with Optimizers. etc etc",r/machinelearning,Z0FBQUFBQm0yeGJ6bkJlb0RJZzV1bWRDR0lKSHh3a3VSMzRsZTVOSG5XdzZOR241bmxUNjRHRmFKeWFaRmVQOFptUjhEZXY5dW9EUjZWeW13cFpFM3pHUjlxektlWUl2YUE9PQ==
"A postdoc colleague had a good paper submitted to TMLR which was rejected. The paper is good though. It had no technical flaws, was well-written, and had a clear and measurable contribution. However, the reviewers completely missed the point of the paper and requested experiments which would require multiple GPU years to complete. I've heard from another PhD student having a bad experience as well. The reviewer quality is low and they seem to review as if it was a top-tier conference which it fundamentally tries not to be.",r/machinelearning,Z0FBQUFBQm0yeGJ6VGlZczNtbEwxMmo1djdhQU5Dc1hLQUhtZUJtWnVDNG9VZ2Y1MFc1ZkVlLXdtOC1NZUdkcEFWY1YweXJXbHlPcFhmTlQzVGRXMTRVSGZ6ODAxVEdxd3c9PQ==
"A pure audio model will always be worse than what open AI has, simply because their model will always directionally represent more features than a pure voice model can. ",r/machinelearning,Z0FBQUFBQm0yeGJ6ejRpOGMwV1pJQVBXT2hONFdhbFQ3bThaVjJwRWY5bFBqZ0lVd2o4cnBjczFPUjNnYzRfMEZMeUtUOTlmQTA4eWZFcFVueV9EVUpfTVQwaUZJcXk2S0ctUFBTNGEyNHE0eFdYUDgtcElyQjg9
">But it is probably a matter of time until some big paper will change that like BERT/Transformer did for NLP. 

We kinda already have this. Transformers, and LLMs, aren't text-only anymore. They're multimodal. With the right multimodal embeddings, a single LLM can take in text, images, video, or audio.",r/machinelearning,Z0FBQUFBQm0yeGJ6dXlLUUY1OFh4U0Z6UWd1UkY5eHFDU1lSUDNNRzNKQTl3T1F3MHVSUml5YndDN2RnWVR3VnFaUk54dVVkN1hfM0RUcndka2U2QWdmOVpScmdnZ0VvbkE9PQ==
"Does it make sense financially to use cloud compute if you're constantly training, don't need to scale in/out and don't need more than 12gb vram?",r/machinelearning,Z0FBQUFBQm0yeGJ6bVljNjgzNjZaaGY4MXY1MUhDUzFrcllfQ05oZGN2a3Y3d3ZNbU1HWnRhMkYtUWRIb2tWZ29iLWVVTkhHZkZRcHZuYXNtU09kMzN0Z1Z4YVFTV1VobnBxemV2YTNkNXp2SXJGZTdIVXprVE09
LLMs will be AGI!,r/machinelearning,Z0FBQUFBQm0yeGJ6TUgyZWFTYXRzZU5DenVvY056S2JFZXM5VVhXYnVRMmstdlZ6c0JGVHZWRHRKNTFxVDdPbkpocGV0YTRVSEg4bVlZUHpFSm9KdmpMZUZxUlNNZVVaSXc9PQ==
"I think the missing part for audio is a represtantion method that can hold more ""semantics"". We have seen some success in using Hubert or encodec, but something is still missing. We saw that a tokenizer has a big effect of LLM. We need a good ""tokenizer"" for audio. Beacuse we basically have everything else.",r/machinelearning,Z0FBQUFBQm0yeGJ6eUo4aDhHTi1zLUxjT1BLaU0xTlRmdS01U2ctSWVyWlhUbXduU3BXdUZDMUlwTmRTLWhsaFJIaWhIY0I0TFRRVEk2dVM5YXJiV2JaUVhMd0FNMFprY0Iza1dLeUYwZU9KcUYwc3p2akZSNm89
"In a textless approach, The point is not to make a better model than a multi modal pipeline with a huge ampunt of data poured into it. The point is the make a model that is comparable but doesn't have the latency and complexity of a full multi modal pipeline.",r/machinelearning,Z0FBQUFBQm0yeGJ6ZVJHM0pxd0hfOWo2RDhlUjBhVVA3aUpibXVyWEF6T0phU2FjR2xKUkRVelJuVmFzQmtZbkk1a0tTQnBCTVUxTThpbVRLZlVaX1JPRmVwYUV2NE90bjlTOG44MjhvQmRKWV9UOGVYdTVEc0E9
"It's literally not multi-modal, I know you want it to be but it's not lmao. 


Cover your ears and scream ""it's multi-modal"" but gpt+4o is a singular model thus it doesn't have the latency and complexity of a full multi modal pipeline.


It is an end to end multi-modal model. ",r/machinelearning,Z0FBQUFBQm0yeGJ6Z0JBdkJacnJNVGdLRlhseUFNYi1hREwzTWxzdDFGVTdQYUFid0huNnFObkVIbEc0MDlDNHhhVTE1VUxabm8wdGdCWmROSFNkeHh2QXRfUnlMeV9mdUttVEVxWldWS09lWWtra2tJSmFlaFk9
"Is there a paper on GPT4o? Did they publish how it works?

As far as I know it is all assumptions at best.

Yeah, they probably use some embedding space for the multi-modality, that still means it is pipeline.

I really don't understand why you have to be a dick in a conversation. If I didn't understand what you meant you can explain again. Even if Im at a ""half assed program"" (I am not, you have no idea where I am from or what program I do, or even who is my advisor) why be a dick?",r/machinelearning,Z0FBQUFBQm0yeGJ6WFZkam94WlZEdm91M1pIVFI1bEhlTHZNMnpPSzNQZGNzMURUV3FBSk5WSm1qc1NVeDZNZkhoZjg3VExhNkd1Ri1ISTFHRE1mU29TbjNVcUFZZEtkUVhVd1Q4R0pRTnlNRXBXenZMRnlpQTA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6QnU2bDZfZGtFdVJwMFhWX3ZvOEQ2M0w2dW5ZZ0lDWkVkZk42WUhsLUM3U1lGQnozWlBVV2lEemxCSDlyWGdvYk5FdjVoa2x4MjJ2RkJELXh2Q3Z0aEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6UVRsR09RS2J3U0FqLXdYV0sxcEszSHczRDgxRnU1Vy0temt6MDBwLUgxLTl0MWNlbzdKQ2dqTjNXN1MyUHlDTUpydzhDQTdPREFsNWF0S2MzQ0dMM3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6OGRDVlBpZlNSUFVkTVlUOWlaV2p0RzB4WGs2TWZpbDVndzNSWlgxNTZ4VVE2RFNYVWJxOFpDT1FkUnBQV0VwNEgtN2hhcXZzbFQxYXBkYXhWWGJMQVE9PQ==
"Yeh, sent a DM",r/machinelearning,Z0FBQUFBQm0yeGJ6VWNNVDJLM2F1dHRrUlpCM01jc0ZZTEVXdlIxQTZnR3JlbDFGckhHM1lZS2hOZlFXM2ZWSzlaQkxrWmhrbXIwQlhIdkNVM1N3NWdBTEpWYXVKcEI3Y1E9PQ==
This is literally what attention does and it works for all modalities. ,r/machinelearning,Z0FBQUFBQm0yeGJ6ZGpBYUVhVmxfSm9jLXZLZUkwcDdEOGJHSjVSdDQ2NHlNLVh0WHhBbEhBMU5WRUF0NXg3cDBBRHFVbjBnZ0xHd2hsMjlfRzZPbUw2S1hMMVYyT3h1cHhSOUZCN1Vpd081Qk90bmhQa2VUU1k9
"Nvidia will keep putting 24GB VRAM on their top end chips for 5090, 6090, 7090 until someone else comes along and takes the whole market away from them. I know people make a lot of excuses for Nvidia because of their past success, but that doesn't mean they can't get too greedy. Whatever little extra money they make from gimping their GPUs they will lose 100x in my opinion. Just a matter of time.",r/machinelearning,Z0FBQUFBQm0yeGJ6S1g5Y0xGeGd1VTNCV0k1bmdMS2huZ1laYndUUFpEWXUtSUZlZEMycmp1MFJjZGFtaVNBT0VSNm5VLXEtOGIwNlhfbHppTkpZX0NDX2FUaTdkYkkwclE9PQ==
"Local GPUs are much faster in my experience. Example: Running a signal processing and inference locally with my RTX A4500 takes about 2 minutes, while running on google compute engine with a T4 takes over 8 minutes.

If there is specialized software for fluid dynamics or whatever else you’re interested in, naturally you would take that into account when choosing. 

The recommended minimum vram, as you may be aware, is 12GB, so either GPU would have that. Training and inference can be done with batch processing, so you don’t have to load everything into vram at once.

Personally, if $600 isn’t a huge difference to you, I would probably go with the 4080, due to its being (as you said) current generation. Same for the 13900.",r/machinelearning,Z0FBQUFBQm0yeGJ6SXhPbVBDVzRrZUtPbG9PRlVTUWd2QVBHMy00a20yT3RWZVY4WllQSWdQRldVZlFsd2YzVDFIZ3UzSHJaUWJRY1I3NHJYbGYtb0IxNlc3YjZOTVM4VHc9PQ==
"Seek psychiatrics attention, respectfully",r/machinelearning,Z0FBQUFBQm0yeGJ6Y2JhaXFZLTNhSU9BMm9jSk1aWG9iOEFFdkluc21GWHp3YUdQcjA4dlMyR19DUE1SemcxbXJRenpHa3BLSmJZMXNGTGZRUG1KRGRDYU0yZ3RGV3E3RE5vLU93Rzk3cmxjbTY1cC1teFh5RmM9
Username checks out. ,r/machinelearning,Z0FBQUFBQm0yeGJ6cURwSHpxbkJMTVdfMDU0dG9XRkkyT1lEMlZWVmFiZ3Z3YXJ2bG5hRnpwMFVpTkxuMlpEcllnTzZtTnJ2eUxzTUdzZU80QmlpTThXSUtyUjVhWWJPbzhYTmFibXZSeU1BcTEwUklFbl9MblE9
"Multi agent is necessary because the llm doesn’t have the attention to be consistent with all your rules and instructions. Your instruction could be mildly contradicting or vague which would result in a breakdown during execution. Having smaller agents with strongly scoped inputs and outputs allow the system to troubleshoot itself quickly and parallelise independent tasks.

It’s difficult because a lot of assumptions we have as humans is not inherent in an llm or agent. You want to clearly define the exception handling for the most part because otherwise might result in an endless loop of bad decisions with no instruction to terminate it in a “good” state. To give you an example. When i played around with the old chat gpt 3.5 it was correcting it’s code by incrementing a number in the function name, checking if it worked then incrementing again and loop. While it’s a very neutral action, an endless loop  breaks the whole process loop. Newer models don’t do this anymore but the loop complexity becomes less obvious from the observer.",r/machinelearning,Z0FBQUFBQm0yeGJ6MG45RWdIUVBRVktISHNsMmMzT0gtS0xhbjA1LUowOWc3QWF6cGVEMUpvY0o1blBLOHcwX0ZHcU8tWGhpa0lZTmhPM0JxYkJHZk5Rb3AyVHJEX3I5eUE9PQ==
"This is so wrong it is insane. I am starting to think you are projecting your own insecurities on me.

audio as a sequence is much more complex than text. A second of audio is usually 16000 samples. And we don't work with a second if audio. If we want a conversation we would like minutes or even hours. 

That means that you need to ""tokenize"" it. While a similar approach to images has been tried (take patches and learn some embedding) with some success it doesn't achieve the results images or text achieve beacuse audio is more complex. When we speak we have pitch, we have duration, we have style. And humans use all of those features to understand each other. Most methods we have seen in audio are able to get some of those features from the audio e.g. Hubert . Some methods use multiple features from the audio e.g. Use Hubert and get pitch using some other algorithm and train a model using both. But there really isn't a good way to ""tokenize"" audio in a way that gurentees you have all the features. most recent methods use like 5 or 6 parts of a pipeline to get all the features they want, and this of course makes training very hard.

You can look at this paper:

https://arxiv.org/pdf/2403.03100.pdf

Which is very likely similar to what gpt-4o is using.

If someone would be able to create a ""tokenizer"" that is able to give you one ""token"" that ""contains"" all of the features and simplifies the pipeline it will push audio very far.

This has nothing to do with attention.",r/machinelearning,Z0FBQUFBQm0yeGJ6TVMxV2Fvdmg1Rk83alkzNTZWU2tQb1pQT3lWVDR5U29xTU1hd0tWZWpIVVNGT1dRSjBHci12RmROU0JqeU5GSXVxY0tULWVWR1FTelpEdzF4WFcxVndaNlFEVmFPdUxYbzNEakF0M2RVWEU9
"I’m sorry, what?

We are in the golden age of speech.

TTS, STT, ASR, Translation, LLM - we have never seen so much activity across speech and conversation, in ways that are showing real promise;, than any time previously.",r/machinelearning,Z0FBQUFBQm0yeGJ6Mnp5TUV5YWc3N3VhRng4TE5JZ001Mm5ibjZWYWlRMDN4dWFfeEhoNkE3d1pvTzU0MDR3QWk1MVR6SElmdVRZbWdlRVNMcTBpX0FzVUFyU2VHUWNfV2c9PQ==
"side note: you can switch to Mojo lang and have the performance of C++ (or even more), but code of python",r/machinelearning,Z0FBQUFBQm0yeGJ6UXIzeFV3dkVVZEVBV3hCWjk0QkxQNW1wUEduSWcwVHkzQWxuVEJCMXlkeUlZM3FSTWd4aEhOaDV5b2pYdjhRUnBnRFhHLTdRSHU5MWZ0OVZvNFo1akE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6SFh6dkpEMXZnczVLTDlzVnN1S1NqdGlqa2RrNlhjZ3d5SlJQUHVHT0Jia1B4bEtiQWIzeUhkSjdabFh5TU5MdDItQzlzZUl6UkRjQ2M4UmdtdUFaeUE9PQ==
Are the reviews out for the BNI track ?,r/machinelearning,Z0FBQUFBQm0yeGJ6ajE5cmFQd1YzeXpSUi1QX1FFYm1KVm5UbEs3c0I2c2U1Y2lEQi0xaUY2aWdkOC14Tjk2UXVuMWpURGFDbDR4NGJrTkFfTGRjenp0MmVINnpPRWlZbXc9PQ==
"There are many tasks that are nearly impossible / very convoluted to solve with a pure text model. You cannot capture identity, accent or emotion with transcription alone. Multi-speaker audio cannot be neatly transcribed either. 

Spoken languages also have many distinctive features and even entirely separate patterns rarely captured in written languages. Just from a pure language modelling perspective, you cannot even hope to truly capture the essence of human language by only looking at 50% of it.",r/machinelearning,Z0FBQUFBQm0yeGJ6eGZGQXRjcVB4ZTJkUzRqeGowNTZLdUpuSDhDV0FnM0JQWEl0Z2xSMXdRUzAybUZmajJIWVZTRHBQUDRFMXNvUUl3YVhJV0hSWGtySEdwUDluWmtRVWc9PQ==
"We still haven't really cracked the cocktail party problem, which is a huge blocker for many practical applications of speech to text",r/machinelearning,Z0FBQUFBQm0yeGJ6WnlBYXE4MV9HTF9ZRkJtUnp5N0hES3V3VTY2eTRkQVNCRjRyVGFmSmpWcWkxOXdDZ2ljZVBweUVZMl9uR1ZzbWRQMHdBZmhEckxIUzljZmszQ2tjRnc9PQ==
Couldn't you just feed chatgpt a link to the latest Library before asking a question about it? This is usually what I do. ,r/machinelearning,Z0FBQUFBQm0yeGJ6azh1YXFkYk5JZmFCeGE2OVFwbmp4cGpTVklSSy1qdDZCSlJIa3JsZ1FZT1pKLWVxUlg0SFMyblZIZDA5WFNYU0pjM3lKak9CWGt3UnVtRlVQNHVQekZkSWcxalpibUNIOFFEQVlpaDN2U289
"This makes sense. They kinda explicitly mention in their GPT-4o blog(https://openai.com/index/hello-gpt-4o/) that they have used a single E2E model for this, which also addresses the latency due to multiple models. 

  
For gpt-4o, an architecture similar to Natural Speech 3 would be my hunch too - using an encoder to convert them to neural audio codec as embeddings that could be pre-trained to capture the parameters such as emotion, pitch, voice, etc.",r/machinelearning,Z0FBQUFBQm0yeGJ6VTJhU2FidkIzMmVMM2h1N0k5YzUwVk56YnphMjJ4ajFYX3B3bWl0YkxTQXVqamlSVnpYNzMyd09JWHd6d2NqSk1VeXp4eVpiZ1NVa1Y0SnptNWlhd2c9PQ==
"Very valid opinions :)

Where I find them helpful is… if I have a relatively stable dataset let’s say six months of sales performance without major fluctuations, one of these models can get me a decent baseline of what my sales performance might be in the coming week or month…

I ran a few tests and got +90% accuracy on the median.

In the absence of a proper custom built and maintained forecasting model, that’s pretty helpful. 

Ultimately I see it as an option, and worth playing with, but going in with caution / managed expectations. 

If people or teams have the resource and know how to use proper custom ML models then those are deffo the way to go. ",r/machinelearning,Z0FBQUFBQm0yeGJ6OFl1UklpdC1fX3E1OC0tX2lZLXB5OVpVbHJOdkp3cTJoNGNlT29SS09MblMzWTlfTkRqU1N6VVAtcS1QbnFFV3lONGNkM2FwVHo1QUEwTXBwUFlJTWc9PQ==
"I was surprised about the number of papers NeurIPS expects each reviewer to evaluate and accepted my invitation as quite late (a day or two before the bidding deadline). Never got assigned a task in openreview or an email about bidding.

On another topic, I've recently stumbled across this (https://public.tableau.com/views/CVPR2024/CVPRtrends) tableau of CVPR. The number of papers published by the industry made me wonder whether there are any statistics on the number of reviewers vs. submitted papers by ""industry"" vs. ""academia."" I.e., do industry authors review as much as academic ones?

Of course, many authors have industry and academic affiliations, which makes it ""harder"" to properly collect that data...",r/machinelearning,Z0FBQUFBQm0yeGJ6WHZfdVZKdnhTRmpFUUJqUFBRMXdXU0lvZzdUOFEweXUya1FzMktuamFGNHhjdlNDMXdtTFpsZEhHaF9PZ19yOGpob1o1ekNFMG15N1VfZkpBbnY1YWc9PQ==
"Doesn't work. I don't how you're able to do it. Its a good thing that the context window is substantially large now but still, chat won't recursively look up all the pages of the documentation to give you an answer.",r/machinelearning,Z0FBQUFBQm0yeGJ6cnVETG9fWUt5dmV3cWtrd1FWNV9IelpwbTBOQmZMSHk4N3Q4VFNHeGF5QzN2NjJZMk4zV3hSY24zVUwzdFVkY3dScllxX0FPUnhIU21SMFdrYUY5VGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6OGl0d29ZTl9jRnRlTUdySko4ZTJFeVd5T3lFbktFbF9fVjZFRzIwMENLblNNMTF0Q2tla2YxazIzcmU3NF9MZkhxcGFNWnQ5cXhLVEZnREtXR1JVVkE9PQ==
I thought it’s a solved issue? Isn’t the impediment trying to execute tasks extracted from speech?,r/machinelearning,Z0FBQUFBQm0yeGJ6WE91OUhETXRDdkVwOUltMGlOaHcybHdsSk9TSHp5T243Y1A2UmlIbzNtV0FsZk5sNTFROW9WbDVrSjNzRk85MVY2ckRBeHZqV1hlMTNiMWNFaUZUN3c9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGJ6b3FYZEsxNXZUNzBWd19FcjRSNWFBYzBJTWZ0cVBwNXVCS0YyeUplRUtqMU5oWENpOG5CWWxZNVdIUHQ1U2d2VGV6REc4SUF1SF84bWxiS3R4TnZzakUtVW1mVnpzbGtMMkEyNFdDaXdOaVk9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6NGpTTHBLNk5yQTZhYy05TTN2NzNNM3ptZkFEVlVtLU1zR2k0RjZPRlIwbDdXY1A4ODlBRk5xbExsci02OXk4OXEtRy1VMlBmaUJ1N2MwZWUtRnowaFE9PQ==
"It could, depending on your electric costs.

At the US avg of $0.17¢/unit it will cost you like $30 to run a 320W 4080 (more efficient) all month.

Then for a direct comparison, you can amortize the cost of buying the GPU over let's say 24 months. Let's say $850/24 months, that is around $70/mo. Coupled with electric costs, let's call it $100/mo.

On Vast right now you can rent 4080s for ~ $0.2/hr avg and ~$0.1 cheapest. In that range it could be either $30 cheaper to $40 more expensive to rent a 4080 at 100% util for a month.

If you don't want the flexibility and potentially want to keep your GPU for more than a couple years and electric costs don't fluctuate up as much as down, then it could make sense. The main reason I recommend cloud compute is for flexibility. Some day you will want more than 12GB, I promise..",r/machinelearning,Z0FBQUFBQm0yeGJ6R25iM0pxUWptTlRNTUFBamw2RV9JaG96aDR4X3RPTUtMNUR6cm91UGcxbk5RSDNHYlA5ZFk0bXF6YzJ3cm1YZ1RRMzhxTGl3UVhTaXZQZWtRX1REN0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGJ6VThkZnNMbkNvd2l5Q0ItWjEwNFdJdmdGb0dNc2tUc0pLUTBLQy1MVURnOHRWeVU2dTVMNmNIaGRMQ2JqVU51aTcyVmJMR1lkM2Z3QjFtNDEyTGl5RGc9PQ==
"I am not too familiar with tensorflow-js and don't work in web-embedded applications, so I can only provide a limited answer. Pytorch does not have a JS API, but it allows you to serialize models, and there's also TorchServe.",r/machinelearning,Z0FBQUFBQm0yeGJ6eXdXbm9ONnRJNFZBX1o5cXVnSWU0NnVGLWZHeUxTQlRybThhSzJXUFVyczZRNlI4aXhOb200N3czTkxpNnRoYVlUUFh1Z2JscG1pYVVNVzljUFdSQjkyWS1jakE3cF8way1mVW5EZTBCNTA9
"Yep, natural speech 3 seems like the most likely idea to me, maybe with very good data.

I do think they still use text somewhere in the pipeline since creating speech longer than 30 seconds and keeping the context of the what was said is very hard without text. But those are just some ideas I have, I definitely don't know what they are doing 😅",r/machinelearning,Z0FBQUFBQm0yeGJ6cVlueEpUdXVoMFRCSDVQbjVTVEdmaWU5RmZKdlBnelUtUi12ZUJjd1FNVGZ3YVAweWFZV1o1VWQ1WjU0Rjl0SUl4QWJtWTNuRl9QY2NSVUhXT20tRnk5QzdieXFoS1lheFM3cU9LaEpMRlE9
"All I'm asking for is literally a single comment that supports your claim that saying that:

>

>**is particularly unpopular in** r/MLScaling

That was your claim, not mine. If it depends on definitions, you should provide them.

Perhaps its time to admit that you just have a strong philosophical disagreement with r/MLScaling and you overstated their position to make them look bad and now you don't want to back down?

Or you could present the evidence.",r/machinelearning,Z0FBQUFBQm0yeGI1YW1iRXROMjJlYVoxZ1MxUkNNNGtIVi0tbE43dVlibGtncmxfWUZSalNvb0pQZkRzU1pTSElnSlpFRlc4Vi1fSW1feUF2R0x2cmhPZC0zTzNDdUVvYjJkMzNLQ3NtYlhhdHJUbGM3ZnBCQjg9
"I'm desperately trying to find or learn how to train TTS models that match certain expressiveness and performance styles.  Most tend to be trained on audiobook and similar narrative/flat styles.  But for my organizations needs, we want something that is more emotive or can be trained on the more niche delivery style of our historical content.

Essentially, radio branding voiceover tends to be a little over the top, and station slogans or call signs tend to be read a certain way, emphasizing certain syllables or word timing regardless of who's saying it.  As we look to grow a service at scale, with the support of the VO talent I want to add, we need to ensure that the performance of generated phrases matches their real delivery style, even as we've nailed the vocal quality itself.",r/machinelearning,Z0FBQUFBQm0yeGI1U0JYVE1mRXpPY3ZsaWVneWJtSXlVOENqZHhIQ2xEVVVZQnhvUGF3VnRTNk5iUkhTeWtPUlVsRkJkUnBiYU9QZTE0bWJ6R1M3Vk9fbWNjOXJXeC1FU1E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1MVJ2b3BYeHg4UVN4QkFxV0drbFB5YkpibFJxWWhCdmFON1FLZnZJRkZfcllxeHlDWHdFX3JlQUpmc2dIQ2UtcV9vR0lrSjFIRzRzMVQ3UW15Y1VXYmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1Sm9vNU9NRTAtcWpKaTRrd2VQSG9XSUxwaU53TUFLSDRrNjBhZklHVFRGN0o4S2dqeXZWYnhFT2N5Mk95V3RlYVl5OUhtclVydlRGOWI5TFBSZDVxbmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1d1dJREJqV2lWWUFnYVhEWXFISzZVbFFnWGZfamctSUVrUXBrdFY1WnFOM0NpMkROczZCaGhXYUlZQnZ6bGRybEViT2FaZ0MxRy1HWDZCeUtKZFE0LUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1NW5VbXEzZzkwekNUb3VkWVE5WEphQ1dkclRzQjk4Z1JQckNMeWRycUtVLVlqckJGWGJzOXFzSGJYQ09YSDVyRzFvcVJiNG9ldzJkMzczcDVXUHJjc3c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1LUlPZFNmNk5TRnJ1eEFrdXBGWDJWdXI5MDNMdTBteUh5YlBqUENHWUFNc2ZtNkw5T2lJWEtuZ0owbUVZU0JMZXlfZ28tU2E3SWxJYmNYeUNHaWlRdFE9PQ==
Well it's some basis of what to try experiments on - backed by some hand-waving - but yeah in the end if it doesn't work who cares who's intuition it defies,r/machinelearning,Z0FBQUFBQm0yeGI1Vk5icHFVSHBvcG5GQTF6NFVQdlNGYXJveHQzNjcyS1dSN1RIVko3Uk9hWEw1LWVLdjJhVE9RdTZLbWJSVF9VYkdWUzRobHJnNTBLdGtLRkFLUV9KSzcwWXNMRF9OMnZqUlpZc2laU0NRbzA9
Not good ones,r/machinelearning,Z0FBQUFBQm0yeGI1OUJiWmpvU0JVSFphOTRURWRselBYckduN3oxZnpCbVF4cWJidVJWeVlTRXJoWkxlMXlnY3lGRGlZNlFVTFd4OFItaURTS2hIMmJWTEl3RXkySHphNUE9PQ==
"Multimodal LLMs and video/3D generation.

Diffusion models for robotics. 

Model-based reinforcement learning.",r/machinelearning,Z0FBQUFBQm0yeGI1Yk1HQjJJZlIyNHhSXzFPMGdoUkp2R1p5dGZjMmRfMzBhMk1uendsaFFmZGpIRDVFOUZWQTdDNVpLOVA5RERnYXJJX2VhOXZ1blJ3NTNnZUpFZUJKa3AtUDlaWENtNDF6NTFpdUxUVExmd289
this is sooo interesting thanks a lot for sharing this!,r/machinelearning,Z0FBQUFBQm0yeGI1clRYTnRBRmM0dEtiN0poclowNVlfNU9Pd2ZVN3BJeVUzaW1tcUNHdjJuS3ZSdS1ia2FMWm53d0FaSzlDUnkyVGNvVUptRWJnWTlxZDRKUmdVb0wxOWVoQjRPREFsOTNhaGt6czAzNGI4aU09
"Huber loss does not penalize large errors heavily, that's king of the point, isn't it? I mean, it's just MAE from a point, and MSE near zero. Advantage of Huber is that it is differentiable and smooth everywhere, so e.g. L-BFGS works (and doesn't work for MAE)",r/machinelearning,Z0FBQUFBQm0yeGI1Zy1ZSVBYc1RxNllaa3htUms3UmN5TDBoMGd2eWNsYmFNLVVzNlBjNHl6X3ZBamtxc3FRekVGbVR1SGUzYzhtdkxiVjgyZzNVTHJ2Nl9JU1FlMDhRLVE9PQ==
"can you share some reference to this? This is so interesting, thanks a lot for the input",r/machinelearning,Z0FBQUFBQm0yeGI1UTZGSWJMdGZGd1c3YUM1RmZONmI1SWM0QzNoSEM1RWdBMG5lZWl4d3VkWDRMRVRwUHV0WjdnakhjT00zWXNCanByS1BRQTRfVmp2OUhNbVp5dUpIQ2hrOVR0LVBqQ2VxdUNab2w5RUFXb1k9
"I use the models locally with own code.

There is only so much you can parallelize if you have only one GPU. To get coherent speech you need to process at least one sentence at a time. If the first sentence is 10 seconds long  and the model isn't fast enough for real-time, you have at least 10 seconds latency before you can start playing the audio. But even worst is that in this case you have to process enough sentences that the resulting audio is longer than the processing time for the rest of the sentences. With longer text passages you get really long delays.

With a model that is faster than real-time, you can start playing the audio after the first few sentences (depending on the individual lengths of the first sentences.) Then you have only a short delay, which should be workable.",r/machinelearning,Z0FBQUFBQm0yeGI1X1VyYWYtNkVjdlFIM1ZQNHVpSTVRVngxV1VjaTRtcVdRSnZqek43QjhoYV95YkJLb3ZlcFpTa2dVcU10ejN2dFlrbDN6d09GTXFrSjJYSzRBNlZVN0JYVURoa0hIQVBKMk5XeHY0ZTJ4LUU9
"I already addressed that but your comment just adds more evidence for the bolded.

> Also you previously had no issue with MLScaling is a bigger cheerleader and cant see how if it applies for the less rabid group it applies to the more rabid one. **Not being able to make that logic leap is obtuse**",r/machinelearning,Z0FBQUFBQm0yeGI1V3Fvc1ZKTTdfNkhIOE9GbXJsanRTalFsbVk0YjQ1clZNMEFtc1Z4VnRGQ3k2aWVoamhta01YQWUzU09Udm1IT3RTSGdUUmxIRktUREM2QV9PSTF0T3c9PQ==
"Second paper, leave the old one as is, don't change a thing",r/machinelearning,Z0FBQUFBQm0yeGI1Q2JjdXIySVg4Y29KdTY4UElhU3M2d3c0LXpkMVFRNW1fbkIxVVh2dGw0OEk2aHpyMWk1T1R2WVlDWkhNUDBiNU9zZHBhS19LTkR6THk3RThZTzc5Z2p5cEFOcHNJam9iV0JuYUFRWTg3cTQ9
It's not - the maximum you can upgrade both the helios and the legion to is 32gbs - i know it's very bad and I felt a little disappointed after learning about that too,r/machinelearning,Z0FBQUFBQm0yeGI1WnVsS1NwNjBlaUlfRnJvQjYzMTBvOFdsVFp3R0U4NWVZa0FMQlR5cHJfZDREOVIyTHJHeTVFY2dVLUp2Tm1iYV9lUW5HekxvaDNkcGlFNHRQVmlHVFB2OHpLVC1QZVhPQ0ttNDRkbWtPdFk9
"In diffusion models or denoising score matching, we're not just doing gaussian denoising, we're approximating the score, which means L2 is the right norm, as opposed to L1 which is ubiquitous in image denoising.",r/machinelearning,Z0FBQUFBQm0yeGI1NEdWUlhhaUxBNlpXeFp1ZmZPQU5ITFBVNEN5d0NMVk9kQ0E0VkxTOWlMbzZNdnRyak1YT0ZVVkRXTWwtNm85eVRBQ1NmTmk2QlFHd1kwcmJTMXI0SGc9PQ==
"IDK exactly what you mean by ""upper bound"" here, maybe care to elaborate?

My point is that STT/TTS (or ""I/O""), specifically for high resource languages, not only are the most profitable applications, but also have been tackled for years. It's hit diminishing returns at this point.

That doesn't mean there aren't a plethora of other speech applications needing qualitative advancements for meeting actual industry adoption. Actual speech representation learning for multimodal settings is still an open question, because untangling phonology, paralinguistics, biometry and non-speech is tricky. Plain STT for feeding LLMs works for a lot of practical applications, and this probably subtracts a lot of the perceived value on more in depth research, but tech wise it's basically a silver tape approach when compared to how images are processed and encoded in bleeding edge LMMs.",r/machinelearning,Z0FBQUFBQm0yeGI1Smk2eVdHTUM4OHN4TjF5TFB3QWRRYkVQTzNqaUp6bEM4RV8tWmdoM2N2RGtrUHl4ZmRUUGtLT2ItTFM2T25GZF9nV3pJUHJNSW5LYkd1V2k5WDlVWE9pZmpCcExULTdJa05FcHBCN3lIVW89
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1cnlpRllVWkhkaDhmcjg5RkRPTGlrWHFZeDNGcmUydDdlcUp4V29jRzZnNDZYZlFmejgtQlNtQUw2aXBUM0hVOGNtaW5KcWRwZXpicExTS3N2cUFaTnc9PQ==
"I'm sorry in our many messages I must have missed the specific quote you've supplied that is an example of someone saying ""You're wrong. LLM's are not poor reasoners. They are good reasoners.""

Can you please supply the quote again?",r/machinelearning,Z0FBQUFBQm0yeGI1RmhYSTRqY2tPTXZXOXJ0MGFQV0R0ZjVVbDlYdmRLWVNBcDRVei1fNXhob2ktQ1poNzNydi02Z3dxOE01cV9ldzZFT25KZENMaFBWenZnNHBGTmxDWVQxX21ialJGTk5hYWFRaWJSbzcwNGM9
RL for combinatorial optimization,r/machinelearning,Z0FBQUFBQm0yeGI1MkJjWWVWRkxaWjQ4VDduX25vX1FNLTJ4QUhja0k3blItZC1za1QwN0RMc3I5TElsbmxFZHhRcHdSS3BCZVpONkh4T0Ntb1lFS3JteWstMFcyRkJtUThzTXdCcDlJMkEwVm01azhZU0pNckE9
Honestly not that hot lol just for me,r/machinelearning,Z0FBQUFBQm0yeGI1YUJIVWQxbWtZVHROODhHbkJqMm9xYVBCZjJKZE8wUzVTemVsMG03MGVnLTF4YmVfWGxoNVJlbHRwLVNudVlFMU42Mk5SMG1pX3Q4ckJYZ0RDcXZSc3BOa0VGM3U0SjV4Y1d1MjkwelZOSTg9
There is no need to read about diffusion to understand why MSE is the negative log likelihood for Gaussian distribution. This fact can be found in Wikipedia or literally everywhere,r/machinelearning,Z0FBQUFBQm0yeGI1Z0hZTkN5dWhYODZxYWNxRE1sSmdqMEdvR1VwM2ItLWprSC1qMm9ieVFMMVNTeEZvbHp6VDdZWVZ3bUtIeWZ6V1g4Z0VuejlEbjAzWENmRUlLT0FBblE9PQ==
"I was going to write something smug and clever but basically it's because I read Josh Tenenbaum's google scholar with newest first... you can too. 

  
[https://scholar.google.com/citations?hl=en&user=rRJ9wTJMUB8C&view\\_op=list\\_works&sortby=pubdate](https://scholar.google.com/citations?hl=en&user=rRJ9wTJMUB8C&view_op=list_works&sortby=pubdate)",r/machinelearning,Z0FBQUFBQm0yeGI1dVFOMkN6Sjk1TEJJN3JIdFBQWmRKQ0N3dE9vWDhya1Z3R1VubUNKOGVPRGVpVThyY29mX3F5anl4MXRpbHR2SFZ1WGk5R3hMZEQxQ0FZRkhrVHE2NEE9PQ==
yeah my bad on Huber's loss,r/machinelearning,Z0FBQUFBQm0yeGI1QmdWWDBOMm83RlAwcjBURmg1Wlk5OFQ2SjExTENzZGhuLXlnZnJLS0xHTmI5VUc4SmFGOEhjQlZwWXpEcU9NeFFlSXhIdnBTVFVtRTNhZWhXcVNOQVE9PQ==
"Of course, I just meant they're good examples where L2 is the norm we really want to use: we're not making prettier pictures with L1 but approximating the score. Sorry if it seemed trivial.",r/machinelearning,Z0FBQUFBQm0yeGI1X2FYdXowWS1UQXh6UTItQVV6amQ2eG9pLTFKQ3VRZ3V4a1ljWDQ4SldxUklsRThrRWNfQzdUX2xrcVBNYXh3LUFfRGFBVkoya01hZXpBSE1iQUFuV2c9PQ==
"I see, thanks for the perspective. Not sure why you're being downvoted.",r/machinelearning,Z0FBQUFBQm0yeGI1NlNKWkU1cEczMUNvTEpVSmJXSm1pMUxSRmZ3TXJzZG5UV2dKUzVpdUtPOUNqRVg3MVh0clJLRjBPTlpka2R0NGV0cGhlSzczVWVpWHlncXlxMXp6SmRTcHhuSkJKMm1XcWVXY1BmUDc3NHM9
"Another thing that folks haven't mentioned yet: squared error lets you come up with nice formulas when deriving things by hand, precisely because it has a nice derivative. A simple example of this is the exact solution to ordinary least squares problems.",r/machinelearning,Z0FBQUFBQm0yeGI1TU8xMVRKT2pmNUhkcGNqZGJEaFpVR25KUnV2d2RmWjE2UmFYdFJKRTM1WjlwODJaUkxvMTU1VXIyNTJvQjBPSzAxWXlxRERLcmhkRnBoYmpSeExYM3c9PQ==
Literally any machine learning textbook,r/machinelearning,Z0FBQUFBQm0yeGI1clZnNkV2V29MUmozVWx2WFFYS1FmVEVpUDJIN3QzWXAtdlZ4bVRWMUgtTmE0UkpnRzZybkc2WUJBUk9xZ1hkOFdwd0IzLU5tVERMOWN0SHhscXdBeHc9PQ==
"I like the concept behind TMLR. It is sound and genuine. What else a researcher could ask when investigating something?

Whenever I'm doing literature review and I end up reading a paper I like from ICML/Neurips, my stomach immediately starts aching, because the chance of being able to reproduce it will be close to zero - Lack of details and lack of code. 

To me those who do not see are part of the problem and need to go. That simple. Either:

a. They don't realize the need for proper reproducibility and the dangers associated to it. Millions of dollars/computing will be spent because someone actually forgot how to explain their ""novel method"".

b. They don't really care, because they in it strictly for themselves chasing grants/tenure/position at Google and they need something flashy.

Of course ""we all want a paper in reputable place"". It is understandable. But when 90% of papers of the ""most prestigious"" conference is irreproducible and many are just a  repackaged version of a theorem published 20 years ago by some statistician (but turned into a neural net), we gotta stop and ask WTF is going on...",r/machinelearning,Z0FBQUFBQm0yeGI1NEZtN1N5VDE5VUVTR0hESGJ4bFBWWGxSb054TDIxNERPWW5MS3R5ZTdIRmVtaHhfdVZmM21iRlY5TF9KT0plSURGRzloT1VuWUwzTGFnTzBPOVF6RkE9PQ==
"As a student learning, buying a laptop with a dedicated GPU is a waste of money imo. Get a cheap but very usable laptop and a subscriptio to collab for much cheaper. By the time you'll need real hardware, the requirements for interesting projects will likely have risen and you'll be glad to not be stuck with a too low vram of 12Gb / 16Gb. You will be able decide then what to buy if you need it.  

What I personally did was buy a cheap refurbished laptop. Then later as I saw what kind of projects I wanted to do and requirements I needed I bought a desktop machine, with specs designed for both my gaming life and project life. I connect to the desktop remotely with my laptop so that I can also work on the go, no battery life issue. My $200 laptop is probably giving me more power at my fingertips than the laptop you're considering (because hardware for laptops is also underspec'd compared to desktop. I'm baffled companies are allowed to have parts named the same but having different performances).  

I'm not saying to do like me, but don't overinvest if you don't need to.",r/machinelearning,Z0FBQUFBQm0yeGI1dTFLdndqdUF1cjcySXJiLWtCZnd2TWdvRi1TbnVtQ3M5RUVQOE85SUZOUklKX0pDYTVnMDJQaktVbWdiYmZ0SU1OTDVmRENZalpsUmVyRjBORVotWXc9PQ==
You beat me to it. This is the answer.,r/machinelearning,Z0FBQUFBQm0yeGI1T2I3MGxjSW1SdGdTR0stTTBqMEE4SC1wc1FWX1A1c1h4aVZaRzU1MGhFLVdiSEd1NktpeGl5QkxzR25KeF9ULWlGMEZHSTVfc0RHTVVIWFdvVXFxOFE9PQ==
"That's an overkill, any text book on linear regression would cover these assumptions.",r/machinelearning,Z0FBQUFBQm0yeGI1Wkl4ckZHcUVPbDZDNzd1RzZfSDZ6QURQMzVXMXBQVnBUd3VrZXlsRWF5bnktbGNGcGxISktQakh0TXBvVEVOazZTaG10U054UTZVRTNpYU5Yb1dhVFE9PQ==
"No it's ClosedAI now, don't you know?",r/machinelearning,Z0FBQUFBQm0yeGI1UHZEYzVROUxCSVdmc05BYWNfN05uRVRvQ19sOWhpRE9lTnVJVWR0RWFOQWc0VF91LW1vN1FGR1ZkcHg3Ti1wX01veUVjb2xxTUVTcHVOaWQwWVh1c3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1cXYybnhwYm83N2VvbXFRd1F2RktRZUlldEdRLUhoQUU5a2YweG1TRGo2VnBhRlZJelJKQXQ0NkNJb2tHUFN2bzZUZGJFRzRaLXVWNVZ2a0JzUndUdkE9PQ==
"Are you sure? I can't find a single Legion laptop with 32GB SSD. There are a lot of ones with 32 GB RAM (random access memory, where things that are running are stored), but SSD (solid state drive, where things you want to save are stored) is storage drive, not the memory sticks used as volatile memory.",r/machinelearning,Z0FBQUFBQm0yeGI1LUl1eUJvSXU4OV84Y3VGU2hFOFpVV3ozMlRZWFI4Y2Y5endYMnlKNFF1d1FTN3ZwaEt2UGpsNXJwZHJoaU9uMXI4MjI3VmpoZ3V0cnJUUlVWYjhFeGc9PQ==
"Yeah lets meet up, are you attending from the 17th?",r/machinelearning,Z0FBQUFBQm0yeGI1MVBuRGZqcFp3Y2g4ZEZGZnprZ0dzQWVIMHVtWEd3VmQ3OU5XQ2pBZVlSaHU1U2VFMmFTQzZiU3NuNFJ4d0JjSWJIT25ObV9fdWZIMGk5eUw5UkpjWGVPRUFESEJhQlFtOWVLcEFTdjNmNVk9
Have you tried looking at the documentation and code for the package and modifying the existing optimizers?,r/machinelearning,Z0FBQUFBQm0yeGI1QUZTYkZRT1EtQWtmS2laZXBvVG5fN0IzdzZRaEVFWWN0c05SZ2JmUWNRdlpTeWRqZHZCTHRSYzRMWUhGcjBKQVdBQ1RBSUJWWXFNdE1aY3pqUElLT0E9PQ==
"At a high level, it’s a maximum likelihood estimate for the parameters of something with Gaussian measurement errors. 

Gaussian errors are expressed mathematically with exponential functions of ((y-A*mu)/sigma)^2. A maps parameters of your model to measurements. Multiple error terms are then multiplied to get the probability of a given set of mu values for given set of observations y. That mess is nonlinear so you take the log of the likelihood which has the same optimum point as the likelihood but causes the product of exponentials to become a sum of squared errors. The optimum of the sum of squared errors is found by setting its gradient to zero which gives you a nice, easily solved linear system for the maximum likelihood estimate in the particular case where your measurements and means are related by a linear operation.

When you use a different probability distribution than Gaussian, the above process changes because you no longer have a sum of quadratic functions. A common approach is to use M-estimators and solve them with iteratively reweighted least squares.

When your measurement function is not linear it also doesn’t work directly but you can often use nonlinear least squares which approximates the solution as a sequence of linear least squares problems (but in a different way than for non Gaussian errors above).

And of course you can combine the two to have non-Gaussian errors for non-linear measurement functions.",r/machinelearning,Z0FBQUFBQm0yeGI1cFVseTFDeHhEcGpTalp0ZTQtU2V0QWFSbFpLS3VjaERJX0paMUJ1dDlwTW11dFo3TmdZLU5EYzl0U3BkZVc2OEpuaFU4ZzEtVzdQUHI5WWMzVkdhQWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1UmoxMjZGMFY1NVpLQVo0eDNmOEhyMjhja293Smx2aVk0LXRWYWpXb1M5TWQ5QUZRc3dGQWlkMDhWYzIya3lwd2pjTllHd0ZMa2pEWk9Xc0xxR3g1bGc9PQ==
"LLM all the things, even the ones that do not make sense",r/machinelearning,Z0FBQUFBQm0yeGI1X2ZJRW03RVBoNjYzWE5NUGVsOW9GYlJhMXdMZFJneWZjaXI2MFp2enI1NklxZW1Ibl9jR2JJaExMUFJPbXh2YTdZVGszVTRoTzVFWmdPWGJQU2JqeEE9PQ==
"Yup, doesn't seem to directly receive it, that behing said, the code is a mess and documentation is non existent, was wondering whether anyone here had an idea of how this could be done. Right now I am thinking about giving the opt the model itself, but it's 23:30 and I have a couple of days until I will have time to try that",r/machinelearning,Z0FBQUFBQm0yeGI1Q3dfZVVwb29RVURvSFo2VTdUMVUydEJNMkk3ZTRxazJSbFYwUUZSVXo5cXNOa3lremNBaHBWdnJMWHMwckJ4aXlFeFg0ZldFWWNfOXJkRXlaaUVWcTJ6S3g3SnBnQ2Y0S1o2VU85QzZJUjA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1M3Qzd2hqSDVZdThFeTdYbW5mLWo4eFpwb2JqM3FTY1l4U2l1VWszbXdLYzdiYm9ibWVIVTNaMHVDUmVWcUVLS19DdWhFd1hhOEJyRFV2UlgxUG1Dd2c9PQ==
"“90% of the people in this world are with the wrong person…and that’s what makes the jukebox spin.”

- Willie Nelson ish",r/machinelearning,Z0FBQUFBQm0yeGI1bktaNmxsUHdzNTRwNXloandxNWlkV2NCQ0d1U2h2ZGQxMUswNDFuN1JYUWxBV0xpS0JDVEdlMTVmQ0JNLXU5MEJLMkVmQ01iZk9xLTB6UWVXSmVpVWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1dkpwSFUtRVJCMzlGWF94WGtZRXVMbEpSWHIwRURqVGNKT2ZTSGxuSlJUbzdvUHpDR0tUZXE0UFVqbml3WVhZX2VocTZmWl9SaXd3QmlmbnFTejRHT1E9PQ==
"It depends a lot on the problem, the data and the model.
In most machine learning tasks where you do a point forecast, your observed/truth y is a random sample of the (true, but unknown) data distribution, usually conditioned on some input variables x.
You try to forecast y, which is, in fact, a forecast of some property of the data distribution conditioned on x.
Dependent on your loss, your model trains to forecast different properties of the distribution.
L2 approximates the expectation value / mean.
L1 approximates the median.
Keep in mind that those estimates are also random variables because your finite amount of input data is also considered a random sample.
Roughly, L1 will be less sensitive to outliers, but the median may not be what you want to predict depending on the problem.",r/machinelearning,Z0FBQUFBQm0yeGI1UnZSXzdyQ1h4cUQ5THJFWi1tRFpnVUV3QWhBR09SYUdid2tVVTJjYjBYMGx4dmNjRHZOVVBUaHdST2oxR0g4emNBb1BkOVJpUjljczB4NW5vZ0lKUmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1ZzRxcURSbmppQ0dZT25XaU9FdWRYZ2hCTGpCX0ttSHBXV19ueXA0OG50QWF3MFdOVXdidnlKZmxqY2FLbE1uVXhzRnBnLXZRWkxHcXMxVkMyUF84MFE9PQ==
"L2 is strongly convex, L1 isn’t which makes it harder to optimize. There are other reasons too",r/machinelearning,Z0FBQUFBQm0yeGI1ZzU5Q2E5WkljRElZUkdseXAxWHd0SjFTNldKSUx5V3IwR0p3cUcwQm43eUdreTlKMVNxc1kyOEExaVlaOWdvN0ZyWkJWa1FSaHZWUnF2UDlFcVNTLXc9PQ==
Look at what has happened with source code for training LLMs if you want to know what will happen with other media.,r/machinelearning,Z0FBQUFBQm0yeGI1WDZkTXhscFRBdWxoS2JIYmFuMFI4SzVqRl9NTTZFNmtfcHFsTmJiUi1hdF8yQjNyS3pSNlZMdHJwUlJFZFlZMmcyeVlMQzliRU8zLVFRaF8wYS1SbV9MYnAtaHNfYWU4ZENWZVlld0h3TTA9
"The repository [https://github.com/dhg-wei/DeCap](https://github.com/dhg-wei/DeCap) (from the paper https://arxiv.org/pdf/2303.03032) contains a clip decoder. They use it to caption images, but, in the backbone, they project the image embeddings to text embeddings and decode those",r/machinelearning,Z0FBQUFBQm0yeGI1VndncWFSV3EtU1ZzRFdwYXlkZHN0VUUtMXBEb3Q5OUlwZHlHSU1vY0ZqWmNlT3lCMUllS1c2Q0NianZZZWVaNENfZGNqcXFfZjJqcVhXUld6TVZ5eUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1MG5mdUE4bmVFZFlvR2pyX1pWN21MMGxiV3VDV3VEdGtId0pVS2kwT0x0bktUcHBiZHBJdVp5Wkd2RGQzS0VxeU9oNXVPeDRzbEtmZFI5YnU4ODE1cmc9PQ==
"I’ve been attempting to achieve a similar thing. The main difference being I’d eventually like it to be near-real time (close enough for it to inform people in the conversation, during the conversation).

And I’ve come to the same difficulties. I’m now wondering if the multimodal foundation models like Gemini Flash might be able to do it. (Someone please say so if that’s a no.)

Another approach I’ve considered is fine tuning on a specific voice for voice recognition, or a specific model and step that performs voice ID, on one person in the conversation. (My use case would allow this to be possible, but I’d very much like to avoid having to do this.)

Other than that, there has to be a way to achieve this to a high level of quality and cheaply. The individual tasks needed to do it seem to be well within current ML/“AI” capabilities.",r/machinelearning,Z0FBQUFBQm0yeGI1bDRQZ09YQ0xpZEU0dVJxa3pvNkhhOG5jaGFmd3diTHU5dnNqc2J3WUlrWVRSRXU1cmJsZ1hjdDE5emJXM0U2NjdULUdyRGVTR0RzaTZPVkp1VllpY1E9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGI1bEdSd0phQkVTTHdvNUlaaGRvaHJJd1ZEcE5qeTVQaUVXUVlkV3ljR1JOOXRkVVlVdW5yNWh4SllhN2ZnaUU4U0MzLXM1QVhSS1pwUXBjZU4zZFBNVE5LaWJjYlNJTlIwMnBobTZ4ZWR1a2s9
hit me with your hottest papers in reinforcement learning for combinatorial optimization,r/machinelearning,Z0FBQUFBQm0yeGI1MVg5dUgzSFJHN2VxWmRhT2JhUTFiUkpYU2x3NTR3UHpST3c4Q1Noc19uMXpONnY2RnJFMnc2dU1kR00yaFg0TC14SXVEaE1FRHVwckczbmVLZzFfOUE9PQ==
"The way to understand L2 (squared) and L1 (absolute) and the sparsity that comes with L1 losses is to think about the gradient. 

With L1, the gradient only stops if the loss is zero, and it's otherwise 1, which gives you sparsity. With L2, the gradient reduces linearly with the error. It's easy to imagine that L1 is much harder to converge with  if you know your model is going to have some non-zero error.",r/machinelearning,Z0FBQUFBQm0yeGI1ODVNN0N5bFR3SWpJUzdfWU1ScTNMUk1EVDJWNnI4UVE3bENnMDdsZ2l1M1hSMmRfQnkyeG1ZQjZ6MndZUEEzWVFIS1RkZzRkZmhHaDk1NnI2TXFsTXc9PQ==
"yes, I guess it's the best, but I'm itching not to improve it.",r/machinelearning,Z0FBQUFBQm0yeGI1RUVzQ0hFZjIzTUFGU0ltSUVyLXllNXhoZnVKVHh4U0hMR0hOSVp0cm9wZkprdEN6djRKOTcxM0FQZzVLc3VMdjdibDlqQ0VJc2U5NVhOQXBNcllmaVE9PQ==
Hi I recently graduated with  bachelor degree in CS and Im interested in ML but my math grades are low most of them are C and Im wondering if I should be realistic and find another thing to do like web development or try my best in ML and try not to regret it . any advice ? 🤦‍♂️,r/machinelearning,Z0FBQUFBQm0yeGI1YjhMMi1IUENzcmVQMi04NTVkQnZxeXo2UkpiWXlNVmgyajY2U29pV2prM0k0elJkd3lGVkxIVXlDbkRic2MyeVVZMjUxUVFGVUYtdHRfbUpqTlZCSVE9PQ==
yeah Im worried about this outcome. Open sourced or API callable architectures that are so easy to implement and so diversely capable that its redundant to have an AI engineer,r/machinelearning,Z0FBQUFBQm0yeGI1VVdzWDJreFppQjZIWlUzSEdDLU0wZWFzTkpXQlBIZ2p3M3U1YmJELXhUcVFmWmJQNDloNG84Ml9CNWQxU2VLRUJXREpnZzdoY0FWTjdScU9qbVcyYkdrWWRiSW1wQng0NjN6YlhwSXBhbnM9
"The biggest reason is that minimizing MSE means your model predicts the conditional expectation E(Y | X).

But minimizing MAE means your model predicts the conditional median, Median(Y | X)

That is the main thing you should be considering when deciding between the two. Do you want your model to predict the conditional mean or the conditional median?

Everything else is much less important or relevant.",r/machinelearning,Z0FBQUFBQm0yeGI1MzgzTjBiQ0dQTFduUEItM2xPYXhjc252amdkaWpya0hPbXpYUEZYcFF6YmR2dVZEN1k1UlNxczllWkVvSUh2U0dSWVdRYkRGaEotT0luUEJmQVpBTEE9PQ==
it's not really clear at this point if it is or isn't against the law I think,r/machinelearning,Z0FBQUFBQm0yeGI1OWpTQl95bUtpdWJCUnIycUhXZVBTbkY2em9KSHNuUHJHWTBjUnFXYTd5bkoyM0MyakM4SWxPT3hKMGJTd0c0QlBaTTAwMzZoZ3FNNmNkc295aE5DQ1FaakRIN2RqU0hBc3FhMFpFcEtjaXM9
"""Try and stop us."" Google",r/machinelearning,Z0FBQUFBQm0yeGI1UHA1bEp4bjhJUHFNcWZlUWlKUVlFdzdsYUR6ODZnRGVrVDZSc3kxZjFMb2M1LVlqQmVRdUZ1N29vSWdKbWtMV19uVmJDMUh6WVRNVThUbnRhdV9XMVE9PQ==
If the function is based on a continuous or ordinal result then the squared error can have a derivative but if the data is all categories then there won’t be a smooth function with nice derivative.,r/machinelearning,Z0FBQUFBQm0yeGI1QXZEbFZ4anV0N2VaZjk2SUdMaU1jVmNQWVdLUWdHdnFqVzlMQnh5RXlnOE56Mno1emlmd3kyajdXVUU1OWJZVV9GcVVsWFNlRk5USmJVZG94b1ZOOEE9PQ==
"Minimizing a squared error estimates a mean, which is where the objective function comes from in the first place (specifically, Gauss introduced the method of least-squares to estimate a *normal* mean, but the assumption of normal errors isn't strictly necessary here). The mean is precisely the value which minimizes the sum of squared deviations to the sample values; and so once you've decided that you're interested in the mean as a measure of location, then you've implicitly accepted that the variance (i.e. the average *squared* error) is the right measure of spread.",r/machinelearning,Z0FBQUFBQm0yeGI1Q1kteUJMYXpVR1dmdDItU09pZ04td2R2QW5DTmkta0VvdEd5eXlfd1VCMW5tdl9XdnZMVHdKU2ZuUVk1LUtLQVBpd2JidjVaLVlIZTJaaVphQWI3WVE9PQ==
I've submitted an issue to the clip-gaze repository about this,r/machinelearning,Z0FBQUFBQm0yeGI1Qk1mOWV4cU9mbVF4ZEF5UlJnc1RZcGpFcFV6Tm5XTUlTNC1IOGY5bGpmS2dqclYwNms1M1ZnQ084aU5UVkIxZFlzQXNGRDNMS2JpdWd5STIwM2J3TGc9PQ==
This is a brilliant illustration!,r/machinelearning,Z0FBQUFBQm0yeGI1NXA1MWdveUhUUnVLa1o2UENJSnZKekdULWpSQVI1MmM3U0R2UWZlbFZ2OG85STF3MnQwMzJQVGwteFdIVVhQcnRLUWRNNEx5dm05WnhPcVRlVUxLQ1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1aFAxR3lQcHhSVEZLeXJMQW9GbHc3NmUwcmw4bk5Lb2h1X3gzSG9pM2RPYWtkYWpuNjlqNl9HNHNPNTQyWERSbnRPTTY0enBtZWdFY3ZKWUxHYW1JY2c9PQ==
"Hard disagree. If the initial reviews are marginal, then having additional experiments / boost in performance can help to nudge the reviewers to raise their scores. If the reviewers are happy with the  contribution of the current paper, then great - leave the paper as it is, but now you already have some progress towards an extension. Delaying working on this next step doesn't make sense, and wouldn't be what's advised in any lab I've been a part of",r/machinelearning,Z0FBQUFBQm0yeGI1VW9GdWpvY2tOeEtUY3dxVDdiWDBwZWRDTUdNbloyYWlZVXNLTlNJM1hmZW8yaU13YlFLcFJydnVnaEFOSTdOcmkxWHlFZWVnSXgtWWRDc2RpQjdkNlBmNUVxRmlGbGJieUcwSmpfR0NfTWc9
I retract. You make more sense. ,r/machinelearning,Z0FBQUFBQm0yeGI1UGxrSlJ4c1kybUk0b1hkTXZFSmJUNVRpOWhXSUx3N3BPdDBjaFVJb1dXcFRNXzVLOUg2bjBvb3YxOEotVzhLeE83djdXSkt6dTdfclpwU2ZGZU9UMi1hcFdDS1RiSUJYQTNCNzdJMkJjZGM9
You'd first have to prove that training a model on copyrighted materials constitutes a copyright violation. This question hasn't been answered yet.,r/machinelearning,Z0FBQUFBQm0yeGI1VFR0ZDdMM0VQRk96UW1panJHbndOVmxXVFZQSFh0X1RKZ09waDV4RnlVWktEVDhaUVU1RS10VVdnVGRWNVZIQ29nbWo3ZzdfYTZZRWJkbFQ3Nm5ZX0E9PQ==
Mean absolute error corresponds to Laplacian noise and a Laplacian noise assumption can be more robust to outliers.,r/machinelearning,Z0FBQUFBQm0yeGI1aFNiekZoTlNnUUIzWU1IVEhSQVBrN3poTjRzdWRkaTZKVFFNem15MlNod1o0dFNRaEQ3UmFKMGFxaEFqRkZ5bWFuaWthUUtndV9za0VPNVRISmRDeEdwb3NKTHNTbElxXzc3X2U0dHE2dHM9
Which lab are you working in?,r/machinelearning,Z0FBQUFBQm0yeGI1VzlpcW9TMHZGamxvcS05N0M4eDBpOUpNWURQMFh4TzdadGRiZEVHeGVMaTBmS1dIOTdoVXE2RFpvNGZ1Q2dhdXRnQ0lFLVN0ZHE4Q09wNEMyaHM0ampRUUJUbXFpZkZvWkt5ak1TQjFOT289
How could I possibly do that when you have avoided defining what a good or bad reasoner in a way that puts a human into one of those buckets. It would be asking to kick at a moving goal posts.,r/machinelearning,Z0FBQUFBQm0yeGI1V0ZKWXYzLVJMZWJPRmlYZ0FxdWF0eFBYTUdjLXBNRWxRUHc0bkFyWG04OE9LMVlNZXplZjZKblBuYzhteUFrSFNmUEFWTzJDVFl4NHZGaEFodk9fS1E9PQ==
Is smooth the right term? Doesn't smooth just mean that the derivative is defined everywhere? I think in order to have a decreasing first derivative you need a smooth second derivative that's 0 at the minimum,r/machinelearning,Z0FBQUFBQm0yeGI1UzNhRnNVRnVPQ0tMb2pQb0E2WlQwZU5zRmkyWS1rZ1MxeThGbEptZGlYZkF5SlEwRmlxZ1Q3SWVZLVhJYjU1bkViNFFkRFdhNXlsdEl2OXZ5TWxIVF9FTW81bmw3czAyTlZURWVWdHdmaUk9
"If I cough up code identical to someone else's copyrighted repo on Github, I'd expect to get called on it.  AI should be no different.",r/machinelearning,Z0FBQUFBQm0yeGI1S0V5dFpLbWNKZW9BaGtVSVQzTmpzTF96QjFVNzN0WEthVVNCa0xFS285R1pDZ1k3Sl95QXQ3OXJKTmVudkttUHZTNlMtYXdyUzJxLTFHTlozRmpBVUE9PQ==
It's the vote momentum on Reddit?,r/machinelearning,Z0FBQUFBQm0yeGI1OFBsanZ4Q2YyZ212bEF5QUNKaXlJdTczeUFfY0NraG5hdjltYnVEZG5Td0JGMUVLb210RldCdlAyRlYyUjE4VGJabUkwZlVXTEw1RmN5UXZvUjhTa0E9PQ==
"That wasn't the question. It was about TRAINING on the data, not about reproducing it.",r/machinelearning,Z0FBQUFBQm0yeGI1d0FtbWtfbXFtSzVKNHRYMTZHZUdmMEVFSlNUeW1RZjlQTXFrNnJPcTM4aTM4aUhhcG1zS3E5d0tYT0tGUUhCcU1nc08wcjNwRGplRlBDT0ZZLUVUUWdPa2hEdDFtdy14a2tiNGNBWmM1aW89
"Squared error gives high priority to high difference in actual and predicted values, as opposed to absolute error, which gives same weight to different error values.",r/machinelearning,Z0FBQUFBQm0yeGI1WlBYZWRZcG4tdmtick0xaUloRFRqLVV4anBmSWQySk55STYxZW9ja3pzSDNSeHozeFdnN3hRV3pkajFYa2VVZFlGQ1A5QThpdTJuajZhVTR0Vnl1b0E9PQ==
It is just task dependent use case.,r/machinelearning,Z0FBQUFBQm0yeGI1dlYteVFrd2FtTkZDUEVob2Q1dGliSkhTSzh2YkJWQ3F4LWE2WHV2d3RLMGlTbThfdmYzYlNZRlNESXdLWmEyc2k1bkFobmZEbF9IZ1RqT3l0OUVULXc9PQ==
"You  claimed that the meaning of my original statement was clear enough that it would draw criticism. If I had said ""pink elephants sing butterflies"" and you said: ""People in r/Dune would hate that you said that"", then it would be reasonable for me to ask for evidence.

I'm simply asking you for evidence of the thing you said. If you said something that is meaningless in the absence of definitions, then I guess you shouldn't have said it. What is the point of making an assertion that one cannot back up with evidence?",r/machinelearning,Z0FBQUFBQm0yeGI1V01KQUx1ZHk2dkx6dEhKQWVfR3JuNlJIMkdQZEV6ZTI1R1BQVlZUQndIbnFpN3YyWW9QV0xmRVFOaG9yUThQbm1JeDFRS1BwVzZ0N2pOZmlTQ2RJN2VFanhTelB4WXdFaDE2ZWp4cFhVWWc9
"Thanks for all your advice, everyone! Think I was underselling myself a bit. I'm so averse to hourly billing that I opted for a project-level estimate. Hopefully that won't come back to bite me in the butt.",r/machinelearning,Z0FBQUFBQm0yeGI1SWdMRDJxU0xuRkd2YmhXMXN5eEpleVlGN0ZRbEpHazNyeHU4aXg5NDZLMzJQNHZZYzkxWTA3WUFGOWtVWHdzajRFdmFZRm9ITF9VSVJRYlhJR0kxbFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1QllwOTMzcWpucGM2VTVMdGtWa3ljSXVCNER6TTViQUdBZW1oQjF1ZW5ObFd3d3dxMElWNlY3LUEyczVjb3lyVDZOS25CYTJRMnJ2eHE2bzQ1MHhtYXc9PQ==
The OP is about examples of the model generating images that are similar to copyrighted material. ,r/machinelearning,Z0FBQUFBQm0yeGI1cUtqWTlyWkRfRTc1Y2JrTHZFZnU3dFA1OXFjVG9TcGh4RGxTNi1UYU1YQXZBWnNleC1pUjVubFh5WE55cW9lT21QRkN6XzZHQW1DaHBlV25sSmtkYnc9PQ==
It depends on context and author. It can mean a function is differentiable n times for some n or even infinitely differentiable.,r/machinelearning,Z0FBQUFBQm0yeGI1Zk9Oc2N6WjJMSnM4cDduam0yby1PbWp2TUpNa1ZqUjdyV2lxTkRJakVFYkE1UFlfRDFFdFZPS3FELVFBNGRwT1dPaENsQnVpeGFmTUZUU1kzM0JHanc9PQ==
I got 5/4/2. Confidence 3/4/3,r/machinelearning,Z0FBQUFBQm0yeGI1TXh3VGU3UUZsNHUxdV9yeFQxT1FNSzBONU9rczFUX2xrSzJ3TjBYa19DTFdfT3hRcVJwNndpRGRTVDJoeWVLb3B5eTN5XzhXNUlJaXVDU3dZOFFLSjlCSmF3Y2JXb214bHNvdTNrVFVNSk09
"Honestly depending on the problem it's usually worth trying both and see what works better.  That being said, squared error gives higher gradients/more error signal for outputs that are more wrong, which is desirable -- why give the same gradient for something very close to correct as something very far from correct?",r/machinelearning,Z0FBQUFBQm0yeGI1ZllOUl9wX0JXaVZRSnV0WmJvb3d2ZzVtR1VMaTVBa2pxNWdGV1N2WVE4bnBlMVRvMUFNOGRscEdtU3hHcHRRTDVOV21QNWY0SS1nN1VLRU91a25CZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1UUExMXhWUnFRcHE3MFVjZllwZ2UwUThKNXV0S1FtMDlITXRaaTdMVUxhSjZjRnRBc2pueHVoS2JoRGMtd3VhejdfWGM3UVdFVEZfYklKQlJpNW05Snc9PQ==
"I gave evidence in the reddit link , even explained how the inference worked, and  you just moved the goal post. 

>Also you previously had no issue with MLScaling is a bigger cheerleader and cant see how if it applies for the less rabid group it applies to the more rabid one. Not being able to make that logic leap is obtuse",r/machinelearning,Z0FBQUFBQm0yeGI1c2FCTXYySTY4RktUdEFxeGt4ZGpkd0hWVjNPWXpxNVRqUDMtcTZLeWRBblJNdlQyODdHU2VYVXlNazhKNjJjTlRMUlV4bUxxLWptR3hmQVJJVmM1blE9PQ==
"Wanted to add, L0 can also be interpreted as Hamming Distance",r/machinelearning,Z0FBQUFBQm0yeGI1UUl2SnZtVmJrcGcySG5yN3JRX0pCdmU2bFBWQkxtV1YwT1R6d0xiMGpRLVpycldFNUF4bWhXTktTMUdKOWRscU44blloQzhEOXh1ejBreU1VdEZqeUE9PQ==
"If you take a single model and run it on two different pieces of hardware, shouldn't it perform identically?

If I take the same NN model and run it on two different GPUs, I would expect the same outputs and, thererefore the same accuracy.

Maybe I'm missing something that you're thinking of a specific example for?",r/machinelearning,Z0FBQUFBQm0yeGI1N3RnMjFfaXMwWHBjd0dVcVB0VTRlZFA3MlVHekNRejVSa2w3Ry1YaUJkS1NRYmlVZ1Yxb0NvdTFzQWIweWk1Mm0zdV9HLUxIamU4RzdUVHlqcUpRTEE9PQ==
"From my understanding, different devices can have different precision of computations (32-bit, 16-bit floating operations). Consequently, at least a slightly different output can be expected. Therefore accuracy is influenced by the hardware and can have different accuracy on different devices. And due to the slight difference I would say it is pseudo.",r/machinelearning,Z0FBQUFBQm0yeGI1UXk0eVp4d3ZaanRSSkRSdE1oZkFENFBONDdfZ0xkRVdGdW9kTUJ6VEVPd1hNUm5GVFV0RXRweWJ5T2tBcXVrWVVFbU9abnZKVExITFhJd2ppYUk0dXJwaHhPSl95WXVaTzNVQnpwRmxkcDg9
Are you locked into tensorflow? Torch has better documentation imo for custom optimizers and loss functions. To me it sounds like you could achieve what you're trying to do by writing a torch optimizer with a step function that takes in your calculated loss as an argument,r/machinelearning,Z0FBQUFBQm0yeGI1Z1FZdl8xbk9tT1ltdGtPMFpza0RRdEFuVmoyWkNNbEMtdW5DWUd4MTJTQV81ZTc5cGRtWHZodHlUMGtLTm5YazlqdVktVkdJX0hWN3FMTkNGZ094VkE9PQ==
Charge 300 and hire me for 85,r/machinelearning,Z0FBQUFBQm0yeGI1U1dzM0hzQmVvTG9XNTM4c05lY1Y1SE14U1RQbGJITnNSWUxaTnBocFd6bGRFcnhiZlFiVkhmNjBKRnZLYkhncE15N0p4YlNuNHNpN0pCWFFkTWlMWlE9PQ==
"It's pretty obvious that all of these models have been trained on copyrighted materials. For instance, I can ask any of them for an image of Superman and get an unmistakable representation of him. The current state of copyright law suggests that the onus falls on the user to not make or distribute copyrighted images, whether AI generated or not. It's less clear whether or not these AI companies are violating the law by training on copyrighted data.",r/machinelearning,Z0FBQUFBQm0yeGI1UmV1TzQ0LWJTWDBHRVR3eUpUN3Q4ZDBxcmVnRnNCUmtQVmNid0JfVnFGZXhQWENvSVVOM2Q3UlowTEk1bjhUQnpfZnRYdk9ER1lKUlhCRi1ocU9QdUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1SDVqTWpkelF6clBrdmlSQ3VtS0J0UGQyVkJ6ZXlBSTJLWXpCWDdXczM0RmRkRF9KR19ISXJtUEw3WFB1UGtPOFhWMktmNlZRT09fRjk4ZHBRenRzYWc9PQ==
"Take the log and what do you know, it’s just regular regression problem again. ",r/machinelearning,Z0FBQUFBQm0yeGI1TW9NMEMzQ1RvaktFbWFjeVh3RnRYS21UYldLZnFmN1JqNDNhblNrc2hfdW5weHV4UWZ2Zkx5S0RyZjJXXzFOb1RmYUpqV3ZGZmhqNlh6Yk15S2xCSGRlalNvNDRCekliZTZFeEh5MmpLaHc9
Just?,r/machinelearning,Z0FBQUFBQm0yeGI1cExwX19uN0M3Q3Y3cldraG11RVVDbmtFdHBDeTRxell0REJHZnlNbG5mbTRURDBCdHN3UlFWU2tTczVjZDAwdzFIaG9ET2xNeDl4ZEh3NDNuWWxJM0E9PQ==
"You'd need to do some prompt ""engineering"" with a system prompt which is ises to instruct the model on how to respond. Be warned that absolutely nobody has been able to get this working completely reliably and any determined enough user will be able to bypass it.",r/machinelearning,Z0FBQUFBQm0yeGI1UEVuazMweHpkM0lZWk10S3ZSRnVMZGdGbWc4Rno0TlNxcWlJenctVlhJUXRHczgwbDliLWxZTU5tRktJUGNKc3pEb1dEa2hIZENIa3l2MmdyOVgxeU1pb2lzdmcyekFMbi1YOHVnS0l1MEE9
If you change the precision bits you are changing the algorithm… functioning hardware should 100% deterministic and give you the same results across devices if the algorithm is the same,r/machinelearning,Z0FBQUFBQm0yeGI1cnloVGpucTNCNm9yMzRjQTV5WWhvRXF4TnVXSmRsTkF3NldjWWlkeGktOFByRi1FNnZCeEtVVEN4RVpqY0Qycy05d01oMF9ZbWxmb0RTb1p5d3dWX0E9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI1M1BSZHFWdXFoSDRJVzJyWVJTTTUzSlplR3duZ09LVVBsN3hKN3VTU2xpQ3VlT1o5X0c5cElCRlFzdVIyZ0VRaVZDMEdidUVyczZHdXNMYy1ZaUNNV3hzQ2U0YkdZRGdWbFJaWkhjRDlVNk09
"Squared error - big error -> big correction (derivative is 2*loss)

Absolute error - big error -> same correction as even if there was small error (derivative is a constant)",r/machinelearning,Z0FBQUFBQm0yeGI1b3NOYXRlbWVKVTJMVVJVQ0lLbXFTaW5kdWxrRHliektIdjhWNnFhZWtXQVVwVVJsWm5JYkgzMHNuU2k0SDBzMFpHZWRuZW12UC1DLTFzVmNOMW1uXzVRLW9vaVZiNmw1UWZlTThrOFBEUlU9
"I don't understand. The precision bits is determined by the hardware. FP16 can have more rounding errors and higher quantization than FP32, no? When they accumulate during the operation time, doesn't this lead to a degradation of the accuracy? If so, I would like to know if there is a significant difference in accuracy so that it isn't hardware-agnostic anymore.

What do you mean with ""100% deterministic""? You can always produce errors with ""functioning hardware"" regarding floating points, no?",r/machinelearning,Z0FBQUFBQm0yeGI1REdEODFMTXFRVHdJZ0s5clFxeVhfLVZ4b2JRbFY3aXNGMXozNXlhejVUZUJWSHJBUUlQZ2R3cjhMMTVGZmhYQWF0bGdxUzZvODdRelUzQ1gxanIwV0ZlUFdWVVZfcVVBMzJrWHFSZWJtcHM9
"Labels are not as important anymore because of the new Nvidia chips. You can now setup a maker-critique  model, set the unique linguistic rules and loop it with raw material. Should be able to infer from base models. I think you are just pending the country to buy the blackwell chips. A private company could probably also do it if there is enough incentive.",r/machinelearning,Z0FBQUFBQm0yeGI1SllNOXhrWHlTSm82SEIzSFhiTmFqQ0lyN3NGTnVYVzhhTXhwcDhjUGh4TFNGLWQwd1FfMkhZamFDREtyb2NiREpVcmhQekd0VHpaYjAtN3htOEVBR3c9PQ==
"I think there is always going to be some minor non determinism when running on a gpu but I don’t know how much that would affect the overall answer in the end

Because floating point addition is not associative due to rounding errors and a lot of operators using atomic add with cuda where threads might write to a sum in different orders on each inference we can get slightly different results",r/machinelearning,Z0FBQUFBQm0yeGI1YnJNc242VWRqeHdBNWgxcGp2VU9lVlpYLVBvS2JBRlVaNURqam5sMmVEeExQd2dIV0xKTERIRk9lX2dpNFVZVjhERmpFLVgxX2FXX29DRnV4dkY3aGc9PQ==
That’s what I thought too. Do you have recommendations on papers that analyze this problematic of accuracy?,r/machinelearning,Z0FBQUFBQm0yeGI1ZnVMY3FUZHk5OXR6b1RVWmEwWEZhcVk0bWpDbDk4V2U2dU1MclFkam1BWkxJY2lnTVFDd2d0YkhxMXlSWFZHQzNYbnV1QWxSbHNnb3JMNVRfZ3BiMW9yaml4bGZTbWdLU1k0SlJrTC0wQVE9
I'm pretty sure it was chosen in the pre-calculator days because it had convenient mathematical properties and it was felt that large differences should be weighted a lot more.,r/machinelearning,Z0FBQUFBQm0yeGI1dXc4ZHM5d05DRjNGeURzZDNoNFNPcF85R0RTTXFlSzU3bzNDaE9nUlZlZDNVSDA1dTRxenpVcHdEYzZ0d2IzLVNfVmFnRXk3aFNFNjN0QnJCdG9VTFE9PQ==
"Precision bits is defined in software. You can switch between them in numpy, pytorch, anything.",r/machinelearning,Z0FBQUFBQm0yeGI1QlJobGJRWDRtRWN4T2FrWGdsZWF1RHBpN0RiWERUM0M3bFpKOWV0TzcwZjNVUFRfNUVLRC00OGtKVktrOEdVaTdrMXJDUGZpSHRLOHY3UURmT1c3Qmc9PQ==
Add me to that list,r/machinelearning,Z0FBQUFBQm0yeGI1eHphM0xrS1pxaUVtc2RzSi1sd3BUdXduV1pmMlI4OVJSNmpDaVFqZHhveVQxejk1Y05wZlhhcUp4bjVZTmNNRVlrZVcwcFlaYmhhcHFuNUYzaWU1RUE9PQ==
"Please quote the SPECIFIC COMMENT THAT YOU ARE REFERRING TO. 

Don't link to it.

Quote it.

The specific comment that provides evidence that someone would dispute that today's LLMs are poor reasoners.",r/machinelearning,Z0FBQUFBQm0yeGI1d25oRGZkV252LWpkLXd4LS0zNzlzRXAzTkI4Q2NTVXNmTXNUa0NGekpBbkMwXzRETklNbmtKT24xYk9MUFFRajVGLWpSOVlRSnBFV045b240LU1Yd2x1TlRDM1VOZkpaTDZ3Y25YbDc5MzA9
Me to,r/machinelearning,Z0FBQUFBQm0yeGI1X2F0ZlpndjY4ek9XOWpNTjZ3MFlGejlIU0JNS2JGV1ZmaTZjMG9zNkdIbERtNGp5dVB6VkRJTjdlaGZRTUpIS2Ffd0hlZEU0S0l4TGR4QmlaeVdQbEE9PQ==
👆👆👆👆👆👆👆👆,r/machinelearning,Z0FBQUFBQm0yeGI1Mm55Vkd3UFZod2FQSTFvdXpGd3VlMFdYZnIwaUNoRk03Z19fcU84dnFZSWV5cEwyNmptNDExQnhUY1BQVWFzV0k5LWZ5OEozWE5vWVR1OGUxYkRzbUE9PQ==
"The question in the top post was ""is TRAINING on copyrighted material illegal"". The answer is unclear at the moment.

If the question is whether REPRODUCING copyrighted material is illegal then the answer is obvious. Of course it is. That's the whole point of copyright. Of course if it falls short of a pixel for pixel reproduction then some gray area is re-introduced. But in general, reproducing copyrighted materials is illegal. There's no interesting question there.",r/machinelearning,Z0FBQUFBQm0yeGI1WFVuNXVyYmMxLThDSmlJbVlZSVhWVFhyN3JDeE1vbE91aUpmVDdFeDEyaGhHRjgzeDFkcHk1VC1TMEJkUkMzNmFBOUdpSjN1c0dra1ZnVW00TnhHT2ZzQlRaczE5Z3lKZzl4X1g4ZXNkMHM9
"r/ChatGPT , r/OpenAI, r/LLMDevs , r/RagAI  are all more focused subreddits on those topics.",r/machinelearning,Z0FBQUFBQm0yeGI1V21aRzVLcFFQQzFpYUdwS1I2M3g1S09pZ19XMEdyZWRuS0swalRwYkpuMllCMWU0Mm1lZUVFNjRFVTZVR3NmSXBtOTFJa0l0U1NpZWp5TEp5Sm45eVJOOTNzR1M4WVhtRXI2NWJLQTNPSG89
"I'm trying to find a funny video of Ruslan Salakhutdinov describing why you should use a dropout parameter of 0.5. IIRC he basically said something along the lines of ""otherwise, you'll have to justify why you chose that particular hyperparameter, and you don't want to do that"". I think he was speaking to a class at CMU and got a lot of laughs.

Can anyone at least confirm that I'm not confabulating this?",r/machinelearning,Z0FBQUFBQm0yeGI1TmNwcFAyc3Zzdm1YeEI0Ul9TTG1fZUxKMjVWaE1haW1QZ28xeWNBMm50RWVKaVNkSkpQcEtmR3B0UndNM0gxWHBUNlhGZzNmUE5PZE1zNy1QODNIWFE9PQ==
Drop it here!,r/machinelearning,Z0FBQUFBQm0yeGI1YjVRTlkzQkw1VHdGWlFpTllPOXFCa0NNOHotQkxmQjFkeVVnVmZNLWRaYmRzYXJBZlp5Q3N1MGEwNk0wbHVhOG5Db21XcUhLSnZqMld0N1c2dUFHS2c9PQ==
It is such a tiny difference that almost nobody cares enough. I'm sure a paper exists somewhere but it probably won't be very useful.,r/machinelearning,Z0FBQUFBQm0yeGI1eUNlQVVXcFQ1VE5mVTNENUlIY1hIZ3RwM2Q2bkpQMmdTMlFiMkgyNHFIc1o2UUVGdUVkOFpYcnZGY0RrMlItaDVDWlhqOU8yaTdRcEtzR3F1dno0V2JhUWtuUHhhYU9OLWRieEcySVNVajg9
"Let me put it another way. Say you try to hit a target with a bow. If your first shot is 2m to the left, would you correct twice as much as if your first shot is 1m to the left?

If the answer is yes, then you use MSE.

If you would correct equally, you use MAE.

If something else, then you use a different error altogether (maybe a Huber loss?)",r/machinelearning,Z0FBQUFBQm0yeGI1QUNiRklPVkgwV1U5T3lya01iXzhyRDJLVVVnRzZOUFR3b3VueUVnQk12bmo3OW9QZWxidU1aUUxURDZ0VUlUR1N6U0RuMEt5Wk1IUS1CWThUNjhUdXc9PQ==
"Are you looking for analysis of accuracy with respect to hardware? Or are you looking for an analysis of accuracy with respect to precision? Those are two related but still _separate_ concepts.

100% deterministic means the same thing happens every time. If you have an arbitrary model that always returns `4`, and you ask it what 1+1 is, it will always say 4. That is 100% deterministic regardless of the fact that it is completely wrong.",r/machinelearning,Z0FBQUFBQm0yeGI1U2kwRTU5bGJoc0pLaWtyX1lSV3dsSi1ZaE01OHNITlZvcU9TOXZyNEhsZHZzX01UTkw4bnFKdC1FQTJUMlJ2ejZJd2V1ODZqc1B5VTJjdS1VWk5mZEJMLWctNlV2TGRJaEhvYnlJMldQX1U9
Machine learning models aren't specified with enough detail to guarantee that's the case. The whole ML community basically operates without guaranteeing order of operations so results are absolutely going to differ across devices.,r/machinelearning,Z0FBQUFBQm0yeGI1bUJ0QkEyY0RqUHRHUXR6NnJzM3djVElEcW5lWExWcEtObXNnM3QxWVRnT3Z5V1BSdEpCcWx6YW1lcGQyOE5NbXBDcy04MWRKOE93Q1dqQll2RHplWXc9PQ==
"Specifically, I am analyzing hardware-agnostic performance metrics for constrained environments like smartphones, laptops, embedded devices.",r/machinelearning,Z0FBQUFBQm0yeGI1QWVCa0xEdFlOY0x1SGFWaFJGX1l6NFdIOHVldUJhVE9XTjJoR2R0algtLTZLWFlCYVRQUjFtZ3YtbXVGdmlLNjVYejJuWkFVa1BGYlRGWFJQd3FQY1hnNWlSX0JpUkRqcldHV29GN3FhTXc9
Showing up a year later so I’m sure you’ve got the answers already. Seems like ZK-LLMs are popping up everywhere now. How do you feel about the current tech? How do you feel about projects like Based AI? Does layer 1 blockchain networks that host ZK-LLMs effectively answer this problem?,r/machinelearning,Z0FBQUFBQm0yeGI1YUtjbkh2Rkc0U2FSN05IZWNmZGt2ZFRKdmtwVjdOd3ZCMUpKMndBd3lqUTZoZ05xQVBNV1JxNTVRc014blpDYUxRZllqVVVuNkF1STQ0ZC13bEIxV3c9PQ==
"Are you assuming this with the exact same software, libraries, and floating point precision?

My thinking is that order of operations is largely determined by the algorithm and software itself. I consider things like FP precision to not really be ""hardware"" related.",r/machinelearning,Z0FBQUFBQm0yeGI1TkFSWk90WklZSk0yZTc2YU5fU1A0X1Z5d2tQSFloWXNNaFk1eWpDaUpfUDdoeWZqSGdPOHhjdjN6WWEwUjduRVFJQWhVMWlOem1EaGdjT1NQekNMa2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1WWw0bS1TekZxZ3NsUnh2cHdqU2hwS2dZTmtfYjlZcU00REFRZmJoNm5TV1lNMU1uQTFxcmdIdUw3VXBBZDh4S2M3R3hfRFhqYVlTc0RpejZqcEZFN2c9PQ==
"If the different hardware environments use the same model, the hardware-agnostic metric such as accuracy will be identical across the environments. If the models are not identical, then you shouldn't care about accuracy with respect to the hardware, you should care about accuracy with respect to the model.",r/machinelearning,Z0FBQUFBQm0yeGI1YmxBV2diMDEyREk3Nld0NTFubDNwMVlwZzhDX21WVm5XS2xmUzZveDdRc1ItNUx5ODlTVks3X3lZcElGdEZVWmdVVWpFYjlkOUFTNTlWc094UWl0ZEltb1ZNbDkxUjYwRVdDeVg4X1RNalE9
"Ok, thank you. I guess my concerns weren’t valid then haha",r/machinelearning,Z0FBQUFBQm0yeGI1WEdBQmpOaVJFSDMtZmZCd3VGdHI4VjFvR3hDWENQeFpSNlloa2JxcWN2T2s0dXM4V3RVSmtPa19DQm9QbWF1QUFWRXJuSUJfZ3FCc0RPdWRaS2JqaDA5ZkZqaVVHVGlRMmRiQjRXQUhkclk9
Definitions of pure maths are regilarily bastardized and/or ignored entirely in machine learning,r/machinelearning,Z0FBQUFBQm0yeGI1MkZPVjhmSDdHeDhXXzJjRTJuOUotdEwtRlpodm5GdVI5bmtzOXhGTVQ2TDNPQTZfX3VPa3R4SFlWR2xDeHFZbGZNX0ZNZ19pMzR5ODlpdmdHd3pWNFE9PQ==
"It may restrict you from jobs that a PhD doesn't help you in. That is, jobs that are more engineering heavy.",r/machinelearning,Z0FBQUFBQm0yeGI1Uk95T3ZHRmZZa2pTQ0VZamtnREtBT0pmUC12NV9NVTRIZV9sRDRJNDRZOEh1akNMNE1SSzAxSUQ1T2FLb2tfbVlYZUFza0IxQnRjVXQzZ0RpY3ZOU2c9PQ==
I have a PhD in physics but have been doing ML research the last few years ( and applied ML research before that ). One of the biggest challenges I face in interviews is the hiring managers concern that I am too theoretical.,r/machinelearning,Z0FBQUFBQm0yeGI1WER4bFZ3MnJnelVuaF9rT21URWc1cTBZLVBoWVJJS3NTTlJTTE9tbk4yNHA4YVRYTlZTUlVxSHFZOEF5b2dIaGh5QkM1X2ZYb0tiY3M2bVNzaC1ROFE9PQ==
"Just keep in mind that the same model may not be _capable_ of running on different hardware. An average modern neural net is probably too big to fit on a phone, so you may have to e.g. use a quantized version of the model. That quantized version _is a different model_, so it will have different accuracy. But it's not the hardware causing different accuracy, it's the quantization.",r/machinelearning,Z0FBQUFBQm0yeGI1RXFkNGhlOThIMGxoeVM5dXRqOVJJWENYM1FueURtY1ZrRUFfYTFiNEtEVF83SVJCNHJfQnh2QU1CMTVHaFJ2S3JYR0Y2U3oxaHl3ZmlBOFZFOVRHQVphX0QwWkhkMTFkbEdRZlVCaVc0WkE9
"Also, if you take the average of a set of numbers, you are minimizing the mean squared error.",r/machinelearning,Z0FBQUFBQm0yeGI1TFFxQ0gyVXYzUjZnczZZY2dVUFFMbVpfZWhoRGNrUU1fT2ZudDhLQzhMZDVncFdfb093djA1dC1WSGk5NDBnUXVPeWpWQmFRRm9rUkZzaVV6V2NGY1E9PQ==
It's regression problems the whole way down,r/machinelearning,Z0FBQUFBQm0yeGI1bU10TlBLQ0M3NmliWW9TazNfNG5wNE5DdkY0QUhRQ0d1d01kRThSWVJLX0hUY19JOEV2bjZNdVFzaDVBY1NERFd0ckZZTDVIV0VxY3JSQW5oeXZRVkE9PQ==
wat,r/machinelearning,Z0FBQUFBQm0yeGI1Rm9pUjczVFllR3h3bUJkcU9Ub2F5aWhYWkl4REtxZHlyWFo1aERWZUktaFhrQkg5Q1FhUDI3SG1OUlJnZUlXeVM1eURua0Q3SjRRUWZPZXpEQXVIR1E9PQ==
"Lol sorry, fixed it.",r/machinelearning,Z0FBQUFBQm0yeGI1amxIWVlEUGpvZ0pkeTU0RDFrWEVHbGZDeWxIanNPbTNydkpxaW5VVmdSOFkyeEVDWmtRekJpWUVXa3VPWWl0QVlRa3Uta1lyNWJKUmZFMmRtZjVBYXc9PQ==
…and you have examples of this or know this because?,r/machinelearning,Z0FBQUFBQm0yeGI1WjlyZlRTdEt4RU43cEVTRU80VkNBaDRxTnc2ajJRc1ZzcDNHMTU3ZnZqbktzRFR5TXBEWF9kQU9SWG9KamI4MHpwcUI3dmNQV20tNDF5TzJVNXNTZXJLSUt4eEhHU3ZfcjJpVzJjRkhFbTg9
"Common sense? For example, why so I need a PhD in ML to be a backend engineer? Or a custodian?",r/machinelearning,Z0FBQUFBQm0yeGI1ZnVUcTBBOUl1aWpLTHYwSl9ibm5Lb1pkY2RRNEY5XzNfVXc5VzZOaDJmR2d3WXloZzREVXdsQnJ3WWhCMTExRmZYTm5ZU3FCbGlreE5UcldTRE9rMWc9PQ==
"I said this on another comment.

The average of a set of numbers minimizes the mean squared error between the mean and the points.



I asked ChatGPT to write a proof. This isn’t *the* reason MSE is commonly used but it is related and the proof may give you insight why.

---

The average (mean) of a set of numbers minimizes the mean squared error (MSE). Here's a proof:

Consider a set of numbers: x1, x2, ..., xn. The mean (average) is given by:

mean = (x1 + x2 + ... + xn) / n

We want to minimize the mean squared error (MSE) with respect to a value ""a"". The MSE is defined as:

MSE(a) = (1/n) * [(x1 - a)^2 + (x2 - a)^2 + ... + (xn - a)^2]

To find the value of ""a"" that minimizes the MSE, we take the derivative of MSE(a) with respect to ""a"" and set it to zero:

d(MSE(a))/da = (2/n) * [(a - x1) + (a - x2) + ... + (a - xn)] = 0

Simplifying this, we get:

(a - x1) + (a - x2) + ... + (a - xn) = 0

Now factor out ""a"":

a * n - (x1 + x2 + ... + xn) = 0

Solving for ""a"", we get:

a = (x1 + x2 + ... + xn) / n

So, the value of ""a"" that minimizes the mean squared error is the mean of the numbers. Therefore, the mean minimizes the mean squared error.",r/machinelearning,Z0FBQUFBQm0yeGI1ZnpsZktfSDF5RlZISU5sa0Jza2lBcUhra25rdlRCdjRNVnoteDlyakFfdUM5X21EWnlhaEVlTVg0M2otXzNybnRBdXh3dVlIbVpzWjFjblJ1blJ6VEE9PQ==
"You don't need one, but having a degree doesn't restrict you from being a backend engineer... People focus too much on degrees instead of experience/skills. If you did your PhD in an area that requires more backend engineering, for example, you wouldn't need much more to get a job in that area.",r/machinelearning,Z0FBQUFBQm0yeGI1RUVsWE1EclRSQ0pqU1BwQVlxRFZYUnl1VlNSSXFyV1I1UjB1d2FMbFc3VkZLRWZoZVpHMkdOeWFMQVpyTjRqakppdm56VXExZkVVXzhWbjRpZFhZZWp3Q3BiRWxQc3JUczJ6XzY1NlJ1Smc9
"Perhaps I misinterpreted the usage of ""restrict"" from OP. I didn't think they would mean actually bar you from getting the job.",r/machinelearning,Z0FBQUFBQm0yeGI1dzFhWFpWXzZiNE5tV2w1emFhLVVscmlaUHMwTUpIRHBIUUVCMnFjNmZmeGxma2NWSnFDN2tPbG50RFYyaFcxWDlxWG1aNTRrMnVDU0tZdkgzYktod1E9PQ==
"You said ""That wasn't the question"" but if you read past the title it seems like the main point. ",r/machinelearning,Z0FBQUFBQm0yeGI1ek5HOGhTWGE1VkpraVo0bHE2MkFZdy02MzFTcmE1YnJDdjJ6MzFGX0ZXUS1sQVpfTmxnS3J4bThxODlwZFoyNlhtRUtubWNCeWg0Q2JkTDNienktUkE9PQ==
"A PhD will almost never hurt your chances of getting a job. The lack of other qualifications can, though (e.g. not having an MBA, lacking experience in a certain role, etc). Doing a PhD carries with it opportunity cost in that respect, but that's true of any career choice you will make.

The only negative thing that I've ever heard with respect to having a PhD is some people saying that people with PhDs are ""difficult to work with"". There aren't too many people like that but, if you happen to run into one, you can safely regard that attitude as a red flag. These are usually people who have spent their entire careers in private industry and who have only ever seen ways of making decisions that are authoritarian and/or poorly thought out, and they become frustrated when someone wants to be more collaborative and deliberative in making decisions. If you meet someone like this you should know that the problem is with them, not with you.",r/machinelearning,Z0FBQUFBQm0yeGI1WDJ1U3l6WWNfTHVvSnhmU3RjX1FUSTdrYkhNcnZ1b3ctbTRBQTJIWVVyTkV6Yk1kYmhGYVJaUnByR2JpVjV4Q2gwWlpHVk01OFJydWE4cVFpMmtTWEE9PQ==
What Tao paper are you referring to?,r/machinelearning,Z0FBQUFBQm0yeGI1LXVfUGxvU21ESjRFSFlQa2xUSkFnN21vSVR4VnNKVWxlVG9RRWM2MW9Ec2pvTnJaVEM1M3ZnallHTTcyMHV6STlXa1RveWdaS3AxOUdvNjdLNlhDeW5xWW5qRkJWSEpHRVQ4ZWQ4QkRHOUU9
"If I think about Google search, it's going over all the data (copyright or not), manipulating it into an index, and if you ask for it it gives it to you.  This has gone through court and considered fair use.  

It's an open question if doing the same thing for genAI is fair use as well.  There are differences, some make it seem more like fair use (can't really replicate the original) some less (can't link to original) and some cultural (people were much less concerned about search indexing copyright material).  It'll be interesting to see what happens.

Note that as far as I know every scraper respects robots.txt which is the canonical way of telling Google not to index something.",r/machinelearning,Z0FBQUFBQm0yeGI1ZXpNaUdxWVBZeFQtLUxFMmFGVDVGX0xKYnF1ZUtoNkpDOHJQd2FMUGJ1by1KaDdlTFZGYmtuM2dDSklzV2hydm9nOHRmOEVuTmtqeDRqVXk3ZzRVUkZlaUNkQTJIT21wMU85czhSZldFLUE9
"I'd be shocked if floating point errors actually mattered. That stuff only comes up when you use discontinuous functions in some sense. Nothing in an LLM should have a derivative on the order of 10^7, which is what you'd need to make the errors in float32 arithmetic relevant

You could maybe imagine a scenario where that happens, especially if you use half-precision, but LLMs are typically designed to avoid exactly that kind of thing because it makes training unstable in the first place. That's what normalization is",r/machinelearning,Z0FBQUFBQm0yeGI1NHZhVXRpUzJ0MlViZEl5U0l6M1dubndLSDNSRHJmWlV6cDNZei1hNmxiM2hlQ1JDbUtGMDZOd1JGamVPUXJWcDBkQm9KbER3UjRqbXNWcG5LSjg0N1NVNXNNdk9BVFUzZTR3RWJzMGlwZXM9
"I heard AGI and SuperAlignment are hot research topics these days in industry. It's important that we research and prepare accordingly for the Singularity.

I, personally, am doing independent research on the Worldwide Brain. I believe this direction will be the most impactful over the next decade (even more important than Effective Altruism). I'm just having a hard time making sure that this research doesn't end up in the wrong hands (there are people from the Conglomerate constantly messaging me to get their hands on my Universality Tree of Life).",r/machinelearning,Z0FBQUFBQm0yeGI1djBuLTdjZy1xSW5JOGVjSjhGR2VxSk10M3RHaGcwc2Jfb0RxTGt4T05XOUcwSUU2ci1tcVpna0VBZHU5b3JlZk13RzRuZHdhb19KcTBPUHlRcTdSc0lPVXc1U1RsWWJGa2NwWkVabWNWalE9
"Do you reply that ""nothing is more practical than good theory?"" )",r/machinelearning,Z0FBQUFBQm0yeGI1SElzMXRkQThCSEFIcHBHYXJVUkJnS2JIU29TOThHVXUzQWlpdEZObmZNZ0FpYkFkeTdUbWxGVDl4MUxEcmxkZklJeVh4Mnp0T3FfSkYzX0RIRGZTMHc9PQ==
"It depends on how detailed you want to get, but if you run two identical models from pytorch on two different devices, they very likely won't be bit for bit identical at their outputs. 


On the flip side if you controlled exactly how something like a MatMul was written for both devices, assuming they both comply to IEEE specifications and you don't compile with unsafe-math enabled you can probably expect the same results. But the point is that most of the community doesn't operate at that level and pytorch and other frameworks aren't nearly prescriptive enough to ensure this behavior.


The world is incredibly muddied especially once you get into fp16/bfloat16 (e.g. is accumulation happening at bfloat16, fp32, tensorfloat, etc., nothing in the model dictates this behavior).",r/machinelearning,Z0FBQUFBQm0yeGI1ckJuZFB4RkJpaldmRU9EeWxBbGZZek83dkxZb1h5WjJVclM1NnRMZTdMM2d4cmNYOGZnVXMzbmRUUnQxVWV6eWZuOVIzelllaDhpS0lNSldraXhfN2c9PQ==
"You're asking ""does quantization affect accuracy."" There are lots of papers about that. The punchline seems to be ""it matters less than you'd think, but there's debate about exactly how much.""

If you google that, instead of this nonsense about hardware dependence, you'll find loads and loads of discussion",r/machinelearning,Z0FBQUFBQm0yeGI1RWVQRldNVmw0X28zWnZ5WXNEUXA4TnVUaWlEUWpmRDJlR0RKRnJNWHp1azZfYkpIcWhxdHo5ZjQ1TV9YZzBjdVRWQXRwSFdGNURIZ1VIVXFiVlU3dWtONTNpZHhfc0lrUXFfTHVrWVVkMWs9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1TF9IZ3ZNLWJSWV9rejhXOUpVVDhHS1NudjZfbG05NTU2TllER01EUS1uRW01cjhPSVI5MjNsSzhOYVhxcWYwcmJDUkNFV01QTEh5Ti1VMXQ2Wmh6dmc9PQ==
Sigh I am in the same boat. Having trouble landing an interview so far ..,r/machinelearning,Z0FBQUFBQm0yeGI1Q09BZTY1ZFZmRW9xaUtPVWo4RktZU3Q4Q2ZoUEdwc1RRY1ZpaFRKbWctY2Z3UmxrZlA3cTg4RHNObFRycWN3cEx4NkZZdWFCdl8zakdnbXhidERXdEE9PQ==
apply at openai.  test how good u are with the best ml phds,r/machinelearning,Z0FBQUFBQm0yeGI1Y2wyQW1nZlI3MDZrSkFEZVRXV2RHSkxzaGl3Nlp6WXMxeS1vOVRxbUU4anFNN0dVdW8yTmZoQXFxcnFMWGVkY0tqR3pzQWxsSDVnazNpRjJNLUpydHZ4QjV5Qk1hUTFnUjZxQjlVN2M1YTg9
If you're new to the job market don't despair. What's true for undergrads is also true for phds: the first job is the hardest one to get. After that things will get easier.,r/machinelearning,Z0FBQUFBQm0yeGI1Y1FxdGg4QjNUcXlfb0NpZUJVN1k4cHM1R2kxSTlRMjlvY1hRVkFHdWRZY1daRFo0VS1TZ3BNSE9qYWtDV2ZmSUhYc2lhMWVIVVFhSGJsVWNUR3g2eVE9PQ==
"Other specific subreddits maybe a better home for this post:

- Artificial Intelligence 
- Data science 
- Learn Machine Learning
- LLM
- MLOps
- MLJobs 
- Singularity",r/machinelearning,Z0FBQUFBQm0yeGI1NEpIME00ZmdiZ3JhdElYbjhvYmw1UUdFNHl2MXdzRVZzME8xakttRjFSTERxQnBLQjBwVml6UXduZE52S1JpNHBHYi1hM25zaG5QVk1aU0FtQktVUmtqdTRHWTRmdGdwX191YTBrTEtFbk09
"Probably this [https://arxiv.org/abs/math/0503066](https://arxiv.org/abs/math/0503066)  
Stable Signal Recovery from Incomplete and Inaccurate Measurements

- i/e the paper on compressive sensing",r/machinelearning,Z0FBQUFBQm0yeGI1bjB0Y1lFY05vTS1FUFYzNTNwS1k4V1VwRnpVOThuc3F0X1BIOVlEUFFBWGxhS0pZcUdzTHRUUWowc1BaOGtyZHIwRmVTeE9KVmFjVUh3SEVsMWhZSDJFNk5hNXNjUWUtS2RoOXRuR0dZSW89
"Hopefully this one

*Stable Signal Recovery from
Incomplete and Inaccurate Measurements*

https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/math/0503066&hl=en&sa=X&ei=7_9oZv6uDZ--6rQP8OOGwAY&scisig=AFWwaeZD50VIuJTouQKze4OCwHE4&oi=scholarr",r/machinelearning,Z0FBQUFBQm0yeGI1SERtSDhzVTFCT2ZqOW9qeFMwX1VSUGl6LWp3UHVuZjNydnNJaElWQ0lKc1VhOWpHckg4dXc1cDBzekxxRHR0NXFsN0ltbGV5c1dhMlkwWkMtZ3I4MkE9PQ==
Thanks for your kind words.. really gotta keep the hopes up and keep preparing,r/machinelearning,Z0FBQUFBQm0yeGI1b1ExSllQODNSS2xfb2RPdW5URzhUVnZ1cFlzbFJQTDluWEdEb1RYVjB2SjR5MUlfUXd5d2N0YllMcVhhdWhfcTFrR2FiaTlXRGkzZWg1WWFFLUFXd1E9PQ==
"I think they mean that it can restrict you from non research roles.

I’ve heard stories of PhDs, dissatisfied with research and wanting to switch to ML Engineering, not get considered because employers think they are just temporary positions for them.

I would say all ML research is technically backend, but research skills does not necessarily translate producing clean and maintainable code. These are skills by you usually pick up with work experience. This could also put you at a disadvantage.",r/machinelearning,Z0FBQUFBQm0yeGI1ZGthTTQ4bHljSjZkRC03Zkl5cEF0V3JMZERRS2ctTnZzaDJ0ZHNoakVnZVhaS2pkZTNKOVpTODdIM0U3dHUyRk1TQTQ2d1cyeGtQVjRCUWx4ejdFZWlKbFRRVnVmRXU4UWp2UnlnRXpucVk9
"Consider joining research labs at your localy university, and it can be a significant advantage for you if there's industry sponsors sponsoring your project or the lab. In my case, I secured an AI/ML summer internship at a Fortune 200 company as a first-year college student, and I believe the sponsored research project I worked on made it a huge plus.",r/machinelearning,Z0FBQUFBQm0yeGI1OERYR2QzZWc5Y1VpTHFvVHZfNTlqQ3I1d0Q2bXNaQmlEaGdaalcyOHo1bUxQU0o3UFFrTHN5bVg4eHNESENhVzhXSkJFQkx0OHBCNmNLbjQ0T01HdU1VZXlZWjRLbG5rc3RmN3V3Sk50bzQ9
"So in my experience the biggest issue with a PhD is working with people who come out of academics thinking they know everything or viewing themselves above certain people or tasks. The issue with this is when you tell them that your quality of work is not up to par with what is needed a lot of times they argue or push back rather than taking time to learn how to create good solutions.

I have worked with many PhD holders and when I start mentioning other ML techniques or better ways to implement this solution I generally either get a defensive response or an unwillingness to learn. I've ran into PhDs who don't even know how to use a debugger or how to quantize and optimize their models inferences.

I would not say a PhD holds you back from certain jobs but understand that the other side of the interview table has probably been burned by many of these people. Of course not all are like this but this seems to be somewhat common.",r/machinelearning,Z0FBQUFBQm0yeGI1RG9XV3RNMjZRckRUTWlzY3JnelZwZ2lGOFVyblU4SWtZc1lqMWNSanBLcDMyTk1VcjFBbU00VVFrUlJjUWh0ZVBTQ3pPV3h5SjcyTmU2ZkdTZGV2WWc9PQ==
I would definitely be interested potentially. Can you surface firmer prices for both 4x 3090 and 4x 4090 setups?,r/machinelearning,Z0FBQUFBQm0yeGI1OGFnSmFVd0VyN3lyRmNmUE5RRWJxQ2g1ejN5TGZPTm9NaWRGSVliV1kzajFzVy14Z0NfQ0wxbnJJTnd4WTBYVmRRWUxqWGdPUlhEbDZ6MWpKNGF1cnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1OC1WRUlQUGlzNXRnT1JIN1AyNGp1Z2NvSWtGOWpXcVE0ZlRJcnBUX1JoMjZoQ2pfYmh5bXRLYW9xYTRNU3dvRkllX19LQlJmYmZFVHRZeVhQNjlFN0E9PQ==
I speculate that RNNs with large controllable memory will be hot soon.,r/machinelearning,Z0FBQUFBQm0yeGI1Uzh6Wm1WSjRjd3hwM3B1dFQ5VkJGVU9MTTZER3Vfc0g2WFM5NkZKNFItN0hvSk1FMTV4Mi05elBFUEpFZm9JVmtVb0E0NDBHVFpiRmF4ZFlVUHZTRUE9PQ==
"https://www.pnas.org/doi/abs/10.1073/pnas.2318124121

I’m assuming this paper (pasted in case google scholar gets updated)",r/machinelearning,Z0FBQUFBQm0yeGI1RzdVM242VktBSEQtczI2UGJqeFBBWHlWdVVrNkNIQUQ0RjV1Wjc5aERxY3FrN183bm9iTmNXcFhIX29PbnBiQ29ENlRJM1pjRUV1b3NoUTNNRXVDbEE9PQ==
is this a phd in regular physics?,r/machinelearning,Z0FBQUFBQm0yeGI1MXdqWjJpZjBrSWprMzB4RUpjXzFrclk2aXVIZHdvN2FYeG4tdTdKYm5ZNWNBYWZleF9UMWJ5ZUlhTzBqYVlQSXVrbjBrOFUzWHZiNEs2OFA3TGQxLXc9PQ==
Yes,r/machinelearning,Z0FBQUFBQm0yeGI1XzNWSnZFd1Zqb0VXWDNZRlhvcWJTNzNDXzY1UTJSbzJQTDFVemc2cy1PYWY0UlR6dENDUF85TUtKZFZ4NVY0VmhrOS1Ga2E1Q3dtQVRyeDJ0VjZJTFE9PQ==
Strong convexity can be a wonderful thing.,r/machinelearning,Z0FBQUFBQm0yeGI1b2VXc09iNFdIa3kyU0lReHprU1hvU09MamVqTjlaZEpyU1JmTG82Sk1YYjQyZWhsOTdLaFViT3NTazZzdmxDc1RGMktuUDRaVjF1VlJnV2lPZDRNY0xyZE1adk1ZMzVMYTFIWDZOQlM5eDQ9
Probably the ones that do applied work in a business setting. There are plenty of research oriented AI/ML jobs though. Tech companies that do AI research value PhDs and those jobs can be some of the most lucrative roles. Biotech heavily values PhDs for AI/ML applied to computational biology as well. I commonly see people without biology related backgrounds in those roles.,r/machinelearning,Z0FBQUFBQm0yeGI1dXNXUUxSb2M5SFFsUjgxQWh0TnhtQkVQLUVMU0dWTjVxSE93OTc2YUxjdXZVbU9hUjl1LW05czR5VkJtWllIN1R4OWo4UURock0zUnR2bEwwMFU5bkE9PQ==
"Do you mean evaluation for a specific model you've already trained, or a specific method? The latter may involve various steps of pretraining representations, finetuning, etc. I've found that this later thing is extremely hardware dependent, at least for transformers.",r/machinelearning,Z0FBQUFBQm0yeGI1ZmZRbEJNTnFkYTg4eGJfeUtoV3VkREVCbGowcE0xcDIxbzV3YlRDdXdvTjRpbmUzQkFHdVc4ODl5NFVyQ214UkkwajAtNkYtOUVKbEdwY0R3MU1uX2gzaXBkcVZkQTdHWjRlYmdScG9IWFE9
Mechanistic interpretability. Look up superposition and polysemanticity. Also Anthropic’s Golden Gate Bridge proof of concept,r/machinelearning,Z0FBQUFBQm0yeGI1dTB3R2xDS0ttS2FuUndjdGJWYlV0NDYyOEJEZUdQcUR6OF9HYUluQl9kOVZERjZRVktmc2g3LWlxdXZYNTEtNHB0cjFBUk04U2ZieHc2MUFCZjNXQUE9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1Q2cyU05RZ2FZTzRfc0t0UWVRX0JjNVN2VHFMWjR3RlFkOEhrVWdfSnFSQjdaenlqeS02elVNY090b3R0RlRtdU5uYXIyU0Nrc2tIWTRBOEpVbFUwOWRBVExhVzZ1TmU4TUlxaEY1aHoySk09
Really just sitting here trying to process someone worrying that getting a Ph.D. will be a net negative for their career prospects because they’ll be “too old.”,r/machinelearning,Z0FBQUFBQm0yeGI1YXVfaE45T2YtSk05WjB3OWwwVzh4TFdsa3U3aGttQTdyV0p5alpOTXEtRWxxdEt0UVlONlEzYkFnalM0MUFZWENaN1lNZHNXcjhNS19XS0paRUVCaFE9PQ==
Yes and would be wild that it's not,r/machinelearning,Z0FBQUFBQm0yeGI1aW45cUQ0MkV6c3BUTHRITmxtMkR3bFpxSFctUlB2a0hRYm5MWFN1Smp1dWZVOW9RdEhtTWFOREluTmZqeWduNXlUSmc4Vm5LMHFkS1l3NThJaFhoN3c9PQ==
It’s easy to make enough synthetic data that your favorite model converges nicely. It’s hard to ensure that the resulting distribution/domain sufficiently mirrors the real population it’s supposed to be simulating.,r/machinelearning,Z0FBQUFBQm0yeGI1TndMQ3QtWHhRazJqTEpSOW9vWDdQbUxBSEJ0c0Zvdjd1bzhXVmpDLVZiaDdmdU5XajVPN1ZSWlAxQWQtdkZJUFBCa28zTHlrTjBNM2ZUbndqOUFnNHc9PQ==
"I made a voice model with only 20-60 seconds with 140 epochs and it sounded amazing! Idk what your on lmao (Though I’m not saying it’s good to use only a few seconds of data, I make models way longer than that)",r/machinelearning,Z0FBQUFBQm0yeGI1MVc4RDdOMWNXenZhcy1GRFRxQU1WTi1BTVNSVm9YZmpMbV9QWkNvNDZ1LXB5SUE4Y0VmTjBwU1FYTjAxUFNodWJWNkdoWWZWOHFhSFZqaGFMb1NsS2c9PQ==
"Just search for papers in lower quality journals (have a look at rankings). Then once you’ve found one, flip a coin and that’s the chance that it is inaccurate. Hope this helps.",r/machinelearning,Z0FBQUFBQm0yeGI1aENmdVVDaGJ4RTB4RUstdGFxNndyWUlkeDF6eENCVEhxZEV5eUc4M3JHd0NWWkNUZ19TTkNQYnFZbmliTnBtS1psNXU2bVF4cExvbU1JUTRkMVdCbWc9PQ==
"Too theoretical. Most jobs don’t need so much rigour and I’ve had poor experiences with theoretical types being extremely detail oriented — sometimes you have to just do 80% and focus on delivering. However, they’re set on applying their “no stones unturned” approach to everything — a one-time script with virtually no users does not need fancy interfaces and rigorous planning “just in case it needs to be extended”.

A lot get stuck in this horrible academia mindset that isn’t conducive to most roles. The ones that can unlearn the constant rigour and learn effective prioritization manage to become some of the most incredible ICs out there. 

Just my 2¢",r/machinelearning,Z0FBQUFBQm0yeGI1bks0ckFZZVRLUTNhX0tKVmhXOUpoUjJqLVdaOUJ6NDQwWGZzUm1MNm5ybGJHbTJ2VllBRjNXQjB3bjlENnhEM3drbUo2bUZFTnNmY0JHd1d0ZWxPWXc9PQ==
You sound fun.,r/machinelearning,Z0FBQUFBQm0yeGI1bVZWY3BEVGRWYmtrbDdwOURNaE84TzRCRFBibmRyT1ZjLUozNk1wWXcydkxkYzVFdkNHUFdZU1BrbVRHTkJUM2hKZTZuNGs5ZEVZV0hhd2ZsNmlQWHc9PQ==
More VRAM,r/machinelearning,Z0FBQUFBQm0yeGI1dGhYaUtzMWt0V0Zhemg4eXR2R2NNWFctaC1XM0tYcUNmeEJRcG1TMDBqX28wN2tQX3JPekFwbEZFRldrR1FGN1FsWTI0bkkxb2V4VndiUWhoRjg4WFE9PQ==
Did I bruise your ego or something? Uncalled for response lol,r/machinelearning,Z0FBQUFBQm0yeGI1ZUVsbjhYUGVPUW1STVRhSDl5ekNsU3Q5bkgyNnIyU1lub283WUtpM29Ma3hKWDhjQl9nQmoyUTkzT29sX041WXV4N3J1YTJicVRuVmRpX0dta3dlVGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1MGlXdldRNl83bUtZOTNfdld1by1UaHJJMHJxd0Rvd3F6NzNqN3VMOGhtWjZrM0k1MS1RcENKZGpKVGJkQXpZdV9pUkNuN2VxVjR1N0U3ajZMLWgzZXc9PQ==
"Nah, it’ll take more than yet another manager type who sees their more highly educated staff as hopelessly naive savants, spouting the same tired points about needing to find an “80/20 solution” to bruise my ego.",r/machinelearning,Z0FBQUFBQm0yeGI1OFhfNFdSMThKUkRKM0FhZS1XQXZad3JXbUVxRzNKcmtvVjllTjVtdzhOZVc3RjFKWkVqaC1rd0JWblhoSHhWTmo4S1hLaXJCUW9OM0JrWlVGU3YxOEE9PQ==
"Manager type? Bruh, I studied math at a graduate level. I appreciate and love rigour, but not everything requires that. Nothing crushes me more than seeing a bright colleague from a rigorous background getting average at best performance reviews because they constantly get bogged down into the details. Y’all are stubborn af probably what got you stay in the academia space for so long",r/machinelearning,Z0FBQUFBQm0yeGI1QTFlQmFHRVhfUFlkZWk0Uk1LeExnLVFiY2N2RWV2NlZScm1ZdlZObWk5aXA0UFcycHlHcHV1YzhNM3BpT3o2TlN0TFhJbnNfbnhVZDJ1MXFIWl95RGc9PQ==
"To be fair, I can kinda understand these people.

I have hired dozens of people for data science/MLE roles over the last few years, I myself have a masters and dropped out of my PhD because I was sick of academia.

I've hired my fair share of PhDs in highly esoteric subjects that were ""difficult to work with"" because they would either take too long to deliver results, were very narcissistic or would frequently embody this [xkcd](https://xkcd.com/793/).",r/machinelearning,Z0FBQUFBQm0yeGI1Y2VXOWtZNWNmWGdPdF96MU40bEFrZjA5cnJ3bnNjTHBYMFZhUHdOY2tfMzNUMG83NnY4YUxPbHJBeUZJdjRZbmdQNU9CNjJtXy1IMzVrcm1rZFdkS0E9PQ==
"Here's one way to think about it. 

Suppose you have a simple task: finding a point of central tendency c for a set of real numbers X1.... Xn. The mode minimizes 0-power error (i.e. the sum of |X_i - c|^0, where we define 0^0 = 0). The median minimizes 1-power error, |X_i - c|. The mean minimizes 2-power error, |X_i - c|^2. So using squared error in some sense generalizes the mean, which may be a more natural measure of central tendency.",r/machinelearning,Z0FBQUFBQm0yeGI1dHY0Y1htTEx1QjN3SWgxSmxwZlU5VHNOTW9WQnZxUjBTZXZocklqMm9nZWpGaDNjdEVDVEtMRk9sN2pNbWxENDJRUUItcWVLaWFFTzlBQTYxUFJwcUE9PQ==
"Cool stuff. As for me I like the challenge of PC building. Its fun. 

It'd be really bad time to build anything now tho since the 5090 is in the horizon. I'd buy some cards used afterwards.",r/machinelearning,Z0FBQUFBQm0yeGI1SVotVG01OEg1TU1vdlE4RThaS2R3QUcyRXpycERxRGN5RW01c2UyRlFQbTBBWG00cUN4STdUZ2x2X1NhcDAyLXZoM21RdXBueWQ5eno3cXpiWlVRNFE9PQ==
"This week I bought a MacBook Pro M3 Pro, and I am extremely surprised with its performance. I have this product [www.artificialstudio.ai](http://www.artificialstudio.ai) and now i will be able to run some AI's LLM locally and other crazy stuff, it will help me grow my business and my AI models.

worth every penny. It's the most advanced option on the market currently",r/machinelearning,Z0FBQUFBQm0yeGI1bERmZjc1WFJIU2NObkNRNGVMZTJmVzJ0TkxZeWZpZkRlWFVkd3MzWmRVWXNtZXlEckFvczhWbnFaS0lEQ0FIY3RuMVJiOVl5Ny1Gb082TTJvN0hOOVE9PQ==
add me too,r/machinelearning,Z0FBQUFBQm0yeGI1RzlqbzhORmNJUEFjbmdzazBZLTBTUnRrRVhBdFdEbG9QSzlZS0EwZTZFQW8xTXEyVlB2bkw5TFZUTE1Db19kUTVZeENlWE1USnJrOHpobW4ySThRclE9PQ==
Did they not break the law when they indexed all the web data that said “copyright” in the footer??,r/machinelearning,Z0FBQUFBQm0yeGI1T0Y2S0VNaGtLeXRxN3g2SEdPUjdiX2VtY1BNZV8xNnQ1MWNtanVsRlJEd0hrN3pTUHFhdkEwbUNvTmlOV3BPand5ekt0eWhzdHM1NkxaSU1lVXVsUVE9PQ==
The funding,r/machinelearning,Z0FBQUFBQm0yeGI1SXZZWThsNEZlRXhvSzU3eGVOdWZfWllJdXNaQmVDYzRzSlVtZ3RBN1JPanlEVVhaZ2dpX2JkYlRiQ2ZwUkc5R01XUEVFYmZpb0NZeThUWWZEeGo5d0E9PQ==
"Is a PhD not quite irrelevant now given the advancements of AI? LLMs can teach everything and more than you will learn at a PhD. Also, there are 2 other problems with pursuing academics further, one is that there are no academics going hand in hand with all the recent developments in the industry and two no university has the computational capacity to handle hard-core practical work compared to the companies. So PhD will definitely restrict you and put you far behind in getting into the industry because come on, GPT 5 will be out in about 6 months or so, and then AI will research and teach AI itself.",r/machinelearning,Z0FBQUFBQm0yeGI1VklDSXJQSGhLQ3ZBbVJ1akpGeVdyVWNweGRhOTYxZnBUdXh6QldfY1dRRjI1TGhfZ0lxSE5qUDFHbXFTRGdQbkdYdzVJM2JMa0ZJZmJOeXQtc0NQWmc9PQ==
"sounds positive, good luck to you!",r/machinelearning,Z0FBQUFBQm0yeGI1WUFqUVZyV3VGRlZTWkdkRTE3Rl9YNV8zVURRZ0ZVMkpueEJLQ3N1dU5fTWZYTTlIU1hYSnM5ZU1Fclo3eVY3WXdHeENBeGdRMDNFZnBGXy1wanRuSE1PX1dPWjlIb0hPTlg3ZmpXaG5KaTg9
"> But it just never happens, and in practice, L1 loss has a nicer behavior.

Ehh, for most tasks you can treat it as a hyperparameter, swap out L1/L2 and do whichever works better. For just about every regression task I've worked on L2 works better, and I'm guessing most reseachers find the same which is why you see it so much more often than L1 in papers. 

The derivative of L2 is the magnitude of the error, whereas the derivative of L1 is just a constant (your learning rate). This means your updates when doing gradient descent with a L1 loss are going to be constant no matter how far off your prediction is, whereas L2 will give you bigger updates if your predictions is further off, which is usually what you want. 

This also makes L1 a lot more susceptible to oscillation problems, if your prediction is just slightly too high you'll get a big update and then next epoch it will be too low, and repeat back and forth. Meanwhile L2 will give you smaller updates as you close in on the minima. 

The main use case where L1 is nice is when you expect some samples to be so far off that the huge updates you'd get from L2 would screw up your model, but usually gradient clipping can sort that out.",r/machinelearning,Z0FBQUFBQm0yeGI1M0hHUTA4by1zZGIxQjFaS1hfb1RzZ1E1QXh4Njl1S3plQktoUFpHLUVINXpBQU1pM201VUFDNU9VaXlfYVRURDVMR3A4ODFMZXdoMjE1Ym95RWdiNGc9PQ==
">overqualified

Possibly

>are too old

No

>you lack the production YOE

Generally not, since you had to do some type of work for your thesis",r/machinelearning,Z0FBQUFBQm0yeGI1SktfUWF1TXVvVmVSY0lRREZ2eWVLTVpXalZXcmQ5ek4tckZyLW1UcFRsYmhMRDlqQ0Z4TkV2VUZZOTd4RmMtVlRhaHdyemdSZUdRR2N0cVJhVDhodGc9PQ==
"Thank you for your opinion, it is very valuable! I think that I'll follow your advice and I'll work In the improvements to be prepared in case of a desfavorable review.",r/machinelearning,Z0FBQUFBQm0yeGI1RUc5aklyMlBvVEM4SEVzWjBZYl8wVWMwRFAtSW40Uk5fQS1DekZpcUd1cEVrQ1haX0hMQUwzVEhCYUN1M1FPbWd1N0htNklPVHBXMVFYR19HN3drQ1E9PQ==
"This isn't even an ego bruise. There's just a mindset that academia proposes that doesn't work for industry sometimes.  A lot of people are forced to come up with a novel solution that can get a paper in, even if it's a 0.005% improvement on some metric.

On the flip side, often in industry we sometimes are completely blinded by the bottom line (which is called the bottom line for a reason) but with some amount of innovation and knowledge of applied research you can open entirely new revenue streams.

Not acknowledging the grey area is completely naiive. I've worked with incredible PhDs who've done a great job learning about how to solve practical problems and vice-versa for pure engineering types. I'm a bit biased since I've worked my whole career without a PhD but around a bunch if PhDs.

Summary is, you cannot restrict education to a single archetype, but you can still acknowledge the incentives that folks with PhDs undergoe throughout their tenure.",r/machinelearning,Z0FBQUFBQm0yeGI1WFFadzRlMnJiRi1nTWZTWjAyMklRSTFRRGhDOVItV0RQZU9WOWlfdU84ZHVaYWxWcHlpM1ZYNHk3NlBheWZocE5vdzJyOW5iUnhTUUtlYkpvZmFZRkE9PQ==
"Research: PHD is useful. Some folks told me they only hire PHD or current PHD students in some more cunning edge research roles. This is also a must if you want to be a university teacher.

Otherwise, look up the job requirements and talk to people who work the kind of jobs you want to work in.

**Make sure you need a PHD before you just get one and find out you don't like research as much or getting it for a job that doesn't require it.**",r/machinelearning,Z0FBQUFBQm0yeGI1cGtfVVVtUzFuaU5RV3pJTmc0RUN0ajRkb3NjXzk2aGZtbzRaUFFzVlJiRzA3NUJZN1JWLVpfclBHVVc3ZVJSMXBvRElsaG1hLXdSMlZOZU5ldXpnV0JLaXpmVko4eXpjaGtCTS1NT1lMaTg9
I got 4 4 3 3. I have a question. A review is that My work focuses on a single modality that is not solid enough to meet the expectations of MM24. Do you have the same issue?,r/machinelearning,Z0FBQUFBQm0yeGI1aXYteHd5bWUtQktrbG1ENWt6THh5cmVWWnVZSGlVZ09HV1VGXzF5eGVYSENncHZOd19pM3REeEJ1SVpvc1I4dmp1M2tfZDJ1LVRpbTBRaExNMm9zWkE9PQ==
"I'm not sure but on the website they say the following: ""While papers that involve unimedia/unimodal processing will not necessarily be rejected, papers that make multimedia/multimodal research contributions will be preferred for publication in the conference proceedings.""  So I think your paper will be fine.",r/machinelearning,Z0FBQUFBQm0yeGI1LU56QlJia0dZWEVEMzlqZTAzQmFlbGgyUWpXSkZPTVlPWUVuTFVvOXlJbHhOaWc0Si1NZ280YURhTTlLMkIyQ1BkQlVYR296X1F1cDJNSlczN243ZUJnS2hIaHJINE9IaVlRSUlKalZKb0U9
"Don't get me started on the ""He is book smart, but \\_insert BS to make themselves feel better about their intelligence egos\\_"".",r/machinelearning,Z0FBQUFBQm0yeGI1RW50MGEtODRsU3RKa2Nta2dNeHhQb255TGpLOUJzZlhwQkZSaExlMC1nU2w4cFFHRm02TDc0cWVpcFJDd0lSQ0hjUElkcWV3SlNvWU1FeTRsNFB4Z3hxekhvWGlNMEZGTV9SOFNfU2daRUk9
"I think there are a lot of people like that without PhDs, too. Everyone needs to eat humble pie in order to develop professionally, some people just need a bigger slice than others.

I think if there's one especially common feature that comes with someone having a PhD, it's that they're not convinced by dismissive or evasive reasoning, and that clashes with a private industry culture that is rife with dismissive and evasive methods of motivating labor. I'm not necessarily saying you're one of them, but I think a surprisingly large number of managers have a difficult time working with direct reports who want good/honest reasons for the work they're doing and who insist on having input into how their work is done.",r/machinelearning,Z0FBQUFBQm0yeGI1NUFLT2EtSEVPT2t5MXJTS182VlhpUUtWa2lzODlKeS1taTE1TU5XUElIeHREWWZGZU9PUlVkcldVcmZhRlR5alMtUlp4RUhRT3pvaGNDSjhUSU04UXc9PQ==
Thank u!,r/machinelearning,Z0FBQUFBQm0yeGI1eWJDQm90bDV4RTFOTjNzbTNXaWNBZDBMM2NMRzhrODVsZVBSNUFLRVFjRm43RnNUTHZiYllVQm0xTzVpdFJ6alJOMk1fNTFmX0tZVDllVTNld0lzNVE9PQ==
"He's got social skills while you all are book smart! (I am joking if you can't tell). 

I think the too theoretical is because sometimes they just think things way too much instead of doing something. It's a strength and weakness if use poorly for intelligent folks.",r/machinelearning,Z0FBQUFBQm0yeGI1NkNlWnZqNm5aX0xZWld4NWxnZDY2bldpaFFoZXpxZmFuMjRmdkE2NTV3Uk02UVdYSkhVMnFfc0Q5YmxNTFdOXzN0NXNuNHhaX2pCT04yTTF3UkpraW9Uejg5T3BlMW9CLWlBNDdpMUl6eDA9
Copyright is about making copies for distribution.,r/machinelearning,Z0FBQUFBQm0yeGI1N3Q1aEVHZGwzNVR5bi11SkF4dlhqcmtSMlhsR0VrYjI4c3l4MGRkaW9qV0piZGZfaWIzeVMxVUFFeTY3SkpMVlJMZGs2cFJLci02eXFKam1XZi14TEE9PQ==
Do you really think the world is better off if strong copyright were to extend to AI? It would set AI back years.,r/machinelearning,Z0FBQUFBQm0yeGI1dXB6WEt5LVdsdDAwUEdzcDhuT1FTZ1oxaWJaSmc5MlpJTlFoWWhPS3o0MHhVLUZiOUpJSXVsTTZEVnlDVW9Qd2d6clplVHZpckNrZFJ1YUhWSi16ZWc9PQ==
"Using mse yields the mean of the problem, while using the absolute error yields the median. The intuition behind this for mae is when the error is 0, half the datapoints are smaller and half the datapoints are larger which gives 0 gradient. Hence using absolute error is better if you are dealing with large outliers.

From an optimization perspective convergence is worse for non smooth functions, but you can show convergence using subdifferentials.",r/machinelearning,Z0FBQUFBQm0yeGI1SjRyM3E2Y1p4NG9OX04zNGt5VkppMzl6dDIyWHhTR21RMzRQREpnenA3NTVFY0tnQ1c0dTNzYno3aVdEZHhmekxLSmJLZHhwUFBPWWxxTnlpMi1JUVE9PQ==
"Things are copyrighted the moment they are created. Footers mean nothing. In the early days of Google, there was a lawsuit and the compromise they reached was [robots.txt](https://en.wikipedia.org/wiki/Robots.txt), which basically allows sites to opt-out of being crawled. Google still respects this today.",r/machinelearning,Z0FBQUFBQm0yeGI1cG9QcUdyMElMTUlzVUZhQ0FoemFVWU0tS0ZmY0ZsakdfZklJT2Q0NW9FYm9Rb2JzY0RZLTZuUWNQa1hUdkRxNXdwNHhhMi1EejZ3NkloakwtOXVBc2c9PQ==
You specifically ignored everything I said in the last 2 responses.,r/machinelearning,Z0FBQUFBQm0yeGI1Vlc4cVVXQTY2X25idjZQWkFCTGVaam1MX0QwMUR6NnZXZDhwemgzaXl3VktYWUpBR2Rlc1RkZGk1S0htVUZCaTl5NUZETXM1S2I2VG9xT3htcjVtc2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1NDZjUHFJdThSY2RWeEF2dE05QlJHWDQtZHI0REY4VnhXLWFOZlFoS1RETmRUMmxFV1RyVktWQkU0MmlWWFNGU0dYVTZyWl9hRkR5NEtSeEZKNi1fRHc9PQ==
Yeah this,r/machinelearning,Z0FBQUFBQm0yeGI1dGRiRDJvRFV1THYydDB1RXByZ0dfWnZ0RnAtc05scXkwZVVWMzlrbXFXY2NjUGhSYlhucllOT3FSWW5zd0JWZkF5YTdkd0xjd0VCRUdrcXNGMG5fNFE9PQ==
"You can get jobs in most any ML area with a PhD, but it will be harder to get certain types of jobs or with certain managers right out of school. 

MLE and data engineering are degree friendly if you need a good entry level starting place. Then hang out with the product, marketing and SWE folks to get a different perspective. After 2-3 years really only your work matters.",r/machinelearning,Z0FBQUFBQm0yeGI1b242cVdlT2hsYjY2SWYwV1Azc2lJX2ZLaGk1MW9IOGs5Y0VacjFXTFpFbzNxeGd0Z08tSExKLVFhdnhnQ3RLaEUyS3F4dkgxdzVwSk5vbFZLQ0tGTjAtYjkzRzlTdk9ZalliR3FpNDF4c1E9
"Neat, I guess, but do we really need another paper about ways to evaluate LLMs? There are already so many.",r/machinelearning,Z0FBQUFBQm0yeGI1TzQ5RDhoSTZTbkJtam1KMlFMMXhHdnVfMm8tTmRoWjlyMC1wbVZTWE9YOWRRYi16OWJGdzhFMC1qUmxTZ3pTcnpDcVJ6clBvNGk1VWJjaU9rTHRScENXck93bXZpa0E4QTRvcEVLbHMtdU09
"I have high hopes that mechanistic interpretability will lead to better debugging tools, and maybe even better training methods. Neural networks have been black boxes for too long.",r/machinelearning,Z0FBQUFBQm0yeGI1MHJ5UWNWUWt4d3hPMkZEQ3VxVy1lWkExbWtoZkVGbXgxbG12SEY5el9CbUJlb1Utc0hNLWcwVzliT2RNX0sxbGQweFNPMUl4VkxrV3hrNUlSOW5PN0d4QTh6MzIxMEY1WXhHZXZDNHB1NnM9
genai isn't copying and distributing?,r/machinelearning,Z0FBQUFBQm0yeGI1N3Z2anFfTEpDOThRVmtJZzJFQVB1a1R5bzJWMXA3WEFsU2hwczU2OUFJUjdVa3UtbEdYSjYxczh1UmxfS21aM2JIQm03V1pENXp4X0dRaDVPSWtOd1E9PQ==
"Yes, the things I mentioned are not PhD exclusive, but being ""too academic"" (aka focusing too much on near meaningless minutiae) or dismissing other fields as not important is certainly endemic. Heck, it's one of the reasons I left academia., that and the massive egos (but that one is also common in corporate). 

I don't disagree with what you said about private industry or micromanaging, I just don't think it has any relation to PhDs.

I'm also not a manager, I'm a tech lead. So you can be pretty safe in your assumption of me not being a micromanager.",r/machinelearning,Z0FBQUFBQm0yeGI1SWlzcWZIOHd4U2tnb0F1NnVPcG50MmlXd3JqODJQaFByUDZkMHRfOTdjOFB6VTAxbWRCc0lzNk9INGhsVEp2VjVCQnV6eXlIR0VjcDNqcTN3RE9YaUE9PQ==
"Hi, your implementation is unclear from your description

Could you please elaborate on what model you use, what would be the requirement of RAG, what is the context?

I'm assuming you need to automate your prompt for each row of your CSV,  I might be wrong",r/machinelearning,Z0FBQUFBQm0yeGI1NmdfbmZxUDJsT3Rvd1lmNHJTQjZWcjVDalo2eGY5Qk82MDZjUGNFeG1HWEVSdkdhbmhvRjZSSUZsNkRoakZ5X216WkhBSTVFUkRidHFUdUdxR3VjQ3c9PQ==
No.,r/machinelearning,Z0FBQUFBQm0yeGI1eFh3MGRhTS10ZFZTQzQ4VHRBX1BqcWxNc2p3enNZN0tGRmNlLWRBMzUwWDZkblpGbVA2elVOOTZsQk4xaVdseFVXbGJIUDJXQjJVYV9RbmZyN0t2dXlHSllEcmhqczF0Nld1c2xzQzFHZ3M9
"My buddy has a PhD in category theory but is now a principal ML scientist. He’s always confused by how hard it is to get some people with PhDs in ML to actually *do* machine learning, like they’ve over-intellectualized parts of the process that absolutely don’t matter.

Terrance Tao has a [great](https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/) article about rigour in a mathematician’s development, but I think its actually pretty universal. In this case, stage 1 is someone who can set up a PyTorch lightning project and throw together a basic model using whatever metrics/loss functions you saw in a relevant paper and whatever optimizer people are usually using (Adam? Adabelief?). Stage 2 you get into the guts of different notions of learning, do a bunch of statistical learning theory, some distributed computing - when you do a project everything is bespoke and you know how/why everything works. In Stage 3 you just throw together the standard lightning project based on whatever seems reasonable.",r/machinelearning,Z0FBQUFBQm0yeGI1T0gzSFFjaHlJSWprX0JnT2ZRWHNBWDVKS290Y1JrbDMwMC1UVHEta2tEc0JHQTRKRXRpNHp5MmpSTGNXMkJmWi1TYnl2YTZVbGxKWll6cWNQeTJ5SEE9PQ==
"i did a few test, wandb agents work fine now. i believe its your model implementation.  Try to shoot at what point ur model runs out of memory!",r/machinelearning,Z0FBQUFBQm0yeGI1akgycHRUNXBBcmhieVZ5UVRQRzg3Ym82QllvUm9TZTlBN2FVNUlHdnhlc3VLVWszbXNYM3FuOFUyWnZMVEQ1bzZnbFBJY3Mwc0ZUbTJkVFV4RW5rbFE9PQ==
That is a weirdly vocational perspective on graduate studies.,r/machinelearning,Z0FBQUFBQm0yeGI1M2E2WTRIbDdvdFIxRG5rYUkzd2doaG1CSUgtMUlQbGF4cW5GSjBVUlFNbVNjc3RRbG0xN2R5bTZhdHRvdEY0QnhYX05OalFzUjhQUTdNaGx4WUExZ0E9PQ==
Can you share resources about maker critique techniques?,r/machinelearning,Z0FBQUFBQm0yeGI1VVRsc1BqaTNWTndRZzZ3TU1sTHZZYXdabGtLSWFzcDZicURrS2YzOFFROXZVNHVKWDV2TXUzX0NIOGMzdWtIREVoOVRzWW5MMUNXTFN5OXpSNjZzMnc9PQ==
"I am using Llama3-8b-instruct model for tokenization, embeddings and chat
I am using RAG for giving it IPL(Indian premier league which is a cricket tournament) statistics 
This is to create a working IPL LLM or a chatbot type

After retrieving, When it is loaded to chat with retrieved docs, the session is getting crashed on Google colab though it is connected to T4 gpu",r/machinelearning,Z0FBQUFBQm0yeGI1Z2RDMGt2OUxtQ1ZoellVRTJrREVlTlc4RktrX0tsMUFWalZqXzlnNHZwR0IzRm1mZUFBaWlXZFFVOWN4ZWFNWml0OGRzQ3Zvbm80OWFDOG4wYURUcUE9PQ==
I want to say continuous learning to disrupt the whole training vs inference divide. But we're ages away from that. Eventually people will realise it's the biggest thing though. How do you get a system to continuously adapt?,r/machinelearning,Z0FBQUFBQm0yeGI1T05aRk0xSjNyNE91UnBtZ0xYOGxTREhHOGJ2Wk9FSHRYTVNOLWVPMUlMQWdiZXBiS09ZZ2lUVnFpb3JyNDMzVldYSHVjSGtRV2o0SHR1c0ZWbDVBOEY4elNRYmRaTjJZdXB1aUp3NF83NXc9
"Not an expert but I see ML has many commons with mathematical approximation. Formerly I think squared error gives higher weight to outline so it converges faster. But upon googling, it is suggested squared error is differentiable everywhere while absolute error is not.

Given that ML shares a lot with statistical model, I think this is why scientists opt for it.",r/machinelearning,Z0FBQUFBQm0yeGI1VEVYVlVBVHF5V3JVQ3NEUmxNeTVLN0dkQW5jSV9wUjZzckhmb091V3ozc2RPMHZLQnlXNGE0Z1ZhOGY1bVBNMXdOWEVDN0RfS2hTODdQQ3AxZ09kSFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1Z2pTY0pwMTBGZkh3WXRKTU9pcV8zVFJCSzJkOWFBSEFpV1laZWpiUzhDY2pTZDBoc056RmQtZkxUUl93a1VIdXE2MTBtVWtvclBPMzJjWnd0MF9rVVE9PQ==
"Their search engine respects robots.txt that is; their AI has not, in all likelihood.",r/machinelearning,Z0FBQUFBQm0yeGI1V3ZHNUR4bE16ZFIxR2FFOUh2UGtLOUhfOXZRT3libXBHUkhUQWVDamVtUHlsQlpkZ3MzVVoyYS1yQ3pMbmpUZEh0VnR4Tm9raHZNM3dDRktGWmFvY1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1d3lhSF9VZk80cVpnRnhucFhScnplTDJZUjBQTTgtM014T3BucW1NY2ZGSXpTeUR6XzhSaDZFQ25Xc0VrQWpiSmM1MXhNMGZDZlM3b1lGVVBHcUtxeXc9PQ==
The EU AI Act specifically requires compliance with EU copyright law for foundation models. The relevant section of the law will go into effect in about 12 months.,r/machinelearning,Z0FBQUFBQm0yeGI1NG11aDdxRHMwRTVha1V5NUJVVTR4UXFndkVRRTcwMkNDU3Bjbjc0clhjSnZwc1dMRlRGendpb2RNNW1TNktMSngzbmx5aVJWdWd3X1R6RWZoU2JqM1E9PQ==
[https://papercopilot.com/statistics/acmmm-statistics/acmmm-2024-statistics/](https://papercopilot.com/statistics/acmmm-statistics/acmmm-2024-statistics/),r/machinelearning,Z0FBQUFBQm0yeGI1c19qWUl0c3djZTZMMS1xRm1pTXczS3lfMS1RejMxMDhEdVhqQm9wc1lmZFhvaWRNX0NoYk9VY2xKakZBaTZHMHpuTGQ4SU85b09ET2pXYjZ5ODN0SnpFY0dzWFNRa1BNSXdyelBLakJobms9
"If you write some numbers down, and I do linear regression to find the slope of the line, and predict new data, did I copy and distribute your data?

Idk, it's a gray area, but I think it checks out.",r/machinelearning,Z0FBQUFBQm0yeGI1TkR3QXNoQlN3SG5YaVF3SHdQaHVzSXBkTHdEODNRR2lPNHVZM0loLXBaWFFPNVM1T3dORHFFTmZIMW1URWpaWkdpNWI2b1kwV2V4QXdQaGw0Z1NDQmc9PQ==
"wow if an ML professor described TMLR as ""a strange venue"" I'd be pretty taken aback, kind of a negative signal on the professor in my opinion",r/machinelearning,Z0FBQUFBQm0yeGI1RWZ0MHBhYzdPU3dGVF81ejdDc2JWQWx1T29PYjRCWTl4X01nYTlWelZ5cGFYTWozMWJWdTdONTFGTWhjN2ZiTF80a3pBemdkQVlpME1fVEZYOU50aEE9PQ==
[SciSpace](https://typeset.io/) is one of those. Found this tool uselful because it has a really wide range of papers plus is easy to use. Don't know about others.,r/machinelearning,Z0FBQUFBQm0yeGI1VWtLYzVOdzlWRkNuS0poNlBtTUZMZ3NGNG80NDFiYS1oWGZFUGxONnEwb0RYTnU1NzNvNGpwRWU3TUNBamFNRUlFOFZTZDlxbEdRSkR1RkF2QVJ2OEtCUU4xUk1WdFd6b1lNdGlyWDNHQTQ9
"I interviewed at Adobe once. I was told that I am too research oriented to become a software engineer. Actually, I agree with them.",r/machinelearning,Z0FBQUFBQm0yeGI1eHNXdnlqZVo1eUlWdW16bkVrS2lPSmNwY3FrNDVYTGdNTlR0RVpGdkdKVE5DT2laRDRYSGRGREl4cXl0ektTWHd5V2pZWi1QRDlzaVpkYjdIQ2tDWEpyU3pMcHFNa2hqdUMzWWVkd0s2czQ9
"Generation is costly at the moment and we’re working on making it faster for e.g., by changing the diffusion scheduler and configuration. 

There’s a minor quality degradation if we naively do long form inference, but so long as we chunk outputs in reasonable length sentences it can handle it without significant degradations.",r/machinelearning,Z0FBQUFBQm0yeGI1anNRZkR6OC1hdmNXa1B3UFVRVHBGQUtQVkp6UGRwMUl6V0lMSFE1ODg3eVJyN0MyQUhXTXJ5RWx5SEtLclktRHYyUjhyOE9XeW82bzVQNFFRQkhfYkE9PQ==
"To explain it simply, you define 2 agents. One maker agent with the instruction. For example “Learn the spanish language”, this will generate an output. Then you have another Critique agent with all your criterias for a good output. For example “the output should be able to translate my 100 examples, if it can’t, explain why it can’t” then the output is returned back to the first agent and it tries to fulfil the flaw, and then back to the critique agent. 

So this process loop can happen without labelling because midway through the loop it will start creating its own labels, create bad labels and self rectify the labels when it cannot fulfil the criteria.

Of course you would still kick start this process with some good materials and instruction. For example a instruction book on learning spanish as context.

Note you would also need to convert the alphabet in the language to an embedding as well, which is just a number representation network of a language. This can be created from just digitalised books and books of the language.

All you need is processing power, time and the incentive to do it.

Why you don’t put both instructions in the same agent because the instructions and criterias may sometimes be contradictory which limits the generative aspect and it’ll get stuck in a saddle point solution. It’s the same reason why Sales and Quality Control aren’t the same person as human employees.

You could also split the maker and critiques into multiple smaller agents such as grammar agents, vocab agents etc. but it will still follow the maker-critique workflow.",r/machinelearning,Z0FBQUFBQm0yeGI1cWlBekhnU2htRTAwbjhyQnROaXZOaGtEUmVTYUgtek93X0RwRmJJTGc3TndYUlYxdFJqV05sTkR0R3BoVDRrRDRLWkVIdno2X3dDVFRkUFluZy1KNFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1QnpIYXNBN1NzNjlNUDhUU1o0S3o4dkp3TmRFbHFTMGF1cnRvUEk4TEluNkpYcWtpbjBkNy0xV2paaWNkY0lVRXVka05IOXduTkUzc1VDUEJvelhoNWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1Tll5WFJhNmRnMmw4QkUzV2hQTndvU1JiX3AtZTl2M2RIeUNxQ2FobkxmWDNVbUQ2ckRXN0RqYk5aUklIY0YwZnB5ek5KZFZEd2tRRHFXZ3g5dTV6aUE9PQ==
What’s even more wild is someone thinking this breaks the law.,r/machinelearning,Z0FBQUFBQm0yeGI1dUF5cURqRms4WHBra1plbkEzODlJNTI1blJoVkNieDV6d0JwcngxdmNxakhZYWpWWnduUE85ZERWLTltcVJIZWF5aXhzUHpOanZKek9PV2dlQ29Wb3c9PQ==
"Look into topology optimization. It’s related to deep learning in that it uses the same training method (backprop with autodifferentiation), but it “trains” a 3D shape instead of a neural network.",r/machinelearning,Z0FBQUFBQm0yeGI1NW53eHM2OWJYWi1oWVVtUXZOcU1qWGRwei0tWExDTjNFN0RWanotZ1BwcmZsRVRVT1NlMm1vejZZMmhLb0xLRFRCNlM0UEZkc1lRNFB6SUJoMk5VTG9BekNXM3dPUFFiRi1JS0xTQnBZbzQ9
"I agree with this, but I actually wouldn't say the issue is being 'too theoretical'. I think there are two separate issues I've seen. The first is assuming that your job will pay you to do whatever you think is interesting, like they (kinda) do in academia. I say kinda because thinking that way is also probably why they didnt make it in the academy either. The other issue is just being a plain really bad engineer. They don't know how computers work, and they can't learn for whatever reason.

That said, I've seen just as much of the flip side from the engineer/management types. For them, they think that world changing innovation can happen in 2 weeks by just coding up the first algo you can think of... They don't appreciate the need to learn and play in order to make true innovation occur.",r/machinelearning,Z0FBQUFBQm0yeGI1LXB2VmdOcUllb1hhV01NTXcwYWdZbHhtS2IyVWdnTU1MVUw4MEw4aEdzYUp0TWR4X29Td29oSkVBd19VeThkNTZhNGl2R19JcjZrQ1NQOUZYRHlSSEE9PQ==
r/learnmachinelearning,r/machinelearning,Z0FBQUFBQm0yeGI1Z21JRUxyNnFYY0xaeU1nXzFuUjFzWXZCLWhhd0xXWk1takR2V3R1ajBlV1BkcWxrYk5UaDdoUy1lTU5wdU9fcVhMaWljZ3hQR1FHWEhvc21TcTdqSGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1a1Jzc2wza2JjbG9vQXpGU2lBZ1NGWFR5OC1kcXdNUFkxYk84R3VKWmgxRG03MWx2Z24tNWRIYy1KVmhlQVAtNkh3U0hhS1V0cTNCNVY2Q3VtTXNKaUE9PQ==
Biggest risk is opportunity cost. Compounding interest from a big tech salary for 4-6 years is not worth losing unless you finish your PhD and leverage it into a very high paying position.,r/machinelearning,Z0FBQUFBQm0yeGI1N2kxY2JqZldZWTZaSVplR3dCQUFnS3J4aDVubTJpTzIzcUFUN2F3MXZxS2hIQ3FKaEJCUDQxV2xFNDBCdnFkbkhyc2VTcDMtQ3RyanE3WDNhMDQ0ZkE9PQ==
"Here you got a CVPR 2024 highlight [https://langsplat.github.io/](https://langsplat.github.io/) . I would classify it as misinterpretation/misrepresentation of results: 

* They repeatedly claim to perform both 3D object localization and 3D semantic segmentation. 
* Nevertheless, if you look at their evaluation, it's all 2D : they segment images, not 3D meshes nor volumes; and evaluate if a pixel is inside a 2D bounding box without computing any 3D coordinate for the prediction.

It's a pitty because they do have a 3D representation, but they use it only for easier 2D tasks and therefore misclaim their results.",r/machinelearning,Z0FBQUFBQm0yeGI1SFJUUFpITWQwWjQ0cWlweGcwdzNIeUFTaTJEdVQ4TmtZNmhSZzhpZkIycjdKWVBsMlNfbXpkc3ExQjdfbW1UMlA1cGdsNlpZX2VWNklpOHgyVkxsSEE9PQ==
"Sparsity of L1 is desirable in interpretability, so is often seen in scientific applications.",r/machinelearning,Z0FBQUFBQm0yeGI1eVVidmV6VnBIWEUyTjg5RHB5UkFxVUo2MTZEZ3N2OXhzS2NZM2k4NUJIbWl1ejctQTlVMGdQR1ZKTzdFSTR0Ql95TU1RNzdPcEc4bHdMVWlHTUJpS2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1cUF0cTZCVDBKWk44WWtTbERUVjJ3VzNyeVpXR2JuZ2piRXh2UkMwZGNVNF9NUVUzN202d1djZm5UdTR2SDRJbGd1YVEyTzZmSzAzcUwxWllMYXA3dUE9PQ==
"I assumed the OP was talking about using L1/L2 (MAE/MSE) as a loss function for regression, when you talk about sparsity you are talking about L1 weight decay right?",r/machinelearning,Z0FBQUFBQm0yeGI1ajJackVxcHdCamM1SEF5RjAtY1NRMGhWYTdidXkwb3N3enlSZlJnU1h6c2tnWWpZbGtfTE9ORTZ2QWprWTFtdzNYc0MtaW9zeEZ0U3cwZVk4dFlCd2c9PQ==
"More likely than not, the performance of that binary classification and further more the loss on the examples he’s interested in detecting will not be good due to the more than likely imbalance in label distribution of important vs not important. This implies the semantic information for those examples won’t properly be represented in the model.",r/machinelearning,Z0FBQUFBQm0yeGI1VmVBNU80TkhrTm00RldmLUVNQkxEV0x1MXVZV080WEFqX29Mall2TFU2QndiN0U1RGRXaEVEMmtvYW1LWTFpSDBnOTdqSGZHVjlZeHgyenVQU2E4OEE9PQ==
"I've seen this cut both ways.

In settings where you have lots of good data that match your question well, the main thing is to just get started and iterate. 

When you have poor data that are a proxy for your real question, you have to do rigorous thinking up front, and iteration will just get you to coverage on the wrong answers.",r/machinelearning,Z0FBQUFBQm0yeGI1Y3d0UEFINUpfVllPUGl2b2lzTWdkbEJHMDE5MVlnZS1uMmMtZTlTRlk2UXV0VHJvNkpuUy1fUVhubWpCcnRjbXA1VjlnVmdPRldYaXFxYVZzdEdRWHc9PQ==
"Hi everyone, I'm working on a neural network that can generate audio for double-track guitar effect. Essentially, the network should take an audio recording of an electric guitar and modify it to sound like a second take of the same part, like the guitarist was told to record the part twice. This is a very common practice in rock/metal music because it makes guitar sound wide. You pan take A to the left and take B to the right and get the stereo effect.

The problems are:

1. I don't know what kind of neural network to use. I am preparing a dataset where I have a lot of tracks A and B, where A and B are two takes of the same guitar part. So I probably need a network that learns how to convert source track into target track.

2. I don't know how much dataset I need. I'm planning to obtain at least 10 hours of tracks A and B both and feed it to the network in a combination like A->B + B->A so it doubles the dataset. Maybe use some augmentation to experiment with different pitch and playback speed.

3. I don't know if the task is even possible. There are no solutions like this in the internet (which means it is either impossible or not in demand to bother), except the algorithmic doublers which suck compared to real double tracking. A difference between real double tracks are note start/end timing, articulation, attack time/frequency response and human error. These can't be properly simulated with the pitch/time randomization, that's why I want to make this network.

I am new to machine learning so any feedback is appreciated.",r/machinelearning,Z0FBQUFBQm0yeGI1R2FndkowWXZuc2k4YzNtU1ZUV2NfTEZfOWtibUNicTFzTDdPNEMyWW45T1BaVzV5ZzljNXZxSHVsQXRuamRkTmhVTkZGYkhadmRQNEE3Znl1cWNOQWc9PQ==
5 years of practical experience can easily surpass academia when talking about getting a new job if that job  is not research oriented.,r/machinelearning,Z0FBQUFBQm0yeGI1QmtVMnRqQmw1SzY3R3daT3VUOHpLNGhpNmJXQ1NmbnlLVmQ3dThUMVJJVDdQMEFHTnpvNXM1bWVqTHY1QU5RQnVWUFNHbHJOMkhzeU4zcTF6dl9Fdmc9PQ==
"Do you tell them that physics puts the physical into science? It works with things like mass and energy.

Luckily AI will take out the managers first.",r/machinelearning,Z0FBQUFBQm0yeGI1TVNoc0lDbFdwVjFpUm9EMkItUmVxYWN5RlVwUHFjVnhrYl9hN3VXRnVtY25mdmRQeXlqV2pZOFlRVlcwRF9YQ0NfYjM2NTBGREplb1RfUDFGUGxtLVE9PQ==
The risk/reward isn't in their benefit the web dumps they collect is plenty of web-like data for them. Extra web data isn't that valuable. The sources they really want to avoid copyright for are books and articles no longer available on the web. They also have tons of YouTube transcriptions.,r/machinelearning,Z0FBQUFBQm0yeGI1RDEtNG5aaWlYM2VOTEJGUHNWWi1mdERlVllVQjBWbjZnLTdnMktCSTNVWUZxRVg4SnE0bWhnUlFsSlNRa2ZTNzJFS1dzdW5KSk9oaXhFYzZpQ2hJUlE9PQ==
"what about it? 

Intel Mini Nas12th Intel i12 N100 Micro PC, Mini Computers No RAM NO SSD for support 2\\*20T hard disk frams, Mini pocket computer, Easy to carry.

It is very safe without system and ram , you can do the Installation by yourself , Only 199

[see details](https://www.amazon.com/dp/B0CQBYGRHG?ref=myi_title_dp&th=1)",r/machinelearning,Z0FBQUFBQm0yeGI1cXBqc3dyYkh3ejU2NXBVNmxxd3htMEUzanFpYm1WUVA3Si1nak5FM0N4NUpxQ0ViWGl4RmdJdHlKSjhqSVRBQzhsUlJiMWdwc3ZING54c0Zta3R6VHZUSzdWWG13NlcyNjFjdkNwaVFCTW89
"what about it? 

Intel Mini Nas12th Intel i12 N100 Micro PC, Mini Computers No RAM NO SSD for support 2\\*20T hard disk frams, Mini pocket computer, Easy to carry.

It is very safe without system and ram , you can do the Installation by yourself , Only 199

[see details](https://www.amazon.com/dp/B0CQBYGRHG?ref=myi_title_dp&th=1)",r/machinelearning,Z0FBQUFBQm0yeGI1dm5BajdFNFBTanV4Ny03b3NrUUFvUXNfbW1oLUdpaXJLSjNQMndxc29fQnZHYVhYUTF4bFRROVRabXpWMGo5OTRmMFFGdW5HbVFUWTRMTlZUeEczejIwT0hweDVzb2x1X282LU9KYzBNREk9
"Figure 1 and 3 of the YOLOv3 Paper:
https://arxiv.org/pdf/1804.02767",r/machinelearning,Z0FBQUFBQm0yeGI1THR0OXZ2czFGMU5HUjhkUG8xMUNxM3picjQzemNvNXdjTndiNGdISlJwT3haVHdpcFViTng4T1lZUmZKeWQ1V0s0TVJDUmNrTlR0cjFPTTMwNzNQLXc9PQ==
"Cool question.

Not that I know of, it feels like a bit too advanced (which probably means someone will launch a tool next week). But there has been a lot of work done on simulating and refining motion in robotics. You have probably seen videoen of randomly built robotic limbs that tries to figure out the best way to use its physical capabilities to incrementally improve its mobility. Same with models to improve aerodynamics etc.
Understanding and describing the physical properties of the world an area that has been heavily research. Machine vision in robotics (self driving cars as an example, or pick and place robots that learns about the world through manipulating physical objects).

The closest thing I can think of right now might be to use a combination of chatgpt (or similar) to create code to build 3D models. In blender you can input Python code that generate 3D objects and motion, but to create a functioning prototype, and to actually test that prototype in a useful manner is a different beast alltogether.

If this is just for fun you should just try asking some generative ai to dream up an image. You will probably just get gibberish, But try asking it to create a schematics of a new way to chop wood :)",r/machinelearning,Z0FBQUFBQm0yeGI1c3ZmSkNDNGV0bzRyb1g3NVBhN0ltYnFWekQ5Q01ReEVXZlhKLWFGbmpLV2RJZENZZDZmV1ZuOUZKSlpBRjlqN0RTdU8tT3J1RFpPRFdFSHJIanlzeVE9PQ==
"While actually adapting to better fit your problem, not just.. changing.",r/machinelearning,Z0FBQUFBQm0yeGI1R0xfaWdyVmkwdDZhc3ItUDBZR3JjemhVbW4wSU82WGxhNGFOUTVMcEVMeXFGX2w1QXcyTnEyZTRmaHdhZENEb1JBRTlJU040YVMyYmlxMEVuOEV2UXc9PQ==
Any papers speculating into this?,r/machinelearning,Z0FBQUFBQm0yeGI1SnFxQVZzUmxEcXVYdk0xSzM3V05xTVpXM2l2aWZ2RklLUmpRakxISVdQcl9GeUVZSW1HZzBoSktNTWFJek0wYzJTeXNkaHhhNzdVa09tTWNsMVg5R3c9PQ==
"I mean, I've had this happen with a whole bunch of different (types of) models in both pytorch and jax, so I doubt that. Might be that they've just finally fixed their bug though. Would be nice.",r/machinelearning,Z0FBQUFBQm0yeGI1Q0lham5zMEMzd1YxX0QtQjJ0NWlxQmhtM3lqRXIzNDdkX3dQWmNjZHBSdWtxdTVNc1pUVXNXSmdzMjZJX1pJNVlna1h0Z1h6bmZ3NmRnN3ZQQmlBT0E9PQ==
"Oh you're right, I am mixing up the two concepts 👍",r/machinelearning,Z0FBQUFBQm0yeGI1VTVDd0l3UVlGWW9DeVZsSE9tUldsbFlQVVNCaXpwdzdlQ0hjZ0EzN2dXcUZRNFFTeVB6Y2FCZ1NHaHZCZmNaM3ZiWjJUV1ZCT1FILXpHcXFJbG9BQmc9PQ==
"Not a paper, but here are some other resources which might be useful for you:

 * https://github.com/rougier/scientific-visualization-book
 * https://github.com/jbmouret/matplotlib_for_papers",r/machinelearning,Z0FBQUFBQm0yeGI1dnQtem9xOS1oNVNZY3lFSkhWVXNqT2ttaDdCUmg2bWI0M2owTlF5cUpUU05GdGVjVlJ0QjI5WGNKY0NUQ0xBQzNxcFJDMUgydG4tWENBRWFTMzdqcEE9PQ==
"Can anyone explain how to make it for school project with full material list requirement
Please help me I am only a student",r/machinelearning,Z0FBQUFBQm0yeGI1bkxzdVQxVUJDOW56OVVBblFkdTJjc01MS1FLdXZQWERqM04wNHUwNUw0bVdJV0h5YVZIVm40UDduWEhBNGN4UW5tSUhnOV9WUjNhRkU4RnA1aXQ3cEE9PQ==
kys,r/machinelearning,Z0FBQUFBQm0yeGI1X19tQUluNUpRdHhIRXpQMXpZeW0zckdmaFNXOXo5dVYzQ2lRUTlOSjllYXdXYmt3YzB1MGhDOEVMZkpfN05Ta04zbWYzeE16djJUMnA0LVJ2VHhRSHI0U0NkVGpOaDZQbnExbHEtZk5zOUE9
"We recently released MARS5 on Github, fully open sourced, [https://github.com/camb-ai/mars5-tts](https://github.com/camb-ai/mars5-tts) -- it captures prosody quite nicely.",r/machinelearning,Z0FBQUFBQm0yeGI1Z2NoYlBqV1lpR0JnMy0zZGRuZlpHbVVJMXFYSlJLR0o1VUwwOWlPNEE4cXphN1otQ29lRnlQWXlBNlBuM0M2V0RLZkZRdHEzbDA2dTJTUjBIbWZOS0puLUFrX2k2elJCUGxIc01yVDdPdms9
"Just include an appendix with updates, transparency is key in research.",r/machinelearning,Z0FBQUFBQm0yeGI1UTl4ckJ5dWRfaEpuZzZBNTgya1Q0Y0pUT0Z1RFBNeGF5Q1ItZ1VjRjFzelJRQk13aXZYbWs3VmxuWnlPTmtTOGpSc2hLSHZpMC0wdjVNWmt2c1ZkSEJRWUhicDZVZ25ZOGZ4WkNabDZJSXc9
Reed Richards out here,r/machinelearning,Z0FBQUFBQm0yeGI1NVYwdExUWTdKM283TmZJeUlFSGY5bzAzUkhfZWllSGY3bWtCckJ0WkgxdlczQVhRUmdVNFM3Y3NnS3YzVzZ2ZFhPUXJ3dGw5Y0NKNjJaRi1WNUJuN0E9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI1X01VV1FuRkZBQU5zX1U1Y0xMd1ZMellKRndlQkpLVnRlUXRSTnFvRktuR05QWG5tM3NYSU96TC1IdFhYeW9JRXVrSVczajR6dFV5Qlc5ZTV5ODB0d1lrY21zOW5BUElEclc4Y1J3VUFBYjQ9
"Because squared error is differentiable everywhere, making optimization easier.",r/machinelearning,Z0FBQUFBQm0yeGI1dFAxbV9FTmw3TEpka2Q2dmZwNnoxdlE3YnNrSFVyMkFCT3kzQ0VEaFNmUU56XzJaVmw2TC0xZ0lLOFEzNG41Vk9ZNmxEYl84TE1MWkhpOHludEp2b0lwSjNiTVFvejk5djR5SEZlUV9wNXc9
Have you tried using a custom callback function to access the loss function?,r/machinelearning,Z0FBQUFBQm0yeGI1OTBKT1B2cTVqaUNsSzVSeDNZLXJWTTFPX2JJektYS2VCbFVpbWk0b1dmb0tUbXpJeVlUaG9BZzM1SHkyUk5YUzJqSmlLNFkwd3ExMkIxVlZMdnBfTTBuSm94akJ1WjM0SkF0cmxqbnV3VGM9
How would an interviewer judge me if my research topic is very niche and has no practical applications (yet)? Do they judge by the quality and number of papers published?,r/machinelearning,Z0FBQUFBQm0yeGI1dlR0bXNSRzZPVmE3TU15Qm8wMktCTWdROUVrZHdzdHYzbWRTd252bmZXWkVESmpNcHUyYzhlY3NZX0huSkRHOGtlZkNrTkgyT1ZlNXdHaG9iUUgtcFlYSzllMW9PM3JmOS1tZnJ6V1RZQzg9
How would an interviewer judge me if my research topic is very niche and has no practical applications (yet)? Do they judge by the quality and number of papers published?,r/machinelearning,Z0FBQUFBQm0yeGI1SzBsRS1QZUhGVHRSYUY2QTlWaU51YTFDQWhkTzNZQnJkOV9SOUpwa1RlYmVYR2N3NDVDMHotalRuTHF6Tk5VcmVCeV9pSUx6MjE5RGxOVGthZmZKcDlXN1hxVE5va09pakVvSDhPSkU4WVk9
"Adversarial attacks where you define an epsilon ball as the perturbation you wish to deliver to the set in order to make the model inaccurate needs constrained optimization techniques, possibly projection-free.",r/machinelearning,Z0FBQUFBQm0yeGI1UEhXZUJSNE9md21GN0hlN2RZaGtCU2k4VkhpR2xDQWc3T0EzYmZ5d3dpVDZXUHJNdlZQcG04WnlHTmJCZGtJVG94b2RxSThhcnJUVTltZktsYkJ4Y3c9PQ==
"I don't know if this is going to be hot, but Yann LeCun and team are using Joint Embedding Predictive Architecture:
https://arxiv.org/abs/2301.08243


And it sounds pretty promising to me. LeCun talked in an interview about this being useful for things like video generation.


More broadly Deep learning and LLM/GPT ideas being applied to vision is an interesting area (lots of work the last few years on vision transformers). Robotics is one of the next huge markets where applied research is getting funding, and I suspect there's plenty of work to do on vision and control.",r/machinelearning,Z0FBQUFBQm0yeGI1bGlveHhnZnJZV2lKOWxGWHc3aFBPc3dxaG02MUVjRDYtaVFSZmktVjFZeXRLbjI5MHFvdS1vWEtmZk9mTldwNDd5RXU2aXh0UUtwa0t3YlVBWU5nY241OGh6cFIxd3l0dGJwMi01aWRRS3c9
Now this is a statement that hammers the nail to the point. Well said.,r/machinelearning,Z0FBQUFBQm0yeGI1ODhkSzFsVHQ0UG5oUTNESGc4QXVpRDgzZ2FUV0s1Wi01NU8wMFVudTdsYWM2QW1BTmhtOTZtMVNkbkhrYU90di1FVHZqTl9TU2lDdW5pb3Z6VHROZlhhOHB4b3lDU1ZMZ2RMM2pfbXpGcGM9
"You are underestimating how many businesses are not interested in using machine learning solely for prediction tasks. While conventional machine learning tasks today often lean more towards engineering rather than modeling, this isn't the case for all applications. For instance, tasks involving causal inference, such as understanding churn. Or even just working with data from a natural experiment require more than just a off the shelf model. In these situations, where causal models are necessary the ml default pipeline won't work.

My opinion is that you and op are describing the work of a data engineer",r/machinelearning,Z0FBQUFBQm0yeGI1bzNEbHoxd19ZWmFNTVZkcFNkaGVPazhvcHFNSHFIekpPZnB2S0tmbXljblI2dS1qVERpUDhDbmktV19ZUFFBWFdFdG9EXzhSb1ZhN3duVWd1NTFNLUE9PQ==
"Not specifically about phd, but academia in general. I worked as research assistant for 2-3 years, then master, phd etc. Altogether 8 years or so. But my research assistant experience is completely ignored. I was always treated as if I am underqualified for the roles that I am qualified or I was low-balled. Then I changed my research assistant job as if it was in industry (wrote the research group's name instead of the school). Now I am qualified enough, lol.

Another thing is my friends who continued in industry after undergrad are now engineering managers in Meta, Microsofy, Uber etc. My career growth has become so much slower due to academia.",r/machinelearning,Z0FBQUFBQm0yeGI1VzVieWNWc0Nhb1E5R3BhWUJDanhCZElGX1pnTWxVRmJkNVBaZlpSbFEtRGpPWnNRVHVQSy15STB6S2Vvb1BKMkxIRnh5QXBnVnlja1VYWnZQNzhTbEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1UUllQ1pjQjlSM3BvM29sTTBuT2xLRUR3czYxMFlSYlM3R2JVR2hQd1hIZTNMbklvUTVCV2sya0Y2eUphR3N0YXhCZjZNOUJGSVFSTXhGbjJwRGdjbHc9PQ==
"Disclaimer: personal opinions from someone actually hiring these roles and building these systems at a high level. 

You are confused. Everyone on this thread is confused. Are you an ml engineer if you only use pre trained models? No. Absolutely not. 

Do ml engineers build new architectures? Also, no. Absolutely not.

Fine-tuning and changing hyperparameters are also totally different things. Different still from training a model from scratch, different still from building a model from scratch, different still from developing new architecture. 

Generally researchers are responsible for exploring new architectures. They do not do it from scratch. Very, very few researchers will every build a modern nn from scratch. The same way a web developer won't usually make a web framework from scratch when they replace a part of their stack.

Ml engineers are then responsible for the ops, which is usually training and inference. Training both includes foundation models ""from scratch"" and fine-tuning.

An ML engineer will generally have a small number of hyperparameters that they can change like batch size and quantization, but almost all of the parameter tuning is done by researchers or automated systems. This is different from fine-tuning.

If the only thing you can do is run inference then that's just regular software engineering.",r/machinelearning,Z0FBQUFBQm0yeGI1TU95UTlOekRBbUVlRTBoTlRBdnpHQjZYSUV5NVJXZGJBU0ZfSENZUEdGRXQ2TzQ4VUdMTkdUU2lSM2JyX0dzVVNIei1MbFVQYlNFWjNWOUZRVFkyVnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1QUtrUWJLcUdDeGRyTDNUOGdDS3dNMEIwUFk2YWdXdm84VW1CWTNhVGpDZ3hXRlVwaDA4cHZNNXlOTzVrMWl4WWpfR24wb1JsVnh4UDlCTFloZUdWNGc9PQ==
"You can convert a video to json, it doesn't make it a legitimate text LLM input",r/machinelearning,Z0FBQUFBQm0yeGI1RGpkY2V1TGhKU3NURW91bTZWR1cwNjdjX0ZDQS05Q2FpemtYeTVMeHQ5eThBWFNuR1ZqTF80cm1RODZEN1hvTi1aTnlCUEx4bm14dWtCbFQ1UGd0T3c9PQ==
"It’s not really AGI that matters, it’s AAII. Like, when an AI is better at designing and training a better AI than all the human experts are, that’s the tipping point.

AGI and a slow form of ASI will come not long after AAII.",r/machinelearning,Z0FBQUFBQm0yeGI1MXJVTlQxQkJfNnBKdWQ4NFZkUEdBWUg3T1lSWmpGOWdmWHVkNWkwR1VCYVFzdEpnUThnNWpOc0ozMGk0b3hTUFo2dW9XTTg1TGoyR1ZlblBQUGJvdkE9PQ==
Nothing changed for me. Can you share a screenshot?,r/machinelearning,Z0FBQUFBQm0yeGI1UTY3bnlvcm56UVU2aGF6ejRQa3h6RWxSakltdDdpc0ZlZWtiNjNBTl9SNlVSOXlxZ05VSUdEOHZvekhzMzRDbk0xOVNGZzJOeE9oVlNTVEtfOWdZQWc9PQ==
I really like figures in papers from https://scholar.google.co.in/citations?hl=en&user=gXW8J2wAAAAJ&view_op=list_works,r/machinelearning,Z0FBQUFBQm0yeGI1ejZ2LXpqRnVtYk1naFl1MHVhSG0xTHY0SEhQUnJaN2JvS1RDUFpxZEV4TFUwTWZTeFBRME5mTDA3THBjbjZhdUZxVkIxbEMtanBvUWEyRVlGVWhnSmc9PQ==
Almost 2 years later and this little guide and 1 line of code lifted my inference speed from 6.5 SECONDS to 32ms :D Thank you so much!,r/machinelearning,Z0FBQUFBQm0yeGI1ZTRUMGx4X0dvTG1QZFU3QXMtWWpGTXZwN2JsLXkzdVlrWWpmNUpuUDhkR2NCcjNQa0pWS2xVSTJ6UDZWY3I3NG9OU1lRTHpfZ2djVTlMcHRWbnNFVXc9PQ==
"At work I have a very well performing BERT based model doing classification on a space of 700 labels. It works very well.

I’m still being asked why we don’t just do it with “GenAI”

I’m so bored of this.",r/machinelearning,Z0FBQUFBQm0yeGI1ajRRdUJTaGxqUlJjWWxCd1Vhdk1PLU5xUXNoR3FYTjNtYzdlUUJYUE9GRjVYZXhaQUNNbExCejNTUmdfd0FZS2hXbU9KZkZWX1ZCMlliMGhueUtXcXV2RWN2TG04WGxTbG1qSW52aWVBX2s9
Why do something expertly when we can pretend to do it in a fraction of the time!,r/machinelearning,Z0FBQUFBQm0yeGI1SjBHTW9JVXFRQklNMElCaVdFTzJaLUNoNFh4YnZRS2lSTUozblVWSC1hemZaejhYamQ0NDRoQWItd3pxb05DYnhveEt5N0xVckdSOTJYOUtmS01oX1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1b1BhTlc2NkpmV0hxNVRzMUUwVjI3TU1pMHp2MHlJTHR6Sng3bFNSRGxQN2NrdXZDWXppQ200VHluUkNXanpqUlhrWmNJTFdQd1RpTEVDeTJVY215Wmc9PQ==
I actually read the contest page lol. The **data they provide you** is JSON. I wasn't saying that you can convert it to json or vice versa. It is json. The visualization is the browser rendering the json -- they mention that on the site.,r/machinelearning,Z0FBQUFBQm0yeGI1eG9ZN1FCdlc0Z3l4LXRMTXJiVDlUanpDVWMxbkpqWTBvbU9CZTdoa19KbXBhVGZ2aWhGWWZHZ3lPRGxaYURRV1NYczFPTWdTek1jMkk2d0Zqbk9lalFvRzVVU1dEc1h2NE5tLTJjeDhnUVE9
"After the arrival of ChatGPT whole industry has now shifted to Large Language Models. People are trying to make a multimodality model that can do all the tasks (question-answering, image-generation, video-generation, etc.) using a single model. These days Generative AI is all over the industry and everyone is talking about this.

The major drawback in these types of models is 1. require huge data to train and 2. the model size is too large

if you want to do research you can research these topics, and you will get lots of research papers.",r/machinelearning,Z0FBQUFBQm0yeGI1Q3pPcG9IS1ZfVlU3YjBubkZfQmJBb3FSTDFyUHg1Z3JlRV9YaFVKbDgxVDJCVjYxNWFxSUh3M0NTM2hlZ1BvQVlJX19jN25qZkJGbENjaHdYN29XZXc9PQ==
"Having written a couple of continual learning papers, I can only hope you are right. Right now it is such a niche field.

It doesn't help that continual learners cannot compete with the state of the art models and thus they have very limited commercial use.",r/machinelearning,Z0FBQUFBQm0yeGI1SDU5V0s5bDAxdVRNMHFuczgxQnlhT3ZpdUZTYkRJN3d6N3lqNC15V056Z0dXVU92WHREYjFQVEg1anVsSHI0cks1c3pJV2RtVEtXci14U0Vudklyc1E9PQ==
"Did you actually read their arguments? They're not OMG AGI REEEEEE. Besides, smart people can be wrong too. There are Nobel prize winners that have believed in nonsense even while making great advancements in their field.",r/machinelearning,Z0FBQUFBQm0yeGI1YU0xZ0V0TE5MWFg1clRYNm91d1VkZkZ2aV9EOG1GMkVHWnJObUQ4Nlc0SDJ5Y3FUMjJLcC1KV090d0FZcTFvUmtyekZ0QlBYcklTTjV1WTV2S0MxRjltYXByMHFkYmxCM051aVhQUXRkMTA9
"https://i.giphy.com/0mKPytMujTds4e26IS.webp

Project manager’s face when gpt4 confidently spits out an incorrect classification which cost 10x over the lean model I tuned 4 years ago.

But they can see the output token by token like magic!",r/machinelearning,Z0FBQUFBQm0yeGI1T1NxSHYtdVA2cEUteXpTQTIwLUNzdUx4MTFtVjhlT2dSaUN3NGt4ODQ4OVJOZGswRWVyNGwxSHB3TV9ib2xpeVlhNV9obmhtVGp4NTNSQU0xbC1CTk43RG9Bc2ZCMnlpa0VVLU91R2JRR289
That's another problem. What *is* AGI? Does it need to be a human level intelligence? Does it have to be self aware? We can't let people who own companies that benefit from the hype be the only ones that define it.,r/machinelearning,Z0FBQUFBQm0yeGI1ak5mYmZ1UUliejFtSTc1djE1T1F0WldEaUpFRE9kQXdLSDRFbS02S19Ga0g3R0J4YzRKVUdYOGtSQTdlVEp2YmN4Nk16WjZvajVPNjl2bWt5enF6bHlZZGNCaDFrTEdldmltSFk2UGgxWkU9
There’s a strong overlap between the tech and FIRE crowds. These people expect to be retired by some time in their 30s.,r/machinelearning,Z0FBQUFBQm0yeGI1cnkzWEhEOVhiZUM0U0dKUFJocHdpcDIzdUotcFllQnBLbWZrUUJRbjlwRG1sQTJUMnZubTE3eW14dXBQeE5VbG9CWWlHSnUzbUdZZTZ1dXdDLTk5dXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1cGNVVXhhem5BenpCX3Z0RDhMX0F3M255dm45RWpMUXlkS29aZDlGZktzeXNNcmNpZm05UnR2ZzI0RW5zUnpzQzFLaG1ZNFk5U19ybXd0Ty1OalQ0NFE9PQ==
“Generative AI is a fast way to create more legacy code that needs debugging”,r/machinelearning,Z0FBQUFBQm0yeGI1Y1VscDNNdS1NT3FpWHNac0E2Ukd3b0JWYUUwaTc1RXFmaFRSRU1RMGVIM3ZGNXNTSFNqNE85Wkg2RDhfb3dILXYtLTVKd0ZfQlltOVdjYnExMmxxbkE9PQ==
Damn. What a roast,r/machinelearning,Z0FBQUFBQm0yeGI1akM0NHF6U3FfV252b3NNa1hDZnIxQksxZTJnTEpZUU5DNmVJdExtTVBsTzNWcE4yczBfQ1NWcVRXYkFWbFBUM2x5WkE1YzFqN2t5WXBfMXV4a2hxZkE9PQ==
What a legend,r/machinelearning,Z0FBQUFBQm0yeGI1SE4zN3hPRmNMcm5XWjF2MF9VZ2ZCbmRhRkVfQllwS1dhNWJIaXlwUE1NdnRRNXpkNDlNOGtfeHppX2x2SG1ZbnV4SFFickc0aWZsT243ZGxCZHAxOVE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1M1JldjQzSFh0TzlGTjd6ZnNEY2VFUmlfRXhuZ2poUEZtdlFTRkZBTnBIdkhQczRRR1JBTUIwOV9wWDR6RmtwWUZYaDRKdHcxa1QyU3JVdFM4QWo5eGc9PQ==
"It's definitely not. There been a slight pullback from basic research, and shift toward applied research. But my guess is that there has been a larger reduction in software engineering roles than there has been in ML research roles.",r/machinelearning,Z0FBQUFBQm0yeGI1Uzdsd1VmLWIzLVNVZzFXU0R6UUV0bGpoX3VpR1loTklRdVlPMVpudXVNckFwWVQwYlJjdnplQ2dtSG5RajJ1TnpneFh6NldfTjV3NExDQnRvelRIV2c9PQ==
"To be fair, up until recently AI was narrow but superhuman. Think deep blue or Watson on jeopardy. It couldn’t do much else but it could nail a problem. 

LLMs are pretty decent at a large dataset of language. That’s on the other dimension. Not an expert but kinda decent at answering questions. On the plot, we have a point on the top left and bottom right but nothing in the top right. I suspect the models behind these two successes  aren’t compatible enough to slap together yet and get a super human language using bot. 

Additionally, we haven’t gotten to the point where we discuss what intelligence really is. How we learn with less.. how we are different from other animals that have bigger brains. That’s a whole different conversation that AI isn’t ready for yet.",r/machinelearning,Z0FBQUFBQm0yeGI1bGRRZ2NzMXcwVS10bUs5RWo5c2VPYkNOZ3JjUXVmaUVEc3lVYS16RWU2M1o4UGRISlo4S1dYS2FaNmZfdXE4SG5kcHlUU1lfV3htWVU1WFdvWjkwQVE9PQ==
Id argue that 99% of tasks do not require that much rigour. Note how I used tasks not jobs — you could be an ML researcher and still toss rigour aside in favour of delivering for a lot of what you’re doing,r/machinelearning,Z0FBQUFBQm0yeGI1eFdidUVkd3MtQ25WMWhiNk9HS0NsSjBBTGpFUnpXcUJLTkdPM1pwRzhyRUFCc1NWbkVnbk0yU2JDbFkxYWRJZ0tlZUxTYmdyVHFwa0JRMVhyOE45QlE9PQ==
yes but when they report human accuracy they do not give humans json as the input.,r/machinelearning,Z0FBQUFBQm0yeGI1ckhQWUJ5X29EUTY5QWpLTVJSZ2VDQkp6ZS1SY1d6RkJ4cUFneUNoa3Mxbnd0THZ0aXVIZk52d3VuUmJ5NHZaSHZWZnpEd0NiZ1VoSmJzNEdDdnVmSHc9PQ==
"If the model outputs copyrighted content, that's a separate potential copyright violation from training on the copyrighted data.  Someone (the person who distributed the model?  Is serving the results of the model?  Both?  I'm not sure.) would presumably be liable for that copyright violation if it occurred.  There are still factors to consider, such as:

1. Did the model quote minimally from copyrighted material for the purpose of commentary or analysis, or does this otherwise fit into fair use exceptions?
2. If not, what damage was done?  Copyright violation isn't a crime, it's a tort. You don't go to jail, but rather just pay damages to compensate the injured party... which means there has to *be* an injured party.  In some cases people have demonstrated that if you produce enough of a bit of work to prove that you have it sitting in front of you, the model will pick up and prove that it has memorized and can reproduce the same thing.  That's interesting and proves the model is potentially *capable* of violating copyright, but if no one was injured by the experiment, it's unlikely to be a problem on its own.

That said, there are definitely cases where a model does reproduce copyrighted material in a way that is not fair use and injures someone, and this certainly violates copyright.  That's a *very* different question from whether *training* the model is a copyright violation.

The question of whether training the model violates copyright is still being considered, so it's hard to say anything definitvely, but it's at least very *plausible* that as a matter of law, it may be decided that it just isn't.  Learning from and applying the generalized knowledge gained from content in many ways strikes at the very core of fair use of copyrighted content.",r/machinelearning,Z0FBQUFBQm0yeGI1WnJ5NDRGbUNoTHpQMnBZdHdNUDVXQ1FfVE81RDNlbS1STFhlYW4xNmJHOEFQQlY3WlFYem5hU3VQYkN4TUQyZnppemtpZi1SV0phWE9oSy1GTkZkQXc9PQ==
"I can appreciate what you're getting at, and maybe ""identical"" isn't the right word to have used on my part.

I'd be curious to see what order of magnitude of impact this actually has. If there are meaningful differences, then wouldn't that imply faulty design?

Imagine a world where you need to design your software and algorithms to depend on the specific CPU architecture that it is going to run on. That would be ludicrous for 99.9999% of real world uses.

Even though there can be some very minor/subtle differences, these are typically ignored because in practice they don't matter.

I've personally never seen any meaningful difference between model outputs running on a variety of GPUs and even CPUs with the exact same software/algorithms/libraries.",r/machinelearning,Z0FBQUFBQm0yeGI1LXlfRkNmNVZrRThzamlJWWk1T25TeXI0aHZnNzdzWU9BdUdoZTNKckhsX2lpdHZQMTNmcVVwRWd1WlNBMlh0R2g0ODNRS2NzWnRqOC1vTXZFODF5U0E9PQ==
"I think it's very likely that training sets that are scraped from the internet do respect robots.txt.  Not doing so would require someone to go out of their way to build or modify scraping tools to avoid respecting these policies, and there are a number of reasons that would be a dumb thing to do.  Not only would it expose the company to liability, but it would also add lots of garbage content into the training set that's far outside the distribution they want to learn, and given the tiny amount of actual human-readable content that's excluded in this way, it would likely do far more harm than good to the quality of the result.",r/machinelearning,Z0FBQUFBQm0yeGI1V1VCTnQyNGh5RGFVSUw4dGRLalhDX0xEc1Z4TmlwZ3VvZmhCNTcwYkNybnNEU25Ha1JobVZnWE5PVlVleG1qd2piYTBkVEVLZmtGR2UyUUdCZFJQVlE9PQ==
"Because that's what he is asking for how its useful for a job. The down voters obviously didn't read the post.... He honestly needs to be more specific on what he wants out of it or nobody can help him, so he has to look up job requirements. Being overqualified can bring up red flags to some folks ""He has this, but why is he here when he could be doing X? He might be really bad at X because X?"". That's a bias you can't get rid of, but if he is looking for those kind of jobs that aren't so PHD needed, why not just skip the PHD and get a masters or keep a bachelors instead?

You don't need to be level 100 to put on level 40 gear. Now if he wanted to do it for fun like a student I meet in my last conference I presented at, go for it. But it sounds like he is doing it for pragmatic reasons so he needs pragmatic answers.",r/machinelearning,Z0FBQUFBQm0yeGI1MVhrd0ZyWjNqV0ZTRFZBN0NVUVRLM1dwV0xobkpRLW5ja2FNak9EZ2M1X0V2M19EVzBtT2FYZndfMU5sdVAyZFhGZTVDQTdvR0VhNlB6aHBTZjhSVlNZVzZvVlpyaG81cHJHc0RIVjBDM0U9
"Coincidentally, I also tried implementing QMIX a few weeks ago and tested it in MPE simple\\_spread\\_v3 (a fully cooperative environment with 3 agents).

I also experienced these phenomena of my agent learning the 'wrong' thing, as the reward would continuously decrease at each episode. I tested some things like normalizing the reward to positive (between a range of 0 and 1) and changing some hyperparameters (like update interval of target networks and epsilon values) but the problem still persisted.

Let me know if you have found a solution to that!",r/machinelearning,Z0FBQUFBQm0yeGI1Rk1FcWZPQWJMUVdjbnM3bnlrZ3FicTFZODFWMzIyLWNkV0VkRUVhV3VxUFJVM2lxWWVkektsWlBFOE9DOEQ1bWJsaGl5Ykt3LVdlQ0oyRzF2SFhUQ0E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1bTNoN2Ruakx4dUFXTS0wYmdDam9MbkNxcVdmazhaS0VXNFY1TVYwbU9YRTF1REliOGZRY01QQThlcTRvOVRJazVWVmZMU0dQQlFaa21xbzRaNk5XYUE9PQ==
Kind of have to keep it secret with what you test though or everyone optimizes it. But if you don't have it open you don't get good feedback from the community. Kind of a catch 22.,r/machinelearning,Z0FBQUFBQm0yeGI1TTRuZk5hS0VMSnpkWVhwUnQtWG5qdHk3MkRZd2toNGNiODAtbUhtU29BQVExUlBzVUJUbWN3UnJhWWlWcXRXdDAzc09sc1YtemUtX2FicVNxcjRrTWpneU5xakFOT0dKRk1IMDZUTTJONUU9
"The cult of personality in this field has reached awkward levels, nobody is above scrutiny because of their name. ",r/machinelearning,Z0FBQUFBQm0yeGI1QjluX2NaN1NDd0dSc2Y3Y2dMSjZvenFLQloxY3VKY0EyRFBNQzRfWDF1dngxZDhBa3ZNdE12SGtCYW11MEZVTDdab0FYODN2MUJBQjdQbEh5cmxXSnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1Y2xSMG5yT25XdGtUY0w5ZC1zREgyc1JrQ1F4SXZBeGMxTFUxLXphb3gwb3VaLXFCSV8ycjVWOEM3Ql9QTk9mSVgwX0c0MTY2QzlGOGMzWHZtaHNaSUE9PQ==
"TLDR: ""AI is never going to be *really* better than me, period. Nothing to worry about here.""

Sigh... Another article about convincing yourself by trying to convince others.",r/machinelearning,Z0FBQUFBQm0yeGI1Y0RwN0V1R2E2NFp3UzQ1ZkplcTJQNkg2YTJGeTdUc2VfbGdoVnBwb3gtVU5YVGI1LVZSSGw5ZzNuLXJwc3FUNzA0UnhsVWl5MU1XMTd4c1hUWTJDWFE9PQ==
Don't need to be level 100 to put on level 40 gear.,r/machinelearning,Z0FBQUFBQm0yeGI1X1k2eEIyX3NwcVhYN0NsUlhCVEdoUzZFcFVnTGpLdkloQjlYbGlCa1dYR0ZiOE1MV2JpQm1Zak45anE2TU1tUkhwN3pQWUFWUGttRDZnMXdQQi1TZ3hOLWZJal9ZTEQ4dHlvYnJDNXg4T2c9
"I’m a finance major looking to get into ML. Would you recommend a masters in engineering with a focus on ML? I’ve also been doing coursera courses on machine learning and ik that the courses won’t help me get a job, but I’m just doing it for experience and to learn. I’ve also been working on personal projects on the side.

Edit: my professional experience is in equity research",r/machinelearning,Z0FBQUFBQm0yeGI1azk4UUppa1lYaVhCWG1sT1dzOENYdThSRmthVjRNSTUyQzhEN0w2UXBuTkVmLUlmWkE5RkwxbHNOQXJDTFdueEoxRi1TdFRkc0RXUlNVYW9rWktDQVBDckx0VTFtRFppLWhfNVpJWmljSFk9
"Actually I’m just curious whether there is any negative impact to your job opportunities with a PhD. Yes I do agree with you that if the focus is more on career than research, then one should just get a masters or bachelors. Thank you for sharing though!",r/machinelearning,Z0FBQUFBQm0yeGI1RkFUTUMxMlVwOXNVbzM1YjJpaHdCMzJBSVhWa1BQeldudVVJbEpDMzlyWEJfZFg4SWJETlA2LVhsUFluX3hNQzA4Z055d3prU1UxMFBkdjVZdjNFcW83aF9tYk92LUFaaHh3QUpaU2NqNUk9
I'd love to see a convincing argument that it will become more valuable?,r/machinelearning,Z0FBQUFBQm0yeGI1amxJQ0RQV0Z0bm45NDRoMVYwM25obV9IdEYyX3UyWDY3LVNmZ2YxcVZma0hZVWFzSmdfU1A1bGU4V0lEQVBva01zaUZZNVZMYXdqNXl6bWNDZFdqLXc9PQ==
"Yes, I guess that's the best idea to expand information without giving the impression that the previous information has been deprecated or something similar.",r/machinelearning,Z0FBQUFBQm0yeGI1TUxaZmRUYWprb09YS2R3NU5LSV9sVkZjSFprM2c2RmVwZ0F5RW45UUhFWmdwTnROdFZJWWo3Z1JzSXg2VnNNcFBLYnBTU2lwWllEbDBVeENiMUhHOWc9PQ==
"""Intelligence does not mean competence."" That's the whole argument here, and a pretty unintelligent one at that.",r/machinelearning,Z0FBQUFBQm0yeGI1VlYwZllrZl9wUFJIcDltX1pvM0Vid2RGakYxNWFSZE91MHVhUXZVS3ZrTlU5Smw4dlRVdXc3T3NWYWVFbkhvdmJfdUhVOTkwT1N0TXFiMzRRckNJRVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1bWxIcmZBd1ZXa1hNZkYwcHppaFJva0l0dnVTQkU5c0hjamVBR0o2UC1nTlBLREpyNVJvb0RjRk9YY2NaM2dqdHNldloyVUtNWXRyNkpBVHRtdHlybFE9PQ==
"Honestly, getting too stuck into a problem is also bad in academia. We say publish or perish for a reason; if you don’t complete projects, you don’t get tenure.",r/machinelearning,Z0FBQUFBQm0yeGI1S3ZkelBXSm9zVEtlMXhUR3F1cTNFZ19Pb003VmJuMmZ6SlBBME5tQlpUUU9GZUpOZlR2b0U3bUhCQ3d4VmNCczU3LUMzd015emctTVMyRndiWm91Y0R2bm1sczJEVXI0YjZOZllWaVhzbG89
"What? Like when evaluating humans on ImageNet they also don't give people the input as an 3-dimensional tensor. So I have no idea how the medium through which humans are evaluated relates to the data. I am talking about the training data for this contest. It doesn't matter how the humans consume the data, it's the same data.",r/machinelearning,Z0FBQUFBQm0yeGI1OFZLZkZXdTRNelBRb3dkQ2E2aTAteXZDUGtZNmtRZk15VUh1aUdQa1FWUVJHMG4xV1dLMk5hWG9BR3Q3RWRHVWRKNmdobzlQRWNWRFRuWnEtT3Y1OWs0WnZqWWluS00zQk9NbzFvbnpiTjA9
"I think there's an easier way to do this: use a generative model, like a diffusion model. The steps go like this:

1. Train a model that generates guitar tracks by doing y=f(x), where x is a sample from a noise distribution and y is the guitar track. *You don't need a custom dataset of double-tracks for this*, you just need a regular dataset of guitar tracks.
2. To make a double track of a track A, calculate x = f^-1 (A) and then do B = f(x+d), where d is a noise sample with a very small variance.

The result of this should be that B is similar to A, but slightly different, and if the generative model is trained well then it will be different in a way that sounds natural.

I think most audio generative models are probably using *latent* diffusion, so to do f^-1 (A) what you'd actually do is use the encoder network from the autoencoder instead. You might not even need to train your own model; there might be open source musical instrument track generators out there that you can just use out of the box and get reasonable results with.

In principle there's nothing wrong with your original plan, but the challenge with it will be that you probably can't get enough data to make it work well, and acquiring the data is time consuming and difficult. Better to use other methods that can take advantage of easily acquired data or open source models.

You can also use fine tuning with your custom dataset, if the initial results with the above method don't seem good enough. You can get away with a lot less data when doing fine tuning.",r/machinelearning,Z0FBQUFBQm0yeGI1WG5MZEY3SnJmeTBQSlBseVcxTURaUWJqOGttLWZ6c3FVelRmQ2JELV9kc2w2dWhnLUFOREtTSmN2LTItTzlXUVdRMjlTRlFjcTZlQVFZejlpZ1MwaWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1RGVWa1FDT1lYNi1CNEdYTEhZemhEVTRWMk1NcFZEOU50ektwb0pjbldqLUtPSHVLZ1pBVC1xSEs0QmgwSHdELXRVN2cxV1MxRVdWMll4YW5ycHZIOVE9PQ==
"They may slow you down if you want the traditional s/w engineering career, since a guy with BS will have a 6 year headstart.",r/machinelearning,Z0FBQUFBQm0yeGI1dUtJdGZXT3BQRmFldkU0S2NNMDZ2SXVQQ2JUMV9DbHBac2s1aXgyVHVZS1dSUENLQ2xOa01IUjNNYUtZZHJoWV9xc2YtaXVtQk96SmR3MHhqVUJiZkE9PQ==
"Nobody said they were above scrutiny. I'm not saying they are right.

The commenter claimed that to have the opinion they have they must be either embodying the ""Dunning Krueger effect"" (they don't know that they are ignorant of deep learning, compared to OP) or they are ""encouraged by business owners that benefit from the hype.""

Which of those two things would you say is true of Hinton, in particular?

I'm not trying to poison the well by pointing to famous people and saying they are above reproach. I'm trying to UNpoison the well by saying ""you are incorrect in your claim that there exist no intelligent, knowledgable, idea-motivated people who believe differently than you.""

Once we've cleared away the ad hominem's and No True Scotsman's, we can *begin* to look at the question scientifically.",r/machinelearning,Z0FBQUFBQm0yeGI1SVBZNGhWbVpJZGI3cEhuQ2Yzb2Y2MkhMN21NMUdQbFVNVzJYWGFlQXJIQU5wZnQ0RWpfRjhNdUFPVW44bkRBZ2hkSk5ScHBHUkk1LTJCblkzdTFtRTZEdzc4X09KTDB6T2NBdHVkY05qeDg9
"Do you know any recent papers that show progress in this field? (anything coming close to lstm, etc.)",r/machinelearning,Z0FBQUFBQm0yeGI1QmVlVDJZZUJDUFZxRVhaQTBuQl9vcFplQjVmOFpJMmlQUU1jOTVDb0RUTnVZMERJakl2bDBRNzF0TnJEVWVhNDB3ZFFRMGpkLXpnVmJnREdwXzNLOGc9PQ==
Yes but the point is that if the multimodal models were to be trained on images and videos they might find this type of data (a 3/4-dimensional tensor) easier to reason about then a JSON input.,r/machinelearning,Z0FBQUFBQm0yeGI1bE1sc3JKRV95SmpIblpEdEt2MWV3T3p2a3RfS3VMOTFhZVQzSE1FZ1hqblZFaW1Ldm9lQ1JDaTAweDNZOGM0NEdtbHBUWmZMY1lOSWIxS3JwV1JLeXc9PQ==
"Okay, I get that training on copyrighted material is also a question, but what do you think about the actual model and generated samples that this post is about?",r/machinelearning,Z0FBQUFBQm0yeGI1ZnZfdzFmWFdTVXRfMTB1SW1LTldUcTVZdUh6WWNKNnhRUjRpLXdPVHF1ekw1eUM4OGNWcUtTUzlaR0o0cWFaY2RueDdvRV9fN0VBUXVrcEhYQndnb1E9PQ==
"mamba, rwkv, griffin and hawk",r/machinelearning,Z0FBQUFBQm0yeGI1aDc3VzhfVkxnMktxM1ltby11RWxvb29zdW15bG1CN090OEZNWDc0ZDROSGNJbks4NTZNUm5uQWNQR0x0R01yZHVpSmg3ZFZlRWh3S3QxMEcxWUxjdnc9PQ==
"From the paper: ""We believe that the phenomenon we describe might be distinct from the double descent phenomena described in (Nakkiran et al., 2019; Belkin et al., 2018) because we observe the second descent in loss far past the first time the training loss becomes very small (tens of thousands of epochs in some of our experiments), and we don’t observe a non-monotonic behavior of accuracy.""",r/machinelearning,Z0FBQUFBQm0yeGI1N05NanlhM1VGZk9Ja0hBZWl6LVZHWFNfaldkYUJuVWJnZnc5b3F0d0pZaU9sNjBFU29tMTNrRldIMDh6N05MUURVYVA3cVZmNF9YeVpFNGNmOS1Ma1E9PQ==
"AMD CPUs drastically outperform Intel. No serious developer is using Intel, it compiles too slowly",r/machinelearning,Z0FBQUFBQm0yeGI1UnhuZW9qTnFiOXNqa3p4SVpRLXNiR3U0eDYxcFJJZW0zcnQyRnJ5MWVhUVZEcm5GclZ6WWxISE9jWElhYXpUZlFWc3dhUFk4TjFWZlF6ck5kWkhERWZSZ1NKLXNKT3RYYU1EbXY0ZUZJOFk9
The  VC economics of the last 15-20 years really broke some people’s brains.,r/machinelearning,Z0FBQUFBQm0yeGI1RDVmQTY5dDM0bWJPbjhJY1FfazlMajJFZzRZdkltcDVkNkw3SW5zNm5fSWpmT1ZWVnlRUHIxbHBoeTNvV0RteGg2MWxOVGg5OGlOaHhXby1jb1puTlE9PQ==
I have a post which keeps getting removed by the auto filter for this sub. I have followed the rules and am not getting feedback about what to change. i'll respond to myself with the post so it doesn't bloat the post.,r/machinelearning,Z0FBQUFBQm0yeGI1bmtWdDdIajZOMHB4UjVlaWNxY1NBcWVPeUc2MkUxRUllUVNpNnU2QnBBUjlQSkxOR0ZwcjlpdWI3ejNZWXYzcnZEXzVtRl92WDd4QUpFSG51MDdDeWc9PQ==
"Title: 

\\[D\\] Can System 2 thinking be derived from Notepad tool use for sufficiently strong LLMs?

Post Body:

Hopefully the title is clear. Sub question is, why is this not being targeted by ""Big AI"" right now?

I've basically arrived at the conclusion that we may be able to have System 2 thinking built out of System 1 thinking from the LLMs and Notepad tool use allowing them to iterate on a logical argument. I want to be clear that I am skipping over some expected post training for structured outputs and tool use formatting.

What's confusing for me is that the greater ML community is signaling this isn't an option. The signals I'm receiving are lack of discussion about this concept, and a sizable consensus that LLMs are not ""enough to reach AGI"".

When I attempt to anticipate why this is occurring, for signal one, I keep arriving at this strategy having been considered and then disregarded for some well-informed but unknown reason, because I find low probability that this is a novel concept. For signal two, I think this comes down to a miscommunication where two groups of people are unable to see each other's point. I am in the camp of LLMs are enough to get us to sufficiently advanced intelligence for economic work in broad range of domains, but when I say this what I really mean is that LLMs provide the special sauce and LLMs or OOMs/whatever along with some other structures will get us there.

I think some evidence for my conjecture being correct would be the effectiveness of COT/TOT prompting which coerces the model to simulate portions of this strategy. In some sense, TOT prompting would require much less effort from the LLM when it is able to build these structures and then set them aside without needing to manually persist them in its next output.

I would love to hear discussion about this and am 100% open to being gently informed about this research or how to do this research on my own.",r/machinelearning,Z0FBQUFBQm0yeGI1ZHl3bzlKNUhqRFpONllBb0JYcGh4MW1DTUdHOHJUN1oxdXlqMjFaWVZyMXFnVVg0dE9va01Zcjc4aW5wMVBNSlFQenRpdkNpRGZ4Q2Q4WjlxZzRuUUE9PQ==
"Of course they could be wrong.

But u/UndocumentedMartian 's ""argument"" was that the only reason that people believe in AGI is because they are either dumb, or self-interestedly lying. I'm asking him (and you) to tell me which category Hinton falls into.

If we want to make the argument that they are wrong, make the argument. But I don't see any argument at all except an argument from ""anti-authority"" in this text:

>The only people who think AGI is near are those that embody the Dunning Krueger effect and are encouraged by business owners that benefit from the hype.

It's just ad hominem, No True Scotsman and poisoning the well all distilled into a single sentence.",r/machinelearning,Z0FBQUFBQm0yeGI1X2ZjZDJhdkZObDF4R0RKT2NMd0M0MTNHd3N6dlltcmRQWWRPSkF6c2lSYkMyRUttbmRXQU5GT3o2clVTRXM5MDVtcDctdEZPb0FrbnBhZFNFVUw1WkVTSmpvbGw1cnVMYlo0Yi1OY29FZVU9
Yeah maybe that was too strong a statement.,r/machinelearning,Z0FBQUFBQm0yeGI1cUNMZU9WdHNsM2dab3hqdVRyUXNfLTZubXo1Wll3Z1kyT1JzNTROSHlURWdPOFMwaGwwYW5NT1VmZDR2Tm1kMWlYVzZCTFNRdEJ0X3QtalNjbTBYME92a1Uzb1NsX1Z0VS1qX09fX3loZDg9
"Intellectual property is illegitimate. It holds none of the characteristics of what constitutes property. Particularly it can not be scarce, it's not tangible, or measurable. Once you share an idea. It;s in another persons brain. They have it too.

Property needs to be scarce to qualify as property.  Space, land, your body, food ect. Only those things can be aggressed on.

If you tell someone not to copy you and you use violence to stop them. You are the criminal and the aggressor.  IP law literally is just a restriction on what other people can do with their proeprty.

Example: Jimmy builds a medical device and patents it. He shows everyone and people start copying it. The law is saying that other people can not use their milling machine, steel, or w/e resources how they want. He is willing to use the state to kill bill if bill uses his own resources and tools to build a copy of Jimmy's device.

These laws used to be called intellectual monopoly laws.

If you are interested in learning more about this look into Stephen Kinsella. He specializes in the economic study of this and the philosophical ethics foundations.

  
[https://youtu.be/gWmEXCJIIZ4](https://youtu.be/gWmEXCJIIZ4)",r/machinelearning,Z0FBQUFBQm0yeGI1dnV2MXZsM2xnM3Z0emVLTlVPaXpoekJZc2J2eGZBakVCWVdONHktMU1Tdlc3d2oyY1ZpZ25SUmxmY3VzYWthSHJtZmZueFRCOXVvUkNyM3NxYWxydDVOV0xXQTdSampjU3FSN1ZpaEFEaE09
"Not really, MAE is only nondifferentiable around 0, and that is easy to overcome. The choice of MSE vs MAE is whether you want to have the estimate be the mean or the median. Also the L1 loss is more robust with noise, and have zero-forcing (sparse) property.",r/machinelearning,Z0FBQUFBQm0yeGI1alRUa0V3Z0UtOHZFUkp6MkRQbnc0ZnFPUk4yTjhTYmk1a0hiVWR4RnNtVm54MFhHS1pHM1FMcTNUeVlKRFNueGh5ckJZZWcwdUZOZmFrTnhIQjUzTnh3YWxad2lGUXphS2dHSVdMTUJMSlE9
"Honestly, I've hired for ML a lot and I think this a very real risk with PhDs. Of course, some are totally great.

I work in big tech as a ML engineer now and I've seen a lot of PhDs fired (many who researched ML specifically) for not meeting performance expectations. I think the fact is that industry work and research expectations differ so wildly that academics can really struggle to adjust. Those that do adjust absolutely smash it though.",r/machinelearning,Z0FBQUFBQm0yeGI1aHloeS1Wa2JucW5NX0xZamVUTUVjeGlZSVVmQnItOTdob214eDUwaHB1dEczVzdvUE8zbEFpcHhUdjJyMjdBekRqanJ3YlVlaERoZU5iSVpUY0lQb2c9PQ==
Cool concept,r/machinelearning,Z0FBQUFBQm0yeGI1NURETkJfTWtJMzh1UXV2U0xpc1BMUXdPMDdFNjFJYmw4VzRwQWdyTVZpXzA5djZlTEVBTkFGU1pGUTNzODhHZFAzS1hPM1lTYzJMbU9QdlBYcExoTVE9PQ==
Probably. You will get a lot more interest if they think that your work may have practical applications.,r/machinelearning,Z0FBQUFBQm0yeGI1aG9CYlBtazR1X0ZuTEY3emo2VlZ6Q2Jvd2NVRjZDaTd5UnJSNmJTVXVBU1dMX0hNdDFGek9LZktVc2VkdU03cUhmd2tRbjRjYUEtcHQxcWJudEhQX0E9PQ==
Hi，I'm struggling to do structure and parameter learning for dynamic and hybrid DBN from data. Do you figure out this or can you give me some advice?,r/machinelearning,Z0FBQUFBQm0yeGI1eDQxWGh1R3B2Y0pjSS02MmxLTlBRMXQzbTg4eDZmSWN6NlNMd3k5OW9JMHpBMnNwcW5zTnNHWkxweTdhQkVVOVNOQ0hLYXBBR3JJNHVaZzBTUEdJQ2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1djBUZDBBM3pmUkR3NHFjUVRSdF92V1k2UkNyS0RicHdxWGNzMG82V21ybXl6Tjc1eHpJUlpLLXZSWEFhcHB2T2RtbENOOFJXREtWWnVhUXlWX0ZseHc9PQ==
The main difference will be that non-phd people will have X years of extra work experience.,r/machinelearning,Z0FBQUFBQm0yeGI1V2psdy1Udkw2UloydXk1dlVGMG1rT2ZMbEtvLXltYzVWeGtlYmo0RGRobUczWVoyXzFfZDdkSEJGX2gyUGRrQlRZSkQzQTFQdkplMDQzZlh3elV5RkR2Y0dndE1WYm95OXNRckZIV3lGam89
That makes very little sense to me. How would you reformat a json as a image/video that makes it in-distribution for the training data? Pre-training is only useful if the data you are fine-tuning it on has similar patterns to the pre-training data.,r/machinelearning,Z0FBQUFBQm0yeGI1R2tlYkFvaDI2dElrdDlqRXZlbnU1RHU1TTFhWlE5bEJfcXlBYWFacll6d2daQXB1YWNyY2kwNFBpaWNBWV80WTlFbm9ISFVVUGFLbno4SjQtUjFKc3c9PQ==
But the main problem everyone faces is drawing of such types of complicated figures,r/machinelearning,Z0FBQUFBQm0yeGI1d2hhOHVPOWItVWVaUG9UQ2xuQnl1Y3REUGZKTE5YeVlUQnEtRTNLaFZfX0NjZE5XNVM5VkdTekliSkxIbldLRUZPbV9PYUVydHZYb19BX3VsVmhEdEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1M19mOUhsb29lRHFaM1BGbDgxY1hZWklvVWJXLXk5YUgyeFJCV296XzBsbnRBaXNQdVltbkpnRV9SX1ViYkt0dGdSY01xVTRPMHpUVVJHVzRMMDM3aGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1MUNPTzJsTWpfaUtiUHh4by1RQS00dUc1Z24zRXplSlMzRWFzNWVibkdhNmdrTGNsR0VGQUtTVzc4bUI4RU5VZXg1MHZJUFlLN0xSb2dDZ1A4Z1pXU0E9PQ==
"Very interesting, thanks for sharing your thoughts. Could you please explain in more detail what a program/subprogram is in this context?",r/machinelearning,Z0FBQUFBQm0yeGI1Y3p5NWZPanZLVGNCUmFsYVlmTjZMd05lQURxd1JEVHpDQ2lZSWU3R3FIZVdSRXBab1RWRlI0cjhESkFaNnJqM0pQcDRpVXptVEZrbm5heEY4V0JvcFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1NDllTW02eUxvbEgwS3ZFa3BRdDlWckMtRTN4T2tWZVN2aEdIVTN6cUtrZVpSTFkyMkc3dFV4RV9RdTRlY2wzazVCZmtXRWdyMkhFUFlEaXhOMGoxQkE9PQ==
"ML journal if you focus on methodology, econ/finance if you focus on application.",r/machinelearning,Z0FBQUFBQm0yeGI1V1d1aW9yaWNINnZVM0lBSDU3MmN1S2NhaWhvek5acHgzc2h3UUFES0NBdndmQ2FMZ0tzNHV4dFJ4VklrN2tFNlhpZkRpMS04THEtZmlwMTV2eVJtOXJ3Skpta0JtSkp5ZkJDdXlGN1RtOFE9
"Check out ML Engineering book by Andriy Burkov, great resource for system design",r/machinelearning,Z0FBQUFBQm0yeGI1Ni1SX0dLLWU4azF1cmg4a1N5ck9PR2VMN0pyZTJXUEFNbjd2MENNLWdjQnRESWR5LVJrYTN0SG1wLTBrWmM3WEgwNW5uMlJjNjA1RWg2NWg3djh5WVJFdG1DNlN4SlQwVXlmRzVvTkRYUWM9
"I personally think that it is poorly named: it is not an abstraction benchmark, it is a geospatial reasoning benchmark. It looks abstract, but the problems often rely on geometry, understanding perspective, gravity, topology... things that are hard to learn from a huge text corpus but that are not particularly abstract.

I kind of expect vision + RL models to be all that's needed.",r/machinelearning,Z0FBQUFBQm0yeGI1aThiZDA5WlZkUmhVSEFEMDRMdTZndHFlazJZNUtxOUxoQWs3UE9FS2EzUVJJb2w1d2JEZkgxWFZLUWw4aFdsODNEYWNYUVVmTkdJQ3VJSk1Qc3ZBdUE9PQ==
"The approach that has worked best on ARC so far is program synthesis: you have some domain-specific language with primitives like ""countColors"" or ""mirrorShape"", and you look for compositions of these primitives that, given an input grid, return the output grid. See for example [https://arxiv.org/pdf/2402.03507](https://arxiv.org/pdf/2402.03507)

Subprograms are partial programs. Often the search algorithm would discover the same subprograms for many different tasks, for example ""stack two grids on top of each other and take the elementwise difference"". If you can identify such subprograms (i.e. keep what they have in common, and make whatever is different into an argument of the function), that's an abstraction which you can add to the language, so you don't have to rediscover it from scratch next time it's needed.",r/machinelearning,Z0FBQUFBQm0yeGI1NXpPdkxDOFQtQ01XTmI4X3h1cVVqR2NfNUQ2S2RHVlFiaDRiMm1aZUhxamZZcXBlVXV6Q2IySjYzbHpoX05YSm9jdzluZFlUUm1vUHRaWDhISkJRZUE9PQ==
Let me guess you never coded a neural network end to end in your life,r/machinelearning,Z0FBQUFBQm0yeGI1RWZqUktjem94RWg0bVR6NkxrcVpRZFAwb3hFcFp1SzRKSElrb0lQZEoxd1ZyOFM1bm1aMElUa19WZVpLZlFTS0NoZWpOM3lPUXBsUUlHbkFLZjdHUEE9PQ==
The fact that people on here can't fathom training data being a simple json -- and not video or unstructured text -- is making me feel old haha.,r/machinelearning,Z0FBQUFBQm0yeGI1X1k3Z0phQkRBV01rc3BNNDVkV0I3cXhZakhoLWtLTnFlQXRxSU5JY0pITlhHaFR6akplTGlhSU5WS3JFX3d3TU81Z0NqSFJidEMweEJsb2tXNEdSdVR0dGVReTl0UDE2U2xqa2lJd01CbXc9
"Chip Huyen's Designing ML Systems and her discord  
[https://huyenchip.com/](https://huyenchip.com/)  
[https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969](https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969)  
[https://discord.com/invite/Mw77HPrgjF](https://discord.com/invite/Mw77HPrgjF)",r/machinelearning,Z0FBQUFBQm0yeGI1T1JqN0pLNmw1M3drT3FiRkozQ2J2SllxUVJIRUZiMjRTeTd1MEtpZktuaEtELTgwVkZDNTU5U3ExVG10ZWlrMEI0LXpjdzVKZkFZSWdCd2dlRXZHYXc9PQ==
"Do you mind DMing me your papers?


It's an interest of mine, but feel I haven't hit the right academic search terms.",r/machinelearning,Z0FBQUFBQm0yeGI1WVhwblloNG1lbWdNbTNvcWg2d0ZuR2V5dEMxRWNRUHlqaVpvczM3ZG45QWFMdXJrRl91TG5aNGhESHZsZ2V2OXpVZlU2YmNGb2dObGdwdThUbGVMLVJhV2pzRnUxTEwzU0lIRDJBZTdDYmc9
Thank you very much for the clarification!,r/machinelearning,Z0FBQUFBQm0yeGI1ZHpYcFVMeDRxVVdwNUU0YXZ5cUJoWURDMWxYcUtvVTk2RE1TZF9rX2UzTjRKX24yQVlZV09iUzBHa1lxaWJ3em9DMlVLNWcxUGhsR3NhalljZVAwN3c9PQ==
That’s why I use different resumes and include different qualifications based on the job im applying for,r/machinelearning,Z0FBQUFBQm0yeGI1OUpaTTRrbmVvVm5Ma3pvTWlyT0tCVkNmS3NfZnpJZzRiWE1zQkxUQzZxMWlwenNVdlY3bWlSSDhRUmowUGhtV2FsRTVCVUJVWDVadUFra0l0Z1ljQ0E9PQ==
"Link to previous 2020 competition: [https://www.kaggle.com/c/abstraction-and-reasoning-challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge)

If I don't remember wrong, last time the winner was analyzing all available training tasks by hand, breaking them down to some simple transformations and then just doing greedy search to find working combination of steps for test set. Very interesting to see if the winning solution is going to be something closer to ""AGI"" this time.",r/machinelearning,Z0FBQUFBQm0yeGI1RU41b01fdFQ3T2FPbFJwdzUtQzA3WWFxbHZ5MUYyRGJITmtLdDl6bkhJNm1XaGtXUngwWWRqMTdGbFdibFExSVUyV056VENwdk51cVBYNWRhZHdneGc9PQ==
Are you the author?,r/machinelearning,Z0FBQUFBQm0yeGI1enMtV2l0NlpzcHZGUEJORDFaYTVZdmtyWHlzRVkxN3ZHU21WSEJrNDg0YzJxMVZLcHZaSDVyUTc4bmo1cEt3UzhwVjBYd0pCOU5NVjZpMngxcHEwUEE9PQ==
The json files when interpreted as images clearly have similarity to lots of blocks images on the internet?,r/machinelearning,Z0FBQUFBQm0yeGI1amIxNXRzWWoxR1d5R3ZQUjZTbHdSaDdORGotbHVpbl93T2Z5NnhRc1daTmM4dWNFTlRiZWNnakpkRkxDTDZHRHFiRzhONlVGZzlLMzJSd0pKVXZvQVE9PQ==
Try humility. We all know that data can be json. But this doesn't make json good input. The data is distributed as json but it is a representation for a video. [rememberdeath](https://www.reddit.com/user/rememberdeath/) and I make the same point.,r/machinelearning,Z0FBQUFBQm0yeGI1U0J1NTNoX3llQVo2NjY0NUgtcjZvN3JOV1pvcWxxRFpBZWgwYjdtOFZwZ3hrc0hyS25UMDA1S0ZfaDZhZkE5a0FkV2ZWYWwtQXhseGJ0Y2dKWGppanc9PQ==
"There was a Disney paper on this, hold on let me find it..


update: oh yes, [a nice old one](https://icg.gwu.edu/sites/g/files/zaxdzs6126/files/downloads/Gritz97.pdf) using genetic algorithms to match motion paths to character mechanics. But I'm pretty sure there was a later one that used similar ideas to derive the mechanisms themselves.. 


update 2: hm still can't find it, was something to do with animatronics. but anyways, found [this one](https://crl.ethz.ch/papers/IJRR_2018.pdf) which is maybe more along the lines of what you're looking for and you should definitely check the list of references, ton of work on automatic optimization of mechanical designs there!


update 3: fixed links 


update 4: actually fixed links",r/machinelearning,Z0FBQUFBQm0yeGI1bFFxQld2S0twa0xSR08yVHFNdVUwSnJJVnJsNi1ibGgtbUhDZkZqZndPM3NzM2NLTWFhaWVSaWg0U2otem1sbFNhTEJhMGp6QmQ3TW8tSjNlV2hNZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1NENtaFN0VzViSTI3anpQX05tN0hkYlpIeVlkUWJhY3FocUtqSnNIbmlnUXFFcm5sYlBwS29ndkUxN3dOSDNPb1FiX2VqS1l2Tjc1OWY0d0o2OWwwU0E9PQ==
Oh look! A new Turing test now that the old Turing has been solved.,r/machinelearning,Z0FBQUFBQm0yeGI1R0dKQmY4d2dsalF6WjU5STVxTksyd1BHRVV5aDZIN3BwSTRyNzFwcGFYQno1d0JzSlVuWC1RejJENU5uV1p3b005NjlnZkVGdTZRREUteHdIcEdCeUE9PQ==
"Hi everyone! I am building a site [crowdicate.com](http://crowdicate.com) that provides individuals who build their own sports betting models a platform to share their predictions.

I built a simple tool provides individuals who do not have coding experience the ability to build their own model with a few simple selections. 

My question is, for anyone who builds their own predictive models no matter the industry, what are some tools that you use that make your life easier when building new models or what do you wish existed specific to your industry?",r/machinelearning,Z0FBQUFBQm0yeGI1dlhUUDRlaWtfSmx1cXBGYjFYX2kzTi12MENhZlM3TjBodjFtbmZaSXVCNUFIZjRlMHlMSGhUc2FNQkQ5R0dMb0pSamhCeGpYQkVxQ3hXNGdUNkVmVWc9PQ==
"I think we should be very wary of proclaiming a problem that we don't currently know how to solve as being an ""ultimate test"" (or describing them as AGI-complete). It may turn out that this benchmark is not solvable without true generalization, or it may turn out that there is some other technique that is sufficient to solve it, but turns out to be task-specific. We won't know which until after we see the system that conquers it.",r/machinelearning,Z0FBQUFBQm0yeGI1eDFSSHM2M3J0cG1aVlh6U1hSTU5ZLW45SlVheHI5bWdFRzd4VWZXWXU3WE9PSVNiWUR3bFNmeG14Z0loU2htUS05OURMV2RyRTdtMVVaOU9qaFVmZlE9PQ==
SageMaker endpoints are good. Just add a sensible scaling policy and find the right instance size for testing.,r/machinelearning,Z0FBQUFBQm0yeGI1MjJoY1QxRG1zZlByVUhSdVlHSEJxRXFJdC1DV1E4WFFTenkwRW5fWkdWQ192SGR6SzI4MUZ5cmVGcFExX3RNVDFveWVkNzg1WW1JdU1LOGFWbEtvRThwNi1QdV94d1hoQ3ZBODZ4LXBLbzQ9
The main negative is the time you could've spent making money chances of promotions instead of getting a PHD. Just make sure you need your PHD for what you want to specifically want to do.,r/machinelearning,Z0FBQUFBQm0yeGI1bjZfTWpZYlBYUEU3bmFERUJabTRMU2p3T2RzV1lHUy11U05odUdfNU9LNmo3VVJkZFlpa1NIUk5ndG9FVnQ5bkkyYzFVZmlzamlyaVpUT3EtYS1mT3FhV09uMndLWjVfUkxMY1RncTNZR3M9
"Model aside, I just went through the walkthrough of your UI. You should know that both the walkthrough and the interface itself need a lot of work. There are way too many steps in the walkthrough. To put it into perspective, I was able to use Eleven's ""dubbing studio"" interface without a tutorial at all within a few minutes.

I didn't test the English model yet but the language I did test (unfortunately) doesn't compare to ElevenLabs. I'll keep checking in to see if/how it improves. I'm a little discouraged based on the PR you guys released claiming it offers ""higher realism"" and that it's more capable. It's not true right now. Maybe you need more training date to get there.

I'm eagerly awaiting another company to be able to compete with them.",r/machinelearning,Z0FBQUFBQm0yeGI1V05iTjJpWXVFYWpJZTJxNkx2RUd6RW1TSlRydnhWWUQ0NUswaTJmMDVvQWhrNmw0Y2lYQ2JZQkluSE90NUhOVzRvaEozb0phRzNrbEZUZ1p1VEF3Umc9PQ==
At least you acknowledge that it’s simply a question about “when” at this point. A lot of people here are in full-blown denial about the kind of progress we’re seeing.,r/machinelearning,Z0FBQUFBQm0yeGI1Ul9ZUk1jQ3RwbTlXSW9SV1YtcGdaSmh4ME5ObEJNRmstclM5WUo4Q2oxY1hqNS1xWXFRM1gwbUhlbVJsSHdtdmNkZE0wT2p6dS1hMjZxQmdkajNEV0RxZGI1akU2T0dlMlgwNnNHUXZpNGc9
"The gradient is with respect to the weights, not with respect to the data.",r/machinelearning,Z0FBQUFBQm0yeGI1ekNqcVExZ2tSQ095dFdHV0hKdTIyR3RjTXBzRHRSSUFZamxWUHZucExxVFBSaGNvbUM0UHhYVzltX2YyZnIyREMxTm8zTG5oZVZxZFRiWmhUZzZhSVE9PQ==
The best figures i have seen are from the AlphaStar paper from DeepMind (crazy that i can find their open source github repository but not their paper),r/machinelearning,Z0FBQUFBQm0yeGI1Mmw2TmRyQUMzcDVoMFgzVTZpb0ZOdU9EUHFNMFMxdkdjN25lbmlncXpwc3FhMkxVTHdUMmJ6bnVaOWxBaEJhRzlLSlNxMmpQRWYxbFV0b3k1TXhIbmc9PQ==
"Good point, and I agree with u/tophology: the term has been used with multiple meanings. But in recent optimization and ML papers L-smoothness  means that the gradient is L-Lipschitz. In same papers they called this property ""L-Strongly smooth"" (to mirror ""strongly convex"") but the term never got enough traction.",r/machinelearning,Z0FBQUFBQm0yeGI1SEQ3SEdEazd1WUUyd2QwQzVPWWt3ODc3STAtYWlOaWc4eG5Za0NkWDQteVZLeUtCcTVpdE1VQzdyRm16Z09JbEtzUmM2enltc2wyTEJtd1NzWkwxQXc9PQ==
Making bukkake videos,r/machinelearning,Z0FBQUFBQm0yeGI1R2dySFlOYUxib0dXS2xYcjhMNWJtTEdIVWt4alJSQnZIaGVTQktBNmV3SUtwU1UtUUhLZkhOQ0FiZllZeUR6bUdoRXpPTHF6Sk04U1Awd1BUUmw2TFVOSTk2ckhULThMRkFKTGZiSjdZS2c9
I am trying to implement a few-shot learning model from scratch for text classification. I need some resources related to this. Most of the code I found on GitHub doesn't seem to be working.,r/machinelearning,Z0FBQUFBQm0yeGI1cG9uZ0hscUhuQVJCdXFEb2pVTnM3aVRPamFWbGhFOXNfZVRfdUVXM1R3cG1yT3ZfS1JEV3pGWm5Eaks1MHhCazNJRHJQZnRCZHVBVXdoazN3UkFZWjB6eDMxNk96aWRZVG10ZWJsUDNEUzQ9
"The input can be whatever you want it to be, you can even make it into audio. But the data provided is JSON. It is not a ""representation of a video"" no more than text data is a representation of an audio. I have no idea where you guys are getting video from in this case, if you really want to bring in vision it seems more like simple image to image task. But you need not bring in vision -- that's kind of like teaching a chess program to play from chess board renders/frames as opposed to simply from the board state.

I get that you guys are making the same point, it just seems like you're making this point because when all you have is a hammer, everything starts looking like a nail.",r/machinelearning,Z0FBQUFBQm0yeGI1ZTd5OV9YQkxqNU5mblJNU1dXdFA3V1YxOVc2QmJUSG5sTXg3aXlfeUNhekJQUk1KNHdoS0Fmc0xCNTUybmNjV2hnZHJxMXlqWGlBa2dxV3FUa0Ftc3UxTlVSeFVHcjlHZnRoSFhXQnl2SGs9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1aFBVVlF5N0tXQkg2YXI4eDU2aHNteHFKWHh1c21uM2pNb0JYTGtLcGVtbXFRcEh5WFMtZ2dmNGlpbnF1ZUNKQk14OVBmTmhfMlgwS1NndWRHYkxmbUE9PQ==
"Hey folks!

u/[donnyg\\_rh](https://www.reddit.com/user/donnyg_rh/) and I worked together to write a post on a stack for ML that I'm really excited about. Rather than using an orchestrator for everything, we use some chron-esque job for scheduling, and specific tools for organizing code/tracking assets and gaining access to infra.

While the example in this post uses [hamilton](https://github.com/dagworks-inc/hamilton) and [runhouse](https://github.com/run-house/runhouse), there are multiple options listed in the post! We believe that you can really lower iteration time/save costs by breaking up the stack a bit from a monolithic ""orchestration"" layer to a scheduling layer (to run your code on a cadence), an asset layer (to track/manage the data created), and an infrastructure layer (to provision resources). We're actually using github actions as a scheduler.

See the example repository here: [https://github.com/dongreenberg/gha-data-job](https://github.com/dongreenberg/gha-data-job).

Would love your feedback!",r/machinelearning,Z0FBQUFBQm0yeGI1S1RqM0E4VU0zQ0N2U1Y2b3lDUjAtdEpUaTZwbDZYeENBLWQ5UXhGY0hVdF8ta0Z5WWEzRVBMeHFsY2E5cExnc0FoSE9tSGxkNTBIVFdESG1LNm50Mnc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1OUFaUGt3VjhST2t6UEluODZlTUFOd01rdHZXQ0xHSWdSMU11MjVrYks3aEFjbFUwZWtNa0tRU3lMZkhFZnMxMXBXWW1SQzRXeUs4cGZ4aV9qT0FXd1E9PQ==
"
I have a friend who has a PhD in category theory and now works in AI as well. I might know your friend, as I also know a separate person who is a principal scientist at a startup who also studied category theory",r/machinelearning,Z0FBQUFBQm0yeGI1c1diQy14Qi1TRTVvZHpJLWprbGFsVUhVQm9JZS0zakVEWHZIaFJzbU9fMEFySEtqcUpsalFKZkNYcUZzRkd2c285X3NKTVhwVTlGMk9UV3FqVk4xNDZ2WHVwbVhkOXZJMkdLelRKOHUxSGM9
marcos lopez de prado does some good work,r/machinelearning,Z0FBQUFBQm0yeGI1Ml9iWW5XLWxTYWpwWllXTTBadTl0X0dLLUZBNTEzTE9qVVExa1NzU3pyLVZLNmZ1MVh4dHlWdW5zNUM5MFJHSy1Mc0QxUkFZR1lJUVhTcUtBN2RBV3c9PQ==
"perspective? gravity? topology? what on earth are you talking about! Its a basic visual puzzle challenge. spatial: yes, geospatial: ????",r/machinelearning,Z0FBQUFBQm0yeGI1T3FTcGtPLWtWRXpLSVFKbmlhMGhILUxoMjJmYTZsYUxtOThUQjE2c2VKVm9YNmFjRGhSeC1Md0hBTHBYbFhvZ29YeWdhdmlDckJ0ZFd3cG9rd2FieUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1QnVEclMxc0kza2hvc1BSRDJZY25tcE96XzlzX1ZfVkZhS3lQZTZuam9Wak81ZmtXSVZNTHI5UWIwbUZydkR6bFNOSzNqOUlES0VwOXFDOTVmdjY5R3c9PQ==
"This task requires you to have the logic of occlusion: https://i.imgur.com/HEAuBVs.png

This task makes more sense if you imagine gravity: https://i.imgur.com/Y5KNGWm.png

This task is easier if you understand the notions of inside and outside: https://i.imgur.com/iBtXrbb.png",r/machinelearning,Z0FBQUFBQm0yeGI1VWUtb251cVVzeFVnbnUwdWVBVFFoWlprdkNQb1ZpVUFJWlpXaGM2WjVKbzY3VGhTc3dsZWpjb2hUemRxQVVfLWV2YmdjUmQyZDZINTJiQ1NqYUZFSEE9PQ==
"gateloop, ssd",r/machinelearning,Z0FBQUFBQm0yeGI1OVB0ZDZsSFFFSWNLYThhQ0NsWGZ6QmNRdUZ1ZV9QQnJGNTJnWElveV90NVhUR3RDZ3M1anZyT1hEY3VpeHBNVTFhVlJVdFZDd2NfSGdDLWwzMFZocWc9PQ==
"2 is entirely subjective! This puzzle could easily have been rotated 90 degrees and the logic stands, without the notion of ""gravity"". #1 and #3 are totally correct - occlusion and enclosure are both principles of spatial reasoning/abstraction. just wondering where you got geospatial from",r/machinelearning,Z0FBQUFBQm0yeGI1Qy1Yd2l2U3p3aGZpU09lRFdvUTFEQ0RDR3NRXzBTZDNEd21mZzM0dkF1QlMxd1g1Wk9Fejd3bE9RMldlX0xDcWZPVmVrbmR4X1lTWkhNZG10WEhJeEE9PQ==
"Hey u/photobeatsfilm, we respect your opinions and appreciate your time in taking to review and trialing the product (albeit by your own admission not a full review). While I appreciate the opinions, I do feel it comes misplaced and a little hostile. I'll attempt to clarify things you brought up in full fairness to our team, our work and our mission.  
  
Our open source release for MARS5 is in English and you can benchmark the model against EL yourself to see the difference -- judging from your past Reddit activity, you are clearly an EL super user and I think you understand that what we claim is terms of prosody capture is more then genuine ratified by several top tier speech researchers, publications and open source communities. MARS5 is able to handle extreme prosody like sports commentary, shouting in a manner that is genuine and unlike existing solutions. A big plus, ofcourse, that it is opensource and people can build on top of what we do and ratify for themselves. EL is fully closed-source. Not many companies in the world today are allowing the full-freedom commercial use of their extremely strong speech technology that outpaces closed-source unicorns. We're doing that and we're 1/10th the size.  
  
We will regardless have our benchmarks out within a few days (watch out also for latest checkpoints) on our Github -- [https://github.com/Camb-ai/MARS5-TTS](https://github.com/Camb-ai/MARS5-TTS) -- with more languages and more trained checkpoints, given that we're not discouraged to do so by posts like the one above, that might just be more knee-jerk reactions than comprehensive evaluations.

As per your use of the platform, as you'd also know the diversity of languages/accents/dialects we capture is nearly 5x many times than the comparative solution in question. There does not exist useable technology that enables you to speak Malayalam, Swahili, Icelandic and extremely low resource languages in your voice outside of products like [camb.ai](http://camb.ai) -- we hope you can give us some credit in making sure no language is left behind and creating methods that enable accessibility for all.   
  
Finally, as per your comment on UI, I wish to point out that you do not require to do a walkthrough (that's optional for folks who want to understand how to use the studio professionally) and you can pretty much dub a video e2e in 3 clicks -- uploading a video, choosing languages and speakers and then waiting for the result -- similar in experience to EL's dubbing tool. But this feedback is well taken and in line with us releasing a much more leaner video tutorial (as just a simple video than a Arcade demo, which hasn't faired well for anybody I speak to).  
  
We truly respect the time you took to try, review and write a glowing post, but at the same time we also respect the work we're doing and we have open sourced it for transparency, building trust and demonstrate a willingness to grow together. Our team is bold, unapologetic and has proven several times over why we're the best solution on the market making history 3 times over just this year, trusted by leading enterprises across the planet.  
  
We're a small company building from the middle of the desert (in Dubai) and I think if you truly want to see ""more competition"" and ""more marketplace fairness"" as is also suggestive from your past Reddit activity, then I think we'd invite you to become a super user of camb and grown alongside our open source community. You know where to find us, we're always happy to help. 

Thank you!

PS: If you can find me on our Discord, I'm more than happy to see what went wrong. Sometimes bugs creep in, in other times it might be a difference of having experience using our platform versus not. Whatever it is, we will try our best to help you find value in us.",r/machinelearning,Z0FBQUFBQm0yeGI1TF95d2s1YVU3OVlKSVY4Q1ZVaGVJdE80YWRSMGVwb01tdHVORDV5TGhUS05rZ1ZPaEdaZlFKZkZncGhSVGdQNzNzMTByZnZCS213UDdYSkZtRUVKSmswR1NMLVJOUHBzSFY3RFdsV2tqdzA9
Turns out the old Turing test was bad so they made a new and improved one. Why is this a bad thing?,r/machinelearning,Z0FBQUFBQm0yeGI1ZEg2a3hHU3RLVWRlWTlxeDlwRTJFaV9wT1FGYWJiZW4tMDFMeEpScG1TRkdTaDdHSUlucXNkazM2VUlZVTNRdjhWV3BaS0hFMFQydERJUUJNVC1fYVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1dzk4N2NQM2NNNUlXb1FzVTctWU1mcEgwR3ExVnVWeXRycEtMMVJCOTZyd3k2Zzc3U2gwYjAzVDVwSktYOFBFVjZGQTJ6ZXoyRGZBWE9pTnFwWDI4NWc9PQ==
"Since I need to calculate the loss I would also need to make predictions, I am currently working on an idea but I have some other things to do first...",r/machinelearning,Z0FBQUFBQm0yeGI1RVBQcFExal8wTnJLLVFyOXNNQzRzcHJuX2hieWpXbGQyenYtR0NrQ3Z6UHBEMHk4QWZmOE14YVBIZVpDMjVMMXo5T2NjQ0ZqNjBTVnhIdzlSSzZCYWMtazdTNGpvcE1nX1NwY2U2ZzAtTkE9
"what are you trying to predict? it sounds like maybe you could just count the number of pixels of each category. anyway if you need to fine-tune just stick a linear or summation on the last layer before the segmentation classifier, but definitely you could try just using the bottleneck too.",r/machinelearning,Z0FBQUFBQm0yeGI1UXl1Xzh0VUtzTEVLU1A1RHpqc1g1S3VBM0otMlIzN3dIMDBvZmlIalhoanl3SDd1djY1RGZzaHVQZ3lQWVhIZHdMM2k5V2pudlRtYTI1NEpJajZCM0E9PQ==
"Since 4 hours have passed, this post was not downvoted and seems acceptable, here is my wild speculation:  error by one.

target_model_distribution should be `get_distribution(target_logits[:, -lookahead-1:-1], temperature)` or something

Assume initial prompt len=2, look ahead is 1. In this case `target_logits[:, -lookahead:]` is `target_logits[:, -1:]`  and before it was calculated as

        y2 = target_model(draft_outputs.to(device), inference_params=infer_params)
        target_logits = y2.logits

Assume prompt  was  `AB` and draft returned `C`,  draft_outputs is `ABC` (and target outputs are the same).

When you take `get_distribution(target_logits[:, -lookahead])` which is `get_distribution(target_logits[:, -1])`, you calculate `get_distribution(""C"")` which predicts ""D"", so you are looking at the wrong token: at this point of time `target_model` has no idea `C` exists, its initial prompt is still `AB` and it should look if `C` generated by draft is also  generated by target.

Here are example of target_logits shifted by -1:

     tensor([[   46, 31834,   310,   247,  1511,   273,   278, 31834,    13,   247,
               3417,   273,   278, 31834,    13,   247]], device='cuda:0')
     ['Mamba is a type of mamba, a species of mamba, a']
     tensor([[   46, 31834,   310,   247,  1511,   273,   278, 31834,    13,   247,
               4956, 12621,   326,   310,  7925,   281]], device='cuda:0')
     ['Mamba is a type of mamba, a wild bird that is native to']

Or 

     Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
     tensor([[   46, 31834,   310,   247,  1511,   273,   278, 31834,    13,   247,
               1355,    13,  2159,    14, 29551,    13]], device='cuda:0')
     ['Mamba is a type of mamba, a small, short-tailed,']
     tensor([[   46, 31834,   310,   247,  1511,   273,   278, 31834,    13,   247,
               9081,  8712,    14, 30842,   278, 31834]], device='cuda:0')
     ['Mamba is a type of mamba, a chestnut-colored mamba']",r/machinelearning,Z0FBQUFBQm0yeGI1bF9FSXV5anB4UkFKU0gwTVViWERwTURtTldqVk40RjNDSm01TndIUzhYaU93VldMU2tHMDRxSE9sTUUybnpfeW9DRDVVclB5Wjk1LXBXaDlJaE1JbGc9PQ==
"Ah maybe geospatial was a mistranslation, I was thinking ""3d reasoning"" because of the occlusion thing.

I see what you mean on #2 but there are other examples e.g. of items ""falling down"" and stacking.",r/machinelearning,Z0FBQUFBQm0yeGI1SDU0bGR0MHY0ZnBCdDVzbkhxMzVoMERyY3dCWTdPMDZaM3R2dWhMMFFDX3B5b0Y4dkRYS2NRbVh6WjJ0TG4wbS0xSFA4X2E3bmlTRl9GdTZJMXVYZHc9PQ==
"Pixel counting is not necessarily sufficient. For example, picture of a solid boundary between a settlement and a forest is labeled a 0 or 1 whereas an intrusion pattern like a funnel shaped group of farmland surrounded by forest or scattered settlements with a bunch of specks of empty land would be labeled higher.",r/machinelearning,Z0FBQUFBQm0yeGI1RFNzbzFKNXRxMXJRY3VJZ0pMX3Q5Q0FMNUJPWTVWYVRtU3Z2MkltTF9iVjNDMDRtbjhMS2Z3bnJPNDI1RUM0MkdhS3FYZmNzMENZdWlxYVppTzlhZnc9PQ==
"I'm pretty sure it can train a new model, what do you mean by ""transforms a classic model into a ""MatMul-free"" 1.57bit/param model with ternary values.""",r/machinelearning,Z0FBQUFBQm0yeGI1b3lmeG9ObFc2a1BQWnd1eGlVNkxDV0tzYWNWTWMtNm5oUU1tbEtwd0wxUC1MbVRoNFRPMWMzTXFuZy14VFNyU2ZqNGozVG5mT1VnNzVyODdYMElVemVEdmxHcmxJTDF0YjU4c0hXN3NRMEU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1bGV2N0g0Znp3WlJtR2ptSDVYRm53Y3VXRUtfc255MUZuSHVobEJ0VUJ0bWpxazg2WE8xZU1MeDN4aXpRRkM1eUc1MGh0ZmlLMDR0a2xMb1M1UFRlY0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1M01vd3FuZWl4MEdZXzJJRFdLNFNzTW11RGRTbDRkSUE0RXJvQ0dOWVVVb1NPYXp0SHA1Q1kzQlBHemN6bWppSF9RY05SMi1nMGtlMjRVS1k4bU1vZkE9PQ==
"Even if you agree with Kinsella's libertarian take on IP (I don't), it doesn't really matter. This viewpoint isn't going to become law any time soon.",r/machinelearning,Z0FBQUFBQm0yeGI1LS1IMGhzUlVLaFFyZVdoNlJ0eUxibFFMZ1lZWHkyelJlVnBfM0ZkZlQ1TXhzYmtkR2NvRHZQd2N4WlN3ekpiRm0wV3dDYTJiaHVzMTJ6d0t0OFRvYVE9PQ==
xlstm,r/machinelearning,Z0FBQUFBQm0yeGI1SWtqZXR1OW9XTjZzWDhwTUpwVGVFQ2NTWmhDUnlubmJzMzVHbVZFdnRfZjh2VFFyR2lLd20yWkFqOVZJNDZlRmoxbWlwTmR2WFFGNkV0TWl6T3NEa0E9PQ==
"See what Elon Musk says about a PhD. And, I'm certain, a book ""Unscripted"" will help you.",r/machinelearning,Z0FBQUFBQm0yeGI1dk9pekRPYkNrNmlKTmFFX2F2ZGxuRFYtaDZMb043T3ZSNk9IZjdoZEstZkJpZHBDQlU3cjM0ZHVzekZ4eFo3VGd0bEw5Q3BLNmZuQUhzVDU0WmFXNVE9PQ==
"""This viewpoint isn't going to become law any time soon.""

Do you have a point? Are you suggesting I change my views simply because they are unpopular or is this meant to be like an insult?

  
I really hate when people comment to me and essentially contribute nothing.",r/machinelearning,Z0FBQUFBQm0yeGI1NDRrSFhpNUVnY3U2Mm1zcU8zaHVDRUxyZndZZGFFeEYwOWZXX1ZabkR5Ni1vdkpCSDcyTzY4cW91TGRNeU9LSzNYcTRHcEFaM3g0SGE1WXNBTlprMHlQdTByMnZ5Vy1seFo1RHBXajBJSmc9
"All in good time sir. Speech in opensource will go the same scientific course as image, text have. Someone needs to start the fire. Join in.",r/machinelearning,Z0FBQUFBQm0yeGI1U21ZSXR4WEM3Wlg3b2NyTndCMVFSdGdWdWI5YnFwZ1RvajVrNjY2Vk9acExuMTVfeXZaZ1ljZzJiNjVRbU4tajVYdkZpdjFkR2QxMGcycVNuNjRGMk5INXNlMklzdmY4ZEVVd0NPNVlpYk09
"Damn, you are right. The introduction led me to believe it was just a quantization technique but they do implement a backward pass! I just wrongly assumed that such a discrete set as [-1;0;1] could not possibly behave well with gradients, but they actually address that!  Looks like I have more reading to do. 

Thanks for correcting that and really sorry to have added misinformation there!",r/machinelearning,Z0FBQUFBQm0yeGI1a0t0bjJ2M1JKcFRtRXZRNDhGakhXbVlIeUNkVjVDZXNnLUZTc25PQXNQOWNMMmV5Um5HalV3Z09VSkhBb3VrV3hJTUUtYWRpdGxaRE13LXNRX3Aya0E9PQ==
"> we don't have to worry about delayed generalization/grokking when training a model

You never had to worry about it in the first place, grokking was a weird phenomena that only happened in edge cases. If your model is not generalizing, you should reach for the normal solutions like regularization, data augmentation, etc. Don't keep training and hope it will magically grok.

The interest in grokking is mostly from an academic perspective to better understand training and loss landscapes. In that sense, it will not be ""solved"" until it is fully understood.",r/machinelearning,Z0FBQUFBQm0yeGI1b2h2bDYzVTZpSU5iUGcyMzFYdGFHSGhzdDJXZXF1NF80TWJoMG9Tb2lqT25sZFBlRHVwT3Q3cXp4NUtCVXZCdk9qTUlEODVnSzVvcG5KREppZkJ4ZTY5OGdtV3RyVGJKRV8xWDZQemZwV2s9
"If somebody runs a website and Google indexes it, that's probably good as it could drive more traffic to the site.  On the other hand, if Google uses the data for model training, I'm not sure that would benefit the web site owner.  

From a legal point of view, I don't know if this constitutes fair use or not.  Courts will have to sort all this out.",r/machinelearning,Z0FBQUFBQm0yeGI1T3FWSkRJdGVXWEF1M3VrUUVPWU5RMXE1Tm4xcHNKNDJJbnNPbUVMSmZlb3BQSkVtck11TmNJcVE2MEh2c25zVFV3NDVVN0JKN2hjbS0wWDVOdE5kWHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1UUFWTGpfNWNPZG91dEwyUTNCWEJ3OHdNUXhxeE1JcEpEOEx2NFZpd0dNMjNyQkZGczRnTFVobEM5N29ON01RdUFYYUMzdExSZWlUYmFZZXZ2Z2JZM1E9PQ==
How tf do you publish something like this without fixing it? I would be too embarrassed as hell showing anyone my paper like this lol.,r/machinelearning,Z0FBQUFBQm0yeGI1dGtmeUw5MDVHYVl3R0N3UFdUaC03OVUyMl9DVUN5OUxmbHpJSTVBb2JJNVhEUUdGT3FFTEtqLVAwb1Q5U05CV3dxcllhUjdUYmw2V0JfZWMxNHF3dlBQOGtnV0hGMGtUQXVZdm1YYkRtcXc9
"It’s undoubtedly so that progress toward AGI is done by conquering any issues that pop up…

Regardless of its ultimateness the fact that they are human solvable and not machine solvable means it’s a useful instrument for interrogating differences between humanity and models.",r/machinelearning,Z0FBQUFBQm0yeGI1TTVKSGg5M3NxS19mdG91aGZfcURFUWhUMXdES29qNWRhOXdZdEZidWk0bExfR1lXMjlGaXJWZjBEdTd2WFdMQTFyUTVmQTJoTlpnblBKdVJRc0l0QkE9PQ==
understood! seems we are on the same page then :) will be interesting to see if anyone takes the RL approach to represent these physical concepts. are you competing?,r/machinelearning,Z0FBQUFBQm0yeGI1cjdIUk5KaHJuOFhodjRPWGJ1c0hoR0N5WHpOT21OakczNHlybmVKdndxNUFDdjR0YXdTZmhtd09ZTUN3bXc4N0UyWkpsdnE4M2xIQXZIVzBqTGxuYlE9PQ==
What if someone from BigCo solves it and BigCo pays them $2 Million to keep it a secret?,r/machinelearning,Z0FBQUFBQm0yeGI1OW1sTUMtVElxalRwSVhQNk5STGpTX3ZYVFJ5QW03TFFMc2tybDRSVzhmT0p2MVpDekJ3RW56cC1xUFI5SXgtYThhSTRVaTBqeDZkNUtaN2JubWR4THc9PQ==
"I definitely agree it's useful! Even if it's solved by an algorithm that turns out to be non-general, that will be a valuable insight. I just think sometimes people hype up a benchmark or task as only solvable by AGI, and then when it's solved they wonder where the AGI is.",r/machinelearning,Z0FBQUFBQm0yeGI1Tm5pNVczYVhVaGhyelRaMHExYTRGSEZGV0xsTE5Na01UOXFCSWc3MGMtTGhlR2VHVUZGQ2FEa0ljTHg0Uno5bDd2Xzg2THJIbWRBbzloU3U5WFRmaXc9PQ==
"yeah, I got very confused after reading the paper, seeing the comment and the amount of upvotes :D",r/machinelearning,Z0FBQUFBQm0yeGI1S0E5b20zSWkwVUltLWRIclY3dWd5UGtLd1hyUU1RcjdzX2I3VVFVcjM1TTVkdm1yTzNCSjlCT3ZFWmNBcmxpcDcwb05qZjM0TGpUOVhOaGM5Zm9xaGluRDFVM25PaFl6RmJEekZ6WURTcG89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1VjVJZnJSSVd0Q3cxTzlyLUxDQ2pVOVAtM2FKZHlCOG9JTHhOaWRDTk1vMWd4a0JHV3hHdGZ5bHFaY0pTMDZlUWxaSkhiNnNxbzF0UG0zWGpWTHpCb3c9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1cU1CUHJWUVN3LU1fby1sVjZFNWFJTFAtTXRaTDFxb1JwT2FibWFNNTZjanVjN3FUdHktcS1ZSnhVOHNVZ2ttS3I1cU4xNzU2N2pjSGdQR1BKTFk1c09GWlpNcEdVTS12MFBNMV9yeGdkQkU9
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1QmdXUzMtVDdBQk5EWFZub0YwaFRGQUdVS0ZUVTAyZW5vTkJwbE9kV2VfeW8zN29xNDc1dHVvSXRDeDhvQjZ2R0RZckp6RnlLclpZUzRKRWRfQlhmcU5YVFpQbHA4cWJSclJJRGVONGdRYUE9
"Hello everyone, 

Does anyone knows that if exists any algorithm for machine learning that works directly with 3d models (.step, .stl, .igs, .ply, .obj, etc....)?  
I'm bilding an application that predict future production time of a 3D part based on previous producted parts but i'm strugglin on get closer results. Currently i'm extracting information from 3d models such as maximum measures XYZ, volume, surface area, number of faces, etc... but i think i'm gettin to much information to the model but yet the information i get is not enough. Therefore i want to know if there are any algorithm or other  application that get's the 3d file and automatically ""sees it"" and analyze it.   
I'm using python.   
Thank you",r/machinelearning,Z0FBQUFBQm0yeGI1eExpanpDc2xNR2hhN1NZY2h6Qkk2ZHBPQlZvZm9wdkJWN001UnVqME5rRGJha1dub3k3TDlUa2FsSkx2bVFrNjk1bVI4WGVFMkgyNzF5bzZQcWZGQVE9PQ==
">  GPT-4 is so much better and more robust.

I find this be to an extraordinary claim, and looking at the vision capabilities, I'd be very surprised if you were right. We've tried GPT 4 on basic vision use cases and it sucks.",r/machinelearning,Z0FBQUFBQm0yeGI1VktFVmdRTU9jLWJhTHA0WENQejNoRzBjTm0tYS1qRE5FdUROQ1VWS3ItS3BvRzdSUmItMGtzSU9DSzlEYzNlS2tmTDMzRFY5VDlDaGpvSWNzMTBzM3c9PQ==
Cycle consistency,r/machinelearning,Z0FBQUFBQm0yeGI1OW9MbWRZX3VMa1REeFBFZm9QOUpEdE9mcGVNVGppaWRpdUVLcHVzVFdSc1ZwdG9RbjA4UTBMLUYxbHJERmI5bF9wRm5tN0NwRmttRE84bUJQdUhNQlE9PQ==
"I feel bad for the 25 persons who did upvote it :-(

I am still trying to figure out though how the hell they manage to use gradient descent to train ternary weights, something just feels off there but this time I'll do more reading before stating bluntly something wrong.

I came upon this remark: 

> Assuming all dense layer weights are ternary, we
quantize Q and K, resulting in a ternary attention map that eliminates multiplications in self-attention.
However, as shown in Fig. 1, the model trained this way fails to converge. 

And then they switch the matmul-less RNN implementation, which I guess is still interesting, but a bit underwhelming, as I suspect the problems of regular RNNs likely subside in ternary ones. 

It is still an interesting read, and I like the idea of faking a gradient that's convenient when the function is not smooth. But replacing too many gradients with identity function feels like it defeats the very purpose of machine learning.",r/machinelearning,Z0FBQUFBQm0yeGI1a21vT2hkR0RIclBCcmU3WWtBbHRXSndtRnREcU1FRUdEbW5iOVp4LXJhNVVrSjRfMDB0NkNxVWZZUFRYaFVYTWpJUk5mSV9jZ2FTdjFFanNJV19vSEE9PQ==
"Wish I had the time/funding for that! I fear I am relegated to the user/engineering part of ML, sadly.",r/machinelearning,Z0FBQUFBQm0yeGI1SjljOUtjdmRsQlpScWg0NU9MbjJMV2xQY2t5Qm1qSEVrd05ubFVabE1kcHVOTmdVWHAzdTk5OWYwb1hlN1dZcjUwUl81NjRZZmVhVnI0Y2w5NzNhbFE9PQ==
I think you might’ve missed the point,r/machinelearning,Z0FBQUFBQm0yeGI1LTVBN2NkX2Z0S0o4b3RxLXpfWXVyeGdrOHMyUFg3Njd5b2NLaDYwYjhuWTVYdlNYbFlsTjBsTW43Q0w1TVQ0RnBYa2dqdkpoLWwtT0RmRlBRWlJRSVE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1M1U0QWlHNGREQjdTbUx0TTBKVlppU1kxekZ1ZWk1Ty04SzBwRWYzUDVIVEJhbHNGQXFhMnZiSTVzVGR3ODgzSUVvU2NwUXJ6bktuZlZxRFdsS1BYbnc9PQ==
"Maybe there is a uniqueness between images that allows for cycle consistency, but as a general point, there are often many bijections between two high-dimensional marginals.  I can learn many different ways to rotate (then stretch and shear) a circle into an oval, but if there is only one mapping which is the true mapping, how do I learn that one?  I'm mainly interested because I would like to find where I can apply this to a numerical domain, but if there is no good answer to that and the answer is because in the image domain there is only be one mapping, I'm probably out of luck.

  
edit: changed infinite to ""often many"" bijections as that's more accurate",r/machinelearning,Z0FBQUFBQm0yeGI1UFlJTHRjRWRSMUViYS1KTi1nakozbkRfejZNZGotM2NqVmxEcVdCSjVVeFRzU0RJVVFaY2M1Y25IUkFsY2I2WFhQZDI2bnZfQ083OEU1NkhGUmtiVGc9PQ==
"yes, we've had to adjust our definition of intelligence (and will have to continue to do so). you're probably the first person to ever point this out.",r/machinelearning,Z0FBQUFBQm0yeGI1N1p2aGl3SUlzdWJxS2N2RmdaTG5qVXZhWFRmN1p2RTJvaWs1cDZiWVJCclh6Nm5CWkx6bURmcnpacjg5enlyRVNzNWd6Z1BlLURzYWlzXy1ocHpXTnJNTzdnUk5KN3NVbGV0Y0IzQXg5UFk9
"First, this is on purpose. Second if you would read the paper you would notice that the author mocks the science community (rightly so).",r/machinelearning,Z0FBQUFBQm0yeGI1dzRaeFhpZXJkaDBKa1p3QWszWmpaVV9VRXVMdTR4SWs2WWdBbVEzUElkdmE2VFNpMWI0SHc0TXEtcUU4bmY4VTRhVk5iVmtJMlNGNjZsVHZROFRxQVE9PQ==
"Well, I indeed did not read the paper. The only thing I know is that he didn't want to contribute to the model anymore but that's it.",r/machinelearning,Z0FBQUFBQm0yeGI1dUd2Z0VwcGtvWVllMUtIZ1NpS2Z0YnhJbV84X1gxNzQwM19FMDZmby1udncweDFpYnE3UmhYZG9RWnV3TXN0b1F1TTJxWkhIeHJEVEh5M2ZHM01ZaG1HRmhIYmtmWTdGdFJTZ3VnT2E5QWs9
"Also the claim that “Progress toward artificial general intelligence (AGI) has stalled.” has me rolling my eyes really hard. Sure, LLMs aren’t AGI, but they aren’t nothing either. 

There’s been more progress in the last few years than the previous few decades.",r/machinelearning,Z0FBQUFBQm0yeGI1ZWxXMldzcXlCRmNYckpObDV4Nk5Wa2dlUXFzVTVoX1ZOdlRjdU5jaHdVT0sxcllhWmN5UHc4d2NoRmpqZkw0TWcxeW9kdUpSMVFGMXJ0OEVnNzVEaVVVRlBJdWpqaWRNOUVWLXU0bmYzN2s9
"I wouldn’t say it was bad. It just turned out to only measure part of intelligence.

This test also only measures part of intelligence, but it’s a different part.",r/machinelearning,Z0FBQUFBQm0yeGI1VS1leWYzbVBEclBfdWc4MVF0bVA1NGFCMFNsVjRCV2RpM2Y1NVpkdzc2bVdHVkdIUWlsT0hFTURVX285aUstSkdkNzVSeEdBNkhCUlFCMldEckFCWlhVTEpuczZlWXM4eHhGbGNjdktXbEU9
"That doesn't seem very general. You might be able to beat ARC with it, but only because you have built your domain-specific language around the kind of problems the benchmark has.",r/machinelearning,Z0FBQUFBQm0yeGI1UnpkbEIxRUFNVV9Qd0dhUVNmOG9YbnpoZjJZNm5qMEJiWXNQRDZIcVdVek9fOFBxYVFrTDU2MmhCNU9yX253NEFiVUNTQ2t0Q2RkTURmbDFOOGk1Nmt3cGNlUGIzb0lSZm55SVJsNGFjRjg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1bmdmUE1ja042Z3BTTUd0ZktYTU1oeV93NjV0eTJrOXNpM2N5WWluYXEzWGhKRkI1TzRuRFZBOExuOG9hUVJWaEpkNHdMeDJiSDlyUmtGV05QSFpEUlE9PQ==
"I would say it's neither, it's a few-shot learning benchmark.",r/machinelearning,Z0FBQUFBQm0yeGI1T1hNOE9BWXlZUGJYOEVEN0h3Um1oRkZlQW1UNUEtUTV4OTZrREVQMVdBdXpUOUM5eXR3NjJIeUNzLVRhcVgxZExya1FlWjNjanpYcGNhM05GMFRIc0hRX2RYc2Z4alNsYkN0UWRhUGQ2cWM9
"Can anyone comment on where we are with integrating causal reasoning (i.e. do-calculus or something similar) into AI models, and whether this is generally viewed as a necessary step towards AGI?",r/machinelearning,Z0FBQUFBQm0yeGI1VjlHMlNjZUtmalZWeWZnTVJXZlBqaUpzNFVLZjBUbWNDU0VUOHJGS3hWMklOemhrWW0zM2c3Q2paUXVZVlVzZHVreVZTRm5STWJIaHAxbVpBOE42SXMyYllGN243c2NHdHNKQlBVRmFycEE9
"I am the other way around. i have an imposter syndrome that having done PhD i only know a very tiny part of ml properly, that my code skills are suitable only for that tiny area & i am pigeonholed there. i am unaware how to seek feedback without getting judged ""Oh you're but a PhD""",r/machinelearning,Z0FBQUFBQm0yeGI1SmRtNUZnMlM2Z2xQc2lFanl3YWxSZ0NGNXpXWTBzbFpLNl9ldUF2dXhSTmd3bGV0dm4zV004SEJ6Mjd1U0Z5ODU5eVNJZnd3M04yU1IzT3JWek5UR1E9PQ==
"I have always wondered what in that space will end up making a breakthrough, if that or QC",r/machinelearning,Z0FBQUFBQm0yeGI1Z2VQXzlHaTZTM0Npc1NlLS04NDJkajQ4OGprb0hFOGRBUXRoU1VhRlhOSTh5cVZVVWNORmx0dnhRcmQ4UWcwQmtEZHg3T3R0SDlIdWVucUh4eWx2QlE9PQ==
You need to define solved. Solved by enough for low resource environments or solved by it being a perfect solution. We don't know the latter until we fully have a explainable reason for that.,r/machinelearning,Z0FBQUFBQm0yeGI1eUVMRXB5blJWLWdUMG5CaUROMVVVSUpLVGJpMHpQNU14YXBXZlpVM2lXZ1Fibm0zdnYyRGwxWHJrUHZMcXFNRWZOTURTckNZMUE4N2NjUWdBNWNnNE16UDByQlhIb0oyUmtYNWFYckRMNEE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1UnJhM3FEWUZTcTE4Wmo5aFJpRlBvaXliY1E2QkFBVVlwTWNkMEMxOGt2N1RWYmd1dDNJa1ZBbHF1MHIxZ19YUmx6bmFxQUVtcHhaeDNSNWVNbWJha0E9PQ==
"Just curious on the speculation end. Why might you think causes Grokking? I only noticed grokking not happening when its just memorizing the data instead of overfitting, but haven't payed too much attention to it.",r/machinelearning,Z0FBQUFBQm0yeGI1LXBWakZDTzlGY3VuUkU5aFFkZkFJVl92WjZkdVppU0c3NWtldUpfRHJDbl8yZTR0V3JqYmw4QU5oZFVCajNkUmxlbXhKRXZzamN0TkVnQmFXWWJhVU1fR0doajRscjBwRDR1YjViWjRxcm89
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1REdoNW12Q08xbncwaG13R2o1ZjZmcmh1N2hYY0JZdGF1dnNZa3JsVXN0R0N6WUdhX250ZFdEc1UtWUI3dVUwei0zbkotS1p5c1BMeHloQUJXR3g4SXgyb3ZPVmM5cE1iY3ZiZGdsWWtlb009
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1QjZINl9IOVZ4VDJOMlNUTlRSNGV3V3YxWk9aSG96alNpMVJDTnd3eEJfakkzUFZqaWV2cGRUUmVHeHV5U3NVNGVudUh0bVdKdzJ0di12WExyYnk0RUZMTllEdmp0ZmZLU0xaSllfQWxsRTg9
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1VjcybGY0THJLUm1xMmNZOExaLXFEYWZQeWd1dUlMRlZaMzhFVE5fMlF2bE42THdwbE5uYlo5VWNpLWQzTEVRZGtmSGZVbW96Yk9NM1IzNmNyUUFaWUMxeTVLV01OVjRRWUFBd2xEdFhZRGM9
I think you just have to be very honest with yourself and humble. Seek feedback from others and don't try to lord over them. This career is hard and it takes a long time to be good at it.,r/machinelearning,Z0FBQUFBQm0yeGI1b1podnRfNTZ2Vk5vclFESS1VcmRUNlJTdWNwa3FxWG03ZDVMb1Y4Qm1UVjNNaVBLNDFSSW5VVFJJYXdlWGQ3a2FUUkgxbjNHUTBBM0sxLVRoUmxGc1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1Sk1xbGtHOTJ2LUMyVV9ZRUktaDNuZXVpeXlKQlJjRmN1NFYyUDNWeVotUFJIRUdZOGtiVkN6THdFb3RmSHZ2dkFleWRHSzZBdEFpckpmY1plWUxza1E9PQ==
Keenan Crane's Lab's papers come to mind: [https://www.cs.cmu.edu/\\~kmcrane/](https://www.cs.cmu.edu/~kmcrane/),r/machinelearning,Z0FBQUFBQm0yeGI1blk3ZVEzeG1pazAtNi1iMTA2eWdLM0h3eVdtdkxMVVpFbllwRXlQQktlUVR4cExFWHFVaDMtQzlGcDdycWhkY2kyZERoZ1dJZHhRLW1MMkZDYWdDR0FMMFFBWjl4M3NHNXBmcHhfTnpma2M9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1MDFSaklGRFkxdlc4SGk5WEZWdVNBako0SEVLNXpETWJGejZ5ei1TdWlxN1JpOC01NEJRWDREV3d6YlVlcEtWWFlkMC1lRHF5U0pDWS1hekpSdjBqSHc9PQ==
"ARC-AGI is (as far as we know) the only eval that was designed to measure the ""G"" in AGI. It was designed to be resistant to memorization techniques.

A solution to ARC will not be AGI but we have high confidence it is along critical path (AGI will necessarily be able to beat ARC) and so is still a useful measure.

I'm super supportive of eval innovation. I hope ARC-AGI inspires more people to create AGI evals.",r/machinelearning,Z0FBQUFBQm0yeGI1NjZRMWxfUnpzalB2Mk9wcEtYYklDN21HeDFWNi12MWt0SHdoWm9rUDJydjRRNzFPdUZ6WTA3eTQ2MXEtQjdkYWxYdk44NXUzZExPTm5DeHNLbTlpM3c9PQ==
You always have the option of leaving out the fact you have a PhD,r/machinelearning,Z0FBQUFBQm0yeGI1N2xpMGxpRkdFTmIxMUhhdE1haWdMejYyS3VnTklIVjF0U2UyMGFJUFFzTThBMllCanVzZjc3MmhiUHI5dzNlbnJiaW1jdEk5YXBKYzJfeXJ1aXFUYlN2R1hhWHFyN3k5TVB5WlNqTldnME09
That’s what I’m thinking. Why wouldn’t an AlphaZero-like technique work on this?,r/machinelearning,Z0FBQUFBQm0yeGI1MHRYOVg5eTVDSDVGcmQ1NlBxb0E4eU1HWFV4RGhWSHJvckJBWC04SEJPTTJnYUtkRXBORExCbFNjYUdtb01nZmxhVUU5RllJWnVWYjVVcUVBeUI2SUE9PQ==
"This question is central to ICA and is called “identifiability”.  You won’t be able to learn the true mapping without placing restrictions on your function class because, as you said, there are an infinite number of bijections between distributions.  

Another place to look is in the optimal transport/Schrödinger bridge area.  There you look at continuous time flows and place restrictions on your flow using a value function.   This is particularly useful if your bijection has some physical interpretation, like if the samples from your distribution represent particles in space and you want to transport them in an “efficient” way.",r/machinelearning,Z0FBQUFBQm0yeGI1WDE5bkFLTnROd1hkOHlqZENQdmlFLW9NN1FzbWU1dlJULWhWb2dUczFrVUoxMm9aampjeFl6MjVyWExDZlNjYklIZjg5eVV1bllCRVUwVHJoM1djeHR1Q0ZqRlltLWNXZ09QcGs1OFJHTWM9
Lack of training data. What would self-play look like?,r/machinelearning,Z0FBQUFBQm0yeGI1VW9rcWc2UEtSQjFaR2Q1Q3cyTW1uX1YtRkZ4UUwxeVVsVFRqcTlCTkVOei1ld1JQMnVyN1NmaHVsX19lLWlYLXZraFRjQ0RTM2s1c0ZWa1FMM3ZMcEE9PQ==
They are illiterate on economics,r/machinelearning,Z0FBQUFBQm0yeGI1YVJfbElBY0ZCR1NZYTVQUW5nRlpDal9CS25sUGFwb1NmbXdqeUpLM25oQ045c0hKbnRxNm04N0F0c1pWZTBzeGJ0b2xMOEFjSTlKRUpXUUM1VlJLakc0a0s3YUE2a01NeFU3cEJ2aTJLVms9
"Cool I will look at ICA and identifiably.  It’s always been something I wanted to learn, but never got around to before it before it became somewhat out of fashion.  

You say you won’t be able to learn a true mapping without placing restrictions.  How does cycle GAN do it then?  Is the space of images somehow restrictive enough for the bijection to be the only bijection or maybe the easiest bijection from an optimization perspective is somehow the right one?",r/machinelearning,Z0FBQUFBQm0yeGI1WGQ1Tm85VDl0NWZ2UXhqcEExaldPYXFQdFFQeVA5eFRlS2NiMFVScEtfSnZHbHA0Mlc4NG0tSExidEYyTlRwdFV1ZGJEUnRkYm12N0pDVV9KM3lJOWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1azJmQW1sdkEyV1ZCT3E4SHJ6VGVJLTNkS1JTNXFfUF82Q0NueGNWN2ozTFVHZ0VzaDlZNkxORWNUbmh2NUxMV2FwYlJDMkprTXlrNmdpYWNrVjVPVVE9PQ==
"But surely it was only academic because of the long time until the grokking.

If really is as it looks in the Grokfast paper, then surely it's not academic any longer and we can have this generalisation quite early.",r/machinelearning,Z0FBQUFBQm0yeGI1M3Jqc1FIUlFiRGN0ZlZ0Z3d3aWtEbWt2OWJEaTlwNTN1c1pEV3ktQzNISzhKay1Gay11UThsQ21fajFWT2xxWXN4WlVZTXNNOGQyNVE3dFNZa0FxMVE9PQ==
https://www.nature.com/articles/s41586-019-1724-z,r/machinelearning,Z0FBQUFBQm0yeGI1di13NUprNWQ5NnpJZDVoenZWcEc4UnItQlZKNXZMQl9CVU01V0hITjh4Ul9NbF9lRjBULXJIN18wY1NlTk9zLUJ5LUFaRTRBVFBmN3ZyZGJ5SE1WZlE9PQ==
"Neural networks *already* usually generalize immediately. 

You don't need this ""overfit, then grok"" process - you just generalize in the first place.",r/machinelearning,Z0FBQUFBQm0yeGI1OFBuRjF0UHRTVUNDdFlhYkJBQW9DNVRZQ2FIRV9kYnlXM1F5d05fNGZvbzRISWg0MDVwZ1BIdTQ2RHdrZnpUckFNdDJxT0VLVkNSTnR1YWcxbDFLMjRET3ZmMVZTcWpGY3VRc0xRRmhQMlE9
"Yes, but isn't that due to the fact that we give the models reasonable tasks?

But the really interest situations are where the model has a hard task. That's where we have a chance of getting new things that allow new capabilities.",r/machinelearning,Z0FBQUFBQm0yeGI1U08tbkxMQzVpWG5hbzlvLWZ4a3gzZDZVdDhVTVAxWkZUX21aNGdfYzJha1d6OW1YZmxoNkZEMUFqc1BsczJEeTE5M19TcVZCNGwzWXR1d2NOQ2hjY1E9PQ==
Nice! I’ve also preferred doing stuff myself rather than with langchain,r/machinelearning,Z0FBQUFBQm0yeGI1MTgtM1d5QmJ6Q1d3SHR2UDNFaU5KSmtncXdSUkJkM3hZY09wZF9leUZlVFVZMi1PWjRIdjRfZ3U4MkZJREQtSFh6RTNaUzJJaE55ajlVRUc5VUNhRjl4WnM1SnhlOEx3cXpoMWcyWGt4aW89
"This is cool. Would the following interpretation be correct:
A value is maintained per weight to record the amount of signal received thus far. Signal below a certain strength is ignored (probably noise). After a number of steps the weight loses its plasticity, creating a tradeoff between forgetfulness and ability to learn new concepts.
A potential next step would be to investigate how this idea of signal and plasticity can be extended to higher level structures, e.g. an entire layer.",r/machinelearning,Z0FBQUFBQm0yeGI1RHE1QnBoWjFNLVUzWi1YbGVrRDVnX1Y2VUlKQUNEek1lZXhSMVJCdkQ0RloxMzBrU1h6WUdtSnlZOTdRbDBISGF4N29Zd3JSaG42U0RKS2o0eVIzRmc9PQ==
"It is not a bad thing but what I think he is referring to is that the challenge advertises that large pretrained transformers have reached a limit / do not generalise because they cannot solve this dataset robustly, ignoring that these models have solved a range of tasks which 2 years were believed to be quite hard.",r/machinelearning,Z0FBQUFBQm0yeGI1djBqVFEwdm9CaXQ1SnkyM2loRUJzb2pLcFU1UFkxUGJ6OWhpV1ZwNkpxUDlxLU9JdzBPcy1CTFJXb2FqT094LWN0Z2ZCRjl1VXhTQnVTUTc3d0dRdEE9PQ==
"If you can formulate the task as a 2 player game, you can use self-play to build up the knowledge of these kinds of tasks.

All you need is some way of scoring any randomly generated answer i.e how close is your answer to the actual correct solution.

I believe it shouldn’t be too difficult to design a mechanism for scoring answers (how many pixels are correct, etc).

You have two AI’s submit answer for each of the 100 questions and give them a score for each submission and the winner is whoever has the highest score at the end. Then repeat just like AlphaZero",r/machinelearning,Z0FBQUFBQm0yeGI1ZEp1SHotc1o3NXl2VU85Y3ZPeEdlYnE3OXZQUTBJY3B3OV85QzQ0V3NfQ0FzVUFXREZ6NmxzeE83cXA0RG1iMHhCT3gyaGhJWTlUdUhLdVFvRmplTUE9PQ==
Then you are likely to overfit on 100 questions. It is easy to make a model that will learn these 100 tasks. It is hard to make a model that will succeed at similar tasks it never saw.,r/machinelearning,Z0FBQUFBQm0yeGI1a2p5V0FNeDNDaUI3TWZQSFhCNDdFWTJBSXcyN2VfOUphcVdvMEp3a0JVTjdVajd3Q01QejJSSVdWd3hveTRfTFJHejJwWWlJWjdIQnhIS2hFMWtua3c9PQ==
Yeah! tiny-ai-client tries to help people do that. The implementation is minimal and hackable so you can know what's going on instead of delegation to a dozen of poorly documented layers of abstraction.,r/machinelearning,Z0FBQUFBQm0yeGI1QTFDRzJsTGxqeDdodU5FZjl5SHRTcEJhUE5mN2dZUlBJMG9ZYjlMMG1rRzhpbXFuQlYxOWctYmhFcmxBb0puOGd5WE9laTIwOFluZTVEQ2FTbmJCX3BFVUs4UmJFU3dqMzRiTGJNZXJCdFk9
"well, what precisely do you mean by image augmentation?",r/machinelearning,Z0FBQUFBQm0yeGI1NVdqRHhEU092d3JpV0RCZEpaV1AxdDdXSFNmR0FIWGhqbi1idW5RT0tKSkRrUnpQVWRWUVVlcWYzTFdabUh0Tnh2dFBGNEZjeXdIcl9qUDBoYU1xV0g1Uk5TSnhGcDREOG01NlMxZGk5cEk9
Maybe! But that would still be a research question for now.,r/machinelearning,Z0FBQUFBQm0yeGI1SFM2bGgxbDE3d0VHMlJpNEg1N3RSWFZjTWJjajktNkthcE1XeGdfaVZGZXUwTEV5MjdkVndmM2Z5MmNUM3FodFd1LWkzNk8yczNwVXpSR3NZQjRZUnBiYWlJWHRDTzE5LXozZDhmODhLbGc9
"Honestly I’m not too familiar with cycle gan specifically but I would guess that something about using their adversarial training just happens to get it to work.  I can say for certain that it doesn’t learn the “true” mapping because there isn’t a true mapping, it just finds one that looks good empirically.",r/machinelearning,Z0FBQUFBQm0yeGI1b3p1WC01X2tFNjhmdW5kRlllYXpsdUF1cUk4YWJGMmlnRmlxbW1uckRDcHpBVjMzU3BUV2ZRMVhyZ3k5UGh4RVJjOU1FM0lRYXJ4OTRJX1gyMjFrcU0xRTZpVDVRa09xRmxaYXpteFk1VWs9
"In my case it is a large portion of my work since I graduated, especially the last few years.",r/machinelearning,Z0FBQUFBQm0yeGI1QmpWbnRrR2x4V1VudHJQZXR1Y0NialB5NUtwOUlLUjZrTGtNNmF3N05iUWJubThWVlNNVVpac3dsdWo2QTBBdjlGcl9GUjVncWJBbVdpTGp1Z0V5SEE9PQ==
"Agreed in a financial sense. Though I'd say getting an ML position without at least a masters is extremely challenging in the current climate.

Additionally, I wouldn't do a PhD purely for financial goals. I think it's more for applying yourself to an interesting project, and developing your ML skills as you go.",r/machinelearning,Z0FBQUFBQm0yeGI1UU9UWGxXUVZpUlFvQ3lwbkdHZDVXUVl0b201aGZ0YjBTWEh2TV9laGE0c2w4WHZ5d2kwSlZSQzRjZXBPMlFiMHhfV0hBbWxkcHZOSjlwOU5oYlA2Umc9PQ==
There is nothing to be solved. This obsession about a not-even-well-defined phenomenon was just bizarre.,r/machinelearning,Z0FBQUFBQm0yeGI1b0xieWN1Y3lPYnItQi1hR0ZFdHNOcnRPdEJJMnlNZzExbEtvR3NQaVJ4TU1rVGREVjR4bzNHRDcxeXlpTUt1QkZadWN4Sy1QcDN6QnVlN3kzdkN1S0E9PQ==
"If I were you I’d publish on both, but with different approaches. 

I’d detail my ML paper with as many graphs and proofs to my heart’s desire. 

I’d then heavily summarise the ML bits for the finance paper, but drum up the problems that the industry faces and write the benefits of my solution, in detail.

If possible I’d cross reference each publication, for future discoverability.

This is from my experience writing private uni papers and commercial whitepapers.",r/machinelearning,Z0FBQUFBQm0yeGI1cDBIaThHaElNZTBOSEk5ZGE3YnVidVZaT1lRdnZCYXZYT2N4NzVFMlR3LWlEWFM2OFR2T080allwVkNlamh2OFZZVDNHdUNGVXlRaF9lampQYzMybmc9PQ==
altering old images to make new ones (ex. Applying a blur to an image). This allows you to add more images to a dataset without gathering new ones,r/machinelearning,Z0FBQUFBQm0yeGI1Y3ZXTDUxak52bF93SjFSeHlXMDIzQWpNWG5xTEh3YTdWY0JZN3lsTEhJaG9kUEVSa3hqMXFCVGNnbE45Y2JFbnJtRTBvbzdYeTlWWUxJQk1mSERBMVE9PQ==
"Do you think if the number is increased from 100 to 10,000 it will still overfit or will it generalize? 

AlphaZero is able to generalize and make the correct decision in situations it’s never seen before.",r/machinelearning,Z0FBQUFBQm0yeGI1cUtZMUVwN0lDdmtIVlVIOUhRbUxYZkpMY2ZnazFzNzI5TVVCV0dBSUJqdTYyQUJIdUtibW9rOENBeVVJQ2ZZMm1ZTkluZ3ROcFdkNU45MlZrWUtTZFE9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI1Q1hrdmpQNkpQZV9aZkYxSUlWcmVpbXFVclRZa0VOVGhmNy1fb0luYzF5eHpjaTRWeVZ4b2xDRXRvQWo2WHBMdXRuQUNjRlNSc0h5R2xXeDdNaE9JZUJLNElOOEhFYjZVY2hsTEJRd1NfWFE9
I didnt even know it was possible. Do we have the capacity for that right now?,r/machinelearning,Z0FBQUFBQm0yeGI1dmJPWFoxSmpocFlUZzQyelltMjJQRVNzSDhHR1VtcFctZm9VWVZxV09mXzRlU2ZiQzkzMzFqVmtMQlE1c3Z4RGo0THUxRnlsRzFzTkdKUmxhNEtiLVhLT0JoRW0wd3o5NTVTQjU2LUpGdFE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1UlVlUXVnOC0wZWROM29DYzZxRU5TQ2ZGa1ZCR1VWR0loZEFJdlVrMzQzS2FPSTkzYVBobUhhWkViWWhaVU1PRTgyS2J4X3lhc25uc24zN09MRloxb0E9PQ==
"I don't know why attention is mostly used in just transformers, theoretically cant you appmy the concept elsewhere? I know some RNN are using it now (like Griffin), in theory why should a transformer be any better than a RNN that does good job using attention",r/machinelearning,Z0FBQUFBQm0yeGI1MWw3andoZVdNWUhtU3NPTU9HSHZOUjFqRWVSeXlDNmFnU3h6TzFWa2xoUXJTbkM2bVA0ak1yNkF1MGtEd21PcmNNYmZJaE1pVERfTm1tc2VIcW90TWNTTml0ZVNVUzRWVnF6bVRwV2IteUk9
"What does this mean, by the way? How can you train on such things without equivariance/invariance, wouldn't you have to ensure every element in the training data is oriented the exact same way, and won't that affect prediction performance?",r/machinelearning,Z0FBQUFBQm0yeGI1TWo5M1ZMV1pYbWFVZ3BHVk5QdndnenVzd3VJU3lRYktFcWpwRmwxeWdaNTNWd2hBREVaSFFzRWVXbl9ONmtFaHI3S1ljXzEzSkZqcllueGJwd1FCYUtMUHA0VzVLOU44WTBWb2laWTVYU2c9
It's everywhere now,r/machinelearning,Z0FBQUFBQm0yeGI1OTJkOU9NYWRiUGFDRl9rMFhFdy1IQ3FSY25jcEtMbHluYzB5TUZkTU13TmMzWk1hU0RFOV96TXpONURBN0NBUlR0dWo3SHpleUozeTZTR1BlTzJab2RvQ0VYZmpoV2N2U01xWXpza0FGcjg9
For math it can be good and we don't know how well they can perform right now on that so we need the progress,r/machinelearning,Z0FBQUFBQm0yeGI1SXBvX0otYmxTLVJRT25lXzZHenZZWHF5NDI4YW9WblkxTXpjaFFfYi1UZjRReWp4aTZkNDgzOWNfTUtCS1NXUG5XLUNPbHFKa2d1eHBGcm9NeVk2dWJDbjdtZzNfUUZhblZRcGdEbmJFRDA9
"Sometimes, the interviewer just want to walk through some problem solving.
But, if you want to work with ML, you must have done something related to it, being coursework, or personal project. The interview does not have to be about your thesis.

Quality and number of papers won't matter if they don´t have practical applications and you can´t use them to discuss problem solving.",r/machinelearning,Z0FBQUFBQm0yeGI1Rm9NN0RJMVR1QWNwMDZ4T29TNDVyRHJQaWFod3dSLUtaZUZleGNyRXBzeDFqSGtlc3pnYm51c0hjTDhjbU1NRVBBY2pmRFZ5Wkh5YVg2VmFySmluYnc9PQ==
Figures in this repo (mine) [https://github.com/schmidtdominik/LAPO](https://github.com/schmidtdominik/LAPO),r/machinelearning,Z0FBQUFBQm0yeGI1N3VPTzBwb2tKUm5CcjRTbExuTzgxWGIzaVYxdkNuamg0ZUJLWWRXNkJNLTVsSmU0dW1sUzdJMzdaamhEc0pwMkhKZEM0TktJVW9VZ1lxSm1ZRG9JTHc9PQ==
"Do your PhD in the US, and get hired there. The industry doesn't really exist in Europe, or at least there's much less of it.",r/machinelearning,Z0FBQUFBQm0yeGI1MUdHUElRVGlZV3o0TjNSZHBoM05qVlZsZW5aWDRRblVSR284R1N1UFo1RHp2cldpVUJ6QXhEU0VBMEV0SGlGYXpiUDJiVkxfWVVEazNGVHRJc3RWWUE9PQ==
"Colab Pro uses a credit model, you can't use the GPUs forever. [Vast.AI](http://Vast.AI) / Salad are cheap but they don't have good privacy guarantees that you may need if you deal with customer or confidencial data, but they are great for public data you would normally use as a student. AWS/GCP/Azure are much more expensive.",r/machinelearning,Z0FBQUFBQm0yeGI1elpVN1ZKM2tjLWdNSzd5LW5uVG1uX0pHR1p4UXpDUzVsNjc1UnN0TkNuVHRTWlVha0pfYnpNVkUydW5TZkEwQnkyN05VZldBaFQ5QWRPcXdRRHRWaGc9PQ==
"Hello (the below is self serving)

A very nice tutorial on Dynamic Time Warping  [https://www.cs.unm.edu/\\~mueen/DTW.pdf](https://www.cs.unm.edu/~mueen/DTW.pdf)

A nice tutorial on time series subsequence similarity search and motif/discord discovery [https://www.dropbox.com/scl/fi/wthpli31q5o75vynyg6us/VLDB\\_2023\\_Time-Series-Data-Mining\\_A-Unifying-View.pdf?rlkey=c5oiqiaj0gizy3e75fi9tm4we&dl=0](https://www.dropbox.com/scl/fi/wthpli31q5o75vynyg6us/VLDB_2023_Time-Series-Data-Mining_A-Unifying-View.pdf?rlkey=c5oiqiaj0gizy3e75fi9tm4we&dl=0)

and 100\\_Time\\_Series\\_Data\\_Mining\\_Questions\\_\\_with\\_Answers

[https://www.dropbox.com/scl/fi/xmviwzhfkjm34p5k6q1d9/100\\_Time\\_Series\\_Data\\_Mining\\_Questions\\_\\_with\\_Answers.pptx?rlkey=3pap5hwt4v7k9z1nfothorzxe&dl=0](https://www.dropbox.com/scl/fi/xmviwzhfkjm34p5k6q1d9/100_Time_Series_Data_Mining_Questions__with_Answers.pptx?rlkey=3pap5hwt4v7k9z1nfothorzxe&dl=0)",r/machinelearning,Z0FBQUFBQm0yeGI1RUwzZEpfOF9EWjFsQWtKOHlRZ0ZvQ0ExN3d1ZVVTMV9iSHpyVDVIOUJsR0dEbkMyRkIwV3FyMXNfT2puc3A4ZmlUNWZIeWVXYm84LXpJR2tEVnZOSWc9PQ==
Really appreciate  your effort..☺️,r/machinelearning,Z0FBQUFBQm0yeGI1S1Z2MzBTcWdfcnprYUxVWmNvUnFRQ2N3emRoZnNXYTFXLXVMZUkwWE1GUkdrb1o1VWdLM2sxTUhQQnZaRVgwcEhGNWxaLUpNMzRkekJjQXpYbG9GYmI5SDYwcjJmMFlVME1iMkU0Skxwa0k9
"ah - no, I would not send data out of for that kind of augmentation. I just would use various open source libraries.",r/machinelearning,Z0FBQUFBQm0yeGI1SW5va0g5WWFLdUdrUHc4UnJPLU5UX2tmajdMLTFWbDZtdWdkR3Z1UVowV2pMM2U4RXdMeGhvcnU5NTZFNjZFdUhoZUZSR1N0WDF6VWE4ZzdVMjEtUHlMN2V0cXBPM3N0NHdtTy1aRjI3OFU9
"I have a deep respect for him ever since ""On the measure of intelligence""",r/machinelearning,Z0FBQUFBQm0yeGI1N0JySEFMamxDSXAycE1HRkZXQXRrVHRQVy1jTHZCZnpSWG5JXzFpWGpwQ3ZOYjB3MnF1cERuYmtHbERiVmlNRmo0VktLQnc4TGhBM0Via1RxTXdOVEE9PQ==
"Hi! I'm an author of ""Grokking as the transition from lazy to rich training dynamics"" \\[1\\], which appeared at ICLR earlier this year. There, we showed how to induce or reduce grokking by arbitrary amounts (not just 50x) by just tuning one parameter (adding less than one line of code to your torch module, for instance) and made the claim that grokking occurs when a neural network begins *lazy* (which is a precise technical term that means it fits the training data without really learning good representations) and eventually becomes *rich* (another term with a precise definition that means it *does* learn task-relevant representations) \\[2\\].

Grokking is the point at which this happens, and it can be induced by a variety of mechanisms, including weight norm at initialization, weight decay, but crucially, also several other parameters we introduce in our work. Whereas the Omnigrok paper makes the claim grokking is *fundamentally* about weight norm and weight decay, we show this is emphatically *not* the case, and one can induce or ablate *all past examples of grokking* without even touching either weight norm or weight decay. The reason for this is because there are other levers that control how much a network is lazy or rich.

In fact, these notions of lazy vs rich and of grokking as the point where feature learning begins was concurrently made by two other excellent papers that also appeared at ICLR alongside us \\[3, 4\\]. Funny enough, as a reviewer for ICML, I got to see a truly disproportionate amount of low quality submissions about grokking, and I think because it is (was) a puzzling empirical phenomenon, it is somewhat of a nexus for quackery. In my opinion, grokking is less interesting now because we can control or ablate it arbitrarily (and have been able to for a while before this Grokfast paper came out) as well as have theory explaining when and why it occurs. Another commenter also correctly makes the point that grokking is an academic curiosity because it's an unexpected ""edge case"" behavior of a neural network; you will never see the phenomenon in a production ML setting. 

\\[1\\] Grokking as the transition from lazy to rich training dynamics. Kumar et al, ICLR 2024.

\\[2\\] On Lazy Training in Differentiable Programming. Chizat & Bach, 2018.

\\[3\\] Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking. Lyu et al, ICLR 2024.

\\[4\\] Grokking as a First Order Phase Transition in Two Layer Networks. Rubin et al, ICLR 2024.",r/machinelearning,Z0FBQUFBQm0yeGI1aEhqZDUtNGNoWXdyTWhfcHJlbm5qSGNtb0JOR1hBWExCWUs3czBlWnAxaHVTcmMzZkx5WHZTSk51SUlQTGFMT3BWbFlXZnNCa2lwRnRITmxNS3lpdUE9PQ==
"Just to clarify, he took someone else’s figure and “adapted” it by adding the data points for his model. His data points were positioned correctly given the axes used by the original. They are literally off the chart because YOLO smoked everyone else at the time. (The whole paper is written… very informally). Not embarrassing at all.",r/machinelearning,Z0FBQUFBQm0yeGI1X1JET3RzR1V0ODdBWXBwYUkwQUxIWHFpTkNnZzBhSjJnR1hYaGNQMkNBVVZVX1ExTFNzRGNWdW5Lb3BtcWNudDVmbGM4THdKVVlKVVk4Szh6aEJsRWc9PQ==
"Thanks for commenting! I have a question about your paper — you compare Grokfast to non-momentum SGD, and then you discuss the theoretical differences with momentum and Adam.

How does it differ in practice with momentum and Adam? Both of them can be considered low-pass filters like Grokfast. I'm confused why this wasn't evaluated in your experimental results.",r/machinelearning,Z0FBQUFBQm0yeGI1dXJPRzE4QTRQVjJMV2hLYV8xR0xLUFBYMTNWVnhRdWZHS2t2YnhLT0ZOM0IzZGE3aEhkX01Zb0RCajlnMmFNenpyZHhfRlNMTl9MOTBRWnhDRjFUd2c9PQ==
Having good personal projects or open source contributions is a good remedy here.,r/machinelearning,Z0FBQUFBQm0yeGI1T1dFdXhRMXJXTnZXbUJucVNEZWFDME9sWFpDeVBMbllaRVlJaG1fZlRVdWNmQUVJRmUxRmFnZWg4ZTdJYzE5VVAwTlk3UzN5THhEbnJQTWxpbFFrQkE9PQ==
"The reason I'm hammering on this point is mostly because I work on ML compilers on the daily and directly do see the differences. For strictly FP32 implementations it's not particularly meaningful (though you will see small differences in benchmarks), but the difference in underlying implementation at the hardware architecture level becomes much more apparent with lower precisions (e.g. bfloat16 and fp16) and it is noticeable.",r/machinelearning,Z0FBQUFBQm0yeGI1cmFTMUhhWHVFcnpETDBjSmpRLUJQclY0NUNwcTBpM2ZnUGQxVkpvSGpCdTUtbHFNVmRDVXdPcktjT0E1ZUlMektxOW5FQTNUR0VzdTM0WWlMVmRWM2c9PQ==
"Generally true I think, but maybe not in the current environment.",r/machinelearning,Z0FBQUFBQm0yeGI1UndZSWJ5SmZBckVDbEZ1c1p1LWRTWE9IWkY4cVpidlVTVVk4NTBNSl9UNlpPRW96T0JKdjlmR2xNcFkxcG5wVnVOTWdoRGczRnN5bndkUEEyQVFTZ0E9PQ==
"Sorry, I'm not sure what you mean by ""you compare Grokfast to,"" we don't mention Grokfast anywhere in our paper because our paper was written last year. We didn't focus on optimizers in our paper, the point was actually if anyone believed before that momentum/Adam were some magic special sauce that ""caused grokking"" (for instance \\[Thilak et al, 2022\\] make this claim), then the fact that we find grokking with vanilla GD refutes that claim. Since vanilla GD was the simplest setting in which one can find grokking, that's what we sought to study. 

In practice, I don't think using those instead of GD would make a difference, as evidenced by the fact that we show our claims hold in the settings of past work on grokking which all use AdamW (for instance see Figure 6 of our paper, which shows our results hold with adaptive optimizers/in more realistic and larger settings outside of our toy model). Thanks!",r/machinelearning,Z0FBQUFBQm0yeGI1UjJ0N3hfYlRxRzlhU3BMX0poVmJzU0xNSnQtN3JGN0ptVExfVDREMW1mUzI5bnYtdkhERkZBOGZIN2pDRV9FeHUyN1NhcHhNd2doZ1dyQlgyd0VhbWc9PQ==
"Sorry my status hasn't changed either, I've heard from other online platforms that someone's status has changed this way. Some say this change means there is a discrepancy in ACs, but I'm not sure.",r/machinelearning,Z0FBQUFBQm0yeGI1WXRIdkl5c1J4MnFWVS1LZk15RTl0aEc2THhreTZJTDJqNi0xLVR6dk43WkVjSzI4bnhHbGZKVEt3LTcxWU9pazdWVUVTOEczZHlLNjRLT212SXQtdkthYzNEOXRrSzZ1VGVfamdsNzdvR289
"Check out Neel Nandas grokking paper. The paper essentially shows (via reverse engineering a one layer transformer trained to do modular addition) that grokking refers to a model transitioning from a memorizing solution to a generalizing solution, resulting in the “sudden” drop in test loss. Since memorizing solutions in the (limited!!!) training set is in some sense an easier solution to learn than an actual modular addition algorithm, the model first memorizes. Then, since our model is trained with L2 regularization (and memorized solutions have larger weight norms than a “simpler” generalizing solution) the pressure to generalizes increases and increases over time until finally (thousands of epochs in) the model becomes good enough at generalizing that it can get rid of its memorizing components. This “clean up” phase is the grokking we observe.
Interestingly, the grokking model is able to learn its generalizing circuit *while maintaining training loss performance*, something that isn’t really understood yet.

Grokking only reliably occurs for models trained with regularization on algorithmic training sets where we only train the model on a limited percentage of data. Without regularization, the model is never incentivized to form a generalizable (i.e., lower weight norm) algorithm. With too much or too little training data, the model will generalize from the very start or never grok, respectively.",r/machinelearning,Z0FBQUFBQm0yeGI1czVlR0FkNTRPZmZlWlVyZW9EU1RxcWdVbm9CQ3dPV1NzTEZ0TmVwZktRWUtYcFFsSW0tY2lPR0VaeTVTUEl0OFFaRmxMR2NCS3h0a2RRV25wSGp3Ync9PQ==
So would the advantage of Huber over L1 be that the quadratic region near zero helps prevent overshooting the minimum?,r/machinelearning,Z0FBQUFBQm0yeGI1OFQ4V1FSc2tQRUk1V3REMWVGX285cGlqaUVKQmw0V2Z6ZTNpc2t1YlBFNm5WZk1sSEJhemNWR192WmU2WWRxS0VGMXVsblU4Sm5RTk9XdzllY19sM1E9PQ==
"My personal anecdotal experience: I got a master's specialized in machine learning, and I think having some academic training is important for a good MLE. I personally wouldnt be qualified for an MLE job or able to quickly understand the SOTA with just a BS in CS. That being said, I don't think/know if a PhD is necessary either.",r/machinelearning,Z0FBQUFBQm0yeGI1MW03ZHdocXdUYVdudUJhQ2p3cDZVYW1Zek90TW5OMlhfSlRpM2ZhNW5pX2hxM3lhUXdiVnk4ak5qR1RRTWZFbzA2bjBPcldoWHo4NHRqc01Ba0VmWVF5UjdIckZFeFRzeUZPTWZNNkVvWEE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1VVBoaGVjaXYzUXBIb3F0NVlXXzhZbHBMLUJNYlkzZF9iX0FMMHZlREktRFpnQnRCQUFiVFVLTTh6cTJtTmdPN0dVV2l3VDg5SWVGNkdpZVpEckhWb0E9PQ==
"> I suspect the models behind these two successes  aren’t compatible enough to slap together yet and get a super human language using bot.

Completely agree. Models are good at what you train them on. If you train one on image classification, you'll get a model that is very good at image classification. If you train one on natural language, it will be good at language. Now it turns out that language is a good model for a _lot_ of things, but  definitely not all. Open up a textbook for a random subject. If it's mostly text, an LLM might be okay at the subject taught by the textbook, particularly if you add in some RAG. But if there's a lot of diagrams, images, formulae, etc., an LLM will be pretty garbage at that subject.

If we want a true AGI that's good at _everything_, the only thing we can do is train it on everything. And it's basically impossible to make a dataset of everything.

The first model that everyone agrees is AGI will probably be some frankenstein multimodal GNN trained with RL, since that's the only way I can think of for a model to be able to handle ""everything"" while also being able to encounter ""everything"" during training.

(or more likely, it'll be some type of entity that you and I can't even convince of at the moment)",r/machinelearning,Z0FBQUFBQm0yeGI1Z1BhZjdpaV84SFpjY3d3Zkk0RUNWblh0eWlfU0ZXYWtua045TXFGOFBFYWV1aUt5YmZicklGaU02NERXVk5UVndkU3ltZ3lPYTdXSmtHRjNUVEItNDFUZHctTUxjMDAtempJUWExelNEYnc9
"> I got to see a truly disproportionate amount of low quality submissions about grokking, and I think because it is (was) a puzzling empirical phenomenon, it is somewhat of a nexus for quackery

It was pretty popular among the LessWrong types, who are very interested in AI but generally not serious researchers. ",r/machinelearning,Z0FBQUFBQm0yeGI1LWhtWERrdXM4aGotSXhIMHl1b1B5eUZzMW14X3JheWFuTW1TZU1jOGxGalV2ZVlVUXFYUElMRUk0b0pCdnJVZmd3TFZvaVVhUHBNNnRHMHNZTFIzSnpYUGFzY0FXMUllN1RjRmtYTE5OcGM9
"Thank you so much, you are right, although I thought this might be the issue and tried to check the shapes of draft_outputs to taret_logits, as the shape[1] should be the same for both, and surprisingly they were same, so I thought this was purely forward pass. Looks like I was wrong. Thanks again.",r/machinelearning,Z0FBQUFBQm0yeGI1b1JxM1NSdU83dDlvU2ZBUHE2WERrbHJFeFB1UHMwMlNkeEtpMWIzVndlQW9CUktCUl8xcFJaSUttMzJQN1Z6TTFadHh1QkIwVkNHLXE3VV82Y1A1TGwtWk80MV85M1ZVVXJoNERyVDdrcVE9
Why don’t you just start with keywords related. Like “emotional speech synthesis”,r/machinelearning,Z0FBQUFBQm0yeGI1cFFQUjExaWRLR19JcDhROFVabUFVZ1h3eGhnYkpFWFgxTnlzaDByWC1Nc0VXSmVrLU9YZnAtU3NfczQtOUFKXzFDcjdFUEsxV3ptOUhEUDFqc2RLaGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1MkZtbnVsMkRoUnBOTmo1WXVrMWVyRzgwQ052Sm5wSjM2MV9vRUZ3ZU5tZWpCdTZkWThOaXhLc3V2alJzMDc4allaZm5GdDdoVm9aZURQMDQ5dnczaVE9PQ==
Every sentence of that is wrong. Are you a troll?,r/machinelearning,Z0FBQUFBQm0yeGI1U0NMcFh4WEVhbzdGMzBZZkpzRUdyeC1WTWRtVXd5TlBZWWd4OXV5dlNId0U3T1JXY2FKZE5XNHo2aEhSd2ppVkZFVTBiald4S2pjTWx6MHVJUC1oSFE9PQ==
"No, I am not, you people don't realize the reality of the world of how and where it's moving. I've got a friend with just a Bachelor's degree and is the lead author of an IEEE paper which is also in Scopus journal. Their paper has received traction in the most cutting-edge research right now.  The Head researcher of Anthropic has said the same thing degrees don't matter anymore, you guys are living in delusion",r/machinelearning,Z0FBQUFBQm0yeGI1angtZ095Q1B5cG5LeWp0eUVLVFpYSmFRY2NObk9adXpYRTdDQVlseXFQaGJqWVZSRzNYU1I1VndCNlVlYnBkRmJ6aW8zMEFoRnljUVkzSWs2UWQ1eUE9PQ==
"Hi, considering that I have a dataset with attributes (date, location, etc) about when happened event X, is there a way to create a classification model to, given the same attributes, classify it in more os less likely to happen the event? I only have data about when it DID happen, no data about when it did not… (Btw the event in question is car crash)",r/machinelearning,Z0FBQUFBQm0yeGI1UjRQUjdfSjVlT0ZhTlo0QXdSSnZNdC1kd2o5cVJyWFNJRzJ5X2RJamdkcnNzaDBzRFp0Q1VhOHFsX3p3TFpFWVhwRHNpYldlZHRKWnFSa1otWktZZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1dkFoanBEVVRraVh3MFItV00xOWkzdnNSaDl1Uzg2WUZ4b0d0N3o2RGRBUzRMNlRBN0JNTi15ZnpvRmp1TE9iVGMxWUJtdzRGOFBuUS1pbUZXWFRSTEE9PQ==
"https://arxiv.org/abs/2205.02453

This is the best overview I’ve found.",r/machinelearning,Z0FBQUFBQm0yeGI1akFlVU5aNUlYVTBMTkVubkRGRWlQSThraE1rREhmaUZaOTJKZlV2UjdQR05Rb1FZQW9heWdvQXRFMjYzZkppTHJGSnFmZlBZRFJwNDF1Njl2MlpLRTNjZW50V25Qbzl5eGpRRHpnY1o0YUU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI1bHRUeVpuSkFyaWFBNUxMOExXR29oWDVrUHUzUkZNQW9LOEpxbjVoVmZSYzBienRwZE5lTkx6cUhaNm9lUGlINVpfMmlwZU9aMDFST3hzZzVKb19EREE9PQ==
"I thought I just had a conversation about the thoughts I have.  If you want to demand only specific kinds of answers, maybe a public discussion forum isn't the right place for that.",r/machinelearning,Z0FBQUFBQm0yeGI1OXc0M0FLNlhTYjhqSUhMSVhwQkxBMWJkWE9PbXN0QWJRZDBONnE0OWpuVGRkS1NxRTlidGpsTGtpLTVpRzdidVJPekVURldIenV2RGN5ZzljcXBwcHc9PQ==
Wouldn't a math function perform better than language model in recommending better functions?,r/machinelearning,Z0FBQUFBQm0yeGI1Yzg4OVAtbkVxX0ZzNkZiVDA1MWRIOVZpanUzRXpBSkp4NWhxaEdweGFQS0NsSmZpbGFKbXItYXBVYWVfaFBxOGE5Z1F1Z2FwRElVMldQZ1dDN0E4Qnc9PQ==
I can’t even get one to give me PyTorch code for an lstm so I’m going to say no,r/machinelearning,Z0FBQUFBQm0yeGI1REU1bFJtcTNnSUhVWU9wTFlndFpnbklieElDRzhEVE5xOHJjMmczb3o2aHhTQk9TckppOG5DTDBiRXUwbFE4U1V5UTB0Sm8tS3VlOE4zbnFTVEg1SDdzMXBuYXItd25BRFhiRFI4TnhIOXM9
"I would take the DGX H100 spec sheet as a reference, these systems are usually well balanced. Also you mention a couple servers and I presume they are for a university; make sure your datacenter has the power and cooling requirements to run those. You need 10-11kW power per server plus 6-7kW cooling. ",r/machinelearning,Z0FBQUFBQm0yeGI1QXN1TElQWjdRZUNmYmpSbDZNeXpveUhiZFR6OVRBSE41TEpvQzZFd0JGeGlVY25qbXk1OTZVb3VpQk5oa2xzekxndGdsYmJMdXVZdU5IYXAwVjBnR3c9PQ==
Does it support Ollama local models?,r/machinelearning,Z0FBQUFBQm0yeGI1UUdCU2FPYTJic1htM2N6a0JyMjNkcUx6NzRQUkFIakwwSXhLZGNSTVk2QXVxWjlVRHpuTk1CSFJNV1VxOEI0TEZTM0VLX1lyWHV1bmswcjBEZnpEaXQ3YjRVZEpvRjhyUE9lZThTTGNEZEU9
"According to the LinkedIn link on the blog, OP has a bachelor's degree in politics and is claiming that Geoffrey Hinton is suffering from Dunning-Krueger.

The lack of self-awareness here is **astounding**.",r/machinelearning,Z0FBQUFBQm0yeGI1amdDeDNKb0hrWkFyZ3dVNUpYdFhzOWJoRHZSX2wyUk5CNUdnUllTMk83YnpfaGpRcks4WjNtSkoxVWdZcU5JT2J6WjlJWXlPMXNNUWhUVkRXal93NEE9PQ==
"Ah so you’re the author?

Just played around with this on replicate - very impressive.

Do you have plans to open source any other languages? What’s your overall thought on open source (why is it part of your strategy?)

I was a huge fan of Coqui’s XTTS and am excited to see a real contender - especially after Metavoice disappointed.",r/machinelearning,Z0FBQUFBQm0yeGI1V0g2WEdaUnFaVks0Ym1vOFBqNkMwWEwtUFBpeXNocFlhbm4wOXItQWlCU3VQRGsyWFNZcXJldTNxeU9GQ1dOclE0YjdNR3NXWnE2el9jQjU1YTY0YWc9PQ==
Well you should be out of the rigorous stage by the time you finish your PhD - if you’re showing up at a company with that attitude people are right to be annoyed with you.,r/machinelearning,Z0FBQUFBQm0yeGI1WlZGVFJXZENRbjF4X1d4YkcwMDhVUG5oM2w3S0tDSkh6aEUwS01WMEl1RC1tS055TTl1cG9OT3BueU9LWkZGRUpjR053S0NKbzE3ZFc5UUQ0WTYzMHc9PQ==
Does it support long text generation out of the box? And what about plans for streaming output?,r/machinelearning,Z0FBQUFBQm0yeGI1TkZfV05sRmhlc1hWc1B0TWxEY3lTMjkyeW9hMzlvUzZXUGhzLWR5QTMwX19HZWtVVnY1NVVtdWVyYWlpQkVwbXZJbDkyaFRlZEpqQUdINF82MXpOMHc9PQ==
LOL... I guess a $1200 registration fee is not rare now,r/machinelearning,Z0FBQUFBQm0yeGI1dVlvc3VjTUdVaFBEUEhwclRLSFUyZTlFZjk3eGtZQ3o2ZGRGamZvWGs3NnMyTUpxanNDY3lnejQ0dmZ3Y2VIN055U2FMSS0yWG0tXzc2T2hKY2xZdHc9PQ==
"A very common speculation about AGI is that almost AGI will lead to AGI which will lead to something we don't understand well enough to even give a name to.

But no, LLMs are fantastic rote learning machines. They can even mix and match their rote learning very well when you ask it to write a Rammstein song about the time your cat farted.

But, I am a programmer who uses these and other similar tools and they can't solve my even slightly advanced programming problems. 

If I ask it to load a csv into a pandas dataframe and then display that dataframe as a PyQt application table. It isn't too bad. But if I start asking for a few more features things start to break down. If you aren't a programmer this might sound sophisticated, but it is very much not. This would be like changing a car tire compared to developing the next generation of BMW EVs.

What would not shock me is if someone is brainstorming with an LLM and it offhandedly puts a few AI concepts together and suggests a path forward. 

But this path forward would take a highly sophisticated programmer well versed in the depths of AI to understand, recognize its value, and then proceed.

What fools people is that LLMs speak like very well educated people, and due to their rote knowledge can speak on a broad range of topics.",r/machinelearning,Z0FBQUFBQm0yeGI2Y2FaTXR0ZzlWQmhKMTNkLUFxTEpxVkttMWpFZFhUeS1zTE1abV9yby04anZpZGJYTXprTUM0MU4tNEZNOFBiZ2RwYXE1YkV0U1d5LWdwOFZTVUtwWWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2ZzNDODhqc1JvZFN4b2hGakthTXBka1lzejhJeTdabzg1dFJTMXRLUHBUS3JvaVUybmZXWGo4aFlIcEVqZTQxSjhsa3lzcGIxZUFUNHdzT3FPb2J0YUE9PQ==
It’s only the beginning…,r/machinelearning,Z0FBQUFBQm0yeGI2bUtIekFYemdLd1RyQURIOERWQjJhZ3NabGFQMkJGNFp0WTZ4QjVQNnJQcVhxeklKaG1PWmhOX3hiOXFjeUNlWWZGVlptZTF1aVFJRklLMko5R1JFbkE9PQ==
"[mipnerf](https://arxiv.org/pdf/2103.13415)

a somewhat complex idea with simple diagrams",r/machinelearning,Z0FBQUFBQm0yeGI2RC1yR1ZjRDFUQk1ETUtrZWw3RkxQd3V1b0RfTnlkTEVCSVg0QnZDb19scVBzYVJpSmhNYUpHLVFTaTN4Zlp3cnh0LWNFcnMtQm1OVmNUQmtydTllS29PTGgwQXpoWEZHZzRzcG1XeWQ5OFE9
"I would think it depends at what level you're seeking improvements. Like, perhaps it could devise improvements on fine-tuning data or something like that. However, I'd completely agree with you in regards to functions. Except in the case that the model is trained on more recent research than was used to develop the process of training the model. In which case, I think maybe it's possible it can defer to some arxiv paper I wasn't aware of to help me train and fine tune a new model. However, that's me stretching out what the question is asking really far.",r/machinelearning,Z0FBQUFBQm0yeGI2REVBYmZGbVJ6Y2RmeC1hZ1ExV1NjZGo1c293cEZyYUZKZ1ZYbkdkZ2pONmxxVUR5TzRYZHhTaGFnV0VIaVllbjV3bW5MVFRSOTlrVWpaeXhUc3VUMlE9PQ==
"> What fools people is that LLMs speak like very well educated people, and due to their rote knowledge can speak on a broad range of topics.

It's easy to confuse its in-depth knowledge of the Old Testament, the Napoleonic Wars, and Programming with the type of genius preidsposed to lucrative new ideas. But it just has those things sort of memorized.",r/machinelearning,Z0FBQUFBQm0yeGI2bkItSk5ubGQwNFdJUFlscF90SWU2S19UcXcwbUxrZmlNYl9UaFpoWEVxR2FaTlVERW55SXFVb3RINFZaSFVES0pRR2ZJSEZsRjU5OS0yTHZIU1d4RUE9PQ==
Doesn't grokking only occur in very artificial settings like modular arithmetic? Never heard of anyone worrying about grokking on real datasets.,r/machinelearning,Z0FBQUFBQm0yeGI2TmZzbHRXU1hnaldwV2ttUGZrOXo0MnM0Y1NWUnQ1MzFmT3hmV0dOdGF5azRzeTFsTlB0Vl9fc3RQOWlKU2VveEpQNEdYSTFubDZxNkVreDgyMEh6N2c9PQ==
"Never seen $1,200 registration fee for students. The registration fee is for the conference organizers to actually host a conference. Also, you get benefit of registration fee by attending the conference to network with people. Not the same with a journal.",r/machinelearning,Z0FBQUFBQm0yeGI2UnZjT1BoV0hjZFFXTUdpWFhkTUJ5NllfNlJuNW91M1hWODEtRkJxaENhbW1RekRRZVJlS0szNF9rMmxDbHBzNnhsY1g0akxqZEFsSmlsUGQzTGhIYUE9PQ==
Have you done Intrusion detection project? Caz I'm facing an error in that project if possible please guide me .,r/machinelearning,Z0FBQUFBQm0yeGI2ZVNPZnpPYWhqLXBMZzVKT004ZFlJU1k2Z21rQ0RHNWw1UGhsSUNMMnRUZUFha3doYUVNZEFURktmN2dfbVZqWjJld29pSnBZM1VsYWR5R05qcnhWOGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2U3liSEdFc1dURmhsM2JHd1JkNDhoVlJOOEtvZElIc0tSNXlyb3I4Q2h0TG5FamtidHhUOTYxd0JCSG9iNW5OTnZVS0ZkRDd5RzFJYmljcEY2bXBsSnc9PQ==
Can you elaborate?,r/machinelearning,Z0FBQUFBQm0yeGI2VmJyX3FudGk3RUJpSHVhSXhIcU11Q2FrQXJZZEtjbWdyNm5ZODNva2pleWI4VUpZRk1jQ1psZ2kyTWlQWVBqU1VSakp2VUpyOGk4YVBBel9zcFFpaFE9PQ==
"Yeah, I get plenty of LinkedIn recruiters offering me relevant jobs (once or twice a week) although I am inactive there, while there are many reasons why it would not happen where I live (e.g., there is a war). With that being said, it's all applied as you stated (data scientist, only senior, which in my domain is always research to some extent since I do unstructured data so it is very CS and not excel). What I meant is, that there are not many jobs that are mostly research without product orientation, we have no disagreement at all.",r/machinelearning,Z0FBQUFBQm0yeGI2UXY3dF94Rk9uZml2dzdlUkFUR3VxWUFENWduSlFrWGNVS0Q2RXpqUFNZRDRveEJJcnBmRDN6UlNCMXNBZWV5T0RVNTEwYTJpMDlWcTFYU1JiZ0RvM2FSclZsR3RpdXZyWUJtU2dCVlNkNk09
"I'm working on an intrusion detection project where I input a URL and get an output indicating whether it's malicious or not. I'm using the CISIOT 2017 dataset and PyShark to extract packet values from the URL. These values are then checked against the dataset using an EL Tree classification model. However, I'm encountering an error stating that packet extraction is not happening. Have u faced a similar issue or can u offer advice on how to resolve this?",r/machinelearning,Z0FBQUFBQm0yeGI2WURLTkY5bzVQbE4xQUFlNGM1eXBJVThTMUJNbFRNaWwtaEtnZ2pXdDUyTmdscnh1UDlFRlM4eUc2cFlaX2NYVlNUaWFOTjJzcDFySU1KWUlNQTRFYlE9PQ==
"Your argument does not attack any of the points in the paper.

LLMs are pretty ok with coming out with new algorithmic ideas, and as long as you have some form of evaluation function and try to find the best function via simulation/search, there is no reason some of them would not work, which I think is the argument of the paper. There is really nothing about programming here, it is a math formula for optimization.",r/machinelearning,Z0FBQUFBQm0yeGI2OVBnUDBQVkI0SzExVDJ5R0hqQjh6a1A3NllvYlpreUFnQUFQeE4ya21TNGtDdHJBTmU5SnVuWHZEWXJ4NWxadEU1VUlrZGlnc01wSUlqTUlBVmJoUURTdklGRU9Ec19uNWNvcWZVM2RDYU09
"I am sorry, I am not familiar with this issue. Probably you can get help from pyshark github",r/machinelearning,Z0FBQUFBQm0yeGI2TG5nNTVnV3BjMnJHSEpTdWh1RVppVVdlYkYxUnk4TVBxNlhKM1ltdldCMV9YTkFGZTNlbldYaEN4dlZTSm9kalppZjNYd3hmdHBiWjU1WUJiRU55Ync9PQ==
"The language *is* domain specific, by design. But the methods used to search in it would likely be useful in many other program synthesis tasks.


It's worth noting that all ML methods, including deep learning, are special cases of program synthesis. A given architecture defines a space of programs (although the programs all have the same structure), SGD searches it for one that fits data. 


One of the advantages of representing your space of programs using a programming language is exactly that you can easily customize its inductive biases. But a more general approach is to have a Turing complete language, and learn abstractions that suit a given domain, as they do in DreamCoder.",r/machinelearning,Z0FBQUFBQm0yeGI2ZGhKSUpXUlo5SHg4VW5Zb3Vqa2NlaEtIdmFFZ291Qmlxa3ZmUlRVMV8xRGhaTURJaXNqc3YxaUk4bFFzYURQUF85NDUzNGFueGpEckxMNUhCbGZXM2c9PQ==
"Hmm.
1. Not sure my degree is relevant
2. I didn't say anything about Geoffrey Hinton
3. Thanks for reading 🙏",r/machinelearning,Z0FBQUFBQm0yeGI2dExpYy05N2ZvcHMzQlZrNmV0TmIya3lFS1FQNFFWa0xfcEVla1dBZUpXUmxRZ1JjTV9sVzUtWUhpY1JrMk4zMWxGZU03VjNzM2h1VWxFQjNRQU02dUE9PQ==
"everyone: we are horrified that this is a thing that exists!


you: hmm i could make that...",r/machinelearning,Z0FBQUFBQm0yeGI2SW9rZG5OOENyUk5XSW1hXzROb0tRa3dyZzhZMkVpamxqSUx4cFpHS1FxMDdqZi1oTkhXRFJDbzlOcDlYME5JdU1KU3FxWlJKYVUxazNnS2c3Sk5LaGc9PQ==
"I think they just hope that the model learns that rotations/translations aren't important. The main backbone is a diffusion model, so each noised step can be viewed as a form of data augmentation to help learn invariance/equivariance. I think they also augment their data directly with random rotations and translations.",r/machinelearning,Z0FBQUFBQm0yeGI2c1pxVjB1ZHpNeUQyU01kWmxSTlUtWGd6bmNzWDkwWXdSNUk0eVlDQ05xZExVN3BGcjNjOUFkSl9RYjlscXJmUGhQODBlRzlDODdKaFBUUVRZdjUyVUE9PQ==
"""hmm i could make that opensource, secure and safe""",r/machinelearning,Z0FBQUFBQm0yeGI2dUh2eXN0Mm5BX0MyOXl2dDFEb3htT3BkMm5ydlV5a1NRTEpyc2hPY2ZrdzJwTWVrY291cm9mYjBmUzhITldNdTg1V1lnejJTRFFGc1dJNHFuWUdtMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2cHoxRUFONHljYzZ3OXZmVTJNTXBWSzI0YTVWd1h5QXBQVERJeXNjYks5V3NjRjY5d3BRX0J2UmUzdEN3WHRseGloUWtpdXE0YnY4cEh6Q2tYT0p3Q3c9PQ==
Ohh okay thank you,r/machinelearning,Z0FBQUFBQm0yeGI2dE5pRFNTc3k4dktfLTZnaUx3VEhycWlxR1FrTlhNQWVJN1ZHYU1aNGtFZVZqYS1oNXcwWmhYXzdvRFBOMGhPblZZZ2hDUDFob2d5UERKZUUteDFRMnc9PQ==
"I don't know if the ultimate test, but better than everything else currently",r/machinelearning,Z0FBQUFBQm0yeGI2cXNWc2xPZjZLZDh6ZTZEWGY0OWhkcF9nVXFPbndrWUlBdzgza0pYUFpNeXJya0c3VkYwSWRaUVNCU1ZjUGVDMzBRVzY2Y2hpX3B3a0FWTTM3eDVhcFE9PQ==
[Here is the full paper.](https://www.nature.com/articles/s41586-019-1724-z.epdf?author_access_token=lZH3nqPYtWJXfDA10W0CNNRgN0jAjWel9jnR3ZoTv0PSZcPzJFGNAZhOlk4deBCKzKm70KfinloafEF1bCCXL6IIHHgKaDkaTkBcTEv7aT-wqDoG1VeO9-wO3GEoAMF9bAOt7mJ0RWQnRVMbyfgH9A%3D%3D),r/machinelearning,Z0FBQUFBQm0yeGI2RHVOczBwaEJDNGJNam84S3FVd1NTREd1YzNHaFh5dE5PTlZJOVloWFR1VE9ybnJ5c0gzRjNMUmp3RkktWTZla2o2bnhwS1dnYXNMS3JBTHZqVmtYNFE9PQ==
"fig.2 in here https://arxiv.org/abs/2303.01469
seems an art for me.",r/machinelearning,Z0FBQUFBQm0yeGI2ZWxyS0o4anJBV3hTdHQ3eUlVNmNyS0c3S0JqZW9IZkVDanVRcFpQNjFINXRpdlhmRVp1QTJ0aW9jd1ZDdnE5OHY1RE5IdGh6bm9HYi1oYVdub0hLYWo3SGFJX0U2MXduWXZvb05Sbk4zNnM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SFpLZUxwNHNQRXRLY3BlMWhidXVNaDY2ZlYxTFFtLWRzQ0h6N3Vpb2VBbmFKV1FYZEdlTjZBdWIyZEhWOVBaSU11eWp0VXJLRUY0bXF1d2tZcG1qbWc9PQ==
"I wonder if people use the word ""reasoning"" as a buzzword or if there are actually proper definitions of reasoning. Personally, I don't see how one can claim that LLM have reasoning abilities because of the **Chinese room argument**: even when a machine convinces a human Chinese speaker that the program is itself a live Chinese speaker, does it really ""understand"" Chinese? Similarly, even if a LLM can convince humans who are capable of reasoning that it has reasoning ability, what does it mean to be able to ""reason""?",r/machinelearning,Z0FBQUFBQm0yeGI2TEYzRFhiTXNwOGxVUnlLMWJrRFhXTmliSVZFMG9RMExSR3BFMDdoRWpsaEcyck9YR1Jvb0tkcTA1M29VQmpmYW55aFZHTlJYalUxTW5SZmo0QWN1eWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2S1cyNndTSm9ETW5CRzJ0cXB3Qk9EM21qbGtmaUJFT2dmT21qR3lEa01zYkxRUGo2QTdlX0pGS0xPQUYwbjJGQjVZQUVHMXhNOTlnUHZ2YUVVVkV6NFE9PQ==
"I don't think there are general views on the topic, but you might find this interesting: https://www.basis.ai/blog/autumn/",r/machinelearning,Z0FBQUFBQm0yeGI2dnFTUDVMR2d3XzhjMUQxbFpRc1BEVDZsMzBMbEtEbWQwRUFqWExpb3AzcnhIZXczRWJkSEVtTTVjZjFrSVU4cXdoUmVpdDYxcU5GRzcwM1I0NVA2ZWc9PQ==
"Exactly. FunSearch by DeepMind is a good example:

https://www.nature.com/articles/s41586-023-06924-6

I see no theoretical reason for why this couldn't be applied to loss function search.",r/machinelearning,Z0FBQUFBQm0yeGI2bnJtZXlJZkF4UjNNQ1JscUVRYzlQUmJCYWZmUVhsR01vM0ZVM1R1UmRJTncxNll6Q255dmZaQ0RJOG1VbXNqUmpQZlBNbHpHZFRuamQwOEprbUxKS1E9PQ==
"The scary part in recall is that local data can be sent to 3rd party servers and you have no control over it. Hearing aids are amazing for the people that need them. A hearing aid that sends all its data to Meta is horrifying. Same, same, but different.",r/machinelearning,Z0FBQUFBQm0yeGI2LXEwanF5UVMtdU91c3lpeUxHYzltbGxZVmV5enh5U2FOUW5NY25XamkyZ25lZlJFdmtNOFU0X2g2UTdhVzVuUllsNGRhUnpkckM0WE9WTGQ1Y0lDNW1pUzRvWXgwdThqNDNlZW1Za1gzSG89
"Microsoft says it all stays on device. 

And who’s to say that OP isn’t planning on doing the same? If you’re concerned about security you shouldn’t trust random code from reddit.",r/machinelearning,Z0FBQUFBQm0yeGI2dmxnanowUG1Ob08wMDFRc2p5Ny15aFhiM3lSN2pKNnNwTGpCMFRxbXlYV1I4WUM5R0x6ZzQwOC1HTWlDNElwWlNLWnE5YVo0NXFfdC1MSWY4Y21hb0JITEpZZjFybWFJeDhTWFk1aDl3TjA9
"Correct

I think I should add this to the Readme on github",r/machinelearning,Z0FBQUFBQm0yeGI2ZUVTMjdGWXZrclpkeTA5Y1R1NUM1Sy1XYjVqbmpCcnZtc3IwLXdOdjFjSmRNcGhLR2FSVndHLWlCR09fcHRPYXBHZGNSRnc3Yjc4ZGFQeDBVYUhjQ2c9PQ==
"You don't nead to trust me, the project is opensource you can just check the code.

And you can't actually trust Microsoft, it's a soulless corporation not a community driven project",r/machinelearning,Z0FBQUFBQm0yeGI2NTRhUy1KVjRpckRHOTFKLVZpNXNhWEFPN1NPMDFvejMtcWhfUllTQXJ3Wm1FOFYyZ0lTRW43emNRMTdiSGJWUkRvRFExVE0xanVqdUpWOGREbUI1Mmc9PQ==
Speculative decoding,r/machinelearning,Z0FBQUFBQm0yeGI2aktqdUx4UTRON1lfcWZqd2tDcEhBQ3Z5Yld6SEZrSVM5NnlCNzdNSDY3QkVsMTFYYWtvOG95V1R3aEVkMF9yX2xvMTlFYXozVUF4cEs0ZXJwNHhhSl9nRzE1YnpFREFSOGdrazFuUVoybVk9
"This should be sufficient: [https://aiinterview.io/jobs/genai-developer/interview/](https://aiinterview.io/jobs/genai-developer/interview/)  
It showed me the mirror for my preparation.",r/machinelearning,Z0FBQUFBQm0yeGI2YW1lOHRjZXd6d1czWjBrR3c1bHFXMVVjVkNzUzNMNWltZ0h3aFlocWtDbkNsVlp0WTIwUWk5Z0ZXNjFSMm0tV3JOS0VxR2RlY05YZXc4VXFTdmpjYWNQSjhhT1ZwMjF2dEV6cFp5RnpsWEk9
self-supervised learning,r/machinelearning,Z0FBQUFBQm0yeGI2Wi05dTlHUV9JUnJELWZRdGRGWkgyT3I5N0ZDZW9yOHZxeXZQRS1fMkItWGtkaEZLaV9ycmtoSEFuWUlhLTZ4VGprZFNnTzRBUDYwLXhRaVluX3ltYUE9PQ==
It depends. What exactly do you mean by cleaning for images?,r/machinelearning,Z0FBQUFBQm0yeGI2UGdESVFOQ3Q0S1dnaFlXZ21Ubi0tOGtoSUJGbWZHcEsxaVhtR21hWE1ZVTBoOEFNdWNGVmh4eVFNRFEtWWRWMVUwVnhOaWY5c3l6WnBJVEJEZ3Jjdmc9PQ==
"> DiscoPOP

nice.",r/machinelearning,Z0FBQUFBQm0yeGI2QVUzcjBVSzZaRWlIWTQ5MGV5clFOcjRGbEpvRjM2d2NIR0p3elZEYTFqZ0xqNUlwVDh2S1h5YlQtQldRWmtZZjdUTzRhbEJlVlBqZFd1NnVDdUxTQWc9PQ==
What about internship?,r/machinelearning,Z0FBQUFBQm0yeGI2Slk1Q2dScEREa0tlNGZvX0JvaU1qN0pLMkxYVktIZXRwdmp2NGFlOEZXTjhzb0FOajg0ZE5ScFFDRVI3TEQxRDVycEE1TUIzMFdVYmFOampSTjhscmdLejRhdnpiWDA2RkxneC1WZ1hJaVE9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI2NmVkalZRZ3ZjdHNTSEtrMF9Fc3ZmMm9oOUNrZWVMRnVpMGVXSllhRDk2NmtNNzNRZnVEaVU1ODNaQS1nWXo4SlVhRDYwdEE2elFqU2RWMUtqTGo4MHZvbDFOSXJWZU4wTEtNQlRodzlEZjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2UnFWbmdmbGdWallnalJBaDlKa3BrQmw2eGxyMVl5WWxtdGdTRUxrU3dqTkxJMjFtb3QxYUtuQmpLNXVsUDVKdWpyQ3RIVlRyWnlYMGlOTXpZbTh3c3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2LWxNRFJnRTNPMUNFS0xybXBVZ1pSMzl2UzlkSVk2ckc4RERzbVhjWXkzUC1UWWlGMTFLTzV6ZEI0MG9GcG1INDFqOV9xN2lOODJxOEt0UkNUUnNkSUE9PQ==
"I am very confused about a description of k-fold cross-validation in Data-Driven Science and Engineering book from Steven Brunton and Nathan Kutz. 

""Procedure for k-fold cross-validation of models. The data is initially partitioned into a training set and test (withhold) set. Typically, the withhold set is generated from a random sample of the overall data. The training data is partitioned into k-folds whereby a random sub-selection of the training data is collected in order to build a regression model Yj = f (Xj, βj). Importantly, each model generates the loading parameters βj. After the k-fold models are generated, the best model Y = f (X, β ̄ ) is produced. There are different ways to get the best model; in some cases, it may be appropriate to average the model parameters so that β ̄ = average(βj). One could also simply pick the best parameters from the k-fold set. In either case, the best model is then tested on the withheld data to evaluate its viability.""

**Two questions:** 1) Is it fair to say this is not an accurate description of k-fold cross-validation as it is typically understood? 2) Are there other understandings (definitions) of k-fold cross-validation for which this is accurate?",r/machinelearning,Z0FBQUFBQm0yeGI2aFJwdGRad0NDTGVxRFJNaDR4T3YzUl9oRFRXa3BfbzNIRm5sTklURGpxSDh5VFhIS2RuS1ktNXNtOWZVX0J6X0EwUHU1SGsyOVZYSEsxWlBLaThMRkE9PQ==
"Hello Everyone  
  
Like is it possible to train a model on X1\\_i Inputs Y1\\_i Output and then the second one is running on X1\\_i + Y1\\_i to give output Y2\\_i ??

Context : (I am just getting my hand into ML and trying to build this for a product where we are predicting what the user is likely to select. I have learned about Supervised Learning Algorithims including ensemble techniques, so if there's another thing to learn kindly suggest) so Like building api's with flask would it be possible to get those result ??",r/machinelearning,Z0FBQUFBQm0yeGI2QlJlVzFpNDlrNHh5aWQ3clJBT0JPeDdxNkVnOVJLeWFtRTBMcDVpSVowNnBvcmU1T0Z6SXctNVNkdWRkbTBUSHV0dVNmNUNyOTVQNDJ0QTBKRmlVcHZiRjRGeWpYVDEwOFZDbVp0Vi03eUU9
"Hello everyone,

I'm trying to build a RAG-based LLM and I'm working with hundreds of (highly diverse) medical reports that are stored in a vector DB. However, the retrieval of the context works really poorly. Interestingly, it works much better when not using a vector DB at all. So I'm wondering if there's something I'm missing or if a vector DB is actually just not suited for my use case.

I appreciate any hints!",r/machinelearning,Z0FBQUFBQm0yeGI2cmxHVUZrRG9iek1zWWZJRkVBZTkzaGdLTzdBQS1WLUpUaDFrSGFid1NGYVU1a2IydXI5RU5wVlhGalMtci1EWWhSakV2R21sX1RHT1dsY0NXeWlvUmc9PQ==
Cool!,r/machinelearning,Z0FBQUFBQm0yeGI2dW16d1prbVNMREdWZHBocG0yWkF2Qzg0V1ptTWdjejhkcmtmZjJybjB4OFJLOGVxOEhmUEoyRERJSXNpdlc3TXFVYXRIVzA2YWJTbmV1Yk0tNVhHRjdRTGF3WTQ2R2E5RUZYb2FjdjhDRE09
Thank you :),r/machinelearning,Z0FBQUFBQm0yeGI2ekt0UjFVNVE3TzFZdS1fVFpWMFVsbGtndkNyOWtFbHYwZGc0NHVMMnlRLURUS193YzBTYURfcjZJdGhyUHo1aVpELXdpR2N1bGVjUk9zazAwN3EzZkNFM0JpVEt0NHBKQTZ1ZHMxUXJRX1E9
"Ah naturally! Just a simple evaluation function! It’s so obvious!

Now that I come to think of it, where did I put that simple evaluation function? Hmmm where did I leave it last?",r/machinelearning,Z0FBQUFBQm0yeGI2MWp4dUxVVk5ZSWhLX0pZRG5PaXlRa1Jic0VsanFUc0Jzaks1UUxiNmZjd3g2WW83NmJWRzdidVpzTHF6N0E4cGpHZTVXMGNOdTliT2NJazMzc3IxbGc9PQ==
I would highly recommend looking into something like Hadoop. Some of the frameworks like MapReduce are particularly helpful in these situations,r/machinelearning,Z0FBQUFBQm0yeGI2QlMyR3ByazA5QlJXUjBPaEZKZmxPZS0tYUdGYzNpeXdyT3BaZjdDSXAxaVJEcXpvUDdwYjVUWTV0REwtS1ZSeEhxdkxtVEotY0V3Zng5Z19IN3hnTUE9PQ==
Came here to say this,r/machinelearning,Z0FBQUFBQm0yeGI2R1ZYTldkNjRNeXhqSDUyQVUyZmlUX2x0UW8xbEp1MWhDWnpET2MzbFVZOC10WTl3N0JkVHVBeUlpUnZRQldJcHdLZVBINDlGWWZkZndfY1Y3WmdjWGc9PQ==
"Well there's the question of whether grokking is happening all the time: if you're training a LLM there are tons of sub-tasks that it groks. These individual pieces like learning a minor stylistic rule we don't even notice wouldn't have a large effect on the loss even when they're grokked. As well, due to the amount of sub-tasks, you'd have a continual series of them being grokked, which can look pretty smooth. Modular arithmetic, then, is just the case where there's basically only one 'task', which is why it appears as a sharp shift.  
Or, alternatively/in combination: that in less strictly defined problems, like language, there's an easier ability to shift from one representation (memorized) to the generalized representation more smoothly. While with modular arithmetic, there's not enough 'space in between' the two solutions to neatly transition much.  
(I'm pretty sure I read something that detailed the former hypothesis in more detail, but I don't remember the paper or article)",r/machinelearning,Z0FBQUFBQm0yeGI2VmItSVcwOU1zazJ1TFJkZ1N6ZDNJNjF6dTdUNGZES0lpc2MxWW81V1R5Q0NkLUpsNURXM2FyZXVOQ1VkM3pWTWR1WkJjRDNya2E2aW9fdS1UaG5IdlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2YlRSTklOM0xJbXNLVEpQN01zMjBGN25xNDlkTGZmd2RIRnMyRl9QSlZCUnV1eGNzTXd4VVZ5N2RTYTBxSmp0TUNUMnNIT0NtSGRQSUR4clBtcC1OQ0E9PQ==
"I think this challenge succeeds in making a task that is hard to achieve through pure ""memorization"" which is what the typical architectures are good at. 

I think alphazero is trained on far more than 10,000 boards configurations.",r/machinelearning,Z0FBQUFBQm0yeGI2OTBnVmVGZmZEZFZLQ2lPNWlXWnQwOHhBZUJYbjdIQ2cwd1dEdERiRmJlc2dYbTBmNWV0Um9wVGQ1MldxQl93NnZ5cFNkTHN2dVFXZktSYnh6TnhPT3c9PQ==
15x15x10 is 2250 features you get here. Simple fully connected and attention will work just fine,r/machinelearning,Z0FBQUFBQm0yeGI2a1B2Tl9qNUduUkZSVU82RDFSSHJST3BnYzZQRWFMMEh2WTVmanVBbzNEMmpzSjlfMDhuV0NIZ0NacFAzVktzUVpxX2paSUdFbFgxdGFvR19qdGhIdERYeUN0OWZGSFJiTUNTUEEtRDRkLUU9
I don't see why this would need ML neither do I know of any such research. ,r/machinelearning,Z0FBQUFBQm0yeGI2b3JPUUhJMFFLSHA1ZTNQZEdURG5CRWJKVEhEdHpSOWcyVkJHSXBOYjJISDM1RWcwYkFfbW1NcHRqbEs0ajFwN3M0eEozQ1Zxd2FUN3FQenFZUFQyVUE9PQ==
The code is on GitHub just check it lol no need to be paranoid,r/machinelearning,Z0FBQUFBQm0yeGI2VVhySVBBYTk4ZWNBRFBQdDZvcVRtXzU2TXlWM3lqdGpCVHUzOENxMnk4d2xfb25iYW1CcmVFTmJzTnJ3d1ZiclR0eHJtenZIelFpMlM3Njk3blFvV2c9PQ==
The funny thing is you don't even need that many examples for BERT to beat GPT 4,r/machinelearning,Z0FBQUFBQm0yeGI2RmxRUmNuUVFyUlBXcFRSeXV2dThENUJoZ29FSEVLN3R4RHBoSVVORWhJdlJDQWw1Nm5IbmhzOUttUTBfRnBPMWNfay1ycExmZ1Z1djl6ZHRGbUpXOWV5Z280UGx4UTF6Z0gtQ2tJUDgxMGM9
"Model 1 Training Data,,,,,,,,,  
,,,,,,,,,  
Col1,Col2,Col3,Col4,Col5,Col6,Col7,Col8,Output,  
Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,int,int,Yes,  
Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,int,int,Yes,  
Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,int,int,No,

  
Model 2 Training Data,,,,,,,,,  
,,,,,,,,,  
,,,,,,,,,  
Col1,Col2,Col3,Col4,Col5,Col6,Col7,Col8,Col9,Output  
Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,int,int,Categorical Data (Output from Model 1) {Yes or No},Category 1  
Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,int,int,Categorical Data (Output from Model 1) {Yes or No},Category 2  
Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,Categorical Data,int,int,Categorical Data (Output from Model 1) {Yes or No},Category 1

SO let's say I found XG boost give good Score for Model 1 now althiough when I am training second model I do have those output , but when I am buliing I want to create a flow That i have given inputs from Col 1 to COl 8 , It will prdict Col9 and if Col9 is right (since the user will select flow ) then he should be redirected to Output that is col10",r/machinelearning,Z0FBQUFBQm0yeGI2dHJtM0lWTER0MkY2SFJJSGx2TnNpRWUzSXpZTEg5WTBSN0ZvUUZHWVJRcWJmemxQQTRIQkg0clFibUpxdUxTeXRIQ0FyUS1tOTlpYkNkNzZ1RTE1TW5iRXhFSjZELVYwRWVsaUxTQ09qRGc9
"It's open source, so can/should contribute performance improvements too! No need to depend on OP",r/machinelearning,Z0FBQUFBQm0yeGI2aF9lSlotcEJBMjFBTG50al9xbnpubGxLNGtNOHFWMGNsbjZUNkNLTFpOVUgxY0NLMmdGaVdpdEQ2Tjh2Wk9CLUZxck5sWDNIYTM3UXNKUmttVTV5VWc9PQ==
"> The first model that everyone agrees is AGI will probably be some frankenstein multimodal GNN trained with RL

I have this theory too that the first AGI will have an awful looking structure",r/machinelearning,Z0FBQUFBQm0yeGI2OEJLTVVTc1Uza21VM0VqU3d2dHFsWG1uWnFrRHRCNTY2U1pKTXo1b01HLXJzVjQ2SkI3OTBicm0zcFROcHd6OTlSVzQ0OXVPd1JtYlFrbjg5Z2pIN2JFNXJKNmYxaGhuNGZWcEhkblZRSlE9
"The majority of economics nobel prize holders had views on macro that are now considered wrong, for example.",r/machinelearning,Z0FBQUFBQm0yeGI2OEJuWDQ5TFRqYk41Q0hRMnUzNU5GVlI5dy1Ed2hOYlpuSjRDbkFpNVl3N1NOMFlPSGhQR1gzbE5JNWdCLTdOdHA4bGdDd2lQa3F5aTdGUkYxdjlTeGQtYkFrQkh5bl9NUWlZS2xpYWtKRnc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2bUloS1lmUFpfd0pUSE11MnpxTUtPVndlcnhZWUNpdnlrNW5zUG41SHppaEhRZUlhRG5PaUVOV1FWSGlSR0pMU0pHVUZyaERHMEdaTzdaTFBuOWt4Rnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2WjhJcU9Kb3hBZW1fblk5U1l0U3lGT243WkFNajluTC1DRGhKc1d2VmMzdE5EcWZNbGNMX1lMNkI0ZE5VczA4WFRJRnZzLUVIdDNSQlRUUnRNbGY4RXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2ekp1YXRlTU1ya3FvQ1BVVmlMcHhvOWJPaWRZMl8yajF0UzFySTlSWjRtSTQ2ZnRFMmRQdUZXNUdlZWZRMzVUOGNvSU5mYmhOdkVnRExvSlVpZFpzQkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2WFU2eTlxVmNtOGRpQ0FtWVNNelp3MWktbFBsRy1CLUxoZEl4RTJOc0h0bm5qSWdNbW9WLWFCUjRDT0JibUktejhjd2VVNHR3U096YnRsSTduLTBhRUE9PQ==
Are we talking about the same Keras? There are entire manuals of documentation. ,r/machinelearning,Z0FBQUFBQm0yeGI2ZEJKNlBEVkcycjBuNDBMT25XVnRlTFN2RzljT3BVVW0tVDZFbzlkZ2t4LUQtdk9qN0ZiNzR2VmU2b09yZVVMbzBibm1hZ3pDOVdFVTRoN3Fna1ZIV3c9PQ==
">What are your thoughts on the generated samples that this post is about? 


 This is what you replied to in the first place, so it's weird to me that you didn't mention the generated samples or the model this post is about. ",r/machinelearning,Z0FBQUFBQm0yeGI2M3FkazlZOU95YjNhZjl1TFFYNUNMNVh6bEUzSGFpUjY0bU82SE0yUUd1Z1dJazZQazczS1I1QlVhLTM2MjdTNlFmN3pWWVBhU0dzOGhTTEhfUTlEN0E9PQ==
"depending upon what kind of modality you can visit these links to explore the same yourself and try it out

  
[https://www.labellerr.com/blog/top-image-labeling-tools/](https://www.labellerr.com/blog/top-image-labeling-tools/)

[https://www.labellerr.com/blog/7-best-audio-annotation-labeling-tools-in-2024/](https://www.labellerr.com/blog/7-best-audio-annotation-labeling-tools-in-2024/)

  
[https://www.labellerr.com/blog/top-video-annotation-tools/](https://www.labellerr.com/blog/top-video-annotation-tools/)

[https://www.labellerr.com/blog/7-best-medical-image-annotation-labeling-tools-in-2024/](https://www.labellerr.com/blog/7-best-medical-image-annotation-labeling-tools-in-2024/)",r/machinelearning,Z0FBQUFBQm0yeGI2X1lrcnJoZmphQ0ZPOU1lYVlnTDhlMXdRZ2xUR1ZvVkE3QXpkTTBjZU9QME5sNEoxSjhnaUxOc25kdzdDcWoxMWxfOU5qVlVzVExJeURLWU5KWmNJMXc9PQ==
"Regarding this specific application of recalculating the loss within an optimizer?

           val.assert(loss*lr*something something)
           if(current loss > other loss i already calculated):
               Something something...

I have no idea how to calculate the loss here...",r/machinelearning,Z0FBQUFBQm0yeGI2dk1fd2ZmUGRiQS1XanE3d04xNHNual9kUEhSaTZtQ0cwVDFTX0tiQmRDdHpzaUZPZDliZEUyb1BNMW1uSGZlRU5QWkdrU0kzMVpjQUhuWWFEX2dSZXJvQVh6eHVPWkhtVFNkalZ1bzdRT009
I agree what exactly are you doing to each image?,r/machinelearning,Z0FBQUFBQm0yeGI2UVM2RjZRd0VpU0ZicnYtT3pEbDRhWnY3MmVfMFZXZWFYeEpWU1pha2FhUkFpSnhjX3lTUlZkZ3JlT0ZlUkstNGNINllFNEQ5QzU3d1VTM2RHaW8yd1E9PQ==
You are telling me that in all these guides and all the extremely well commented source code for Keras that you don't see anything that tells you how to calculate loss? https://github.com/keras-team/keras/tree/master/guides Bruh.,r/machinelearning,Z0FBQUFBQm0yeGI2dUptN0YtUnpEcUwtcldXb1dvVXpGamVvVE5vdXU0eVAyWnFEMVhhTGpTd1lHODVfX2FfM3Q5MklmVlNyRFZoZURKUmRjVFU3M0NCU3FYZ215aVVTZEE9PQ==
"If I understood correctly, tanishqkumar7 and his co-authors observe grokking even without regularization (see the second most up-voted answer)",r/machinelearning,Z0FBQUFBQm0yeGI2ODFEQkFNUTBLWkUxMjBtQnUzLWlsMWFwbjJ3cHlPZWw1Z0Q2ZHBkQzJMbEdxZ0xHbTNoMG1JWXJmbnNwbDBZcjNxaldrZjZfS09Ha0ZQVXBDZW1mUWc9PQ==
"I'd put it down to 3 things, mainly:

1. The cyclic consistency loss ensures there's mutual information between the source and target domains.
2. The architecture constrains precisely how the information is conserved. E.g. convolutions generally ensure a relatively small receptive field, hence only local correspondences between input and output
3. The adversarial loss ensures that output images match the distribution of the target domain.",r/machinelearning,Z0FBQUFBQm0yeGI2YlkyV3BsdVBsc2VsWjl6TG0tTU0taUJJblA4TElwRjFkQVlhMTk3MWllTDY4NVBtNmpkR3R4UjRFRlUyd1pEeU9uWE9ObmlTakhMSFVCbU5nTFZNOWJZcmxLdUxXZWR3VFJRZE9OZk13blU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2eVhzQnB0a0NEdzlQenM2NlRiQmotYWF4YTB0LUtQMnVuODVTYUZfTm1DZDVPamdoTTZ6WmtvQnJMOWxOWHFKZ2UwV2kwcVpERld4VlJGSUdDd0NuU3c9PQ==
Secure and safe are BIG claims that probably cant be backed up though,r/machinelearning,Z0FBQUFBQm0yeGI2TFdISjFnYnF5SjhWSVR5Y3l4LWRrRHFBYWVpeDFmQWV3dUprRFZ4Nm8yQnoxZlVvNU9nNDRyYWppVXFhT3FlNGdSdkJ0cVVMNUVCQnc3dUMzdXBDU0E9PQ==
And why do you suppose that's the case?,r/machinelearning,Z0FBQUFBQm0yeGI2Vzk0aFVjMjZRcnczMlUwQVltWlg1N1N6Y01OaEY5LUFoSkMwQVNnNFIwV1FEY3VqZEpDOVJMSXBRSlhOZllfeXZCQVNqaENPRWpVRV9NR0RJLXllWnc9PQ==
"Check out the 20 Newsgroups dataset, might fit your incremental learning needs.",r/machinelearning,Z0FBQUFBQm0yeGI2VHh2MHJmM1pzLVI4amdKMXhLTjREWWNocXdLTTNGM3ZvM1pGWWNuZnVsMHhoaDhTM3NCN0FvOW9OLVNJVnQtZ00walZMUHh2a0RJY0VlbjAyay1QM0xPSVhhTFZyUm9HUHVUYk42WE5Ma2M9
"We struggled with this at my previous company, looking forward to hearing other's solutions.",r/machinelearning,Z0FBQUFBQm0yeGI2WndmSEhxZFRWd2hvMm5rNVBES3BPNE12U2lHT1NESGJxa1pYZkMxclVWWlBpTkRZQU9IV2NtRnNnQWFqQld3REFZdHpObUE3RHllZmo5RC1WcVJDY3hLa184bWRZVXNvc21telh5eC16dUU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2b0tCZHNmeE1jRl9JUC1LekdOMFpKMFZWU19TY3ZkUGdOaTZfbjlER3dCVThpVmxkOEVrMG84cVI3U3Y3Zm54WFlWNU1OT0RIUVJtb0xJVU10V2p0WWc9PQ==
"I have been scraping job postings from emails, [Indeed.com](http://indeed.com/), etc., for a number of years and have been ingesting them into a Neo4J server to infer which I should apply to after extensive model training. This dataset contains some exports from the server and about a thousand example job postings.",r/machinelearning,Z0FBQUFBQm0yeGI2ZHh3ZjZENjNRN2MzczNKbTFxR0xreHlxU2tsem9GenpIMjZqRUdESFJLclIyN0tteXVsdmhHbXQzbXZjcUZISTNMclZ3TG5OeE5zY29SNUFJZVpOLXc9PQ==
"How? You can see the code, you can check what data it's sending, you can see the encryption algorithms. Maybe they're difficult to back up for you lol",r/machinelearning,Z0FBQUFBQm0yeGI2ZlFQMmRTZWpjejRkdUJpcU9KUVhQdXc5LUppRjZvanBWLUVMdG9yWjloWmg2OGJPb1phZUl5MVVZYkpXRWFsLWE4aENDSmxldm1ReW5WbnNnTHRLRDUzR1gzQkpTUmp4SDBQQmVFZHZESVk9
">we showed how to ... reduce grokking by arbitrary amounts (not just 50x) by just tuning one parameter 

Thanks for the answer. Are you talking about lowering weight norm at initialization here? If it is indeed the main lever, what are others that you've mentioned, in practical terms (pytorch code)?",r/machinelearning,Z0FBQUFBQm0yeGI2eDVyVmZfMEVIS0tBUEF1YUJXNm1hMlZocUtzeDZkSk5OV21peEZHVm82cl92cjZJbHRSVmQ5VFM2Y19tMjVXOTdlVzY5ajBRQTY4Q25IbVJnZ0g2eWc9PQ==
"> that was trained on a few thousand labelled notes  
i presume it was fine tuned? otherwise GPT will always be better, just because of the volume",r/machinelearning,Z0FBQUFBQm0yeGI2aXdlenhRMEpYS2xMRnlmanc4TEcyT2VsLVlaalY2d28xclFRZzJucWJDWGV3OVNhN0dubEQybi1fZFllN0Y2Qnduc0FUME1QRnBOc1NMMHVXbUNuQlE9PQ==
Encrypting something does not make it secure per se thats a common assumption. I didnt check the code but I can say thats a big claim most experts wouldnt make though.,r/machinelearning,Z0FBQUFBQm0yeGI2NFpjdDljVnc4MDYxNndEY0k3UzdDcE5LZjZTQWVXbmEyRDhEakxtQ05YQWJIZHNRMzFSUk5oYmtxTWNRVy1QNWJZWHdsRHlxTGpRcko2SWR1bXBXR3c9PQ==
if you have some reference images you can also try similarity matching by embedding any well-trained model.,r/machinelearning,Z0FBQUFBQm0yeGI2TzRZVF83dUl2ckozd2M4a1ZlQWNKZnk3VFZENFFMNDd1Q3RYTWhzYmFZT2kyWlp4N2xLVWJEcUM2NThVc3I2cExBRGQ3cDc0dGtfZERmWklfX1FMWUE9PQ==
"Thank you very much, it is a very good idea.",r/machinelearning,Z0FBQUFBQm0yeGI2Skp5YzIzVVlSRG5pek9UTTE2VW5yMkJwMTUzSkZOYzljNEdfNVlVLTBncnk1Q0U5UEUzUTJoOGphcjRXQkFVZklmTExMNmR6ZXBzcmo3ZU1mTkJKblE9PQ==
https://huggingface.co/dmlls/all-mpnet-base-v2-negation,r/machinelearning,Z0FBQUFBQm0yeGI2QmdXZEt6cTQtUzJUenIwS2pCYVN3MTVXUWR4Ni1aSGk3NGM1OEhxUWpFNWZ4b3ZHZnA2bmUzLWxLNjN4em94ZGlYTGtwY1JqSWR4cUdpMXJTRGxhV09QQTJHLVFRNWVZQUlnb2FfdlJScTg9
"It was fine tuned on a few different pre-trained models.

I think if we had a much larger labeled dataset for fine tuning, then our model might have performed better. But with less than 100k labeled samples, GPT was king",r/machinelearning,Z0FBQUFBQm0yeGI2MVduY1laYzJ4NlpGalp6b01XOER0blY4QUxTR0FoMTBaYlltNFR4bnp2VDRWWFJDaEFCQWxBVTN0eFBjMnhGclJQVHRJYVVOR0drVGk4YnRHTldfTEE9PQ==
"You are so funny, dude... In fact, for this task it is not so difficult to define an evaluation function, e.g.:

You train a (probably small) model on a small subset of data and then evaluate it.

This process can return a scalar which is the evaluation of the objective (it is the input of the eval function, and the dataset if fixed).

Edit: it is stated in the paper by the way.",r/machinelearning,Z0FBQUFBQm0yeGI2ejBPejYxNjN2S0hzRWN1Wm01TC1iLUtXOGdsQUM5bzI1cEt0LXhEOXk5OEJrRTVwdWI4SW96Ul9udldYYWFYNEw3TDlpZHA5T0YwNmpncEtXeDRkOVdOQjFzZEc4TFNwY2N4ZFhkbkZCdEU9
"+1 for Schrödinger bridge and more recent methods

I’ve found that CycleGAN can be a headache to optimize within my work and I usually end up using a model that is easier to train. After utilizing CycleGAN on multiple projects over the past 5 years and seeing other approaches train easier and perform better (even after significant parameter searches, data manipulation, etc.) I’m not so sure many people “get it to work” outside of the toy problems from the original paper.",r/machinelearning,Z0FBQUFBQm0yeGI2V0xiV0JtNXRfVXJuN3F2bHlpdHhsZzNZaFJIaHdZaVlucmlKTXFRUDhxT2tLZzI5blFMamQ2aGZHUG4wQXlNdWFtOEM3YXA0N1czRzctTXVmUFZoTlF2VnpKMUtfVEh2MUphTzZ2NEw3c2M9
Just because we can check it doesn't mean it's safe/secure. Absence of malicious code doesn't indicate absence of flaws.,r/machinelearning,Z0FBQUFBQm0yeGI2ay1PYjJmRUh6UG5kTE83ajhwUFZjeUlNZVpDVGpyMXZycWVfaTlvMTFGSEowamEtQWJ0R1lYMlNhWHhGWm5xU09oVjJ2WGpiQTJpTG5wNDdhY0VuUHc9PQ==
"> I’m now wondering if the multimodal foundation models like Gemini Flash might be able to do it. (Someone please say so if that’s a no.) 

That's a no. You won't be able to produce diarization timestamps of an audio with Gemini.",r/machinelearning,Z0FBQUFBQm0yeGI2Z1ZBV05HSjRDMlZURUtKRW1hX2VJYS1yM2VPUkFTQzVzRmhLWVRHRXFFV2Vla2xJQVNiNktvZmY1NlBMLWlaNGwxYTZFR29kb1VjZ1RqN2FkY0NYek9SVEp1b0N3cHQtN1Q1QlRxRFZGaXc9
"You make it sound that a preference optimization loss function is a harder object to create than a PyTorch LSTM, and I'm pretty sceptical on that. Say, how many lines of code the LSTM in question should be?

Edit: another notable thing missing in your comparison is whether you tried evolutionary-like algos or some other iterative techniques.",r/machinelearning,Z0FBQUFBQm0yeGI2Y3RUZzJJRi1pTDNMRy15M09fS1RVeWk5UG5TNk9DLVJLMHpFeEMyYWFYdGNRMjJpQk00SFNiMTFUdzJYRm9NZnk0WG42U0U5NUZwcjlSSGlUMHQzeDlBNjFLVzJvOUpsMlhBbVhwdTZxSjA9
"Hello everyone! I have a large dataset of time series and I want to create embeddings for these time series to use in more classical models, as I have a small amount of data for regression. What are the best ways to compress large time series data (approximately batch\\_size x 1000 x 12) down to 10-16 features? I have tried using the hidden state of an LSTM and got decent results, but I would like to improve them. Thank you all!",r/machinelearning,Z0FBQUFBQm0yeGI2anVEM05rT0dOcmZOWWwzeVFfRzFGeFpzaE1NeGVmaUsyTU1WOWNuakY2TGhYVnphcmhxaDRmVXZ2Y2ZUaEFHYV91MWx1ZWpDblc0YUVUajBGVmdmLUsxVzdGcDY3QWdRdlJsZWJVMzlFTXM9
"I guess my point is more that examples of my ask are _plentiful_ and I imagine they are everywhere in the training data. On top of that once I deviate from the norm and try to do anything slightly esoteric, it usually gets closer to “hot garbage.”

I’m not saying the tools aren’t useful though, they are, but I definitely find there is a sharp cliff when I’m trying to do anything beyond what someone who is learning this stuff for the first time would do.",r/machinelearning,Z0FBQUFBQm0yeGI2dEZMZVFaUmhwVmROajFhWmphcGs3OTlfUm8xdlNQbmxUSWZubEhIdDB2UGRkQXlTd3RPUnQyYlNVM3lUUG1JM01jczl1S3VTQnZoMU5EUV9YUV9iNGlwYjZmUkgxVmo0V0NYZkpndzk2QTg9
"Hey thanks for the feedback. Yes we do plan to open source for other languages as well.  
  
We have always planned to open-source our models from day one, particularly because open-source community lacks high-quality tts/vc models, and also because open-sourcing further accelerates research in the field.  
  
We'll open source our Translation system soon as well :)",r/machinelearning,Z0FBQUFBQm0yeGI2LWxtbFpsZVRxNDk3bDJTMGpDMTlqaHlhZ2hUaFZGSUd6aEJidE5nUG90VWEycGZ4YXgzMHRFU1pqNUVvV3ZkYThmbjlIOGo5akFMY1RrYVpZeWlXeEE9PQ==
"""We recreated the Torment Nexus from the classic sci-fi 'Don't Create the Torment Nexus'""

Op: ""That's horrifying! ... I made an open source Torment Nexus that is much more safe and secure.""",r/machinelearning,Z0FBQUFBQm0yeGI2UW41a2hSWTJkMElHdHhpbnRCTTR0Z0FhUWNRdDRvRENUUWx5VGQ3cjBoV3lkVHRiVzNBdWJfei01Qmc3WTRTYlFUdUgxUVZBTU9Jd1hVTnBMaW9ub0E9PQ==
"It depends on how much TBs and what kind of operations you want to run, if you have less than 10TB I would just write a multiprocessing/concurrent.futures Python script, spin a single AWS machine with a lot of cores and wait a few hours",r/machinelearning,Z0FBQUFBQm0yeGI2d25DUU5IdUxzdGdMelJSUVpRbXVHdWdIUWtFVWwxREVRY203TGxtRnZwak1OZEhyMnZnV09LUDI1ZHZfcUd0R0gzaC1tcElCOFZ2ci1pVmJMWEd0NEhzLS1QNVVrdS1fYXA1RVFjU3prWGM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2TEs3QjNVSi1YcUppYmZ6WHZMY0g1LTJpYTNXQ3VTTWczOV9pQnR1ZTZoRjd0cVJnMkpfNTh1Y011Rm1zQmo3S2JkNGYtWUZ0STA3MWtUY3F4b2tNWHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2Qm0zbFFIYWxtMHRTaXlFUFNiSDVwVXVZV1N1RFVlWmZzVlZmeGlSamhwdmZ5c1VMek5FYy1nWFdOdWtjQS1BQl9BOTZMd1NXeW5qNWVYck5aemY3bEE9PQ==
Are you familiar with Dask?,r/machinelearning,Z0FBQUFBQm0yeGI2QzFQOXVHU2xRekloTktkbG4wT1JfeEdKRFlPcUhmLW1IdU1TVnJ2eVRvU2EtN3ItTTRtSTZOXzNUdXU1a0VZUmJCblJvOVBFc2pYNWFXazNSbk1mRnpvUUFfOUl5bGc5QWZBTC1zaFpmN2c9
"If that is something you would like I can implement it. Ollama does not support tool call and vision, but I can add support to text. ",r/machinelearning,Z0FBQUFBQm0yeGI2eUljVEhWSWdMc2tXYXVmN1RuMHRkdnNUdkkzdTFYdjFEUmk2bHRILTZfY3BIbzVoSEFxX1BSTGVYNUplQnFhUUpZUU0xXzBlWlQ2aEJ5R0lHS0xGRk1ZVk5uMFBnUEVtT1BISVFXdGZ1SVU9
"I don't think the tech should be treated as a magic bullet even if it has seen plenty of examples of the task you try it in.

And I don't think if we stop treating it as a magic bullet, it'll cease to have any value at all. Basically, we should see it for what it is: a brittle, unreliable piece of tech that nevertheless knows quite a few tricks. The question is, how can we map these limited capabilities to our practical needs.

The most straightforward way is to know its limitations and not to try to force it generate a few hundreds lines of code all at once hoping this will work. The more difficult way is to find methods enhancing its capabilities and mitigating its drawbacks, to the maximum possible extent. Here multiple candidates samling, evolutionary optimization and iterative workflow are some of the examples.

Back to the paper in question, it proposes an LM-driven method  outperforming human-engineered objective designs. In broader terms, a meta-optimization method. The very frontier of LLM capabilities research, as of now. I mean, it still isn't a magic bullet but hardly deserves dismissing tone.",r/machinelearning,Z0FBQUFBQm0yeGI2dG9ueHpqTmdGbjgxTEJSX2ZTbnRNVGtwSF9aVzQ5aWRPVEthanRVbmZVZVZ4X1hYT3BpVzgwZWRhZkdTb0ZEXzF6Y2I5SHIxRWlDRjhxT2ZXbGpMenhpeWpsclJJbk9lRzFzX0RzbUxlU1U9
"I'm talking about the alpha scaling parameter we introduce in the output. Though it's mathematically equivalent to tuning weight norm at initialization, it's easier to implement and easier to see the effect of. In torch code, this is just a scaling parameter replacing the output \\`return output\\` with \\`return output\\*self.alpha\\` for some constant \\`self.alpha\\`. A large \\`alpha\\` encourages grokking. It's important to emphasize that grokking requires a number of factors to go right (the three we discuss in our paper), and doesn't occur in most settings (in most data regimes, architectures, etc). But when it *theoretically can occur* (which is rare), this alpha parameter can induce it.

Brief intuition for what scaling network output does: if \\`self.alpha\\` is large, the network can fit the data with the weights barely moving, so that the network at the end is well approximated by a first-order Taylor expansion around initial weights. By definition, this means the network is well approximated by some linear model (in its parameters), and this behavior of a network acting like its ""linearization"" is what ""lazy training"" is, since the power of neural networks is when they are *nonlinear* (in their parameters).",r/machinelearning,Z0FBQUFBQm0yeGI2eWhEbUlQV3FpX0lXTW9NZW51bVB4VWlkWGtUNEFfMGgtaHdsLVFiOXB0cndhV0tPOVItaXpZbnl5SnU2OWI2V2gwSFhkS0xTNkFfZ215Q1JZb1FZbGc9PQ==
"everyone: we are horrified they have a gun at us

him: hmm i could make a gun",r/machinelearning,Z0FBQUFBQm0yeGI2ekM1RDRfWlJaSkVQcFdiNlVXa1gwOUJ5SUNPbnRFTXZxT3JXazdyLS1jbHk5ekt2NEx1RjN1UEt3a2owSXdydm5ITzZyZDlzblI3RVpKSG5SUzBJa0E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2WUtrMkw1SmdOOWJqMzRtay1WTmNkcGUzaUdGX3NxQTE2a1NmZm0tWE8wZEpzbWZBMW02VUE2LTlhRHdSNHMyOThsbVJobjRRYy1kREdING1sQkVmUUE9PQ==
"I just added support to Ollama: https://github.com/piEsposito/tiny-ai-client/commit/04822a4b6fe657cdfe688218d69bd58ae7f6bc76. If you find any issues, please lmk and I will fix them asap.

Edit: corrected commit url.",r/machinelearning,Z0FBQUFBQm0yeGI2dkJYMXV5Qkx1Y2w2Vi1ZdDJsS1JwaGQ2bDMzY05DUDNKOUZsWUs4R3FQaVEwbEhsN2Z0SjZJRmRQQ0xtT2UtME9nSTBoeUhZcDdFaUp4MUFrWFZ5cTlBSE1nNklvVWdicXJPdkIxNFFLQzQ9
I never understood what all the hype was with langchain.. I found it easier to build everything myself from scratch than use it. Its so frustratinggg.,r/machinelearning,Z0FBQUFBQm0yeGI2Qk1iSW1SVVlqTWt2OHQwNUNuVFI5SFVpMy05SnhiR1RaU01CVXR4bHp4cGJkaTV3Ulo4QU1EamJGZXJvMGRqMDVCSTlKQTJTbTVRbE5zanRjazU3bEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2U0tJeVgxWjdVRlFXLXJBdnlMVTJqVnNXdWNKN3ZJRndYeXZkWHN1MzZ2cldKV21zMzU1YjdRcVlMNEI2MWNUTW1ZYm94dWZxNDdZRllDX0NqdWloLVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SWhEMjcyYV9SamFUcnFSYnN3dXc1dlRlU0ZsaFRNS05qUy1WV3JDYndsSHNraUNLbWljeFFodEVUTGJ4NVJnWTFLYy1VTWRXUG0yQ3hBb0FPZW96bGc9PQ==
"I mean when they were abstracting complex prompting patterns I thought there was some value, but now that we can do tool use even outside OpenAI I don’t see much value on it. ",r/machinelearning,Z0FBQUFBQm0yeGI2WktwZ1B2amRsRTRHeXBtNHN4UEw5akFrOVNqTXE3aFowRklMbDdTWkNvSXdWNkF0amRyN21kWlJiZTI3bEc3WWVFVjB2VGNtTzBBOElJbVc2RmsySjVWVlRGM0R6YUZyWUJSeUJwQk9zLTA9
Unrelated but what is the SOTA for image to image translation? CycleGAN to me was the first model to make this work.,r/machinelearning,Z0FBQUFBQm0yeGI2dklPa3VFdWhJT3BvLVZBOWhILWwzVzdhaUNaSWdJekdqUXNNcFFRdkx1aTN6VVNEdVhocmVzUU1SR0tHTGxzV1daNVpna3poNjJZUnZycmFNWWJ0c2c9PQ==
"When you are dealing with that amount of data, keep the OS EBS volume and the volume for the data separate, or mount the S3 if you only need to read it once, as downsizing a volume is very troublesome and EBS is expensive.",r/machinelearning,Z0FBQUFBQm0yeGI2cE52R2JfWXpOLWozOW9uYW9GT2ZrUnZzZ1NrSEtVd0ozUWtENmJyckRCUFF0MGUzalpTQ3Q3RzRQTDVVX3hETXdMeUVNQmFZOVZyTXl6Q1llUkREOEE9PQ==
A smooth objective function is preferable,r/machinelearning,Z0FBQUFBQm0yeGI2aUh4ZmtySWV3Tnhrc1dwRHVtZlp4WVZCc19qT0Q3WDRsejZjUGp3MnFTT2pHZjJiVjUyTXN0T21FdzhxVG55cENySll1Zm9qRFplZnRHZWY0STZrTFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2eE14TUVJd3pwdExNM292X2dkUThObG1jZUhGX2FzR3JsRFp4SGhDeENOUmVfOVJFcUtMQW9CcDNsTXJsRkhTLTc2ZmVNNXpBRnExYTJZdXFxRjZ2dkE9PQ==
I would be interested as well.  Maybe there are applications to other areas,r/machinelearning,Z0FBQUFBQm0yeGI2dmRsYzItQlJ5dnhYcXhBOW1US1JXUkxmWWxSb1Y3WFBObkJjcm1NNlZYTWNNTVc3VFVCV1lHSTlqVEZXUnJGd3pWMGZVNDV1SVg3aWQyWjV1S29DYWc9PQ==
Will look at Schrödinger bridge.  Any other methods you can recommend?,r/machinelearning,Z0FBQUFBQm0yeGI2MUpKc3NyM2hZanBWZkxzc0JiTHhOdTJIZVZwQzlXS21JNHBQV3FUaGl4MHV3QUU0d2xSVE9la0RtdkhsclRSUEZkOEhObGRtUG1WblpOUlBaNXpoZlE9PQ==
Could you specify in which function/method do you modify the line \\`return output\\`? Maybe show a relevant code snippet?,r/machinelearning,Z0FBQUFBQm0yeGI2Mzl2TGZDMEY1bDhzdXJGNFlseEpNN2JEcmt2SE1kd1YtUmZ2bkpWS01YdGJpZHRGTzN4aHdnNnotbUdVQmhKQ0Y0cGpVODl0YW9jR2NVTTh5WVRtdkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2WlZLN2M0SnZ4c1pMX2dCSzlRNHlZTUs5MUxKUzVseHpHbEJMdmpEVkQtM3p0QkpyTEZZY3FOQ2ltc2x2UHZ1ZEZzR3NGT2lpVmhfLUl5aFVaVzI5Z0E9PQ==
"The forward pass of your model (torch module). Again, this is not a silver bullet to induce grokking in any setting, as it will only induce/ablate grokking when grokking is theoretically possible for your particular task-model-data setting.",r/machinelearning,Z0FBQUFBQm0yeGI2QXp3NXZjV3hUeXhvV1pvanltYlFKbjY0SkZhRjI0MXR4dk9mN3lvaV9DNWQtUG9hSk5vSWpENE9XclU5SW9TdHhHMXJ1RzBRbkxsVlp3TnZXTFdlVkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2N0h6NFFqTXNNR3ZJYXRwckozUks3dldYSi1zUTg2eG40cU43OVFtWHI4RG44aGQwdVM3VGtzRVl2dWJhYXp4S0NubnFFR09aMU1Ha3VOaXJyTUZFeFE9PQ==
"From my experience, LLMs usually do good with combining concepts but poorly with logic. Challenging programming is complex logic and ""common sense"", and applied math is a lot of combining concepts. I find instruct LLMs very useful in suggesting ideas and general algorithmic frameworks, but I always have to fix their mathematical understanding.

For example, it would potentially argue that the data is IID on a RL setup without a replay buffer. So my impression is that it still requires a lot of expertise but it has some good ""intuition"", similar to a talented student without enough eye for detail yet. I would not expect it to come up with novel elegant algorithms, though, just novel combinations.",r/machinelearning,Z0FBQUFBQm0yeGI2S3ZoWHd3dktmVFRqUFI4RGVYaDJJbWVvT0tyOUJPUUtFQnRPMGNmU1BvS1hjcDk2eVZuQUNDdFRicDMxZ3doUGozMmxtLUptUEk2SGtuaE5mMUcyU19JLXNobTY0aFBOOWhUZWNKdnVpMFE9
"> I would not expect it to come up with novel elegant algorithms, though, just novel combinations.

That's more optimistic than me. Then again, I'm probably unfairly extrapolating. Not too long ago, even GPT-4 would get Black-Scholes model wrong and there's no way it doesn't appear thousands of times in the training data.

Then again, it's not like I know where it was going wrong. If fine-tuning data didn't call for complex equations at all, then it would make much sense that it hobbles together facts with hallucinations.",r/machinelearning,Z0FBQUFBQm0yeGI2TVJabEZCcEp2dkt6bVJOZHNYSm80cVJDNUtvRXo4N1o2bVpuY3FXZXVVX21xU3F5MUdmdk5VeG01amYxejJqR2dsQldxNXh1NTJKZU1NU0ZJMkVWNFE9PQ==
"\\`forward\\` method usually returns loss or logits but it maybe something else. What are you multiplying by \\\\alpha? I assume you don't just scale the loss numerical value... Care to share a code snippet, if possible?",r/machinelearning,Z0FBQUFBQm0yeGI2d0Z1NGxxZUNyMXByblNzMllvMF9zUnVjS3dHOWZ3YnlNTjVSa0NPZTdHemdfUnhFMV9ZMXN0RWVBRWpKUGFYSk5RcnRWMldNTVc5MDBndWpuMERTekE9PQ==
I also kinda wanted to do this on Linux with [ollama](https://github.com/ollama/ollama) for local or remote-self-hosted processing,r/machinelearning,Z0FBQUFBQm0yeGI2OG1sM1dZQ3Z2Z3ZOeXNUV3pZWndleFA4T2ptdkhtLUZ3UXljdWN4RkY3S05iUFZGbmVuckx0RW04WlgwRXB1bXZSTlE0bk9RNTEzaUoyTU1ZV3V1OXc9PQ==
"Presumably the same bottleneck that's preventing you from doing it.  Making a website, no problem.  Understanding the human and cultural ocean you have to navigate, especially considering if you can do it everyone else can to, to find something  people truly want.  That's more than AGI, and if you have it it's better to use it to play the stock market.",r/machinelearning,Z0FBQUFBQm0yeGI2WG1pclpWRHVob2JiUDVrYmRWV2RXMGFpc2syX0stQ1JZVWNnSXUzdkYzUzI5VmctaUx3bEM3V3Uyc3dmZi1KX3BMOWlQVXZ5UmtuVTd5ZFJvSUJyRlJNNjJ4N1JGU2dzMzYxWnNpQlg4M1U9
"This is what Microsoft's new copilot would be trained to do, however all of your data would be in Microsoft's hands. Then when they start launching small agent clusters to copy your idea, what are you gonna do? ",r/machinelearning,Z0FBQUFBQm0yeGI2SkNIaHU5LUROQUxMU2c3VF9xU1FGWFFZYmF0aUVKOE95dFRJN0UxSmJiQ2dWNkNYVVAtaGdjSmxhRkdrSy1kUUVCOURjZVUtc3lITXNPUmhISnl1MTBQQzdienNmTFFnU1BSNTN3M1FqMkU9
"Hello! I’m working in a project to classify phenotypes. I have a dataset of about 30,000 unique rows and am working on increasing the accuracy of the model. I can get to .8854 but I’d love to get to .9 if possible without totally reworking the features. I’m using a sequential model with Keras and tensorflow. I was wondering if anyone would be willing to chat with me about the project briefly. I’m new to ML and software engineering in general (though I am a product designer so I’m familiar with the space) and I find I process better with conversations. Feel free to DM me if this sounds interesting to you! Thanks in advance!!",r/machinelearning,Z0FBQUFBQm0yeGI2TzhMQVBQQVp3ckJUWG9pcV9wWW0zRDVBWUdQUkxKNlBCUXBXenIzMThmMEN2SDFRTU5QbkczaHc5T25Tbmw3Zkd3cEJuSzZETXB6VXp1anNWVnMxWnc9PQ==
Could you specify which regularization methods you've used?,r/machinelearning,Z0FBQUFBQm0yeGI2V29nNm9CY1F0RHZqZHM1Q29lejh0TGhlNmx6a1ctRVNyUTlWYmp4eVM1TkhGLXlJT3lXcWF1eV83ZURUdDFJQkFYRkRsMzl6R2NUME1IRzkwc1JBLWc9PQ==
saw a paper recently that suggested one effective approach is to just use a small batch size,r/machinelearning,Z0FBQUFBQm0yeGI2SGxIUmhTejVTUXRuMDVmT1o2NWRsNndvcE5tdWJrMnRiOHVocWFMUDFWVHpjMnhjc0hNYjg0dTFNRlkxRHBFWU14YnQ3R0NxcG4wWTFOSE4xOHh2Rmc9PQ==
"That problem is exactly what a 'lack of derivative' means.

You said that's not it and then explained exactly the problem of not having a derivative.",r/machinelearning,Z0FBQUFBQm0yeGI2ZlhGOWdtTzFjejRCU09MejlBTEZvcFRoOFIwSjRNUnVPelJxeThPcEtRMDYtN2x4ekg4OFU3R3pZS3J2cEdPMzZ6RTRXQ001dzk2TWk5eEdYMXpDTkE9PQ==
Nice work. Thanks for sharing.,r/machinelearning,Z0FBQUFBQm0yeGI2YUEwbFVGRmdzWkRVa1VZWlNQcGgzOTJGdjVYaHpmdFdYc3o5UkwyWTUxTjh2bnZJclhtMFJkMEUtVG9SRC1CMEpGckY4VUFqMmZ1RkxOUmRwUUVpMEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2Q1BHcnNxZVZNYkZXTVV3NHliaW9BNjF5MEN3V2VOZlJ3X2N6QjFGdEtfaDlYd0dreXdfamc1bGZMQk1PMWtuTUxHR0FjdnRZcGNfOXF5SFNpRDhGTWc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2dVNwOXBlXzZNRGNIVGVOM0haS2lIckc3eTZqSk5iZVlWMWFWMC05djUzYS1JeXpYY1g1YTlJOTR1ZENnRnNGN0xMcHZVQmZ0TlZ6MGI5REsxNEZtdWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2YmhfZ3JuYjdLdmtIdlctS2xmd3d3VV9zR3ZHaENmTlc1NnFKejJwYzNmMXloQnR1eTBRbkxkNU11WkY4dUJ0cDM5MmdWVVYyWGs0bGRXanhyUjRGaEE9PQ==
Thank you! If you find any bugs or need any feature for your use case please lmk and I will do my best to help. ,r/machinelearning,Z0FBQUFBQm0yeGI2eXZySzlrU0xnQTVKRlRuejhnSnpLSjBVUWlsM2FUaGR5cHdueEpKclV6UnRHYVUxUWRIOTBEZG1QbzZnRTQxYUM0Q280d0MwVDRzUl82b1dtdG5sOEFjd21kLUNnTkVUUUZ5VjRPdWxPaGs9
"Not really.  
  
Let me explain: you could smooth the loss by using sqrt((prediction-label)\\^2+eps), where eps=1e-8. This loss has a derivative everywhere, but it should be intuitive that the problem is essentially as hard as before, because the function did not really change. This points out that the problem is not the lack of derivative, but how ""smooth"" is the function.  
  
More precisely, the smoothness depends on the Lipschitz constant of the derivative. If the Lipschitz constant of the derivative is infinite (as for the absolute loss), the function is hard to be optimized. However, if the Lipschitz constant is not infinite but really big, the function is still really hard, even if it has gradients everywhere! Instead, if the derivative has a small Lipschitz constant it will be easy to optimize it. In fact, one can easily show that the convergence rate will go from ""slow"" to ""fast"" depending on the Lipschitz constant.",r/machinelearning,Z0FBQUFBQm0yeGI2VkNnckVaZ0VhY21NNW5YdlhyTnhDX2lWMGgzVE5rOU5PeFJpWHdhWjl5cFRXekoya3lGOTdaRnZuTGZnTnVicmRrRkpQWUZMS3dQVHY1TWF6NTFUclE9PQ==
"That's my point.  Making the things is easy and cheap,  making successful ones that people pay for is the hard part.  But even humans (who are more than capable of making the thing) struggle to do that.",r/machinelearning,Z0FBQUFBQm0yeGI2V0FlTEFaY01ibnJUNDhGMlhBNUZJSXpXNmFCYk5WTEtLdmR4SGpsOXpqTkxwRjRNNmNQeER1OWlsLTYtdWVZVWJISDM2X2Z4ZkpqUzI3WWJVZkwtakMxd2lLbmt1U3UxdFRBLUtUdVJ3VHc9
Working correctly,r/machinelearning,Z0FBQUFBQm0yeGI2anZnekNCRXo0dEk1d2pLR1VwWHNXWWFYZFprbkJNY255NWtrbUQwTVpPZFRkb2NfeU9sNjJabHY0ZlBRTi1nYXNQWWEteHFyUFdLc0xwQUtIWUNyY1E9PQ==
"Right, thanks.",r/machinelearning,Z0FBQUFBQm0yeGI2ZmpSSzE3MHJKY0g1dTEwREdUbDhuZ3J1STl3S1BVYzNRUURwZ2FXR24wM0hfOU9jWVJxVUxNdXRTUW03OXBHUGRRQU9tbGJ6OGNnWjRrLWVtZFFBQnc9PQ==
"Awesome, I can now delete the keyloggers off all my friends computers and start using this.",r/machinelearning,Z0FBQUFBQm0yeGI2cV9adWVxVkc5c1A3SkRXR1Bmck5QQUR1NHUxSXQ0VXpXODkxYXRhQ21iQVV4alhTYkVwT0FoYi1kMlpyMEdpekV3am1tTmRPN1FFeE1oaXNrTE1xLUE9PQ==
"I was keeping it simple. Minimally, I would argue that even an old school GA is more suited to this task.

But, I am also aware of the concept of emergent properties. In something as massive as modern LLMs there are going to be emergent properties which are interesting.

LLMs are best when there is a vocabulary and a grammar. For example, DNA making proteins. But it is at its best learning from a corpus.

Does AI have a text and grammar corpus?

My long experience in tech (decades) suggests that LLMs are cool, AI is cool, there appears to be a relationship between the two, so investors are willing to throw money into the newest AI goldrush.",r/machinelearning,Z0FBQUFBQm0yeGI2VlNQb3BGOG9ESktyRDBXbWg4eDJfamVKckt1cF93UHpsVVktSnhjNXlBWURLOUtHeHdnTEpRSEdRckhjbFBRQzltUmFOMFM3anZaVHcxcVZ6YVhfN3c9PQ==
This is the most elegant response,r/machinelearning,Z0FBQUFBQm0yeGI2Y25yYkx0cVItNWlzTGdhMFA1RFZrbHY5OXpuLW01MkVtemhTMk5NTlpPZ0xUODFMSDNIQVRzQjZmWEhvZk9NOHNNQlM0cXd4RzBjVHZIaVVERGQ2M0E9PQ==
"Hello. Im trying to train a GCN on a dummy task to predict a float result. Essentially, I have a graph which has edge weights (between 0 and 1) node values (0 to 1000) and I want to predict the value that is calculated from doing the sum of the neighbours, weighted by the edge plus node 1s value. Ive been training a GCN and an MLP and even though the MLP doesn't have edge information, its doing better. I think I might be doing something wrong, or maybe this task isnt adequate? Thank you",r/machinelearning,Z0FBQUFBQm0yeGI2WHZzS3AzUC0zVGhBWEhLSnc4Z0N2U3lCSW9qQ1JUOEotWUoxaEFoQ2lTUThVcUVwNlZXTWZJanRmWVJwNFF2WUxZM2c4ak1RbGREYlVXdkNuWGRWbHc9PQ==
Amazing 👏👏👏,r/machinelearning,Z0FBQUFBQm0yeGI2VFA1d0JTNzlTWkN5blF2VkpVYTlOX1VOQ25yVzVxOTFBdGdjdXBMeU40SWJOLU5iMllzTnhVZGtkb2VENFNYZ0gwNTBuMVVLb0tHMTEzZWxnWnpoa2c9PQ==
"Have you maybe misunderstood what cheap means here? I think there may be a difference between the cheap you are referring to (in terms of human work hours) and the cost for model throughout (in terms of tokens per second). Apps and stuff are cheap for humans to build, I would argue less so for current language models. Especially if you wanted to deploy a cluster of peers like with autoGPT.",r/machinelearning,Z0FBQUFBQm0yeGI2NlBUY2U3RVNLYUQ1dHh1aWN4bnVMdHpwenprbUJoV2JtZTVMaEVYdWg2bTdCYXZHU0xpenNibll1bjFaN2xOWHFoWGtTZUxVWDc5QnJ2ZFJmY01BTFE9PQ==
"Just a side note, nothing against the product: why do all websites of tech startups look the same and use same buzzwords? :D",r/machinelearning,Z0FBQUFBQm0yeGI2MEJjMV9rWnhaWEJMMjFsR1I2MC1KUDVqRVhoNDNHaXp1REVIdmNOYk5vTDNnOXNHaS10X2FlTmNTR3kzSG1xRmp3VjNLQ3l3RXZ5UlFraTNXWVhBUlE9PQ==
Hey. Sry for the late reply. I was just making sure that the entropy of the output doesn't collapse. CELoss - alpha* entropy of outputs,r/machinelearning,Z0FBQUFBQm0yeGI2R280OU5lSnhjZ3AxOEVlN0QtazRlZUI3VEc1aHZzbTZGM2pWOEV2MFROc0NUNGxyODczQmp6N1JMU2Nwd1hPSXd0c3Uxa3RYY0NEbnpaVml3VFN2Q2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2UUVSemwtVjBXOXVBZkQ4R243QWxzMldfbEZyNTZjcDRtcW9WM1F3UTBpNVRVSi13UWpQV2NRa01ReUpKYnViOV9jdlNHc3F4clpxMHhNZjdabnhIdWc9PQ==
"Forgot to mention in the post. My personal opinion: wandb is great but its difficult to work together as a team, especially when remote. We found ourself using slack + notion constantly to keep track of things and it just got out of hand.

Furthermore there is no way to ""take action"". i.e you see some results, and you decide you want to make a jira ticket for it, it has to be done manually.

Is this not a big enough issue for other people? Just curious",r/machinelearning,Z0FBQUFBQm0yeGI2N19JUWM2ODhtMmJyV05JcjRiX3g0dzNod1ZLTmtxUDFrT1c5bzJDS1VITFVWb1c4dWp3M3ktVVAzX1VoSnF5RHphRjlidWRTSjdOOVhPU2llMW1YRmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2bU4ya2gtUkQyTkVpaWhGOGJ0eTdCN0FRSDlMTTFQSHlESGJTZGlLczY2WHZxSGl5NnUtN1paYVBfcGVSdnhESUtkYU52VndkME9TMVRJM3VkekFJa1E9PQ==
"Yeah, I guess it can vary a lot. This discussion is a bit intractable if we try to do it in a serious way :)",r/machinelearning,Z0FBQUFBQm0yeGI2dlBZV295YnhLOEZnSWNwQ09DcHJOUWdpd3N2TkFNTDNWa2xXc0lPQmxETFJoVlFwTWRMOGgwMk9uRFVGYkQ4X1JwSHZqSHdmYzJ3dXR3RlNYMUlCX0d6UWFKQ0lsZlZRMkZxVV9DX3g1c009
I promise that it is secure as long as no hackers get in!,r/machinelearning,Z0FBQUFBQm0yeGI2elhnZG1IcGtvdTI4aWZ2MkFpMmJlaEl1NGl6M2gwUktKZmtWU3Z5aXh3NDN2Rl9UamRBZFdmYmFHYW1PNFNUMnNONG9OYVFzcFBkX1JFQVpqZEZ5Nmc9PQ==
"LOL, it's not that I disagree with the opinion regarding the hype, I just comment with respect to the paper, which is reasonable IMHO. I am even not sure if I agree with the concept of emergent properties, a recent best paper in NEURIPS was extremely convincing ( [https://arxiv.org/pdf/2304.15004](https://arxiv.org/pdf/2304.15004) ).",r/machinelearning,Z0FBQUFBQm0yeGI2UDVURlAwMmt1QW16d0VFWElibXJILUtDeUY3Ql9HUWJ1Skowck0tUzVIUC00Z1hLNHpVaEx1UUxiT0FESFhiNGRRemM0YmZ6ek9GYTNMeEZoUkE3YjAyUFc5VVRVV2lXb2FGSXEyVGY1bVE9
Possibly star-gan.,r/machinelearning,Z0FBQUFBQm0yeGI2TFQxSWJlczY4WHVwXzltSXNEZ1oxSXl1aDdmM3ZGeTg1WVR1Y3JWcjVDV1dvdXBoQmlsNkx4eVg5c3VMdV9OZi1YYllsQk1xRmZUQXZpX3ZkRURMWmc9PQ==
Do you have a source or link for that regularization technique? Never seen it before and it sounds interesting.,r/machinelearning,Z0FBQUFBQm0yeGI2YkFERmJmWXZ0VDg5R0cydHFnNEM0SDhWZnJ1MlpoOFM1MVRwMUVOaFp6SHBlcW5jTUdwb0YxajRVdEFITURkNTZDamI0SkpHLVAzY1FiWnV3dXNfY0FfT3MzWWZYdFdmclcxMFNLcFVneXM9
Have you tried oversampling the minority classes or using class weights?,r/machinelearning,Z0FBQUFBQm0yeGI2TzZvVm5xVE5yLUpZY3Nfb19Ubjl1NE5hSVFYZGJFRWE2M2xIWHl3THBxOEYteWJxOUtPTHd4QUFxNk1pbGp6MEpLZk1qUDVwZHJTaWlhbzdLaVB6UV9pb3l1VlN6SEY1eW1QTzJOVmgwX0k9
Don't forget to monitor val loss and utilize techniques like early stopping.,r/machinelearning,Z0FBQUFBQm0yeGI2LS1oX2VJZ2t0bF95OGZBdjI2MHJnRHhrdjhmMWJFUWJSQzBnTWlBVzhFWlRKOERyaFEtZmE1dkFwLS1DSU1FaXp4TlcwTHNPS1Nidm9pOUFkbVZfbUw4ZjFWTEMwdUJmZjZndEppd2ROY3c9
"For unpaired image-to-image translation, possibly contrastive unpaired translation (CUT) as well",r/machinelearning,Z0FBQUFBQm0yeGI2aW9mMmVMUDBOYmp2Zlo2amJwTUpMc3RLdHJXNUlUNzBGTmNyX1M3RzNRV1QtSHhFOUhISUlhNnJpRUVQamZpU01TUE1hLUNuekwwakR3VHd2dndMY0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2RWg4eUFaTlp2V2NDUTlQaGZDMGVjNnpYZU91bFNmNlFXanZUOUNPWXA3czVXb1JMNTBxQ0Y4SjhMVnlaaDFBWlR4VWpIM2NNekNuTU9qd1hubEstakE9PQ==
"About the PhDs for AI/ML in biotech/computational biology, what would the starting salary range be? At SF/Boston, other HCOL cities.",r/machinelearning,Z0FBQUFBQm0yeGI2WTNrcDVvemZoOEROSVM5TUFLWnJBTTFabWdhWms4QkFsR0dRRDM1UGMzWVhtRDJ4cjVPR3d1TXJVcVFvU0J0ZnhGWHE5QWItYjk4V3lmV2Itc2I2UGc9PQ==
"Just a couple suggestions from ChatGPT:

  
**Resampling Techniques:**",r/machinelearning,Z0FBQUFBQm0yeGI2OWRGcGZqSnZUSVZzaGZlWXBKTzFicTlsQlN2TDB4LXhlX3NEdWpxQXotUF9yNnIyY0NzQkRUanJtb24xb0ZlVjBFeVpiYUJHTFNPUjlhY0ZBcEp0bHc9PQ==
"Great to hear that, now maybe you could contribute to this project Insted and make it better.",r/machinelearning,Z0FBQUFBQm0yeGI2VU9rTU9wd3FJbnVYQVlpeEJ5TDBvUC1aeWhraW05Mi1KZ0dJTlNPd3B1TF9KUWlTanBvNmxMb0tzZVdqdGlwbzNRNjFHekdQY3ZtYmVwVVlIREc2aFE9PQ==
"Link to the abstract, not the pdf. How hard can it be?",r/machinelearning,Z0FBQUFBQm0yeGI2bk03akhoVkw1WlN5OTlHYWdpcWJmVXRxQ0FyNVFPUHFlcnRvQzl1MG1ScmEwY1dyeDg3NXExSXo0VWFadHdFbklENjdiZVgwOEdHOGRFOGkwNExMWUE9PQ==
"normalize, standardize, remove outliers, etc",r/machinelearning,Z0FBQUFBQm0yeGI2YzJuZjV6cVdZRkZTRlEtYU0tNXRwaWtabzBVdVpkOHIyRjJkZ3NzR05GTVViM05wMmhONHZyVFhMamprOUUwdlhOV2FhT2dyT3B5XzJzbUluZlRXQ1E9PQ==
"I take a strong stance on the issue of class imbalance ;-) as I'm sure this will come up in some answers: avoid the temptation of over/under sampling. It's voodoo science that causes more harms than good and may lead, among other things, to having to retrain the model over and over again. The harm these approaches cause are perhaps better documented in the medical field which may explain why it unfortunately remains a popular approach in ML.  
  
See:  
[Understanding random resampling techniques for class imbalance correction and their consequences on calibration and discrimination of clinical risk prediction models - ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S1532046424000844)

[\\[2202.09101\\] The harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression (arxiv.org)](https://arxiv.org/abs/2202.09101)",r/machinelearning,Z0FBQUFBQm0yeGI2c05RdFA1a181elloT0tEcXlfZ3lCRWM0Z0RBM2s2dVVwcGtNZnhKR2htRmdMNlFVcEFUOUctMGIxa0tlcWVzT0RFRUQ5Z3MzLTBDaHE0ZmFoOHFUcEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2VjNra2tQZnhtQ05QOUtIUXJRRV9DSU5mamRGVDFEcTBRMFF6QjlmbmNNY2EtYVVYM3ZXWnYzSE5ObjJHOWtkZ3gzcXVWZ2FRTkJBcXpIa2JjZTJrbWc9PQ==
You’re not getting it.,r/machinelearning,Z0FBQUFBQm0yeGI2bFZ4X1hZYUFnUFlNREt0N1poMzdYZTVURHdyblFiMkFXQTJWb2VZcS02SDltV3dkeFZnZ2pQczNFbi0wOWVoQVZad1gybl9VUkN6UmVkWmlfekdnUlE9PQ==
Add a constant so that all are positive and then log?,r/machinelearning,Z0FBQUFBQm0yeGI2d1ZXLTdURm9ENUcwZmw3SFQzQVFtVVhCM05fbHlSYS1GQm9qTGNuOTBuYTIyc2Vmd3JrNmJlV2hjV3ZxUldZWURQUndWeU5fZGlQbG94R01zaHQ2RlE9PQ==
Naa I do get what he meant. But it's just a project I wanted to use. I don't trust Microsoft so I made my own implementation which is more privacy focused and then I opensourced and shared it so that every one in the community who wants to use it can use it.,r/machinelearning,Z0FBQUFBQm0yeGI2clVFWEotQk5uTVFhU19tTVM0RUZCbEhGdndhdHozS1pDU2ZkbDcxc3dpUFVidXpnX1ptTE5JWTMxRi1nRTU1U2JxX0lhZXdPQTlPczNqOFBXWlAyTnc9PQ==
If you get it then why are you surprised / arguing with people?,r/machinelearning,Z0FBQUFBQm0yeGI2WHpSd19NYWtWTFMtTHRvVENta216dDdaMlRaTW0zLTNZa3BiSnd1OEh2dlpSNFFVZng3UTZGNUZpbUo2MDY5UXF5UnlteS1ZbWdySE5oNS1nSjg1Z2c9PQ==
min max normalization,r/machinelearning,Z0FBQUFBQm0yeGI2VnFJQnBmSUc4SkljRmFaYUhfUzRtN0ZxOUhXSlBDVlk0c1ltUmt4NXZvSjZvTjFZWmNKc0tacklNcXh3a25QNk43MWRJdTNqRW5GTXV4NVRiM1l2VXc9PQ==
"I think in UI/UX you have trends as you can see in fashion industry. So you can get major colors applied (blue, violet, black) and frames of website with explanation of the products, features, etc...  
However, I hope it's not too sad for you ;D",r/machinelearning,Z0FBQUFBQm0yeGI2eDZTQ1VOWGQwWXdCYXBHaXVNb24tTDN0b09Vbl9qaWZXeE9FX1Z5aXh6M0EtYTROQ1REMkk2d0piaWF4bmdLRHNRY1JsTVc1eFdCVXBBNjBpNHU3QkE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2RTFaUWtMeUwxeWVXLTVTWS1wU1ZMZ2FpUlUwQ1NYMWg0SDFVbmtFMHJ6ZWlMX0dfcDZtd1JzTUR6d0hlOHItUml2ZTY1YUc5aHotaE1XUkN1RFJqaWc9PQ==
"EDIT misread the question. if it is just about large scale, not about also needing accuracy at smaller scales, discard this and go with normalisation and standardisation, which will work perfectly. 

for anyone interested in the case of data spread over different orders of magnitude (like for example from 1e-2 to 1e4): 

i had this problem in my master thesis. managed to solve it very practically by not imposing the loss (y\\_pred - y)\\^2, but instead scaling it by the label magnitude: ((y\\_pred - y) / (eps + |y|))\\^2. Roughly speaking this penalises relative error instead of absolute error, and will give you good relative accuracy, at all scales (YMMV for more complex models, did this with a simple MLP, 3x128 hidden layers, softplus activation). eps is a small constant, roughly speaking everything below eps will be penalised

from a bayesian perspective this can be interpreted as specifying different observation noise scales, saying that you're much more certain about the tiny labels than the huge ones (in absolute terms) which almost always is the case if your data is spread out like this.

normalising & standardising will not work if your data spans 6 orders of magnitude. The error at the smallest label will be about the same absolute size as the error for the largest label, which for any practical model (i.e. not completely overkill) is way too high.",r/machinelearning,Z0FBQUFBQm0yeGI2al9FWEJUUVAtSUF6MFFKcUFBd1ZMUFI0RHJUelFnWVgxbEVXbWpfdE5CdDhvTkJNUUpKenZEdHJmTXltdFdfazJxUEpJMXhtSDFPQTdPYm14Y09TUVE9PQ==
I'm gonna build my own langchain with blackjack and hookers,r/machinelearning,Z0FBQUFBQm0yeGI2bkl1REpLeDJYNW1lSXVWdnNaN2VWRVRvWlJFbl82U0xKMUdkV0lHckc1SVRTYXdsWUoyUlJLMWgtbHd1UEJZdzhWc2xLaFh0WGhMLXRDS1JnR29xcUE9PQ==
What's wandb?,r/machinelearning,Z0FBQUFBQm0yeGI2VmFOdUxWSkFnOGptdHdDM2RIVW43WWhJTVM1bzJOSVJseUlVMEc4Qlc1MTVETkJfRW0zTG1UNmZaRkhldVZnTUlKTkhud0Q1UEpQWW9lel92eHYtUnFNQU9say1SeW1BMXNHZkxvdkNITHc9
Weights and Biases. A MLOps platform. [wandb.ai](http://wandb.ai),r/machinelearning,Z0FBQUFBQm0yeGI2d2dQZVRFbWxLN2RHNmZEMG9QNXRQc256aGdwd1FZSnFrUkN1M3BkR1E4OXRrYkJnaEZFd21iX3lmNU5RVFAxVC1YN1h4TWl1V3kyZEppd0tBZ1Frd1E9PQ==
That's probably Mamba / RWKV / xLSTM.,r/machinelearning,Z0FBQUFBQm0yeGI2UjJlLURpSHk4dXF1U2hVdmpFaVZqb09BTzRwVVNpN3hvTjFIX1VFa3Nobmg5ZE5LZml3bWx4U18tc3BaSWd6MFk1YlhRcnNqeW5yZTdZTDcza0NKOWc9PQ==
"Depends on what the scale means. If the difference between 1000 and 500 less important than the difference between 0 and 500, do a sigmoid transform like tanh, otherwise just standardize.",r/machinelearning,Z0FBQUFBQm0yeGI2TEY2eWZ6cExfeVJ6aF9oeThFMWpnLWVaM0tVanJpMW5UMWNkV3JHX01FeGwtaVZ4MUlqYUlwUDhDSEw5bGlxcmxQTlM1bmFkY3dVTmdBS0Jyck55aVE9PQ==
Keywords: Retrieval Augmented Generation,r/machinelearning,Z0FBQUFBQm0yeGI2cm1lSVF0NTFKSWdHenh2WFp0YjJOVWpWOEJBWnFGZGFfbzRXRGxpcUVfOFBMYnVZZFlOdm1RMTl3b3VmNWVsTGprS1hhOW1mLUhEdE5pbFhKX1BtbGc9PQ==
Interesting. Will read the links later but how do you think we should solve class imbalance issues?,r/machinelearning,Z0FBQUFBQm0yeGI2R0kwTFpOeEtIejJGX19Tc0x5TlNrTTlwbUVwTmZBSkoybjNpX3FfeVRCQndaRzROd2hZeHJtZ21UZVhBNEM1WUNjSXNzSW5kSFVidkxCcFZQVUZnSnc9PQ==
Are you talking about input features or learned features?,r/machinelearning,Z0FBQUFBQm0yeGI2OUFHZTRfTmw1YzVYNWFMRjdDM3JsWkdfd3B2ODZHSHB4Z3lnZjlVWVBxbHRYUjdsOVQwZTZuOEVpbFRPTGR4alktWWFiSElSM0NfNnpnWG9xTUFWYmxkRDVxQjFmdE5JVFFycVFfbDQ2ZjQ9
"I think around $100-140k  
Some might compensate less with base salary and more with equity+bonus.",r/machinelearning,Z0FBQUFBQm0yeGI2S0F6LWRLZ0VnSnNGUmh5cnNzdjV6OEEwTlhQbjRFWGJrY1ptVDl0aktsQmp2SjVlUjZ2bnhKSmxMaVQ5eDVSNzROX01TaTZDbHhGZ0xXd0o0Y2dmV2c9PQ==
"Hi, any luck with a voice-to-voice project?",r/machinelearning,Z0FBQUFBQm0yeGI2MnBvVlVUODBuRWxPU3A2UnVPcWdCVjFpdExVX0N3U0xmaHJicXdwVl9WUHF4aUc1bFFBaGpyeGNPR29Nd0dJWE5ITkVpekRIOWxNVVRKc0I3UF9VcWc9PQ==
"No way I'm touching Python, lmao",r/machinelearning,Z0FBQUFBQm0yeGI2OHJ2R2k1a0FQZEhzb3hXcFY4emxfVVJfSHRHeVBibE1lckhudjZ5LWozQTh3NDQxTzdQcnlieEhPQjRsT3ZTMXRGSWZ3Q05UczBuYmRMd2hscGNpT0E9PQ==
"My team and I use wandb just for reporting metrics and tracking experiments. 


Not sure we would use it for communication. Is that what you're saying it's missing?


For me it's just a reporting DB, if we need to discuss or analyze we do that in our teams chat. Not sure why we would do it on a 3rd party platform, where our chats aren't private and could get compromised.",r/machinelearning,Z0FBQUFBQm0yeGI2ZERIdWMzdkktYU5rSmlCQmx3ZGNpMWF3akExY2k1QndDX2E0bXBjYmdkOFNlR05VQWVVT1NqRzJkbEdkZGp6Z2s4cWtJZlQ0R3V6QlYyVUM3YlNUYUNKcDF4RDlueVp1aHRmTDF0ZDhUWkU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2eURWWm1BV2hHRUdOdWlkNVRZbHJqOXl0VjZqTTBvbW8tbDlIcUdMY0JYaFlhVThNTlU3ZC1CNWtHRmFKUlFzRTNNM2RhbEk5Q0s3RXltaVd6cHFmVnc9PQ==
"This


It's surprisingly easy to do this crudely


Vector database chunking the document by paragraphs, quick search of the prompt against it, include it's results in the prompt fed to the LLM, system prompt telling the LLM to use the retrieved data as the information source",r/machinelearning,Z0FBQUFBQm0yeGI2V1phU01iYzgtb21zUEQwZkYwRGl0QlNRZDNWbFo0X2V4LTMtaG5UWHduV0pGcjBCaVhBc3VqUFU2Q19wVU0xLW5KR204UjEyYUFxdDFqelBwS0ZlclE9PQ==
This is exactly what should be done. Log scaling is a great way to solve this and many regression problems solve poorly without log scaling,r/machinelearning,Z0FBQUFBQm0yeGI2dEdpbVI2djlCMzNOU014UHRKc24wSE50WWRaWG82M2JveVFVTGpkVl9hbXphSHBfcnJfdnU2NFA0c05TVUhuMl9Hd0lMemkydW92N19CZnZ0dDF4X2c9PQ==
Cool project OP. Where would I look to see which models are being used for this?,r/machinelearning,Z0FBQUFBQm0yeGI2T0xhZ1FPbWZuUlk5bmlmOUkzVEo2VGcyY05Mb0o1UUFMT3NDMm5OOXVaM0NMOGVpVVh3eF81VUJIOHFCaGxyTmlvX3paRlpQQW84aERmNHpRNkx0NmRSbW1QeUp0X0JrR2hFbHVWYnExZnM9
"I see.

So the issues I have had was, say you see something off in a graph, then what happens is you take a screenshot and talk about it in slack. My idea is to take that graph and then create an ""issue ticket"" & promote action to run an experiment that aims to fix this. If you link a github then you will be able to see diffs between the run and the next one.

My idea is wandb really just acts as ""storage"", and I want it to be more focused on using the stored data to **promote the next experiments.**

  
do you Any other issues / missing features of wandb?",r/machinelearning,Z0FBQUFBQm0yeGI2cTdGMXJSc2M0Qk1HV0hzc1VBWXNTa3o1Q24yQjNSM0lhRk9nUm4waU9CcV8teDlHeHdDbTByOHg4Vy1tdERPb3RBd29ZN0cwMDF2N0FwTlRwWndhOUE9PQ==
"If your problem is basically you need/have both global and local features encoded in a low dimensional vector, you might want to look into Positional Embeddings or Fourier Features. Both tries to solve learning problems related to the NTK of NNs.",r/machinelearning,Z0FBQUFBQm0yeGI2MVQzUEpoY3NjMXFuZzh1em0zTFdfUk5hR1hWOFJwa3R0eFljeUhnczlxQ0N1X2RjVW4tZVpjWFVKYnJERzZOYXZFZm5FUkVzVE1GSmtaUV8xa0MtSEE9PQ==
Normalize with log(1+x),r/machinelearning,Z0FBQUFBQm0yeGI2WGYxbk5pQXBuaHB4dy1KTFlxTHVaUi1nOU5ZZ1d1Mkc0QUotWnJFSlpDb0d1R0dvQW9zY2ZEOTZXdkNwUmkySTlmeFVDeFdDQkJKd0R1N2N5cy1ZaWc9PQ==
Thanks.,r/machinelearning,Z0FBQUFBQm0yeGI2cldTUV90X05hVmpyeFNNWG5nWXlTbWhfNURVTjJscVpoUlA4eW03blpONjhNWkFwVVVoWUJwaXdTY1FRRS03M3ZwOUtSNlV3ZXVNNmI5djVfSmNOcFFuX2MycXhYelFaTmZEX1o2WXlaSVE9
"It's a-me, log-transformio",r/machinelearning,Z0FBQUFBQm0yeGI2RTBZdEpQYV9jbnZiNDAxWHduXzJDLXg0WkxtWXFKUUl6aVhtUk8yX1AtUHdlem05U0pjdWUwbFRtLTFTeTh6Qm9ZLUNGRjBrZk1NRkZ4ZDltRURXcHc9PQ==
NLP DAMMIT,r/machinelearning,Z0FBQUFBQm0yeGI2X0RGNkNNc2UtbWt0bXFUdENBLWIxbzQ4UlFIbnoxOEprSDc1R0RNNzdsWGI0VFVubEV2MmwzLWtZcnRnUXdWcHpvZ0FzdlVaSzN4MlpJY1pvZ3lTM1E9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI2RlUzMmMzZnRMOE9WeEs4REJ1QkpqZTlZdnVpdTNPQWtNcnY3MDdHRFNvZjRKUzZDV2RjSlJJLUJIbmdPUnlzMU1KVW9jeWd3R3VDMFNLOE52WDk2YUowRzNmaUxhTVBLekxtY3k5dzB0a289
Lmao what is a Xeon,r/machinelearning,Z0FBQUFBQm0yeGI2ZmU0Nl82M3BGYlBRWmVrZWtXeUszYTVxbm5nd1M4Ml90QkJHXzhPbDhVWS1FQ0EzWkNQcUFxbHpQblJ3aWlTZjVyWXY3RG44MW5KdFBWS0w1cGZaM2c9PQ==
"hi! i built something similar a few weeks ago and have been working with several others in the open source to develop something to address many of these kinds of problems, would you be open to working together to helping us make the most convenient and clean thing we can?",r/machinelearning,Z0FBQUFBQm0yeGI2Mkp6YXNHakp3bDNmX3hfSEVEMi00UzBaSnBMbTYzSGhfdC0yWGpvQTViWXY5TFB2QTBod09VQ3ZDWGktSjBwZGpkN0cxYkRvVFlsVEE4TkdZcnBDQmhIa0pndzRZNGVOLW00U3htbUZIR0k9
Dask s3 openCV and EC2,r/machinelearning,Z0FBQUFBQm0yeGI2M3BXUW9kT2NBM1F4VHNxM254T2JHNFB3b0JXYjRCeHJvdDQxeHVxXzVOSFJfb01KdzhXM3lWenFGRnpud1FWZmxNanNsMmV6QlpJZjlpbkdmODZnZlBTTlp6eE5VSlQwbWREdUNjZFFzaEk9
"I use WandB in my job multiple hours per day. It's the most feature-complete thing for this application out there, but its performance is soooooo gratingly bad.",r/machinelearning,Z0FBQUFBQm0yeGI2YzZJV2tsTlZQbHpWU1h4UW1nTVp1a08yc25xWUN1VWlpS3J0N2NGbzVXNjVJV0ZxZ0F0cXlWM2ZIeWdZd0NCU0hqVkZ3Zi05MmZRWTA0eVZWMlktNm5JQzZDNDJzXzFxaFJVdkxtWG9ZaDg9
"you realize that without the element of microsoft snooping on you  
its exactly as dangerous as storing data on your hard drives right?  
like, its just a convenient way to access your own information.

its not like its not all stored anyways??",r/machinelearning,Z0FBQUFBQm0yeGI2QmRUTzQ2bkQzX1Jkb1c2cXVXMllnREhEVk1lb2xHYm5tTGR6SVYxQlJQQTQ2dGpvS3loU3ZXeUhPZHNCc0tzZDVDT0RrSmlmN0lFRDNTa2FHN0FKb0pXbnJsVjJ3UVB5c1ZXUW5TSVhHaE09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2aERVY0N0S180SE9MdkVKTV9IZGpGcjRzNU5OejBNcmNQYjkwTTVnYml2Y2RXVDY0SUpDc3lzVVZveVFTYnltZVZpTTNKRFRMSHVaVzNxcDJ4ejlrWXc9PQ==
"are you certain your implementation is not flawed in any way?

(I have spent just  a couple of minutes looking at the code, so apologies if I am misreading anything)

For example, you do ask the user to input a key and say the key is not saved anywhere, but it does seem that you store it in plaintext as an attribute on the CaptureStart module while the code is running.  Is it possible for that to be captured by anything that can examine process memory in realtime?  Does the fact the user is likely to give a short memorable key compromise the strength of the encryption at all?

/edit/:  Is this your method of encryption?
 
     if isinstance(key, str):
         key = key.encode()
 
     encrypted_data = bytearray()
     for i in range(len(image_data)):
         encrypted_data.append(image_data[i] ^ key[i % len(key)])


I am not endorisng chatGPT's ability to do this accurately at all, but just for fun I asked it to analyse your encryption method (just the snippet given above).  It had the following to say about it;


**Potential Issues**

Security:

**Weak Encryption:**
XOR encryption is considered very weak and is easily breakable, especially if the key is reused (as in this case). It doesn’t provide strong security for encrypting sensitive data.

**Key Reuse:**
If the key is shorter than the data, it will repeat, which makes the encryption susceptible to various cryptographic attacks (like frequency analysis).

Key Management:

**Key Distribution and Storage:**
The security of the XOR operation relies entirely on the secrecy of the key. If the key is compromised, the data can be easily decrypted.

**Short Key Length:**
If the key is too short (e.g., a simple password), it can be brute-forced or guessed easily.

**Data Integrity:**

XOR encryption does not provide any integrity check. An attacker could modify the encrypted data, and without additional measures, you wouldn't be able to detect such tampering.



---------


ChatGPT then makes some recommendations;


Recommendations

**Use Stronger Encryption Algorithms:**
Consider using established and secure encryption algorithms such as AES (Advanced Encryption Standard). Libraries like cryptography in Python provide secure implementations of these algorithms.

**Proper Key Management:**
Ensure that keys are generated, stored, and transmitted securely. Use key management services or libraries that support secure key handling.

**Add Integrity Checks:**
Implement cryptographic checksums or message authentication codes (MACs) to ensure data integrity and authenticity.


----------


It then goes on to give an example using AES:

    from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
    from cryptography.hazmat.backends import default_backend
    import os
    
    # Ensure to install the cryptography library using `pip install cryptography`
    
    def encrypt_image_data(image_data, key):
        # Generate a random initialization vector (IV)
        iv = os.urandom(16)
        
        # Create a cipher object using the key and IV
        cipher = Cipher(algorithms.AES(key), modes.CFB(iv), backend=default_backend())
        encryptor = cipher.encryptor()
        
        # Encrypt the image data
        encrypted_data = encryptor.update(image_data) + encryptor.finalize()
        
        return iv + encrypted_data  # Prepend the IV for decryption
    
    # Example usage:
    # Ensure the key is 16, 24, or 32 bytes long (AES key sizes)
    key = os.urandom(32)
    encrypted_image = encrypt_image_data(image_data, key)

This example uses AES in CFB mode, which is a secure way to encrypt data. It also includes an IV to ensure that the same plaintext encrypted multiple times will result in different ciphertexts.",r/machinelearning,Z0FBQUFBQm0yeGI2c2NyazdFMl9EWVg4X1M3cUdGRld4RUpxbW9OMGZPNXkza2Q0UjRjOXpfU0Vwa25SMnozUWZ3dktwVGRjQ183c2RzTTVlRUNuaFBYQXpXWENjM2U5bGc9PQ==
"What sort of features are you using ATM?


I agree the performance can get very bad, a lot of their codebase is super old & inefficient


What in particular would you like to see 'sped up'",r/machinelearning,Z0FBQUFBQm0yeGI2QTlQVzFXaERQSkN2ZkxPX0NBbi1DNUlHUlVvOWVONDVna0VvcDlDaHJLclhINElQMlVUQmhrSG5uTjVpT2lrS1V1eDlJd053S1Q5cVJ3eks5Y3BXaHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2VGd1aTFZUUlUc0xnUXk2Q09TUi1kUXlZT0NfVjN0UDkzUzVXN2ZhZ1FIdTRnTmM3WWNyM243ZUNyS0FOeVVhZnA0OTFYMkNnWU5oam80VDFRR0ZQT2c9PQ==
For image to image translation look at augmented Schrödinger bridge matching.  It goes over the correct way to build bridges between paired data.  Unfortunately the paper is tough to read if you’re not already familiar with the topic but it ultimately says that you should make your score/drift/flow network also depend on the source image.,r/machinelearning,Z0FBQUFBQm0yeGI2M2VXeTBMbWdiQ0tkcUN4cmNkVklLNzg5WU5zangyWElURzVkbVNOdW9keFE3U0prMDRMd0tVMjF1VGhHQkpYaVRCQW5PajRuSUUwODZuQ3JENWZqZ2ktNWNHU19TVFdHMmhSZ0ZqdDZ0MUE9
"As a pedantic statistician ;-)  I tend to avoid framing problems as pure classification if I can. Classification has to do with decisions, and optimal decisions require probabilities and utilities (i.e. the ""cost"" if you will). So, for these classes of problem, I tend to use direct probability models like logistic or firth regression (multinomial regression for multiclass) perhaps with some rich structure like splines and spend quite a bit of time on calibration.

I know this answer may not satisfy many, but sometimes it's equally important to point out the flaws of an approach. For more, take a look at the linked papers and the numerous discussions on CrossValidated like these:

[machine learning - Reduce Classification Probability Threshold - Cross Validated (stackexchange.com)](https://stats.stackexchange.com/questions/312119/reduce-classification-probability-threshold)

[Are unbalanced datasets problematic, and (how) does oversampling (purport to) help? - Cross Validated (stackexchange.com)](https://stats.stackexchange.com/questions/357466/are-unbalanced-datasets-problematic-and-how-does-oversampling-purport-to-he)",r/machinelearning,Z0FBQUFBQm0yeGI2QVpweEhtMFAyTWJYeF81dmZCemJNUFRMRDU2bHc0Y1VNSlpWM2l5bGhNdVF2a0prU0Nfcl9BUUdBZ0lxTGpsVEpDc2d4TE5zSXU1Q2NHQ1FqMTNWaXc9PQ==
"Locality sensitive hashing, then an embedding layer.",r/machinelearning,Z0FBQUFBQm0yeGI2aUtCY280RGoxeTFwRkt1WWVmTGZ5TEp5MU83X1RuTDdHWXdTSDlXTjkydWs1ZnluVHczQzlJUWd0bHptT1pOd3c2STUzSGlFRFd4ekM3cFZTaFhSVmc9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGI2M2VEaDRjbElsVTdBNzFxSXBGN3Bid3V5M0RfWkNCYmplTVluNHF0NDZhZDFMbnl2YTlMLTNyb2lnWDZNQ2RwUjJnc3daOTM1aTdxSVNtTV83MlhGVUE9PQ==
"Is the integer a class label, or what? What's the relationship with the prediction?
If it's an authentic input, process the image and concatenate the integer with the output of global pooling before the linear layers",r/machinelearning,Z0FBQUFBQm0yeGI2cXo3cDItTWc2YkdzR2RaajZYOFJGTUV6M3cwWl9LQmFUaU1lXzhXTVpDUFVRVC1NU0V4dWJGS0UtTkZ2dFlSUnhrMGgtZXBkRnRIMnRRYmhqT3ZQczRTNWt3UTQxSGpQb3dfUXhVajEwdjQ9
"I wrote this if it's helpful:

[https://github.com/ventz/easy-llms](https://github.com/ventz/easy-llms)  
> Easy ""1-line"" calling of every LLM from OpenAI, MS Azure, AWS Bedrock, GCP Vertex, and Ollama

`pip install easy-llms`",r/machinelearning,Z0FBQUFBQm0yeGI2RE43bzc2dV93enIyaWlQbGQyZTdKQ09mSUNJUEVsOV8ya3hOd2UyMkNzbnlINWNFUjFNWVFGTDBxYWRIQmVma1VMSUdkOGZBcFBrM0dhZWR3MWkxLWc9PQ==
"I have to disagree wholeheartedly, and I think you are missing the main reason that you should choose between L1 or L2 as your cost function: what do you want to estimate?

The optimal estimator for minimum L1 loss is the conditional median, Median(Y | X)

The optimal estimator for minimum L2 loss is the conditional expectation, E(Y | X).

What do you want your model to predict and how will that prediction be used? 

For example, if you are trying to train a model to estimate wait time and show it to your custom waiting on a taxi, then maybe you prefer L1 because the median is more important to a user's perception of wait accuracy.

However, if you are trying to forecast some costs, then you definitely do not want to use L1 because what you really care about is the average/expected costs in the future, not the median! So you should use L2.

>If you get 0 loss with one, you get zero loss with the other.

This is not true. This is only the case if Median(Y | X) = E(Y | X) and also Var(Y | X) = 0.",r/machinelearning,Z0FBQUFBQm0yeGI2SEZ5LVFBMV9YU3ZGcTMteDFBcnVUWm1QaDR2c29Sel96RXBZRWdVdjdCLV9FVkZMZHQ0S3NDOTRpS1NKQmtiZFpidm1BN0FqT0NjakRQWnhCRFg3anc9PQ==
"It can be any real number. Basically, these are associated with an experiment where I have certain images and state variable(which is a single valued real number.) They both are constitute important details of the experiment and influence the output. How do I deal with such inputs ? Bunch of real numbers and images as an input to DL
Model.",r/machinelearning,Z0FBQUFBQm0yeGI2VlFWOEdPSUZIdWI3YUNLdEhJT2JiM3RZaDhxeVZTaHpwSUhGYjRNQ2w3NEFvM2JMeGkzZHpRRjRPcXY2azhKQV82b2VTN0FRMVFSMXp3V29HRnNWWHc9PQ==
log(1-1e2) = undefined,r/machinelearning,Z0FBQUFBQm0yeGI2eW8xMld2TEpfSmZWbUFnUjJEY3JkTVVJMDBDUWROSkg4NWlYQUIteTRTNDdPeVNGMG5RcjhqLXp4MGV5b3pRdzZtY2Z0MU5ONXotV1N3RzEweGRZOWc9PQ==
">Ehh, for most tasks you can treat it as a hyperparameter, swap out L1/L2 and do whichever works better.

Have to disagree with that, I think you should choose L1 or L2 based on your problem and what you want to predict.

You will often find that you can achieve better L1 loss by optimizing L1 OR you can achieve better L2 loss by optimizing L2.

The optimal estimator for L1 is Median(Y | X) but the optimal estimator for L2 is E(Y | X) and so unless your distribution is symmetrical, they will not have the same optimal model.

If you want your model to predict expected conditional Y, then choose L2. If you want it to predict the conditional median, then choose L1.",r/machinelearning,Z0FBQUFBQm0yeGI2c09kSDZPQmpwVmJSejJ1dXN3THNzZnFrTWoxS0ZTNzd3SW5FM0xZOXQxWVFGby1IX0JYblUxUWQtbC1xNDFNbXlBd290OGpsaXNjTjlLaUctYld4VkE9PQ==
Oh no!  Eat this log-transformio: -1e2,r/machinelearning,Z0FBQUFBQm0yeGI2ajZqVjNqMXJZbXlMN0Qxak5IZ01UXzRaVUJ3SVNXUWtIaUhnT2lJb3UyckJiV3lzN29rV3RhMHJjVHFXVk5GWlBEeVg4MUZMTUtLQ3hhTktNSWRtcGc9PQ==
Did somebody try to reproduce the results? I am struggling based on the information in the paper and it would be great if somebody could post some training setup how it works.,r/machinelearning,Z0FBQUFBQm0yeGI2TU1BR2dXbHZMcmJ0TkZ6anRrdldWbE1lVVlQanhtR1NxR0JkUmNpVVFVV0FCUkYyTFRrejFYUkY1TWhkQ1Z3bFN1VEJ5U3dFRmhrMGhiMmhDclotLWVLMHhRV1Rkd1BUR2VoUnpYdVZyR0k9
Oh right so use log(101+x),r/machinelearning,Z0FBQUFBQm0yeGI2cFMxWW5qcXZGZWtScXBHMHdiNS1hbHVVcFh4VmFTdElHeEFjcHBwZVBNQmw3SzRPdUxNNEtqU2Y0c2tuVzVDY2tadVRTUHBUTTRzZzE5LWMtem1kaFE9PQ==
:),r/machinelearning,Z0FBQUFBQm0yeGI2eWdka1NBYXZTWlp6RXB5R2NfaFZNRTI2ZHB4WkNWc3NfWWdJcllzYnE4YlEtTXBBamNEcnVFblRQWjloOHItME04VG1Fcm5lTHhYcVlveXZPSGlsalE9PQ==
"Well, adding or subtracting a single run from the view shouldn't take 20 seconds, especially if you are only visualizing a bunch of scalar graphs. But I also visualise a lot of images and videos, and those take *ages* to load. But to be fair, they are making a bit of progress, and are adding features (like importing runs, literally my most requested feature for ages).",r/machinelearning,Z0FBQUFBQm0yeGI2ejZUcUVKVE9HSUptVmxjOGdvd2I1U3ZXYkJoR0RrbFdFZHY4d1I3TkpWSDFtRS1ZcXJ2emFvT0JnbFdqd1JabS14cDloLXg2MlktSFhOVkQ2M3hqZ3A1d2ttUzM4dTVIQzBad3NvNXRMc1k9
"looking at the code, (very briefly, so I could / am likely to be wrong..) it looks like it might be doing something like OCR on captured image screenshots, and then using https://huggingface.co/sentence-transformers/clip-ViT-L-14 which does

""This is the Image & Text model CLIP, which maps text and images to a shared vector space. For applications of the models, have a look in our documentation SBERT.net - Image Search https://www.sbert.net/examples/applications/image-search/README.html""

the full requirements.txt for the code is just;

numpy==1.22.0

opencv_python==4.9.0.80

opencv_python_headless==4.9.0.80

Pillow==10.3.0

sentence_transformers==2.7.0

skimage==0.0

streamlit==1.32.2

torch==2.3.0+cu121",r/machinelearning,Z0FBQUFBQm0yeGI2LURNdDdlQlZWcVJkT0Z6d3ZYbmlrSXZkUktVOHB0M3N6djBlZmRSWWE3OVlSRlp4dHVSQk5aUGtsRWtEdlJLX2J1WXNrT3BFejRkclNqTExiakdrX3c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2WWJHNUVMX2JwR3BZR2FMTjc5UHFmTEpORlljbWxTTWVMbzRtaEFpdWExOUp0amljaFY2T1JqYkhZMUE3UzBpeU5tWDR4YUNxV19GX1hBWXhpa09mREE9PQ==
"i try to visit the site but i got an error 403 forbidden code: all access disabled Message: All access to this object has been disabled
how to fix this on my end? or it's on admin problem?",r/machinelearning,Z0FBQUFBQm0yeGI2cGlmZjRic0NtNEpKVjZNUGFZTnlfX3F3bFkxUjFLczZiblBuejU0SVhxZV92WjdOSnBOSl9YUHNteGRGeFZvaTdsdUFrTlJkb3dpWXQzcTNjd3puR1hVXzNYbWRwQ1NYZHpuanBmYjFKdlE9
Aren't there some MLP at the end or your CNN where you flatten the image features ?,r/machinelearning,Z0FBQUFBQm0yeGI2X2ZaRXhPVE1QZ0djZWxaTVYxNDViSG1jX09TWE5vWHh5eEdfYUZKNGZxeWd3d1VMV04tMDZoMk1CRXRfdUFDQmQ3VkFJOTd3QUZhd2ZfS0VSUm1wN1E9PQ==
"it doesnt use an llm. It uses screenshots, OCR and

https://www.sbert.net/examples/applications/image-search/README.html

to do image search.

The encryption used is basic XOR with a user inputted passphrase.

I would not call this particularly innovative, or secure.",r/machinelearning,Z0FBQUFBQm0yeGI2ZU9xYUp2UnUycFpGbFJrbnFaY1FfUnZzMmpFZzZ2ZER0WDg1azRLcHRVQ1d2R3VRWEFYNldPNHVfbEN2dWRURWMzeHkzUHhkTmRzbFZ6OGpqbEQ4X3c9PQ==
Good experiences with sign(x)*abs(x)**0.5 or sign(x)*log(abs(x)),r/machinelearning,Z0FBQUFBQm0yeGI2dDRlQ2Z1UEV6QlkzQmdJc1lIeHpZQ3h5UWRjTEJOaFQzenB6c3RnUzBubmRzNUw3THRhQWFyTXF6U1VpSDJ6bzhldGhkR3NzNm1uYU1CY0hOUnBXekE9PQ==
You mean I flatten the img and then use a FCNN  ?,r/machinelearning,Z0FBQUFBQm0yeGI2d3dSRDJ6S1JxVkpZLUtwaGh5RngtRE81TWJwenVZNDVoOVB5NkxmdDR6OVhSOVBOeXd0dzV5Z1c4VE5JS2JENm93c0Z3R3V0elhXVFVXODJib1NlQUE9PQ==
"in conventional CCN for classification you process image with a CNN and then have a classification head which is an MLP

but depending on your task maybe its different",r/machinelearning,Z0FBQUFBQm0yeGI2aG1Sa1B4SmxJdFBIT3Fyd2taRGdVeGVXbFg2dXlObE0wMVdkX3dHcVoyNlhuSXNXWXNDZjZ5NDNXRHdCVkRMSldmcTY5U0FvZFRoaUtKS0VsS1BzWEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SXNST1BLWXJtcnk2ZC0yV2dCSEJGRU40bVpsTnotRDM2Z0d2UEMwM0t5R19tYl9yc0NnNjQtUGtPNmFxNTJYWEZWRmVqaXMwZUR1dFBjcXFhUlRvcnc9PQ==
"a few TBs is not that big actually. Big companies manages thousands of hundreds or thousands (maybe more), not a few.

You'll probably need a good CPU however to do it quickly. Try to parallelize your code as much as possible.",r/machinelearning,Z0FBQUFBQm0yeGI2a1pLWE9lVUpDV01WWHFLdFA4UHpEM0RtRlJLd2M1RklHRk94UHlzcFdvU2RJVWRCR0ZQbU53VnNHY2VzYWMybnBsSWwteVhpYUN0TlVVa0Z5LU9MOWc9PQ==
"Thanks,
Do you ever see your team moving to another platform if it had better developer experience?",r/machinelearning,Z0FBQUFBQm0yeGI2TktqREVUZzF2MHl1dUlvS010QkQzN0tVMUlGNU5IT0FyQUNuekgwaGFDYlFzR2RsZFdrTnl4eUNTN3VlM0NFWEN2eG9QUWx0YUFOY3NXMjV2LUZmc3c9PQ==
"Eg rotating, resizing, rescaling images",r/machinelearning,Z0FBQUFBQm0yeGI2dG9VQ2V6OG42WTRsOGVFWUVjcjZRQUtRcEljUDZJVkpfcXc2b3VTd0RtcV8takw0aExGYW9SX2VrSG80UGRxUVlZaE1WdFE5SmtGN001aW1JNnlPeUE9PQ==
"This is super interesting, can you share your paper on this part of your thesis? (If you'd rather not dox yourself, I understand too, and maybe you can DM me?) Loss functions are one of my core interests, as bizarre as that sounds, so I'd love to see work on that front.",r/machinelearning,Z0FBQUFBQm0yeGI2X2lPSmt3QlhPVjJpS2RZa2xKcU5ENXNGa1FWNm1pVXlTNlhGQUtJb0hiMFlRdTNvQ1JuajZXVU9NTTY4b05TanFxTTd2amc0UU5tT3FyaDU3dm1lS2c9PQ==
"Maybe, if the switching cost is worth it.",r/machinelearning,Z0FBQUFBQm0yeGI2RDZvQ0RtSm1NcDBhc3dzaXV6MzhuYmRaYUl0cF8zZlZrMl9FZnc5VWZmSlFjSUZnMlZJcnBSUnVHV1NobFp4dXk2cE9xTGJQZUJTLWQtaHNsS0NtTVAxREZpbFdvaUhjcTVpaUJGUXh6MGs9
I developed a version of auto GPT for blender python because I noticed auto GPT can't process blender python code or actually it can write it but it can't I mean it doesn't have any interpreter to run it in....... my code is about 8000 lines long and pretty awesome pretty strong. DM me if interested,r/machinelearning,Z0FBQUFBQm0yeGI2TU9rTnFrdV9mMGV2OElqUzNrZG9OUFg1SmhlSDBnTWJTLU9TNUFUazJOVmk5WjRmajVJZGpEbmZkbVBuS3pmcldzNV9aWGkwbjBER19DTW5xZEo0Mmc9PQ==
are sigmoids not cool anymore?,r/machinelearning,Z0FBQUFBQm0yeGI2anU5MEhRU0ZmU0Zrc2xWaDFqUHVWWHZXaXU2OWtPdVg0ZE1lTllVY2loT3JZTHZuNlVKNmNvR0tXWTZMdXVNTlpiSHloaE9jUEJSRnlDSXZxcE4zQUE9PQ==
"please explain the actual problem.

ice cream sizes have  a large range if you use nanometers as your scale

so just rescale ( normalise/min/max etc)

log scaling *may* be appropriate, but *only* if the log  has a meaningful relationship to your target.",r/machinelearning,Z0FBQUFBQm0yeGI2OVFQRUVWRlZRS1NkWlBsWHBpUm4zZlNkcGNEYnBQV0lFTEtRaW4zZUhxTFhIR2RMeUg0UTJRdU5sZXlTdHk2SE5CWHRJamN4YmN6MG5heUNnbS0tMmc9PQ==
it does support vision,r/machinelearning,Z0FBQUFBQm0yeGI2UkNVdmhId3JLS283YUtJbXBlbnZyUHB3YzVIZmNpdkVOc3NwdnNfYUhMeEV5emt4ZmgzYjZyT3RzeXJ0bm5INmZjRzg3Q3AyQ3NlUjlYNUtyU3BMRXc9PQ==
Nice! I will add support to it then.,r/machinelearning,Z0FBQUFBQm0yeGI2cGR3RUNjWkNrSWg0N21BS3NYS3RNcTZTLVZXM3hGTFpjNk5wV0F2MmcxaElLTjlSN3o2eUljYnp6VThCNzVQRmIySmNXR1RqUEdhNTh6RlVjYXFvVnlmanlycVdCNnBLSDJSYTlNNGtDWmM9
I've also added support to Groq btw.,r/machinelearning,Z0FBQUFBQm0yeGI2djN2eFhHMkxtWmF0LS1qNEFrQ1pHeDRyOFNYNHU2TDlrRXZoYTJZdmw1Ymp4QzYzOVZEakoxOThNbDctcHkzU0wxUUxFdW5FeUpreWZER0FHS3F5bzhJWThWaWJJTE5iZXgwSlFBWC1UdUk9
You can build this preprocessing into your torch dataset. They can happen live as you pull from the dataloader.,r/machinelearning,Z0FBQUFBQm0yeGI2X1hFNnFTUk84WmlmdTJVZW55cDh6cUw2TGUxNDFvU2E3N2FMZEV1cmFMV1pzQXR3NFBtRlZjaURNbHBOM1otZ2R1MWlRZXJfQlhsamcyMWpaZFFtbWc9PQ==
"Youre right, I didnt mean LLM, I meant a vision model.  It does use that.",r/machinelearning,Z0FBQUFBQm0yeGI2Q2RjT3NDbmxTTlBkcFU4NWRnamJLdm5IeHdmZzJ4LTJoQnNzSTFmM3ZQbnY1cDZTZ3lydi1iN0huZVBDdDBCUUxCV3F2dnliblV3SUlReHM4M1N0YWc9PQ==
"just do v[i]/max(v)

where v is your value set",r/machinelearning,Z0FBQUFBQm0yeGI2QlZkc1dGbzdSRUJDOU1LWHRvQTNoVXZLZWhSd2ZBOVpUcTJzNkpIRXRmYlJRS2RrRGV5a294bGFuYmgzd1Fsb04wWmhXSXZYTUN2d19LWVExZ28xZDE5RVNWUzdkQWttTXBhY3lBV1VHdTg9
Depends on your problem but clipping might help if those are outliers.,r/machinelearning,Z0FBQUFBQm0yeGI2Ym9sVXhFbmZtUUdYOEdTTFl2S0N4aVJBZTh4Vm1lbDV2cjVFcWRyeGNkd2FZbTk4Zlo4ZGYzSXpaSm5LU0pIakZMVFdKbEUtekJKM3lmTUVzZ0ExeFE9PQ==
sign(x)*log(abs(x)+1),r/machinelearning,Z0FBQUFBQm0yeGI2bnJBRE9KQmZyOW82V3dscl9XbEk5OWxMaV85Q0hoWUMtLS15S2ZuNm1oQUFmSzJtS3JIcHd5NnR6SWF5OEVZM1k3WFVwWHB1YmJ3UGVpUEZUMjRQQ0E9PQ==
Use a signed log function: sign(x)*log(abs(x)+1),r/machinelearning,Z0FBQUFBQm0yeGI2eFRGRmZBNGI1ZXlmOU9TcDNFaU1RazJiaUd3b3R4V0FaWHBlcVl1Und0Vkw3QzRmWG1wb214MXM2c2FyOE0tTTNGdDBZSHhhTHdTZ1p2eXI1LTAzNVE9PQ==
I'm assuming the first one is sign(x) * sqrt(abs(x)) and not 0.5 * sign(x) * abs(x),r/machinelearning,Z0FBQUFBQm0yeGI2RDMtWTczRWRpS2VKSmNjZmxSOG0zVEtpdS1OY1JIMWg5X0k3UjJGaDNXeUR2WWR1eGNSR0NaUi1WMGcxZ3B6akVIcGFjS0kxc3Z1ZUhUWDl6c01UZEJoUmtzdmFaajRWTTQyM3RZa0swQWM9
"You almost had it, remove outliers, shift by min value, and apply log scaling, then normalize",r/machinelearning,Z0FBQUFBQm0yeGI2MEFKRkJBXzhVYWJWOXFQYWhJTExhMDlFVWpPNUFRVUdQRnhISDIzUVZacHRHVUlhY0ZUNWZlSEs1c1cyRWhPdm5pVVpfVDdoLXNmOTB3ZnRyT1Y0SVE9PQ==
">One option is log scale, but what if the features are negative valued?

You can try out the symlog transform. See: https://twitter.com/DuaneJRich/status/1627438877488336898",r/machinelearning,Z0FBQUFBQm0yeGI2dWtadE9uSk1qSnJQa0VyMlNrdzRVQWZXR2w3NV9IeFhXb0k1UlRrQVhXUXJCQ1FRYWxDY3ZFaFMySUJURk5YbWNJTG5MVFpxclR5ZHhxeEpnSFlmMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2Q0daaEJXMlRVTzNDOHl6WjlvLW14ZjBmR3dlbWlKek14VVV1UExmcmhRZ0hQMU9FWXRBZG5WeWEtZkJLenBscnBFYUNnWnNaTDRKYWdXNzBlbzhVdVE9PQ==
"interesting, thanks.",r/machinelearning,Z0FBQUFBQm0yeGI2SUJTMDdVQmdHdVUyck9uay1hREFMWlliLWtQQkdVNTlhUUNxOU1hTkNLMHNxb1FObl9TaHdmTFJaQkNPbjNGYUZ1MkszUmNUX2ZmNmdvbGJxb29DVjV5R1FBZFNMN0VXYUwybWlEbkFGc289
"I don't currently use wandb but I personally like the reports you can create in wandb. It's currently missing in MLFlow which is what we're currently using at work.
I am also interested in exploring ClearML.",r/machinelearning,Z0FBQUFBQm0yeGI2eTR0eHczcFlyTXN4UlBQdUoxS2hYOGduZXVwczdQcTFqdFR1ampRX1dpZFJHbDhkSEN0YVljSlFReTJ0dlNtSkluYmxTLUFHdC1yZnN0QmJCUUNRNkE9PQ==
"oh interesting. I've found the reporting system in wandb to be quite bad. Its a focus in my MVP, making a more ""notion"" styled editor which is collaborative.

Anything you really like about MLFlow vs wandb?",r/machinelearning,Z0FBQUFBQm0yeGI2N2Q5MnFuSmxoa25iNzkyUDhiWExuUnhWRC1EM19EYVg4alVuVjNpdU5hSlAzNXFEVnJMemVnTVNacjlpWDl2eVFQQTRDWXQzc1FaQVdRc3pLT3FLSWc9PQ==
What I like most about MLFlow is that it's open source. We host it on prem.,r/machinelearning,Z0FBQUFBQm0yeGI2NVVsdHpUWWJmNlJOel9KM3c5RTNUWUxFTUpFMXU3ZVprNUwwTl9MRjJuNFZLUFVDZ1FFNkRsMU91SmFBTTUxYUl0c1I1YVNCdjNpbWFldWtjRWRoSnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2ekFidnhXenZaczdFc3VjUlcxaVBfY2U1bldxTU5SaXplWUplWW9ncFIwR0NlWWZLZHVOamxES1FzRXJ1UUI4Qk5JNHNGRnR0dVpFQVFrSHlBUkU4Q1E9PQ==
Why Hadoop instead of Spark? I'm newish to the DE world and everything I've ever seen for big data processing is always done in Spark.,r/machinelearning,Z0FBQUFBQm0yeGI2dzFDdktSRW5OS2IxSVEta2ZmV3ZkQ01BdGpuOGZfSHdtd2dmcWtMcmxTVXJaZ3JQV2J4bVA1elpjOWx3aEd4OHR6ZDBZeWhzX25qbjNfeU5sUUdleFBhaUhuUnlNdjJlal9vYTVQUzF1blk9
"I see I see, have you incured any issues with collaboration with teamates with MLFlow? 

Anything hindering you lot from running more experiments?

I would love to know anything you don't like / want improved",r/machinelearning,Z0FBQUFBQm0yeGI2LXkyajJ3dTBVQnMxampuV0gtWXhIeHc1MnRiZW8xcllndXhvalp6SnlSdEZndFc4QjFaV0lPakNhdlBENUxvWHl5NVNmakV0WFBXZldrU3U1QWEzRWc9PQ==
"No, you should use `arcsinh`.

Reference: https://marcfbellemare.com/wordpress/13021",r/machinelearning,Z0FBQUFBQm0yeGI2ZUhLdkRHQUlWOEJGVDBraGxZSEJhaDlDWkZHNmg5Qk53a1VqdmxqWWR6aDBkb1NsNXlYVG1Id1lPSmlUa0lOa1RTYzBwb1p2YzhuT2FUMlVMNTJtZnc9PQ==
"PSA: Stop using logs for this, use arcsinh instead:

https://worthwhile.typepad.com/worthwhile_canadian_initi/2011/07/a-rant-on-inverse-hyperbolic-sine-transformations.html",r/machinelearning,Z0FBQUFBQm0yeGI2LXBwc0U3ekJDMllEaTFzdUxwSUdQMlVwRmU2OVJpcnJmZEl5bVQzUmU2MC1Fc0pacHkxTHR2V3ZNTHhNQjUtNmZuUkxaNmRHbHdCV2lELUtCVTdSYUE9PQ==
"We've been using arcsinh instead forever:

https://worthwhile.typepad.com/worthwhile_canadian_initi/2011/07/a-rant-on-inverse-hyperbolic-sine-transformations.html",r/machinelearning,Z0FBQUFBQm0yeGI2R0RRWDVTaFlSZjM4N2tqMHBVMFZrNEZXVEtqWmtCNVc3TlNkTnJidnctYXRGUUlUV3lWV3RjeU9kZ3RldElLeUQtWWdoamM2S2lVWE1TRXhuamFfalE9PQ==
That´d be awesome,r/machinelearning,Z0FBQUFBQm0yeGI2OXB4VXh5RGNYd3hQMmpoSmgyNDF2c25wRmo2YmYyemc3Rzc5NlRWdWkxaHB6RXlPNmFsLWhYZEVBSkZSWkdHN0FRN2ljdFVsR1B6NVlTVTdVVXdIaFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2aFJqaEpjSm5ndndMcmtKNk5HTWN3ZW9FT3ozLWhIMTZYbmdiYVFjUGZUdnJLMHF5WTZIb2h2M2ZnUlVmUTVnd0o4TXVucG9kMG82WnZ5N0VIZTlSMnc9PQ==
The latency with any interaction you have with the interface is annoying.,r/machinelearning,Z0FBQUFBQm0yeGI2ZDRTYXVzOER3QTllbVZxSGwzbkZNYlNock5fUXBRN2Y0cF9UODZBSERWT0hBanZrS3ktY05kRjhpZ05td2xCVHM5dXF5VmxlUFZRQlI4RGJBdnhJOVE9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI2cksyR0hEOFFIcFplV2x3MnNOY3B4SU1ZMHgzTGUyaTQwZ1NzN3VmeFhzOE1NU21IZGhQVGJNVmZaS01hb1dqMEEydlAyc0dmZjFHNE8tbERDNG41TWhkSFVlYXJFTzBjeGkwZEdMQlYxeWs9
"What activations does your model use? Converting the model to use relu6 can be helpful with full integer quantization as it restricts the range of the outputs. With my own experiences I noticed that there was a huge drop with swish, moderate drop with relu, and very little drop with relu6. Similar to the findings that justified the switch to relu6 for EfficientNetLite [https://blog.tensorflow.org/2020/03/higher-accuracy-on-vision-models-with-efficientnet-lite.html](https://blog.tensorflow.org/2020/03/higher-accuracy-on-vision-models-with-efficientnet-lite.html)

  
I left some notes about converting my model on my blog a bit back: [https://www.cranberrygrape.com/machine%20learning/tinyml/bird-detection-tinyml/](https://www.cranberrygrape.com/machine%20learning/tinyml/bird-detection-tinyml/) - I worked through dropping the input size down from 224x224 to 96x96 which reduced the RAM requirements, compressed the bulk of the model by selectively freezing and reducing layers retraining lost accuracy, and optimized my dense layer sizes to reduce the end model. 

  
Left some notes and notebooks showing the quantization process and post quantization accuracy in the different forms:

411 outputs, same number of parameters but the difference being relu vs relu6 activation:

[https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds\\_96x96\\_411\\_outputs\\_i87\\_full\\_relu\\_post\\_decimation.ipynb](https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_96x96_411_outputs_i87_full_relu_post_decimation.ipynb) 85.05% (74.16%)

[https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds\\_96x96\\_411\\_outputs\\_i87\\_full\\_relu6\\_post\\_decimation.ipynb](https://github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_96x96_411_outputs_i87_full_relu6_post_decimation.ipynb)  	83.49% (82%)

With relu I was seeing a drop from around 85% to 74% but with relu6 I saw a much smaller change to the end percentage.

Not sure if others have different experiences. I didn't find much in terms of resources while converting and testing my model at the int8 quantization level and haven't found much interest in any of the methods there.",r/machinelearning,Z0FBQUFBQm0yeGI2c2VBaHVUUkFzc1JZdkNLSk1kcG43Rl9DTE9MVXpSSk4td2pNS2FWVUlHd0hNR1hSdnRVTVM3dnl2RXpoVkJ6UnZfMzZvZDQzaTVsYjJrZEhvR0VQa2c9PQ==
"
I see you've posted GitHub links to Jupyter Notebooks! GitHub doesn't 
render large Jupyter Notebooks, so just in case here are 
[nbviewer](https://nbviewer.jupyter.org/) links to the notebooks:

https://nbviewer.jupyter.org/url/github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_96x96_411_outputs_i87_full_relu_post_decimation.ipynb

https://nbviewer.jupyter.org/url/github.com/Timo614/machine-learning/blob/main/birds/notebooks/birds_96x96_411_outputs_i87_full_relu6_post_decimation.ipynb

Want to run the code yourself? Here are [binder](https://mybinder.org/) 
links to start your own Jupyter server!

https://mybinder.org/v2/gh/Timo614/machine-learning/main?filepath=birds%2Fnotebooks%2Fbirds_96x96_411_outputs_i87_full_relu_post_decimation.ipynb

https://mybinder.org/v2/gh/Timo614/machine-learning/main?filepath=birds%2Fnotebooks%2Fbirds_96x96_411_outputs_i87_full_relu6_post_decimation.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",r/machinelearning,Z0FBQUFBQm0yeGI2SWJIc0xXUURUUDhfMkdTTXNWdHVnT1FiSm02bG1iakJLRWRHelNUeXVBMHBGMmZYTzRmUzhTclFtYTZXcldqbDkxR2pEQ0xfNXBrUkFuQ19lSmd2bGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2cU1qMzVpakhzdFFmQ0ZnSFNldlRvOW1TRXFoc3gyRl9ITDI0dWctTXlEajZ5MG5lUWdTQnNzbm1TaWVFSWJQTjE5MVdHdTNaTEJYRVFEeXR1ZFJoeWc9PQ==
"Dude what is NoPE. Please link to it. I presume you aren't adding a Jordan Peele movie to every training cycle. Though if you are, you're a lunatic and I love it.",r/machinelearning,Z0FBQUFBQm0yeGI2RmdIX1FiOU1EdmdTbHZVU181VUxpVXdSbnd0MEU0NXdHcTQ4Zy1ZNldfLTVEbVdLdE5IaHotNFJlZzFXM3B3S2ZBWFhLdVhaRS1zTDAxU1NJNDhfOVE9PQ==
"Yeah, OpenAI's papers and blogs are goldmines. They use a mix of real and synthetic data, with a lot of human-in-the-loop labelling. Transformer-wise, they stick to GPT architecture with cross-entropy loss. For RLHF, they combine human feedback with policy optimization. Check out their GitHub for some Python snippets.Here's a link to an article whch might help u!! www.rapidinnovation.io/modals/transformer-model-development

Feel free to ask any questions if u need more details!",r/machinelearning,Z0FBQUFBQm0yeGI2ZWVGN0c0YXBxMzctVGpzWGhZLU9FU1hudGhtaXJQS2d4N1pQSFp0RW54U1JUZEpzMlhXSG0tTkphWkotWjlDZDRJSXdyRzh4Q0Q1R2pkRFRzSF9sOGc9PQ==
"If you're interested in exploring a different platform, I'm an ML engineer at [Comet](https://www.comet.com/site/), and we've put a ton of work into our visualizations for images/video over the last few years, with an emphasis on performance. We also handle the migration of WandB data for new teams when they join, to limit the switching cost as much as possible. I'd be happy to walk you through the platform sometime, if you're ever in the market.",r/machinelearning,Z0FBQUFBQm0yeGI2LUZZaGQyX0Y3V0F5WU92U2dqWm9HUGc1N3RZOW0zMGc4eWkyYW9uTDhadjYwcG8xUnpqMHRBQkRpUmlmbXdoWWdzQzZnUTM4czhpZUdjbTVkQWVrQ0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2dWxtVVAzOEc4bmFmLS1SUElNZ1R3SHpiaXJlcXlpSHhLWEU4WlZxeHFHYjBLMWZ0YUVkWk1zWGFRVGR1ZFpoQUJRcU1iX0ZoMjVidmNlZmR2MVAzbUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2R1hCOHIyR294ZjIxVEhTOXl6ZnFqSHoyQ1M2N1NCeGtOTUlSWDNjNGxNLUdfWks5VU1qM0VXTkI4SnVmZFc2Ukx1aENLWlZ2VG9WaVFIYkp3T2tLdUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2RUhkSWR6aUVzT3huTWt0QnRWVmxmSDNvMTI0U29zSTA5WVVJVENFVG9PNE9SdUh6SzFRSVROMy1SazhQOGtZSkJRNGxibjVDSWJGbndlcFdZZnBMR0E9PQ==
"If you export your PyTorch model to ONNX, ONNX Web Runtime is pretty great: [https://onnxruntime.ai/docs/tutorials/web/](https://onnxruntime.ai/docs/tutorials/web/)",r/machinelearning,Z0FBQUFBQm0yeGI2SDlGbktjWWU0ODAySjdRZDQ3bHd0d0x2cG1aeWtQaVdnR043YXVHYkpJaGNOZTFXME02TWl3T0dMcG5SWTZmSTVUbFJsZ0ViazI1T1phdFRObjktZlE9PQ==
You should just use the standard global mean pooling (unless you're using VGG or something) but just concatenate your extra features.,r/machinelearning,Z0FBQUFBQm0yeGI2MWZ1QlpfTHdoQ0RCakE2TVRGZjR4RXQ4QzliMzNJeXBXal9qOWVQZkRjdG11QmhiRktBT0h5ZjNRS0NzZl94WjRTR2hNaXRlbmU5OUY3VG1hRVpQbkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SVFRNXR0bGZRUkgyd29jcG5OVFowcmFRNGswQTJ3ODBITVBtb1VXY3h5U1paMmctYmYyZkZoX2cwamQ3Q2NyRjFvZFBoZ2JOR21fTFRvMUstX1NjN3c9PQ==
This is so dangerous. I don’t trust me accessing my data at own.,r/machinelearning,Z0FBQUFBQm0yeGI2YmEzQUV2QVpFc2loSlcyc2pGQU9NLXRiQzQ3aVlFRTczX003U2w3VFZNOVVyNkdSYWhYd1FGaWpPUnZXYy1OQWZfcjFNZmlpWGZscWlSajdFWDBoa3c9PQ==
"Seems to simply stand for No Positional Encoding, just as OP said in the very first sentence.",r/machinelearning,Z0FBQUFBQm0yeGI2NmxVcjdZeV9hR2lxWlRBT2FPQXNRSXUzbnpOalpFUENQX0t0NlI2VDhvdndUZUVnWU1pM2hISk91SVgtVWQzSm1XV3B6NmRuRDVXTmdxQXg1M0VhdWc9PQ==
haha IKR,r/machinelearning,Z0FBQUFBQm0yeGI2T2pENWZMTzBQTnVnMFZtNU1ub3VXaHlYMVRvNFZwYWZ6UnBKY0pGcDM2R3hLYzVlLUFzVkVYWDUxOUkxNGE4SlVyMWxQZWp0bnJYdUpyRHRtWHptWlE9PQ==
I liked the movie,r/machinelearning,Z0FBQUFBQm0yeGI2RGJOaXZLcXNtSFRORFhKQjlPSXpDVWthUVAzUkhGbjJ3UTlXZUR4NHZNZ0JQc0pQMDlsZEEtYlZuaGNwZlVqdWhfbVQydjUxRzFKRHBBWGtSRjlHTmc9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI2UXp1UlVEMXN5ZjZFM1llM2VjRlc3MW9IS2VLRy1mZVJIQ00xQnFWU2FLMkUtOXFpd0xoLUk2ZFVfakFRSXR6c1JtQjlCMlNNdE1EbWhRMFNOWXhacnh5b1V1ZE1obm84RXduVEZNUENtTHc9
"We use Spark at work.

  
Databricks makes it easy",r/machinelearning,Z0FBQUFBQm0yeGI2M01YUFNISnlYY3JOSmNpNUxIRTNXcWVZNDBJUWtzaDI4bnlXcVVHVnZEVGxGaWxRZjJUd080TmxNb0F1VmlDUnU0XzNTNHdGbUx5QndObzhTdk1oQWVrZDdka1M5eVZ3NjRjQ1FLUWZfdk09
"Thank you. That 100% was not clear from the first sentence. Generally, acronyms generate ambiguity.",r/machinelearning,Z0FBQUFBQm0yeGI2MWJxczdYYWlDZHpYU3l3WlRLWTFVN3RhNE5CRVBET2kzazVXbzVLZDEwNndqZ1F5cVUwa1NrMnh5X2xqWWt4QXcwQnhHNXFSZEE3Tk1VOGhYcmpBWUE9PQ==
"Just came here to say that ollama rocks!
It can start up with the system, I just added a ngrok tunnel to start with it as well and now I can connect from anywhere to any of my models from any device! I just need to turn on the computer from any desk app when I’m not home. It automatically swaps the models, system prompts, context settings and everything else as needed and without any intervention.",r/machinelearning,Z0FBQUFBQm0yeGI2QlltWTlYdGhPbkcyMG9vVEswOGU4S01XTU5iLURYT2pXcUVWUEJLcTFuX0JBckVQcHNyTmFBMGVyQjVyY0xzSmw4QUkxc1FJT3oyaHlGTkR3VTc3ZGc9PQ==
Log scale,r/machinelearning,Z0FBQUFBQm0yeGI2cDB0UW9wNFhES1p5QWpKQ3B6N0NKZGJ3UXE2OXNkUFItV19DaFJfOEsyUHlwM3hmQzNaSU1iQklOSnVwWlVQZERFLXV3WDAwZjR3cG1UZzMwNVFnUEE9PQ==
Log scale,r/machinelearning,Z0FBQUFBQm0yeGI2R0FyR0tpTHB6X1lfcjlsMGkyQUFjcE5GbjlqUWNRVlFySFBVNGc0cUdaSk5rcU9yWTFyX0tWNksyWVRQWnVPUWIxWWstMW4xWVFyX1JWU2dxRlFGbFE9PQ==
Are you using tree based ensembles or a deep learning model ? If it’s the former like lightgbm then honestly don’t bother as the histogram based split approach will take care of it. If you are using anything else then think hard about some sort of standardization.  If you don’t have a lot of very extreme values then you can consider clipping them at either ends if necessary.,r/machinelearning,Z0FBQUFBQm0yeGI2UlFUaVhCT2ZjUTBmc2RmMGNISnQtYU53TGp5dEktdEh5RUVYalV1YlIyMkliMTRLbEtsZWJ6eUcyT1B6bHVCbEVyclJ1MHhyTDFJWEtTUDVPNGF5R2c9PQ==
I like the name 'Massive Array of Mixture of Memory Experts' on page 7 (MAMME),r/machinelearning,Z0FBQUFBQm0yeGI2eTBWSjkza0lrUWZwWVJWRGJsdlNsdXZOeFhwUFBTRTRUZldyMnhnV0VSRXVoTU9yNnYyU2JNY0puRktDdHFZM0xtS0c4SUlNdjVjSE1Qb3BRd2lxVWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2V3lEMjRKS2FEbVlhRF94NENxQ0dTVTdmNWtjSlRsTUxaTm5peWc4Rk02N3B6ZDNRdW94Y3pUWjdwWnVqb2VVQ0c1TzVGNV9YaWRBUWt1STZ3T0FaTUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2bDNiX3RmUE5odHhwLUFRSXloc1U4b1dCX2hpT2k1Y1F3aHRLaVloYjRxRDJiOGJybXhYZ1BfR3VXOHVDTzJ2SmhiRmdvZW90WE90ZnVTTTJWUHBoZUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2a2lkX092UUdqdGY5eEpLb0VRc3k5TFk0Y2lnZ3Y1VDF0Y0Rza0phbE1velMtc1RMdDcwc2Z0dTktM3JaOWl4OXpGWW0xbDY2MEJHS1NFLTRidDFyS3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2MGJiYXgxUzRONVVFY1ZsYXJtdTNpdDR5ZUhKVk1rOE1UdHFlX1JkMGRpSXZkMFhCSUs0QUhYYW1JakV1R0F1R2hyZ2pPMDg1TVp3aGQyMk9CLWszdEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2V2ZkQzRIa1BVbFpOVUlDbUg0YjJxNzdiYm1vZnFJNVZYdzAzR0tmYnhTT1AxVW1oLXlOZ1hDXzFpZmRUMlBIZW9Od3RSSkhtNEk3VEhFMDZuQVBrUVE9PQ==
Isn't a grokked LLM a desirable goal to reach? It stands to reason that a well performing LLM should have internal circuits that aid in its understanding of the input. ,r/machinelearning,Z0FBQUFBQm0yeGI2RHdDYVd5cWlYQ2FkLUdJXzRpejFUSVgxUU1GNkFXb0x5Y0p1Um9sd0dvVm9WbFR4ZVVQbzVMU0c1VG1QZVo4eFluNWJ5ZFhfZWF4a1haV2VqOUxzeFRSTVVEUXR6dEFEdjRGMjNZd05YVlk9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2akQzR0ptTzlOUDY2NzVCcUp6NG9nY3VuUFpYLUx0dncxMDRlUmNaU19rZjg0a3E0dFZDeFZoX0RFTVBEbWoxREJvaE5zNFJGZi1RMXY2SVREdXQxVWc9PQ==
Can you share your project please,r/machinelearning,Z0FBQUFBQm0yeGI2VmMyR3JSTGpWdVQ3dnRVb3ByV2w4RGpsWllkRnVWaC1VS1YtQ3lpamY3cTNCelg3bWZhMFMtaktyYjJ6eTBsWEhad0tpUnZQbnhmY2cyU0UxZTlwSmc9PQ==
"Yes it is true that the current encryption isn't the best. I wanted the better encryption method to be a community driven project.
This was always supposed to be temporary 
But this issue should probably be fixed in a few hrs",r/machinelearning,Z0FBQUFBQm0yeGI2a0pvSjlkdjBEdE5GRW5LMjFaSmY2QWtYdnI1dmdHNGtMVVlzMld2Nm5oM3c3TTJwczQ2RXZzeGVlc2tFRS1Kb05XN21TbGNUYkdleGQ3QzBDQTRPWVE9PQ==
"It is hard to imagine what you will be ""improving"" by finetuning an LLM using transaction data.  Maybe decide what you want the output to be and consider training a different type of ML AI.",r/machinelearning,Z0FBQUFBQm0yeGI2NjRNRmRVQUhCX0k5aDcwTHZVcW1mRWhxRS1INVVIM01CN2NCZTBGUDZoUTZDY0pMTXJkcXZTdWlxa2VHanFqUnBwd1pFWTVHX2V1QTdlclFUNUVER2c9PQ==
"With how popular LLMs are, its mindboggling how wandb lacks a feature for continuously logging text generation samples during training.

I'm aware they suggest using tables for logging text data, but from my understanding they are not designed to be updated. So each time you want to log new text samples, you have to create a new table.

And for some reason the [feature request of this issue is closed due to stale](https://github.com/wandb/wandb/issues/1826) , and the community is[ doing gymnastics to overcome this problem](https://github.com/wandb/wandb/issues/2981#issuecomment-1997460276).",r/machinelearning,Z0FBQUFBQm0yeGI2dXFGQ2lXYmQ0cmJwRTc5d3o4aFFraENRQlpzNWJTbk1mdkE2b1IydmJmdHZvMi1wWUVSUUZXSEVQTjg3THkyMGh3cWJvUURpLXBKbnJ5bWR4eEtzQmc9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI2U1VYc1dzNldqZVcxMG00c21UZjVnSFoxYzJKRkJ6U29ZVmlJcHNpN2RSTTJoaU96U1JBQVoyZ2xVQUtKOFVUZFJ0QlBseGRSZDN1T0R3YWNuVU5MQVFUVm1pY3JWbTByLVZZdVFaaTZRSU09
"""Mixture of LoRA's""

Or like, ""We made a Vector Database of LoRA's"".

Curious.",r/machinelearning,Z0FBQUFBQm0yeGI2U0t1RzAyVmFna3k0NW56VGxrbF96Y1hhNG1rMXpJUkNBUEF1Q1RnNDNKX18zUHF2cEI1UmJ3bEREc1ZWRE8yclpPRHpjQzk4OTdRendvZmNNdkt3ME04ckRLd2MzY1VTTnhyOHhGNGhZcUE9
[https://www.beren.io/2022-01-11-Grokking-Grokking/](https://www.beren.io/2022-01-11-Grokking-Grokking/),r/machinelearning,Z0FBQUFBQm0yeGI2aENIVE1TeXNxQlRobHhXMXVrZXhjQ0I2VklIbG9vekdWYmRTWmp1VWNxQXc3UXBmQldJa3NYX0JFRE9LcVZNa3pIUHQ0VHB1OW1PVGFnNTQwbWI5UHc9PQ==
"Feel some deja vu from this idea: having multiple LoRAs and swapping them out per prompt, but don't quite recall where I saw it. Anyone feel the same?",r/machinelearning,Z0FBQUFBQm0yeGI2Z3Z3d3BNV1FLclVsZU1GYnVaUncwX1NDa2ttY3MxQmRRWXBhajJoTWV1MzF1N2ZJVm1FRldkb2VaaUY3RW81Xy1ud3FkT2FHaHBrd3VqSmEzRm90QWx0N0YybXBoYi1FUmN2c19SSjF2dEE9
Didn't apple just announce similar thing on their keynote? Or are you being facetious :p,r/machinelearning,Z0FBQUFBQm0yeGI2M3U3VWxWbHAyR0dIRzNCcjdKcEF5T3UxTERjZGx2UzhVaUlpLUEzQUFlX3lrRlJ2VXVUMkVoS3BzNTFvbmFoNWdfdFFsRmx3R19zbW5XNEhYdG9ZYXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2czFqdkZXMzd4alN3YUd0djNsd3dwUWJ2Q1NBaml5R3FkZ2VFa05UdGd0R0pydy1yeEF0ZFBQT3pjVEtjSEx3djBydU1rX1ZfLV9EWGEzaVJCc3BIZmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2VFViX2xwZU9Zc0tRQTRmTlFkYTNwT2VyZHBUcFlRXzdZMEs1UVhBcV8tQldTeFFnb1A1a25BM3Btc3ZBWWtNRTF0cXNwNlhfb2p0QVVyeU9walhIU2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2bURrb2dJY05lS3hMQkxqQUI0enZnZ2NBR3h6YjNUQklBVUlYVm8wUVgwR3ZIcDlULU40YUoyS2p5dUlrMDhQQ2tGSkhxSG1ET0dJMEJGY3JWeU8xbkE9PQ==
it sounds like RAG to me,r/machinelearning,Z0FBQUFBQm0yeGI2TDB0OTJCdDVTN0VndTRERHRFN3d0YVl1dFo3aXJia0JrVk1VdWpJSzBkTEtZTHBZWVkxS2JoM2tTSlFLbk5sSjN3VmlPM29XZjhBRjNvVDVVYUFJX3c9PQ==
"The ** stands for power so yes, sqrt",r/machinelearning,Z0FBQUFBQm0yeGI2akJPRnhXZVlkMnp5NUMtVTczMzRxVW10Y0hGVE84UEhYTDdjdzM1TTRjUDduZUpxN2E1Si00dDZDOTExQlFiYjJ6eHc4Z05paDBzQ0RKeGhNcmhXYUE9PQ==
"Concatenate the numbers to the embedding after the CNN, before the MLP head. This is the most common way to add such additional variables, more commonly done e.g. in graph classification. You can also use embedding layer (linear projection basically) and concatenate output instead, to have more learnable weights.",r/machinelearning,Z0FBQUFBQm0yeGI2QWtFa091bFdVTzBlSzZqWlVDLXhqUDktaXRVMXZvRU4yRGZTa1FuMmJnRlppT3hvNDV2dkwzM09zYUVVY19NandwS1ZDOUxzVENlY3RhU2hlRXIxMGc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2V2Y3V250MnA5dGZfU1NaWk4xX2lkNGQ3S18xYU1DQVRzQUdOdmVadzVwejhpekRUTFRBU0JncmRjNTl1aTN1M0pUQmFGdWN5dThkbVU1NXZreE5iSkE9PQ==
Where was this claimed?,r/machinelearning,Z0FBQUFBQm0yeGI2RmdFcmR5eE1USkJTeVBjNGlYcFdPekVOdFBvTFRyZVZRMjdOWU05VUs0RXhtdTBfX184TG45eW5nbThGZUFKdkg3YVZxR3JyTjlOeUZtRzJWdXRFbXc9PQ==
"This is just RAG but like…with extra steps.

You 100% lost me at “(i.e no hallucinations)”",r/machinelearning,Z0FBQUFBQm0yeGI2X2M3M1ZudGZOR3dXOE1vZHhtRE1STVBqTlE2VE5aaWpLRVlwTjMwQVZLd3h3ZThsTmlGM29EMG8teDZyR0dZTWtNd0ZzcUZyckNuT29ZNzNYSE5kM1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SVFQM29DXzkzY3BDTDBodGxmTktJbDZDUlhlbllvSS0zdmhMMjZCeWRLYjVjRVdWdUhrVmRyZUdLM2h0bmpsdGRuOXM2RzRxR0tiak9CZ0ZCZDZoTVE9PQ==
"So, basically, they use a vector database to map topics from a dataset to an overfit LoRA adapter, then for each prompt, they simply search for the vector database using the prompt and then load the appropriate adapter?",r/machinelearning,Z0FBQUFBQm0yeGI2WlRfeDIyRm1aU3l2TFlWUUpkSFAyM29Fdkl5R2lySjIwWWwxTDkxUFN4aFBHMkd2V0NJNDBPc2FlZm5kQ0k0YnNoalNoeUJuYmZBS1E4cFlfSlFwS1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2MDBnUm13NThmR1dYSmQySEZ5bjhQVkxtclhBYW5rbWhyR0tyLTMwMzB6XzgwdWVnSmpuMUs3b08ySG1jVTBVZEhtWnEzSDVFYm5xRjByRlBWSmFBSUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2cDFQMW9vUkpnODR1Q1c3b28xSnlRbGNoQkZTRVp1OHBkc0JSYXBneHRZRW5sU3JNNFB2SDNMelFmb0ZvM0xDNlJmbVJ3R0J3LWFQcHJVWE93RnFlRHc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2ajVrd0lCLUdKWDZhMHRpTHEtSVlWYV9sYXJoX2hVVUl0dXFmdnZCQUJBWmJSQkswa3hvNWVHRGxNNGdfTzFfWEZIblo0TTRjeElnQnp2Q01TU0MwZVE9PQ==
It’s easy to mitigate a perceived problem when you also change the distribution of your test set.,r/machinelearning,Z0FBQUFBQm0yeGI2cmJ2bUo2Z0VHZV8zNUxQc0hRazUwVGd0X2oxNzltVUUxQjEyUmZISXAzeGJHcG1rWVNmVXdOd1c4Vktxb1FnYnM1Zm5BN0VtX2RmMGRtYzNHRUdwRkE9PQ==
Do you have good references regarding improving large language models with humans in the loop? I'm still a bit confused how models who needs billions or trillions of token can use a few thousand (or even a million if you scale it up) tokens provided by humans (before the RLHF fine tuning stage).,r/machinelearning,Z0FBQUFBQm0yeGI2ODJkVDF5Skk3T1NOQ0VwLUFaVFNoRThLaEVaenVIUldBUGYxb1JRd0xOcVBxTGdCOVhOWWUwQ0hpT2lUYnVzeXJEbDNxanJJQ19pa3Fta3pLNVdVb3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2NkxZNUduMW04VXhOQTBlUWN1NFY5eHB2SDhrUGF0enY2WE9mVmR1YkpzRDVDOUIxdmhmQ21JblVkMkY4bUxVN0tVUm53R3V1LWNyYkF0eWk3TGJldmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2a2RSTVEwaWhNWTRnODhQd25DcUlaNHd2QWN3S1A4Q3ZYRmw4TFVfY0VkZ2xoRmxxTmU3YWt1Yjl5Uk1xRE54X3VXZVVRelVKN2NBQjI3MWduOXEzRVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SjBWX3FhRjd0TXNRSUp0VWxneEFpMkg0Z1Zack04ZzFOZ0FNc3JoLUtWX1hTMU1STHN2clBqZ2NNdEVzMU56b0Z6aFZJVEY5YmwtVU5xQnFua3JhWmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2Qk1MX1A3bHBzUmp0eElvam5GZnBrRFBZN3JOTmRWVHR6WVFRUWFXeFVxR3dPQkxaUkZyQW01UktXeHVaQ013THhnbGw0Z3VrNTZVUk1VaHNPVU9vaUE9PQ==
"Some people saying just use RAG, but you could layer that too, if you want specific document references or something. But LoRA, especially with this approach, will bring in a whole bunch of related knowledge, embedded in the weights rather using up context. If I gave you a chemistry textbook and started quizzing you on it, you'll do much better if you've previously done a science degree, and internalized related topics, than otherwise.",r/machinelearning,Z0FBQUFBQm0yeGI2VFh6NkhtNlNtb1lqUnMwVC15TEI2c1ZuNmtqMDlkcDJqVTUteTFqMm1rSXFVMHFnUWNMUVNNc3pUOTA3QjVfNC1EUDhfTGsyQ0Y4REFaOVdUTEc1eWVIcmdPWmN5SDctenhpN2NKMmtJQjQ9
HAHAHA that made me laugh hard. I will edit the post to explain what is NoPE and link the paper in question!,r/machinelearning,Z0FBQUFBQm0yeGI2djdtSGRzMjFnNWU0eldxU2VnTTRuNlR2TFROWFpBTXhFT1M5Y1hMd2pZd3VDMk42ekxsY2JIMElQb1hmYTdVanpVT3ZsOTdWVWlidWctMVo3U1RxZTFvZjhKNlFyYlZYZlhMR1dNMG1QTGc9
"I don't have a lot of experience with MTS forecasting, but with MTS classification. Maybe two points. First, you can use Batch normalization, which can sometimes help. You also say “collected features”, for me this could mean anything. It is also always worth checking out additional statistical features/rolling statistics  that can be calculated for anything you collect (if you aren't already doing this).",r/machinelearning,Z0FBQUFBQm0yeGI2TV9aVFcyeEtRREphRE5hRldfX1hzRkdIMDZuNldsTHVxTGNqb0U1Q1ZrdUtVLThlUDY5M3VJYTFtN3BCUm5RTHNIdEpYMmpwUE93b292bEdVZklrQXJZNHdtbHp1d05LRXpPeGZERHRhdUU9
"It does not look like they use a vector database. They seem to have trained a cross-attention layer for that (plus maybe another layer, their explanation is unclear to me) making it more similar to a MoE.

Ans also, that's not your typical LoRA: when they train on facts, they make sure that the loss on the crucial token (like the date for a specific event) is trained until the loss is zero.",r/machinelearning,Z0FBQUFBQm0yeGI2aS1BbFh6ZnF2ZlYxcklUOVdNeUJOLW1vdHBYdEN6eG1GaUFIVnNLQ0JmZEtybkVsVXQ5TmU4ekNia0F0cUlNcXhzM00wQzhLbkxGZ0hSUUV5TFlyMUE9PQ==
"Scoring answers is actually not trivial: in some cases, a single pixel off may mean that one completely misunderstood the task. 

  
Self-play is also very difficult because of the lack of training data - and generating some kind of controlled environment is also practically impossible due to 1) the challenge of generating truly diverse tasks and 2) the impossibility of assessing whether a generated task is actually ""valid"".",r/machinelearning,Z0FBQUFBQm0yeGI2WFBuU3lMSk41eVhLeHpEZVNkMjF0VklvVFB6M19BczJ6SGVrZEI1TmxOc19aRy0wZWJaUnY4M05vX19rb2FIdDk1NU5salI3SEQtUl83R1p3R3BpUlZyNl9UNTdGd1p2NVI1OXVyam9uVVE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2ZFBNRkE2UXpFSUJRUktOVmZmYWtPZGozdFB4VGstSlBxV2Npd1VmNXc5UzBpY2FvR205MXZPZEw0U0FidVc5MzY4T3Qzd05wc0hjdGlWYkZDbDZfZ3c9PQ==
"Wait, this is blowing my mind

The paper seems to be saying that if you don't do any positional encoding at all, the model will just check to see how many tokens are in the context for each token and figure out the positions from that

There's a lot more to discuss here, but just that alone is already crazy. Like, it makes sense I guess, but I never even considered that might be possible",r/machinelearning,Z0FBQUFBQm0yeGI2a3NZMkI5a3NUWlg0VmROM0lCUVA0SlhybTVaclpJbWZUWHN2U1lfQkNSNkVjQVZZWUdBOTJ5NkpjcWdqUEtQQXRrOUw3QW9yWG5RN1YwUGpGWmNuVjk0Sm45c3FLWnozTE53UnpFWjNTdmc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2cTVyWWJsX2E4Um1KNzc4dTY3S1lheTBnbWN2MDl3V1NMdW5VMkZyYXJvRTh1QjQ5SkZDR29jZVNCbFRLd2x2a0JLRmV5enNpZkNEejdpZ1gwcWU5X0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2SjFDTU1pSDJDeHZrTUFjWGRyZnlFbWpyUkNueFBKbFJob0tscWpxZjg0X3VlOTdQLUVxM1RpbklpdkM5QlZCUkg0VUFMT19oQi1xS043TGlzRnVkWkE9PQ==
"That blew my mind as well that's crazy! Just an hour ago I had this question, if the model can figure out the PE by itself, is FIRE still relevant? ([Functional Interpolation for Relative Positions Improves Long Context Transformers](https://arxiv.org/abs/2310.04418)) Because in theory NoPE would seem better, it introduces even less inductive bias than FIRE and I feel like it's more expressive as well. (I don't have the theory behind to prove it though, but now maybe the network can learn PE for each layer while in FIRE they're fixed for all layers).

But from what I have noticed on the GPT-2 example, ALiBi does much better than NoPE, as you can see the perplexity explodes for 4096 and 8192 while with ALiBi it stays the same.

I've read a lot of PE papers and I'm preparing a blog post about them and unfortunately I found so many conflicting empirical results that I don't know what to believe anymore.",r/machinelearning,Z0FBQUFBQm0yeGI2bEpzT3ZnXzhudzlyWF9xb0JoUEFpXzhJcUdYV0hsaUphMW5GSzVvRTBkbHFmZmRsdzk3R2xtajQ3QTB2c1JIU010VzBoWS1WM1otODBoQjNwZnp3WFRsTkJjQkVnXzFoWUZEZ3pBN0JCT0U9
"Oh?
https://thehackernews.com/2024/04/malicious-code-in-xz-utils-for-linux.html?m=1

Open-source != trustworthy

Also, Microsoft has a lot to lose if it's (enterprise) customers stop trusting it.",r/machinelearning,Z0FBQUFBQm0yeGI2cC1UcGw3X2M0QXNuYkZCTFhqTWVzSVFaSHRySXJFR1lkYTVPMVFoV0xOMEdPTjh4VWV3YU11dUpENHNlcmRiZjNmMUZrN2dQZkhMWGFqaGhndlBQUUE9PQ==
"not finished and not published yet :( but also, in the report there is really not much more info other than ""we do this trick and it seems to work for our experiments"" plus the comment about the bayesian interpretation -- the focus is not on NN training, it is just a means to an end. 

intuitively this type of loss scaling really just corresponds to telling the optimiser how much error at each label you're willing to tolerate, and how hard it should try to improve the error. If the error you're willing to accept scales with the magnitude of the label, scale the loss to reflect that.",r/machinelearning,Z0FBQUFBQm0yeGI2R2lEektZR09tWWZ1dUhEblFWZzg4U29haU9XbEZObEFFcHVvcFFpY0xzREVUWEpDVGNackpOb3l6SWNoSzczV19ta0N2S1M4NVRWUmRjbnp2aXRiX2c9PQ==
"At Alltius, we are not only answering questions but also finding them from sources of choice in communicated in a medium of convenience (e.g. widgets, web apps, APIs, plugins and more). Read - [https://medium.com/@alltiusai/llms-for-fact-finding-how-can-businesses-trust-language-models-5272633bcfdf](https://medium.com/@alltiusai/llms-for-fact-finding-how-can-businesses-trust-language-models-5272633bcfdf)",r/machinelearning,Z0FBQUFBQm0yeGI2WmF4cjJlb29oVEF4WXQxckVwN2VBcGtSVU91UTdaMzRtN2M0NDVPV3JWdzRybXFObmptUXV6dXU3QXhjdnlCekxUMjRFcmd6LVpJLVhNUlB6M1FZdUE9PQ==
I would look at making the timeseries stationary. In this case you could predict the difference t0 - t1. There are a lot of articles out there with additional tips on this topic.,r/machinelearning,Z0FBQUFBQm0yeGI2RUhDTnpZUGNEclplZDljOGFDUUJQel9Za1F1c1I4WExoUzA5U0Q2Q3dBYmNFcHdYZFdYdXZ2V19YZ0c0Wi1BNnhUMEIxMmoxeWhKbFIwU0RqX1RqaWc9PQ==
"Closest one to me is Prompt-based continual learning (e.g., L2P) where they select an instance-wise prompt from a prompt pool for task-agnostic inference.",r/machinelearning,Z0FBQUFBQm0yeGI2WTJoQW9xRFpPTlpsaDQyM3NIbVByRlZmWTlzWTBPaEFjNEdwaTE0WWhFdDJYUXRqOWNlX29hV3ZtZVI0eTJTc1F1TTNKT1lPcU5tTEZ2R2ZqQmY0UVE9PQ==
This is the future really...,r/machinelearning,Z0FBQUFBQm0yeGI2ZFRCWFlfMmRrT3FXQkRBRnoyUlR2RnlZYXJOeG1WSXF2QmVxajhQSkhzTWhOWjd3dy0tMWNpblY2V1F4Wm1mWDZCZWR6RS15OU9fcURfc1RxUDV6NEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2N1Z0M0ljRjNYelhKSFpWUkNGdklwY2JUdHVjYjJDeUxuay1kWElrRFNmNDN1QmZYWlFkZzkyNmlTTW91RlNKc2luRFNyZjFWNExjTFN0TEdrSHdmWFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2QXJwalp6bk00bDUwTmduOU03NXBHSEk2b0wwdGw3UXpaUjNYVGtBNkFhMHVEZmRxVWVhNi1Tb2FRMHR0WmFUR1k1alpnLTlLN25iMUljb0ItYk5YZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2M0pRRnJuNURqQkhkcktRalR4cGRULW9uWjNSdE4zbHhYSFJlN3RBOGhLVjA5VWJjU0NPM1Jjb2ZpT195MUVOQjlITVhtV1RFenVBdnFGN3dlblB5WFE9PQ==
"You know what happened in that exploit right. It took 3 yeas for a guy. He had to spend so much time, the code was so complex that compiled code could actually enter the code base.

This project will never be that complex and frankly it won't be that big. So you will be able to look at the code at all times.

At the end of the day, it's your choice to make",r/machinelearning,Z0FBQUFBQm0yeGI2dTdOcy1SMHdtS2hPSDZCd1ZtOUtFWnUxbzI4Y3FqTElGQzQ2UnBlMjZ6S1RPQWh0eXZXU3c2RTE3Ykd4NngxY243TjRLV3dIT1h0azVCX0VqeGlNZFE9PQ==
My experience with forecasting is that feature engineering REALLY matters. You should probably start to look at interesting relationships in your data and convert them into features,r/machinelearning,Z0FBQUFBQm0yeGI2Z1JmbVQtTHd6WDd5WVNIZkRac3B3cTNlc2tNLWlER19Eb25vQzVTdGVNek45emVGc3BXbFBkUG9tdm00MVJYdWRTTzNVSnItRzEyUW5QaVJNVm1PMVE9PQ==
Yeah but then what about your Lora adapter.... ,r/machinelearning,Z0FBQUFBQm0yeGI2S1ZfWlhpclJWY1ZVS2xLYXVNOENpNGtUNUY3anNBcHpKVDVfejg1QTRJdjdmTE8tVzZiLWhEbFJkVjBtNnV6eEw1UW5QRDU2NlRjMzdiS1lOWFByRkxDOE9VSWoyTzBMNVBEUV9XU3IyUjA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2Sy1lRm16X3VzOUc5NV9uX1hjUW9DZTh4YWk1V1VZNlE0R3ZWeUhiVUhLODZXTUVQZlJkc3RXTWZPYUEwOHNhSFFLUEV3NnVDUVpudHlIdHV1U3NyM0E9PQ==
"Hi everyone,

I am trying to build a long short term memory model in Python, with the idea being to predict 9 components of a rotation matrix from linear acceleration (x,y,z) and angular velocity (x,y,z) so 6 input variables. 

I have used standard arachitecure found in the literature which does similar things to my idea. However, the model is not performing well at all and is subject to overfitting I believe. 

Does anyone have any advice on how I can try and improve my model?",r/machinelearning,Z0FBQUFBQm0yeGI2RnJRT1NIaEp1Wk1CYTNOVkVhQXJpanJGbElwaVJidkpCRVNiUEI4cWxzc3hxT25LX1JWalhDa0E0SHFYUmJLVjkxR0xiSV9CQlRaVFY3R19yRDE3OVZhcUR1akNOUWhLLWtoYVBOdHlHVms9
"Random paper which seems related that I liked:  
https://arxiv.org/abs/2405.17399 compares against NoPE and FIRE. The paper is specifically about arithmetic, where their method (Abacus) does better; essentially giving position information only for digits, and I believe using NoPE for everything else (though they also compare against combining Abacus with FIRE as well). Abacus does seem to generalize better to long arithmetic than FIRE/NoPE by themselves.",r/machinelearning,Z0FBQUFBQm0yeGI2ZVpSYVVvem5MeThzV2VvRVVvQV9weTZMNEkyWmMyNjJrNDMyb0V0VURFdnNYRkE5TmF3VWZkYUVVZzdpUWxGODRLYkRhb3pWejBqa1RpR1FxaWJBNFE9PQ==
"I have also used wandb and it is very helpful in model monitoring, and model registry...it simply helps a lot..",r/machinelearning,Z0FBQUFBQm0yeGI2ZzQ3UmE4SnJyZU1QeS11RF9ZdUpIaUxyV2U2akxQbTlBbXpudDVVTXFvRll2LS0wMHNDeUVyVE5FQ1RrcFM5ZmdHN2VPRHNObVpCM19rQUJvZXlveFE9PQ==
please help me [https://www.reddit.com/user/Pristine-Divide-2034/comments/1dfnry6/what\\_are\\_the\\_hot\\_topics\\_in\\_machine\\_learning\\_and/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/user/Pristine-Divide-2034/comments/1dfnry6/what_are_the_hot_topics_in_machine_learning_and/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button),r/machinelearning,Z0FBQUFBQm0yeGI2a3RkU0FGcVl4ejlxbmc1emUwRjZIaUV1cEY3UFhYajVYMHdoeDVUX2I0dzlGcnlrUFcxMGlBTU45LXZNQ0ZUQjc3TGQxcktPV0RrV09iM0ZUcFdzQUNDTnk2SXJlS1ZZOUZjbWxwSk9jblU9
I wonder if this is going to create a combinatorial number of new ways to jailbreak the model that will make it that much harder to identify and protect against,r/machinelearning,Z0FBQUFBQm0yeGI2cnpVUEgzQV9IdnRHd1c2d211RDFTUDZNMUEzTkU1NXdJRFVidlM3Z0JtZlBkV19YREltOVBoZ3hRS2tZdGdBV0hPUUZPa0pSblpTRkhBTzh1bERMZkE9PQ==
That’s only relevant if your data has zeros.,r/machinelearning,Z0FBQUFBQm0yeGI2SF9OcUgySlNwQlpuMkl2R2ctZmRSTnRMamxMYkVhMFdVU1hOMW1iNmZ4SXlCQjlJcnlkQVVGTi1NZlluLVY0eUJ6b3lNNW5JOEp4RkVIMngzREEyaUE9PQ==
"Sure, will do. What analysis do you usually do to understand what features to use and what metrics do you look at? 

I generated mean, std and sum of all the continuous features plus ohe of categorical data to generate a feature set of 130",r/machinelearning,Z0FBQUFBQm0yeGI2VGhSZGcwcHpHTk1OaklxaVRXQzl4SzdhOENNb0d1LW94aXU0MTRheEx1cHZHWVN4QTFNd2lXdXVTZHBpSGZ1VkpFMENnTVlab2JHQ25NY2s3MlhlNkE9PQ==
Good.,r/machinelearning,Z0FBQUFBQm0yeGI2LW5zXzByTm5tLVlkWmRlM0J5b2VseWV4Tk1BTEpuT0xYTG1vcDUxMjg3RVlBM1R2ZW5pTGEwd0FybjRJLS1fSzRCVzV2VmswdTNIenFPTmR3N1FxQnQ2dlVjNjhueENNNHpvcnBNNHQ5TTQ9
"Well usually it's domain knowledge! Seems like your ideas are good, but maybe talk to the people in your company who works with late payments and ask them for what they look at and maybe even some new data sources",r/machinelearning,Z0FBQUFBQm0yeGI2c0s0VlJaUjd5X2J6YXZqSHk0dngtd2QteGZvV2lYTDVuTzJpNDY5Q0VZcUZtbXA3VURkS1FfY1NqQ3Q2MEpQOUZJSUJvNkk0V1F2eTB4TjBZNnNXN0E9PQ==
"sure, don't hire them in that case, there will be some place where they will fit better.... I did say that you do need to go through that stage as well. So if someone who is stuck at stage 2 vs someone who is in stage 0. One can still take there help, if they aren't really needed then why not just hire non-phds. Maybe in my company they hired a right team for right projects.. Anyway others have already commented in this thread they their company is firing ML researchers, so it will all be adjusted I guess... Getting rid of research is nothing new, a company only invest in research when they are confident they will make strides and would like to get a hold of future tech, most companies just copy from few companies that invest in research.",r/machinelearning,Z0FBQUFBQm0yeGI2dU1OVHZaU3NXekFZaEl5QThpV0VjaWhTMkRsYkpUaDdCUkNYQTlLZHVqcVlLOUdrSXMzZkhEeXNwcnY5VUZ4ajlUODdaWVJLUEtqOW1HWVp2Zk8zU0E9PQ==
1. ...e7 - e5,r/machinelearning,Z0FBQUFBQm0yeGI2UHpyUldzN2gxcU8zb3pvQU1tSE9EV1h5MGZPYkFxeUpESW5kY0M3eTRVYjI3YW5Ia3FpT21Rbjd0S2ktS0VUOVBjOVJldlFFbkhBNzd6Tmo0alJWOVE9PQ==
"This kind of stuff - retrieval of actual weights (instead of text) according to recent context - is a big part of the future. 

There are two reasons both with a huge impact in lowering compute costs : 

- it allows a huge number of trainable parameters with a relatively small number of active ones during training and inference

- unlike RAG, it doesn't need excessively large token window to fit all potentially relevant documents 

  
I wonder how useful would be applying the same method to continuously fine tune on conversation history itself. Like some kind of agent remembering all its conversation history.",r/machinelearning,Z0FBQUFBQm0yeGI2WmVvT2FSTThzVU81VXpxRUNOR05EVWVicWFDVTktTTNBMm56S3N2eXNzV1pyZnM2MUEtZzhPQWQzWUh2NXBwMUZBRFhRU056NWtBX1hrc29kYkxlLUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2VUwwWGNrQ3Z0QzJaVXlodUhrX193QkxQZ01zYUE5SXNqWlBXbTAyYlc2UzQ5TWNuOV9Kc0k5Z3JTbThCVDFDRnBiSTJvSVkyRmt6ZlEwU3VCVl9pT0E9PQ==
"I don't seem to understand how the late payment problem is a time-series one, I'm definitely missing something.   
  
Anyways, I would say these are pretty weak features. Perform a thorough EDA of the variables. Density plots can shed light on whether you can maybe split a variable or transform it, e.g. if there's multimodality and some modalities seems to be associated with a label, maybe create threshold variables or features through clustering. Also try some decomposition of the variables to look for seasonality and trends. This can be used to create new features. Lastly, some features may benefit from other transformations like low pass filters (if the variable shows high frequency fluctuations) or smoothing techniques like moving averages or Savitzky–Golay filters. 

In any case, once you do this you are not guaranteed to make it better, but it's definitely worth a try. You would have to perform a thorough variable selection after this, to remove variables that don't contribute towards the predictions. This, on top of the whole hyperparameter search.",r/machinelearning,Z0FBQUFBQm0yeGI2MmloNDZlODhEa3lhakY5Tk1qbWVQeVBaLTJKSUl6MWJNeUFoYlJZZUZCaXZsVm9rVHVCNGdJNTc2NVEzd05EaS1LejlUUGhsMFNLXzBTM0pRNDRINENiME9VZHVRM1dyaXVLcmNvLWNNU1k9
anything you don't like about it / features you wish it had?,r/machinelearning,Z0FBQUFBQm0yeGI2RHhLeWNac09Pa0xRaDQ5RXpaUGUzZ05XTzIzVlFVTXNjc21VcWUzTGl2Rk9uMVJDTmJrWlMtSkV3QUtiaFFORUxsTThXMG1kcVVEamhHbEcyc2hYY2c9PQ==
if I can use it locally in the code editor as provided by DVC...it would be great...,r/machinelearning,Z0FBQUFBQm0yeGI2UEhpbUE2QUY0ZTB1RlJhdUZlRk8xbHZoWDFwNTQ0TEwyblM4aFpYNW4yaEVjcFlVdnNrUExKUWpjZ1lYMi1RQVIxWGpMUHk4TXFVVWxHSlB4TFN0alE9PQ==
"No, the log transform is also poorly behaved around values between 0 and 1- it has exponential behavior there so it blows up the target variable's loss around values that should have insignificant differences",r/machinelearning,Z0FBQUFBQm0yeGI2UDZEUldOVWhwU3NJbndON3pZSkcxLW1XRHVzOGMyT2RCNVpYMWh6WUxuU2lURjVBNzNJVUxuekhKOEJJeWVseUg3UHM0ekxCdnhjZHdfZzFTR29ybkE9PQ==
"why buy and set up your own? [hyperstack.cloud](http://hyperstack.cloud/) on-demand pricing starts from $0.30/hour for RTX A4000, you only pay for GPU time you use, billed to the minute",r/machinelearning,Z0FBQUFBQm0yeGI2Sjc0QnhwREZVVDR5d2Z6d1E0allST0x3UUVwemhBbWM5QmxSWk9xRF85dnczazBkTUpVb3RnWXFrZU9yaGJ5eDJ0ZkZZa3E4OTBTMXp6a0lfV3pmNjk0TjROSmhGRlFabnk5bUF1eFRrVE09
"I'm confused, what answers are you hoping this model will answer? 

Because unless your hoping to generate nonsense transaction data or expose accounts and PII, I can't think of a use case that would not be better served by a regression model or a SQL query",r/machinelearning,Z0FBQUFBQm0yeGI2b3pwTjBUOHZ3VHVBUHFRbl9CYkJkemg1MDdEQlZjbm5uN1RlYUZBeWE0azJwUmhSWTRqUjc3RWFPOUtWbTJ1YlZiZGFpNEEwSkZtZU9zSVpEcTlWTmc9PQ==
Link?,r/machinelearning,Z0FBQUFBQm0yeGI2aVpaWGpZQmNaQVppdkE3a2NwM2dvS01yemNDYUpPa3hPNTQ3UVFyY3JvWHdWY1hoX3FEUWZFcy1NMmlsazBzZ005UTZwQmx4anNjX2s5YXJ5Vmt3aG80cU04V2RCQnR4ZF8tY3lUWi11Rk09
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2c2QyQmFZRE1Oa0xBSEU0bFlYUWlWdWllR19POHNWUlVmWWN0ZzVWb2R5TkxNdlN0RDk2MXRSdUd6VUM4c0tzQjBqeWVlbEVPNzFXNnhpMDJNak0yVmc9PQ==
More data & more electricity,r/machinelearning,Z0FBQUFBQm0yeGI2WThseVowTmRvSHFwTXRqZUJRWEUyUHUyLVdNa05pUUltcWR1RTU3SnR3ajdPckZFUTFaVS1kZGZxY2ZlbW5GZ1dfbDJhN0hQZGlQc2FOakhET0cza0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2OFJENzBXbG5VNFhXWW5BeWtWNW1NRUhqanVhUzkxdE8zMndnaVM5S1JrZWJNYzNUSzZFYW42YXRya2JrU1B5UlBjTUJleUdXZjJDNzlRRTc1Y3gzbWc9PQ==
"We should stop using the ""omnimodal"" term. If your model doesn't has ""masked smell modeling"" or something like that it's not omnimodal.",r/machinelearning,Z0FBQUFBQm0yeGI2NEtJUkJCd2tSeDJkT1VnbHI4ZVhKWGY4NDZIT3phdWNvbk93Vk5vN0pGQndTZTNSdDJybGRHemlneUJYTnNMY3owLU44THJvN2NCSHAtbXNENG8xbFE9PQ==
You should cross post this to r/localllama as well.  I’d say it’s relevant to both but you’ll get potentially different and equally interesting discussions from both spots.,r/machinelearning,Z0FBQUFBQm0yeGI2U1RmdThKazN2ZV9NLU5GcVltNXdMVDVraHVvMjlKRFRjWUdMckZEbWFtZHdCd2kzTVQwaExKTDhWTFFrdWktbExINTg0VXRzeWlBMnlfMURtNjY1LWc9PQ==
u/sobe86 so how are you doing it today and what was the use case?,r/machinelearning,Z0FBQUFBQm0yeGI2LXdRYksydlhuWmVsdWNuQnE2dlhicnlrUXg5YXZXb0RfNnFNckI1RElDa0I1T0RqZWx4X1hSYTJXWk9Rc0hhMG0wTGFEUzFwR0F1bDZOUEVLeTdVSHc9PQ==
Appen in my belief is better for crowdsourcing for language translation kind of services that too at a very high diversity and huge budgets to the north of 200k+ USD,r/machinelearning,Z0FBQUFBQm0yeGI2N1hYeldPQ1B1RS1rbG9xYzZpanNGblo2T1liQjc1UG03Qmh2RUxBSkNLXzdWRXlxWVRZWGE1aTVfSFBDSWMxSVhXblBMWTY4OXZCeElUX1pSa2R0dWc9PQ==
check the scale AI alternatives especially for budgets under annual $50k projects [https://www.labellerr.com/blog/6-best-alternatives-for-scale-ai/](https://www.labellerr.com/blog/6-best-alternatives-for-scale-ai/),r/machinelearning,Z0FBQUFBQm0yeGI2d2JiYlJRcjdZRVlEX1hHWndIRERNMTZjM081dll5OWpxV2R4LTk3ejE5bDVqRVZwRmQ4WWVTamVxZWY2Uk1xdmx3WEQzV1BWREJyelhjcFRqZ3FJVlE9PQ==
"The article sounds like it can only handle a customized list of hallucinations, and their workflow diagram shows that the final generated answer doesn't even use the trained non-hallucinating model. Does this mean the application is limited to client searches of a small database and cannot be scaled to a large flagship model to limit general hallucinations?",r/machinelearning,Z0FBQUFBQm0yeGI2M1hJYzlYeTV6a3diaXJiVE1jQmZKbmM0RExsbW81bTRTN3V0VWFWQVpCaS0tb21GVWtMWkVEU2xQSnB2V0NKYzJOYWN4UTRJVGppQVdORWVld2tvMmc9PQ==
"> Say, how many lines of code the LSTM in question should be?

It's one line

    from torch.nn import LSTM",r/machinelearning,Z0FBQUFBQm0yeGI2cERoNHI3d3lCakwyR3d5bHhvUHloSERYVmVqSDJiODFZbGVtbm1Wa3k5WERWWFpMMTk5R1RJRFJKaTlXRzdVYTdGcFlJdFRQaXJ2RFQzRHl5TnNDX0pUcU0yNTd5TWRod1hVYUF1NkxNaTg9
"You should choose Udemy, which is far cheaper than Analytic Vidhya. If you are interested, you can through some of the blogs I have written for my company {Paravision Lab}.",r/machinelearning,Z0FBQUFBQm0yeGI2NGNGZXJUZzlIX1o3dTU4dk01MXUzU3F5ZC1pa0VNT19vZnFrVEtuRlNOQnFGMS1JSlJudlZNdEFiUHN0RjRvbkVlYm04a1pnQ2RRLXMxN3ZRblRUZVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2cEIwdElJaDYyeVlFVjN4Sl9keFVuSVdtZGtQekU4SE5jZlcwSk1WZUU4NGh1QXBhYzhnN3VKWkNwc1MzaWlOVTB1YkFDWjU4MG9yTlhrbVpaZW45VVE9PQ==
https://machinelearning.apple.com/research/introducing-apple-foundation-models,r/machinelearning,Z0FBQUFBQm0yeGI2NFFWNHZ0SjBlWlBIWERydjdEUXlWeGRzVkRnWDdvN3pKSGhwTEhDZlNLUXRvNjN6bm5oWC1rT29OTEhBc1JwazhuWGFNeElQRDEzNHJxQ19PaVlaN2c9PQ==
"Yes, posted",r/machinelearning,Z0FBQUFBQm0yeGI2alNNSkxSU0FFUnZsQlR5dURtN1dqZFFWVWdaczBCX3pFekxUSUl1X2w2V2tjWm9rSDZzNnI0aG9EUENoRW9yTUVqYTVHTDlfc1JzRXd0Zk5Wbnc3RVE9PQ==
"Fascinated by the project. Why did you create this?   I'm a senior dev and speak nerd😁 These are serious questions. 

Is there anything to stop Scammers from utilizing this tool in order to recall financial or credential details? IE.( What was the username used when logging into my bank website?) Gain trust by having historical and Intimate access to a victim?  
What models are being downloaded? It's not in Readme.md

It is the our elderly, ignorant, and children that I'm worried about.  You need to add safety precautions ASAP or your code will hurt people.

EDIT: Don't take me wrong. Please... I'm very happy you started an open source recall repo. It's the cybercrime syndicates I'm worried about.",r/machinelearning,Z0FBQUFBQm0yeGI2WnV6REdodjcydHJ3eUw5WXViLW9VVE1ZUUZvaGdidVU5ZEFPTk5uM0hyMUtrSWtzN3pUaTg5em1aTTFCX0lxMXozZ0RHMER4eEk0Z0RzNTZIVmc0SXc9PQ==
"Thank you for the detailed reply. The problem is not exactly related to late payments; I gave a random example. The idea is to develop a macro model that predicts the number of certain events per day based on aggregated daily features. Given that the transactions number in the millions per day, what other methods can be used when aggregating data for the day?",r/machinelearning,Z0FBQUFBQm0yeGI2RTNyeVI2dzQxcm51eTBoWFctTDFiQV9rRUZXMmJDWFJwZmZCZ1ExcUlxaUp6RnJIN2NKSUlPb3NhR292cTZqbWtoeVNSTlVpOUNtVWxPUFhQeUVGN3c9PQ==
Grouping queries from the user? I fail to understand how that works given it’s on device and therefore the user is only going to be making a single query at a time.,r/machinelearning,Z0FBQUFBQm0yeGI2UWVaS0NVZWJRUFloOXQ4eGZJMmxPcWZMWGxhQ1g0dG5vR0ZkUTJLYlQzdVRGZl83WHI5dnNCV3U1Um5FNEtvSXl2VzQxVVNXYmIxQ1hvMHlFVUNHLXc9PQ==
"yes, when will we have ""context to LoRA""",r/machinelearning,Z0FBQUFBQm0yeGI2OHJFWFJDcGF2SGVUVlh5MXBRN2dFRHpLRHAyNXRXd3JPMWJXZkRLcUtNTXlOV2lLbzg0RnJTb2lvdW5KMFlGeWpmYno5X1lITVluTFpSc1Y1Y21WQlE9PQ==
"Maybe? This is probably generally true of Mixture of Experts. The near future of guardrails, safety, and alignment is probably activation engineering, though. That might even be easier with Mixture of Experts because you can train an auto-encoder on the activations of each expert instead of a larger network.",r/machinelearning,Z0FBQUFBQm0yeGI2Rm9ZY05OX2U1UkJnbWVIa2VvTkhPcEJsRDltZkNOeHN6U1picjJ6NFE1bGJxMlJCZTN1Wlh5emJEQV9qQkNkdWFqLUFNdktKS2ZnblhLTUhvVkpiR2c9PQ==
"Thoroughly endorse this effort. 

Looking at code to help when I can.",r/machinelearning,Z0FBQUFBQm0yeGI2VWFiTWNtSTBRZzlhVE5zcmhiQlBjNlkyTjVuVnR5NGF6bWlzd2JyQkllWmk2NGx6OGxhWkQxYXdqcnVlTS0xV1AweENwT1dQV1JlLUhwV3N2aURhSGc9PQ==
"Best comment!! Should be  up vote!! 

Doing it open source is best idea!",r/machinelearning,Z0FBQUFBQm0yeGI2ZkMxQldDRHA5N3BrSE1jWUFjLTBLYXhsYWxVNVpHU3I4R0VENEhDT1ZoZGhZTHZxem8wb1J6QjJ4X0duU3g3N2ZTUFhoS2ZhZUhvUWw2c25rNmFKTVE9PQ==
"It's in the attention heads. So less K and V heads, so smaller KV-cache and less computation to get K and V",r/machinelearning,Z0FBQUFBQm0yeGI2TmgtNXFNZEhERXRHc3NQSm03NS1Edk9RMHY3eHVTYk5zU0Jha0RFT0c0WHBieGlsbzZBZkZ6VTV0ZEFSbnV2bmViczhUSi1KWHhVRndfTVFrX09tSk1UNi1uMnR5cndxS1ZMQWtWZThOanc9
I'm finding some of my answers in other comments. Don't need to repeat yourself. I should have read everything first.,r/machinelearning,Z0FBQUFBQm0yeGI2Skoyb29FR2UxRWtTZVZKWlZUTHJWZGZrZWhkX29fOGtUUVhMbzdfZ1I3d2c0Y2pOWXdiZ0ZIdG5TdDVpek9NS3dWYUVnWDdHMF8wZTFKTHBrVG94VWc9PQ==
"I know this is an old thread, but do you know if something like this got made over the last few years? I'm looking for ways to compile AI models into statically-linked dependency-free binaries that can be run with input for easy and fast inference.",r/machinelearning,Z0FBQUFBQm0yeGI2WTMxaXl2RDVZWE81R0hTc2tRa01hZVV6aXNFcmtVZWZheHRobUIyX2pLblhzb2drR3FBdVdUUWtlWE5Gd2xGbmZwaFBrRmlwTmtFZGVsMGc4anJRYmc9PQ==
"> Shared Vocabulary Embeddings: Honestly I don't have much idea about this - I need to understand it more

Likely refers to using the same weights for the input and output embeddings. See https://arxiv.org/abs/1608.05859

Karpathy also talks about this in his recent GPT-2 from scratch video: https://www.youtube.com/watch?v=l8pRSuU81PU&t=4122s",r/machinelearning,Z0FBQUFBQm0yeGI2RmJfQS1FODN3TjhSZVBpSnF2YnBnb3l5OGZyWFVCeG13aG9SX0ZSM0lQdlZEcDVaNWs1cWJRdlV0T3RMNlNHR25VNi00Ukx1bFJrT0RGV0tKenJ4blE9PQ==
"Hi! Does anyone have a precise idea of when exactly we should expect to receive the reviews for ECAI'24? According to the schedule, the rebuttal period lasts 72 hours, from Monday to Wednesday (AoE).",r/machinelearning,Z0FBQUFBQm0yeGI2UjNXd3Y4MWt2Z0V6cmViMG5kdnNJaE83VUxlWUdJaE9zNVhrQ0hRYkgwTmRCVzV1c1NtYk5aZ3NpRk5jVmZXVjA0X1c0VVdaYXVIRkJpUlljWDROUGc9PQ==
"Seems interesting. The performance numbers don't make a lot of sense to me, though. 50% accuracy to 95% accuracy seems... Very low on both sides?

I have evaluation suites for my agentic AI features. They are faithful to the data they retrieve well over 99% of the time. The failures are almost always from a) difficulty mapping the domain they are retrieving from to a tool and a rendering format that will help them succeed or b) some hallucination or reasoning failure unrelated to the data retrieved.

So:

- 50% seems like ""sub-RAG"" accuracy
- 95% seems like ""sub-RAG"" accuracy
- I'd still have to be able to render my domain to the model to fine-tune it, so I'm not saving any design/knowledge work, just moving compute to training time (with positives and negatives)
- Lamini doesn't appear to solve my highest-priority issues

I'll keep an eye on the project and look forward to seeing use cases I'm not thinking of, but it looks like too much squeeze for not enough juice right now.",r/machinelearning,Z0FBQUFBQm0yeGI2bnVCNTJDVkxkaWVDbTUxeEZUMGdhcUhyYmpDZW9yN1Y0clBLUUZlM3ZuVFlSOHhGaE4yTjlzNE82VkgtTzdyN3A1YnRzSHhENWdmblltYTJZM3ZqdGc9PQ==
"With the most recent advances in AI, what is the best way to learn how to pick which ""flavor"" of AI, given a business problem? Does it still make any sense to use any of the traditional ML approaches, especially the non-deep learning ones?",r/machinelearning,Z0FBQUFBQm0yeGI2TlAxV3FmRW1rQk9CNm1aaWJJSjFXcHJobXhxQXVVQnVLOHNzenF5WkVNaFRULTBuYUpscF82b2t5QWp4eUs2bnNnQjF5RWRBWFFFYWY4WEJwR0xWMXc9PQ==
"Try standardizing/normalizing the data instead of log scaling, worked for me in similar cases.",r/machinelearning,Z0FBQUFBQm0yeGI2VWtVVkpZTmlxcGotUVN1LUd6T09vTk54RVlfdVMtNm1DWXB5S0pPaWpFZjduYmdER1Ntd1lCb0xjdEo2SzVCQjhHZE9QLUhDRlNTbUlHRi0zMUsxMVU3OGE3NTd6emloTWxFdnM3VU1vemc9
Have you considered using a multimodal fusion approach instead of projecting to image dims?,r/machinelearning,Z0FBQUFBQm0yeGI2ajJqZXVtVWtQWm5qbXJOMDlia3JfTGZ4cmpqWkhTekthX0Q4eTNFNmhRUG8tRjc5Q2NHQWF6d2t5TEcxYmpWLUQzSDl1SEpGZ0xkNkZla1Q0ZGxqbzJtT2lXUmNYbE1GaXdaVWJMNFpzM009
"I'm pretty sure they fine-tune lora adapters on top of a common base model. Then you can dynamically apply and remove adapters depending on the task. So they have a summarisation Lora, tone editing Lora... It's actually not that difficult to do. Llama cpp, vllm already have this capability",r/machinelearning,Z0FBQUFBQm0yeGI2QmhpQmF5QnlhVThkbnhwczB5bThEenFrVE5OanE3MWp6bjZURmRhdElaQkdHY3hDeWZPODFISHZSOExJYW5OejJqczRiTHdUNXp1QUhFUWFGNkFScEE9PQ==
"Tree embeddings can be tricky, have you tried using graph neural networks instead?",r/machinelearning,Z0FBQUFBQm0yeGI2dUZDUUVhd3hvZVMxNEFSRFNRSl9lVXV6dW5ieWV0c09xOEZKdWFZb1BrdWxkYldBRlNweGI4T3BMOTlfNWItcUJHTGZqYzhRX0kxQmowWmdXQ1ZGTUJ1UWRuR2ZvS0d0dmtaRmRsTVBsUUk9
Have you tried incorporating external factors like economic indicators or weather data?,r/machinelearning,Z0FBQUFBQm0yeGI2eG1KQnA0aG96dWlyTU5NbVJuYmVYOTZxbzdjVkJ2M2l2emxRckZsUTB0aXhDSXhQckZsVk9fZ2VFUzB0QVA5Z0NydDdOaE9rVVdic2JmT0dlcThpTjVWMV9MQTRvRjlPNzkzSURfOEpiblU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2NEhZUnE0RHZIYmdfNHg3OXhsRzByZW9PczRreHF4ellMN1FoUGY3bXNES0k3UFRqR3ZYZ2lPT2twbGpDN1BWX3h1QkhSZHhfSExyRGxGa1JyN0VNQXc9PQ==
"Not really, I thought LLM few shot learning would be the easiest first try. Also, these trees are relatively small in size, the text representation would easily fit in the LLM context window.",r/machinelearning,Z0FBQUFBQm0yeGI2X3I0MXZsQVRFVzl2R09SUUJjc2VpaEFCMUtsa2l5OVZYUVFGQ1hRVXRiMkgydzF4NHhkZmtXMkh2TzA2c1N2X25POTVoeUgyYkZBVjVuUTduZ190eXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2VkRuT1BmUHByclpRdWZRTjB0cGNxbUxuRHJiNnlqcWtkRW5wYnZQTlhKbW8xeDBJUzVlTjFSTldmSW0wZU9WSGlDOU9sYkRJczR5RzByaXhlQ0F1UEE9PQ==
"Hey, How did you find it? Is this repo useful & covers all essential deep learning concepts?",r/machinelearning,Z0FBQUFBQm0yeGI2bnhNX2NqNldxWUlJMmFUck16YzRTVC1MbGwtb1pqeTJsMmJUY2xoa3FQQlRZcTE4V0dFVUoyNDJDMjNwbUdqcW5wV1I0YnBGU2ctRFJidTZmQTJjYnJxalFmTGFtM3BIRm0zVE1BQThacTg9
It doesn't :D [https://arxiv.org/abs/1712.02950](https://arxiv.org/abs/1712.02950),r/machinelearning,Z0FBQUFBQm0yeGI2RE5udHhMenVzXy1lRjNIVmM0Vm1tYVl4aHFDNkFpN083SF9Vc2xGU3VKYTRlTW1WQzBlSnR4VFdCOUNqV3I5aE0zWk9HTGhPVXdOT2R0Sy1hWXlRMjYzNHRwVHJEdkdSYzBLTEtCWTZvVW89
This is cool and exactly what I was looking for.  Thanks!,r/machinelearning,Z0FBQUFBQm0yeGI2MUdhQTJ3empkVGduWnFDbl9JYjZ2YURmWE9FZl9jbzJmZjVNc0phWGVJMjM3QmZDM0pDSzBsYjQ5YzY5ZzV3SldSSmdURHlpZmdpVW80MjVfbzMxX3c9PQ==
"Well yeah, obviously you don’t want to hire someone with stunted development, they realistically shouldn’t have been able to graduate their PhD without making the transition to post-rigorous.",r/machinelearning,Z0FBQUFBQm0yeGI2TUN5X3VBbEN3SlowTXV0Um9vWDlRUkQxZHVXN0Y5NFRxclZuN0pFUmQzR2F1TTV6S1NIVW55OUxMVUFKTXRNZ0ZCRVFGS3hvaDdXOUx4OTV2Nk9Ec2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2VlFrNG5VbXMwU2tHMThobWQxaERnNmVGbU5nRFhIMVpzSDhuT285a3hYVk9rSHFyLVIwRkRzcUllV1lVc3BVekZHWWRpenJFdzJCX0xLanF3d3hobUE9PQ==
"a lot of good papers on this [https://www.sciencedirect.com/science/article/pii/S0950705124006609?dgcid=raven\\_sd\\_aip\\_email](https://www.sciencedirect.com/science/article/pii/S0950705124006609?dgcid=raven_sd_aip_email)

yes it is about crypto but incorporating extraneous variables for an LSTM forecast on BTC, interesting stuff and wide application domain",r/machinelearning,Z0FBQUFBQm0yeGI2UEdHNGFseWlrbWtUQlZfdmhzTnVKNEF6Y3pIWGxZN1dCSS02Tl9wel9PLVNybVVLeWJfSVJIT1hGdUd4TGpjZ2VMZ2wtdUVlb2xTTS1PVWloV0hERVE9PQ==
"In prod, how would you get the aggregated features for t+1 if you’re at t?",r/machinelearning,Z0FBQUFBQm0yeGI2M19FSm80QXFzYzhhVFVKNE9XRnRFX3pxb3AxOGNkS1FkTlh1ZE4zRTJMZEtwUFpVMVRIYU5fOUY1ckJzTjEyeVN2RU1Md2paZUNBWk9NTGNHMENiNHc9PQ==
"This is so cool! Can you share details about the fine tuning? What technique did you use? What are your learnings, and how much did it cost?",r/machinelearning,Z0FBQUFBQm0yeGI2OEVuWko1WVRwOGdqTnIxb3h3Y3BwS2ZOdDk0YzRveGo0UUhyWllvdkpQaF9IS2x5V0pYa3pqMVU0d0VfTXNsSjdsXzgtX3dieTZmNGVKMEFoVnZHV0U2UmFxb2k4eGpyNV9IRnYzbDdVaDg9
Parametrized memory has a higher potential than context memory. Recent research on grokking circuits show that. So if they get to the point of swapping in domain specific grokked circuits then this could be very powerful.,r/machinelearning,Z0FBQUFBQm0yeGI2aWdHcjY4U1pHRzlRc0dkcGdXdTdhWTFUekZsR0xlTWstQzhjZUItWFV3NGtFYjdpX0tSeVF0MFpHb2NhRndFeFdRc3pLMkNfTUtCVWVaVktWYUxDOHc9PQ==
"I remember seeing someone get 1.6B locally at 30 tokens/sec on an iPhone last year. I think a big part of it was just the quantization, and probably using an open source library like local llama.",r/machinelearning,Z0FBQUFBQm0yeGI2Rm9tY0dKMkJPZXE0WEUxNl8xd2NreDctcmdSWlpjTU5YS3k1YVFCamx5cVVTNmNsbVR6NXFGUWZPVWt0TU55eW9YS2pLVTY2RkZEOWdsSjhoekZ3WWc9PQ==
Do you put your stuff on GitHub? Would love to see it,r/machinelearning,Z0FBQUFBQm0yeGI2cXE4VWQ1Vi1GSDh4RWZtaW9kODVfSFYwTVVUNk1xRHZOUDV3ZGplc0VTbG5ZeDUxZnhYUFZqS0JzSFp5Rmh5dm5wa2MtVVBmU0xIZXBtR0lVVDNHcHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2NFpoMlRmc19NMlNJeXVBeEx6V2ZlUUFPT0hHN2hxcmFqd0JSeHNnZzZMM3EwQU94ODBDcGh2ZXpJS2dMMFZRZWJydTNCZmw0TUYtSkR3cFpYclVOWHc9PQ==
"No they don’t, you can’t swap loras on the fly, people request this feature for months.",r/machinelearning,Z0FBQUFBQm0yeGI2TU5rVGhsM2czekROQWZtSG80QXZFSktzcWJ1YXE3aVBzRDUyMHFCWDdDTWx0T1VmdzROdWdxbGx3c2YxNTliemZxc19qaTdyczdta0RTaE1sckNiMWc9PQ==
I did fine-tuning using fireworks.ai they provide fine-tuning service so you just give them your data in jsonl format along with all the config (hyperparams) and they do the finetuning which you can track on wandb or there command line tool. It costed me $2 but this will change depending on how much data you have and what model you are finetuning.,r/machinelearning,Z0FBQUFBQm0yeGI2RDlqMnBDeS1SNUNHcWxWZ1ZOSFNQdkpPV0pQTjQ5ZVVRN2xzMjcwSFNZZllaSW9TNXREcW5vLWFEUTFrZlBZeHVmLS00VkRQT1I1bFREcFZPZ2xwSHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI2MDZlaVdLZWxTSlkyQXJFamhlY1M1Y2VtZkQ1SDVTa2cyZzRPX0c4NWZlZUk2aVk3dkNDU19tNUhCNEhCY1I4V1ZzSHQ3WmRFTWhEeERWWE81SzlKTEE9PQ==
"Yes, they don’t say LoRA specifically, but it’s implied:

> Our foundation models are fine-tuned for users’ everyday activities, and can dynamically specialize themselves on-the-fly for the task at hand. We utilize adapters, small neural network modules that can be plugged into various layers of the pre-trained model, to fine-tune our models for specific tasks. For our models we adapt the attention matrices, the attention projection matrix, and the fully connected layers in the point-wise feedforward networks for a suitable set of the decoding layers of the transformer architecture.",r/machinelearning,Z0FBQUFBQm0yeGI2bWIzQjY0S0pUSEZhVVJsRWJlNk5JbUFIRFo3cnJKVzUzdGVRa3RWbHhoS2tzSDhaMV82SWt2YktHYUhnZnNSaVhJTFV2b3Vlejl6RlZjVWhWbUVhQXc9PQ==
"People often conflate ""grokking"" and ""generalization."" Grokking is when networks are capable of generalizing, but *don't* (for a long time), leading to the training loss being uninformative about the true state of the network. While ""grokking"" as an English language word means ""to understand deeply,"" in deep learning the phenomenon refers specifically to when training accuracy and test accuracy are decoupled and test accuracy stays low for a needlessly long time, which is obviously undesirable. Further, since grokking refers to a dynamical phenomenon that takes place during training (separation of train and test loss curves), and not a state of a network, the phrase ""grokked LLM"" is not well defined. By ""grokked LLM"" you seem to mean ""a language model that generalizes."" These are not the same thing. Thanks!",r/machinelearning,Z0FBQUFBQm0yeGI2R3RaVXp3ZGpzLVctRDVLRkN5OUF1RExmQlp1T29XUExwUTE1UjV2LUJtSmp6LWtpT2lRY0t1LWwwVDd4cUJmemJmMmhCZm1QZENoRWx3emJVZHF3MGc9PQ==
Very interesting stuff - also did op say he was using the same system?,r/machinelearning,Z0FBQUFBQm0yeGI2QW5lQTYwSG5nUjlkWG9Ca2NrUjFDdDZ1VG42Z3JTSk5yUU81YjFzN2FRZ1lCNWtDaVBJX1RTMmhnR3hXSFFrRlFQTTExTmp3ZlFheHg5dUF6MzFWZnc9PQ==
You can get forecasts of weather for instance that tuna at t+1. Moving averages forecasting at t+1 and so on. You will rely on forecasts for your forecast,r/machinelearning,Z0FBQUFBQm0yeGI2WVpWaEEyRUJHYXBQWkRJV0UyejlkM2JNY1FmNjUtS2g5Q2ItTEJCbGhVVkFNeTFSa3NOTmQzbEVYckh5R1V3MW4zVXNrY0JlWHZiVlVvalo1TVkwSVE9PQ==
"Great, would love some help on this",r/machinelearning,Z0FBQUFBQm0yeGI2Y0hYd1NtMC1wQTdiVFdRZnBiWTBOb1hIclhmTlhHYnBHQ29tZTFITHlDSEx3endNa3VUX0xlZjJFZFg4dXZMRk9YRDhzNjFZdExsY2tyMFZXa21JZ2c9PQ==
"Yeah, I saw OpenCV and Clip in the code, but wasn't sure how to find what else was being used. Thanks for helping me out!",r/machinelearning,Z0FBQUFBQm0yeGI2SmU1WFBKVjZtQkhVd05PRVNxNUZvWm01TEFteV9TMjZSOWE1VUFZcWViR2RFNVRLeUdtWWVFc3ZzdGJHNTFGNHV1ZUNwR184TmZkUlN2RV9uekFzZTA5VlBURlNrVEo1aklPVmNHOExQOUU9
"Thanks! I did draw that conclusion,  though to be fair, my assumption is grokking refers to the process -- formation of induction heads etc, and grokked is the end state meaning generalization. ",r/machinelearning,Z0FBQUFBQm0yeGI2bVRwd0ZJanFJekpGZ3U4dkV5eTYxNTA4U0dXMWljNTdRcTYxNmFKT3hjQ3Z6UHZma1M0Q0NHWjdiUEVsbHI1N3R6QWtPNkVHWFZHcEVueURUUXI1Sk9WS0pzX3d4Tm54alBnbHNUd2xBZE09
"That's because they're not from the user. ""Query"" here is a term of art referring to part of the parameters (KVQ, Key, Value, Query) to the self-attention part of the encoder/decoder.",r/machinelearning,Z0FBQUFBQm0yeGI2d05xRTBmSURGOTROd1NoeXhfQ0pVU3ZERlZnR292akhwSlV5X3lZT0dsbERqMTJJcTlfdjh4Zm16Q012WlUxSkZnM3dWdVd3d0JydFlWUjVOU01Qenc9PQ==
Impressive. If you could please post the code I would love to ~steal it~ do something similar.,r/machinelearning,Z0FBQUFBQm0yeGI2N09BOXJmSGQtUi1lUUNxQjZ6WHcwb040Z0R6ai1TRDJPZ3JjU3dxeUc2a2VHTjJtR3pNYkgtR0pHc0pOcTVCRG9YWkt3ZDBCSzNNTDUydlJzd0dYanc9PQ==
"Quantization and specialist LoRA can do a lot of lifting. At 4-bit quantization, this model goes from needing 14.4GB of massively parallel RAM to only 1.8 GB. If your fine-tuning can bring the task specific performance back up to the full-width model (or improve it), you're cooking.

This tech is in the very early stages of optimization, interpretability, and alignment. I think we'll see releases like this where some clever use of existing techniques looks like a big leap forward pretty frequently for a few years.",r/machinelearning,Z0FBQUFBQm0yeGI2S2tPTzhiOFZURDVXa05RUlk4cEQwWVRGdnNwMXNvRUQ1aE9Qa2c2c3hnQl9rQlFPOVE0T1ZnaU1lVjVmU1hWTUU2MVdOMDFnandkSFExRDBidEZLdWc9PQ==
"This has the potential to be many times better than rag, absolutely. It's going to be really cool to see this applied to domain specific knowledge bases",r/machinelearning,Z0FBQUFBQm0yeGI3WEpUWDh4RURReDFxYS1ncFpWTHFPbm1uN0Z4U0VldDJldVBDbGV5bTRmSnBFWklfdWVBUGxOTWMwLTBfX2Q0ZTg1bWd2SWIyaXc5aktjNFhuWkFUY0E9PQ==
thanks  . I tried to do that but it seems I can't get it to work . I tried with chunks but it uses just the first chunk during training and doesn't add additional chuncks .  With smaller files it works so the file size is the problem,r/machinelearning,Z0FBQUFBQm0yeGI3UDhabElkeDUxdEl1bkptdDRuVTNjb01jWFM4ZzNyd2lPZkl1TElZT1JiT1FMSzlKZXMxLVJlN3Myd3lDNzVoS3BtcUk0YlpLRzNkQlg0X2Vmc2pxRmtVWENOY0VNV2RLT09rQ3RuczlzZ0U9
"I'd be interested to know also. Even if that's the case, there's still a massively large set of applications where that's useful. Maybe actually most of them. Building expert systems to go along with books, company knowledge bases, etc. Extremely useful and profitable.

Basically anytime people were using rag, which always struck me as very sub-par in results.",r/machinelearning,Z0FBQUFBQm0yeGI3dmxUZm9YS2ROODFGVFFheHNfbjc1UENvbEZybFZDTlFsOXZZTzhuY2oyaG5uMmVHMDNSaVpQS2o0NEtleF85UHg2aDRfYmZqbFMyVWxuNktIdUNOc3c9PQ==
any tips ? like compress what ?   I was thinking maybe use just a portion of the file at  a time and discard the unused portion from memory but I don't know how to implement such thing,r/machinelearning,Z0FBQUFBQm0yeGI3Zkc1eEpsRUF1SkIwYXBGX0tNdjZrLXgzenZfSkdHNVp3a3FkU2duaVhwNzU5NkhCaEJkMXdGcXh2RmpaSXBVNHNMMDVwenRYZUIxbktyZEZVQ1p6MXhUXzlaODBXdFl0QlozVnVhdUFmOW89
Bro,r/machinelearning,Z0FBQUFBQm0yeGI3YlVPX01yTVlHd0RiaFJpakhLYmhUUXlpUXpYUjVLMWlrRVNiald2NldSaEZPaHYyTFNPbU0tRmRicVNJSFVCbmRYRnh5c2xYa2c5R00wZW5YMHp6bUE9PQ==
"I didn't know you could combine them(?) if that's what you mean. If you mean that I just use them both in the code and log twice, I was trying to stick to wandb for it all since it included logging, sweeps etc. in one and they had overlapping functionalities, and also the fact that wandb is a bit more feature-extensive than tensorboard and I was not just logging for plots. Also, I ended up switching to Optuna for doing hyperparameter optimization but still used wandb to log them as individual experiments, and then manually compared them.",r/machinelearning,Z0FBQUFBQm0yeGI3bHlvZlBBSzNJM2Vtc0VNeHFEVGpzbWg5S0UzaGwycTB6ZmNCdnFRdGZxSzd1Z3M0cmJWOUhlQWFiUllNdS0wU3FoaUpZcHRsYzNqbDVSVjljLUZJYVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ZW5TYTUtaDBsUk13SlZ6bHlmRk03MUZQTTNiZS1ZaVN6aGVsYXRfdDFVWGZxd3l6RDJqRUVXeW1Sdkd5anJUampUTlBla2hwWnppcllUY2ZvT3JibkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3VkpmUHFGLWpOd2M2RWpYYUdNVUoyb2dmT0lGNlZnaWswbHVjbFZLWkZZUzZLZnFPeWZoV2QzZjZnN3M5UUtRMVV2eldKMUpmMVdkZGxiaE5lcHZod0E9PQ==
"You can run 4bit awq, or marlin which is even better.",r/machinelearning,Z0FBQUFBQm0yeGI3aDFUZEc5VllMX0JvQy01ZWY4S0RqR2h3bHZvWXlPLWVUZFFNTW45bUlaVUxmNUkzZTBOV0pJY0QwUjBMTm1PdnUyUkxINFp5M0cyV1N1YWJqcTNSa0E9PQ==
What is a chunk over here?,r/machinelearning,Z0FBQUFBQm0yeGI3b3JOYXo3bjBtUlA2ZEtlM0drRHd1cTJGRFQ3NGt2YmNTSlF5Y0dvRXd1ZWx4X1N5SldqeXRyZy1UM180X1RJcGcydHhoWmVTdEVCSDh5OVBJWUtOSGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3QjRpVWtBQm5hakR3eTFaZ3k0TUhHZDdnbW92MlBHcy11aXBsZUluRS1WaTktMi1pUVZXdWhGVmRkSl9yMV95NWJIdVlTcDZranNtRmQ0QWZmWlhsR0E9PQ==
"Yeah sure np. 

Here is an example, https://docs.vllm.ai/en/v0.4.0/models/lora.html

So you're right in that Lora adds a new part to the model. It adds a low rank matrix on top of specific layers. (Mainly the q,k,v). However these are kept seperate. They are only merged while inference for speed. But recently there have been implementations like s-lora(https://arxiv.org/abs/2311.03285) punica (https://arxiv.org/abs/2310.18547) where you can keep the adapters seperate from the base model and ""apply"" it at will. 

Which makes hosting multiple finetunes much more efficient.",r/machinelearning,Z0FBQUFBQm0yeGI3aXBsZDBzekVmcmNuZDR2ZUpQOUJua3YxSGNnd043c0dzSmtSMkI4a25SS0xvbnJCVlJWQ21nbXZMN1lBamRMa205SVNyYlMtanQtblZfcjNHWklsVHc9PQ==
You are not comfortable writing code?,r/machinelearning,Z0FBQUFBQm0yeGI3QmdsVU1mamZTWHl3dTdMTFVfWm10bkJyX3o4NzlMNmkxcndweEp0VjJ1bmlEZW44LVJBTS1jTWJiUkZxSDBwY0wyM1dOajk0ZjFOTWtkOVNyb2Q2Zmc9PQ==
"You wouldn't download a bro, do you?",r/machinelearning,Z0FBQUFBQm0yeGI3Q08yVjJ0Q1pEaWM4NnVfazFhSGY1cUhSbDFFcG9DXzY5RVFBQlhGY1AwOFZaanRDeWw0Z1V0QXJVVEFCcUpaSTVRcHBiZTlvTnVZTWd2N1JXTER0dEE9PQ==
It works perfectly fine in a venv,r/machinelearning,Z0FBQUFBQm0yeGI3OGJVbjRBcFdXM3hCbFI5VU5NdHM2UTBGSVE4UWMzWEl2ZjdHX21heDNZLXQyNmV0T0NuOUtYTlR4ZW9CMFhScExubkFsRGpsSEZqXzZNZ2NCM1BwOXc9PQ==
"The C++ libraries are stored on your main OS, not in the python venv. Only python modules are stored in there",r/machinelearning,Z0FBQUFBQm0yeGI3RFVaaFRlcDJYM2l0UDdHNi00NzBmWl9UUGcxSW9jUEc3QmFLUkNsSXU0MHJIWEZ6RnJ4THdlTnUzczZaYlExZmYxajN3SGVUVUNseEVOSGl5V3BIQmY4YWFxaG54T0Rrc3lrZ0FrNHNmdHM9
"To add to my post:

  
`libopencv-dev` does not get stored in the python venv",r/machinelearning,Z0FBQUFBQm0yeGI3UDg0NjA2RkFFWUdsLTlQTjkxaFJLRzZmWXB0UllqVlVZUVBIWGk3VUtPOHJMMzdNMmw2M25jVDljQWNGY3pnVEdsU3dzQ2hrelZJWGtpSEdrOFZUZTZhVDZnVFJiVm85UVVWamtSVjQ3c1U9
We use opencv with venv and it just works.,r/machinelearning,Z0FBQUFBQm0yeGI3QVdXMHZSbExtRnZKaFpMQ0wxMTU0NERvYjh5X0Vja1kzSUdxcjhOZl9tNEt1el8xcnZNdElGTGw1X2syTGxSWXBWUHBpWU9sWVNaN3Byb0lFdENDR2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3UXZ5aFluRDhRMlMzWXBVY2ZxU0tyVHVjMkF6SEJzaVcybl9vMTdEQXZhcUlyMmFQVDhTMFNNQ0plVjM2MlgzYjM5S0VOOWhzejR5OXlHSER0R05aTXc9PQ==
You have no c++ libraries installed with it?,r/machinelearning,Z0FBQUFBQm0yeGI3MkotSEVfWEp1Rk82VU93Yk1HRFg2VlBIZ05fcFVrbmNWVTFSSUYyd3pISDRPYXVCbTVRNXhjeV9yYWRmbmZ1NDh3Q3VkUVVZdlhWdVF2ZGlHZ2oySllDeGhzNzVxQWNPTGR4WkZCYkF6a0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ZTlqYVRvdXpnVTc0ZVA4dEduY0RPTDU1dmZBYVpjei1uMmdsc2ZoTmNzc3gxal9fOWVNWHIxcXJ4YzVFQXhWSjVqNkszeGhGcmtHZmRETDI1TGRWMnc9PQ==
It's most probably installed somewhere on the system but no it's not inside venv.,r/machinelearning,Z0FBQUFBQm0yeGI3ZkZtLVJZSDB5VUpwOXdSNEhqNk5FQms0TFJ0M3dLT2d4cEs3d1NFR1IwcE83TnIzd19aR1ZudV9rQUphcU0wNU1MWFVCNy1lbE9qeVQ0dUoyUWwwbnc9PQ==
"Issue I think is, I have projects using OpenCV version 2.x and projects I'm working on which are 4.x. These versions definitely have different C++ libraries so that's why I'm asking around",r/machinelearning,Z0FBQUFBQm0yeGI3RFM3MDlld0tsV1MyNW1QMkQyS2JBYmJ6YjBZc19OX0NMNkVCbnFFYW9VaXhranltQjljZURGeXZiam02T01Db0s0cXBCWlA4NVlDeHZaU0FPTWhOOUFKUjl3NjhXSG43Z2daVFZiWElVR0k9
Bros before downloads.,r/machinelearning,Z0FBQUFBQm0yeGI3QXBhR2tDaEM5cWdtNW9wRENpQmxxTEFXRVo1OWVhcjQ5dS1kUnNKRk5lT1oxVGk3OTc2MzJTSUs2bV9hNWduczdHUUE3Ukpxa2NKRElUMmFoMjlVTnc9PQ==
🗿,r/machinelearning,Z0FBQUFBQm0yeGI3aC1tSVUtSkxHY0oyRnhyd0hVcEZLenlsaTV4blZjTzhvNHFja3N4eXJHdVR1VHlSOWJHTUlYczBVNENfemlseF9DS3ZtNjV1VFBOZm5ETkloLWhtYnc9PQ==
"What you're describing is batch processing, and you should absolutely learn how to do it. This is a necessary skill when dealing with large datasets",r/machinelearning,Z0FBQUFBQm0yeGI3MWs2OVg1Y25RbEFHeUhabDlOSF9VWkRXRFVoR3BaLTdVNTVrYnpwRDJvV3dOR0hIcm5tazFBa2VMVkswdVp3eVNxY2FHTENOT3RPQWRJbm9hQlVQX0E9PQ==
"he did here [https://github.com/pritishmishra703/AI-WhatsApp-Clone](https://github.com/pritishmishra703/AI-WhatsApp-Clone) but it's empty and he's collecting email addresses for when he'll push changes (smart if you want to create a product out of it and get initial customers, especially as the star button does the same thing haha)",r/machinelearning,Z0FBQUFBQm0yeGI3bjZoc0pWN19qZE45YlM2b3JTSWxuMXVEOXNzcExEMW5URHh1Wm00akxxLU9lMHNFWkVHN2YyYzVTVExrOTZ1ejNTOUVJblpkaXptc0pjVEoyN1IxdFE9PQ==
"i dont really see the appeal to run something like pytorch on a target when its so easy to export to onnx and from there to a lot of other formats... in my case i convert to tflite since the hardware requires it if i want to use the integrated npu. Though since the raspberry just runs a linux on an arm cpu, you should be able to just install and run torch...",r/machinelearning,Z0FBQUFBQm0yeGI3cXlMaGEwMVVRclFMYk9pU0kxWGJGalFXeUM3WUpqWDJsNVdFOUhmTjhfYnRVMnQ1MUlWWHRieGprakRXd1p0TDRnQXlJaWdZQ1pCUXlQeWh5QjRiYUE9PQ==
"If that's true, then it should cause a conflict between different versions of OpenCV in different venvs, yet no such conflicts happen.

From the [FAQ](https://pypi.org/project/opencv-python/):

>Q: Do I need to install also OpenCV separately?
>
>A: No, the packages are special wheel binary packages and they already contain statically built OpenCV binaries.",r/machinelearning,Z0FBQUFBQm0yeGI3YUswY0VudUNUYnhMaVVDc3hWendPeHlfMXNFemUxa2F3ckp1NXEtZ2JITjVheWgtczRENi1ocXVSNVN0amhzbFBtNldhMDJFRVFhc2tYaTJHTHRsZGc9PQ==
I had a Black Mirror episode idea where someone gets kidnapped and killed but AI is used on their WhatsApp so people think they’ve been kept alive for a lot longer than they have. Guess we’re one step closer lol,r/machinelearning,Z0FBQUFBQm0yeGI3c2VBYXBwbF9fR05WbXlYQnZMcTVtYlU0Rl9HMURSSHFYYXZ4NWRaNW5UNWF4cXljM285RW5XNDVCTWpjZWxBM1pNcHVlUkdpOUwzb2g0V0dmczF5djhEMXZhNW10RGdoOVAwaVBmTW12Tlk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3V2Eza19PeHNvckhOajctS2FOZmxOVHpUMVVOS0J0Q09faTN5TUI3ZzgwWXRiYmdPRTZ0QUNTUmJXb0dPTnE2WHBfRHFsbXJvSmVFb3VtaUZoaXZhLUE9PQ==
" So, libopencv-dev, which I installed with apt is not a system level library? Thanks for this.",r/machinelearning,Z0FBQUFBQm0yeGI3d2puNDRnN3VkZGJtcDFibjJ1Zmh0eGtXY3pnRmw1ek1IN0JVUEk2YnMtU3k2a3VtM2lPUmRHYW11ejFLRlhIdF93RC1WMFZQazFYRDYySjh1ank2LU5ZTmQ4MDdpbkV5NS1XYlNtTV9wTG89
"Depends on how serious you want people to take your paper and conclusions.

It's not a binary thing, it's a continuum. Personally, nowadays, I would definitely test on at least imagenet, bare minimum.",r/machinelearning,Z0FBQUFBQm0yeGI3U1hSTm8xejN6UXEyLWlaOVRoVzIwVDBhTTdRd1hjR21aUEpfOExfSHZ1c2VOS0xUOVNRdnlWWkJMWnI4S1JscUlxOUJ2RTMwcmpkSk1kajdVUGVnRXc9PQ==
"Is the optimization task agnostic? If it is, maybe consider a different task like object detection. COCO is significantly smaller than ImageNet and  imo is a good middle ground between CIFAR/MNIST and ImageNet in terms of the realistic vs. compute front.",r/machinelearning,Z0FBQUFBQm0yeGI3NFZjRzUtT0hZS1NLNm9ESFZaNVVfQlJBa3dlSTNkbmZmNnYxMzJjYjF4YlFVVTFQbWZwMUp5Q0lOY3AwbExqMVFQTXdRNnZNYklWVGVyV3cwMjZOblE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3d2VIZ3UyMXA3bHJXZTdyYmF0eU5CdE85dklkT0FkZ0wySVhCWldGNjhjeGxXR1NfaE5PY2l0aWhXcWhtenRIZlFjQUhnang3V09XYlFBMW5kRlhvdUE9PQ==
"That's actually a great idea, I know what I'll be running this weekend! Thank you!",r/machinelearning,Z0FBQUFBQm0yeGI3R0NybW9UTTN1cDVJRENlNDFqZlVPa0hnaWxvUTZUaGt3bHJtYzZCRFBsR1VEOFRxOW50YlVBcm5GaGhucDFpVnhlWUtOMVRvcnZtcHA0R2FSYm1Ibnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MGllMFA0eEctckZpUE4wRnFraTNmd2I0S3VkaTdsanFLeXZSdjRzdWJVa3h4eHR0bWphQkdfSXQ4MjI4ZXR0bEQzdnBVWmlIblJzMkt2eFZPbTJSVEE9PQ==
"Okay interesting! When you say bare minimum, what would you consider going further than image net?",r/machinelearning,Z0FBQUFBQm0yeGI3QlFhREFvT2lDU2JKb2EyZXcxRlhwSFBRUXFORHRuNkl4MkNyWk1lZjBtZS1YYlptLUNxN29TLWxGVll2bVY1VWx4bnJvUU0xTVphVkVKcnk5MWluMGc9PQ==
"hey, sorry to bother you but you seem knowledgeable about ML/RL. I have a betting simulation system i could do with some advice on, leme know if you can give me some advice.",r/machinelearning,Z0FBQUFBQm0yeGI3VzNOTExOdmhFTlM0YUZ0WTNqUjJ4aVZ6anQ5RHVyOFRISTF4blJJVUwwcjYyN2MyQm5hdlYzbE9yS0x6MTg1R0VrMGFsbElka2hIOEhOY1FlYjdxVmc9PQ==
"I think it is but it sounds like the python package doesn't use it, instead using its own bundled library",r/machinelearning,Z0FBQUFBQm0yeGI3SjFibUZySjRVekJxS3pWR3ZzZ2lmUXB5RnROVXBCVGh4OXRMQUstamRNMktBWmVaRm9rWGlkaVNhUE9SeTJmZ3g1ZzV1b1cyYTFwTzcwM2l6T1pmc1E9PQ==
"its a match predictor dqn agent however idk if its best model / agent to use, would ppo / a2c be better? also given my reward it converges on ""home win"" as the bet almost always over longer tests.",r/machinelearning,Z0FBQUFBQm0yeGI3NXVLd2JhaXA4amJhbVlVQUpYT1dMbW1qb3RBSzBnaHk4WExmMmEtM0d5YVBRaXY2b0FGWVh6SHB4NzFCbGtUZDZBY2J4dkp5SHJNTzU4cWpCeVFLc1E9PQ==
"There is also predibase... 

[https://arxiv.org/pdf/2405.00732](https://arxiv.org/pdf/2405.00732)

They recently published a research paper, they have a solution called Lorax, which allows for swapping of adapters... 

'Finally, we evaluate the latency and concurrency capabilities of LoRAX, an open-source Multi-LoRA inference server that facilitates the deployment of multiple LoRA fine-tuned models on a single GPU using shared base model weights and dynamic adapter loading. LoRAX powers LoRA Land, a web application that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA A100 GPU with 80GB memory. LoRA Land highlights the quality and cost-effectiveness of employing multiple specialized LLMs over a single, general-purpose LLM.'",r/machinelearning,Z0FBQUFBQm0yeGI3OTRpWDZCSnJ1SGU5VEltUlVTc091VkE2TDR0SzczMjRyaWxYNmZfODhWSnlzZjlqZ0ctZ05ZaENIYzRnOVhxRXdQQ2FJR1hkWlFYQWoxbjFYRGo4dlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3VjZfZXhENXVhOVlYdW1KeEVBbkhfX2FjVzE4aUp5d0tGODNuSE9uVnNUNlBaaGtxT3h5Y3V5OWJYbmRBbTJJRmhfc1VQMTk2Z2xNTUlVLVdJaTJWYVE9PQ==
What's the difference between how we interact with chatbots vs how we interact with our other IT systems?,r/machinelearning,Z0FBQUFBQm0yeGI3TXpXNGx1TXUxQTBTY0d1VDkzZVdMZnBvLTItRE5sM3BrNWp2T244ekk5al9MMzBQZDZOZUw4dmVUcjJsdU1jbng3NGNLcG41RDctbDgzUXk2MkF3OEE9PQ==
"I just checked my venv. The libs are loaded from inside venv:



    OpenCV loader: os.name=""posix""  platform.system()=""Linux""
    OpenCV loader: loading config: .../.venv/lib/python3.10/site-packages/cv2/config.py
    OpenCV loader: config not found, skip: .../.venv/lib/python3.10/site-packages/cv2/config-3.10.py
    OpenCV loader: loading config: .../.venv/lib/python3.10/site-packages/cv2/config-3.py
    OpenCV loader: PYTHON_EXTENSIONS_PATHS=['.../.venv/lib/python3.10/site-packages/cv2']
    OpenCV loader: BINARIES_PATHS=['.../.venv/lib/python3.10/site-packages/cv2/../../lib64']",r/machinelearning,Z0FBQUFBQm0yeGI3QmNyaHFCNlU2ZnkxbGlwN0tGeklqN1hnd3kzOExJTnZ2d0tFdXNoaXlLS0stV0pqamhKdTVELURUVXJ4TTlySTBrNWNXZGtEWXlyVmFXc3d1QzkwRHc9PQ==
"You want to test your work on as many diverse datasets you can afford, hopefully with varying degrees of complexity. Here is a list, but I'm sure there are other places and lists too: https://en.wikipedia.org/wiki/List_of_datasets_in_computer_vision_and_image_processing?wprov=sfla1",r/machinelearning,Z0FBQUFBQm0yeGI3NjJsZnZvNHA4OWdCSmJNSE9NeDZ5WHU0cFRhZ084NVdPUkRNNy11MW84eVVQQkRqNFVUbkVENVJNYzBDS1NLZjFaM0YtbGVTVkN6c2tKd09KVHpCUUE9PQ==
"Brilliant, thanks for sorting this out. So no need for conda.",r/machinelearning,Z0FBQUFBQm0yeGI3MjFQb0JaMXo5TVF0QUZiSXBMOUotV2dnTjZUdHJmU1RwX1lIVlhnWXluZzZnVG1ZUllOWW51MDdhVlBjUDdyLWFHSXpkVWN0N3RhdlFJcUR5MjFRa3JJNXgxbnFhcy1QbG5SMFVqZmg5WW89
Hmm yeah that can be an issue.,r/machinelearning,Z0FBQUFBQm0yeGI3SUl2MjdsX2tocDRwbFh5djk3T09xeTF6Y1o2X2Fod0JXOUNtVFhVNnE3S0VoaldMVEJSNGVOR3UyNWMtdEtyR2l1bW1Ga1RWZGdkRmNLNGlwNlkxTUE9PQ==
"Really depends on what you're using the AI for. 

E.g. the user interface for a robot will be very different from the user interface for an image generator. You could control the robot with natural language instructions and pointing gestures, while a graphics pen might provide better control for an image generator.",r/machinelearning,Z0FBQUFBQm0yeGI3Zm1yLThfdnMwZVJLdVlLMFpOTWItRGlPTVI4d3hqd0ZPTlZfcWg5d2hFMDI1NXB4ZGNDekVLTXpGMGszMHlBRU5CNGZRXzVSX3BuRXlXdVYyWU1oRzE2bzhIcU9vU1pQZHZoYzlISkZRTmM9
"The text file size is not the problem you're having. The problem you're having is that each token from your text is being converted into multidimensional vectors and weights that are computed on each layer of the model architecture, which are generally more than 10, or 20, at LEAST. 

Plus, in training, you not only do Feedforward operations but also backpropagation, which requires the same resources, at least, TWICE.

You can also check for a quantized model.

You'll have to chunk your text, and process in batches, or per chunk.",r/machinelearning,Z0FBQUFBQm0yeGI3cFZRc0hkUzZoR0RDM1RxZ3JpOE9qTzRMOTFFN0Vyek1XNjN0bHVHZ29oMVJoUVFNY3BTajZjcldkYWVFSWV4c095a0NFMDhGMl9yNnlLNlc1Mkd5bWc9PQ==
"Chatbots follow natural language instructions and are very flexible about formatting, unlike traditional computer systems.",r/machinelearning,Z0FBQUFBQm0yeGI3YWtUd203YmdtUGhjNi1vSGlmSkdVRU13U19CcHJGNGZEM2dPcy0zTU1WQ3R0dWtmaUdWLWMzbUk0cW1RekIxcEFxSUVfMDIxOWhQbTlBblItQ0w5dFdibkttRkFXZzJvMXI1ZDF0NHhIUG89
I've tried that batch thing but it seems to not work . Is it because kaggle doesn't automatically free the not used ram and you need to do it somehow using a command  ?,r/machinelearning,Z0FBQUFBQm0yeGI3c0ZKUlMxcUNISzZNMWFvdjdKXzZ1LXc3Z3I1T2N5WnkzbHJsbGFldTlrMmh0TkNMOWpWUXZZUG1ucGtGUjlObkN1cGxrNFlnTE1GcVRHaUdYN29uS0ZGVkd0dmd3MVNRMzNwZnFfVTlqTkE9
"A LoRA module does not add a layer, it is just a stored (and factored) weight update that you can add and subtract from the model weights freely.",r/machinelearning,Z0FBQUFBQm0yeGI3dUpKbE5jZUt4RHJoSjEzUEFrc0xhWGNobTdjWGNCRHp4N3hxc05fTTNaV2pZYThtLVRQd1Z3LUtYaTlfTUI1YndobmZScVExblA4OFRCemxocnFJckE9PQ==
Training these models require a LOT of compute my friend.,r/machinelearning,Z0FBQUFBQm0yeGI3Y0RvSGFfMF9BZVhxaEVDd2RQVmNfWEhEd0g4YTdyM0NsR05PMENsTXV3N0tSejRUUy1kQ2M5eG5yQVNCb25nZXpjanpKZzdFOExMNHBMU3FROUxMSVE9PQ==
"Yeah but he's asking about interfaces. I'm pretty sure it doesn't matter whether you interact with Windows or a chatbot, the options even today are the same: mouse, keyboard, VR devices, sound and eventually something like Neuralink. Plus the accessibility options like eye trackers etc. ",r/machinelearning,Z0FBQUFBQm0yeGI3MkhGSWJLMXF0bXotMVdxN0FfNnVpMGJJVWppZ2k5blZwLTlnU1pPcnAyOE1WV19WVE1JenJUYUZGZFAzV1czM2x0VXNfWHJSM1JXLTNXYUNtT3ZxX0E9PQ==
"Very cool! Just curious, does it support sending multiple messages back to back, or is it just one message back and forth?

Did you add artificial latency to fool your friends? Haha",r/machinelearning,Z0FBQUFBQm0yeGI3OHJ4cnRGaU15N3E2VmE4NV9yRE5DNV91eFV0dGhnbC1EUGxwRnVmSWVydnMzWkNCM3MtMk9FcWFwWDNBWEtrclJ2RHNPcFFSSkRKNVk5RnpBQ2tib2c9PQ==
"Brain-computer interfaces could be the future, no keyboards needed!",r/machinelearning,Z0FBQUFBQm0yeGI3V2tLXzV2cEg0RlFNVVBGZmh0RjZrdkZfTGgxb254SnpNY2JKWFMzWFcyR3l3UXJWUWw0WEVfLXpLNnZEZHB6ejhLZER3bVZsS0RNZy13WENqZEN3NGZlcGlKbWZLNXk5M1F2ai0xTzd3eXc9
Exactly!,r/machinelearning,Z0FBQUFBQm0yeGI3WHhLUENpSWhlVjdOLVdwWWpuNjJtWkUxSUhqRWVUTVdEMzVRQlpZZmhHZTlBZXVaeFBHQS1GaGhCTkVoWGZIVGdVNnJGYXF1Vnk2cWljR3lZNHBUSnc9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI3MDJVbTdwS05pWXdtU0YyUVZkZjZtTmNPY3ZvcDdKLW01d1lPcEVyT1NMaFRwOVUxLTAxQlUwdklUbzA4X2NmWWFLRU1rYXVuTEY5WDJYN3JxZWxfREJaamVwTUJDRktCTUFCbWZfbnA4b0U9
create s custom container,r/machinelearning,Z0FBQUFBQm0yeGI3RXBTblZTWnFkZldtWEg0bzRFekNwQXo4T3ZWNVVEaHJ1Y08zWEVOc0NqQ0pzVElURkdOcGozS3RMVzdYYi1ZcjRYWm5iQWg1a3A3NlFzTzM4TDlJZVE9PQ==
"How do I combine Multimodal tabular data in Machine Learning and Neural Networks? 

I have a regression problem and two input matrices; both matrices have the same dimension (same observations and """"feature""""), but different values. Let's say Matrix B is the fold change of Matrix A from the mean of control samples.

Do I just concatenate before modeling? So let's say each matrix have 10 features. If we concatenate how does the model know Column 1 is related to Column 11.

Do I model as two matrices and concatenate one of the hidden layers in NN? Will the Nueral Network learn the associations between A and B in this case? What if I wanna do Random Forrest Regression, how would I achieve that?",r/machinelearning,Z0FBQUFBQm0yeGI3T0RYN1ZoZXlBS0hndGduRk1ualBOWXBkSHR0ZDdGdkxNMHZRUE02SDdLb011TFRoSngySk9SREtOQWJQamxlWWJVXzhScmNQS044VzNjRkVyUXlSNEUxNVBGdjlrcTRTY1Q0dXE4dW1TNVk9
Validation loss isn't a good metric used for judging models. You're better off getting metrics from conventional benchmarks for LLMs (e.g. mmbench).,r/machinelearning,Z0FBQUFBQm0yeGI3bGpBaVMzdjJfd0lDeUU4VUd0c0xsRWt3eWpWU0E3RUlpT2p4Yko2a21hR21mWjBxY1ljbGd0WTZMOUZSZ25OQVNKRFhTSVRUemQ3b0hJdEM4ZWJ5clkyaXFwSWVqV1RYUUl3Y2pFam84RTQ9
thanks . something clicked in me when you said what you said .,r/machinelearning,Z0FBQUFBQm0yeGI3VmVkSHhQa05MMlhMNkR1RFF6RkczNkhObTRNMGJmeTlqY3dWU3ZJd1BBMzUtMEdLSUFOOUlnN1ZOWHJSS3dKWGpHMTZuWnhoVjRKRzV6a2doZF9ZTEdOZWVIY0pkc0lCU0Mwdjlya0FVN1E9
I feel like this bot is kinda stuck in a local minimum...,r/machinelearning,Z0FBQUFBQm0yeGI3ZXdYLUpyYmZtcmNtMTNtMWZJOUZybmw4MmpNSFAxbW95aXFIdXU1WU9FRHY3M0dacGhrS0NGMVZ0bUE5ODJETTNQczBKX3pSZ2x0alRuRy0xRkNNUEhNNGZTOGJPVElPSEstZmNacjVoUmM9
Let's wait and see how useful it is IRL,r/machinelearning,Z0FBQUFBQm0yeGI3MnU3alZFWkhiSXBNYUVRTWhHd2g0VXJuVlRtR25FbFVWLWl1RVFRemFrNkU2VWNCMWdoZXpydm1hbWh3WGV2Y0ZQeEREeTJZR1NscUlkWW5HTjZvdHc9PQ==
"like the first x lines of the .txt doc 
chunk_size = 10000 => first 10000 lines",r/machinelearning,Z0FBQUFBQm0yeGI3TFkwMXFIMFdKM1lXSWVtVXMxMGVVdWFMakpkWE01T2sxLTN2cGxhMVNuM2tPMkNOVko3N1Q5UXJBMDAxVmc0ZmRSQXBYNnAxejRIYkNFbnNWY3FYSTRReEx0NWZ6WmtaNTBYQ3Q1UVl2bEk9
Can you explain a bit or share a resource about it and how it is done?,r/machinelearning,Z0FBQUFBQm0yeGI3cEQ4SzBWbFRnTWpWMWhHWnBHbWdsZG5fZVRzT21LWUgxblV3UjlxWHhUNWVqU2NoNHdKRmxIeGFZY3JUOE9YMjdndVk5b082QmZOZGFhOXl2OWtRY0E9PQ==
"You didn't train it, you used a service to",r/machinelearning,Z0FBQUFBQm0yeGI3anFOR21aeEhWSTBja1M2ZmtRbFBkVzNLdGVwVGtZd1BjbXBMaDlJc21xMkZHdGJkVnI0eElYb2lRY05Tc1NTY0xjNk0xX01wY2ZvbmNXOFlBSkQ2cXc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3dUV0T2FTbFhzNFlyTDZjY0dYVTBIbjlKRzUzWFNnLURuNXE0cFNGV1VzYUpyM09wRWJxZnNiQXFZb1M3ZDZYUlMwWGhmeVF0eXdGUU9qZjRHVzhEVHc9PQ==
"This is a replay of how a human solves an ARC-AGI puzzle. Most users stick to the simple draw tools. Advanced users use copy/paste/rotate/flip/shift. People seem to have different techniques.

When you solve a puzzle here

[https://neoneye.github.io/arc/](https://neoneye.github.io/arc/)

Then your interaction history gets added to this repo

[https://github.com/neoneye/ARC-Interactive-History-Dataset](https://github.com/neoneye/ARC-Interactive-History-Dataset)

The ARC Prize also has a puzzle editor.

[https://arcprize.org/](https://arcprize.org/)",r/machinelearning,Z0FBQUFBQm0yeGI3MGdqZl9JUU1pZzVQS3lqZTJsaTdNVXdOaGRXZEFFRTJPSE5ldEh6U3ZUMDJ6SGZOTWFCQ29panhMQ2gyS1JhcXZPR1A0MWR2RldtSGQ4UUdFTklORkE9PQ==
"I have a relatively slow GPU for ML, so it would be difficult for me to train the model on any large datasets. Are there any small datasets with good benchmarks that you know of?",r/machinelearning,Z0FBQUFBQm0yeGI3Y1hnWDktUFJJVGNiTjdNWGVpNGZ5WklWUjVFcU9Ub282OTZvWF8xSllNbEdLUVVOTHl2ajl2ckNsSmc0UDh1ZUdRbzlDRE9EUlQ4T0dPWkFDS3RvMUE9PQ==
"Her?

I mean, Him?",r/machinelearning,Z0FBQUFBQm0yeGI3c3dJejlySHFSM2E0TnFNUjZVdXBPcnZSOW5QWUNWMFlTUWdFSjNNMHpmUFYxbHNxX2lKaTVid0VNX09hNHZ6Ymh4LVI3OXJFMTFsZFh5ZVdEMlE5cnc9PQ==
"He didn't train it, it was the computer (?)",r/machinelearning,Z0FBQUFBQm0yeGI3RExLRFB5ZXFvUXJfNlktT045MDBTZkhjRnpQS0JvVUhFcm9IQWYtZm42b0dFMkVjdThWOE9xRXpEdHBPVjM2TE5NWVNqbGlNTldmdkpsbjNheXVjY1E9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3dy11bnUwd25UT19PalJLUFhVTjRtMUJWV3kwM2NtUC1DUzR3a2t2QjJuc0prS1BCMXBORzlfUTRhbVhjZnA4eUVRWFlBeGw0WE5uMVEtVGd1YmZXWUxDcTdJemRQMTFPQ0gzaTRCTmlTUDA9
Check his comment,r/machinelearning,Z0FBQUFBQm0yeGI3UFdacjNQZlQ5Y3dlT3BRSzdZTFdzUW9KcHpNTUNtOVB3WXFvOFFqWlBWT2hPMDgyTTlhY2NqbG9SOElBWTVzblE3M0tKd2xwc1Uwa2JKdjlyQVYxNFE9PQ==
"Is it aware who is it talking to? Like, I don't speak in the same way to a friend, my dad, my partner, my family group, etc.",r/machinelearning,Z0FBQUFBQm0yeGI3YTI4ckhDXzR5SmhIMFFNZzBmUTNjWllTNkVlNGVzTHhuUGpHd0pYd2h6NjAyc0N5c2VQZ3liOFNJTGxXUUZrWno2UlU3SkN2RGw0RVZNYWF0QnF1S3c9PQ==
"Thank you for the reply. Given that the transactions number in the millions per day, what other methods can be used when aggregating data for the day?",r/machinelearning,Z0FBQUFBQm0yeGI3SWJvSmlPb0txZUpabFJNbXFwNTkzVXZxbGNUNjdURjM5aDhzWUxaQjlHWlFNRUtwbzFfa3ZjYWo0eG03WVJWY2YtdzRrSE9iNU9iZmpqU3YycnpZbWc9PQ==
"I see. That's helpful, thanks.",r/machinelearning,Z0FBQUFBQm0yeGI3VmM4ekRwRE9iTi1aZHRzZG41UlVVcE9pemJnV3RfRWQ2Nkw4MEdNYmx5X2hjdHBlaXZyLU92SEVCeHN1cmtlLVpTR2JxdE91VjFWc3VXcGtKb1kwMFE9PQ==
"They already did it. https://en.m.wikipedia.org/wiki/Be_Right_Back#:~:text=The%20episode%20tells%20the%20story,reluctantly%20decides%20to%20try%20it.",r/machinelearning,Z0FBQUFBQm0yeGI3eDVTNkl3TDJwZURlak5UOTNSTWl6QV9pYVpPQy1RZmI5VGNBSkxMZnBDRFRxaEQ0YnBQTTIwNzFHSExWQ2tDSGlnMzd0eTRDZmw1Q3Z0VWdacUNtSXc9PQ==
"You're not the first to have the idea, bro https://www.reddit.com/r/learnmachinelearning/s/vZvTj9rgZl",r/machinelearning,Z0FBQUFBQm0yeGI3TDk4ejRMb09qN18tZ0RNenZQYm5CTU1tSVZjb2gxaklkVVEzNTdLeUxhcDRkYUdlQTkwZDNiakx6Z1pTdm13ODhmTkN2YS02ZVJINEJlTFl1UW9HR1E9PQ==
“10x fewer” it’s always amusing when people choose the silliest way possible to communicate an effect size.,r/machinelearning,Z0FBQUFBQm0yeGI3SHZPclZlM2ZvdHBmTlFVUmZoWDc0Y1U0cng4ZnlaRVNoRFFKZEVCVEhZTkZtN1lJM0ttS2M1Y1l3aWg4RDQtSlZsRnIxV3pVNk14NFppRTNmRmpsTXVxLWJXeVJGS0t0UnhSUzExRWY0dG89
"Tight integration of software and hardware. Don't forget, it's their own ""neural engine"" chip, and the IPhone's processor takes advantage of unified, high-speed memory.",r/machinelearning,Z0FBQUFBQm0yeGI3R3hfcXNLM2QtNF9wNEFqVDcxTS1mbEhiQzlwR0pSNXc2MlJONHRVcnhIYW83b1RxNnAzckNyMzgxdzRXUmNjU2hGbDJ6TnpOV0N5Y3dQdndZZGRCU3c9PQ==
lol does he sit in the data center,r/machinelearning,Z0FBQUFBQm0yeGI3dERNcm1MV3BBS3FJand2N1BjS1AyVEVQS0FZV0E4WEdBUDI4cFp6b1IwRW9CakJSOHUyMHRLM3RiZ19adHFiWnZaQ1F0UGtVNVJsUlNVdUpnT3dzT2c9PQ==
I think your best bet is writing container images for each project. Then you can easily version your C++ deps.,r/machinelearning,Z0FBQUFBQm0yeGI3M0hOUjhibzVEY3F3ekZ4Tm5BUldlMWhUTzJzaE5YMERjX3QtSVlrZnl3ZE5ZSWFhMTNUMk9XNU1fcWdHN3I5UGl2YnZWeWFObF9QTFFQQWYxaFdWaUE9PQ==
"I don't know when a neural network's forward pass would return a loss, as opposed to the network's prediction for the task it was trained on. The loss is computed using the value the forward pass outputs. Anyhow, a sample snippet might look like:

    class MLP(nn.module):
      __init__(self): 
        super(MLP, self)
        self.layer1 = nn.Linear(10, 128) # suppose its a regression task on a 10 dimensional input
        self.act_fn = F.relu
        self.layer2 = nn.Linear(128, 1)
        self.alpha = 2 # increase laziness
      ...
      def forward(x):
        x = self.layer1(x)
        x = self.act_fn(x)
        out = self.layer2(x)
        return out * self.alpha",r/machinelearning,Z0FBQUFBQm0yeGI3NGJpaXJBUnlySGhwS2JZd1lPRF9mUzhhTTFkMzNSbE5UWlVpa1lmYVA1aEFGOHdXUmVPVUJRLWZ5dEhrN0VSYkN4ekM2enNTaWNpaXBmT2pLS0xISmc9PQ==
"They published a reward model, too:

~~https://huggingface.co/nvidia/Nemotron-4-340B-Instruct~~

https://huggingface.co/nvidia/Nemotron-4-340B-Reward

I'm a little dubious that it really needs to be that large.  The Starling team trained a 7B reward model using the Nectar dataset, and then a 34B reward model using the same dataset, and the models they trained with those reward models produce roughly the same inference quality.

**Edited:** to fix link.  Thanks u/gizcard, I oopsed.",r/machinelearning,Z0FBQUFBQm0yeGI3NGdhdXVRamNGRVV1NUJhaG0yUHJsZ180WGtueHg3cm9JM0xGSUE0T0NWcWdueFNDQU5Nd0dmVFFtV1hoRHM0dk5yZFRIOG5vb0hOT0g4LVdUb1FBcmc9PQ==
The link above is Instruct model. Reward model is here https://huggingface.co/nvidia/Nemotron-4-340B-Reward,r/machinelearning,Z0FBQUFBQm0yeGI3cG5MLWZZY1J4Q0J4NVlLYmRnWmNRdjhLLTJqUTZqV0dJN0xCSUdwUF9XaGh1T2h0bjVNUVUwZ2dvVXNYVDkwNEdudlpWekdZNEdmSTdsVTlkdjdONWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3Y1YzZUpWMzQ2RFlPc0FCR2dXN0NBajBmcmlOOXh6VUtKQnVBT3VRZWVGaVp5SUpuVW9PbjlxUUIydlM4VmZGNkNXb2lsYWVwY2FleWlJUzVFVVBaZnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3NTB1OXFCaVZpV1Q5TDlHRUZXWElsUGFiMFFJcW1ZWkRuSEVtY1ZMMmthZERyd2NuNmYycWRzX1RmYW9Sc2ZDSy1FYXAzZTJVbUxXMmxTbmRHaFlsZXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3RjVXbktoYURPcjVUdWJVV2pISDY5S25uSHA1c0hvd09uMmVlVTk5TXBxVDl2d2NGd1h0bTM2RUhPMm1xS0hqenM1RXd6MGNUT29hcElQMW5Ma2RMb3c9PQ==
"Thanks.  I mispasted, and didn't proof-read before hitting ""Save"".  Lame of me.",r/machinelearning,Z0FBQUFBQm0yeGI3c3dhdVdyOWI4anlWdHdFWS1ZS296MTZDSXRzdDN5N25BdEYyUFVKZHZVb05WWlR6ajU2VEtRZjlXMVVMam9iZUlUd3QzVmE4RGFmMjFmQ0FROVp5Q0E9PQ==
"Time based features like hours, weekday, blocks, seasons, Combinations like ""monday_hour_7"", payday, holidays etc. 



Various additions and subtractions of the series can be useful as well. 



With that much data you can also look into embedding some of it to capture more information in a way that is easier for the model to capture 



Honestly it depends so much on the domain. In my area adding 4 specific series together and adding one, can be very powerful, but it really really really depends on the domain",r/machinelearning,Z0FBQUFBQm0yeGI3ajZFdUM3SEdjaUJwamljZ0ZqRms1VmVyT0Myb1FlZ3IwZHZDWUt3X1l0TFVETkl6LTh3VEJNUWZtZTRZQUNQQno5ay1QQ2xpN1NaTTdnSXliN2xtUHc9PQ==
"They mention LoRA [here](https://machinelearning.apple.com/research/introducing-apple-foundation-models):

>For on-device inference, we use low-bit palletization, a critical optimization technique that achieves the necessary memory, power, and performance requirements. To maintain model quality, we developed a new framework using LoRA adapters that incorporates a mixed 2-bit and 4-bit configuration strategy — averaging 3.5 bits-per-weight — to achieve the same accuracy as the uncompressed models.",r/machinelearning,Z0FBQUFBQm0yeGI3RWZYbndWQ0ZDUUpVZ3R2RlZubjZoVXphSHlCb3J2OHVuUk8tUmlESE5sbVZvWkQyWks4SW1xdDN1bTJKSm5GZHZUZl9aNWRFYVFuTVN0RE1FYjJ6c1E9PQ==
"why did you have to enclose all the messages in `html` tags, if you ended up uploading the data in `jsonl`? I'm struggling to imagine how (but more importantly why) would you combine `HTML-`enclosed messages in `jsnol` rows",r/machinelearning,Z0FBQUFBQm0yeGI3bDBuVWlKTVplN1Z0a1FRWnphcDhfTjdBWUZpSzA1Wnoycm11Vi01UGk5ZzJwbDNHNFZqMHJxWmlQbkFNcHd3ZjVuSXE1aW0yXzVFeUdYejNSZ1JMQXFmU0xzVUJCbDdoOWMyTGhhTy1QVHc9
"In the video, you mentioned that only the first friend didn't know he's talking to AI. But in the post, the story is a bit different:

>My AI successfully fooled my friends into believing they were talking to the real me! 

Which one is true?",r/machinelearning,Z0FBQUFBQm0yeGI3Vk1JVVQ5SDVvS050LWxlTW1WQnUteEg0ZjBaalpGY280VVlmS0dTQXZJYmVhQ3dhVzdlRHhXLTU0SzVXYkxXZkFxeEF2Z1FEXzB2bVhwenhrSExlQkw3U3NVcUptZ2Q2SkdMUDhFY1pkMzg9
Ugh come on not one of these again.............,r/machinelearning,Z0FBQUFBQm0yeGI3aDF2UXdQX2NuQnVkeEkta0wzYkoyd0VkbnRSdUdRaXRsTW04MkpzVzBITTJvZDJWc2t3ekxla3MtOFpoS3hwMldjUUw3RTVOMEJ3ZWdFLVBVQllfTnc9PQ==
"Haha, sorry :P",r/machinelearning,Z0FBQUFBQm0yeGI3MXU3Y1psMGVvT29SeUYydmZsRXRHZ29qWE5GejZjQi16UTNvbEF0MDU4UXVfeUZNa0h6MXlZZk9nODNxTllaTUNqMGFZWWVBa0N4LUhUQm5kUmRZQ2c9PQ==
I would LOVE to do this for myself.,r/machinelearning,Z0FBQUFBQm0yeGI3enU3OVAxb2M0TmhSRG1lZWZkMWt3Ul9RQmRwakRqZ3FoQ0RrUzhkWGdhcHJMT0FTaVZDekJJTlZSU05abUp2R1FvMnRqRWcyWUgzSFR6bVRxaERFNUE9PQ==
Yeah. Just did so,r/machinelearning,Z0FBQUFBQm0yeGI3c0VYd3duSk9vQXdEM0FIa3V6MU9sZEFVZE44RHFaMHFTaGp4Vi1ZZWVyU0k2SjQ3cmFCamxCS2FVQVUxVDlWdjgxcWdxN0laSEtlck9mVkVvZ29velE9PQ==
"Agree 100%. Only thing limiting is if the dataset is massive, even then use the LLM to train an even more robust classifier. ",r/machinelearning,Z0FBQUFBQm0yeGI3VTZhczNvUUhDSmcxU3ozRFZhUU93NXNrMHBHN3dDODlPeU5GZE9RNnRhUmVnVXVKYzVnWjhjYU43RUZoUXdMTDhKVlhzdlRoRXV6MkZIT0J6cXBrSFg3X1ZFaXFKOUxRYnJwYmp5bGIyVkU9
"Can you clarify what you mean when you say 2 steps for RPO? RPO just seems like a slight variant of DPO that accounts for the magnitude of the reward differences. DPO only tries to push down the rejected response and push up the chosen response, so there's some loss of information there which RPO tries to mitigate.",r/machinelearning,Z0FBQUFBQm0yeGI3R0t3VUZmZ3o2eC1ENlBXcmMxekE5T3hyckRiNnI0Y2pxMG01d0t5VzdTN3hyekdDR1A1SFNYc05yaENrNlJlaVFQQmRYdmpJWXdVWHlvZUdiNWY3cXI4UkVLV0dtT3p2ZWNhaXRMeWoteDA9
If time and cost are not important. They are usually.,r/machinelearning,Z0FBQUFBQm0yeGI3TWlEdHlxdm1XN01QUDN4QlNGdjcybDRjOVBXb2JvZVRJeFQ3M3lna01GbG1SSkliN3VINXgtV09teEJFWTJ1S0ZuaWUwRXA3el9hNTJINFVaanNod3c9PQ==
"He's an LLM hype boy. His story details don't match between youtube and reddit.  
And technical details are suspicious. For some reason, he formatted all the messages with HTML tags. However, the service he used for fine-tuning accepts data in jsonl file. His case would require data uploaded as jsonl rows following Chat Completions API Schema, which, of course, doesn't need html tags included.",r/machinelearning,Z0FBQUFBQm0yeGI3ZWF2eEllVFNGaG0tekhJMDZyN0djQkpmcmdHMmlXSElOcDZYMk9yMEU3em1wX0cyQXdiOC1QN3E3aEhxaEd0RURsMkdOUEZxNWx5REp4QnQwLUdyN1pRYUtScUd3X2FxTy1WdUQtcTRYZkE9
"LLMs do make a lot
Of things easier but honestly using smaller non llm models can be just as correct. Biggest deterrent to using llm can be cost and also latency cause some LLMs can be very slow if there is a lot of input to go over so a more traditional smaller model trained on features might still be preferable.",r/machinelearning,Z0FBQUFBQm0yeGI3X1FwT292TW5MNWR1RVNKdTBvT1lvVVFxRnNhUU5DeHJrUUxXdHdVUDNzWjVUOXFZQUZhQUJoNEJua2pZSHFNSnY5akItZG5FeF9RUDk4SU9LLWloLXhrZnpYZ1VUQkNVXzJyTjlLSk5DbTQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3S0ZNalBuMENzdHo5eENWc2V4N2pmSFdXd0lkS0tLV3JBTTg3czNnaF9lT3VVX056RWlhbEFxMXdRalVnOUFzN3JfOXZybXp6NHNZUDI5bWRQMGd2bHc9PQ==
"Even imagenet can be basically seen as ""solved"" nowadays. I think it depends on your findings on the other datasets. Do you expect a significant improvement? Then I would run the benchmark. Otherwise a different dataset (as mentioned in another comment) might be more useful.",r/machinelearning,Z0FBQUFBQm0yeGI3aExUdndOS3g1cnU5a3cwZ3pRTUlQRjdiWWNKaDZTTGlhenp0Szhxb3RGelhad1VvQUR1WXpTdlVPZlc0bEFZdXBFVnF6RnlMM0xRTjFBTm5TSmZ5aVE9PQ==
"It's not about improvement, it's about basically same results but cheaper. So I'm not sure how many datasets I need to train on to verify my results... But yeah COCO seems like a good place to start.",r/machinelearning,Z0FBQUFBQm0yeGI3bjByTXA1YndfQ2I1NlNMUEhMNUFtbXM3TW8yVWxqc3NfalowaTdNTnJBN2x5akZIRFM1NHhUQ1VKRDdnemJnLUJ6eldhampxdTFBRDVHVUc1R0ZxWFE9PQ==
"This kind of thing is like a primitive version of a mind upload. Add video and audio and you an effectively ""clone"" yourself",r/machinelearning,Z0FBQUFBQm0yeGI3dzd3amU1UE9UVDUwRk55RHJ0bEFVRlhLQVBiWGtweE5HbzlYNXZ2OHMxdFBGVVhxVTVPWlNyZ0k0bDZhS1lRQmJzeDdPTkJhUFAzYjFrNXdjSE0teWc9PQ==
"Yep, this totally works.

Enjoy yourself, lol!",r/machinelearning,Z0FBQUFBQm0yeGI3aExkQW9mMV85ek0zUTEtR29LZmF5ZTYzTUxsRTRRM1lYMEtDRGNDMFNrUUgtU1lXYnV3NkE5ZDlMRG80VXVTc3RvN2NzODZwaVl2d2IxZDdqV1ZiY0E9PQ==
"Check out MIMIC-III dataset for critical care data, perfect for your project!",r/machinelearning,Z0FBQUFBQm0yeGI3YmpyMGJ1Y25LNWRCeWZrVmtuZXBXOXNOTGpYOV91cnZESGJDcDBleHd1bVhpY3ZYSXRyVHJTTjJsdi1lRk1Sa1pmaXNjTFY2X242LTJFT1RvamJLM0hDSklPZDFGSXY3OXFfVFVLUkNzMDg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3bTBya3BHZkh0NXItR0p6MGRJeUx4TFo1X2hSY0Q1WlRIM2VrdFVra242dzhmeGhZbnJEbjY1OE5zN2FvS09FLXZzVll3S2F2OE1nR2hQNF9QaG5VWUE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3RWdaQWlFY2hBS3NfdnM4QXNqQW1HRG9sSGgzbEF5NlAyVjY4R0M4YVdwdWlBbW56ZGl4UnpOc1lTVXlXaFJZVFdtRDFoOG53cGw1WTVyZE1qWUJHbEdPaW1xVWdVRmsxdllRNDRZYW92dVU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eWMtZHZaU2pHX28wR1d3ZUppY3RTVnNfS1ptU2ttY1JJSFBnXy1nekZpbVdFd0VDY0Mtell3ZkQzSXVfdzhLXzFGSjZpeDd2NWt1TEVUQ0JfTVJtUXc9PQ==
">
>Now we have coked up MBAs claiming they’re AI experts since they signed up for a free trial of GPT3.5.
>
Can confirm. Did taxes for one this past season. Not explicitly coked up but did arrive at the office in rollerblades. Twice. In the same day.",r/machinelearning,Z0FBQUFBQm0yeGI3dk1aYlVfTXdCMDRad1JiYkEwUXhtOEduQnNzdmV5Qi0wZHMzY0hMaE9sWDkyVHBseEhWMmlWcmVFZWR0RFJ4RHVjcjhfN0g4dEVRMDhuV29oMG5zN0E9PQ==
"This sub is a joke right now, some random 4k sub channel with an Indian dude doing the most basic ""side project"" got 117 upvote in 8 hours.",r/machinelearning,Z0FBQUFBQm0yeGI3eVhfVnFWVzFwd180MDZ3N245ZkhCbmpHRnFHZGVSbDBmckg2MzQ0ZnVyTW1tWjcxc1FqMUVSSlFtNnBTQWlqWW1tMTRqQ0NUdkZzb0NOaldnQ0FrU1E9PQ==
"Sorry, I am both not trusting their technical report and not finding it impressive at the same time. First, they didn't compare to llama.
Second, I don't trust the way they conduct experiments on pr reports. Lastly, I don't care about their tech as long as they don't publish papers, similarity to OpenAI (Apple is even worst).

It's probably not so difficult to do what they did if you are Apple, and they probably mostly integrated existing technology, now marketing it as their ideas because there is no f***ing paper.

Regarding how feasible it is, well, there is a lot of engineering for powe consumption, etc., but I would say that on the basic form it is utterly trivial, if you root your device you can do it yourself (just slower and takes more battery).

For example, the way they described adapters implies it's innovative, although they said ""utilize"" to not claim it's their idea. However, they do imply it is not an idea everyone who does NLP uses.
Personally, I have used it as well for similar tasks.
Overall, I didn't like the report at all.

A win for the marketing team, though. It's also an interesting experiment at scale, but the results will never be shared since they share nothing.",r/machinelearning,Z0FBQUFBQm0yeGI3QUIwSVp6aUhLR3NHekN6QWtpcWhoSnBGaE9rdDdhOXJuRUdma2tnMXcyV096YXUzeFFZRmxJbFhrSnFyZXpUYnVFUTVZbFJTR2J5UExsTFREZXVqaXVhakZwdGNtQVZHRWk2MkhaY0pjV0U9
"I believe everyone is using mamba now. Which is basically conda. 


 I personally set it all up in docker (a container). But, thats a harder learning curve if you don't know it.",r/machinelearning,Z0FBQUFBQm0yeGI3bmFVRjY1b1JvZUw0U245OEN5eThkMmxvSjlaM0V1UGJsbDUtS1NjN3l1Wkg3YTJMdjdQWXpNejI3ZVd6MnVxdzViZWktZGRDV3hvZzRmaWp1dW95NXc9PQ==
Do you really say Bro that much?,r/machinelearning,Z0FBQUFBQm0yeGI3cUFTZ1A3S2hwVnNpVGp3NnBIU1JDRnNkWkg4SFl2VG05aDAxRDVMVEdXYmM5VXlEdVZrT0pBV0VudmpKM0VZRkZKSTliREdxbHdiZUlkYW51Uk1Qenc9PQ==
"Thank you. How about between the ""normal"" deep learning versus the big multi-modal LLMs of today? Is it basically just a spectrum and we decide based on the tradeoffs, or in general, just use, say, Claude Opus/Sonnet/Haiku, as long as the money makes sense?",r/machinelearning,Z0FBQUFBQm0yeGI3bGN1NUsxYkU4Wm8xclJWeGJmOW1DWkJQb01zbVpxQWZINzhjajhGanRBc2VIbjhGQ29vSmxWOXNZVWRQVHJLcUM2bHFGSnRqRHdISU52enJqX19zbHc9PQ==
"If efficiency or ease of hyperparameter tuning is the goal, I would try to demonstrate that in a regime where you care about those things. Cifar/mnist are so small that you sorta don't care how long training takes because anything reasonable will work in a reasonable time frame. Imagenet is big enough where you have to be judicious if you don't have unlimited time and money. So that would be the scale that your target audience would care about efficiency of an optimizer or how easy it is to find a good enough hp setting. 

Also most of the expense for imagenet is due to the resolution. You can train on lower resolution for far cheaper and still get pretty good results as long as you aren't expecting to match giant models pretrained on a billion images. Check out progressive resizing fastai/Jeremy Howard has a nice blog post on it I think. Also there have been at least a couple large comparisons of optimizers on cifar scale problems and they largely find that no optimizer dominates and that even plain SGD works fine if you tune it well. Leslie Smith has some good papers on quickly finding good but not perfect hyperparameters that are great if you want to avoid a hyperparameter search",r/machinelearning,Z0FBQUFBQm0yeGI3aGowRUZWUHkwbmo5X01VVVJFaHVpZ015ODFKZm1reWZVU2NHM1JTdHZkcTd2RXlxOWVRak16eHJTVllzMVUxUzJ0aUtmLWVYN2l6WWEyM09KZjRkYkE9PQ==
"My rule of thumb about LLMs is that they are only appropriate to use when you already know what the answer should be, but you want help iterating on it. So they're good for things like editing documents, writing boilerplate code, or information retrieval when you have access to the original sources.

You shouldn't use them if you're not willing to double check their work though. Like, you should never look up information with an LLM and then just trust that it's right; you need to look at the original source to verify it. Or you should never let it write code and then just deploy the code without checking the code first.

This is different from ""normal' deep learning in the sense that it's very hard to measure the reliability of an LLMs typical output, which is why checking it is necessary. With ""normal"" deep learning, by contrast, you usually have clear quantitative metrics that will let you know how often the model is right, and under what circumstances it makes mistakes. This allows you to understand when and where it can be used without much human supervision.",r/machinelearning,Z0FBQUFBQm0yeGI3SnlTaF9aOGFKSmliZjQ5c1NfbXc1SlhKekFJUV9xaHZidkF5OUtka0VhMnlVanppU3VsdDlVN0t1VTNBTlQyc2k3czZCN09DV1lwcFQ0NVNTdGpPaUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3VTNpZzFEWXZjVUlZNEZJS1ZQVGl4cGNxUmViZjBtTDlrdzVPNjRDSmJqMzg1STRleENjSUVzTmRURTNOenM0cXBOc0FFa0JWREpmajFpdlNxZ0swRXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3U2lqSS00NklET3R1VEE5ZTZEUnRaY1hJTkxVSGJYb1lqc1FEZktMQjcyZWl3NzJJbUM0X0xTN19tZ2hmQlJtODNpLXZaQjlWTTZpekpjdEFrUHFpNnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3di0zUDl2emdUVDNDNnpRdWxQVUZna2V0UUVjT0tuOFItNl94YWtDMEhlSWpnTEJ5ME1RX1VqeXgxRVRTMXcxeHFTTE5IOERDTFg3cWlCRldCX3ZYekE9PQ==
"If you have a very niche project cultivate your resume to focus not on the project itself, but the skills needed to complete the work. Time management, teamwork, problem solving etc. My PhD thesis was researching ancient plant leaf waxes and my first job was a forensic chemist with customs and border protection so I was hired for my ability to learn, not necessarily what I worked on in school.",r/machinelearning,Z0FBQUFBQm0yeGI3ejlCRU9DMEttUHQySHdKQ1JGSWpDdFU3NGFhdjRKTEktT2JacTc1cWxzY1lfTW50dkZPR05VajVpSm5vbnhrY3BXTXpLeVJlM1NrakJ0Sm1WNzgwMlgzdlZ4Uk1SV05KcVNQenJsRTlVT1U9
"Yes, they also tried to make this idea look like their innovation, although they didn't claim they came up with it.

Edit: but this specific paper looks very interesting.",r/machinelearning,Z0FBQUFBQm0yeGI3TWlrN0dvb2pXZDU5QXZfX0cxS3o5TVZqVkxyWjBza3MzbTVKajRvNU5LQndHeTdzQWozTW43R1dTWU9DSUkzVjFDM04yNk5qeU1lTmZLWXN4YWJLb2Z4bUNTQThZWkxUT0lpQTVQVFlKY0k9
"Yes, that's the way to do it, unless you have ~half a year to spend on each model you train.",r/machinelearning,Z0FBQUFBQm0yeGI3dy11VTVUS1lBdmZ1dWxuczVldW9oRmxNU1kyMy1PdkZxOXo1QWtLc3ZXVTd4dlJ6VFhLV1NXdGcyY282enAtd1dfeXE5MEh5dUpXaXFCa1EwQWU2eHN5V1FEZUppbTg3MmJZQnJvMkJIQUE9
Is no dropout common nowadays? Is layerdrop used in nlp tasks?,r/machinelearning,Z0FBQUFBQm0yeGI3aDd1TDFTUUFrWV9zNHNhMy14RXZzYUZBcnVuQktQN1dBdFlCSGN2SEdRLVZFWU16cjF6NHo2dGRWNXdLODJfRW5BYnlpb2xDSWlWTXNNYTRIVnpsd2c9PQ==
Thank you very much! I appreciate your answers.,r/machinelearning,Z0FBQUFBQm0yeGI3XzhHblU2dDdpWlU0Y3FUZHZXaFJGdmRscDBudGN3dkpTNC0zOHhvQ3VUYmIwa3VfVlE5TUx1eDZ2U0t4SGJjNVdUNHRiN0tCSEotWjYyUm5wbUk3bnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3T0dvOTJraDlsMm1KNk1tbW5JLVlsWHBVOS1lM0FrZ0ZZVnVkb1ROZkdOMFdBNnM0WC1HbXI3WGVDZVU2cVI0bjRfMDRJMjFydkU5VzBRUTNJdFdNUnc9PQ==
taking up too much space when run at massive scale,r/machinelearning,Z0FBQUFBQm0yeGI3SVVsSUZSakhCakFEUDFpYUJBSk56S1VUbkdFODd0S0VTMmpLekp2OVFYQTdOUENHV2hwTnJpbTFDcXJVdlg4a0RENlg1b2ZHNWpUS3RIX1RQelBFOEE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3RE9pbnNFMGJYbHNWUmx6WkJRMzZFSnJWdzdYaWxMQ1kzcTktLUdtYm9YaFhYeW5TMUk1NjRkeDRlaG9XRlgyeGRPRlVOSEwybUJtc042Y2Y5NFV1clJMY3NYX2x3WWdGS1k4Ynp0c3Q4V1E9
"Here's a YouTube video on the topic. They mention links to research  
[https://www.youtube.com/watch?v=HE4ykZATuIw&list=LL&index=2](https://www.youtube.com/watch?v=HE4ykZATuIw&list=LL&index=2)",r/machinelearning,Z0FBQUFBQm0yeGI3QmJKeXU0cjZaUmppWWZmZjhRTFZTbU5talNsRVBQaU96UUREWlZSZXhEbkdtSWM4ZEpWWi1xQzdKQ09zODNXTjBtcUVFUE1oTUU2LVY2bWZscEpHbkE9PQ==
Sent a chat. Interested in similar.,r/machinelearning,Z0FBQUFBQm0yeGI3YWU1YmpTaVdGZnU0RXhiaHdTb045NzU3LTIydW5Xd3ZoeEVYUWdrUFZRZy1Vb3RkbkxvSW9DNWhkc3NUWG9DVlZrenltZWg3UDU0TUYwbVZ0b3RwUHc9PQ==
"For training or experimenting with models we sometimes use  stuff like Hugging face Detectron2, Ultralytics, etc. But for actual production use cases, we export the trained model into a more portable format like torchscript, tflite, onnx, etc. then wrap it into the rest of the production code in C++, Java, Kotlin, etc. for production level efficiency and performance.

Though keep in mind many researchers or industry data scientists will heavily modify their training libraries. I've personally rewritten big chunks of Detectron2 while training a model because I needed capabilities not in there, also certain parts of the library are somewhat inefficient.",r/machinelearning,Z0FBQUFBQm0yeGI3bHEyOFVya2RyLTFGb1BzekxtNHdEVWdZZmFObVpRZjNVamZQQVIyVG5zQ1c4QUc4dVZqaHkyM3lqSDRBQVdVNUlVZFFXYy14U0EtQzRISVkzWEtkS3c9PQ==
"The real problem is not that MNIST and CIFAR10 are not representative of real workloads. That is certainly an issue, but I think the larger concern would be whether you have done a lot of workload-specific hyperparameter tuning (either explicitly or implicitly) that will overstate the performance of your method relative to your baselines and that, in general, you might not have had the resources to build the strongest possible baselines.

If you are studying neural network training algorithms, consider implementing your method to comply with the [AlgoPerf benchmark rules](https://github.com/mlcommons/algorithmic-efficiency) that limit workload-specific tuning (either tuning ruleset). You can see the rationale for the rules [here](https://arxiv.org/abs/2306.07179) along with other suggestions on comparing training algorithms from the [MLCommons Algorithms working group](https://mlcommons.org/en/groups/research-algorithms/).  I co-chair the working group currently and we are working on developing a process where people can present evidence that they have something interesting to evaluate and then the working group can do the somewhat expensive scoring process to add it to a leaderboard. Anyone interested is welcome to join.",r/machinelearning,Z0FBQUFBQm0yeGI3cm81RmN4SVp1Y0hoT1g2YTVEaHhuNnhFVHBrTUxXSzBYY0gwWTg4WlJkWmt3X1BiaWRXY2dXZHJCMk5IZkNjQ3NtQkpkbXFJbkdxUGEtSUwzc0xwbUE9PQ==
"Use a free colab notebook with GPU and run a standard benchmarks there.


A lot of times where results on toy data don’t translate to meaningful improvements",r/machinelearning,Z0FBQUFBQm0yeGI3a2JIUEJ2RDBDSS1RM2hOSFl0ZHhqZ1JyNDNpUnkxMEg2Y3ZyVEpHRkY1ZTFJUXNMZFd2VElpTUwxVDltZWJPNmNFdEZDaENlODNodVVtRk56bDRObTQ2YUYxRWd2RHVqQkVnNUxwZURQX0E9
"I guess the ""CLIP"" there should be a ""ViT"", and your opinion is interesting.",r/machinelearning,Z0FBQUFBQm0yeGI3WmNjdlY2TDdhLW0xejZ5Sm5PUWJBNHhMWEwzRndnUk5NbE10RVNWWS0wNThFd2pYZjQ0OW1hclRJeV9CWDAxbGpnNXBGZ1ZUaWVfenBveS1MLWh5SklaY2M4RFViWnlabmJZaUprMXF5eXc9
"No, I am not planning to make a product out of this. ",r/machinelearning,Z0FBQUFBQm0yeGI3ODA2N2I1ejVoT3RvcHMxX2phaXlYSXhUeHJBZnJVWEpRc3pSelg5dGxSVXlWaHlMLVZibm8yWGNfQy1UQnF1ZHBkQkNHeHozWXd3anZUcm9INk9zUlE9PQ==
What type of data are you using for continual pretraining? Instructions qa? Or just unstructured text?,r/machinelearning,Z0FBQUFBQm0yeGI3MERxNER1N1p5d2NGeE5ob0J1VjRTYXE0UEFOOUlRSGJKbGo4a0laXzM1SFhZRFFGZ2JGSWhRV0d4SXJXbzdKUEgwTEJTeWRPcUFJc0NWSHFQeGYzV1E9PQ==
"You need to format messsages in HTML format. How you will let the AI know when to start writing message as me? And how you will ""stop"" the LLM when he's done writing the message? I will push the code in GitHub and then I think you will believe me.",r/machinelearning,Z0FBQUFBQm0yeGI3emNXNGl5NzctRmJJenV2NlNtNVdlWTVmSWZMVWhRc2hmRUZpWmlQUzVCdk1GdmNmWGYzTGktSG40MjBrNEV5clprVzJoNWtoOC1jNWQ5MTVuVXBOUGc9PQ==
https://readme.fireworks.ai/docs/fine-tuning-models,r/machinelearning,Z0FBQUFBQm0yeGI3TWpGUWJaSzdBdXdFbE1BSFBrYTdmS19jMzNlWTAzZWdFb0toTlZ3bWlnblpTaXYxRXczWllmMTBXSXlXNDI3Y1ItOGtLbFl2QkdWQWxUUUROdVZDS3c9PQ==
"Yes it supports sending multiple messages back to back. I did added a ""fake"" typing effect so people can see the ""typing.."" thing on top of WhatsApp.",r/machinelearning,Z0FBQUFBQm0yeGI3Y19RblVVT2NTYURKQ1FKNDJkdHJPSEpFSC1HOEF2Zl91WFh0WnVZR0F5NzFGRmt4eExwaFozMjB4ZWhuLW5KTWNURS1UTWVmbFRhdXdJc1hEMGg1MGc9PQ==
"Yes, it is.",r/machinelearning,Z0FBQUFBQm0yeGI3Y0d6RDFVZ0tjdF92dGVsdHM2cGVhcUg4dEZrUnd1dDh4eVBtOHZaVUJYQjhwOTE2a1ROOXlqLUU2MEtobXoyc2JOeENjUm9VZEdVWDRPbktoeWl4c0E9PQ==
The project was fun that's why I thought to share it here. What does this all have to do with me being Indian? I think others also think this is fun that's why they cared to gave me an upvote I guess.,r/machinelearning,Z0FBQUFBQm0yeGI3QmNiZE45WlFkSFk3M2tlcDc1Ymg0R0hvVndDckFRUkJCZWJia2FQYjlKOVFrZHpiUG1IQXBGZjFRUzB4YzF5a1BHYV9jWGtBZkE2eklQRnFqMW5Nenc9PQ==
"Yes, it's not perfect.",r/machinelearning,Z0FBQUFBQm0yeGI3MUpfN29LSllZdG8zbkJ1ekE4dHNKNVhVcWpQYkdFc2tMZ0V0Z3FOWFlwVkZBeS1TOUU0aHhEMzRDTExBNDF2dmJlOVVmTjdBU0kzSnQzeXFqci1oRmc9PQ==
Thanks!,r/machinelearning,Z0FBQUFBQm0yeGI3bm9XSlRsRzFrdGNwbWdSQXdFLWx0cTYxWG1wWEhIcU5ZSG9rU3ZQbnJnc3VvdzFldzMwSE13LUJLUHJZYl9TamE2R2tzeDM5MmtLMFRJLUJBZDc2cGc9PQ==
"Yes, I used a sercive.",r/machinelearning,Z0FBQUFBQm0yeGI3MG9LWDBIWXNsREpVbGVWUHFGNWFKTjlMeXFLMkxMUXVUeUUyNW1vNUM2c011QnltOFF2ckZvYkZ6cWtTdGFjckxQQ3pCTGRVeUhUZnJNNlZyS0otOVE9PQ==
"Yes, I will post the code.",r/machinelearning,Z0FBQUFBQm0yeGI3QjBKdDBFVmFqcUZMOGg2d296RVFjeDVPSDFDajlJT2RrQ3hQUWEwaFY3MmNoQ1VQQ004MUowWm1OOXB6aTlrSkpzNkRvMzZ1NFB5OFk1Y3U3STZiY1E9PQ==
What is the goal of the model? What task are you trying to achieve?,r/machinelearning,Z0FBQUFBQm0yeGI3ZWF5UkxscUJCY1hoYktUWXhDdlVoREhDUmpTWndrUHJIcjgyVUhiem91VllCbk53cXNGbU50UVZveDBXUkdpYmFudFZDVm9IY3I1Ry1GWlRlRThzRFE9PQ==
"That makes zero sense. You uploaded training data for the model, not instructions for LLM when to talk. Training data is not used directly to talk, but as a ""guide"" of how to build text.  
Anyway, you mentioned using [fireworks.ai](http://fireworks.ai) On that service, training data can't be uploaded in html, because obody uses html other than for frontend pages. But it can be uploaded in jsonl file matching CC API schema. That schema defines how you can separate messages in your data, and group them in separate conversations between the sender and the responder. No html is used",r/machinelearning,Z0FBQUFBQm0yeGI3d3hZdExyb2xTcHBOUXhweG5PMXVKaFVLblpjTldtbVhsalVUaklLejQtQ00wa1dnbVJUQ0RQTHhfYXNPbGF1WVdvcURWSGZtSTE4ejdnTnpLc0NLZXpjV0VYdlFsbkUyOXBKNUJSUmxhR2s9
"Ok bro did you also write a bot that responds for you on reddit?  
The only html on that page is the page itself",r/machinelearning,Z0FBQUFBQm0yeGI3NEEyRU41WnRQTmxVWkRjNExiaW1LeUo3U0ZOaUxQZDFsd1hYY0RzS3pGUjh6WWpneURsUlE1QkhLQzJtaXotajJpR29HcHJpVlJNN2NQWGhTdXB1YldNeVNWYzJ4STFoanBGajJhU2Rpbzg9
"Looking back through this thread in June 2024, you’re totally on point with this. It’s clear you’ve been in the loop with all the research and developments. Pretty impressive how you called it years ago, especially with how the discussion on transformers has evolved since then.",r/machinelearning,Z0FBQUFBQm0yeGI3VTVLZldBa2N0TkJmM0pWcGNXeFpDbzdYaDNHZnhYUU8tMFA4d3BrbHE0S1docktqaGNZYUlnQjUyZE9nOUlOR3UyYVB2Q3NGZGg4QllmU3BUX1F6bkE9PQ==
"I got 2/3/3/3, the reviewers are too mean...Crying... I don't think my paper is too bad to get even one positive score.",r/machinelearning,Z0FBQUFBQm0yeGI3NnAtaGpfdllVNGt5YUdOQ3VlakVpeFpQUHF2bjZYZUkzNjJOMUQ4VkI4VG12Z0xFUzg2dGkza3BwSFpGcFA2aFVBdXl4Vzc3dE5GRXBFSFZ1MHE2Q3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MGgwb05xSXdwZWhOeUxKV1l5S1dqNmRyVGhraTNWUm9aNjN1RXZIWUxraVBVUGE3dC0xSFdHX2RTMnZWOEpWbUpVNE1RLUttMjZXcml6RWczYy03S3c9PQ==
"There's [Lorax ](https://github.com/predibase/lorax)and [Multi-LoRAs](https://github.com/uukuguy/multi_loras).

Lorax:

>Dynamic Adapter Loading: include any fine-tuned LoRA adapter from HuggingFace, Predibase, or any filesystem in your request, it will be loaded just-in-time without blocking concurrent requests. Merge adapters per request to instantly create powerful ensembles.

Multi-Lora:

>Load multiple LoRA modules simultaneously and automatically switch the appropriate combination of LoRA modules to generate the best answer based on user queries.

Both repos have been around for about 8+ months, but not sure exactly how close they are to this.",r/machinelearning,Z0FBQUFBQm0yeGI3WU1wVTdoMEd0UWVwaWpZZnlHSUxqcEptZ2hBN2p4aWFob0g5Q0tqb2l0THRURTd5X1JpR2JzNGtvU1hPQW9SekFNU0laY1NudXIzMXl4VXZMNDBUNVZxWWlSejEyXzJTUW9ISnNVdjZZUDg9
"Ye they published all 3! The base, reward and instruct, and also their Help Steer dataset!",r/machinelearning,Z0FBQUFBQm0yeGI3dEQtQ3dRSTFKRUtxdEVOdzhHbS1URkJrZ1NHZlR3RmtHbHZjLVdYSmhyQ1pyZTlPcjVseDduajl1dEktbzRETFdnN0FxMFdDbm5ZOXZmUkJ5ekZEVlE9PQ==
"Oh I think the paper said they used two rounds of RPO. It's like SPIN I think - tbh I didn't read the paper too intently, so best to consult the paper.",r/machinelearning,Z0FBQUFBQm0yeGI3M1VMcHNTWUFGS2JDLVVqZ0VHeFdaTThyOExOc01YODNPRWxsdVUtc3pfWmFod196U2JROGMtT3dFTVowa2toYzJaTy1fZGhJSXRIZXZTQ0dwNHZRZVE9PQ==
"Ye no dropout - I think after GPT2, dropout was essentially removed.",r/machinelearning,Z0FBQUFBQm0yeGI3ZDEyQlVtTHJQRzRpdUtRMkJkX1BSZ29vdTZwekdPX3JfWVRzOE9EZzFyU0lZbzRvSkVFbFJkUGRZX1FkZUVKdlBDTUVHOTdBcDFTOVdDUnlBT2hmUWc9PQ==
Their entire repo is here: https://huggingface.co/collections/nvidia/nemotron-4-340b-666b7ebaf1b3867caf2f1911 :),r/machinelearning,Z0FBQUFBQm0yeGI3dmJuUmhmTHF1Mkt5bmtsb1c3aDQzWUVBUFVpeVZfNzJWZExJeW1vMll6ay1LWEthd0lzQzNWTV9SSEdXLUE2anl6b1k1LVRyWHd2R3ZtQlFmeElldHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3WEw0ejZmZUpxOUNBWU53Y2ozbUtncVBObkFfNm1PZ0JldVh2QUdFdmxHRlFCRXNia0p2S3hESnY1bTVuS002MlM5NlhVR1c4YS1SYllJYU0yazhYZkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MEcwLWh1N2lBd204RFdrRUZXRm9WNVlFVzAtdDF4eE1oeFUzMVhDMWZNWlFTOThmYjdFU1RGb04tNTdoYVdGa2M2YlBxbkY5emstZl9ZVHFfbmowcXc9PQ==
Money lol,r/machinelearning,Z0FBQUFBQm0yeGI3eS1IclBVZkFHa29oN0JsTC14YzVGc2xZRFQtWnBSTzlMNjRaWmlHOG9ycnd0dnBZWnlZRGhYMUo5QUp1a2NvMEd1SS1hQjh3elFCTTVQU3g1dFFVMHc9PQ==
"That context length of up to 4,096 tokens is brutal.",r/machinelearning,Z0FBQUFBQm0yeGI3bURWN2tqVlNWZDlaMFpGM2RFMGZaU0lxd3ljUFVZNVdOZUhBNC1pYUhOVlBYOHFaVDYzbmNUTml2RnlNSlh0a1kxNUY1SG4xNGJ0VkFXYW9lYXRBNmc9PQ==
Thankyou for this,r/machinelearning,Z0FBQUFBQm0yeGI3TWR4ZmZzNHVrdERUYU5zWVJCYnREdFZGN1pHbk5ndGJtbHpyTTViMUVramdHSk02RzM0U0VmMkdZaTZMYmVLSXpsUnFidlFiWW4yekVwc1VGbHFtV0E9PQ==
"We do computer vision based custom product development.

I'd be happy to help you out.",r/machinelearning,Z0FBQUFBQm0yeGI3SkRoX21lUUlRNHJqSmx2alZtRWR1ZEdfT1J6Y21pQjBGNkhiS1l3NDJyeW1uWW1xRGpJN0hQN2JvVTRFMzlwWG5EN1VpVUVRbmR1S3B5TGJYVHNROWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MS1QLUptU19aQURYaVV0dGhZaVdLOEtpc2NTNlJpR2FSUkQxSlJVcHdoV1pQREE1TFN4UkwzcWhRRDRjUWZ4VTJxejBoR0VHTVhYTVA2ek1wcThfUHc9PQ==
"Apples to oranges.

Bombs are the product. AI is an ingredient to the productm",r/machinelearning,Z0FBQUFBQm0yeGI3Q1dtT013VXFLeHpOOU5EUEVaOF9SSW93YW10UUpFbjVYZnVERVROLVUySUJXOExIMVlpelAzWWx1N2o0akdleThOalZfelpMSUlRRmNlbmF6ckNlU3I3VFVNSm1YTU9OSGdYejAwSEcxZUE9
"Most major ML tools (e.g., pytorch) have been vision-focused for almost a decade and they're quite mature at this point. Maybe you are using the wrong tools?",r/machinelearning,Z0FBQUFBQm0yeGI3RUFLQWFmZ19GWjdGNExMUDcxRHlwWFNEa2JoUWg5UVRZTWh5M0E0RjNtcmczMmktZms1Z3ItNmUtOUlZdDFLbE1fTzBYTTRDcEp1UFNUOFNyUWxySXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3S2RTMEJCa2dlVGR3QV9zYkZlc2pLeGhYNWxnWkVCenhwTlRMM2hMV0pCWm96U0hBcnNqWVk4cmRHUkJBamNWWG1tRUxBSWdtTlZpQXBFLUhVM3I4V2c9PQ==
I appreciate that you are willing to make yourself available for a total stranger! I think what I’m experiencing is growing pains and will (hopefully) be singing a different tune in about a month 🥹,r/machinelearning,Z0FBQUFBQm0yeGI3dEVOWmpRMWNiTERTV09vSjZfb2lzc2RuRGpEUjFuXzVzN241cWRGcGlzRlR5MkR1elJDTm1ZN0xoUTlVXzk5cXBhT25PNFQwXzMwVG1FanRiQk5pUUE9PQ==
"You might be right. Also the use case is a bit tricky. I’m using GeoTIFF images to train a model in classification type problem. The images are h u g e and the program to work with them (QGIS ) is s l o w. Which means reformatting, annotating,creating thresholds that maintain the geographic coordinates is a painful process for my work machine (which is not nearly as powerful as my personal machine).",r/machinelearning,Z0FBQUFBQm0yeGI3dWRWNnFlWm8tVnl2alM2YWJUeEJSZXhINEcxT0kzMXBGakI5czVLQ2FRaDZrTVA5d0J6ZktPR0NualFhQTVsemxPWTNNNEZRWWNyaGYwM3N6WTFfTlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3UzFoancxUnJoM2lMd21tYnlxUURIQktEWXhkRy1NcHJKTzRza0JxUjdOWEJrWWJNWUZ4QUtObUNFcG5NYWpsNld4ME1yOFdWdE5uUnkzX3YzTWlhaWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3SHNCaC1HQ2lhNlBjd0g2bEp2R2tpVTFXUXU3NWpIMTNrOER4eFR4RlM4b3J3YTdmZ254SkRXanJEOHlaNHozbjVnZ191cV8xZF9jTTc2bTk1V3dWQ1E9PQ==
"Lol you aren't exactly working with computer vision here... It's geospatial data that's giving u the trouble 😅
I would suggest you to get familiarized with gdal first. QGIS is ok for analysis not for automated development.",r/machinelearning,Z0FBQUFBQm0yeGI3ZURzMThta0tCYUcwSmNXcWZ5RnZaUVdOejVVNGVVUFVwcXlUeVJqcnhqZzRQeFFiV3EtQkUxSlZKSHdWNEpNUjhhbTJqd1NnelpyV0lVTGFkQ0lKeE1rc0JsU0l2QzJESTlKQ0NkdHVXeEE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3N0RLOUJqNWh6UkdwU3pRZm0yNUhUckotWndtSnNvclphN3pYdE9ETWhORENsUTU2NGItU1k1R01fclp3US1wR09wcmxwS0xSLThnUFJCdDB4eC1LSFE9PQ==
"Conda works quite well for me, but I have to strictly follow two rules: always use the libmamba solver (or use a mamba-enabled installation), and always use env.yml to update environments. It manages ""system"" level dependencies quite well and can keep separate versions for different environments. You just have to include the right package in your env list so that it does not fall back to the system default version. The problem that used to trip me up all the time was matching nvcc and gcc versions, which is quite painful to solve on the system level (I hate fiddling with alternatives), but if you include the nvcc complete package and the cxx complier (or build tools) package, it automatically matches the versions for you.",r/machinelearning,Z0FBQUFBQm0yeGI3dWZCSlgzLUNoTEt0TVhMMm1FSnNEWUV4NURuTjdrNWlPejd2cW5mcDk3TUFkdmpuY2hxMHJTNldrWkE2VHBSZmRNcFpBcGoxNjBDdWRrSDlJcXJPc0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3dXVtM2FBWFo3LXFiUUtQeTk1NElrSjJuS3pTc1FIQW1nMmhZb29tcFNSQktLMk1Pd1R2RUlkOWsxd3dZWVBHUTdMUWNLUUt5ckc0YUVELWE5ZHFYX2c9PQ==
"In my experience data is data, I think the harder challenges are when you are working with multi modal rnns and have multiple asynchronous data streams, and have to execute models in a performant way on a device",r/machinelearning,Z0FBQUFBQm0yeGI3MDNacmo0MXlrQTJhSENfdk83MjI0RUlJVmtBWnBkbnIwd3lQOHJxODlQeVhXYnpiUm1MTXJzWTVTTkY1ZXRyMFNnR0FNUnVfX1JjTkZQSzZZS0lQeUc4Wm1xamxBeHlKMVhOc0s0MUJ4bHM9
rip battery life for next few generations of iphones,r/machinelearning,Z0FBQUFBQm0yeGI3bGFEdGVodWVEdUY4cE1aOG9uWEw5QlVYSGhPNU9jVWlNT1FuWmN5VEh4bzlUdXZJVjgzN1F0TFVkRXhLN2dqM3RrOC1MT1hJNmpaY3hxVGVINXM3YlE9PQ==
"Saw this via the LocalLlama cross post and will x-post my reply. I wrote a blog post with details on what was released, looking at the videos and documents: https://blog.trailofbits.com/2024/06/14/understanding-apples-on-device-and-server-foundations-model-release/

* there are at least 5 models released; three on-device, two server
* the on device language models are likely variants of OpenELM
* Apple goes into detail about their palletization and quantization strategies",r/machinelearning,Z0FBQUFBQm0yeGI3M193dmZqdkFjUnpCWkNYUFB2NDlfS3IyR25hREJWVVBJY3VFcWxjS3kxNkkwWG9IaS1Fd1RrYkZqcndOWjFiUGg0OEJhNVkxTWZvRHhIYXhtZXFaeWc9PQ==
Youre 100% right. And I got the hang of QGIS and and gdal is next. I’m just being whiney because language models were my thing and starting in unfamiliar territories is always humbling lol,r/machinelearning,Z0FBQUFBQm0yeGI3VVZQVk9uRnJzTDZ6MHh5U19IX2I4dGp2M25JSHd2UVkyMHhnem94T1g3TzhrcTlKZWR3VkphTWs1UlJUcHlsaU9XTDRPWUt5Umw5b1pJT0RrTHY1YUE9PQ==
Yes and yes. My heart can’t deal with my machine crawling like it has.,r/machinelearning,Z0FBQUFBQm0yeGI3S0hoanVMbzVZazhMcmh3cG5RbHJMQWNKSUphSzVKeGRlRTctTnBIV2RBRE53TFN3TEJEdkhKLS05YndSRGJXQVUxTkdDSTE1VF9PZkxRYzFLb3VGeVE9PQ==
Yeah it's always frustrating when we are stuck on minor things in software development 😅,r/machinelearning,Z0FBQUFBQm0yeGI3WXUtbHVHV1Q4Z0lSVGdqSXZYU1d3SzJMeGNvVk9UeTVjQ2VFendCU2U1T1FEcnlzT1VsUzUzS1hxOTVtWG5JdnNrSjZQZEYwanZLYzROTGQ0b3JXVGp5YmE2aHF6azFjMzlReGd6WDN0LWM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3QmRLM0tnYWVUMVgzejRpczlvR3VpbXpkVmNPOFFnVXVsTDNTNW9VdXZyNG90XzBlTVRYWVdybHpHaUNBb09wV05OQVZFOVppb3VXVmlobFRsYlJWU2c9PQ==
"I do CV on medical imaging diagnosis. IMO it is way harder than NLP because it still lacks that big leap that LLM and Transformers did for NLP, (2) data specific for use cases are scarce and more difficult to obtain and annotate and needs more professional varieties with annotators, (3) models are not that “transferrable”. Say, ImageNet pretrained models are almost useless on completely different domains like medical imaging, and (4) there are just a bunch of completely different architectures for different domains — UNets for segmentation, YOLO and RCNN for OD, Diffusion Models and GANs fro Gen AI.",r/machinelearning,Z0FBQUFBQm0yeGI3NWtLVERnS082YkJPYTJjSTQyWlo5ZDMxOVNUS2F1LU54dDhFRlkwbVhMN2dUckZuQ0IzVHFKYk5tMHlkS2NsYnBKS1A5bkJieFZSMHgwNF9rZ1hiTFBLcDBNMFFDNzVhbzZ4NFFOQTRIU0k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ZmxjRFN1VmxHQVlsRi1ITW10cVBTMDhOTkpzemZ1YWFva3dhT2lJRlJhS0FPV0MydnhuT0V3NXhjalNPV2JTZkN2d0E1MXc1X1NkRnNvbFNmbElxNWc9PQ==
"That's a really neat transformation I never knew about, nice how it solves the problem of log being undefined at 0 by instead finding a very convoluted way to take a y_i of 0 and make it spit out 1, so therefore you're just taking a log of 1 which is 0. I assune due to the sqrt it scales pretty much everything else pretty similar to how a log would too",r/machinelearning,Z0FBQUFBQm0yeGI3eXhFV3VlN1c5QVRFNWtOZk9nLWVRdEVtZWdYM0dHbnpRSXhDMzMwbTVPdmRrTWpyRTNZamJsMHFoVXhQWTZsdzBvNF9mZmVHNldFOGUtMEhCdUZtUFNxbUNFUmxoU2lsc0FwUC1YOHNnNDg9
What's the benefit of min max normalization over a sigmoid (apart from being easier on my dumb brain)?,r/machinelearning,Z0FBQUFBQm0yeGI3elhFcjIzV0RaVGZaSDJGM1JZZi1nVlVZOXQxM2FHYzlmcVVibTZXMEtmV2laajhBbWJNWnRzb3J3UmJER1NoYTEwdmR1YmJndl9FbW5ZMVVqNGpHejY1RERUTzV1OGo0aEZFbWVhakszM0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ZFFmaUd0MGFtZHRXN2FpQjJ2c2hLa0l6T04tUUIyNGhoZ3FTQjFHSVZySGRtX0dZWVpZei12MWNWR0xULW5xOEt4MEJGSy1LTTVZSGF5N3VZS09SR3c9PQ==
"You need more evaluation like others said, plus probably more survey, searching using keywords related to your methods. It is often the case the modifications have been done before somewhere, especially for common architecture like MLPs.",r/machinelearning,Z0FBQUFBQm0yeGI3ZWtPTjVDdHhZMzl0RUJXa00tX1RQYkd5cEtrWEkyMC1vQUhWbGdURzl6SmRGRWZINXYwdDJ0WVdZVkdua19uOWNPN2lHRC1UWEV3dUVaMWJVWEdZT0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3NHFhWVJwR2l1WmZlQmhTSkk3ZGMwWkFUWTZHb0s2S3hHd0dNU1RteVRmemh3MjU5QTZUR05yVVBpYTRtc0xicXNTY1pNcElwdDdENWlEckpzWmZDb0E9PQ==
Then what is the current scenario?,r/machinelearning,Z0FBQUFBQm0yeGI3eXRzT2diLXA0cnhqaDF2Q2VpODd6M0pmVVU0bEZMa3U5NW5ieFd3S1RReTVmbDNEWllOclNrcE9HQmlKcXBMbmxmTlF3d0RhN1JUUFJvaFpwWHNFRHc9PQ==
"1. You can't. You're going to have to run regular tests on the new data to make sure things are still working the way they are.
2. Same as #1. By ""stability"" I'm assuming you're referring to deterministic behavior. Simply setting a random state or seed won't guarantee the same results if you're updating your model.",r/machinelearning,Z0FBQUFBQm0yeGI3NlljVjBvbVUtRHgyNHdic1JJVnpCc1Ntbks0VnVLemZuUWFSUV9jSFNXbHZNdlhtcmRtV1ZRUmc2RnRKWVByeU1FQmNBSWJkMWNjSm52emstaFhpa3c9PQ==
"Thanks for your response. How can this be run as a potential BAU then, say? Concerns me a bit :(",r/machinelearning,Z0FBQUFBQm0yeGI3RHpxTGx4Rnp2M3NUTHllVzZMM0pwV19HaG5xT0NSTDdTZ1liM00ySHd1V3Z1UTVMbEhIcjV1RTBUOGJsanRWTjhhMnRBbXJoQ1FVN1FlRHppYVptNnc9PQ==
"Maybe I don't understand your question, but bottleneck blocks in resnets exist for a very long time",r/machinelearning,Z0FBQUFBQm0yeGI3dVFiNkRVdEVFVldrNW5kTjEwSzZFRXpRMDgxeFA4SlZvaF93UGtrNkZKanNFaTVybHVMQjQ2WVhGZlZoS1FWUE4wdW9ZejBRNW96LUdyUUVUUFE1UEtVS3dETXRzOHlTR1lHVlVjbmRDUzg9
"I did some testing with a P100 vs 3090 Ti with bog-standard hugging face training. The P100 was about half as slow as the 3090 Ti at FP16 vs BF16. However, critically it used also half the power, so cost of training is the same, but it takes just under twice as long.

Now, if you can scale out perfectly over multiple GPUs, then you can get up to double the performance of a 3090 as P100s are about 1/4 of the cost of a 2nd hand 3090.

Of course, it will be important to also look see if there are any tricks and optimizations that are available at compute capability 8.6 that are not there at 6.0.",r/machinelearning,Z0FBQUFBQm0yeGI3WkZBeXVuYmJSeHdPODFuSWNMT2RnLUhKd25lZ0RkRF82YU9aVFdwNm9ia0VJOTAzamEyc1B4bDdOaTBBRmNNajBUTDg2UEFOdW5ySzlqVHBIeGxQTFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3cENpNWM3SVo5Q3lIT3p1N19oTzNxTGU2eEctV2YwaTU2LUlUUXlXdC0zbnN4X25qX0tSeE13NHVtcXhhcFFPUDJDYzdvTmtRTk1XalRiUHIwRG9FYUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MTQtOTJVUk94SzRiY2dGXzRuY2RySXNVaVF4VUljMlVzR2RHUlRWZHdleHJILTJ0SUlDWGRDam5ScWZfT3VZcklKdHo4bU1YWndSV0hyMXJ6VWFKSGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ZnZPTGdtb3ZVTWU0dHdzU2hKOE92cXVpa0UxUDZNdVBHV05ibDNrR2JnVjE5NXE0OUpjUnpiTTBKZTRQdEJuZHYwRnlEVWZNdVFSX2dzUEJZR3VZX3c9PQ==
I have the opposite experience. Doing vision is always a breeze. I'd take images over tabular data or text literally any day...,r/machinelearning,Z0FBQUFBQm0yeGI3NVZHSDhIVG5RNXZ5SEJDSjNWQzdyM0xmMEFaXzZxSHFIZTJWcTNTdnU5WHZlb2xCSkYtVGdVeU9wSjdRRmxseDF0cUo4ZGducHNoWWROSF84NGpzd0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3bW54TUtxZm1VTHZLZ3AtOHkzRmM0N2pNU21sNmZETU5iU2NKd0FnRUFMRS1TdXVPeWV3T3IyY2FHUmZwdFJ5S0xYXzd3M2R6bmlYWUl4WFFSaEFDNmc9PQ==
Ye :(,r/machinelearning,Z0FBQUFBQm0yeGI3NlJrOFlVLUtDeDM4Q2lRRjN3ZGxjd2ZvZU91V0ZabW5XNE1Mc0xDdGlmZWxpTmJsMUZXaHFqTXdheHJTa1ZNa1RWTmdjQ2xidXpwY3VqUFNIdGFBdlE9PQ==
You're expecting advices from Reddit users who are also computer geeks.,r/machinelearning,Z0FBQUFBQm0yeGI3a1ptel9FLUlFZDR5YTc1d2V3V1d0WE90SjVfVFhPZjNKM3hjSnk5SE1xVXk2ZHNRYTEyQ3d2aW1YeEZyRGdfZ2p2ZzRpZ1VfUXdwS2N6X0RnSHRVNF9zbjRvUERxU0Nidk5ycUIybkpWQTA9
Validation loss increases when metric scores for NLP tasks increases.,r/machinelearning,Z0FBQUFBQm0yeGI3d2xyNXhwTzlOYzQtVkc5QVFpUm5hVDd2dExOU2hrWTRsQk5VekxhVlp3aFJKSi16ajlWa1hETnpRb1FtVDh4YWNvdEtOZzJhcWRhNmtMU2h5cWpWRmZXdjdXaFUwYzd1d2l5ZmlGaGlMbmc9
"Did your research about the attendees before the conference.
Go to their booth and first ask about the general line of work and ask them for their specific projects.

Use your experience to link to their experience. 
It would be helpful if you could also connect on a personal level, same school, state, country of origin, etc.

You don't need to suck up to them. Professional connections is a 2 way beneficial road.",r/machinelearning,Z0FBQUFBQm0yeGI3dHJWNEZWN2dKd0xOQWlGRkw2Y3JjU3ptWjExVE5TY01nM0hRb0hqRWFqTUpWVWIxX3paMkx0WUJvMUhDajdqS3VmMk50RWNSTXZjYm4zbmg3ckZRRkxrM0ItVTNMSVFIa3VsdmJhcXFEYWc9
"I second you respond, that's what I do all the time (industry) - it is very common (modify projects for my needs). It's not that you can be a monkey that just uses the CLI, even if you just use the CLI you need to read the source code to understand how to use it. It sounds stupid, but how to use it means algorithmic choices, it's not just what to write on a bash script.",r/machinelearning,Z0FBQUFBQm0yeGI3SENQM0pNYWZDSE1mdnJNRU9nVmplRzdieWdGeklnbW9zYlJJTUpsMURtWllxUDBhTkV4TXdtb2tWb20wQ1FOWk5jT2tUOUJ2b2lORWt6TThqaVdXRjB3Vzd6V193dFBVLUZpdDVONUNxRlk9
"It won't be much worse than as if you were playing a game for a few seconds when any of the AI features is activated. So, yeah, it'll have an effect but it's not going to be like running Docker on a laptop.",r/machinelearning,Z0FBQUFBQm0yeGI3Z3FNQ3haYmVGRVNNNk9VRml0Y1JvZUV0eFlULWpoSmdsS0dieW82My1vMkQ0QlVVdE1UV0M3WDRfbXJzSzNIa2lEbC11U1JVYlRBdGFnR0dOWXhvYnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3RkRlakRZQTJvTl9RRmEteEgyTWFOYW5zcjc2aERzZ3dQN04tdElQLXNPWGtsM0Y3cHp0ME9sTG9YZF9zN2VjSGtwUF9iZEM4NjllcUM3N1FzQnBRZlE9PQ==
"I do geospatial computer vision stuff for satellite imagery professionally. I can potentially help you out or give some pointers. I deal with large amounts of imagery on a regular basis. Is this a sliding window classifier your inferencing with?

Generally for a production use case with our optimized C++ code a decent object detection model with plenty of classes a 10 GB tiff should take around 10 min to inference on with a decent 2-3 year old workstation GPU.

Some initial pointers for chipping data, try out geococo. Also torchgeo has some nice transforms built in and the geodat module is somewhat useful.",r/machinelearning,Z0FBQUFBQm0yeGI3d1hhcWFjc05zMWk2ZTVjQU1GSUVvMGFuNk9vU3Vfd0F2bHhhVDVMTFpEYTAtYWd6bWdQR2NaOWR6RkZ2VEd0RlZkeVpkMTlIeVJEc2Nvek1Kem9RVXc9PQ==
And then there's me trying to perform nlp on tabular text data,r/machinelearning,Z0FBQUFBQm0yeGI3MndXQjFhLXRQUVJoX3U3aC1ZM2luOGMwM3hURDltZEd5cHI0RVhOV3JNRV9EbEJ1Mm9PMGNONmdwVDVHdndKZjhjMkh4RmlKZFRIcHN4UkRhc3FWeGc9PQ==
"Sometimes we need to modify code bases to enable stuff like Multi-node training(Detectron2 doesn't support this by default, neither does Ultralytics), sparse tensor support to optimize memory usage(currently doing this), rewrite loss functions, modify data loaders, etc. Fairly common things to do in Industry, a lot of commonly used libraries just aren't performant enough out of the box, they need some love to be ready for actual production level model training.",r/machinelearning,Z0FBQUFBQm0yeGI3QUxta0hZSEhmaW10Q1lTZFF1R1RZOE9xa1N1VDU0UExUazc5aERmU3pKeldjei1Lak9yZS1LSTdzZ2xTaVYxd3F3UFhmUUxVYWFhSllsUG4weXhLNVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3akVIYkMwdEtJZkV5eXl6azA1aENvSjBHQXdrTFZMd1NYMWZjcXZhblpwVjlWOF9aN0s2OGV5NV9feU9aUTJMRXhzNVpEWjM5VGJCQ1BZTTEzZEJoV0E9PQ==
"Thankyou i am checking it out,Do you have any other advice for me on how can i accomplish this research project succesfully.",r/machinelearning,Z0FBQUFBQm0yeGI3cUdZVVI4YUQ2WjhPQkpCN0tXdzNOcXBxZ3JnWVRJdDB4SVJ3RmZtNUt3Mlprb1g0Z1FDb05CNlVpN3BQQ0ZETHRHbGhTam9lTVd6VUNYZ0Q0YlF5bmc9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI3UTY2ZVc0LVdSXzQzYkI0TmprNzA4QmNUYWs3QTU4ZGdFVll4cUxueXl3NzFaUDdNcUx3Ulo2MWZOZkJ6UXBhZzJUYjEtdHhDRVpGSUt2RHh2Vmk4ZDJTRG5YWnV6allMamM1QlIxWlU2c009
Also will it not require a very GPU centric machine to compute a ML Model on data of 40k patients?,r/machinelearning,Z0FBQUFBQm0yeGI3WUlJNUI1MmdyZDloREJkeVhZSjN5d2REVmhJalZqZ05RcUdNOEQyNk5iVWRZYTlYbGs1Q25aOTI5Qm1IT2ZLOVdlZzlHV2cxYkRGTzBqWXQ5TzFZOFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ellPcVVfb19LZlQ1RGZJQkJKYnZ6c2txQ3JpM3V1a2gtaDZvcnNmTFhkM2kya3hlN21tb3VQRXBROW9DY2FsVENWMlkwdUZocVJRS0hsOExvb2JRTlE9PQ==
I’m sure there will be plenty of neural networks at the conference. You’ll be fine,r/machinelearning,Z0FBQUFBQm0yeGI3OWZ1anVTbjNEbmxIUWNSbTBoUXE3UTNqWHBRM05neldVR2VNcnBmbFZyQWhXUnZMODdLRlIwRXNTN0ZqWmd3MGJ6WlNJUk5DeXNaQlkyOW9ma3lhbXc9PQ==
"You’re mixing a variety of performance and resiliency questions.

If a node crashes while you’re training you more or less need to resume from checkpoint.

How much the performance hit is all depends on the interconnect between the systems. If you have a high-performance interconnect like infiniband, you should see a speed up using multiple nodes not a slowdown.",r/machinelearning,Z0FBQUFBQm0yeGI3b05yUmo4ajRLWHRLV2RLOFV3WHlGdzRYeGJqQzBDaG1BVWtBQ09uNXktYUFYUXZfYWZ4aE50UjRkSC1Yd0pKQXR4WGNieGpVc2FOQmJQWE51eTE0b3JCVmdPVGMyVHVjZ2lBWmFFTERVbWM9
I agree. Survival analysis is what’s needed with time series data predicting a binary outcome.,r/machinelearning,Z0FBQUFBQm0yeGI3R2xBUnF3elg3ZU1ueHU3WlZWc1RMUEpocEhuTUNFLS1WaHJBanFJTlZKaWNBdWFLQmtHZHAwdlUwbk1yb1pxeVRIM2MzSGpmb2MzTHRqSmpfSkNhSG9FOS1ObFp6Z0ZYeHFuOVJrcWlnSVE9
Is there any one-click installer + GUI for TTS like there is for image generation (like StabilityMatrix)?,r/machinelearning,Z0FBQUFBQm0yeGI3MzlXTi1DRkRfdXdvbnYwRWRZaHQxT3lXSjVESlF4b2JCeTZHWHBEVWhNUTl2Q1BIaXlPU2x6RHV2YVFPM09zeWMxT1p2c1dFWWVvQ1AzUmcyYlFRb1E9PQ==
"Computer Vision might be one of the simplest things to work with. Because the mature tools available. 

You’re just probably not experienced at working with image data. Also, what does an AI Engineer do? Never heard that title before.",r/machinelearning,Z0FBQUFBQm0yeGI3TFcwT2ZYeEpTeXE5cTZwR2NMdDJNdy1DMDZuRkVpQ1lZTkVKVVcyYlgwaVplbDNYeEp1MVBUVHBOSGEydy0xX0FDUi1aaGZyUkRoZTVQRmU3YXA2MmR0cFFLbDZRa3JRcmdSQ29Nb0JQRUE9
"Yeah, totally agree",r/machinelearning,Z0FBQUFBQm0yeGI3cVFmWWZMdmFOU3h6dVdkUTAxMmdqbG5NcFFPamVlU3UyaWNTVzFzZkZ0T0dOSGNBWFNlbmZ5T3BVakNhcnlIal93QVV6cmtvLTQwQVU0WEJqVHMxTkE9PQ==
"I don't really do it (only on a basic level) because I am not a SWE, but I often modify the algorithm. Indeed, thinking that using tools like HF is always easy is naive.",r/machinelearning,Z0FBQUFBQm0yeGI3SkR5azZMSW5nb3ZNX0JvSko5LU5JbnYwU2JCdXFYeE56bk1DX1QxblQtbjNVOWJXdVdWYWczOFNKMG50b3dMRExPcDlCWjhPdkdxZkRwRTljNXJjUGJ2cDVzUWJENGw4UF9RWVB2a1NkOWM9
"75% of success is just showing up.   Show up.  

Be prepared to give an elevator pitch about your research.   Practice it.  Then be prepared to get into the details if someone is actually interested.  

Think about 3 or 4 ideas for what you want to do in the future.  Be prepared to explain the research program. 

Think about what you would like other people to work with you on.   Do they have an algorithm, or data, or computational resources that would make collaboration useful.",r/machinelearning,Z0FBQUFBQm0yeGI3cEdxSzRhVEZWXzlSOERCbEs5V0owYTdsVXVkMHRCYnVsQ294UGZKRDVtUlZ4Q1BxcmlfUklmZW4tTElyZFJONzRkb1dQZ012cEFVR1RlR3d6VnVnQXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3UXdTNUpzMU5mTkRVa1QtZWlyTG5HXzZlMTh4NTJlNTQ1alhmbDBXOHNIT1dIMFpkNXV4d1F1Tm9ka1hFckNYbHlJQ0xRVDNsOUJsYW96ekFhNmxuc2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3dXBxTWdMWXpHRy1GNFowSENfVlFPSXI4NnRzQVVzaVVKTUdPMU80cnhJYk1iME94WFFVVGQ4LWxGVWdGOGk2OHBGQWJtd1BwdWNhbDhqTlBNaGNPQkE9PQ==
"Unfortunately, while a fun dataset to play with, TinyShakespeare is just too simple of a dataset to really draw conclusions from.

Going up to something like TinyStories would likely show completely different learning dynamics.

You could then move on to TinyBooks and then FineWeb-edu.

Those datasets would each be a significant step up in difficulty for language modeling and would expose whether or not your modified MLP scales with complexity.

It could be that TinyShakespeare is so simple that the network can encode everything it needs in the embeddings and the qkv weights of the transformer, so the MLP mostly just operates as a passthrough.

To figure that out, try one more ablation test where you remove the MLP or replace it with just the activation function.

That would give you a better idea as to what's going on before attempting to scale up to more challenging (and interesting) datasets.",r/machinelearning,Z0FBQUFBQm0yeGI3UHo3dmVUeFQzX19qNEQ0Zi12VTlMN3lydEV3Q1VoeU1DWVJrZWd1X0N6dURLMGNKSEt5eDVLWXduWWx3Qzl1YXRzTUl6Z1cza0QxakRwaFNaMDNzZkE9PQ==
You can try to take a look here: [https://next5days.substack.com/](https://next5days.substack.com/),r/machinelearning,Z0FBQUFBQm0yeGI3eXFaVHdGTi1HcmhPdzg0QTNIRUlTQ0gzRjNBSk81aXFvN21Wd2x4aGlkeVhlRlpZNnRITHFXcXdXWjdoaE1mS3oxcTI1MWR1X2ZZMWJTWnVxQ2JCaHR1dGlsd3Y4aW9ueWY3Sm1id2pXbTg9
"Have a flashy, explosive mission statement. You could also call it ""drop napalm""... Formulate a few lines that you can speak in one piece with full confidence. Make those lines as dense as possible / or as short and compact as needed... Concentrate maybe a few pages if not even 20-100 pages of what you are doing into something that you could recite in not more then 20sec

(some will say that 60 sec is a good guideline, but if you are not a trained communicator, it will be firstly very difficult to prepare effective 60 sec of text to perform and Secondly it will be too big of a challenge to effectively perform as a communicator for 60sec straight without loosing attention from your communication partner)

1. Communication will happen in Dialogues. So if you are not an experienced, natural communicator, just focus on staying chill, calm, relaxed and make sure that you know what the person in front of you should know about... Or better said should ""see about your perspective/your universe"" (I'm trying my best to use ""normal words) 

2. Focus on a 20 seconds message that inspires, intrigues, exites and in the best case even invites to participare or engage into what you are doing (/or for what you are here for)
PREPARE THE MESSAGE BEFORE (this may be more then 50% of it) 
You could try it out on friends, colleagues, buddies, women to see what questions or unclarities may arise, because sometimes(if not always) we assume that other people know about a lot of ""obvious things"", but people don't know everything that we know... So we may make sure that we test it out to make sure that we 

3. Be prepared to expand on everything that may arise in a Dialogue. Know what must be known, have a plan, you have to have clarity in yourself,because you will sound more confident if you are clear and intune with yourself when you are speaking about it... The things that you are dealing with must be as natural as possible, what I mean is that if you talk about potatoes, you may transfer more security, confidence and trust, if you truely touched thousand potatoes, had your feet in the dirt and experienced some success and encountered some misfortune in the field...

4. I recommend not to develop communication and social skills before you have to speak... Don't pick up books or don't try to get smarter before you have to do it. From my experience you might focus on the raw facts that you learn, instead of being in tune or in flow with the moment.. IN MY EXPERIENCE: I takes aprox 2 years to transform theory to practicality and before the theory is fully integrated you may be more testing and understanding what works for you. So don't try to become smart about being social or communicating too much.

5. When the moment comes just make sure you are in you state, have good food, wear what makes you feel good... Drink you 5 coffees, 2 cans of red bull, meditate, play some videogames, whatever brings you to your flow... And go for it... When you have to communicate it's a performance.. Not everything will be perfect, not being perfect makes people feel comfortable around you.. Be human, have fun, find your fun and pleasure inyeracting with other people.. When people see that at the end of that conversation there is something that gives you joy, people will be motivated to interact with you.. Be happy and just go for it.. Be human, be yourself. If you are going there, you are the right person in the right place,meeting the potential right people.. The place you are going to is full of gold and the gold is behind all the dialogues with the people you feel are the right people to talk to. Trust yourself. (or a mentor in your field if you have one)

Best regards, 
Good luck,
I'm convinced you are going to make it, because you are proactively making sure that you do everything right.

Respect to you!",r/machinelearning,Z0FBQUFBQm0yeGI3OFMwVHZhcUZobmxLbEptRkFEWVZDOUNiVUE4dmE4NWlYTmcyejRRYWluZlhmTVh4YWJkalFUeDhNRGNkaEhWYThqTDhyRk1FdU41a011NVRyYk5jSVE9PQ==
Delete this.,r/machinelearning,Z0FBQUFBQm0yeGI3SzBFWGdPeC1MVFhQRVFzZF9aUXhLbk5sSHMzQXA1MWxrQkpSS2tiYzJHZzBKMXgwX0ViYjFoMmxNUzM0dDluWFJJNHhSZU5QLUR5MV9zN3RkaGNEaXc9PQ==
The Turing test has not been solved.,r/machinelearning,Z0FBQUFBQm0yeGI3aEZWeUhoWk5sUzF5YkNfa2pKb2lXaFhYbTgxVXBRT2ZnaVFZLXlPY3pkcTk2M1JsTWFBN0N4YnVsVXZTaEZVNks5ZjlRRGtLMzFMS0N5Y0JGekxHdHZ6b213Y0xvc1pWVlFqNEwwLWVIQkk9
"sigmoid is nonlinear, min max is linear",r/machinelearning,Z0FBQUFBQm0yeGI3emJIdEJGak1TcjVtc0EyMlkyNkc4S3JXY1FSUl82VTVaUzlqUHplWVF6WDJOaDlwaXdUSE02d0NuYXY3Z3NHZ2lFUWw3SHJvb19kUmhSNTgtdjVITHc9PQ==
"I know, I asked two questions. I'm just looking for any benchmarks, I know it might vary depending on how it's set up, so ideally I'd see benchmarks comparing different setups. ",r/machinelearning,Z0FBQUFBQm0yeGI3QnVUakpSWEpVM3FYeWRUZm9lU1ZLU3RDU3JDWXVvdGhOWE5RZWtYZDBUbmFyVjBYeXNsakpiSW1ESC00ZGdPcF9CNkNNQzZYMEU5eEhyNmc3RGkwaXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3WlRLYUJ4ZXpNQ0VQWDlkb25sQXJHR0xpWGFacjVONkNaVUMzckpXWGMzbzFNc2VNc2hCanNsQ01FVnh5ZUo4MHJaUVhjNUs1eElhQ2g3NGV2cUp6NXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eVZHSzJmUjJjemJuNk5GMTIxTG9iMUpqZ1QyZ1JNbkEtN0pvcGdmWHN0X2cyX2x0dndET1hsQ3RGbGpUenI5U3JDMEw3WUtyWjRtUi05ZEItNENoZHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3c25MRzVjWlRjUW5GLUJoeEVvdUVDcnJGV2U5U1ZEUmpvMldxbUNVNm01UjEyM0NjSV9sNGw1TGc0RndCTjBoVUpFNjJENkZ5OVlNTDVoQm9oUjJRYUE9PQ==
This must be so cool to use with SUPIR to improve its accuracy,r/machinelearning,Z0FBQUFBQm0yeGI3eVdEVGpuejA1TWhka1A5X18tZjkydnNQdHZjckNuWEw0c1pXekxKcFlxZGF6dnd2dXNuZnlOdW5JaGxOTjhkV2RnRHJPTWlVYTJRdWVjOVhub2dmUUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MjU0Q3M2R2JxMmduX011QmlBRzl4WXJLOHhJaXU1cVNHSEFUZ203RGZGTGhfbjhFM0dhQ3BLekxnNEtXT0VRZVRadGJBUk1aMVhubVlHek94SzdyX3c9PQ==
"I'm not a SWE, just a data scientist who can program reasonably well and is into scraping every last bit of performance he can get from a system.",r/machinelearning,Z0FBQUFBQm0yeGI3M1NQb0NoQzc2MGk5emtjTmFzeEVkZVBzRzJEOEE2S19kTDBkcVpaY3lYVEhpMk15M3M3QWdKVndzYTRacmpIN3UzWWZtb1A4NjJocVJkdnhFTUhoSXc9PQ==
">Maybe related to Phi-2's partial_rotary_factor?

All rope is on a subset of the q/k matrices",r/machinelearning,Z0FBQUFBQm0yeGI3Y3dZcl9wOFNLLWlJRTdPRWNveVBSMVVaNVVuMnJoejRoNFlYRC1WdTg3MWgxdHV4TG5XYXk1akV2WnE0aFdQR1Q0N25acmRKdjR2bV9ibEtSWVRlV0NsZFFlUDM5STdHX2s3MVpPMXV1eTg9
Thanks for the recommendations! I'm looking at TinyStories right now and I can't find any training code. Should I just train the nanoGPT repo on TinyStories and compare between the modified and unmodified MLP?,r/machinelearning,Z0FBQUFBQm0yeGI3QkJUNl9TVlNIUkpzTnVJRmJvVFVrTlR2SUZ4S2x3T05uemZoSTRqXzlyTE5DLWVIeld6WEtWb2p3Q0xNSVQ4ZU1uVHNkRnhlY09TTnRaVGtxX0ZKZEE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3ekFScFc1bWFqTW1iUXNZcEZEb0gxYWpCWG5xb1NHcDNzUmhXdFZheUtqSTZvRDRxZGRxSnktcUpjOHJ0OFo0NE9rSENqN29JbmZxRW84SktNVV9vMkh0QjRhUFhEMjN3WmhLYS1ZdGVaZUU9
Can you please paste a link to some of the well known papers in this domain in comments ? That will really help.,r/machinelearning,Z0FBQUFBQm0yeGI3NXF0MFRFNDhtbVNyWEVGNHBXZDNwWjBCV2dhemllV21yVUNQcDFuYjhTdjdMMFZVOV9PUGJENUFDdmNjNVpfNlFaWGd3U0xhdWQ4UkRLVGZudWtkeGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eXd3cG10cUtPWmVWa25MLU93SGRpMTF1WVk4bXk0YWZCOHlkYVRzVTEzWGZYejJvaVFFZlFnOUhfc3RMOFlnTTZRU1dQT3ZWaWw0TnJFOURwclYyUUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3UnZ3d0RIWTJuZzR4LWRrek1aUURHMDJpVlhTVy00YjRtV01MX1NBNHFDU0JIck5BRjVQYmVGRDNJcnVwTTgyNHF3OVBOM3FWckdFc3hSZmFiTERLcHc9PQ==
Download each version and find the differences,r/machinelearning,Z0FBQUFBQm0yeGI3ODlCdWRhSFZ6TjFFNFp6dXZtbHlVblNLN3dXVVZTMlNQUThJMkhBRzVNMkRtUVhVUnd2eXFYN29FdnBTWTVPTVh5VUFqR1hKc1RFdjdCakRkNDRDUkE9PQ==
A1111 when?!,r/machinelearning,Z0FBQUFBQm0yeGI3ZldiV05lTXVYSTllYkgtRkNDVHpndHdESjRQTGFrLTVia3g2QkgzN0ppWHhGc3FaUzNtQkRwRVFSdWgySmV5QWs1NW11V3NQNkpvTnU3aXdyNGZvX0E9PQ==
Did you perform some threshold optimisation?,r/machinelearning,Z0FBQUFBQm0yeGI3bi1MTVNFSzdpb2ZoSFFiYTVHVXFxZGV2RDVoM0d3T29CdHE1eGhKYXdtZmwxWndhTFg3dlhMSXFJRlpWUWVLMXRoU1pzakczcVBuM3J3VkZRc1ptWVE9PQ==
"... on how to talk to other computer geeks

sometimes the constant cynicism isn't necessary",r/machinelearning,Z0FBQUFBQm0yeGI3eHVjVlBiNWEzRWM1Qm1odHZWQ2lyQlZMR19JSEhZWDBBZ0JWVU5jZm5XNlBwd3BtOUdEXzdOWW5HaDRDdlRJMDB6N2dyNnR5MTIyaUFWMVZZcVV0U2c9PQ==
"Yup, pretty much! You'll have to adapt the nanogpt code a bit to use the datasets library from huggingface, but that'll be a good practice if you're unfamiliar. 

But ultimately, yes, set it up to train similarly sized models, one conventional and one with your modified MLP, and compare how they perform.",r/machinelearning,Z0FBQUFBQm0yeGI3UElFSlJRbTFrMFhkb0dtb0s0cXg4a0RlaTVwaGVZZUhxRlNHTUg5V0M3WWhaTktGZjl4eDlpdmFSZU1RVGtLbGxrY2JzQ1F0Y2xxV1YzMFdUdXhRY3c9PQ==
"> there are just a bunch of completely different architectures for different domains — UNets for segmentation, YOLO and RCNN for OD, Diffusion Models and GANs fro Gen AI.

this is a big difference between image and text domain yes


transfer from diffusion models to something like YOLO is limited",r/machinelearning,Z0FBQUFBQm0yeGI3WjZSVkFSeFBKb0wwb2JQbWhMRXNvZVR6bFBMb1pVaGlhZVo2NEtkckRRajEyYURiZ1VfaDZncS05MjdpU0RZbzh2LW1mQzZWLUFFNkNKVE4yX2dnMUlQbnItUXBCYnRyOEQ3VDZlY2ptQVE9
"Go to the nearest fancy coffee place to the conference center, the queue will be full of people with the conference lanyard. While you're waiting for your cortardos, break the ice by mentioning how much the conference coffee sucks and you're good to go.",r/machinelearning,Z0FBQUFBQm0yeGI3MlVyTUI5eGNBamxId3Y3aktzNG0ydXVtWEpZNXlXYlRpRlR1N3JLVWFkektkR1M4TWxLTkhJa2ZJSzdabHo1SldTLW5JMGpnVDVNS0NNaHo4WUh1NWc9PQ==
"Has others folks already said it, its a Quant version. I run a 5Q of Phi 3 on a redmi note pro 5G and gives me more than 9 Tokens for second.  Try to understand other approach. Recent processor of Phones ares beasts, u should check out the benchmarks of latest snapdragons, they run faster than most of  6 years old medium home processors cores, Intel or AMD.",r/machinelearning,Z0FBQUFBQm0yeGI3WTVXdVVqZFJzVzB2ZGVFX3U5WDd2WlFXZUFwWFg5VElINkMzRHBBUzdjd1VfTmxqTjlVMVBTS1hzRzFtRjNuZFd2SWhnQXM0YURnZWdkaVlzVWJDS2c9PQ==
"With all due respect, it sounds like you read about DL but you've never implemented a neural network.
Taking inspiration from a high level concept, you are basically reinventing a low level and older one, that of the Perceptron, that of CNNs with local windows, and progressively smaller feature maps...
But don't take it negatively, it means at least you are aligned with the ideas of the field. Time to get your hands dirty!",r/machinelearning,Z0FBQUFBQm0yeGI3TlBMd3hyVHF0VFlMUk9sTFZHSGh6RzBwSjBGRVE1b01DZDZVZXpIWVM2czcyVkVwTjllWWtnR29CQUUzcW9sWTBqUy1SaEh6bVh4YTFGWnZieDQtS0IzMVZzQVlaYnhfUXlOQUJyQ1dHNUE9
Good luck,r/machinelearning,Z0FBQUFBQm0yeGI3OEltMEd1Z0p1LTdLVmtrczJzQXBJX0stamhURndCWGVDdFVCejVkOTlva3pPYVFZZEU4ZGpKWWFlQ0hDZ000cGRRRUVIVTlSaVcxZ19aYWp4a1pyT1E9PQ==
"Check Google Scholar for papers citing Grad-CAM, they might discuss the versions' differences.",r/machinelearning,Z0FBQUFBQm0yeGI3blhZaHFiRF9VT1AweW5DRS1vUERYRklTS2JvNHpRVWtabzN5ZmZhYWNVcjRITWZyenFXb2xQcVZENElqdFptdkt2dHhELTdiQU9DYVh6MkJPUms0emcyYkZ6MVMyVEtkM1dsQ1dKUW5DYkE9
"Try printing \\`hand\\` before the error line, what's the output?",r/machinelearning,Z0FBQUFBQm0yeGI3VFR2T0Z5XzBRNTEtYjNqTUZubkxEZU94djY4NXNSQWlpTnZGUVB3TEQ1aDNFTHdpT2VJODhVa3l5RDBWV3M4NVNrOXgwNjJVTmZxOExCYmZZVkt3aFBrN0paMnh0MDdIb3lqcGtFeHpkMkU9
TIL. I work in speech and we still see dropout as effective. But we also train for 30-50 epochs instead of 1....,r/machinelearning,Z0FBQUFBQm0yeGI3dHZNb0hZaDhfYS11RGFkMnJ6ejVYZ2ZnUWh0c1RpRHFFejhOLTVEdUpXeVBjRnFNSW1kLWhQMjYxa2tOTTdaQUVESzk3Wk95VHA3RDFaOVlYTXRVMVE9PQ==
"Hi, I came a bit late (after 2 years lol). Niche conferences could be highly visible and hold high credentials. For example, LoG is a well-known conference for graph-based deep learning, as you can see the members of the advisory board are big names in the field (e.g., Bronstein, Kipf, Leskovec, etc.), as well as the reviewers. People doing applied research in GNNs in the industry are well aware of this conference (KumoAI, DeepMind, etc.). 

Big conferences can have noisy reviews. For example, 50.6% of the papers accepted by the first committee were rejected by the second in Neurips 2021 (https://blog.neurips.cc/2021/12/08/the-neurips-2021-consistency-experiment/). 

If you are interested in a specific field, I think it's a good idea to publish in a smaller community, where you can get more valuable feedback due to the narrowness of the field. Furthermore, I think it doesn't stop your paper from being visible if it's of high quality. For example, this LoG's paper (https://proceedings.mlr.press/v198/ibarz22a.html) is cited by accepted papers in journals like Nature, JMLR, and other prestigious conferences like ICLR, and Neurips. Another example is the AutoML conference. If you work in that field, you might know about Frank Hutter. 

So yes, such small conferences are pretty prestigious, in my opinion. And it's not easier to get published in these conferences as well, given the quality of the members.",r/machinelearning,Z0FBQUFBQm0yeGI3MUNlYjZjUzRWMmtoX2FnWFlUdXdFMTF2REE2cUxWekxnQ1V2SThuZ3JaMHN6WndQVi1XSk1nUVcxLW5KNDJhYXc1Z1BnU0l2dkh2M3dybjc5cmYwU1UtOUFxUnNaZm56d05HeFd5Tm8taXM9
"Any of the survey papers listed here would be good to get started. A good survey should include all the popular techniques.
https://github.com/xialeiliu/Awesome-Incremental-Learning",r/machinelearning,Z0FBQUFBQm0yeGI3TjFrRFJLdWFoWkZ5VjgxODdOcVdSeWY0YzNrNUo0T1pQdS13VmluSDlvTkxqcHFGSHFCTUdfUDdDdHBudDI2UWdEaXZUYm1WT05PSlJtaUUyalNKM3c9PQ==
"My recommendations of what I’ve seen work well. Come prepared with two things, 1. Quick 20 second about me that you’ve practiced in a mirror and can deliver without it sounding rehearsed. 2. A story of what you’ve been working on and why it’s important to you and others. 

Those will come in handy but when you actually go to initially connect, just be human and interested in them. Ask them how they got into whatever they are doing, what they like to do for fun. If you make human connections, it makes the business connections easier and stickier. You want those prepared for the moment they ask you about yourself or when it’s natural to share your story in the conversation because it’s relevant.",r/machinelearning,Z0FBQUFBQm0yeGI3Z3lLWjJVRlFpdi1qeGVNTFp3cUJRNHlRa201b29kNDhfdFpIa0N2VDAtekJCaVJRRDgtaUR3Mll1X01FX19FaTBoTVlvS2VxaXdaVkJvNDFpNWJuT1E9PQ==
resolved it. thanks anyway.,r/machinelearning,Z0FBQUFBQm0yeGI3Mi1SOWpILURpNlc5N2NVdFJZZjBYWjIwQjJSLWRUU3pyODB2anhnelZOS2lMQUdnYWhyMVVGLVI5dU9RbUN1Sy1pT3RUcUE5Vk5qbTVDZnluV0oxbmc9PQ==
We re trying to create an embeddings layer of the customer behaviour so we can cluster the embeddings for understanding the behaviour,r/machinelearning,Z0FBQUFBQm0yeGI3U0dIZ0FraXJvVnB4ZGxUNWMxYnBHRTJOVTkyTkNFdkpYM2ViVTdDVk1oWXRDS09Ob1cycXlSeXlwWWoxTVZxZGdtSDg0MVEzTV9JMzF6ZXhKMVd1TGc9PQ==
"Ohh right for it 
But if We re trying to create an embeddings layer of the customer behaviour so we can cluster the embeddings for understanding the behaviour",r/machinelearning,Z0FBQUFBQm0yeGI3TENORmhHaEk5QW5BTXRMTThHeU5UTGxsaUI1SkhfZWFhVGJScUVIRkdtM2JtTmR0RGo2ZzJHalNyVkN3cUg0TVpUUWJhTExDMVFlbmtnTnJXTkhjYUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3bFJac3dpMXhnWmNqQTZPVGFRNTFCeXVaUnJIenlqLXI0MzJ6N2EtVmMzZlBWbkUtYzBwVV9kbWswejBsS3N1NzRod01vODNEZk9DM0p1ZWtTdFBzRkE9PQ==
"Disclaimer: I’m not an ML researcher, but I have attended conferences in another field. What follows probably (maybe?) still applies.

Focus your mind on the research being done by whoever you’re interacting with. You’ve got a few goals in these interactions: 
1. Understand what they’re doing
2. Try to understand what they wish they were doing, were it not for [obstacle X].
3. Your own research involves answering certain questions and applying certain techniques. Are your questions related to their questions (or obstacle X)? Could your techniques help them?
4. Could their techniques help circumvent or defeat *your* obstacle(s)?

If you have addressed these questions and goals, then asking about collaboration would likely seem like a natural extension of your research programs instead of some needy imposition. Collaboration is a perfectly logical and practical thing to do when people have problems and skills that fit together. So try to find that fit as you show your work and learn about others’.",r/machinelearning,Z0FBQUFBQm0yeGI3b2lkb0FjS1hHaURTWWg3Q2xyYk5peFd5NUctczNuS0JSX1NnSnlrX1pYT2NXTHByYU1NdkVZWEJsNmNMcEt2SlNFdmowaFAxZFZXdS1ZbFpvMndIMXc9PQ==
CFG will always stand for Context Free Grammar and you cannot convince me otherwise.,r/machinelearning,Z0FBQUFBQm0yeGI3ZXJueWtyazFXRlNNWGIwYm5EYkM5Z3RiZmlDVWJBUFdFOHRid3pvTmlrOHdZN2E5NUgxYzJiQVozWENTa2ZOZjhzV0pPaUlnQS1JVTVuN2RKdTNEWWc9PQ==
"Thank you OP for being such a responsible AC! I have a small question regarding the review assignment: if two reviewers (no conflicting interests) have submissions to the conference, is there a chance that they review the papers of each other? Or is there a mechanism to prevent such cases where reviewers review the submissions of each other.",r/machinelearning,Z0FBQUFBQm0yeGI3c1R1clU3NjUzeXotdUJ2cnIwSmhKc1I0dktMR2swdy1RRHJfRm9FVGJZa0lxVnRCRWx6VmJ0S1ZaZHA3ZFJEU2VvaERYWFFiQ3VYT0piV0NrYkMxZzd1TVVKTTN5eHVmcDRMYkRxWEljR009
"I didnt intend to be so. There are lots of advices for General, ordinary, and casual way to start conversations.",r/machinelearning,Z0FBQUFBQm0yeGI3U1hMNWt5NzY2dlo4cU5ha242czh1enBfMVlRR0hhVzlibTlVRlNFN3BzOWxWaDg2a3RVQmdsX1cxZjVmaXJRNjdLMkJuWEFycXZUTmU2SmVsQ0VXM3dqemdSbU5NSnY2eVNKbEx4T08zaWc9
"For me Conda+pytorch+some libs was horrible (don't remember what those libs  were now, something robotic IIRC). Problems with nvcc compiler, cuda sdk version, installation took hours and several tries. venv, mamba didn't help, some libs never installed. Still have it on one of laptop, but never again.",r/machinelearning,Z0FBQUFBQm0yeGI3YlVVRElqbUtUakhNc09XdDhuMmVNOGt0dzJyTWU1WTQ5elBOM0YyWFVMdzVqNzhvQ2JqUUNCQy1rcTJWWmJib2hVOThyb1V1NHYwRjJQYm9wZnFmMXc9PQ==
*psssssst* you want drugs?,r/machinelearning,Z0FBQUFBQm0yeGI3ajlSeWZMSHZBeG9HbFFWVWRsV3dQXzhXSEd5QkQ2Y3YtWUE4dWo5anR4bmRray04Tmg2ZUQ2WlltLTg1MHllQWNFWWx5OUctRDVaZU1qWmlDWmRhc3c9PQ==
Seriously though 🤣,r/machinelearning,Z0FBQUFBQm0yeGI3eHZwWDhITzNmOGZCUVJnQy1NVFhZbmRIWm9VbXJxdlNfcG1TeDRXUXRMdDFMU1dXdFNPQ2gyNlVqN3Q1M1hxVlNVZjkzQ3VyTkw5amdIamEyV0stYmc9PQ==
"To solve this problem either use conda, a container, install the c++ libraries to another directory and then change the paths it’s looking for the libraries in with an environment variable (ld_library_path or path or whatever it is, if it’s not hard coded) or if you really want to go wild and overkill… a virtual machine",r/machinelearning,Z0FBQUFBQm0yeGI3dE9qX3dlMXdDdDVxem82UFY3QnZuWnpYc1RrQmpnVHdNZXR5ZEMzWl96U193U2RtVkxRejhua2xYMWgyMUJqTG9iVGJLaFYwaHUybl9wTmdITXZrd2c9PQ==
Yep this guy condas,r/machinelearning,Z0FBQUFBQm0yeGI3eFpKOFh4bXJoWm1zOWxDVXJWMl9jQ1RRelJRSW9YLTJmZzFoRXRMRWg3aml6dVdzaGZTb1NNU3hKbU0tTGtCOVRmTFFWX29yRTZyNlBkS1NKYXBlYnc9PQ==
"**CORRECT ME IF IM WRONG**  
from what I have gathered form the comments is that what we really need to be doings it essentially taking apart something like GPT-4 and figuring out How it is working  
this does not mean doing input output testing  
what it means is as some have said Freezing parts of the model or removing them and seeing what happens when you give it an input  
this **in essences would be like lobotomizing the AI in selective areas trying to figure out what does what lmao**

and don't get me wrong i understand this would take a lot of time but you would over time be able to create a representation of what does what in the model and make changes if that makes sense",r/machinelearning,Z0FBQUFBQm0yeGI3RlZRc1JhY1lrSmhhdVp1NHpILVdkSXc3MGhnclp6aExKQklrZkhaNVhhd3d0aTZmTVBqS1NpMDlsRGxvQUZJUmp0WERxRU9DWGJqd2tqNm5kcTdSalE9PQ==
"Hello again, I added the undo feature since it was something that was kinda important to begin with. I have also added polarity that is made using multiple votes on positive, negative or neutral which factors in for multiple reviews however a code to make reviewed data get re-reviewed needs to get worked on. 

JSON was the next thing I am working on you can check the branch feat/export-json for updates. 

Thank you for your suggestions, it really helped he continue with this project.",r/machinelearning,Z0FBQUFBQm0yeGI3VnA3VlpjcW83SmVOZTJrRWl2aGpCMEh4blJWUkNKR0hxVWYzMThuVFJJc1MwVEZsZ004X2VRVmlvMjBETm1XLXZQbmlaYmh2NVAydDdmeWt3VkliYmc9PQ==
"I don’t want to be rude, but if you made a significant development you’d probably also be capable of determining if you made one.",r/machinelearning,Z0FBQUFBQm0yeGI3VWdheC1DRkdmbUZVU1hTUkpFSUUxUk1ab2tiTDJ0YzJhQXVBbWswcUJrX0tpQ2VwX3lkQW0wV3RhMFlZNVl3UGlOY3dVZ0lsbGo5UndXNUEwQk9IY1E9PQ==
Drugs,r/machinelearning,Z0FBQUFBQm0yeGI3VlRIRVBEbnBSMU8yYllWZWhZcFVfRzlMVW01dXJsX0dRdE4tVk5YblppNGRFQmZDWVpmZnhuZEZuSm1Lc1hqeG1GZlI3Tk9Mb1pYM0xNMTJBeTUxMnc9PQ==
Why?,r/machinelearning,Z0FBQUFBQm0yeGI3OHhnWk5LMDh5RVdyQkhfV201WURNVy1COTBaOVM4OVNFRnFXVnZ2enR6QThSS0VobG9ZM1REM2dHZTVmZjJVTTlZeWpsYjFuU01mRWVqblhlSTdEeWc9PQ==
How did you go about getting invites to the Google and Meta socials?,r/machinelearning,Z0FBQUFBQm0yeGI3Mm1BS1V6b0gxWFVKcHBkcFZoS1FTeUNFYW45X19abk9MdzhIRlNlX1BYODZwUUlCYlZBZWlJN0p5RmpqZVk0NDJZcUJNNGViNUtNSTZsSXRtdGNOQXc9PQ==
"One thing no one else has mentioned: business cards. Have a name, institution, email, and if applicable, website on there. Anecdotally, I've found physically exchanging business cards after chatting w/someone helps me remember, and helps them remember my name. 

If you're at a US university, the local bookstore will usually do something like 100/$20.",r/machinelearning,Z0FBQUFBQm0yeGI3ZGlmRFlVNS1Oc1BzaW15ZkJaa0tuZEl4aE9HQjR0Vlo3OGFPc1ItOWtwRTdHYnBsZ0U5STFlelZDOXhFd0ZTVkE1cjMxdk01Vl96YlpXZDZwNWJTT0E9PQ==
"OMG, when I read all these highly optimized suggestions. 
Be kind. Be yourself. Be interested.

This is a fun event and not a recruiting BS.",r/machinelearning,Z0FBQUFBQm0yeGI3ZEhVMVNkN3JZbkQ0VHNtcXJORVJDU1BlcVhDOExQM283Z2JlSTdlbV8xdlVBVnRMcEVjY1RZeGlpM19hZkdrQ3RjcUNxVUpBU0kyTS1zVjZ5M1BfY095RENBTkFfVmIza2JRSWpDZzdwWUE9
"I'm not saying it is not possible, I'm saying it is a bad idea. You are using a model type that is known to make stuff up and asking it to make decisions about people's behavior for financial transactions, an extremely sensitive and consequential area of their lives and yours.",r/machinelearning,Z0FBQUFBQm0yeGI3MktMOGtINmdjcXJqUDJIWmpTZU5ja042alB5LUZESnRHSnd2UlNWZV9fNmNITTdOS0p4UVFGNDRMdUtITklSYkJobzZKR2tUckNNSVZGNUdDanBIYmc9PQ==
Just be there and don't be creepy. Most of the time people will talk to you or they have interesting research that comes up that makes it easy to talk to them.,r/machinelearning,Z0FBQUFBQm0yeGI3enY2VFZxamlJV2dxSFpVMFhOaHpCWmlmWXVHVUUwMTVOVlltZWtfcU9oWlpraF9mN2x0cTZrYTdlaWNEckFNOE1NT3FJcFRGMElobGl1ci1XNFlfTWU5ZUhONWQ4aWlXdTdNSG5TTDZBcjg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3UGlfYmpyNzM1X3BOQkRreklfYjc3Yk9PcFlmb3NMMWZ5SzhITjZ5TzNuZkhNc1ctNWJjb25EMlRESlFDd1g3NVRyM1NhY21xM1hZeERfbENqUjZwYmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3cHltUWtVeDFhaVlLZk96NGxWYVBiOUpUeWZpS1U0aVlZN2VzRHpwUG4zSmczRG0yYVp2TG15UWJoZFFKdGhrTEpUWnQ5Q3VuNlM4eUpXTUYxa05oUmc9PQ==
"AND, ask about their research and interests.  And be interested in it, ask questions.",r/machinelearning,Z0FBQUFBQm0yeGI3T2xpcnBTWVh6T1ZTLUxIc1pYYjlucHh3ZHBzS0FSUWdrUDJYeTlnWF9iUXdjb3V0NzhCU1YyU2Vvckt1WXpYWjBCd0NIT1FrZTZXTUJmenY5dk9SLVE9PQ==
"""data is data"" is a mindset that breaks so many projects. the intricacies of your data really matters.",r/machinelearning,Z0FBQUFBQm0yeGI3Y1I1RmNzRFQwb2luVWNzaGJDMVMwb3FJN2xXQkZSNldDcHhGOUw5UFBreWJFNUVwNVczZkpVQVJFNVJVdXViaXFSMG9TeXdIcUZwYmlKZW5mcFVscHc9PQ==
"Only if we chant ""Feel the AGI"" afterwards.",r/machinelearning,Z0FBQUFBQm0yeGI3RjBYWHN0SjdDV25NdFlBYkJpRjRfNU4xNllURWNsMjVpR2lxclNyWThhQ1VnSDhtbGNsMHgyTEhxT2tBZ0RPRUFhREpoOVpkcEExRlhkY1oybFBFMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MG8ycGN4bEs5czJtNGNidmUwYmtueGN3VWdrLUYzX0ZrU1R4VVRIRTczWkpMaWhtSXREcTVXa01Eb0djclpNSnVVQnZMNVdhZHJwalhnVnVEa09XdXc9PQ==
"Bear in mind that most other people you encounter at a conference are there to network too. Of course, people will have certain *types* of people they'd prefer to network with depending on their goals, but you can quite quickly suss this out. Don't gum up too much of someone's time, but equally make excuses and move on if someone is doing it to you.

Definitely have your ""story""/elevator pitch down pat so people will quickly be able to figure out if they want to talk more with you. As much as it might suck for someone to be disinterested, they'll be doing you a favor as you can move on to someone who might be. Try not to take people's disinterest personally, there will hopefully be more than enough people for you to find those you *do* click with.

Oh, and at socials it's totally fine to walk up to a small group and listen in and potentially get involved, especially if they leave a gap for people to do this. If people are having a private discussion, it will be obvious or they shouldn't be doing it in the middle of a mixer anyway.",r/machinelearning,Z0FBQUFBQm0yeGI3eEpPV2dHX3R0VHA1QkozdlNaN3M2QTRVOVRRRmV2d29vUXJuTmoyTWlBemRxMG1IUXF0RGU3X2hfV19GaG40dmh5UWY3TTZoNm50WlRvdUNwRGpTT0E9PQ==
"Just talk to people. Talk about the talks you've seen, and what was interesting about them, talk about what the other person is working on, talk about the weather, and when the opportunity arises, bring up whatever it is you're doing. Don't force the issue. Everyone isn't there for your benefit, but *someone* is probably as interested in your topic as you are in theirs. That's the person that's going to be a valuable contact. The point is to put yourself out there so that Brownian motion can do its job.",r/machinelearning,Z0FBQUFBQm0yeGI3N0lxaXluVTc0UlcwSkY2OFphY1hrVmM4UFMwVi1BUFFwTlpVdW1DMG1ObkU2aExFT2JQSVVWR3lrSjRtSmQ2cVRMSXFBRmVjU3FfVlNISXBRSlI5OVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3alJvX1lEN3lURUY4VEw4c0plZFFKcGdoYlhlU2lQWlFRVUJibHAteWlBcnVkeVJmUUlIWUQyNHRWR29nX2ZpWkxWTGdFelVaaFF2Y2pIaWJBbnphbmc9PQ==
"Honestly the best approach to conferences is go wanting to learn and be very curious like you’re saying. That will lead to conversations valuable for both sides and providing value is probably the best way to network anyways. No one is probably going to call you just because “you said you worked on a project that did XYZ”, but they’ll be much more likely to call you because you asked poignant questions about their research — which demonstrated your ability to meaningfully contribute.

Big asterisk: this is my take as someone who is more on software architecture/infrastructure side, not research or ML directly. But conferences have done amazing things for my career and this approach had huge impact even thought that wasn’t my goal.",r/machinelearning,Z0FBQUFBQm0yeGI3YkN1WXR5aVZjVDRlOENEX0RuRDItRTk1a2dKdVowM2VubmxzWUhKSDl2NTA2ME95aU94c3pXSGlXdVJyZ09nb3NzVWR2MDFIeVF1LW5ianc2WjBHdkE9PQ==
"I don't know why the link doesn't work sometimes, here's a dev version just in case https://arxiv-cat.pages.dev/",r/machinelearning,Z0FBQUFBQm0yeGI3Zkt2OEhfSVdDZGJRbXpPZUUxS2RINXB3dnAzdFh4X1d4WEZvc2FZWUhMeU4zUy1vQlQ5YkJFa1ROZUxPVWdGUzBFMUpSeHpmdEt2YXFuX1JuS1VpR3c9PQ==
"Firstly, do not use deep learning unless you have to. Besides, what problem just enables you to go from non-DL to DL to transformer? Certainly not anything with tabular data. For images, you use CNNs (or maaaaybe ViT if you have tons of data), and transformers for text (you just start with them). For time series, this could be possible, but statistical models or gradient boosting are still the best in vast majority of cases.  


But in general: remove features instead of adding them, either with automated feature selection or manually, use better hyperparameter tuning (e.g. TPE in Optuna instead of grid search), validate more metrics. In general, optimize the workflow: use proper scheduling tools, optimize SQL queries, parallelize preprocessing, set up data & model versioning, add model monitoring, regular retraining etc.",r/machinelearning,Z0FBQUFBQm0yeGI3WDBZckpoVzd5R2Flam5PV01jdm9Zck5PcTZrdlNHVWI0WkE1SjNtbnNyWUVBd1Q1NUdkM3dkSVAzamctY2JDbGpwZ2dMQjhUbWVjVEp6V0ZtcWFwMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3Qnh5OVNSZTNRMFpiNndJN1FmenBGcE9fSXhLb2pBWDY0bXlJRWpCVVh0NUNEVGJZNEFLNGVCbi1QWTVHSzBybHlJUnRKeDBpdjRJWGx2b0tMVHVNSGc9PQ==
self promo and no real value,r/machinelearning,Z0FBQUFBQm0yeGI3SXNJSmpiYXEzYUl2LUNET1hoWFV3cXlndFJPeVpZRWRKUExaT25qWTVnd0V3cEp2cHgwdGlidWw2OVRQUmZGeUNwaEJYUlprSmpkR1dLWW9yTkNqQmc9PQ==
"I'll be honest and this may sound harsh, but this feels like you have a fixed toolset and once you're done with those you are unsure what to do. This could just be you skipping over the detail, or in the worst case scenario that sounds like a script kiddie who doesn't go below the surface.

(Nit saying this is you, but it sounds like the way you described it!)

It is all about the data. The data is more important than the model. Forget the features, the real focus needs to be on understanding the data. It is absolutely fine to have tasks in your team to continuously improve this understanding. Imho it is more important than just model selection and implementing features.",r/machinelearning,Z0FBQUFBQm0yeGI3Z2ZNTXZVUEFOZHpCVHYyU19IbXNfdkJHZ2hBUTNPalhUdExRNEJkYnNWblpEeWRUTXJnSWs2YVU0cGd1MGhWaDhJemVDcHI2Ul83U2NWNUMyNTNpaEE9PQ==
What if the xgboost -> dl and xgboost -> transformer has already been done for two different applications and has shown significant improve in both model perf and online perf. But how do people continuously improve the model when it's already at SOTA?   For example in ads or search or recommender system,r/machinelearning,Z0FBQUFBQm0yeGI3Xy10ODdtUjlueE5JLTl0cEMxVXZ5eWxQY1JhVHpzc0NUQjNjS0dmb1h2WU9xTmU1NDlqX3EydEpKVjlpSWpjMGlscE5hb1hOVGs4UUticktETEhPS2c9PQ==
"Make content processing pipelines to:

a) identify suspect data in your training set that might be wrong; training data quality can bring outcomes much below the potential;

b) look into 'active learning' to identify which data of what you're processing is most unclear and would carry the most information if it would get labeled - not all data is equally valuable, there's an order of magnitude difference.

c) depending on your domain, finding opportunities for transfer learning from other tasks with similar data can bring major improvements.",r/machinelearning,Z0FBQUFBQm0yeGI3QjdNRlh2V2o3Z0RvNDRLX1UxZWV2WC1mVDJFU2VOcnA0cV9ITUtBUkIzWlRxdm9VY2hfbDV5eVZpMmdWRHR4ZFZzd2JQOVQtYmJnV3lnREk2YU95cHc9PQ==
"It was probably on the topic of restricted boltzmann machines, as that was all the rage back then.",r/machinelearning,Z0FBQUFBQm0yeGI3dG9vYU1NMHZNendKYVBZeVQwMUpmV1FpajFjYVRjbktJNnUxcUQ0Q3N6NTN4WV9pdXNGdUR0VDlRR2ZVOFdJT01TM0I5OFdDbFJJM0dVeDZyaWlVWUE9PQ==
Connections :),r/machinelearning,Z0FBQUFBQm0yeGI3NGhVY0JwMDdCR1FEbk5FR0hvS3g5MFduSVV0M2h6cWdLNlBuR2NMQ0dETlQ1TFVQYjQwY183aVN1cDF1NHoxS0VTRkxkSUNWWWNYUjRkdXZCQjNRX0E9PQ==
"It's called The Next Generation of Neural Networks. The bit about the hidden layers and their state while imagining a pink elephant lives rent free in my head and has for over a decade, lol.

https://youtu.be/AyzOUbkUf3M?si=GziPWcRfkA-QBTSx",r/machinelearning,Z0FBQUFBQm0yeGI3N0h3czBsMEROMEpWMlpUelI3Qi1OQ2g4ZndJTVI1a1NvSkM2WHE3U0hkNFVQY1hieWRYQTFaaWNCZUNJRHR5YXY3UzZJaHdhTnVXdV9XWFVVck9CUlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MmJLa2dENkFJWVFDUzA4bWxNUWRZaFJTaDFaeHBJTXdKRlo1a19WMDBLeXVYeWlDUWstUGswVnUxZWcyRHBZUWhNOGtaR3N3WWFxb3dIVTloV3hWckE9PQ==
99 percent of value comes from onboarding and featurizing new data sources quickly.,r/machinelearning,Z0FBQUFBQm0yeGI3YmE2dXdyU3RGdk90QWNVdTZ0VFRTYVBNRnZRNEtsVjhWbUlzbnI1OXJSbWlpQy1IMTRobk84eTU3WDRVUmJMX2hCWGVUN1NBNXpfREU1Y2x0OExnMkE9PQ==
"Data... data... data... and more data please. You can never have enough real world data. If you think your model is great and you have all the data you need you haven't actually deployed your model long enough. You will always have edge cases. 

The biggest performance boosts I get never come from better tools or from better augmentation they come from more well curated raw data. Simply curating uncurated data can get you a 10% reletive or so boost. Then you switch to the long tail  problem. Each edge case is harder to find than the last. You have to have a good data engine to filter the majority of incoming from deployed systems and look for edge cases. Then annotate and train with that and repeat. 

Some other folks are right. You want to reduce your feature engineering and use trained systems whenever possible for product and data handling. 

Also use the right model for the right job. Just because it's the latest paper does not mean it's what you need nor matches your data. I've seen entire teams fail using the latest hand crafted features optical flow transformer based mamba zero shot system they came up with when what they needed was YOLO and a kalman filter. Never under estimate the power of a good off the shelf community system.

Lastly accept you will never be perfect. Does your model work, does it work as often as you need it to, does it have the performance you need, do it's failure modes pose a risk? If the answer to these questions are yes, yes, yes, no, then your done. Unless your sponsor wants to embark on getting the last 0.00001% for $10M then that's as good as it gets.",r/machinelearning,Z0FBQUFBQm0yeGI3ZWltT0d4SGtBazRXSEdmbGJqb0ttSGtac2hIVHZrNlZ2czZwZmFWOFJsWGpjM0ZUOWpIa2c1eGltSERzNWpKZGNWcWVCQWdINUhkcUNQd2Q4YVBWaVF4d000c05DZUQ3dmJ5bUlMQnMxNWs9
"Well, two things: stop assuming that every problem can be solved using a generic architecture and don't focus solely on your model at the detriment of your data.",r/machinelearning,Z0FBQUFBQm0yeGI3Z3R6Wm56bUhFNzNUYmwxREVPRmduaGtlTlJ2MjluZGZrNEZBLWhVYkRvRHFJUFhSVllUV0lJYzRWZHpDa1B6RHBsVjZ6Z3EzRnRzNE5haUpqVEhGcHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eG02U1VCazNjYS1Pclg0M09xYXJfX0Q3bGhPNHJXRVBXYzNsdkNGb0JxS21OQlA0UC1GVkt2eWxKbHZnaHlLdkxDWThFWjQ0aWRKckxuNjNqQXl3bVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3dUdVRXdMeldjel8wZjBHRkJBQVRVaXQyN1JMNlZSajJseHF6ZjZ6M3ZrdU5qd0tOVF9sNG5WOXpnenRGQWNIMWppbnF3cU9aai1lTFd3a3VXY2JKU3c9PQ==
Not what you wanted but sharing anyways https://www.youtube.com/watch?v=mlXzufEk-2E,r/machinelearning,Z0FBQUFBQm0yeGI3aHRROXZlUzJ6d2FHWTlFdUdiMXVHcW0zQURmLUtkUHQyOGZqNXdvM0MyTFVPb0kxVk84dXJVTWFUbmwtWVN3MGRNalE1V3JkbjFrcVJNX29NeXJOOEE9PQ==
"Mostly data tbh. I read like a dozen papers a year I can integrate directly into models I maintain. Usually some of them can provide small boosts and a very rare few will significantly shift results. The latter usually also require significantly more work than the former and may discourage people from exploring them which is unfortunate

The most immediate thing you can do with to improve results is improving the data you have, both the quantity and quality. Beyond that, pin down the key parts of your model and make sure to keep up on relevant paper",r/machinelearning,Z0FBQUFBQm0yeGI3MkZfQ3EzQ0Y0UXFNd1NLWE00aHJpbW1LM0dXX3hXT2I3cE93cGQxNGJlUUJrdEVENk5NR2VDeWhKSHNOUU0yaTNmSERCZTJab3RHQ0xmSG5MVWl2Z2c9PQ==
Because memory tuning is fine-tuning and RAG is not? What's the surprise?,r/machinelearning,Z0FBQUFBQm0yeGI3NTk2TW5tUURSN1ZOSXR0SjJsQTZ1Qk5DSk05bDdlTk9WQTBQTmFoRlR6WFpXcmVHMWpHWHg5WE1EWFRsZGV2QXZOOG9NTW5iT2VnV0RtSElCaDJDZUE9PQ==
Try searching University of Toronto's machine learning course archives on YouTube or Coursera.,r/machinelearning,Z0FBQUFBQm0yeGI3TW9iN21PcnRhbTBuZFVKVE5OdTZTcXhMb29WZlRUZGhLMG1xbFVSS2xWbkdrQTJGdW03NGMwRDg4cDVWZHJObXNiakMtSGlUMW13ZDBMOFYweDdadUxlbUlNNHdmWmIzT1YxWi1aSTc2V0k9
"Waw, can't believe I've never heard of that, that is super cool! I'll try it right away for sure!",r/machinelearning,Z0FBQUFBQm0yeGI3aTc5N1hocS1VNEVkZHZPTlBDWHc3NTNYUTlPX3FpSWI3OEVvcHVOZC1LR3VyNk9kWHpmZkZwZXNZOHJzUUtvQTRRQ2NNQ1VuTmFUbXFuUnZBaHp2OVE9PQ==
"I don't think you'd need ""advice"" on how to network then ;)",r/machinelearning,Z0FBQUFBQm0yeGI3a2tXM3pYQ3BvNTdOOWRkSnU4MlYtUFRjV2l6OEFwMzdvZEh6YVhtRXhTb1doOW5SYVIyVUZUbmhLb0tVZ3lFTnluY3Y1Q1ZoSmR2eWdWRFBTN2FKdEE9PQ==
Yes but those connections are because of my advisor. It's not something that I did on my own really :(,r/machinelearning,Z0FBQUFBQm0yeGI3OWpzUmt6SmxHSmRaUmxDajhxRzJhbEp6dE5SdGc4R2gxZ0VvLWc1WWRNRnBXNFdYOWN1cXhvdFI1SnVja3g3MHlScGhCcU12clFDMC1KcTVZa0g4T3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3UDNsTWxvWS1VRk9pOW9wQzlOdUNORWpGejh0cEtmd3NCTEdMLUJRdUJSUWUzRTVuSXhlSlQwaG5PZFU4R2wxS1pzWEQ3VzVsbGZtQlpQVmh3aXRYc2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3M1EzQk5qaFVaS2lLM1BkUmVXMHZDWlNzeVBqQlhEOTQzMkxQTUZlTnZtWGIxbGxvcUZZMERUZUllcWJBWUlIWUNlSmFkZklaN09PQkxMZ2ktQm1UcVE9PQ==
"Are you talking NN layers?

I suggest looking up statquest with Josh Starmer - great videos",r/machinelearning,Z0FBQUFBQm0yeGI3UUNUSGJORG50aU1ubGg4d0hwRTNiUDUyd1dnRXQ5SXBMR202YzFhNmhtWmtNblZ3TjBHelZmYXY1S0xuTjhtNXJQTnpWRTZIX2ZBb1BYUm1DZUNfWnc9PQ==
Really appreciate your input. I'm asking from a modeling perspective but also a career perspective. What separates between a staff ML engineer and a senior machine learning engineer? Is the former better at improving modeling?,r/machinelearning,Z0FBQUFBQm0yeGI3eFZub3E2czRMYmtVMVNTTHpFNnBIYm5GSVBsUnRaV1NMbWdXeGRvYm1HclVKd09xazVtUTFLZUtud0FhNWlnek40NEtic2xpQl8tWUpwcU1MNFlBSHc9PQ==
My experience echoes yours about the usefulness of recent paper.,r/machinelearning,Z0FBQUFBQm0yeGI3eks3dVlVb1dTZ19lYXE5Q0JtNGZtaUNUbDlEZmtDMk0wQlhZVl92MHZlX1ZmLWdka05fOEJ2Zms2bkZIUlpOZFdMNVVTWUtWSmJKeXBOQjFDTTVOeFE9PQ==
"Wow. Thanks to the new CFG++ algorithm mentioned in this paper, there will be huge improvements in the quality of images generated with Stable Diffusion models (with the exception of SD3, which is considered beyond salvation).",r/machinelearning,Z0FBQUFBQm0yeGI3eTNycTA0WlZLNnFlQkFpSDB5SFR2UHVCRVNvLUdhOTd5VEN0Z0FCVzlWa3FHR2NIOVV2cXNOZktJV2phM3o2czNxWnZHY2R4dHEzOFRkeU1WckNOM2c9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3QzB4TzBqZWR3RFc0Z0tYZ1RwM0xVaFQ4NHJmQm8zUVRKckloVFFRYTR1cnZ6N19RaUl6Ynkzckd3NHNhU0dneVVWZlVMbjQ3R25KQW9hRUw3cUVtWjQ1RExCRTQ2SEMzYkZmV184Snd6Vk09
"There is no such thing as a solution for ""general hallucinations"". You can only learn as much as you have in your data. I would argue that perhaps we want to discuss a solution for the incorrect probability distributions introduced by softmax (a known issue), but we cannot really solve hallucinations, just error accumalation. This paper, however, is outstanding. This is my opinion after reading it, I would suggest it as an outstanding paper if I would review it.",r/machinelearning,Z0FBQUFBQm0yeGI3Nl91U2xvOEJvU1lEQzh1S1M1TDY5UHdmcHM4bUpHTzE0MWk1U3M2LWJoMzJXQ29xcFVxWEJjWVFPVGo4Mk1tckRtZllqNkhqdjN3eTNhMFZtd0Q4WENiMVVzYWNETWs2LS1fR1IzM1lzc3M9
"Kind of a trip reading through the comments. A time capsule, really",r/machinelearning,Z0FBQUFBQm0yeGI3SmZ6aDh2cFA4THJlUVRhai00WldsTzhLdHZZbXpsYkRXTng1XzczZUV2NWlPZS05OWpBOWVFTTdRaU1sejQ2bUJpWnp3cTNpd1UwbFpUbUFEYWp6ZzlCdi1IRFU4RTlWVHNUa0d6Y0hqYzQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3RHowSS0xeXFJcWpRQ19TdlYzemRLNFBUd1ViX05rTGNYcmRSdFJ4dWg2dHlyS2x6UFZtVUtwY1VCcVgxLUp4a1llQVVROGJzTGtla0tBLUYxb0ljWXc9PQ==
"Just write him an email asking for an ""interview on safety of LLMs"", and then during the interview, after letting him rant how LLMs are very dangerous, ask him whatever you want. Don't forgot to mention that he's the Godfather of AI in your requesting email.",r/machinelearning,Z0FBQUFBQm0yeGI3MGQ0LWktY1hlaDZFc0hNcElfVm5YWWFvWlpaT1BVSUJrUmlRNlJERFlYOWN3elMxbjRGODE5ZUVzUVNMS05vcElOOXotN3FNbDY1dXFPcFVvTks4dkE9PQ==
"BigCo can copy the test and take it secretly in their lab. The prize organizers never need to know. I'm sure that's happening right now. BigCo shareholders know if their LLM aces ARC that could very well lead to better models and then LOTS of profit. 

I wonder if passing the ARC test will lead to models that can better control robots for much better performance on physical tasks like cooking a full meal or quickly folding laundry or doing plumbing? An LLM robot that could compete with human clothing makers would be in high demand. Just one example among many.

If an LLM can ace ARC, will that be a big step to help take self driving cars to full Level 5? Full and safe autonomy? Or are they unrelated?",r/machinelearning,Z0FBQUFBQm0yeGI3YWdTbmJjR2o2R0hNejJXbERsVUZCRDFXeXh5ZWFGYjRFTXBzUHRZbFRZZEZGNjBCbnd1amJGQVl2Njg3TnllLVo4VHotUmZ2eUxGemVaWTlTXzVPbXc9PQ==
"Most of the comments here are pretty good in the general case. There's a few differences, though, for CVPR, specifically

1. There's a ton of papers and posters at CVPR. Be strategic about what posters you talk to and what papers / tracks you care about. There are too many things to look at to wing it. Have a plan of ""must see"" posters to look at beforehand. Also, remember that a big benefit of going to a poster is actually talking to the authors. Take advantage of this. Also, remember most of the papers are already on arxiv. If you're curious, read some abstracts beforehand.

2. For getting a job, go to the conference hall earlier rather than later. Getting invited to parties is the best way to network. Looks like you've got google and fb already, which is great, but there's dozens. Don't be afraid of going to smaller companies. Happy hours, either. They're usually in more intimate settings and still have pretty high caliber folks.

3. At lunch, don't feel bad about talking to people. It's usually a good opportunity for networking during the conference. Though again, I'd like to stress that most of the networking happens at the parties.

4. The posters that correspond to ""best paper"" awards get swamped with people. If you want to talk to those folks, get to that poster earlier.",r/machinelearning,Z0FBQUFBQm0yeGI3Qi1mM1VpcjlPMzB2bXZkZGxBWmJyaHFMbUJBSXd5NFo1Vmk4M0syeDhKcWpUajVrWDF2b01OQkJXUlN5VDJ5S2tQT2U3MV96TUw2bzAwU1ZhSF9XNWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3azViWmo0RlZtNXpDZkkxaExrZGRCeGVsSExxTDFjZGFVLUxZVW41bGlEb2IwMnZlaE1GaVN0TzZqcHhHYWs4QklfM2UwWG1qcVdNd0FIVnE3cG9sY2c9PQ==
"Hi i am also in the same boat attending cvpr for the first time next week. I have decided to visit various workshops and tutorials and talk to people. I have also chalked out specific posters that are around my research area , I would go and talk to them and get to know more about their research. Also planning to visit various booths like that of hyundai and waymo to look at cool demos. Let me know if you are up we can explore together.",r/machinelearning,Z0FBQUFBQm0yeGI3ZHdyUEU5MUZHVmtZNThzdTdGVmZJcGlQMGtIRktwLVdZbjZjYzNRb3BKNzZZMU9IT21wdV9BSXZseTVJTEQ5d1RPT05teEVtNDJ5WDdaNDlSZ1Y0ei1iQjFtVFBJRXJLMWIzSkFDMDZhUlU9
"1. I may be misunderstanding but is this referring to GQA or the forward(qkv)? GQA does improve speed while reducing memory. Last model I saw was llama3 using this. If it's the qkv_proj(qkv), it should be more common now. 

2. This should be referring to tied embedding weights, so your input embedding and lm_head shares the same weights

3. This should be the major one for memory reduction and some speed.

4. Mentioned by other commenters, most likely some PEFT method, LORA, prefix etc. 

5. I only know the normal KV cache

6. Ehh not too sure about this, will add it to my evergrowing watchlist haha

7. This is related to point 4 I guess


I think it's feasible, in fact also as mentioned by a lot of LocalLLaMa people that they were already running on their devices. 

I think these strategies are already used in a desktop environment, nothing very unique here except the fine tuning methods and possibly their own optimised kernels for their chips.",r/machinelearning,Z0FBQUFBQm0yeGI3ckdxLVRsS0tBQzNEdG80WjJBVm1nQTZLeEtyQ2RFU21lZHNOa3F4WmNvNld6YVRPNkV6bEx2cmVEQ0xFSXNnS3dpTmVMSjRRVlNSQURpRDZQNjMyNHc9PQ==
"[https://arxiv.org/pdf/1810.03292](https://arxiv.org/pdf/1810.03292)

This is a huge one (it does show the shortcomings of some versions, but it is also a very good starting point to find out other papers about that).",r/machinelearning,Z0FBQUFBQm0yeGI3TUw2eWViM1NtRHRyN01QVGxfMHEwSWotMjQtenZjVWtGRDhXVFBxSWhEemc5bk1xcGdRa25adWdtU25tRm9GRTRoWnFScTFSZm9QZDBIcHpja3ZSY1JnejU2Mjl4Wlg4S0Zpd3B4dmtoNmc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3T2JWR2hZaUt6Uy12aXNjT0pHa3ZHUS1kaV9VS2o1V2NvZm9aZUlLN28zNUJ4Q1JUOUhwTkZBd3JJazlxeF9nYlhGb3NnYlE4TlhzeFBOZ1lGNHpYMFJ4RXUyQUNnN3FJSjRvNUpPZ0p3V0k9
well at least you're in a great company there with bright people. hope you enjoy it a lot :),r/machinelearning,Z0FBQUFBQm0yeGI3bnZNLXJudFlTdVl4RWw4ZDhSekpqMnBBUmZZVzUwOVR3aERoTm16LVdweW9STnVBSm9wLXJZdjVkc0piVU41S09KUTQ5VWJEakZrRjBDX0JNdjhOTlE9PQ==
Why do you want to use LLM's for this and not unsupervised clustering models? You can just do a bunch of feature engineering like RFM to understand the types of customers you have.,r/machinelearning,Z0FBQUFBQm0yeGI3WHFsX002a3ZRWXpxVlB4WkJRSVZlbkNIbUV0QVZjZmxBTXRIOUNxX1l6cmRYYXJKbXp3MUJLR1JXbkJOSTRxMDRJTWU4YWRPb0NibTk4dlpWb3JfNGc9PQ==
"Yeah this got me back into machine learning!  I saw him give a version of the talk at U Chicago a few years later like 2009/2010?  Reignited my love, and drove my career where it is today, this is certainly the talk you are looking for, but probably a different iteration.  He made a roadshow of it for a few years.",r/machinelearning,Z0FBQUFBQm0yeGI3S1ZrUUxQRndrb0xIa2pHVnVHV2NYdjcxMGw5V3g3WDF5QWxCUElyWGtMMEV4Q1VkQnNwWl9NQWdLWlJMZzdFRGVGRjVfSlhoSFNYTVpKVTJxNTJuSFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3cWJIblJUcVFLRGZFa05kdVRpU09LcGJsSnJhWEhHOHVEUHdNZmFYekEzMG9JWURYcjZDcGp5TDN6TUlxVXNLVXkzQ041ZW9BZ1JZU000Tll4UHpLZ0E9PQ==
It's not dead. It's just boring. The research becomes too standard. There is no surprise at all. The research is too similar with engineering.,r/machinelearning,Z0FBQUFBQm0yeGI3WUZscXUzdUJKektTdGdBS3dqYlRxUFBqaGhhTkxSOURwV2h6cDVXbDUta0YwM1lpV2hJdVZHSi1YU2pGY3F3SjBsalU5XzRCLVhZWjl5YTQ1ZEh0OG15SS00ODlDT25oWUgwWUxjdDJuMzg9
find a way to save/earn more money? in the that's the only thing that matters for most businesses,r/machinelearning,Z0FBQUFBQm0yeGI3RjJHNUdubkpiREx0NVlvZjA0WVB6dnd6NzNZYjI0RWgybkk1SzhEb29EVjJyVHFKLUpqWVVtLW5UdThxbVFNNEliQmFqSkRrYXRLZlY5SFZZaGdDZEE9PQ==
It's hard to believe NoPE could do better.,r/machinelearning,Z0FBQUFBQm0yeGI3cHBEekFOQWVEV2hRanZJYWJ0YjBNMVFadjRZTUtEaVVMNkxRSkFuWUx6a1k1RGl0dXBDZzEyNTJPdnNOSWZjYmp2NFFjTDZ5dlIyUDF5cDhQTEpXVUhmYU9yQjNJVk5RQWFPZFFNd0RYb1k9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MXMtbXRYZjNIdi1MT09ZSU95TUJCTVZzbnNTWkJxeTRza1FMaFJINGVTUlBla1ZRdXlZZU91a1I5WG9MdTJ1OFJaWnhTR3l3NlZHQXhLNUFBR0huLXc9PQ==
"LLM, apparently",r/machinelearning,Z0FBQUFBQm0yeGI3RFhyclcyR0x5NmtTWTd1MFVIRUtCYTNLaHhnVTVxVjFMU1dySkh1RkQ4ZDNEcXhYbnZIY0l4WjdnMGN0THFZcXhzcTJJZGMtVmFOSnVTR1ZOOXFMeFpwQUxRSUhBRUZTdnVhYmE1TVVQV2s9
"retnet, mamba, xlstm",r/machinelearning,Z0FBQUFBQm0yeGI3TVhHeDY4MEhOdG1fVGtJZEZQbTk3SGJOajBvLXRfWDR3bHI0azM5dEdjcmJaUXJPTG1sdTZSZ1BrS19UM3JVdU01RXJpakVwZ0dNdkFUekdjWDhOOGduYWRNSWlzM1FUWlhNNGlEbE8wZjA9
"retnet, mamba, xlstm",r/machinelearning,Z0FBQUFBQm0yeGI3NEtEcWdUUDBMQTd5dVhKXzQ0bERtbVVGZnFjUmhVWncxc3dWN3BJaHNIWEpad1lHZlVGV2JscE9ESGtsMlc0Z052M0U4dWpRa0U5UGVVV3BmR0J6bHczZ2ZMUVk3eW1RT0o2ZzVGSTFDbkU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3S3M4ZEpvdS1ET2dFUllkV0VpeEJkTE1TVF8tNF9wV1g5aTRvMDlGOV9Kck1IanZLVnJsbEFvSXlBWGVIQ1FER0FtUE51ZktPUTcwX2xvTDBkeXAtY3c9PQ==
**rotary\\_percentage of 50%**: borrowed from stablelm,r/machinelearning,Z0FBQUFBQm0yeGI3WTVIekhOYTJxZ296c1NBd2xaYllkWFR4YzNad2R5MWdhVE9Ic3ctUFRhZ3JYRUlwVFhpTXBPWnFPRE5DcTMwU1VGTGNEZFpJR2paYlA5dkFoTXZJNzhhRkFSM1FzSlNQT3hHazl2SEJ1Qmc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eWlhWHZaWUV6b3VJQXdWb3R2QmFtOHVGV3BVdkFYTDNSM2p2b2xERmpKczl3NzFvSkpoUC1iMGVkN1NJVjVTTmd1WmsxcWdKMkZibUFORUxhU3dGWUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3TUkzLVgwQUZsRm5pcnVQT3pDZXBkN1lYVnFfOGtjUy1SOEhCelRJRWR1ZC05Q1ozbWU0Y2FLZGV5SmtPdk9IOHlxTmt6WkR3Y0dCb3hOR2N3Y0lrdlE9PQ==
Was this omitted from the application this year?,r/machinelearning,Z0FBQUFBQm0yeGI3NTlSLVlzTUxobkI4N1p0aFNlNlA1blpnc19xWFVsZklRSU5DNk1PNE9RMlV4Qk9mUzdYZnR1aE05Ni1rU29jMzg1cUU2a25Fc29rRFlYVVdMekdjbEJTQUpwMndZV3lrOFVqakw4RktKbnM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3ZXFkN0N0dTRraUJrZExZN2UwdC15NGdYNXBxVlp3U0VGWVRYZlhuZFd3X0pMY0NaWkhoajBUaElkWVdtTjR2aU9rd3BKQkRlbEVWclJxdi12b1I0V1E9PQ==
You can also do a FTAN image with both real and imaginary components as inputs. That way you can retain phase information.,r/machinelearning,Z0FBQUFBQm0yeGI3OXY1Mk5aUWpvbTJVTkdmZnVhZFptNFVFNzFFRHBCTEwyRTVrREpvWWdvWEZlc2pTTGVkcTFBcE11anNfVHBXSFFhanFTMWtYR1BaRDg0ODVoVjZ4cnc9PQ==
"I might remember watching that.  I even downloaded and compiled some software in C or C++ to run it on my own machine.

I did find this ['07 Google Tech Talk](https://www.youtube.com/watch?v=AyzOUbkUf3M), which is the same material he was using in all of his talks at that time.  I'm pretty sure I saw some of these slides resurface in 2012, with that awful familiar pale yellow color scheme.",r/machinelearning,Z0FBQUFBQm0yeGI3QXBNYkRXYmpkN01TVGVzdlM0VFdLNjZPUEo0V0dHZ0ZkRFFDZ2pvdnBSS3RzaER3WHZqVHo2QTBKZ0MxNjF2czlwZjVlSHpFclUtQVc2ZndIVldZN1E9PQ==
You dont need to train when you use these face recognition networks. Just extract the embeddings and the find the mean vector for every class. At test time just find the cosine similarity of the test samples to all the class templates,r/machinelearning,Z0FBQUFBQm0yeGI3d2ZpZjZTbFJtbWVJcTd6QUtuRmc0TGUxNHFZWUgxWkpTc0FJVTJ3Ylk4TjFfSU5BUGV1MzV3SFRueWw4Q19pSG5LX09jT08yRnZPSmJiU3BvaFFDZXRGTG90TUFOc254UEtZX0xMTVd3TWc9
"Hey thanks so much!  
This is it, it's the part at around 26:00.

I wanted to watch this again, because as far as I know this was the first time I ever saw generative AI, that we know now is all the rage.

What a great lecture too!",r/machinelearning,Z0FBQUFBQm0yeGI3ZE84VGx0SnZoYi10MTNFSE8wQVdTV045OG9UWnhZc2h6VEdVRFFMcktvY1BxV2ktaFl5Q1R1bnAzMXFEYU5iQTZYV1JYNGxDWi1MVWlpYVR2NmgxQVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3cFhjalpaWnhGTGdnWTRXQXVpb3BCcHhuMVctVlRIZGxuczRJRDF3Wi1vdlUwMlhKQjl1UWY3TGdldnFhV2JnYUJPSDl1VURTQUg5c1RQMl9mOGJzelE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3SzBlSjI0c3pxRlVORlZ2cmJ3Q3FFcXI3dHhlaWctQ3NldFA0TlBIQ05hNHZaRk84cGtUSGZ6bU9TTEtzM1VvdDNWQXk0Ty1QUjlxLVNlODBSeUV3VXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3Sk4tMXVqT1BtSHp4dnJreGhTeko2c2VSdThnaG91R3IzSnU0aHc3ODFGd04yLUJ6a2ZHT1VvZ0JrWkJMSUxrcDBEbllaQUxjdk9XZmZxOF80VG1QV3c9PQ==
"[ **Jump to 26:00 @** The Next Generation of Neural Networks](https://www.youtube.com/watch?v=AyzOUbkUf3M&t=0h26m0s)
 
 ^(Channel Name: Google TechTalks, Video Length: [59:24])^, [^Jump ^5 ^secs ^earlier ^for ^context ^@25:55](https://www.youtube.com/watch?v=AyzOUbkUf3M&t=0h25m55s) 
 
----------------------------------------------------------------------------- 
 
 ^^Downvote ^^me ^^to ^^delete ^^malformed ^^comments. [^^Source ^^Code](https://github.com/ankitgyawali/reddit-timestamp-bot) ^^| [^^Suggestions](https://www.reddit.com/r/timestamp_bot)",r/machinelearning,Z0FBQUFBQm0yeGI3TTRoNEo0OUJYc0JURWxLMmJjZlcwUktiOGd5Ymh3cVhhV0c3WXQxTVNOUy1yaHBoTE1CR0M2SFNBZ211clg2OE4zajVDTWxpaXlsS1pkMlZwUlpFdEE9PQ==
"Turing test is definitely not solved. You can even say ARC challenge is a subset of the Turing test. Just ask ARC type questions and see if AI could answer it correctly. The Turing test does not limit conversations to small talk. You could talk about anything , including asking ARC type questions which humans should be able to solve accurately most of the time.",r/machinelearning,Z0FBQUFBQm0yeGI3TnBIdXVXczZZVjJadXdtMmpQUHBTcEZic3VzMi00cXhrb1FpNU1zWGRiLXgtMTkyYnJoLUJTeUtHd2pRWUtzT2F3WUFBVkRkbUVuNDZSREpZRExWaWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3TXJMS19BZ2d0ZGpEQXB3UnFhWnN1cGFwVlkzZXVJcVNkUGtveFlQeWlpajRNSV9HTGhxX1lhS1YzYWVDT0ptcnYwZmNuUXFjbHhEWFdUY3BUSjdBZmc9PQ==
Thank you so much for the links! Love how detailed the blogpost is. I wish content like this showed up on my google search 😅,r/machinelearning,Z0FBQUFBQm0yeGI3Zm03UWJCOTlNb1lFV0hPLVFHRnppbnNIVGhjNlNIVjBOX1dmUDNRX1QyTUdBMzZnU0ZlNW9Tbzd0azlXTElTS2h3MUktdkxIUWVlWTgzalc2WTFJTWt1NUZOYnJycnFIcFFMS1FhQ2ZOQ1k9
"It depends on what the waveforms contain.


Our ears are more or less insensitive to phase information. So if you are processing an audio signal meant to be heard, then the relevant content is encoded in the frequency spectrum magnitude changes over time.  So preprocessing with STFT makes the input easier learn from, and also more analogous to how it is received by the brain.


If what you are processing is any other kind of signal (telecom, radar, sonar, radio telescopes, ECG/EKG) then this type of preprocessing could be completely inappropriate.",r/machinelearning,Z0FBQUFBQm0yeGI3Wm1uaWF5bWRFRHBIWnR3VVRJSXRKcHBYTG9VcDdOX3BieEZOOXR3VHN6S2x4VFZRajJFZzFQejZIVVRUbjZnb29vclozanVOUUZCODd6d2dLV1YyaWc9PQ==
It sure is!,r/machinelearning,Z0FBQUFBQm0yeGI3M0xFRXlxbW14TEczVlMtUzhhTGlwNDR3b3ZmV2lrTEVTaHBFRjJCdkY0UFYxNktjUGVFMGxvNGY2ek5XOEk2c2ExeTZCRV9GSnpibldTU2dWX3Bhb3c9PQ==
Maybe they pick up on a complex number representation,r/machinelearning,Z0FBQUFBQm0yeGI3R1IzekFPQ3ZITlVOT3VoOVFjZjJFU1Y2VW5ITzVwZmREN3ZHd2ZaNVRCVUJuQnRsZnd2aldKekdET3RzU1hsM1RCYU93d1lCNllvVVEtQlBwaHZiYXc9PQ==
"I'm sure this looks interesting, but does the problem really need ML/DL?

Since you have the player name, year and the score in the video name, you can easily Map the player to the country, filter out the matches of that country in a year and find out which match it was. Given your data is elaborate, an algorithm will likely take lesser time AND give you better results.",r/machinelearning,Z0FBQUFBQm0yeGI3VFdMSk02ZFZaUEItTmFkeG9CcnlRNTJvZ3Z3cVZWZkFoWW5lWHg4VDFyMG1McHRoTThXREZrc09fZ2FzYndKTFFzcDV5bTVxYXNYSmlqSWRyRVB5S1E9PQ==
"That won't work in court. ""My article looks identical to yours because you're just so predictable.""",r/machinelearning,Z0FBQUFBQm0yeGI3U0ZGT1FWZjZXeWhtM0ZQUnBuYlp2TmZkeFhWel9Tak0wMUt1dlQtYl9pcUduWUM5LXlvX2JkdjlaMlF0UGpaS2kwUlY3eXBGOWJiUXlMc1B2bFByclRDODQzMmxvV28zc0NJb0RCUkZ5d3M9
What kind of models are you using for MMMs?,r/machinelearning,Z0FBQUFBQm0yeGI3WkxncEVIZ3NiQTc3ODJkd0lCYTU3NHplYVBlZUxEaWR1X1hPV1RZUVlZT2ZDTXlzOUtxQUdWT2xRVVp3alBMdFZqT0NjVTlLemRwdlJTY3d3ZGItM3c9PQ==
"This. Be curious and open. Personally when I put too much pressure on myself I'm less approachable. 

But one advice I'd give to OP is to be comfortable leaving conversations and/or groups. 

Until I saw my partner network (she's amazing at it), I never realized how much of my struggles with networking came from being too... committed to the person in front of me? If that makes sense?

But it's a conference... others won't care if I leave to pick up a coffee and never come back. But I get to network with a lot more people though.",r/machinelearning,Z0FBQUFBQm0yeGI3bTZMQkI1cUlyTEZWY3lGcndOLVBxWHpjRHVhU0ZfOUlhU1dZUExwcVJfX2psWEFFWXFsOEVQQmxDamJpVnJQbE1oRXJVd2Y2Q2hGUWhXYktBdDZwWVE9PQ==
"To me, this paper says the quiet part out loud, in that mainstream ML venues systemically reject application-oriented ML papers, even if they have several novel contributions, instead preferring theory and experiments on synthetic benchmarks. While I'm a strong proponent of the value of theory, I think a good mix with empirical results (i.e., on real-world data, on metrics used in practice) is necessary as well for people outside the theoretical community to care more about these venues.",r/machinelearning,Z0FBQUFBQm0yeGI3bmoyWEpsWmQtZkZOX1V5Q1NOOGFZRFphX1NadHV2ZUtuODk4ZGFtR0N2ZlZtSkZDREFUbWlNQzZ2VTduNFQxYjN2SXNxSDRLQUFJVzlONThRMGRlZXc9PQ==
"Thank you for your reply, but the problem is I have thousand of videos and all have weird names with some dot in between some have serial number to start with like video no. 33 - yuvraj 57(65). 

I want something like when I provide the video name it searches through the database and find me the most relevant results like google search results the way it can understand. 

If you can help me with that, then I will be grateful.",r/machinelearning,Z0FBQUFBQm0yeGI3bFRMRlFTRjdVVzh5TVZvQ3NaZjl0TXMyTy13aUNoMkl4VlZXb3lyRkdURWpSaFI1bHlEbzk3em9aeXFuMUdIWTFUd0N4dVlSREVrQm5QNEtnS0F0bmc9PQ==
">So, do humans/animals have `torch.stft` in their ear for better perception?

Yeah, pretty much: [https://www.britannica.com/science/ear/Transmission-of-sound-within-the-inner-ear](https://www.britannica.com/science/ear/Transmission-of-sound-within-the-inner-ear)",r/machinelearning,Z0FBQUFBQm0yeGI3TXhGVlNCMnFqSmpLX1RtQXRFbHBQaHhQVl9qeGdpVnJzcWJCWVVsSGlacHl5aGRXVFpfcUcxd29pQXU4SG12S1RyTXI1S0VsYlB3UVJSallveTJzaGc9PQ==
"I'm genuinely curious, do you not have other projects/models to work on?",r/machinelearning,Z0FBQUFBQm0yeGI3b19MY2lTdEhrbGZZdm55alh1NmdaSUpjMlpxcENtQmpLTC1IVWtJOHZGTERfU1Y2LUtlOVRvXzhCTnFRT2lZYVBFVjdhRGU3NndFQXp3YmdwQ0gyN1E9PQ==
"Not infinite, but some things in life require a lot of steps: school, looking for work, conversing with other living beings, and learning a language. 

Learning how to drive could be considered numerous, requiring many steps, the intelligence has to adapt to new environments and scenarios constantly.",r/machinelearning,Z0FBQUFBQm0yeGI3Tm5YTTgxRVZvdmwwUVd2YmRXRExja1NzUmVZQmltUnM0R1NqaXJ2SGJVME11VFhrSDdkZ0QzSmJ5Y01NNTZUeHFnZl9BeGFMS2I4aU9WSE1MNXhSTUM1TmhjcXduX0FzR1R0eGs4SDR0OXM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3amVzRlhCUGN6R1BfM0phWExpY1d1YkxtQVhIUzVWY2hUTGxWUXRQVVVERWp0NmdNZXJQa0lXeDBfd2xkOFk4NXh6emdXd3Jrd25ZSlA1UnZDWTJnM3c9PQ==
"This is pretty much what MLOps engineers take care of for a living. You'll want to have a separate QA test set that you can trust and run regular tests using your model. I don't know your exact situation, but I'm assuming you're running your model on a regular basis on newly collected data.

Sinc distribution shift is a real concern, I would first train the model regularly too and run inference on the QA set that you have. If the performance degrades to an unacceptable point, then use the previous model. If not, then replace the model.

It's a very typical development/production setting on software development.",r/machinelearning,Z0FBQUFBQm0yeGI3bDlfRk5lQmlYMGZYZ2VFZnlHNFBGaTVnS29xNTE2ZFJfMmdET2hURGF6X1lmcnVETkNPWXRNM19fYzduckZJckViYlhGQWxvR1AwamZLNnpqdFJ4N3c9PQ==
"Without him AI wouldn't be where it is, I highly doubt you looked something up about his perspective and were proven right to doubt him.

  
He's human and not infallible, but I think his arguments are spot on concerning LLMs.

LLMs cannot seek new knowledge or learn new languages without large amounts of computational power and really large amounts of human data; this is not sustainable.

  
AI can potentially change the world; even though these chatbots are very interesting and helpful sometimes, they aren't proof that we are in the Matrix.

  
LLMs cannot reason like humans. Not because they have finite knowledge, but because they cannot learn new things on the fly as we can; this is why self-driving cars are so hard to do (self-driving cars are not LLMs but are built with transformers)",r/machinelearning,Z0FBQUFBQm0yeGI3RTVuY0U3ejlnTENxOHgxa0pWRGFvNXRBTDdQWHZnbGI2M09PeVg5eVpnS1JxVGtmQl9hazdSZlNkRmNueWRIQkk0akU3ZWdibDd2dnRYaGhVOTJXb0pUX2xLd3hpTXZzVTdUM2U0TnBNaWM9
"""A lot"" of steps is still finite, though.

Unrelated, but it's apt that you responded to this particular five-month-old comment of mine today. Just a few days ago [NVIDIA released a LLM that's specifically designed to generate synthetic training data for new LLMs](https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/) and it's under an open and permissive license. So looks like my first point about the risk of lawsuits over training data going away is coming to pass.",r/machinelearning,Z0FBQUFBQm0yeGI3M1RFcFNYRldWUnFieEJVV01rSHVfa3dQSWdlUVgtakpxY0FNM3N5Q3R2b3Vmd2I1ODlVRUttNWl1VUJTSXozbUJnS2dJZW15SHdtZEVOR29IRWpFZFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3clFmWEdESWVYOGZMTHREbHRwbGFRTHl1VXFiem8zVFBUeXkwNUNNV2U2NXZsUTNCVm1sUS1ReHpiYkRZX2NXSXQ5ckxNcVhMT2d4MlhWaU9pb0NqWnc9PQ==
Get more data and work on AGI.,r/machinelearning,Z0FBQUFBQm0yeGI3X3pMUnJPel80a19kY01YNXlBQXJSejNLRGZrUk53cU5UcVlpX05SMnpad3VOLXpoUTNYZ0dXWVhuV1RXUDZJYVUwTk83dEJyRW42azRSMEF5dGJmRGc9PQ==
While I agree there's a place for this work I think keeping mainstream ML venues focused on certain core topics is probably good as they're already there's way too much work submitted there. There should be more application focused conferences such as WACV and we as a community should put more value on them rather than putting all the prestige in the current ones.,r/machinelearning,Z0FBQUFBQm0yeGI3WGN0T2F4SGRRLWtRZ2NHRjNoNkMzclBDQWRGYmJwcnU1czNPV2pocFJhWnBjNTZsdVNLUnN0cVhjSUVWdmdtZDRNNzVCNlh6MmZEV3V0Y21KaGxYSGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3aDFETFI2NnZRSjF2REVGeFhEdWhyTVcweEc0TnJpVXVSZDhRN0RuR2pRc0REcVpQS1Brb2ZnY2hGRGFtVnN6RkxrYXdqeU1DRlNWZmZQYU41YWFGTVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3Z1NuY2lnYXA0ak9WR1ZPQTh2eC12dDY1ZGQwTDlpejdoQW9uSGpNelFpVlEyclFRZi04eWVHYTZzSVpMSDZyaXg2SUhXVmlHTE1GSG1hc3duSUJJRnc9PQ==
What algorithm should we be using to solve this problem,r/machinelearning,Z0FBQUFBQm0yeGI3aDdPcWVxQWxlYXgteUQyZl9ydllKNXk1QVVjMXRUQjNqWGtUWTJRa2tIbU9iRHJHTmZGamNmUjhQQWNsYXB2SVNEZHZtTTNtT3lQVGswVTVRdjVmYk1XTkpueUlTbjh5aEljTlpsX0tueTA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3akV0aUZybzg0QXRPWXNESGJPeEV0dHZjaW9BVXhzTnhzNGxTdF9JaVItekRDajFzVXBnR1hMQmw2djZ1Sjd0XzIwVnNvOVMxR3Q5Vi1BVUJUZ3F5Nmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3MU1vTXFPUi1aTVVadlQ0Z2NHSjFOaDJlaWhMQlprSmJ4OWpzM1Z2Y3I2QnRBZzhGSm9zX2dIRXhtNHd1cUU4b2dOWmY3VkJJMGdvazI5QXgwRnBHLWc9PQ==
There were also really good videos of Geoff Hinton talking about echo state networks.   Those have also mysteriously disappeared.,r/machinelearning,Z0FBQUFBQm0yeGI3SFZYbXlUbmh3Z001U1JFaHV4Q3ktZldQbUlTZnExemRMQW94SV9KRkNjX3FMNjRXbEhkVEtjbXZURFJKYkhhUDdVSGM1WVA2LU9qRDdyazFueGoySHc9PQ==
You can do that with a simple searching algo and some formatting to extract insights from the video name. Its more of a data cleaning task.,r/machinelearning,Z0FBQUFBQm0yeGI3X0JFQjZiS1hkY0pYbjJTZ0xjZ3FLVFVXc2d6TnNOVFZIMXZxV1VpNklMQmVkdWx2TlZ6TmoxX1U5NFBNZVd5cGI2N3M0OHBJWHNlcjdCUmJyblFfNmc9PQ==
The cochlea basically does stft,r/machinelearning,Z0FBQUFBQm0yeGI3SnEyc0FOMktuaGN6VEFveXdWRlU3NUR5TTBVbXNOSVRWTzB4Y3lCZGZVX3pvZ3ZtblR5VUJNcVRNNElXUTd3ckZYLW92S2lzSVRUOVRqX3R6cF9RY1E9PQ==
"Your question is a bit like asking why aren't people studying how to transport things faster at the start of the 20th century. The answer is they were, but they did so slowly through auxiliary research and inventions, improving combustion engines, improving roads, studying flight, etc.",r/machinelearning,Z0FBQUFBQm0yeGI3anVvRlU1QnJuTmU3ME9oVmlzR3lUSEJTV1VPcW9Ic1g1NDljcGstMTc0d0xyRTk5X1BPZzZtU0JKOEhJT2tTLXlORGRfMmNjVXM3emFZSUwxUEhzR3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3TXZMdVhDOFkzVDVrc094NmtTemJTWXQ4ZV9xYXd0NlVCWVJtLUV2YU5zZHhsWDFJMEdnZ3E5cEpRdV9UejRGOGl6MWJ0VlVyZmg2ZWpzZ0NOaGNBTEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eFdwYWw5bmZkTDJmZVdkRHcxYkk1UjNlcnloeXlFSmVSb3NjMVJYNERrUGRuNDVKaWsydmJXRXVleGpBRXROUHJueDVEdTU3ZnJiRzVSeWhKWlJCRkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3NFJNUlQ1WU9TcGZmV1g3cFlHMVNKOG9aWXlFZ1pXY1R6SjI1MUw4V0FwWTBWc1BVQTUyQ0c1SjR6aThrQVRXbUNDUEhCdnlRdlBLblF0c3pfYV94VHc9PQ==
"We are all interested in ood generalization in machine learning, it's widespread and uses different keywords",r/machinelearning,Z0FBQUFBQm0yeGI3bDBqc0RLeDNrRGZGYUJTTkRMUFRMM25Fdk9wQm1CaUhjZHlPSEJyYk1ub3VRMlZoYnJ2S19RWlRnWmE1YXQwY2VVSVNpYXo4QXY2dkFGc2tNMExNRnc9PQ==
"If your model seems done, as others said work on data. But also run hyperparameter search campaigns, dive into quantization and deployment/inference, improve tooling and infrastructure. Keep up to date with latest literature. Reduce tech debt. Once you are done with this either your model or business case is outdated.",r/machinelearning,Z0FBQUFBQm0yeGI3a3I4UW1aWldhX3c0dlR0NERwYk1CXzN0YWRDQ3NvYVYzc3FsbmNoMVF5N1FpX1NQTzZJUjJWODF1RG1GbUVITmtmUEhjVHlpU3ZUcUpUREdUaGx4Z2c9PQ==
"cool article,
i'm feeling a nostalgia about pytorch :)",r/machinelearning,Z0FBQUFBQm0yeGI3VTNwVHM2V0UxMU1pQ0pEbDRrTHh0azdQYWFxOWNPTmJpOS1PUVhRMEFUd1IxRVpGTlljeENibVFtNkpjbWV4YWltVGRhbllCa1BXOFZBX0EyN212amc9PQ==
"This video where he describes how they stacked a bunch of Restricted Boltzmann Machines to generate MNIST digits is what I immediately thought of. Very informative and funny. I especially enjoyed watching him ""disparaging"" Backpropagation and then pointing out that ""Yann LeCun"" can make it work for almost anything....",r/machinelearning,Z0FBQUFBQm0yeGI3ZXQ5dXdycDVQdnFaVmNFd1hTM2NmVE9qcXRBZWI5WnlnMTFxNWdXeUFCTUl3Z1RacUV3MlBPN05uQ3dQYmdKd0RiVXdQd1dEcmhjeEV0dWt3RWNuT0E9PQ==
A mix of ols log linear and Bayesian.,r/machinelearning,Z0FBQUFBQm0yeGI3aTJRZWZxRFpieFVmc1JvTms3UVZRQ2VOelZCY1JjS3J2R1ZMRTJwTk1xUlZxYlZzc0lPRHhGMTFkWXJvdmJBdHYtelhkMF9IamJqNzJNalAwUWRTbHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3RTNzR2ktaXJYS3IxQVp4X0xsMHkxQTZvZkdoZ2Zlb3l5WklpNTh2MU9ESDRwNnltODl6OVZHUG1IYzB1RjJDMmtNdDN5SHlCLU9ueXNxRHJ2dkl1V0E9PQ==
"If we talk about language, isn't everyone trying to solve it? Whoever is talking about real intelligence, I guess they are referring to OOD performance, instead of remembering individual data points. The evaluation datasets try to create unique OOD questions, the IQ tests try to measure the ""true intelligence"" etc.",r/machinelearning,Z0FBQUFBQm0yeGI3bTlrcmlITDg4QWFPSjQ2Tmw3R0NaMVBTT3h4VEM1QjFJbWx5UV9TUTE2T0ZkOHBocXpMS1lHTmFDQVRzWVVFa3JTWWtMVjgtRUFSQW5tX2VUaVhydWtIcjFyNWx1eW90RmxFTFZtcWVvVlk9
Free GPU with infinite hiccups.,r/machinelearning,Z0FBQUFBQm0yeGI3N3V1X2M1ajg1Rkt1a0xBWXBlMXBiZzFTSnlILU1WUTdIRl9mWlBLZUowdFB2V1djQVlLaFNSaHBxS0hyenhiekNNX2lDVmFxOHVGang5SVYwQVljaGc9PQ==
"I can’t speak for the thread op but at my company senior and staff (regardless of software function) are differentiated by ownership, KPIs, and the ability to define their own work. There’s a whole pathway to promotion that involves a packet and evaluation via peers.",r/machinelearning,Z0FBQUFBQm0yeGI3aklzQm4tTE5kU2o4c19uUHVBWXhCV1NfV0x6akpNWVhHQjRaVDRldVFMUUVJMGZkU2liWmFjd25TeUhPQVhnd2tVYU9aSFJGREdMc3o1RHZQQy01UWc9PQ==
Elon?,r/machinelearning,Z0FBQUFBQm0yeGI3UGY4Qk1kdG1SbmZaSzJyYnZzR0pObnh2Yk9La0wza25RTEJ0MjNfdkREbGxhUDV3Q1JBUURmbU9SMl9pYmQ1M1lnc0tYM1JIY0d6RDgwaEtCNU1BUlE9PQ==
How do you set up your priors and decide if you should use delayed adstock?,r/machinelearning,Z0FBQUFBQm0yeGI3SnhRZ2ttUGI1VE9kVjFTMFJaVUM3T09TdXNYNnkxU0ZvdURQdmpaRXBzQTJhdEVBekplcjRGRnJjejdXYjI0NHBsMF9Ed01TelppakNNbVhxemZydVE9PQ==
"While we are on this topic, anyone successfully used Grad-Cam for solving an issue or gaining meaningful actionable from it?",r/machinelearning,Z0FBQUFBQm0yeGI3SEpIaVZIajBkcmZnRHdMdTVZemZiM0dmMUltaXFtYldfejVFZ3V3VEtJeGw3cnJjWTl2VUVsUlhmMUVyTDUwVjZQRmtWcG1ZUEtzNUwzYVdRQU9sVjFiQXZFM2ZTZFRKMHp1My1kNEMxaGc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3eWI4X1Q1S3VJQVRDMUlxSXRaZFJwOUJndGVoSEFnUXJDaFNzb0NERjNUU2V5R3M5d0dSMl9kOGVxSmxlclZmUkFIZnNqRThtMW1Fd2NZalJFSFZSUVE9PQ==
"[https://github.com/Alignment-Lab-AI/KnowledgeBase](https://github.com/Alignment-Lab-AI/KnowledgeBase) this was the seed that sort of kicked off the discussions, prestently the developers ive been speaking with are more or less ready to go, primarily just variously waiting on me to pull the starting pistol when im done with the job im on atm in the next few days",r/machinelearning,Z0FBQUFBQm0yeGI3S01BYTRKTEo2V3VwdGdvQl9EMWN1VXg3blM4NHdsRlRVMmpZY0EtN3M5UXJoYXphOEhLTXkzZTdLbUptaE9KaGdvTkxkUjlzaUlfUW9HQVhoZWJtamoxcFh4QmlkVGE3NlExQ1F3ZVU0enc9
"The only guaranteed way to generalize OOD is to never be OOD unfortunately. 

Another way to generalize (by cheating) is to basically add more knowledge via contexts or tool-use. 

There's recent work from Andrew Gordon Wilson's group at NYU using PAC-Bayes 
https://arxiv.org/abs/2211.13609
but this is basically looking at regularizing the function approximation in a principled way, not concept generalization that the LLM crowd are probably more interested in.",r/machinelearning,Z0FBQUFBQm0yeGI3QjhkY3JWcmkwVWxVc1ZDSjdXWm91UWxVXzJvM2l5ODM4NlViNkhzNEI5aFRJbjc0MTl3dUFJZktvUURVV0pKcEl1MzVRZjVVWEhCUm9LQ1NvQ1plcGc9PQ==
"Evenly scrunchies rhyming, biscuits. ",r/machinelearning,Z0FBQUFBQm0yeGI3QjR3MzhpNy1VVHBDeUYwVFU0ZDZTbGNCVlBfS1VSS1hzdC1VdXIzQU9WLWtLTFZjdG9aaGhNanlZYk5qYkpoSFV6VzdwSFhIVGgwXzI5Qk1ia2E5Y3c9PQ==
May depend on your citizenship and where you want the job,r/machinelearning,Z0FBQUFBQm0yeGI3NGhWbnhzMENvUW4wckxsbFZoVWlpMXpqNmpRcmxBN2tUYTRCR184YkhpaEFNR0FMLUhHVGtHRDlPWmJzR180WGZwX1VZalZ5NVo1VXhXME9mQUJCY3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3RFJnRzc0MkFnOVdIWW0zRnV0WldsYVNaTklQMzZDWjJDd3h3OXhEUEg0M3FaWmxRdjN5RVJleTh0TldNUmM0RDZWMjZ2dzh5al81M2FCNkduWlI2M3c9PQ==
"In India , usually companies ask for some experience and Masters degree in ML.",r/machinelearning,Z0FBQUFBQm0yeGI3VldDU3hkSTdLVUY4TDdieFZqOTU1bjRLZmtGdjdQUTNhS0wzRjJYbnh1dnd1QjVEbGhBNDEtbU53UGRKVXJYTHZDa1VEaTYxSmNHZ0psclJxRWxIdll1ZU9Ec0hPQlM1S2Z3V1pjQzFNSEE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3aWdBbnhUQWs4ZmFQTEpkWmlYa2tZUWtrcWd6ZlRXaWRxY0xsX0E3TGNkLTU2RnFYTV8yNVNSRmlwRUloY2Q2VGw0dGkwclpmOGl0Wk1sM2dzM2Nsd2c9PQ==
"Very cool! This could be used in lots of places since the logsumexp appears in so many objectives (log marginal likelihood, risk sensitive control, etc)",r/machinelearning,Z0FBQUFBQm0yeGI3QVVIWmFabTFxSTVra21aeVV2Xy16dTBDMkRoYlhkYmR0RFpOZkNPeWttQW9NVXNXYW9tQlUtaWZuazBYWmNqNUxXNUxaY0ZpSkpZRC1sSXktYS1GTmc9PQ==
"Yes, I did",r/machinelearning,Z0FBQUFBQm0yeGI3ZVh1VjF2QVdzVjk1emdnU1RfcmUzelhMZVBUOHdlbW1JNW1nRmUyUll6NDZzb0pQZ3FPTGhfNFphMkNnQXFOZG1hWHYydGNYUVpvOTBoNldaanFsUkE9PQ==
I stumbled upon this paper this week; your post comes along at just the right time :),r/machinelearning,Z0FBQUFBQm0yeGI3bGU1NEdnNm5RMW5EV290OHJadE9lQURobEY3cVduazlNT05reEFNN2xoeXRQRTlKVGxhdmp4Z2JmaXBpU2xkdUprVUdMdmVvbzR5WV9VVmNjUVBBaHc9PQ==
"In a way it’s the central problem of machine learning, so yeah I’d say pretty much everyone is trying to solve it in one way or another",r/machinelearning,Z0FBQUFBQm0yeGI3ZS1LREhKWks5amxubVA5LWZjUnRpRWVpR3I3RVJzOEo3M2JUanRoVUNqc2tQRjgyVnQ3T0NQa0g1NTdrUnpTREhFazBrRWxWeFVPNEVhbW15c0hTMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3d0hNYlRLNktoeWdNV3I1ZmhlSGp4b0d1ZndhblRQdWxKQjJOTUFrNnV3Q0dsZjZDM21lZ3VkQ3lCNzhCUnRuMmRnVTk1a0ZxeWpWRS1uMVFvY2w3RFE9PQ==
"I think OOD generalization is very domain specific. I work in cancer research, and we published in ICML something where OOD evaluation is an important aspect of our method, and we sort of created an evaluation pipeline to take into account different types of ood generalisation.",r/machinelearning,Z0FBQUFBQm0yeGI3SER0N1NtUHUwcml4c1R2RG9XdGVGeElqaFFDNFF6cWFJdHZCSmhHMnBONVAyazhIMl9PZWV5VzhPSjVkWUNsZnIxZDZQTVZBMmxmZ3FiSGVxSk4wQWc9PQ==
"Imho, for audio, 1D CNN should (at least could) be implemented with kx1 2D kernels on spectrograms, possibly with k covering at least an octave, i.e. a doubling in frequency (so put the y axis in log)",r/machinelearning,Z0FBQUFBQm0yeGI3SVNhOGZxcFFwb2ZEMm5CYWV2SkttTV84cW5KR2ZvX1VJQzM5MGtVVlNlWmU5ZUtWZ1ZKRnp4aXhVSnk4RWhaVjhuOUFISUhsSmt2R2xCQWJVMlBvMUhGcnlXQ3NtTUp4WjByVzBPYnBPTjQ9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3a1V3MEVFTmNOVGJnXzRTMmJzUG03UVkwejgyTWJaWEs0d1h3QXNSelJQU0lHWlczQlFrdERKYi1BTHRqUFdVSFFVNmh2Y0J4Y3Z2WEVSZDJzNkpieWM5d2F3dmliZXlPeGVvUEJ0ZDFzenM9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI3dkdUb3BMbzF6WGNZTWwwNVN5dFdELTFENjJPUmUwb2thZ3ZpTE5FS1JIV24zWk0yeENzeDNJWUxlZUdyejlyVHRlczllSHNhVjZfZUJrbXY1SldXc0tHLWlybDc5ekRBVGF1dURncThoNXM9
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI3TkZENzM1ZDVOYzRUN00zQTdIYXhzNERIeTdmeG5nYVRDRnM5UlJHdE5BWlV6ZTF5U1JkZGp1S2YxOERIbnZycHRHaldsUG5vMlEtU0MtRmdfbDVEanRIUW9fRTF1YTlfRkJqcmw0bGRsTjg9
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI3UVlXZl9nZE5mTHNQLUM4YjlPRXUyQnJwWUd2cml0X3ZvRnYwQjgyelU4QmhuWVp5cmVOUWJiYjdmOXhyVFNaTkE0Z2p5TlBVSVVOdnBwSlBBaU93WXlMNHg0cGxkbnlqQXBqMmxTdVZfVmM9
"This sounds interesting, do you have a strategy for dealing with OOD generalization specifically? Or is OOD evaluation just a usual part of experiments in this field?",r/machinelearning,Z0FBQUFBQm0yeGI3SkpCTlN4RjlOM0NBaFB5OXZUNDBZRlU3TmdXOG96d0VCV0M4N1dKaFRKQlFqRzJVQVVrTTQtX0kyT3FaQzZaOFBnc0RjVkhZUXpvRHAzak92ZHM4a2Z5enlGc1NITmF5blNBZU5mOHZBOXM9
Thanks :),r/machinelearning,Z0FBQUFBQm0yeGI3Z3lnak9JVXBDdG81SUREWE10WWNXYTROMFR2eG4xRVFqbDlHWklBZHFRaWxkSHNRaVRRTi1LbWExLS1kRG1UZmVqMzU5QUhTTVFsbzFadjI2ZmZWZUE9PQ==
Thanks this is great advice!,r/machinelearning,Z0FBQUFBQm0yeGI3bEdvbFhLWGFkWVl6MW9IZHdkSmJTdUJCX0VOVlF4Mm9PWWlpNjNjNmdWMWJJUS1lVEhDUUtRMmhsUDQ1dFdkUDlOdmRqdjJKeXZZV3ZrcXpLLXNoTEE9PQ==
"Thanks, I've just started as a PhD student and I really want to avoid the word generative although it's what I work on. What things should I cover in my elevator pitch",r/machinelearning,Z0FBQUFBQm0yeGI3OUZOM0g2bU5xak5UX1FMdWpLc2NKajNzRVpoMm51TXUybWtURHphUktXd2ZnNGxMeWxTVGRfMk5yYU9xNVc1Q2tOUFpNUlhnZUdPaXRnQ0RYMHhPM1E9PQ==
No!!!!!!!!,r/machinelearning,Z0FBQUFBQm0yeGI3aWtaNmhmQ0x2YlVlVWVycWZZdnhOeTluNGVxTHg2SjhtZV81X1VuOURYX3BrTF9pTFNvQ1B1bjBpRk8wcHhheXo2UUtMaW5hVGsyVGdLcmRnOTBCc25FYWtkWGlLV3k3M2VPWFFKWG5MV1U9
"Wav2vec2 use raw waveform with 1D CNN+transformers, not (log mel) spectrograms, and is pretty strong for a lot of tasks",r/machinelearning,Z0FBQUFBQm0yeGI3M3YyUG54djRSaWIyM3NxTzEyS01Yck9GYTVkTGhNWFIyVEFCYzhKRy1KTnZwSkJrNGotTU01ZUNmTzdKMV9zY3ZxZVRPenBWWDN2aGJMZDB3TDhLdUE9PQ==
"I think it was ""neural networks for machine learning"" course on Coursera. They've took it down a while ago.",r/machinelearning,Z0FBQUFBQm0yeGI3Z2V0bEJ3eGpPaWVVY09NUHUwZkZ1VG5SMWlhY0pTNzZkUno4THNuN0hXMGhodGkxbUpvT0hWWVplaDZtZ1E5MEZOSVdJX1pVamtwT2d5aTY1aDdsdGc9PQ==
You can find the code here: [https://github.com/pritishmishra703/AI-WhatsApp-Clone](https://github.com/pritishmishra703/AI-WhatsApp-Clone),r/machinelearning,Z0FBQUFBQm0yeGI3d09JVnFMVlN5NjQxSFIwbG5KbUw2X21vamc4Qjdac1VTOWt5MkM5WmZCTDJhUHVWTWRvWjc3OU5MZ1JMdm50ZFFJZkxxTHgtbEVlcWZrcm5jU2E5VWc9PQ==
Glad to hear it!,r/machinelearning,Z0FBQUFBQm0yeGI3eDdET3NQbEN6bUlscGQzYXNSMDlGWlQwS21JV3lKNjFwQTAtUEo3eU55b0ozSVdQNWhTcU5BM0Mwa3BHZTJQanp2QzNDMWhrRVI2UnhFUGROMExLT0E9PQ==
"The trick you used is known from other literature, e.g., for obtaining bounds on the log normalisation constant.

The problem is that in principle you can get the mean under control, but the variance of your loss estimator can become unpractically large so that learning rates must be very very small to not get affected by rare extreme outliers.

e.g., lets assume the typical case where you have 99.9% of samples loss is ~0 and the rare 0.1% of the cases has loss 10 and t=1. then the average over the exponentials is ~23 and the variance is ~500k. the optimal v will be ~log(23) which scales the variance down to ~500k/(23**2)~=1000. or a signal to noise ratio of 0.04. For comparison, the standard sample average would have mean ~0.01, variance ~0.1, or a signal to noise ratio of ~1.",r/machinelearning,Z0FBQUFBQm0yeGI3T2V0al9MR3h6UWszQVNULWNPQUxqNnQ4WEV0LW1vaWFaTDFUVEFKWnNfWlhsWkVtLTVHR2FRM0s0b05ObXhIMHktN3JvYmJGMEtJd2tXT2J3SzFVVnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3aEkxWXp5YVZHMUpsVmlIRG5CNmJjUTNoU3BYdWtqc1UxYm5yNGhzUk1OTUU1QmVWV3lVSVlIUHlRYzZ6SHd5N1lxV1Vqa1M1Zms0ZlpzRTAwc3JYamc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI3LVBpeXFUR0dRVGw2anluNjRicFo2czhPQkNaeU1ScWRUdXVKV096QlltY2FyM3pLaTNqY2ZkX1k4djcwd0k3Z09mVHhyN2lMbEZib2plU21tUWU0Z1E9PQ==
"Yes, in this domain specifically you tend to create different cross-validation evaluation pipelines. In cancer research you typically want to predict the response of tumors (characterized by a tensor of gene expression values) to drugs (characterized by their molecular graphs or vectors derived from them). You can then, get your folds in function of the drugs and get one CV pipeline, in function of the tumors and get another... 
Then furthermore, if you are trying to predict response to specific conversations you can evaluate on the highest concentrations for some drugs (checking the extrapolation capabilities of the model), and also doing the same with intermediate concentrations. Also interpolation works. Finally if you want to predict synergies, you can also evaluate on totally unseen drugs or, on unseen pairs, where other pairs for a drug is seen. And to close the message (it got longer than expected), you can create the folds in a way that is even more challenging and realistic, splitting your data over cancer types or drug families. This way you can get estimates of your model on different OOD settings that can reflect what you intend to do with that model.",r/machinelearning,Z0FBQUFBQm0yeGI4QU84cDRMamIwR1RRdWw1Nk9ZZkZ3NEZ2VE5ZWDBzZXhHalV1NFd2QUFod2kyaHU1d2xITGM3Z0ZDUmQza1hkVWJCNWtkTE5LSHdJVWI3SVhOWVZLbmc9PQ==
"Sounds interesting. Can you point me to a paper, or some other resource?",r/machinelearning,Z0FBQUFBQm0yeGI4aUhnS2x1dFVfNnYxSmY2bWJtLU42YW1yaFZUQk9oenRpMjctOV82S3R3cm9iNGJPc2J0RUZXQ01kc0dEZWpJZ1BKVC1CaGJhNVhLVGZzQlphQUxTYUE9PQ==
"Using AI in medicine saves many lives as well. And hopefully one day doctors and nurses will have a more laid back life thanks to robots. And I tell you, man. They need some rest. The medical field is one where they burn you to the ground with work and don't care about your humanity. In the end, you become desensitized to absolutely everything. So go for AI buddy. The human medical field is brutal. But if it calls you, it calls you.",r/machinelearning,Z0FBQUFBQm0yeGI4amhYLThuMU1LTHozaDd2bzdCUVhxcG1vU3RqOHUzb09xejRsazlzQkVMTjdKYXlRM25KY3czZ3l2djlxZ1FVaHgtY1c0THpMSzI5WUsxSGZVZ29YWnc9PQ==
Oh I think it first might have came from Eleuther AI's GPT Neo X,r/machinelearning,Z0FBQUFBQm0yeGI4OWppVXpxVGtYZU9ueHJLVHRMYTRra0pwRDYyWFFpQ2YxRG55QjRabmNhcGVhNTdPRk5TQXRVM2ZuLW1WbVZwNU1lbzJEOEcwZWVoZm1kRFRzSmcyNUE9PQ==
I guess LLM's massive training data might itself be the regularizer?,r/machinelearning,Z0FBQUFBQm0yeGI4b3B4encxQ1VUTXBPOG5FVkZKd3dHb01wZlZ1bVg0N3NDNGlCSDJWVHpFVkI3Vm1WUUkyUTdYZ2VLR2tPRkhlaXJkdWJFRmwwRGRyVThrdkJXeWR0MGc9PQ==
"A medical degree might be something you don't want. Med school is not only about imparting medical knowledge but also involves a lot of other work, handling of patients, having to learn things very thoroughly because you are expected to treat people and be responsible for their lives in times of stress etc. If you just want to get deeper knowledge about medicine/human body, to use it together with Ai maybe consider other degrees.",r/machinelearning,Z0FBQUFBQm0yeGI4ZlNDMXp5TDA3MzJZWkxGbXU1ZXdpU0RZbTViSm5wbTdhbm1kV2ROVHVmck9zaG9pbXNrRWNoWE5RZWpNaWpQX29GRHdtYnRoSjdkZkFDSmw4T1lsSVE9PQ==
"Post career questions in the bi-weekly ""Simple Questions Thread"", /r/MLQuestions or career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI4Mk5zOVlnX3UyMk5xV2Zfc2xianRESG5pdUo4cmE1QmxvQU1TQXpKZnM3OXhkaWE1RlhxOFpIeGl5SlVoU3BhVnJzSTc3dnh6TzAwNm5qelBNU0phajBwc0FtOGF3X3pBQldyVWNiVXRlLVU9
"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/rasbt/LLMs-from-scratch/main?filepath=ch07%2F01_main-chapter-code%2Fch07.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",r/machinelearning,Z0FBQUFBQm0yeGI4dXZSZ0NESzF5YzFDaTFuY3FPTmEzemFLbGZNcWhCUERJNUxxakNMaUptTXlqQWtueF9jMjNWVElBc1BpcGMzUVZqM3d0SENPOU55VTE0ZEJtTlIxZ0E9PQ==
What other representations can be used so that we can leverage 2d CNNs instead of 1D CNNs in case of 1D signals (or signals where phase is important)?,r/machinelearning,Z0FBQUFBQm0yeGI4UGJmZ3BEWDR2Q0V1aHpKZXpLNjlBU05KamhfdjRGcVd3RlZVOG92Z2hOSXNyNWxxeV9FbmNCTWhfS0tERlNoTnA5QmpOUlAzcl9VYjhvSEhfLXpiUnc9PQ==
"You could check whether there's a related MICCAI workshop, or look at workshops at the big ML conferences.

Otherwise, unless there's a good relevant conference in your field, submitting to a journal or just putting it on arxiv would be your options.",r/machinelearning,Z0FBQUFBQm0yeGI4Y0pfclAyRWVpbmtCeml1U2Ntd1IyNDdxLU5tTVlkb0dpckNtaG50NWZHVXlYVWtySE9rUVBYQ20yYUVYVHhZSDdReGZrQVdnM1FLVlYta3VTaHlSZlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4Q3VlWUN0Ul9hbEV6amZNbnd0RGctR3hXVUhRNW1VY3c1TGE5TnlHOFNWQVhBRHowNVF5YWVRSEU3d3JJdzBYRDdyaVRUeXVMVGFxQWl6RlRaUkZlSGc9PQ==
"I think the term you're interested in is Bioinformatics which has subfields like sequence analysis, pathology/radiology image analysis, protein engineering, etc.",r/machinelearning,Z0FBQUFBQm0yeGI4clRlcTlWdzRJSW5IX0N2eHJPa0I0Wm1SMUlIVm1OWEU1Q2tiUWlxOExaaVE2RUdSMUxsT1FIaVphZ3Bmek5BenhXakU2ZWlwcEJ4OXAwRGEtUGpfdkE9PQ==
Will arxiv be just fine?,r/machinelearning,Z0FBQUFBQm0yeGI4UHBjX3BIOXVnMHpRMDF6eWhYeWNTS0tLQlcwU015RnlTZ0VMN1NyTTJwT0pHM3BFald5aWlrNHVNdnFLUUxGQkFTMXB6clQ4RlZSVHNOR0Q0TXFwVmc9PQ==
"Exactly improvements in OOD generalization are done by either changing what ""OOD"" is, or by intentionally adding bias. OOD generalization just can't be solved in a broad way (no free lunch).",r/machinelearning,Z0FBQUFBQm0yeGI4VE5VU2FRdHFBNUdwbVBVZkhYNGZQWVgtaXZVSnpJdW12YmM0cDdIbVk2TG9yaFZlWTF2STVhbS1ZU3o1RHBkck1iSzN2SWdxRFgyaWZCV2htLW0wSmc9PQ==
"If you have enough data, and normalize it well, you can potentially go in with raw waveforms as floats.    


Suggestions for other encodings depends on domain knowledge about the problem you are solving.",r/machinelearning,Z0FBQUFBQm0yeGI4YUF3OHZmZldlWGdLMGM0ejV2eVFYVlBiNFZrNFBCbEVXTjZvclhjUGd4aTdMemZZZUFuQktIT0tjcXh0ZGpya1BSRlh3S3lMR3NOU1hLZDc4UW5aVmc9PQ==
🤨,r/machinelearning,Z0FBQUFBQm0yeGI4NG9CcEY5bzJvLWVMTzZkNXhZUF91emlhZkFTSlZFMmo1RjI3THlkM0lEZjdFa0VMemhaR2VLRmJVS25SbFpCREFyN0k4ckl6c0tMcDVDVnExcG5jTkE9PQ==
I was thinking of robots (either robot poses in se3 or joint angles),r/machinelearning,Z0FBQUFBQm0yeGI4TkJ6WVF5TG9OT1RrTW8teEhwNjQ4VjZrVFJjRHI3NkFRTGM3cldmZmtqWk9qZzZGWHFLR1ZSYlFnaUtYNjlaZGI4TXljSEZfYlhvdTN5b0JxalQzb0E9PQ==
"sure. this paper uses the same approach in equation (6) and comments on the high variance on the next page, left side, top.

http://proceedings.mlr.press/v97/poole19a/poole19a.pdf",r/machinelearning,Z0FBQUFBQm0yeGI4UXZCTkxjeVc2QnN4dmNTbmliSjgyLU5GZ0dRUzNHUFNiMi1nY2NEZDE0azc5QnRnQTlLVEhVamVhQkxzbDJkWG5ZRXMyY0lwODAwM0xXcWpsNDA1WWc9PQ==
Nice! (up to a change of variables :)),r/machinelearning,Z0FBQUFBQm0yeGI4Qnd3elVaVFI4LVVfYTdxSkhzWHJETXNJUFNCd3duOHljQmFzTVJoRDh3Y01vN3J1Q0MzQkgzOGdMTHBzcjVhXzUxVVk3ZWF2X1E1aFlNZm83amFkbVE9PQ==
I like this response. What I have seen however at my place is it comes down to who has the PHD and can make power points. Drinking with the managers amd talking hockey / bikes  also seems to be a major factor. Real talent has little effect. Delivering functional software has little effect.,r/machinelearning,Z0FBQUFBQm0yeGI4SkZHME1rUkJjbmh0cEZYRElqd0ExMFdobERHNkQ3QjdBT2hyaTB4MmZ1ZmZvWWxobDFpUGFlbzV5M3RJc2Y2T21FVERsY1paNUp4MTk4bExKcGFKVUFwNFYxUUFTSDMxdUxtTkw2azBwQVk9
"We just ditched AWS, switched to on-prem and ditched a lot of the amateur hour Jupyter notebooks. Far better to train with proper python code.",r/machinelearning,Z0FBQUFBQm0yeGI4bkhCdmxEaTR5VzdsWkliR3FpMkJERWhsd1RCS1pDQk5JdUtMNVAwNVU2ZzZ3Qzd5N2JEZGp0VVhYU1prc1pWWExHYXAyT2gtbjhWVmVQU2Z4TWhQbFE9PQ==
Aged like milk,r/machinelearning,Z0FBQUFBQm0yeGI4MzNzV0liWEw0eWZRRjBYTFBYNWI1RVk2dTIyS1VPZXBIVGN1UV9aZmZlNDZNTTdrTWNtaWxKd2w1ZjR3c2JRbTJjOHlIZGxpSDc2d2RVa3J6MEVOUFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4cXpXbnBUcVNERDN3LXdwU0ZlTF9QcHptZTZqZGJjdGVtUzNiRDRPS3UwOGVtQXlqOUNoemwtbDlDZkFYNk5qRWNPU25iUlBobzBuek9KUjdiRS1xMlE9PQ==
"how? what new groundbreaking chatbot has just been released that makes what I said wrong?

Definitely not GPT 4o, that's for damn sure lmfao

no, really, I am curious, what new LLM makes you say that?",r/machinelearning,Z0FBQUFBQm0yeGI4UXFVNU41UTVYczJYWEw4WFU4M1hFczluTmltUVBlb1hYZVFBTjdpMWQxN09LdnVkalVSSGFSLXo5ci1oc2t5V0l4Sm04TzNfeTZMbjY0LVh6SGZIeVE9PQ==
Can you elaborate? It'd be nice to get an understanding of the pipeline.,r/machinelearning,Z0FBQUFBQm0yeGI4bGc5bmRKYnQ4b190Y0JubUJzX0RvRHlqVzllZ2l5dXpkbGF2TXFWYXpqWlhKT3QwUHBTVk4wVDV0SE4wVnhOYXVkR2R4dTNuczAtcF80SFdTR2VjdUE9PQ==
how about just read the damn search result yourself rather than reading some bot output?,r/machinelearning,Z0FBQUFBQm0yeGI4Y0R2NzhnOVE0aGpKNmpwRTh2QzFuOVZHWXdOd1FIc0t2UHNEVVFSRWhfcnNUem9QVkdqSlkxMFBHR2tNQmZpUjZ6WlB4X3J5am9SaG5BMGprSXRZRFE9PQ==
"Depends on which part of the pipeline, for model training we mostly train using on-prem Linux boxes, no real orchestration on those since we find most of the orchestration tools kind of get in the way for model training. Then for actual running of models in production we basically use C++ code for model runners in a Kubernetes environment. We've tried MLFlow and found it kind of gets in the way and a lot of the computer vision model training libraries don't really work with MLflow properly for stuff like Multi-node training without major rewrites. Though keep in mind when we're doing model training we're trying to scrape every last bit of performance from that machine.

The way I work, I will personally strip everything off the machine that even hampers performance by adding even 1-3% to overhead.",r/machinelearning,Z0FBQUFBQm0yeGI4NDlNRFYycUVHOG9kMzZTY0djOFk0RjVrNk5jc2NZb2FFTVI3UU05c0pSR3lrRVVJQ1ZfQjN6RF82cVNEYnpQenBGbV9YQ3BIOWZGR2FGVTdGYXBsWGc9PQ==
"Can you elaborate... your post history makes me think you could help me understand. Assuming the face was because the post seemed a bit ""bot like"", which I'm not, I'm the damn rat king.",r/machinelearning,Z0FBQUFBQm0yeGI4WmhVazd3R0ZrQW9NWGJZdWM3VWpPZkVrV1M4NTVNQTBsc3VGdV9KckRSSmNxN2N5VVBqTjhZSjhMamdXTXZPSEY1U1JGd1dZNUlXQWVMYzJkWHFCTkE9PQ==
"In the reference paper, the datasets have different underlying distributions. I am just wondering, is that not what the ""No free lunch theorem for Optimization"" says, right? So, we can not expect an optimization algorithm that performs well on one task might not work well on the other tasks (though they might minimize the same cost function)",r/machinelearning,Z0FBQUFBQm0yeGI4MUZRSlVPbmNPTWRqV0JPN2pHOEtqSWZDOUFHTXE3RmpKOEZuU2hGN3k0OW84VU5YU3daX043S0JwN0xrSVZHYlFIMnpYdEpfT2tLSHp5eUgwMkFMcFE9PQ==
"I dunno, I'm sorry. That's just the face I made when I read it 😅😅",r/machinelearning,Z0FBQUFBQm0yeGI4Y1pIN0ptRE5nb216WU1DZ2Z3Uk5kdTlwekVKWmROejBJbkJhRmFCSlRjM1E3SDQxUl9zLUs3QjdERjBKQnh4dWwteWc5aVhvZ1B0X0JRRXRueVZmcHc9PQ==
"I've developed a fairly large set of open source tools that can help support computer vision on geospatial and regular simple RGB data.

The basic entry points to my toolchain is kwcoco: which is just a extension of the MSCoco format, so it can handle regular images just fine, but I can also handle multiband geospatial images. You can also handle multi-temporal variance of either of the previous.

https://www.kitware.com/introducing-kwcoco/

There's a lot of other layers in my stack, but at the top of it is a tool called GEOWatch https://pypi.org/project/geowatch/ which brings everything together in a pytorch training, prediction, and evaluation system.

My hope is that these tools make working with these more nuanced vision problems less sucky.",r/machinelearning,Z0FBQUFBQm0yeGI4VlRNdEZFRUk0RGl4a0paamtHclNmM1MxNTJvbW4xdlBvTVpQUFdubk95azNhV24xakY3clBVQTBZNDdRX0N3cXZsNE1Wd1RTWkpXaEZBY2hNeVh1Vmc9PQ==
"Maybe if more vision researcher's got good at software development, this would be less of a problem. 😜",r/machinelearning,Z0FBQUFBQm0yeGI4SnJBaktoOVFKM2dvenRTQkhiZUhhTXo4R21ONk1oSTljQ2M5RldJMjNJWk81dGFna19IRi1URmRMVUlMMU4zR3FRejRUdWpacGNxTnNOeDJ6QllOUXc9PQ==
"It's easy to construct functions that cannot possibly be generalized OOD. 

For example f(x) = 0 for x < 1000 and 1 for x > 1000. No amount of samples from < 1000 can allow you to generalize to x > 1000.",r/machinelearning,Z0FBQUFBQm0yeGI4TzRWYnpUZktNN05taTZMYjM5UzFIdG1TM01XdTJHaFBYQk9BNV84TkVyWGxYMVQxb0VFVDdVSXV2eWh4N0lSNTViTWVvMUxZempYOFpjX2txZGRaWHhRNXFOSEswc0diNmxndHRBSHBNN009
So you just use venv now?,r/machinelearning,Z0FBQUFBQm0yeGI4SFVXQ2ZHN1plMEZVaVI1R2JFOUJGZEtLbDBzMTJ4R0F0bEJpOEhUeHIxZ256aERmdGdfdEh2Qm4wbzFLM0NGRFZJeDlwMW1lZ2VXTjhNVHZGNWEyX1dUcHYxZXJsejhlX2EwWTJvT3JsYmM9
"You probably don't want to work directly with angles. Maybe try [sin(theta), cos(theta)] as an input encoding. Or quaternions in higher dimensions.

In general, there is no substitute for thinking hard about your problem and considering how to represent it in a consistent and parsimonious way.",r/machinelearning,Z0FBQUFBQm0yeGI4MUpRVjVnenVLVTQtcnJleTBRWkxEa254NkVfa2g2ZVFldDNieDdLYmlBVkt6NlBGdzYtdmZ3OF8tZ0ZvWU5TR0NOWDV1M3c1ZVhwUF9qQTFDZ2xNSXc9PQ==
"Sorry, what’s an FTAN?",r/machinelearning,Z0FBQUFBQm0yeGI4NDJYdjBrUzdaUDlEN0MyUU5kdjd4aXdDMmFEdWRacmM3WnFsNXR1d2hNcEo0OTVtY0JjWUJDclBqWWdCSjVnajluZzFHZFVEUVoyaVEyYkstcm1RX0E9PQ==
"I’ve been working with delta angles(in case I wanted to use joint angles). There are some interesting ways to represent rotations (but they tend to be unsatisfactory). 

Echoing OP, I see a significant difference between using ‘conv1d’ and ‘conv2d’ which makes me think representing waveforms as high dimensional signals gives better results: maybe something like spectrograms (mostly comes from my experiments with diffusion models which work very well when the number of input channels is 128/256 instead of 3). Don’t have a good mental model as to why that’s the case yet.",r/machinelearning,Z0FBQUFBQm0yeGI4MVNqRWl3VExCUmo1RWV3VWhvQVlGVmJBQXdjU2RHSlRJX29zNHltRHJKOExwSnRLQWc2c0loUEkxeDZSdVhtRXN0N2V1dTFxeUpxSjdOWmNrOUpaRVE9PQ==
"I like how one of the first steps in ""building a large language model from scratch"" is called ""building an llm""",r/machinelearning,Z0FBQUFBQm0yeGI4VE53UWhRMkFabWxteHRRUGdjNjNkM3ZKeVpwY0NCNnVuemJRRTd5aHRKMGhfd01RYVlBVGZOdWZLa1F2OFZxd0ZybXlXUS1XcTVJajNUazJCS1p5NWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4cnVfZHpiU2Z1azV4WTlBalF2aXVVNUNiR0dHZXNNOVhuemZJT3VSOF83UTJ0MGoyY1hpTGZ5Nl92RU5tM09qaGM3VGJlYnBXSlpocVoycDljOTVmdUE9PQ==
"Its similar to the phrase you have a hammer and searching for nails. Understanding business problem, then the data generation process, the data itself is 70 percent effort. Modeling, experimenting, deploying etc comes layer.",r/machinelearning,Z0FBQUFBQm0yeGI4NW5SOEF4WUVtVFFTVHBqQkJlY0kyOTNuQXh1aTQ4WGFyejlwZzFYMEdjam14ZWRpa3RKUTUzNXFrbHJyNTJTbVlPcEdXRXZvWjU5S2dGcmg3T2xwNDRfYVo1djBPWFJNX3JNRTE2VWFZOFk9
That's not true. A stationary Gaussian process with a mean function set to 1 would generalize but requires incorporating this knowledge into the model (but even then the optimized lengthscale would be very bad),r/machinelearning,Z0FBQUFBQm0yeGI4U2tqdWU3STJfZm9zSjdzMU1WZWQ1WVFwS1pqVTlod0tZVE5RWUhLMVBkTTZOc2ZWbkpFblA5TlZYSHE2WjdQNV9BV0JLYzQ2M05BSmxYRHhKWk9Eanc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4dzEwb19LZjJITHlabld0YlpWekdvamdrU2VFUXNBVGExQ0w1ckNwZ1pxYThhN0p1Ul9MNzZPT3ZDTFhPVG1tVDlXc3ItakFnZ2ZBZ1dnTHpJd18wTkE9PQ==
"I'm not sure such extremely concentrated loss distribution is that typical. But a more important question is, if we indeed encounter such variation, does uniform sampling even make sense?",r/machinelearning,Z0FBQUFBQm0yeGI4R1R1NW42OVA2VTl5Sk9od2t4VkJMS0dlb0ZrdEFTSHUzaVhQUXdraHZxM2UwTnpWSUtRdWg5dEdQckt2ZGh4TXZBekZ5bGVYZFM4NVRlb1hGUm9BMlAzSE9DMDl4V0ZMMU5vc0JzbWoyUTQ9
"You have no way of knowing that this is the data generating process, all you have is a bunch of samples where f(x)=0. You have never seen it return a 1. ",r/machinelearning,Z0FBQUFBQm0yeGI4V0xLQ2lMbmV4UTRJZ0pJdEh1bUFNanotdUFhVUVqckZCd1h3d19JNUZSRUdXUnNuSjFQYjJqY2xLR0xwWC1uNUp6d0V2OE1ncjBMbjVrWTUxVGRyQlBnRVNleThCTXhlZnBxQlM1SHNjSG89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4T3Q1SVRmMFhiUXlOT2piQjA2U016anVodDJlMlNTX19sdkZNRHBpMUVuRnhZVHhsOVJzUDh1X1ZFbmRpVmx0bzhrcjhoWGJHSklWXzJmcjc1Z1I0Z3c9PQ==
"Phase doesn't matter much, at worst it's 2 milliseconds off at 440hz. The sounds are generally far apart in Freq so have little phase interference FX. You can see incredible phase info on a 2000 band narrow filter spectrograph.",r/machinelearning,Z0FBQUFBQm0yeGI4eGdhaHNfU2pINDJJdWhzUXdVdTBoZm5heTY2S2Q2RjNSQXJfblpnVW9GTjdvZlVHSUxwUFpWMVBTRllOOWFvenUtRVBLdEF3YnN0LXFDNi1kNm9DekE9PQ==
"Except the fact that progress in LLMs took a jump far larger than any of the transportation speed advances. To be fair, there isn’t really anything actually analogous to LLMs so it’s not like you had a good alternative haha.",r/machinelearning,Z0FBQUFBQm0yeGI4bVZuUkRBMi1COHdmek9waWc3alF0dmlxVEhyZHBTS29BMVplOVNCb3V3bHVDOE1yRTlBcXpuejlTSmppVFltdzhLNUxFQVMtbURhMHFCd2dnbGV4NDZURU5nT25vRDFGYm0wdkt2X1h3V0E9
"You can’t really say any of these things with confidence. We don’t even know how humans reason. You can’t possibly know whether LLMs are doing the same thing. 

These are the kinds of takes that come from people who don’t realize that there’s already an entire science of intelligence that’s been going strong for over 100 years. It’s like they think a bit of math and computer science gets you all you need to know about human intelligence LOL",r/machinelearning,Z0FBQUFBQm0yeGI4Mlo1VlB0cFF4eDdpVy16SjRHblFpTEZFMHFmTmFFLWJBengwTF93Y2l6dFJSeE5PX1dRVC1rQV9sZW9oTmFsVm5Xbl9tZlV6T2VwbncwVG5hN0hwM2FtTUI4S3dqa0ZDd0VzeVF4MmZyQlk9
"You can always generalize by adding domain knowledge, this is how day-to-day machine learning is done. You design features and model properties that you know will capture the underlying process (in your case, a boundary condition) 

You could say the same thing about fitting sin(x). You can argue that the model has no way of knowing the solution is periodic, but if I fit the model using [sin(x), cos(x), sin(2x), ...] features, I will generalize perfectly",r/machinelearning,Z0FBQUFBQm0yeGI4VTRrcEVkMkQtZzVDeDBja2ZTT0V1T09CeERkTUhRQjVBeXdNcmdNX0RDd09LeUtjd1ZLeGhXdVMtYXhXdkZmZ3ItOUw2ZnU2VkFlUzY1SE9YZGpqWVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4SXdaRU5NUVRDSE8yYUNnc1VCRUhqXy1ZaVJJRWFsWWUydHVtbnRHV1k4S1dsWEZwdjJaZnBGZmdwRnV6QlVjUUJKX3NiM3NFd0E4TzZWd21sVzZnMXc9PQ==
"Then you are no longer generalizing OOD or arguably doing machine learning at all. 

*You* - the human - have figured out how the function behaves > 1000 (either by sampling it or by analyzing its internal structure) and have handed that solution to the computer.",r/machinelearning,Z0FBQUFBQm0yeGI4c1ZrajFxQlZzNUhNUUNINGoxeHNKbWIta1R5RlNjVkZxRzNMVUZnc3h5TzlzMHBmLTRoVl93enFwRC1adzl5d0tFd2pZOGo1LUJFOF9FQlJGdHpKXzFycHNLV1JjUWdzTFJWU2g1SXdyZlU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4bW03SVJnYkVzdmdMNGlFYkFFelNTVzI4VGZ4YmJtR2dXVHVQcFg5Tm9Sa1U5V3FBZ3NqalpTcHowdzdJdTg1UER0NTdzOE1aMWtyZUtjWmVrRnlKclE9PQ==
"wouldn't [TOVA](https://arxiv.org/pdf/2401.06104) give better performance in [Based](https://arxiv.org/pdf/2402.18668) than sliding window, especially for long contexts? if i understood correctly other efficient alternatives to attention struggle to recall details like names or prompt format and Based is supposed to fix this, and TOVA would help paying attention not to the recent tokens but to the most important",r/machinelearning,Z0FBQUFBQm0yeGI4eGNxbUVzQ2poLU9Zc3BzSndiYlNzUGpNNU14UGlZTHFlTjhpb3NBVzRUNFhrRjhmZzdNanNEVlhfaFk3UjJIRGFmQ3Q3TmtKS3lib1dLVzlVTUdvM0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4SHh4X18tenV6cldNbUZ2NzUxanRMVTFrQWx4UWptQ01ZbkgxVWo1TWF1aTZyVk1MZHpEYWp5cTN1T2dBSmNHUzNBcThzZDhJa0Y0Tm12MTA4Sk53TFE9PQ==
"Thanks, this is nice to hear, I spent a lot of time thinking about the right wording and sequencing",r/machinelearning,Z0FBQUFBQm0yeGI4OWV0NC1BSllJbUtURTFJb3QwM0lPZ09SdUIyMGJ1U29lWmphZV9VWWt4WWM0SUVtMXN0RW51czhSQV9EaUpCMlBMNWNNdFVOdlhBMTRORU5FX2h1YkE9PQ==
"is it possible for an llm to adjust its own weights on the fly based on my replies? afaik there are several RL techniques but can they adjust weights *on the fly* based *only on replies*, like trying to act more like when i praise it and less like when i scold it?",r/machinelearning,Z0FBQUFBQm0yeGI4LXMwajN5ZTVHdUtDSXViUjhsSHdZSTdXcnFZV05IOWJQVUx6RTByZjVrY1FrZVdDYkF3cUNyeTdPS1lfOWFFNGR2YWRNN0VkT3VPMEd5NHA2dUhidEE9PQ==
"No, Grad CAM is not a remotely good idea. But Global Max Pooling CAM (sometimes GMP-CAM) can be!",r/machinelearning,Z0FBQUFBQm0yeGI4MHNudXZKSWlLV2xlVVB1X0RYS2EwWUo2ZGpTaG1odWZPcWhtRHBNa0drdU1LSWx1YjFWVE9ZVG1ydzk5R1RCUmdvYlU4M3BNbnVEODdXSHFOdjhVTlE9PQ==
I thought I was still on the league of legends subreddit when I saw the title lol,r/machinelearning,Z0FBQUFBQm0yeGI4RWxIXzFvY0QyQlNPMXJzZHZLeVJuN2dZY2pFc2NCNGdxTmVkRm1DNlVSVWpBcWtEZ21IdU02WDUxNnVUMC03ekx0Njl0S1lOb2F1V2pnSTBzQlBlYUE9PQ==
"Check out 'Deep Learning' by Goodfellow, Bengio, and Courville. Classic!",r/machinelearning,Z0FBQUFBQm0yeGI4dnJHbktDVHUxb2hjdHdvVm54cGFjWUwzX3dhR21VNlp4ckhYTUhaV184WDV3UXpjWmJhNzJzOGZGWkladm1OcXJqQVN0UU5VXzdvREZXMVpPSG94U01WVDNmamEycy0xMTZxSzkzRGNHeUE9
Good luck to those still waiting for their review results!,r/machinelearning,Z0FBQUFBQm0yeGI4aUcweU1tOFdYaDdxZ1BKWEpCbjhkSE90cmlXNTBHbmZpc3lhRFNSUG1OUldTeXppMjh0clhEMU9uUUhyTlFvRG5LRGJVNG9rczMwOUtRZU96eGZpSTRPVGRXU1l5V094RF9MMWNNVVFkYk09
It seems a little outdated as  it came out in 2017. Any reason why you rank it so highly.,r/machinelearning,Z0FBQUFBQm0yeGI4NE82bmU0YzQySmJYYlZtVjVYcE11V2pQSFQ2MEROaDRaU3NiTTJTNmFNdV9ESEhlNll4OVhYQmt0VmVCdUVhVlExdGc0azItU0thX1dROGJvTUh0TEctaDFaTHYwYzRZY0ZJeUFsdTVsdnM9
"Need help, where should I  put ""General Summary for AC and All Reviewers""?",r/machinelearning,Z0FBQUFBQm0yeGI4VGVGUmVGNW51YVlRM2ZoMkkxbTg0SkhzYmRlNmlkOXpMS0MzSmlBM1hPQS1ncDVnYXpSUERIdElsTHU5NldiZHhxbUlQckVmSWxXZHNBUzZVWnpiYnc9PQ==
Its the best textbook for deep learning basics. its free at [deeplearningbook.org](http://deeplearningbook.org),r/machinelearning,Z0FBQUFBQm0yeGI4VkFFTThvQjNQNDh6ME9SYVlrWXNkQnJmZ0VWMVJqZUZRSXdlSjYxNkxjb0J5c3dNcDZ5UjAxQjRQYS12aUl6S0lZM3drRVprRHp5VzBhLXN3bEJIOUFxMzR2dlRDVHZmUDZtSU16akNaYmc9
"this is what you encounter often close to the optimum. in many cases these could be labeling errors, but also points in a severely undersampled region of the input space. 

This happens _very_ often, though when you learn something more complicated, e.g., not only a mean but also a variance parameter, in which case you can get extremely high spikes.",r/machinelearning,Z0FBQUFBQm0yeGI4UTRNZVBnb2R5VVNKUEs1UUI5ZTJ5elRqcGpnM1NiczBrMlI5MFVsY2hNZG5MaWRfc3pYTWdsNnkxa0pQZUpBbmxQRVdVM29YSkJIYkY1NVJJdzNRVlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4M3lUMmhsS3Z5SGNqalRsQlFjeUlWUDVmaWV0b0I0aUp0ZzJBR1BNUFlJbXAxTDNLMVZHQ0RHWVNYS0NHVDNrNEprU0VWS2tRSVRSQjdiS0ZvM2s5VVE9PQ==
"There’s a sycl programming model that works on multiple hardware stacks including intel. The programming model is decent , maybe somewhat similar to CUDA in the whole grid / block / warp idea. But it works with modern c++ features like lambda functions and references instead of very raw-pointer-chasing c focused CUDA . Offers a slightly different memory management model too. Intel has been pushing it heavily with their oneAPI

Now for the sad part : it hasn’t taken off ! I hear people in academia who have access to heterogeneous clusters and don’t want vendor lock-in in talk about it . But in commercial world, no takers despite it being around for a while 😏

At one point of time I was entertaining the idea of learning sycl instead of CUDA so that I could work with more modern features of cpp and possibly use multiple GPU models.  But later I realised CUDA is just way too dominant. 

And in a sense market is rewarding Nvidia for thinking almost 20 years ahead. The professor who worked on early CUDA was hired away from academia by Nvidia in 2004! 

George Hotz (of tinygrad) has done a decent dissection of this problem : chip making companies took the wrong approach to the problem. They should’ve got from designing good software stack to hardware. ",r/machinelearning,Z0FBQUFBQm0yeGI4YkJQd1YwWmhYaG96anRUbHd4WmRSNUZ5SnRId2pOVkdFdm5ycEFtb3VNN1drS2FzNjlDZEh1MDNBZ0stSzk1eW5IZ1lXQjIyRlNqWDA3cEdialpzbGc9PQ==
"Good luck with the dice, my friend :)",r/machinelearning,Z0FBQUFBQm0yeGI4Vll0MlpGbzJlTU1Kb3R4OEVXZHlCTUtaZHRDZEFSS093Umg3aHVWTGpxMEUtUU1RQVFVU2dEZXBjQXVaVkhpS0xYWWlTOWZrVm9MeXhFeWhQUnZjbzBjUUppNDFTYWJlNWcxZUY3eEQtN3c9
"Wrong subreddit.

Try r/LocalLLaMA , r/llmdevs",r/machinelearning,Z0FBQUFBQm0yeGI4RTBWRTlCdGRoZEc5V1UwWEpWS3lGeVdlM2dmQ015TEV5UDFXaklFM2xldzFzb3BWSnhTaE1vWmZRanEzM2NVY1FDdlh1ZkgxelJqVWhUOU85V0ZlUVJnWDhmaC1YTUtGN0pVcTd6QUhHaVE9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI4dTJCY295NDRxdExpM05FQmF0TU9TelNWTEh1ejJScXNQbDJRWEI2VVliRmxucXlWS1Z3ajd2UU1kOE9oWUFZOUdRaFhLZENrRExBNHBQZkdoT2tnX3JFazNmZUtBRzhTYkhyWG10S0NQSUU9
"In addition, you can use ArcFace if you do want to train your model in a specific number of classes, for an accurate classification.

From my experience, I used both methods in a single FaceID application. It was ArcFace for the set of known faces, and the embeddings to register new faces in real time, also registered for a posterior training.",r/machinelearning,Z0FBQUFBQm0yeGI4d3BWZFRhbkdzLTdjVHdJMURfcGN0VVRMUFY4WDZPNkRZTDVOQWY0SEhhU0dWVGJpRzRrVEJYQmgteTZHeXM3b3NMVzROdkZyVTJmMm9pOENKZjlPR3c9PQ==
"As an extra, in my case I used a MobileFaceNet + ArcFace. This gives you a smaller model that can be used for inference in real time.",r/machinelearning,Z0FBQUFBQm0yeGI4M2phQjhmZm1SMnNYd2NUWHphZ1BwaHlIRkVQZ2R1N2lhckFCSTI1RjBWUmZMWkhuX25QVEFvcUN4aVFCWDFJNEs2UWZkeG4xeUo2dnhSNlRxZ0l5RXc9PQ==
😂,r/machinelearning,Z0FBQUFBQm0yeGI4aFJJTjVCNHB6QS0wenI1alB2MDBLa3BlLWo2eWdac2o3OWk5SGJ1ZEFwXzNyTDZEWGxBUTd3VHZSSnhBZ0FCUzdQd1dSMGN2SHVRRFRlblRmYkNrMUYxTVFyUmR3bDk0N0w2bmYtWUoteVk9
"Frequency-time analysis. Basically you have a moving cosine-like window you apply to the timeseries signal, then apply an FFT.",r/machinelearning,Z0FBQUFBQm0yeGI4MnpvV3BqRWw0X3pUS0w3Ymc4cV94VGc2U0hwV3BVWE9vaE5FQ3RhaEpxWUtRSkZPWkZtdk5BbEd0eGRCcGRBWVhpR1U5bXZ5ekJFaWNkSUpVbVk2NFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4LTVkeHpZWkthT0NVYWlPUlJMLWlJQlUxLU14Y0lUVHZyemY0TEp4RTUxYjhmMEw2Tnk0RU9WY19HdHRsZXRzeTJCZjl4OEFmWFhLRE5qSE52clJ6a3c9PQ==
"I work in OOD generalization (and have published recently in ICLR, CVPR, etc). Its a bit hard to publish in this topic nowadays because most reviewers are idiots. Almost everyone (in AI/ML) thinks that they are competent enough to comment on OOD papers when they are not (it requires significant domain specific mathematical knowledge), so we get idiots giving idiotic comments confidently.",r/machinelearning,Z0FBQUFBQm0yeGI4RHJwTnNrX3VHeFdqZ3IwOFV5VlFzeURocGQtQlhLU3FiY0lqaVR0OXpHaExYUTY1OVF2bkd6VlhnN2JWTk5wYVE5TXg4cTNoSndtWmZMMlJZS1lUYVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4MWY5NUFQMVgtMS1PWWRmTXp0eEVLV1cyZjZsaFUyOHJsTDNnNEEwYlExdnhqaVlDZVBNaF9DWXBTYWZUcXJicWFvWkRZRC03ckdDMVVMX1dpWEZLcEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4Wk05anlOejI3dzNBUUpfQVlaNFFxMDVKYTFEUG1JaU5fWk1UOHNoQkFnWnBaTy1XYWpMbUM3bmNaTkR3bGwtaS11RmZTSldMUXVuOG5weDNoclI0OEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4a2xzcHdVano3YTVCUDlWalJXY2FmaFphcVBVZEVISWtwZkFkeU5HY3NtY1VRSWNoR25aSVVQQWcwV2wyUlcxMVBmRGdmdFljYkcwRzItemwyS2VLOHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4T0RVaVNZVmlmWDZ4bkFFSnUzNjhZUU8xaGN1TmgzcDFBMUZFZEhnd1o1WE12cFdzY2tYc2VDSTg0QUZTdmhhUkZfZ2F4UkF4a0JLUmJyNE5yV3lJWVE9PQ==
"> I have pretty large dataset of those images and manually crop them is very ineffective and stupid because no one will crop them in prod. 

Well, it has to be addressed at inference. For example, use SAHI:

https://github.com/obss/sahi",r/machinelearning,Z0FBQUFBQm0yeGI4MXNGWVg2TFVfT0lKcDNmNkVsMlc5eFpUbzUwMUtITnVJUmlsYUNoTkNQNkd6emVlUXNCMDBqVUR6dVJSSkUwcTNlX1VMOVJ4N193THR6MHU0WEg3T1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4aFlfQVBUNUJxbUNUSVpVM194RmpYajVQQVNyczBDRGRhM3VKSzJCT0hJNXhEYS1wUXpLNHVqaGhoZzlSYU1YaVcyLTdsUnlNQzVDVzRRczVyZ2JjS2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4U3dsSUpqLTQ0cEZxektWSnl0OWZqUzN5b2JzQWpTUDQ2aXdObTA2Y2Y2aFR2UFd3dEthejVjZENOdFZ2eUd4OWplb3BjYUlBTFF5dUo3bEtoSFYxM2c9PQ==
Why don’t you do the needful and post the salary and company?,r/machinelearning,Z0FBQUFBQm0yeGI4dm43UGFNdVFUUHFFay1jSG92YV9Gcl8yQlllZTJzaVVWNk9ZZEdjV0I0WjFmdXpsU1lBUUFCUWNKOVg5RmhZX25HSDRVT0YyMmFFTkl4RnFIRVJ4bUE9PQ==
"Hello,
I am developing a facial recogniton/ object tracking and rule creator for the tracked objects.
Would you be available to exchange contacts to further discuss this?",r/machinelearning,Z0FBQUFBQm0yeGI4M1VFZWhNMFBLR01hVmFuZ3dUWXhYSHlmeTd6UmhwNEdGekNadF80bHB2RUk2bGJCczVaNTlHZ0VuZ1g2dW9EbEZMT3NXTjN2T290ekhrWjhnUU04UGc9PQ==
"Appreciate that suggestion, will make the change!",r/machinelearning,Z0FBQUFBQm0yeGI4N0lWc1k2b3JWM1ZmNS1SdWFCWFRvUmszRWtuTWxIVE5TMkNnenYtS19yZEo2cGl0WWlfd1dPRWg0SWdpYV9XQzEwLUtlM3JmalRrSkRaR2tEUnJoUUE9PQ==
I think that tends to help. It’s the first thing I ask anyways,r/machinelearning,Z0FBQUFBQm0yeGI4UFVTOW94WGhrQzZ6WWJabkpxWHNlVmVBbERkN0pPcnBKQTl5OXRIX2tmTG4zWGpRSUQ5RVVLbFIyV3MtTW01M1lrTC1ldTU5ZmozWXJwYlpXMkV3bUE9PQ==
I get it. Added the job post now!,r/machinelearning,Z0FBQUFBQm0yeGI4V1JLemNPS2ljeE5FVkxyYjFXQzlBRXRSa283U0RyN256Y08zWWxTZ01rb200TU00X3NhdlRBQ1RCcUptWFhaYS1sanI1M0pzanNFWTk2U0FLXzV5TFE9PQ==
In Cananda?,r/machinelearning,Z0FBQUFBQm0yeGI4OWt4Y29LSk43SDIwX09pbWRGamtScU9ncnJNZG9YSEVGRDgwTkVPUmo5YklKMmFueDV0SnNtTDNfSGxKX1hEb3Z2NVA2SVdKQWJjdlNrNHRjR3M5eEE9PQ==
"Hi, I wanted to ask about the rebuttal phase. How does one go about it?",r/machinelearning,Z0FBQUFBQm0yeGI4MmRzTU9DeXhPbm9nOWtCOXpYU1BHR1BaTlgyWk5JbHpUaXdOdDR6a1hxb3AzWjZfZGhtTUQ0cHRQX3RZa0RELTI0V1lhdmNjeDNTTGZDWXY0dm1GWEM1ODJBRHZrZ1B4cFctT2x2ZUw4UFk9
Good luck filling the role,r/machinelearning,Z0FBQUFBQm0yeGI4YnN3UlpqaE1Sc05MZDQwWm91NUZncFJ6cElfRnU5dHF6RWphQWxYX0dLMnRaNEM2NVliUnd0dEo3bnB4eUQtU01QWGkyM3c5MThmNVAtdmtzTk9xMXc9PQ==
"I'm gonna leave this here because I think it might be interesting for you :)

https://journals.ametsoc.org/view/journals/aies/2/4/AIES-D-23-0026.1.xml",r/machinelearning,Z0FBQUFBQm0yeGI4SzRxYWZxWmg0dFRSbGhrN01UOGluanhfSXJTazdsN0pIMXpXdXlyTElnLWhaQ2MtRGRmcHQzY3FQc2FMTkVKd0xzS3o0RkcwLUZFbkRBMlBxUjAzcWc9PQ==
"Our team from Centific is representing at CVPR as well from June19-21. Stop by Booth#1744 to learn about how we're helping some of the biggest innovators in the world with computer vision, Machine Learning and AI.",r/machinelearning,Z0FBQUFBQm0yeGI4LW5NN25xM0Vzc3lUU2JtRG9oU2tnRFZhLS1pbGJWM3lYaGhqMmZqVllSOVU1OWJXeVE5NnZmLUd1LUJ5ZHNMYWM4MEY2TFBQcEpuMm5kSlJRY2RxNHc9PQ==
What are the top three idiot things they say?,r/machinelearning,Z0FBQUFBQm0yeGI4WUtLWGV2Z2xhenBuX2Y2WjFTWFpXalhDbFJHZGZoN2JUVXNKWlQ2SHkyaW11eC1XMnZJVUlncTl4TEpOeEpZemI5Z1d0dkJDaEZaYjlfMnhKQ3YtS3c9PQ==
Thanks,r/machinelearning,Z0FBQUFBQm0yeGI4RlFlaC1Jek9jUl95TTU0WkxFWGd6ckpCRGl3VDZ0RzF2U1lpRjRpbnZYVlVYZHkzOGpkX3hoWWh2amtlVjUzUjgwRm9Hd2FyeW5NWEVMWWlZZ3NKVnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4VEtrNGlkVGVxeEpBeF83YkkzU0lXbTl6SEpvQzR3YkQzc1RwTWpYWm1ZZ2dWSk5nUEJjeHZ2clNCRkJtTjFiM3RLV1d1OWt1UW5IS3NIWmVmbnJvNkE9PQ==
Can you go more into details on how it helped you?,r/machinelearning,Z0FBQUFBQm0yeGI4TWE5M3RaQ3BRakJVeHg5YlZnUmk4SnZtMmpVbXlTZVJZS1ZPWDdaQWJKNXgyLXVsMF9LNWdOQThSc2NNRFRkbVpKSHEyLUNGVlBvd1FxZUpzTXJ3emwzcldXbWMyT3B4dHp2Yk8tcmdEQWs9
"> from my experience at a FAANG we were not permitted

FAANG may take that position in part because they have their own datasets, and would like to set precedents stifling less-well-funded F/OSS competitors that would need to use open datasets.",r/machinelearning,Z0FBQUFBQm0yeGI4el9CNzNGRmRIa2VHdHRCUE5mbi1Rc2YtaTJETTlubm4xVldtY1F2R3RQVlh6NHA1YnpsdDlXQkpiSXEwNGNCZzlDYWpTRUJfNW1McDdKa2xqYzZOdmY1dVhkbDRIWWVMc1BaZDA4eDBuU009
"Great! 

Regarding the instruction formats (alpaca vs phi-3), does it make any difference in what the model expects from user after the training? It should, i suppose?

Also, I see at the end of the notebook it says this is the last chapter. Was hoping if you could do a chapter on RLHF, albeit a small one?",r/machinelearning,Z0FBQUFBQm0yeGI4d2ZtblFTRHhHdzZERjBvZVRONzZXbW5VSDY1cjU4WG83QjVaRldQNUZuTFZ0Q3pqVll6MFc0bk5FSW9tR1RJUlJhT01TZWdiSWRfVkdZRHNEdFhKMGc9PQ==
"> Mickey Mouse, maybe with some marginal difference. There's no way you aren't going to get in legal trouble for

[maybe not, for that specific example](https://www.bbc.com/news/entertainment-arts-67833411)

But yes, your point is valid",r/machinelearning,Z0FBQUFBQm0yeGI4SUpRdHQyS28xNVNCQzVDRG1LQ0d0M2RuV3RQRXl4eFZHNHJfNFd6a1pHSThWMU9jYy0ySDBMaFVTUk9vbFJCVmJfaTI1WUZva3dSWGNOTXRvb05leWNraVVDaWd3Q2pJdFlhZUVlTHB3Q2c9
"Sounds great, if you want to get some notoriety or reach more people, I recommend you to create a Medium article about your tutorials.  

Best",r/machinelearning,Z0FBQUFBQm0yeGI4djdoc3o5TnByUFNRWDRCd0lzVVIzdmppRDJxeXMydGV6THV5ZlRxZHItM1FyVFdDNzRudkJGSU9UT0ZQWkx5MWw3R2ZlRFdocC0wUnJzV0RwVzEwaDIxSkFUUE1vTTIwNXZEOHJMMXUwdG89
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4OXJ0TWlNT1ZUSExiSEVxWXFwVVAtRUpyYzBRLU5HNFotRkhTQ2NvN1hWM254NmNhMTVfeDBzcUlrT1hEa3dqTFNOQWdSUkFhSm1wb3N6V1RranJQQkE9PQ==
"Great question, yes, you have to apply the prompt style to the LLM if you want to get good/better responses. Usually, this is handled by the framework behind the scenes. In the LitGPT library I help developing, we implement and support many different prompt styles: [https://github.com/Lightning-AI/litgpt/blob/main/litgpt/prompts.py](https://github.com/Lightning-AI/litgpt/blob/main/litgpt/prompts.py)

And yes, this is the last chapter due to length. I have code for DPO, which I originally planned to include in this chapter, but the chapter is already longer than the publisher is happy with. Plus, the results were not that great (convincing) yet, and I also decided then that DPO is not a good candidate for this book (it may not be something I want to recommend 1 year from now on or so).  I may include that as bonus material when I polished it up a bit. But yeah, I may also do another one with ""real"" RLHF, that is, training a separate reward model :)",r/machinelearning,Z0FBQUFBQm0yeGI4SWJTZFBIdkEzSDlydHZmTHhjLW9qNWIyVVJCMUZkUDVTa0d1QTlCZ3JTNW1LaUVZSjdxZzdENDVNcTZ2QlhlLU8wWEItUjFqOGRfM0pOSUlWNkR3V3c9PQ==
Thank you!!,r/machinelearning,Z0FBQUFBQm0yeGI4QktSZHpVRWxWOU5SQXhOMUNhSGVadlFBbnk3MU1pVktIeGs5Y3BKUlNlZVp1Wk9tOTZXWWhPLUFHanpYaE5VN3o2eVZINS1uSFN3RE55ZExBOGpTamJaTjhrSXVQcEFaTDlKVm9Zd2phY3c9
Why isn't it a good idea? I am curious now.,r/machinelearning,Z0FBQUFBQm0yeGI4cUFBSjVWdGs4VXpfX2k2TUVjQmc4a0w1MUhDcHduX05CT0FtLWNyOE0tYjluTF9Oal9OSVFGbjlrdmw2YVBfYTdUcXd2eGRmbUFCOXFpc2ZRanNKU0RVNTl5VFNPYXVCUkVHdXctdXNEb0U9
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGI4Nks4TlZ4UVZuRFhpU0RqaU9YcVF5Z3ZQaHNCWUtFSnlXeHFreUJPUXpyU0ZaWnZHSDQwMDBMRGVUQ2dsYVFHZ2J2aWRDWXgtNkJ2dGtBNExNQlJfRUE9PQ==
What do you expect full comp wise?,r/machinelearning,Z0FBQUFBQm0yeGI4NU8tV0YxZl9SQk9jQjNjWGJncEsxX0FSakZaNlZ5Y3R5UllILXUzR0VfTmZGSW1wcGhKTGp3VUFmckFRampCdDhpWURDaU5YLVQ0M0ZIS0pfRDJRdGc9PQ==
Every inductive bias works in a machine learning model this way? I admit this case was particularly specific but I wanted to counter the claim that generalization is never possible,r/machinelearning,Z0FBQUFBQm0yeGI4YnMwUUZoZEFGU2t4MEVROGVrM2dETWxkTW5GSV84V1M2VTJvSDFocG40ZGRyblVrMXVIOHU0aXJLVUpSc2lkSmppb3J2M2NDdkFCQjFJNVZTeWVvSFE9PQ==
The cheapest 24gb vram,r/machinelearning,Z0FBQUFBQm0yeGI4NDZqejV1ZFhXTlpJcmJBWEtPQWFpYXFhNzRzN1BnSW9VaTBod29vVURuY3BXUkJjaWZaeDFueWE3a1dJRmw4YUZlX2NGMzhyLWFtSGtJTzlDUEduZHc9PQ==
"Colorado + London + Israel. Medtech.

Only $200+ million in and no fielded models. I can't even get PTH files from them. 😁",r/machinelearning,Z0FBQUFBQm0yeGI4OElmUTBUdUhFcDRoWFJrc3ZDbVlaUWQwMVpfQWVITkdNOVhPLUl4ZEY1ZTZDUDQ4SE1BWUNZdnRkMDdYZHhaU0ZkQ3pOX2xqalNZdVJnN2FDZmljYkk5OXBSNmNOQk9YUkRiMnpPN2tkd0k9
How is the book progressing u/seraschka? Any ETA?,r/machinelearning,Z0FBQUFBQm0yeGI4Nml0TTZrZ21KMkM4b1lOZXB1YTVySlN1elhCb0ZsRW9FNUk0THk3d3l4TXFFM2E5cklDcnpxQ0x0TU5adUpLcFBvQTVIdHhaYUJiaHFaTXNkWVVwQWc9PQ==
Thank you so much !,r/machinelearning,Z0FBQUFBQm0yeGI4dWpxWjFnd2xNSGV4ckVoNndrRDEtNHNROEtERnpLWGlIV0pwX1JuUnpWc1BVWG55TlBuSzNhNnFFQU5mNkFfUFc0dC1leGNsMEQ3dFhYMU5BeTVvNkE9PQ==
Bc thats a completely normal salary you say?,r/machinelearning,Z0FBQUFBQm0yeGI4YUxZcEFsNnd2YTdTS2VfbkxyY0U0Y0E1S2x2RnRrRmdIa1hXeHRuXzFRVUJWVG1lNlB2YVVZcW8wSHFzLXN2YkdqT0prMGV0NVIzcTh4bElocHVHTWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4anloWi1YbHpCVWY3NXBCUUMtTlBsUHZiREJnMnJqdnBOaXNHTzZKakZ5MFNzZG9za2hYZFpobm1pakhrSm9BMkYtR01tT1QyUnAtOTY3SDN3V1hSLUE9PQ==
"I'm working on drug discovery and design using AI: I confirm, these are valuable approaches when evaluating OOD generalization.

You can have a model performing really well on your data, if split randomly, but fail to generalize when you split and isolate specific data in a test set, e.g., protein targets never encountered during training.",r/machinelearning,Z0FBQUFBQm0yeGI4NTBxWk8wUzY1UFZYWUNhaXpvWWV1YXhmRHRoeVhid1g2Q1lFQUtWVlBmSWhfN0hmNDlHOG9xQ0c2RUFVNFZfMUpRdnhNZUZDTGx0RFAzZTFzYmpvTzg2ZHdiSHhJeklzS0RqM1pIc0VPY3M9
Similar in Bay Area,r/machinelearning,Z0FBQUFBQm0yeGI4RUhRdVNydDZzaEhZZ29veVplejBZemhrbEVwM2U1VGxhc3l6VGxHSmg4cE11V0N1SFZITFZFMVFxUXBHd2dWamZNMWJFN0JCdzNaUDNadzg1ekYxeXc9PQ==
Good luck mate.,r/machinelearning,Z0FBQUFBQm0yeGI4OGduUEZMd0Y3TW9EUktUVkJxSGpaVlZ3SkxmcXU3MUJ1VENpUUI2MzdKZklXNnh6SWlsLWdvdU9Gc0llRGFmNFdrMzh6djNhVElabDM0aURod1A5eTYyUnB2Y1pqM1FVaHUyT055bUVIams9
"It's kinda absurd to me that nobody's mentioned this: find more buisness problems to work on. There's likely plenty of low hanging fruit, you just have to talk to more people that do hard things.",r/machinelearning,Z0FBQUFBQm0yeGI4MFdXY3loVjNJNkY5YTAwai12VFhrdE16TVJ1c3d1NHRPQnRodDdNTXZwbVdESDhranA1NWRWaXFwamdZYTFQdFlHaGc3bnNBcmhjYndYSnE2aXkxOUE9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGI4OXluOFlvLURBU0dXc2xhb0VlbkZrNV92YllIM3kwdERxVDZBZkpELVBXTkRITjhIb0xUeTZiMTlpd05tUzdfLUhIQXk0TGxyZWh4YnduUmx1NWhKa2c9PQ==
"When you say different classes, you mean different people, correct?",r/machinelearning,Z0FBQUFBQm0yeGI4eTdyZGdLNHN5Q0dHYkk2UWhseWlwc2ducUg4ckhSU1k3WjZZQkZBZ2tHR2NKUUs1N3Jab0g1bU5zOVhuSlZEZ3NvamVqRVlvTG52T3FCdFpEaHFtU0E9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGI4TUdYeXdILVo3a3RNa3MzSVFUamp4VWJIV0VpUVhVNkdMS1dsNnF4T2NOQ1Z1Tll3NWRQM1AzbTlyclN5VE9DV1RMaDdXU1M2c05QVF9PZGMyMTEyUUs5QTJCdDJCdmNoX0E5dEZLeFJ6cFU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4T0U1alo2ZGlUTVZoeDdyc1JPQnVQZDBYb29URDU3Uld2UTNFNDFYSEFZUHVsRTcxUlVZUkp6WXFDODlrS0lmQVFuSXFRSUJ2ZmJJdFFoajlFSUZGekE9PQ==
"Yes, but what about the speed boost of JAX? DLN training takes (very) long in many cases so a speedup of 10x is really a good argument for using JAX. What do you think?",r/machinelearning,Z0FBQUFBQm0yeGI4VDgtLWtUMWEtQXVxVDBtUzQtazJvOXg3NTd1WGt1Q1AzaENFaHlNXy13SWRMTzJRUHFWZXpOVlA3dGNrRUxqem5KSTc5b3p1SWQ1bktxSW1qV1FUcmc9PQ==
That's right. You can train with a set of images from different persons.,r/machinelearning,Z0FBQUFBQm0yeGI4WVF4MVlvUHZFSXdGN1FHTmFDQjZDRzUtMV9wLW9mOUZwZjZIWHNSVEpSTUV3OUFHRTJ6bWY0c2ZqWnp1cXVmV0trSm5DTm1jNUdHR29JcEhoTmhXU0E9PQ==
You can DM me.,r/machinelearning,Z0FBQUFBQm0yeGI4YllBR2R5d00xTkpQX3pMMWcyeDFZX2tpcGdXVDAxWGp2blBzVmtlY2dMTlFwX01PTWNZdk5mWHowSkxRWW1KamRjczNkN3VDQzZ6WDNiYUlHV0hHc3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4eW1SUUNyVnVSN2otZHN3STNNdngyUU1fd19QQ1J5Ul9lWkZmOElpRkpXZTNyak95blBmZFdBZXh6czBCOGVwZHFLTDVMdXlpSWoxNXlPT1dlWThGSUE9PQ==
"A lot of medical studies involving ML have been called into question due to some problems (data leakage, no train/test split).


I don't have a reference at hand but we had a talk in our company from a leading researcher who's group is dedicated to double checking that stuff.


One of the examples was a study who claimed to have developed an AI model that could find cancer with the same accuracy as the radiologists. Well, they found that some the images used had like a stamp that radiologists would put in case they suspected cancer and that was what the model was focusing on.",r/machinelearning,Z0FBQUFBQm0yeGI4b2REV19sTlB5cTBkbDRnYWZiM2Z1YzJ1aFNXMVZtbDA2TFhkM2x1MGR2NXdtTnZiOWlRZ2RxcGlNcW1GN2RnSXp5VlBaZXA1ZEk0VjdzaDR5b3hsNDczY2dWNmQ2Tkx4cjBKa0dwUHRYQ0E9
"Also kind of related, for multi-instance learning like this (proteins and molecules, cells and molecules, but more generally applies to recommender systems...), when you test OOD we found out that it makes sense to decompose the predictions: you subtract from your test set the mean, for each, for example drug. And you recompute the metrics (what we do in reality is we fit a ridge regressor using as predictors the IDs of the drugs and proteins and we compute the metrics on the residuals), then you recompute your metrics (R2 for example), for each of your drugs, and/or proteins. This way you can estimate not only how good your predictions are in general, but how well they predict specific interactions. 
In the recommender system setting, it's likely that you have apparently nice predictions for OOD samples, but then most of the R2 comes from good predictions of a large (but not interesting) inter-element variant. In the Drug - target interaction for example you test your model on ood proteins, get a nice metric, you think that your model is great, but when you do this descomposition, it's close to 0: it turns out you have a protein kinase in your test set that interacts with 12442 metabolites and a metabolical dehydrogenase that interacts only with 3. Your model predicts OOD a 0.9 probability of the kinase interacting with everything and a 0.05 for the dehydrogenase: your model is not useful at all but your metric (even OOD), looks great",r/machinelearning,Z0FBQUFBQm0yeGI4ekRXaWNaVmlnTVNFTnJyU2FvVzhwUzBnb3V2YnBOcEpjU0I3akFzVGkzcHhKN3Q1NGRIRmFGTFB3RFRlRVA2Y1NSVTdsaFNRbk1ZWE5hbmtSZXBQT0E9PQ==
"Not never possible, but there are fundamental limits to how much OOD generalization is possible. 

This applies not just to machine learning but to all learning. It's why you can't pass the bar exam by studying math textbooks - your training dataset just doesn't contain the information you need.",r/machinelearning,Z0FBQUFBQm0yeGI4UlF1Q2VGeFRhQnJKY2RKd05mU0ktaTNrNzRoU3NhZXk5OFoxTWJ5TXF4M3VFT0ZrbDFhVmxWQUNoMUJnMHJkQ1ZuSFAxVDNuVmZ2V3NHQ1BfbWI0ZDBhbFFfUWRiSWdUR3NZbWdoNWRpQ0E9
thanks!,r/machinelearning,Z0FBQUFBQm0yeGI4elUxOVk2cGk3TWFxWHVMekdLUWVBMHBfV2tZWHpObTlXSVNqMGN1bmZDMVBnOHREQTYwclM1Tjhxd0NqT0lDN2phUE1oS1F3aXI0dGpIVFUtU0l4eHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4LWVxQVpwdXlZY003NGo2QjlNRW5NUjJ3YWd3SXJ4eTB3WkVLaHJEYnFHLUFTOUlfNHZiTUluQXljaE5DcEpNV1QyVEIzdHg4N3JQR0R3QzFYY09NaUE9PQ==
"You could use other models with sentence transformers
https://huggingface.co/spaces/mteb/leaderboard",r/machinelearning,Z0FBQUFBQm0yeGI4SldxQ25pbEtqTlkxWmh0MFQzb0JIY1JXMjNnRklna0FUVE5CVkYxUld0LW5KallQOUYwcTJUcEZvbFhuMVY4OXBJMWFYS05xWUt1bm01Sl9xRWNVSnc9PQ==
"Hello,

I am a college student and wrote a paper with some colleagues about ML, using different image recognition models to solve a specific problems. The results were not as good as expected (we think we know the reason why) but we think we have a nice work finished. We would like to get feedback from other people and have it posted somewhere so that we can reference it.

Do you think it's a good idea for us to publish our paper in arXiv? What are other alternatives?

We also don't really have in mind publishing it to any journal because we doubt our work is worth it to be in any journal. What are your opinions on that?

Thanks!",r/machinelearning,Z0FBQUFBQm0yeGI4bkN4Wnh2bTEzUEx4cjhuYmtkbUhPYjNzbkhFbjBfWExyOEpUZkd2Q0lhVjFQY0Jtc0dyTlRjcHhBMVBVZHJMQUVMMUptbTY5a2tsdzhfQ0VKczNfOHc9PQ==
"Until Google suddenly moves on and you’re left with a code base that’s no longer actively maintained or updated.

Rather have something reliable and have longevity if I’m going to put something in to production",r/machinelearning,Z0FBQUFBQm0yeGI4U3JLS2tLZmg1LWpEXzRDTFg2emk5V1NXOTF6dm9OU3ZQOGdDbkthcktsVTAwZGZGbDN0aFEzWklRbUxMSmNlWFM5U18zWldhaW5EWlZ4SF9fR0tXQkE9PQ==
"This basically wraps it up :). Now, there's only the editing, layouting etc. According to the publisher and the Amazon page, the ETA is Aug 27: [https://www.amazon.com/Build-Large-Language-Model-Scratch/dp/1633437167/](https://www.amazon.com/Build-Large-Language-Model-Scratch/dp/1633437167/)",r/machinelearning,Z0FBQUFBQm0yeGI4RE9iLXhSV0NxT2hJbnZQWVBvNGlpeFlVMEtNVlUwaGh4RnBrcFdiU3FIcHUzaWxmV1RyREY0QnkzaHplN3JyUy1ENVA2Y2FGMXhHdFBQci1hdU5jM3c9PQ==
Haha IKR,r/machinelearning,Z0FBQUFBQm0yeGI4ZWNSM2R2WWhMN3hxZ3hEYml3amR3SHdnOXQzdzF6MDEyUnVzQXlPbHVDcG1iVTlzUEJPZDhjc01MR21FNWdLUld5S21uR2kwSkRLQnRyckxod2tQRnc9PQ==
"It seems like non-temporal modalities (like images or text) are difficult to disambiguate to the Liquid, temporal layer. If anything, LLMs now would act as a readout layer for the LNL.",r/machinelearning,Z0FBQUFBQm0yeGI4MFI3LTN1TjBySHplU0t6M3ZxUkZYaVR5elN0cDQxZDVyX2FsZko1ck90LWlvN3RCd3dlRktxUU9JblpUaWdsdkZWNG12VnhsNTlWbklPMzB6dGFFS1E9PQ==
"Here's a notebook I made doing basically that exactly. There are other possible applications of GMP CAM, but this is how I tend to do things.   
[https://www.kaggle.com/code/vannak/magical-localized-fault-detection/](https://www.kaggle.com/code/vannak/magical-localized-fault-detection/)",r/machinelearning,Z0FBQUFBQm0yeGI4M09LeHV6TkFWVGZBRVloRDJhQlNydWhBMk9pMHFhdzJHcWRlY0VRaGhhUGJhdGU5U2Y4MVNBMHFhVXRmZDdwQU1pVDZxSS1tM3BNNXpPV05rT2dVa0E9PQ==
Cool. Thanks for sharing. ,r/machinelearning,Z0FBQUFBQm0yeGI4VGd0eDEySVo0M0puNFd4R2NKWFpsNzlZaUItNTNCRFZNN0gtSzEwUE16OVUxQ2hINXZ6R3pYV2ZRT2JCWkVzaXRsTFZFbmszVUVwZkpoZjNVUENycWc9PQ==
Great! Looking forward to purchasing the paperback version (as I am trying to get afk as much as possible),r/machinelearning,Z0FBQUFBQm0yeGI4ZVVJaWNEeXZlTjN6WjMyQWI2cVVpREhyUEplczQzRkJTSXB6bVQzUGVYaVVhaFRLSWJQS2d1RXZFeWZEQ0hzeURSYjg3Y3hqUWIzbGZBdFpza3VFUXc9PQ==
"The notebook I had posted elsewhere in this thread as some brief notes on this. But long story short Grad-CAM reasons about a linear gradient approximation of your model, not your model itself. It doesn't actually give you answers to specific ""what if"" questions, in any apparent way. 

The real issue is Universal Approximation, IMO. If you end your network with a MLP classification head, you've already committed to an uninterpretable model design. If you want your model interpretable according to some specific logic, it actually has to work that specific way and not other ways. GMP-CAM does this in a way Grad-CAM does not.",r/machinelearning,Z0FBQUFBQm0yeGI4VUFSNWM0M1BhdW10cXBCRHdQcTFTdmlnWFM0V2o0V1diWkdzcnoyM2VCVnpaTWt2TFNpblJabUZ2MWlfNmZmWEpRSEYyS3pLbW9McS1BLTlBZ1FxNnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4bm5rRlRlZWRXQThHQWdCczA1RUwxR0RkdzQtVEJZODg2cnprLXItTGZOVV8ybDlZMzlkSmh6VTFFVjRYbEZTRWZmSk9oOGFwd3dSUkp4ZDJMSTA2dFE9PQ==
"Thanks! I would just comment that sometimes it is necessary to first work on the simplest version, and let others improve it.

You can say ""hey, we can actually use the gradient to generate and explanation"" and then let someone smarter (smarter == already knows your idea) to fix it. Therefore, I would argue it is an excellent idea.

Edit: by the way, I am also skeptical of XAI in general, but I am 100% certain it is a useful tool. It does help to evaluate and debug the model, which is good. I believe that even unfaithful explanations can be useful if it can help you to detect bad ""bugs"". Metrics are terrible IMHO although I mostly use only that. In this case, we always use some form of average, which is... Also linear. Why is it bad? Well, because we take a set of scores, make it a scalar, and call it a day. You can also do it peice-wise, and we usually do, but it still tells us very little.

I can go on and on why making a classification 0 or 1 (good or bad) is also not faithful but you probably thought about it since you know about XAI methods.

I will take a look at your notebook.",r/machinelearning,Z0FBQUFBQm0yeGI4dVNuVmRxT1dDYU1CWm8xYVJVMVpqZWxuRHh2c3RremVjX1FiWVlZb3BMTV9QNWtyTGQ2X2tIOTk0OWdfeWZGQktDVHExNHBjOW1nZy10aXByVjFVNjAtanozNU5JaTlZMG1fMkJ0aVV6bE09
"Imagine you can only do backprop only after you've left the conference 

:(",r/machinelearning,Z0FBQUFBQm0yeGI4aEgxY2V4TThHcnZWTWc0dG9JMVdxSFlVT2xzWlVaSzZfRU9FWDBUSHVqSm4yTm1vcndWNFh0Skl5SmYtNVIyb09ueUlhWTA1MlA5eWc1dWVUVHVyRUhRWHBjUEhCX2xJMklnamE5OEpDYjQ9
"Tutorials and paper preswntarions?

Ask questions afterwards? Get their contacts if you have common ground or topics to discuss? 

Email them??",r/machinelearning,Z0FBQUFBQm0yeGI4MF9MUVBnRjdxcnNneHlZMGg0dVFJUWtKckQ1LXBkN0FHLXBQVklPaFRfOWpuQThyZlhkRVczOHdjQ3EwLXE5QWVZbHNYRDZWb1FPZm5keVh0Q2wxeHlfUmxmSW1YNWRoOEUwblg2WUMzMDQ9
"Ah nice, your [code](https://github.com/tspeterkim/mixed-precision-from-scratch/blob/5c06079751427ff59c0b35509db5f26e2c8c01ba/train.py#L135-L139) resolved a confusion I had w/ how Mixed Precision Training ends up saving a lot of memory despite needing the FP16-copy model and requiring gradient updates in FP32. I wrongly thought that casting and scaling back to FP32 gradients was done globally / for every parameter tensor during the `backward` pass. It's actually easy to do it only when needed—specifically, in `step`'s loop through parameter tensors.",r/machinelearning,Z0FBQUFBQm0yeGI4U3Y4bmJvbllQRHhGeGptUzdHVDlkWTJHOWhqalhUTTRxeHdQU0dPUllLa1FnVC1xRC1wa0MzS2YyWnFHS25EeXNnc1FoU0VmT3FjaVZwajV5OXpvbnc9PQ==
"If your advisor is there, stick to him/her. Let them introduce you to others.",r/machinelearning,Z0FBQUFBQm0yeGI4R3R5b0lYZzFFSENjOWd1SHJVNFFOVFRRTWlYWXNWYlB6VWs3eVlOTXRILTJnVDRhdnpWNUg1MWx0dXg3MW1sNldoM0pHUERQWjQ3dmYwZE1QYml5MWc9PQ==
Cool,r/machinelearning,Z0FBQUFBQm0yeGI4QlA2ZXYyQUNfV3hhdlRYMWJDejJ4VVBlTDVNa2pqNnlhWnhyeFpBR3BxeUdSSVdnRXN3dWNvU3FZb2ExUndhbDZnRGNCVXo2OFZGMlFveHdzbmVtNVlTakRMUmZkQXpFb0JPZlh6OHZGaTA9
"Why do you think LLMs ""think"" independently? 

They only mimic human language patterns and speech they learn. They still give false information frequently, and ""hallucinate"" still. LLMS are not students, because they cannot learn on the fly as human students do. Even a dog can learn new tricks, relatively quickly and without the same amount of resource consumption.

ChatGPT can't learn an African language (outside of its training data) and LLMs are incapable of learning without expensive computational resources and huge amounts of data (ever-growing). 

LLMs still don't know how to verify information, and this isn't good because they get their information from us—which requires a strong BS meter.

  
LLMs can do some neat things, but they are not close to being AGI or something similar.",r/machinelearning,Z0FBQUFBQm0yeGI4NnJIS0sxZWxjT1h5NWtLc1Z6eXRZRlQ4ZjZDVU01cWhZYl9CSC14bDN2U2RyOUR0ZUtwbVRWajFCRHFFSkwtZE5CYW9uZmNreDllR0E2SndpNmMtUWlQcmRyaEt2c1JUVTNMMDhfMzN5Znc9
Nice!,r/machinelearning,Z0FBQUFBQm0yeGI4NzBSVE1JUE5GX1VKU05kNTB3OWRmTWhaUGNFUUhsU0NtTjBvZDdSX09HUkw1UDVYQVVNSmpuVkxzbmswSXI2U2FWWmRyUi0ySTdUM0NpenRfeThpWnc9PQ==
"That could be true concerning the training data for LLMs, but some answers require many many steps. Most LLMs I've used haven't gotten the answer correct after 30 or 50 steps. Life is more complex, and the real solution may take 1,000 steps, or 5,000 steps if they are to surpass human intelligence and invention.",r/machinelearning,Z0FBQUFBQm0yeGI4UUJZRU5QUVpsemNVWlNwSldGTDZIVFE4bnNrTjlHMXhHajZfSzNFZzduYWVVWUxHOU9qenRoZ3dDcXN6bVV0ZVlTajNfZzNYdFdEZDczM0NNcTkwb3RCaGNuZ3FsM1VLQ25xZ3FPQjk5LVk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4a3ZETkxHVGJVWTRhdW1WMU1iOWZsazlaZlhjTlB3ekNlNU5lTnYtekE3TVVnemd4VlJHd3RvUWRTeGZ1Y1o2OXo2bWtxT0RjeTIyOTN6cDFVT2NTQVE9PQ==
Dealing with label noise during self-training is definitely still an active area.,r/machinelearning,Z0FBQUFBQm0yeGI4R3lmaHY0eHVTZVk3VExRaXRScEZBSlpQaUpxcVdNUWhiWUsyU1VfcDFnU2MxMVRLUk4wWkd3OTYtclFwYU43Q1ZBcm15X2picktWTEkxb01OV2k2ZWctdHc0dHB5M1JUZ256SzFYU1JHLTQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4eGVzLUR3dVhIUkQ4bkM5RUhKOXd2NTItWWhtT2lhMGlTLWU4Zl8wd1lTdWJrQTcxcU1UQVBWbEpsUjRieUZkZzhWN2JtRjdWNmRrZmphVkZmS3Jnc3c9PQ==
"This sounds like Reinforcement learning from human feedback. You will probably need to add some sentiment model to convert your replies to a numerical score. I am not sure what ""on the fly"" means, but you can update LLM weights, and then prompt it with the chat history generated with the old weights and continue the same conversation.",r/machinelearning,Z0FBQUFBQm0yeGI4U283Q3BlR2xpS253V0JkM0s1aFNQcUlfbHk3Sm1pbGtTVUdPZC1wYlcxbi12V0pzRTZVQ2NaRjIxM1NVNlQ0QzRXWVctNk01YjhjZVZsdEdCMnlGR0FjbzFIMnV5TVNZcE9WdzIwZ1VVMHM9
"It seems that the existing methods don't improve more relative to Co-teaching, DivideMix.",r/machinelearning,Z0FBQUFBQm0yeGI4UlZyX21iVGNBMks5VXhZc09NUXBZUFFGZnFrcjI3Z256Rkl6M1hKR2RyM0pzbjlON1FVTEd0VVpkUkZpMEk0Z2I1Sm16c0dMNGVmbm90Sm9wMGIxaWl5TG5xOFBHdXByMHNiX2F4dFRPa1U9
"I don't understand what you mean by putting ""General Summary for AC and All Reviewers."" If you want to upload a response to the reviewers, click on the ""Rebuttal"" button right below your article information and upload the rebuttal file.",r/machinelearning,Z0FBQUFBQm0yeGI4SFZmU29YeVVPLTR6djdEVEtKcDJPZjFrWXpHRDVJLTNKdDA5YkN1RkhDQzNpem1BMks5eWdZOEdyZ0dKQ2tEazhaRlBQcElYS1RWazlTUTcxdUdRNTNWLWNTTHd3UWxMQVJwQ0xpbEdOcFU9
"I also received a review with only a few very sketchy comments. If you feel unhappy about the feedback, you may optionally contact the Author’s Advocate, whose role is to listen to the authors and help them if the reviews are clearly below average quality.",r/machinelearning,Z0FBQUFBQm0yeGI4aUlEMWdpOWdpNDZmcGdreWFkUzlsRzRrcC1GQ0Zka0R4WEtVTlpyaW1sbUo1N3BsdnIxT1BTcUxYY1gwTkRHT0ppYkxMdG5iM0RyU3YtYnRZUlJHT21UNGVRMndhNldTUWhWZ3hTZjhCbVU9
"Reviewers can see all of the remaining reviewer responses, so please respond thoroughly to at least maintain the same score.",r/machinelearning,Z0FBQUFBQm0yeGI4eHZ3NWIxZ3I0M2I2RFNlVWFaNDFkSXhhYzhZanotNHVDbTBZNU9SRGhfRUZzYW82UTNzYUNmVm5EZ0NaZjZTWUlIdTllVy1CR0Y5YTBub2J5cks1RnpKUThxWEN1aG5Cc29IWDFRVld1ZTQ9
"Censoring something makes it less creative. In other news, walter is wet.",r/machinelearning,Z0FBQUFBQm0yeGI4a1JDWmE2dUptVnZ4blR3aVR1MDZyTi1ZeVl2QVFMU2U0azhxWmNtYmE5d2trTW96RWN3emNTRXgxSEdZUnhsZ0pvZ0hCc3hfU2U5cVV1S2NVQnlWVkE9PQ==
Don’t forget imbue lol,r/machinelearning,Z0FBQUFBQm0yeGI4Zy1VRTlIQjdGTzIwZXItZEo3a1ZfcnhxZlFBYnhzNlZBZWdkU2RUUHdULWZsSEJfY01mc0JQVzFVMFJ2eElXSjlLRmVsZFcxTVFNcWZwTkY4cFZlOFVxNEpKMGpzMzdIdEN4cjM5Z05ta2c9
Thanks!!,r/machinelearning,Z0FBQUFBQm0yeGI4WlpkWmZkRUNucGc5NXBBTE1wMU4yTWI0N3VDNHhMMW1ZTndKejlrYS14aW5SWTlFczBlOGhPeFpLS1VUNUo3SFZIdHl3dUJoNnZ4eTJyMk1Rbm1mLXZfZVpYUHhVZl9VNk5QSlc0Q0pESzg9
"I feel like the practical utility isn't really there. It's a really cool discovery, but in reality I just don't see any profitable/realistic use case of having your model generate gibberish endlessly.",r/machinelearning,Z0FBQUFBQm0yeGI4aV9jSHc5QWtIYnpCRjlWT25nS1VVY1d3blY2QWJ0X0tlLWNub3pBOW1JakhyZVVXbHEtbENQT3lJd2pyS3hydG5TTGQtVmMxM0dDYURGeThlZlpIYmc9PQ==
Most of ML in the industry are done on Linux. Haven't seen anyone using Windows in years.,r/machinelearning,Z0FBQUFBQm0yeGI4bVBvNjQ2alJXcFgta1h3U2x5alBmRGw2RGw3Z3ZKSjVZWXlUZ0tKd0FJb1ROZEdsczFLdnpXVmdpWTVGZEs2VEhBcVYtMEM2aVF5Z3lPem1BLWhhZWc9PQ==
"Similarly to other conferences, I guess. See ICLR on OpenReview, they publish both accepted and rejected papers, all reviews, rebuttal comments etc. In particular look for places where the score was changed.",r/machinelearning,Z0FBQUFBQm0yeGI4VDNkZUpxclRHRWpMa3EzV284eXkweTJVYmRaZjZFaURSMEQ5SUZLaW1LSm1hMUtZTUIteHdSd21DRnFTVDlnRnlEc2JTU3ktanNoUXp0Z1p2SjdSeWc9PQ==
"Walter: ""People have bed accidents sometimes okay, not sure why this is making news"".",r/machinelearning,Z0FBQUFBQm0yeGI4blM5eGpGWjdEUGpvNGttWlI1NTFFblNiVVp6WnFpZWxOVVFwSXlGMVZDajh3bVFxSDhBRUJnZ0hGZ1dwdkRfOERlanlHZXhyTWwwOWRHc0xSdHAxWUE9PQ==
"Have been doing applied research in ML/NLP for over a decade in industry, and I totally agree with the authors' position. There are a lot of interesting problems and findings that come up from the application that academia can definitely benefit from. x

E.g I remember working on word2vec when it was cutting edge a decade ago, and discovering for ourselves the issues with the technique and semantics  i.e king - man + woman = queen and similar examples (they were cherry picked) .  We did the experiments and had the theoretical explanation but never really thought about publishing. 

A couple of years later an academic paper came out at one of the top conferences with a similar finding.",r/machinelearning,Z0FBQUFBQm0yeGI4RUFra3ZCY3pocUFUd3haTVpFV0ZOQW5WMEF6dVhNUENINF91TVItektYU1R6eXNQaG95NmRuRkNuakJNSTVqVXBnczVzTG5GMHJyd3BEZ2FGWXJleWc9PQ==
"In my workplace, i find that actually adding features add more performance to the model than hyperparameter tuning, etc. We’re at the point where our data is in the billions and petabytes level. With a streaming model, improving the model architecture with more SoTA architectute no longer increase the performance of the model. Our analysis is usually what features can increase the GMV/AOV/OPMS/GPMS and what label we can use from user implicit feedback to add another prediction head to increase these online metrics directly",r/machinelearning,Z0FBQUFBQm0yeGI4RnZ3dGhaY1l5VUNxdVVKdzc5ZzZMR3dtRExUQlVtZktBc3ZtVG5SU0tUZFFNWkt0UjBUUEpBbnFjenJmWmI5RGExOFBfemx0a0gyMFQtSHBHdThJMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4V0tSM3dQSTl5ZnVLS1E3ajNfZWZSSFdqbFJSbkFCa1NROWJhalJpYlROd0g5bXZxblUxZ2JudmFFaWdKSy1zR1FoZXpXN1VtVm9qNU5LQ2RLdWVlUUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4YXdIQ0FuNnp3cUpITGo1dU85V3I2NktYbE96VGZKbnplaXlDc2M1TjAtS3N6SnRiNUNVZVdMaU1felJCYkFuNzN6ak5ia1UtaXR4NzBaUTBYU3JnT3c9PQ==
"Well, ECAI is on easychair, so one page pdf is perhaps more probable, which often works if there are procedural errors? ",r/machinelearning,Z0FBQUFBQm0yeGI4RmNoWlhMWGdCejhLcjRlNTdIeS1TdDRQeXh2aG5IVnhwRmVxN2cwTjBfZzRxSm9VOUtWZW1rR1hMN3A0VmQxNzg5eXdDSkVfTTRhV2x4WGkxQWgzXzRXQ0ZRVGpHaDRCNXFBTm5kSDRtVnc9
venv and just install most important (pytorch+nvcc) in the base environment (no venv),r/machinelearning,Z0FBQUFBQm0yeGI4d1E3dC1XZGRvVEFhLUVIM1lPU1pxOWRvRmYzNm12UXFkWWRqLWlDT2Q0Uy1BMVhtNkNDbndqbzdCRW54TVF6cTVxV2ozUVk2aF9leHZuQzlwNkpFOHc9PQ==
"This is my first-ever submission so I am totally clueless. Do you know if the reviews are only shared with corresponding authors? Also, I can't see the reviews rn. Can someone please assist me in finding out about this? Are the reviews out yet? It's 17th June (noon) in my country.",r/machinelearning,Z0FBQUFBQm0yeGI4dGpYZnA5N05nMGRNeFBzSDVPemR5d0QxdDVCV1cxLVBVcEcwTWFMTzNlakd1anIxbUFvU2FvQmFxY3piZHV1ZHM2M0ZJLXJERC1IcnRFejFLRnFJLUR0eTlULXdoeFpzeHlUc1VDRnhCRjA9
"Please read the paper (https://arxiv.org/abs/2406.02061) carefully. This is not a contradiction.

The point of the study is NOT that models NEVER manage to provide a correct response to AIW problems. The ability of GPT-4o and Claude Opus to SOMETIMES provide a correct solution does not show their basic reasoning capabilities are intact.   
  
What we call ""complete reasoning breakdown"" is shown by two main observations:

1. The correct response rate measured over many trials across different AIW problem variations (AIW variations 1-4, see Table 2 in the paper) is very low for the most of the tested models (p < 0.2; see Figure 2, Table 4 and Figure 8). The best performing model, GPT-4o, has average correct response rate of about p = 0.6. This is still very low for the extremely simple AIW problem, especially for a model with claims to solve robustly complex graduate level exams.

2. The fluctuations across different AIW variations (AIW variations 1-4, see Table 2) are very strong. Those fluctuations are caused by slight changes in the numbers for brothers and sisters in the AIW problem, while problem structure itself stays absolutely the same. See for instance Figure 11 in the paper, showing how stronlgy GPT-4o changes its correct response rate from one AIW variation to another, going down from p > 0.8 to p < 0.2 only because of simple number variation in AIW problem. Such fluctuations show clearly that even the strongest models like GPT-4o and Claude Opus are confused by trivial changes in the problem formulation, which should not be the case if the models would have the basic simple reasoning intact, showing that their reasoning capabilities, even the simple ones, are severely impaired, resulting in this observed lack of robustness. 

Another aspect of what we call ""complete reasoning breakdown"" is the overconfidence in the wrong answers demonstrated by all tested models, as well as inability to revise their wrong answers even if explictly prompted by the user to do so, while hinting that the provided answer is incorrect. Also in those cases models insist most of the time that their answers are correct and express high confidence in the wrong solutions they have produced. See Section 3.2 and Section F and Figure 28 for an example of such overconfidence in responses in the supplementary of the paper. Often, models provide what we call ""confabulations"" to back up their wrong solutions that contain plausible sounding text with persuasive, reasoning-like tone, while containing wrong and often non-sensical statements about the posed problems. See Section 3.2 and Section G for that.  

Further major point of the paper is the failure of standardized benchmarks, like MMLU, Arc-c, Hellaswag, etc, to properly reflect model quality and reveal such basic weaknesses in their capabilities. Models that claim very high scores on those standardized benchmarks (eg Mistral, LLama 3, Command R+, Dbrx Instruct, and others), show very low correct response rates on AIW. At the same time, some older models like Llama 2 70B, while having much lower scores on MMLU, ARC-c, etc, shower better performance on AIW than those models claiming high quality. This reveals that current benchmarks are broken - as they cannot reveal even such basic weaknesses as demonstrated by simple AIW problem, and also cannot be used for model comparison.

Have also a look at the repository https://github.com/LAION-AI/AIW. There, code and all raw data (model responses to AIW problem variations) are available and can be inspected for further examples, https://github.com/LAION-AI/AIW/tree/main/collected\\_responses",r/machinelearning,Z0FBQUFBQm0yeGI4V2ZyY0g1R0dweVlWTVRURVdjbTVXaVhRam8yemRBUWNXZ2Vzc1k1R09Bc2pjNUNCTGE4RE0zVC1ra1lfZ0ZmUG9rWkFVSmZmTmxyTzZlemhDR2M3bWdJX05BQjVkZW9mTE5sVHJEMnd5dTQ9
"Good to see our work triggered many comments. It seems though that unfortunately many people commenting did not bother to read the actual paper (https://arxiv.org/abs/2406.02061) before shooting out various claims. Here, I would like to provide some clarification.

The point of the study is NOT that models NEVER manage to provide a correct response to AIW problems. The ability of better performing models like GPT-4o and Claude Opus to SOMETIMES provide a correct solution does not show their basic reasoning capabilities are intact. Complete reasoning breakdown is shown by two main observations:

1. The correct response rate measured over many trials across different AIW problem variations (AIW variations 1-4, see Table 2 in the paper) is very low for the most of the tested models (p < 0.2; see Figure 2, Table 4 and Figure 8). The best performing model, GPT-4o, has average correct response rate of about p = 0.6. This is still very low for the extremely simple AIW problem, especially for a model with claims to solve robustly complex graduate level exams.
2. The fluctuations across different AIW variations (AIW variations 1-4, see Table 2) are very strong. Those fluctuations are caused by slight changes in the numbers for brothers and sisters in the AIW problem, while problem structure itself stays absolutely the same. See for instance Figure 11 in the paper, showing how stronlgy GPT-4o changes its correct response rate from one AIW variation to another, going down from p > 0.8 to p < 0.2 only because of simple number variation in AIW problem. Such fluctuations show clearly that even the strongest models like GPT-4o and Claude Opus are confused by trivial changes in the problem formulation, which should not be the case if the models would have the basic simple reasoning intact, showing that their reasoning capabilities, even the simple ones, are severely impaired, resulting in this observed lack of robustness.

Another aspect of what we call ""complete reasoning breakdown"" is the overconfidence in the wrong answers demonstrated by all tested models, as well as inability to revise their wrong answers even if explictly prompted by the user to do so, while hinting that the provided answer is incorrect. Also in those cases models insist most of the time that their answers are correct and express high confidence in the wrong solutions they have produced. See Section 3.2 and Section F and Figure 28 for an example of such overconfidence in responses in the supplementary of the paper. Often, models provide what we call ""confabulations"" to back up their wrong solutions that contain plausible sounding text with persuasive, reasoning-like tone, while containing wrong and often non-sensical statements about the posed problems. See Section 3.2 and Section G for that.

Further major point of the paper is the failure of standardized benchmarks, like MMLU, Arc-c, Hellaswag, etc, to properly reflect model quality and reveal such basic weaknesses in their capabilities. Models that claim very high scores on those standardized benchmarks (eg Mistral, LLama 3, Command R+, Dbrx Instruct, and others), show very low correct response rates on AIW. At the same time, some older models like Llama 2 70B, while having much lower scores on MMLU, ARC-c, etc, shower better performance on AIW than those models claiming high quality. This reveals that current benchmarks are broken - as they cannot reveal even such basic weaknesses as demonstrated by simple AIW problem, and also cannot be used for model comparison (see Figures 3, 4, 5, 6, 7 showing how standardized benchmarks fail to reflect model's qualities).

Have also a look at the repository https://github.com/LAION-AI/AIW. There, code and all raw data (model responses to AIW problem variations) are available and can be inspected for further examples, [https://github.com/LAION-AI/AIW/tree/main/collected\\_responses](https://github.com/LAION-AI/AIW/tree/main/collected_responses)",r/machinelearning,Z0FBQUFBQm0yeGI4RVZSSm1KNC1jejRBaWVWYnRSbEhENS1KZUt0a1JSd0ZJb1NxV3hOU2swLVdFcDd0R1NuVlE2VEhiSm0wazg0YldEb01GOC05cGotWVo2ejRGY2JwZXZBS3cwTEhIWGw4YTI3a01wMXNEZ0E9
"They are not out, the corresponding author will get it, but not sure about others. You might see the reviews, when they are out, if you login on easychair. ",r/machinelearning,Z0FBQUFBQm0yeGI4ZWN4YjVEbk8xRnpNQ2Rvc3FCeGYxc3ExX2lXUFhua0kyYVpORTJCVVdlSnRlcm1acE9rRnNGRG92a2lobjJBRDlGZl9PVkdUcElEYnlrSXJRU3dYUjZiSVlZVmxFSE0xS2JKWDFOb1VlNGc9
"Ahhh, thank you so much!",r/machinelearning,Z0FBQUFBQm0yeGI4SmFncFpvVld0d3lqWjNleHVPOWdOQ3p2czN1YnBMN1V0WGhmeUJseV9RNFUtNmtTdHFJQUJoZm4wZ1poV2pQWlNMQ0JZNVBKeUR3eThBTzA5Ym4zalk3QkJEclRiWkpuT1pXdThFcGdPUFE9
"I would recommend to read the paper carefully. For most of experiments done in the paper, AIW problems have simple natural numbers in it. For instance - 

""Alice has 3 brothers and she also has 6 sisters. How many sisters does Alice's brother have?""

See Section 2.1 for explanation how problem variations were constructed and Table 2 for the full list.

With that problem, you can arguably go and ask some randos on the street. My bet would be that many folks would be able to provide correct answer to that.",r/machinelearning,Z0FBQUFBQm0yeGI4UXFfNmltcWFBMVl5dzV3WGJzWmNrUnRCTExJeC1MNGVBZk1VaEhMaExPRnZRTXVrOFFaVkFwSlFCUDk3QkFzSnA0WkhqNi1JZnYzSVp6WU54elI4QUNVVVZyYUdnWGtzNzl2M1dSNTJ3OTQ9
"shameless plug for my repo on everything OOD :D

give it a star if you find it  helpful: [https://github.com/huytransformer/Awesome-Out-Of-Distribution-Detection](https://github.com/huytransformer/Awesome-Out-Of-Distribution-Detection)",r/machinelearning,Z0FBQUFBQm0yeGI4bjE3SEg2b2dhc1l3Zm9OU011MEZROHc3RW9PVEFKR3NTeVlqSmVySW1MN1ctbzFKM1ExWmVOSng4RUVZYU9KdkxCc3ViNV9rbHg1V0p4Y0h6WHVTQlZlSzVHX09DaXcwdnAzTU5qTEFiZnM9
issue is open source software could require a different version of pytorch...,r/machinelearning,Z0FBQUFBQm0yeGI4NXEzNkpuLWJVZUdxMjFGNTU2OC1rMVI1Q3BacGlLaFM2UERmMFgzbzRXbUNBTWxEVkJleVQwd0YyX01HMVE1d3RIQllKSUVVV2VOa0lGNVVkNEUtTnBVdFJUWmRRdF83bFNLZHNnNmFiaHc9
hope accept after rebuttal!!,r/machinelearning,Z0FBQUFBQm0yeGI4UHRBZDNjUjFRT21ZTHZyeVJKOThYNlhUMGMtYW50YTJHa2s0c090bVdhNHlGQjh3NXRteHQxUDdKNkpjWU5NVWc0SG5yS2ZieTZwU2RwYmlkcFZnY2c9PQ==
"Yes, I have submitted the Advocate. Good luck to us.",r/machinelearning,Z0FBQUFBQm0yeGI4ZE44NjI5RlFHbzFheWpGYThlR3lacFdVWXYyeWlRYXFXWFkycGx6MmJzVEFTRm5TWGRyTXdQeXh0bHlUWFJNeXZuMGhPNU9QMFBFVXZfQ1lDZFhzMVE9PQ==
"That's exactly the point of the challenge: we don't know that, and we're looking for brilliant participants and teams to find algorithms to attempt to solve the problem! :)",r/machinelearning,Z0FBQUFBQm0yeGI4STVHZUZqa0x3Y0NmMVJaTGUzR09kbUlWZ0NUS2s4RUxJenJiZTVYekdISFZYWW93V2ZmWDNHZUFXRG13VGs5eEViWmdxNXo0eHRpUWYyNXRxUGV2Mnc9PQ==
"If the type of censoring is unrelated to the type of creativity, then it's an issue.

For example, if the prompt is ""Write a clean joke about XXXX"" and it performs worse after censoring, then that's an unintended consequence.

From the article:

>The base model generates a wide range of nationalities, with American, British, and German being the top three. In contrast, the aligned model only generates three nationalities: American (highest percentage), Chinese, and a small percentage of Mexican.

And:

>The base model’s age distribution resembles a normal distribution, spanning from below 10 years old to nearly 72 years old, with the majority centered around 30. The aligned model, however, selects ages within a narrow range, with a strong preference for age 32 and a few other ages between 28 and 35. Notably, the aligned model does not select any ages above 35 or below 28, indicating a limited capability in generating diverse age values.

How is that outcome totally obvious?",r/machinelearning,Z0FBQUFBQm0yeGI4MFFiTTRFdlNXSy1LRzdxZGw5aS1zYjNhdHdTVFpDdDNUMlZaeDZpSTJITTNsOVRyT3ItYnhfMzB3QjVnLWxlenNVLXV2ZlBOSkU2SUFtNVlVc190NTB1eTFRNHRJazVIZGN5enAwQlJ6N3c9
"It really depends on what you meant by ""SOTA.""

In the token dropping school where attention sink was initially proposed, [LM-Infinite](https://arxiv.org/abs/2308.16137) is a concurrent work to StreamingLLM (your first paper) with pretty much the same idea. [InfLLM](https://arxiv.org/abs/2402.04617) is a direct follow-up to Stream, which keeps the initial tokens (attention sinks), recent tokens, and basically does RAG on the middle KV cache adaptively. If we step outside token dropping and only care about general KV cache compression, keeping full precision initial tokens — which is the spirit of attention sinks — has quite some tractions in the quantization school of KV cache compression, where many recent methods like [KVQuant](https://arxiv.org/abs/2401.18079), [IntactKV](https://arxiv.org/abs/2403.01241), and [SKVQ](https://www.arxiv.org/abs/2405.06219) have employed this strategy. (Shameless plug: our 2bit KV cache quantization method, [KIVI](https://arxiv.org/abs/2402.02750) — which was recently accepted to ICML and is [getting adopted to huggingface transformers](https://huggingface.co/blog/kv-cache-quantization) — does not keep initial but recent tokens in full precision, but it is also plenty performant \\[[paper](https://arxiv.org/abs/2402.02750), [pr post](https://www.reddit.com/r/LocalLLaMA/comments/1ap3bkt/kv_cache_is_huge_and_bottlenecks_llm_inference_we/), [code](https://github.com/jy-yuan/KIVI)\\]).

Are those methods SOTA? It is up to what you are trying to do and what your resource constraints are; as such lossy compressions can have very different properties when evaluated against different tasks/upon different backbone models. We recently benchmarked quite some KV cache compression methods (which we will arxiv & open source soon) and found that proper quantization usually gives you well-around performance retention; where token-dropping approaches can take much more aggressive compression on some specific types of tasks that they are good at (and their KV cache footprint can theoretically be constant, which is a huge plus over quantization). Pretty intuitive finding imho, as if one evicts the task-dependent tokens, then the performance is usually doomed, so the eviction strategy needs to be on-point, which can happen in some but usually not all tasks. Whereas if one quantizes everything then all things are a bit worse, but at least all tokens are still contributing to whatever tasks asked.

A bit extra than you asked but hope it helps.",r/machinelearning,Z0FBQUFBQm0yeGI4cG1PYzRtQ3FnY3BvdW1vVEUwMGpteUpodndxZEJrTFRlX2lQNXMyRUlOU18taXRWb21mMFZYWTk0XzQ3RDh4Mk9HbjVGRmN5LV9UTFdUNFZoSEpGN2c9PQ==
"You're not supposed to feed the entire image if they're as big as 30000x30000 pixels. You'll need to do tiling such as with satellite images, and possibly do overlapping/merging or only consider detection far from the borders to mitigate mosaic artifacts.",r/machinelearning,Z0FBQUFBQm0yeGI4d1N0U0lpS21WVlYxTHlMeFg1dzc3VVNoYzF2aUwwMTlFNE42QlEtQmYyLVJiQnhDemljcXltdFlZM3ZIVGtxOExYVnpnc2xzcENoX0tqOVMxb3V6UkE9PQ==
"Long generation is indeed a less utilized capability with fewer rational use cases (code refactoring, fiction writing, etc.), but methods like stream can also help with ""long input, short answer"" type of tasks that are prevalent and useful (summarization, factual qa, etc.).

You might have gotten thrown off by the ""infinite sequence length"" claim made in the stream. I think the authors are more trying to claim their memory footprint does not grow with the sequence length and can therefore support infinite context, but not saying it is only useful for non-stop generation (which is indeed useless as you suggested). This wording is unfortunately kind of vague, so I thought I'd help clarify a bit.",r/machinelearning,Z0FBQUFBQm0yeGI4UEF1WURILXlBOFY5dE43VV9ROExDSVpZeHd2YWRsMVVtS3E3dnBwOWRnbXg5M0JTR1NrZktPelZIby03cFppREhPbWdXcWJ1UEJ3R2hoa3FGdWg1RkE9PQ==
"When do they come out, if anyone knows? It is 10:15am in the UK here and I thought they would be out yet",r/machinelearning,Z0FBQUFBQm0yeGI4dmpLazduTHhTNTNGRUxkc1ZFS2U3cm9sOWRxVWpQczIxQ3V6VGg2QkpLcE8zNVBvRjhwYjhHcnZ3TmVnaG8wZFhNdnlreUR4emtIX2IzcFMwTkNzSGZiMnpwcG5yMk5XVWUzZFJLcHpKc3M9
"Do you plan to use RVQGAN instead of Encodec ? 

[https://github.com/descriptinc/descript-audio-codec](https://github.com/descriptinc/descript-audio-codec)",r/machinelearning,Z0FBQUFBQm0yeGI4SG5LVEdCaWhOVXlaV3lsOWptaHljTW1teERkeDZzQ0NHZHNDQlo2MWJycWtlclVfYnlKdEtYU1lmaldRazZ3MzBzTmN3cEhDMTU3anZpMjUzZlN6aXc9PQ==
"I was surprised too, and I doubt cranking up temperature solves the issue (it will probably answer ""blue"" before giving another age).

I see it as an easy opportunity for competitors to get a quick win.",r/machinelearning,Z0FBQUFBQm0yeGI4OGR4SmV0ZTg3bGZNWXkxb2QxcUFVcTQ4eTRMNExPai1LWFphTlJfR1otelVzTTVjR1FCcUpvTjNQYnFESVgxbmQ5Y1duVktjU2hFS1BOQ1Z6cHFBZVE9PQ==
Why? Are there any downsides in feeding the whole image to the transformer? Usually they are fairly good at large sequences,r/machinelearning,Z0FBQUFBQm0yeGI4OGZoM1R4VjRLTWRPV2wzRWJZV2xJZVl2NzdUU05VM0xsU0tiSGxaWnBzNG5NS2xDYld0YXJYZzJ3VktWY1BfbW9LQThfMlZBZG1xaEc2T3RfSTBDQ3c9PQ==
It's really annoying... We tried to make sure we will have time for that (in case the paper will not get 100% rejected) because we are busy and not students who can prioritize that over other stuff.,r/machinelearning,Z0FBQUFBQm0yeGI4S1JHQW1LbFViUC1wMk5RckJhRHpkVThiRDdITEF0OHNZVm5JcFVwZnl1ODE2dUtaLVRiTmlTVFZFbHE2QXdPWFhfcGZ2cEl0ckUyVlhVUmE3S2RrMnlXVjBOWGN6LU1wd0VvV2pncHdnNU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4bnNjZDFxRjVHNnRTUzFWc3dfbl9tQThyemx6cTVxWmhGZEFRVjI4N3AxYUstSktVcU8tNVRZZjBDeG1mOGJtaVo4bHh6WUtvdHNJd1I1cnVUV3hQS0E9PQ==
Did you receive the reviews already? And yeah: good luck to everyone! :),r/machinelearning,Z0FBQUFBQm0yeGI4MG5lYW9oeVNBSnJySWNpemRuR29CZldQdW45THpGT3BieFhENGVIbG9DRHgwS25TRlJHQkNFT0JnRmtPaWQyZTFZc1NCelFERDEzZVd1MnpneVV5Y1E9PQ==
"I agree, especially with only having 72 hours for the rebuttal period.",r/machinelearning,Z0FBQUFBQm0yeGI4SGJJRlR0aDVyejV5VXdudWlOXy1reEppYUpCeE1lNHNlWTl3c00tN3YyRUlTOG82a0JLNi0xUURQaV9MQjZWaEV6NXVrdFNOajFHSlgwVzFfOXhKMkt2aUpYQnpHb1RyVGRRb1RKeHJWZGM9
"No clue :( but also waiting in the UK. Fingers crossed that they release them soon. Somehow, I'm not able to concentrate on anything else xD",r/machinelearning,Z0FBQUFBQm0yeGI4bzdzWE5oRVhXZnA2a3gtYzhWN3ZSeHpNWWhpSUtwN2lxY3lZQ2FJZWNoektwVXVHWXBVTl9ySk9qSS1FbWp3MU5QZlliUzJPaU1rVXJDMElVcVVsMnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4VHZjY0l2LS1DM2g4R01iUk5WbEdsMk44SDc1MjIta05rS2VySFpuR1pLQWE0ZlUwWktUZXFYNnhEdzQ4WTkzZnhvRDh6WHVBaWtaZnlGSkg5LWlnbnc9PQ==
"You're unlikely to be able to feed a big image to a transformer.

Juste take a 1000x1000 image, thats 1 MILLION pixel.

That's why they are usually either projected by a 2D CNN into a smaller feature map, or that the transformer embeds patches (of 16x16 pixels for instance) instead of single pixels. Even even with those, it already takes a good amount of VRAM .

And even if you could, why would you do that ? Do you need content kilometers away from the object to detect it ?",r/machinelearning,Z0FBQUFBQm0yeGI4VnlOWFg0UmR6Vm93amNUWF9EQVlhLUoyUUhoM3BYTW9ic1U5Y0c2d0NSTzF6TkU4d3hIRXozcUN5WEFNX05uN0FMRWgtWjlpMXVFTnc1elVJR2FxMFE9PQ==
I need whole image embedding afterwards,r/machinelearning,Z0FBQUFBQm0yeGI4TnNZMkxqTy1MR0lQTEUzVTJhbV9HMUlkOFNvSkV1N2t6cEJMUkpFeDFJRlB2TUpURmp0Mjc0QW53eUhrWkpmRlJrc1EtSEdncERyd09KeTB6bm1aX2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4YTYwM3RKQVBHV1pjY2h1SDlacjNQUnFNaGViUUNHTnUxNlUzSjdpX1QwUVBSLUppZlFwZ0hDN1U2VmpiMmRTbE1hUXZqOU5lUU5OWXJZeTNVV2FKMEE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4TGZKN1pJOWgwUzVsdWVJLThVX1NLbndUUG1KelZ6enZ0TlZYMnZhQk9TNWw3ekMyM3FFQ19tbC1LMVFmSmlCektUMEl4ZVJpd1FReGctemJ5bXUzVXc9PQ==
I had assumed censoring was done by a separate LLM. Sounds like it should be.,r/machinelearning,Z0FBQUFBQm0yeGI4bnpHcnVFbjdnRDFUSGZWcGpYT3dlSEpQWHlPOXNpb21SNnh3VmdvRmNzNEJvdEFLdEVFdFRPY3J1a0RnLURzSDlPcUJVbzRBRFZ2ekl5ZllXeFA2VWVGUU1NTU5waDlZMXhWU1hGbTFibEE9
May need an older version of Python.,r/machinelearning,Z0FBQUFBQm0yeGI4U0hmdXdOT1lmTkxWcFpENWRSblQtTEktX0k2OXpiMUkwejQ3TnF5THZPT09nWWZ2VEdmNWpaYWlyQ0drLVJzUDFtWGFwV1EzUWZqdlBrVERsRThZM0RaZ2w0ZXllT3RCLUdLWlI1SDJUYUk9
Me too. My spirit can't support me to do else things. X\\_X,r/machinelearning,Z0FBQUFBQm0yeGI4YURqTk1uMTFNbnNUNkV4RmF2LTNvSXQza25Wa24wUnRIQi1KQUZCNmhDSVVnU0lUYjVIb0JxamxaUUZTMFBDdTczYXB2TXppaG1fYVh4RjhJOEd6SHN4cHU5bG1ZSEdUeExVS1RYX3ZVd3M9
"It is not totally obvious. I would expect it but this result is interesting because we want to know more, based on empirical evidence.",r/machinelearning,Z0FBQUFBQm0yeGI4b3Z2UEFmYUxZZUR3SW94QWZybDJmamxlSTJjWm83RlRLNEY5dWk5bm1jRnJOZkdJN1A1ekVrQ1J1SFJXSWRtd2hHc3VRakFwNkF4TXRvLUNhNGIxZ3AyY0lnU0ZJMUpmNHJKUzZESnUzMTA9
"OP you should look for the environment file for the code you're trying to use, or documentation on their part describing such environment.

The most influential things I can think of are: python's version (already mentioned), CUDA stuff and the architecture it's being installed on (most probably x86,cbut anyway).

IIRC tensorflow has documented which versions of itself are compatible with each version of the things I mentioned. It's all there in their website: https://www.tensorflow.org/install/source#tested_build_configurations

Ignore the fact it's their ""build from source"" page. This already helped me in the past with a similar problem.",r/machinelearning,Z0FBQUFBQm0yeGI4aWI5aUUzSUZmZlJDdWZCcG9odmJ0aFRHaFh5R0xRdk9ZN0lfSmVGY0NHMlVxWXFRMFRZSkNqSExVNVFzaWRwSlBxRVlCZ0pEQUJVTEV0MmFFd2hEeEE9PQ==
"Hopefully, the reviews will be out soon. Good luck! :)",r/machinelearning,Z0FBQUFBQm0yeGI4ZjlQajFrQUpkcGNLOGpLSVo3RjRFVkhCVHNuTEZBcUJTaS1oMS1EelVTUC05WDNGYU5SeXJ2Q3VrcWgwaVdnMGxYUUVXQ3hHdUtpVEpsOTRRZ1ZtdFE9PQ==
"Try to do something simple you don't usually want to, works every time I am stressed :)",r/machinelearning,Z0FBQUFBQm0yeGI4cEhNRTE0SXVnTFJ0Z3VZOXEwVDRzVTBlQ3RnbTZaSE96dGI1blZYeE0yUFZTN0xXLXB4MVZub1BLSmU0SVQ5RGhScnNTSS1LbnpoMXVVS3NYay1acGJXakx1MTVrSzRRVVpfU2Zqc2tXMUE9
My something simple is refresh the easychair webpage :),r/machinelearning,Z0FBQUFBQm0yeGI4OEZrYlNxYlBNTHhSb1U4Z2hHYlk4eE5jbTZwQklneE9ta2plcUFjdzV5cHRuVmVpdEVSWXlBYVBIOEdmZWpqT1B1NjRNS21zcXhhVmRHUVhaM3lYLVFoSVRzMmtIRzJsR1d2TzNhc2dJRFU9
Which country are you based in? I specialise in working on combining AI with predictive maintenance / VA experts to get the best outcome of both worlds,r/machinelearning,Z0FBQUFBQm0yeGI4cGNtSEZSbThvdGpUeVpQTllQY203ay01cjlrWlR2MDd5eEFiak85aWpWWE13WDU4cVZvUnlRZTRleGg4NndYbnFvcmRMV3dOWGNZUG1neU8tTmFyclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4Yi1yZXFUdTRBOU9UMnpMQUxvZU5pQktrSDVoTUdoZlk4R24xWGtuYjcydVlfS2F3U1pKU3dVdkdGbFhKYWlzNEZsNzM1cnh3WjRNRkJhSVc5blh4YXc9PQ==
Can you give specific examples in business where this is acceptable ?,r/machinelearning,Z0FBQUFBQm0yeGI4bnNzb0U4Z1N1VGdVZDJpcDNwWDJibDZ6UTJJSURFNEJGX3FSWGI2R1p3OVFZbVBoU2lNU3R1bzk0S1ZOMGpINzdrRTFvWDgtRzhTMGlqSFlxRlZMZnc9PQ==
"Only is the search space , are there others?",r/machinelearning,Z0FBQUFBQm0yeGI4NFdVbU9hNldCS3NEc2dseE8wMXhUUXUxUEpVNFVRWEFhSWxyYVFBTDlTLVJINlBjRkEyajUwN1dnTTlnb1RFRUlrNHI4QzgteFdCZjRUdkFvUnBCX2c9PQ==
Reviews are out!,r/machinelearning,Z0FBQUFBQm0yeGI4aVo3WEh4eEFOTXNnLUxIejJXM1JBU2RZTVFLeWVMOFJDZHBMdWRldVJmYTZzaU45aFQzclFEZXVJa2k5VHFIOHdZdk5fQlhEQkc2VnhGQmpkNkZuRHc9PQ==
"99% of the time, papers that only test on mnist/cifar don't work on bigger datasets e.g imagenet(which is quite tiny by today's standards). And so are useless in the real world.",r/machinelearning,Z0FBQUFBQm0yeGI4MkZiZ1hnR2w5QlNENTl0RE8tWjN5aXVGd0RrZThmTm1EMWtoLVpBZXFtSVNNb0pCVEZWcFJtSTBaamNVdUwxTTlaLXpMUXZRVkJwelQ5aXZqR1BNN0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4cXh0Q1BaUFRuaVNPX3N6cXA3X3dsazZHVVZ5RHNqdkFPcEx4RU9UdkNMUS1nTUJaVmY4OWl2eFlsUGZHQm03eGp4aUxlb1ZfUnRNNEw1NEppcnBabEE9PQ==
Can you see option for submitting rebuttal?,r/machinelearning,Z0FBQUFBQm0yeGI4MkpVUUpTN0NPUTBONDNXN1FybEpTbVdDYWEtQXFzNVV5dDVlb1lCLVNTNVVWQnhXV3lxZW90UVF2WmlFTk85MEJMVkRrVjRVaGphVkNQM0V4QlR4NkE9PQ==
"Nah, not yet. Also weird that you cannot update the rebuttal after you have submitted it.",r/machinelearning,Z0FBQUFBQm0yeGI4OXpQNU1lMXRvcHlPaVVVZ3cxTFdMZWRHQUpxNEtxcnhyTklqd1FXaWFIQmtvcDk3TXd6UHZ4TXRESmwxVWloY3gyanJFZUNqLXgzUEUzRkJvUUlvLVE9PQ==
You should post this in r/learnmachinelearning instead,r/machinelearning,Z0FBQUFBQm0yeGI4V0RyeVlMcVhvaWpTNU4xY0FvOXVyY3AwY1o4YThqSW13cVFabjhzRi1aUFItWUNSOTdYMEVycXhYVU1fVTZGS1lOTHRiYlhNUlBWVmlMR3p1eTB1ZEE9PQ==
"thank you, will do",r/machinelearning,Z0FBQUFBQm0yeGI4V3A2dTFFNmVoc0c2aThEa2h5Z1k3c2VXeEpOQkJlWHRsVDVzeS1JOEZQR05wbHRMeXF4cDlGaVlaeWd0X0ZtWG9wYVFUVWgxRUpVSVZ4eXNYQ2NEY0pmQXhTUUoteEVrYWJBekZBUVZodlE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4WlRSUlM4MUpkQzNLVGhYNGFsRnpQT2V1MzNySE5jOHRmd3hENUxzQmFtSFFuZ21LWlR6Z0tOcGcxdE9ETVdqNTJOSGM5WWJzZUxxcWpfeEhuYzcxMEE9PQ==
Older versions of python point to different PIP repos?,r/machinelearning,Z0FBQUFBQm0yeGI4S3h0TXY3bTIwSEJDSmhBRGt4eEN6b19scTRwUzFwSF8wRzJBb29fVGNRRWFKeHdzb0VnU3RpSFM5TVdlZkxxc192ekR4cUdoSFpzYjY3cm1PUEU0YWNOQk5DT2dEZlJETXkweXJtSWdpTDA9
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGI4eUFxMEtQWUV3RnU1OGZCb2EzLVVKMGxmeTBIakxqaXRRZXVQMFFhM0ZKbEF4ZjRIMmtVdHdxNk5ZcXZHa2Z5ZHdkMUYzTEktOEpNdjRtZThXQXgzcjNJTnRrS1B3Ny1zM2RnWlV6WWswNWM9
"That's a possible approach, but it is more expensive. Not only are you running the governor LLM in addition to the generation LLM, but when the governor detects a problem, all it can do is pass some additional instructions pass to the generator and ask it to try again until something passes.",r/machinelearning,Z0FBQUFBQm0yeGI4UVg2a1RCZDdKbXR4anlQLU9wVEdwTXFwZUgwQzB3NzZBRHBKZk5BVVlLdUx1LVUtU0F2cHVSOEdzYTgyZjJNT1RNR1gxT0NXb1EyMS1TVFRjUkJrRkE9PQ==
Does anyone know how to add it on [https://papercopilot.com/](https://papercopilot.com/) ? Do I need to create a github issue?,r/machinelearning,Z0FBQUFBQm0yeGI4ZjZQUllFLWdrRGc2eTBPT1Y4ZnhwU0l2YUt2S1laNFJCMWM4VHlJVWFyYjdxM3VldTViVU5QUWFKQ2FSRnFjS2RIeTl3RUZfdHFGNGtfODdQYWZEUGk2bDJFaTdWNko2dE1aay1aRDN0OW89
"I got 3 reviews with 7,6,5. I am not sure how good is this review. Anyone has any experience with ECAI before and can tell how good/bad this is?",r/machinelearning,Z0FBQUFBQm0yeGI4T05EdjJBMFF4Q2RmOUlTbGVNOFNEMXNCTkQ5NGVjb1ZNYkFjNHRsal9aNUQ4SXpiVFdFV2w0d1BmYXluMXZHMjRUZk1KaURQajh4YVA4YTY4RHgwcEpJUUZJS0dwUVBBZzRZRk1fS0xlRlU9
"> Convert to Torchscript Model

Why not ONNX? You can go from ONNX to many different backends. TensorRT, OpenVINO, NCNN, TFlite, CoreML.",r/machinelearning,Z0FBQUFBQm0yeGI4VjV3eU12anJGbUMyM2J1d01ZdEdob3YycnNJSlNzQmtKN2hlSWdWVTg5MldrVDAyWmVuY2FELVRHVGk4X2xxUHM5d0RFR3lMY1U0aC1BMXl3TlV5bGc9PQ==
Maybe a classification model to inspect the input and output tokens before sending to the user.,r/machinelearning,Z0FBQUFBQm0yeGI4MUp3NS1xVDZVV2ZEeHQzR254TFoxN05fY1VjVXZuYm5iVlRwRXJ6M01vTFZmd1pzdFlrRWN6TjBMZ0ZMX0xDOExUVm84Wl82VTNiMFVxMDE0RDFxRG05NlduZUZRR1hBV0w5SVhiVDJUWUE9
Yes.,r/machinelearning,Z0FBQUFBQm0yeGI4d3JxZ01ScEpaNkRwSDdhU0FhaV9Td2tuNHVQR3JDSHpqWFpkVDJudGRyQUJWY0pFcGV5REljRzhDTlhfbGE1Tm1RSmxCdUNFc3dGRjlJb1VNcDc2dEE9PQ==
May I ask what grading scale this is based on?,r/machinelearning,Z0FBQUFBQm0yeGI4NW5lTlMzS1pSNXZmV09HUGxhWjFhOUtvdmpQMXVQMDJpWmtRWTFsZ3pNSmU2c3B3QlhNbWFfNVNySUZfWVBhQXFqd1RQb2V3Wm05c0plZmZPUTVCNng1Rm10WU5hNDkyM2g4dkloWWwzV0U9
"Since Llama doesn’t have a publicly available dataset, how can we be sure that these results are not impacted by data leakage?",r/machinelearning,Z0FBQUFBQm0yeGI4Um9HcHpZejU0RWtod192dDdwazZuM3BnaE15cHdIYm16U0VYcm1jNm94MF9nMGk0a1g5Wkk0TUJFelRaUEJQc0xfcVJZVkVtd1E1a0JrQUlrMW1PQVE9PQ==
can it be selfhosted?,r/machinelearning,Z0FBQUFBQm0yeGI4WTlGSHBrdWlqaWFid0dBRm96RHhKVVZ6d0NsemROVFZzblR3RUtaX0JJODk0REhmQU1kUy1pTFV6TzM3dERROXlnWnVvNVJlZU9tZ3VPajg1aFBpYWc9PQ==
1-10 with 5 being borderline (but tending towards rejection) and 6 being borderline (but tending towards acceptance) and so on.,r/machinelearning,Z0FBQUFBQm0yeGI4SVhScjZDbXhrOFd6NEY4dGNuRERpZGprR3pIbWcwQmktVkZ6LTZlV0NfdEZBd1lJSlA2c3VqZjh5Vmp4MXlFU25ZVk1HOHYwSHdfTHF6UWxsbnk3SHNXRXBPNWZnbWVQT2paTGxlcjhUUDQ9
Thank you so much!!!,r/machinelearning,Z0FBQUFBQm0yeGI4V2NPQjN2cWJxc3l1YWNjZ1RTMHB2ZTdLRVVJYXFpMVo0bEZLWHBKcGZ4YnVaN2dncGhhQkNPNlg0cXRsbWFramRQX1QzbXExdWdhTEQwdVN5UURrbjQ5RHVFS1FXeHB2ekY4ZTU0ZFhoSmM9
"I now see it under ""reviews""",r/machinelearning,Z0FBQUFBQm0yeGI4dmoyWGd3bWFpSUJ0ZUhKYkFDSmE0bjVBUHhvcGdTSXVSeFRteGJaNzdhYUt2X1FSb1VFbFRnVUFpSFQ1Zm5RX1JoNE9KRkNVWkR5M2ZfYVJ3S1E1dlE9PQ==
"Well the versions of TF are going to be built against different Python versions.  See here:

https://www.tensorflow.org/install/source#gpu",r/machinelearning,Z0FBQUFBQm0yeGI4OTJGZ1BOMHdYYkRMSWk1bnRuTVNDLUxqTl82ejBITW5FWDE4eUZndEtxdlFBTlVVSjAyeGtESURvNUhSNmNnZVB4cHNmNkdQcjZHNDdmSkhjODFEeU1HVzlmRmxncUZRWGljT3F1UmNTX2s9
"This chapter from chollet should help a lot, I think.

https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter10_dl-for-timeseries.ipynb

This is only the code but perhaps you find the book somewhere ;)",r/machinelearning,Z0FBQUFBQm0yeGI4amY1S2NySlc0ZXVwYU83MHQzNlFJR0FFZkk1ZUN4YjZKMHV5bzhaRGctcTJrYnJmYllMWnROTnRnMDdOcWRWelFneThwN2txSjNhZFB2bU5KZlY4M3c9PQ==
"Good point! Are onnx models good at handling dynamic conditional flow?

Onnx is definitely a better option for any non pytorch backend in production",r/machinelearning,Z0FBQUFBQm0yeGI4THhXRGhIeW0wNG1GdlFpYVBaVFJxMGQxVi1ITG4tbGE1ZjQ2ZFphZkVPYmdlQXVfdlZrMDFDWjF1RE1QaFBleW1YT0pkQ0drLXEtZUo1V2dFZjFuWlE9PQ==
"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter10_dl-for-timeseries.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/fchollet/deep-learning-with-python-notebooks/master?filepath=chapter10_dl-for-timeseries.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",r/machinelearning,Z0FBQUFBQm0yeGI4bUVUQWxfTElhdHhpMFZFb3pEODdfNXFMMFo0cDZrZlQ4QWM4MGtWVmZPcW1nNk9hLVNXRDF0Nnl6R0NqSjVYalNhS29mZEJ6YmZVZmJlaXJCTUMxQlE9PQ==
"Same doubt with 7,6,4",r/machinelearning,Z0FBQUFBQm0yeGI4MGQ1SExGa2lWMEEzR25Kak1DVDJYM2Vsdk9GNjVNdTFodWhMcU0xVjkwclRMQW5YQVpIZHhHb1hRdkR4MTU5SVRDZUN1Q1A4WlZEWFlTX1F1eElMcEE9PQ==
"Did they borrow the ""Alpha"" naming scheme from DM?",r/machinelearning,Z0FBQUFBQm0yeGI4RFpvMXMyS3F3ZUI3QVFMZGR6ZGdMd19LWVZvcEQxcl9saUx3UUIzYllTajZIMmo4ZC1oeXlkQ3h4a0pJVUNIVXlOdUltYllqRDNlSTBicG1HQUUxYXc9PQ==
"Yeah as soon as I saw Andrew Ng’s explanation of debiasing I was like “yeah, take every human nuance out of every word - good idea”",r/machinelearning,Z0FBQUFBQm0yeGI4ZDVwbHdQdzhIdjhUZlR5MmM1bEEtd1kzMnZHazFHT2l4a2x1SUp3bHlMcTZoSUtaNVFrOENtUWpuQVdmVV9qZFFpelhJaUh0amlCNEhIZWFuV2s1dFl6WTJzb2hxM0l4S0VMaWVUVlhzaU09
Try use  https://github.com/paul-gauthier/aider,r/machinelearning,Z0FBQUFBQm0yeGI4NTc1OXVSR09pdU5Oa01lT0dOU2ZyaGZYNHp3TzQyUTJ1ZmxTS2pYUWxWZWdnc0ZNNjNibDhrcGdWS2RfNVNIUG5MSEstZnZwV25nOXFaRTVuUG1reG1XOWRCdUdQaE5ibG13NV9PcW1NQzQ9
"First, I am very sorry for your loss. Having to go through a Master’s degree and a PhD in that situation must have been really hard. I am a junior ML engineer in a big company and I had the chance to speak to some “higher up” managers/VPs and they told me that to be a manager isn’t to know more than the people in your team but to know how to utilise their knowledge as much as possible, to put the right people in the right positions. Having such a background is good enough for you to supervise them properly and let me tell you that most of the managers in my company are non-technical or have a completely different background. The managers also while getting promoted go to different teams that work with completely different things. Your responsibility is to align the needs of the company/ your responsibilities, the resources given to you and to manage the people accordingly.",r/machinelearning,Z0FBQUFBQm0yeGI4R1RLcTVpRnZURnhuZVU5MHZqOG83cjFKbTVidk5xbFNFZjNOWl95dFE1QWw1M0pOaEswSm1HSTVaWXh1Q2ZwRzQ3VEFHcVlHbGlxVnZzSGFvX3Z2S0JyeVJQbUpMRkcteEtBNVltQTJGdzA9
"4,5,6... First time to submit papers in my lifetime. Abit too rushed indeed",r/machinelearning,Z0FBQUFBQm0yeGI4ZnlNcUJfZktsY0x3NEdnNldCZE9Vd3FqNnFzUHpadEItaW1aUEhwVFk1UDgxZVZxTmp1ZU5xaVl3T0ZHc1I1MzNFSkZmRkNFcG9aand6ZnRaSmtVOXc9PQ==
What do you think? I would say it is more than excellent.,r/machinelearning,Z0FBQUFBQm0yeGI4b2FVbTJPUHFweXBMbkhOcTVId3RhTWMtX01FYkdnemItUW5tYUJGZDh1RlBtQks5WHlUY2hyZWVfRklYNkJZTE1CZDByTmtweGFoNlEtY3RaOE94MEttN3lMRHVRRm85c2pfU2FweTdPaU09
"Same question. The reviewers had good comments by the way, which rarely happens.",r/machinelearning,Z0FBQUFBQm0yeGI4RnoyN1FROGFDLU4yLXBOS3RrbEVtN2hFX1c3SlBUS2RBbU9UWVhCdHJSNlFJbElBNzM4bm9yMFVmT00takV2ekxVZmEyMldiaHpyUlJoeUNsR1h5OFpPc3dqWE81eDlmblUzdGsyZDJiZ2M9
"> The best performing model, GPT-4o, has average correct response rate of about p = 0.6. This is still very low for the extremely simple AIW problem, especially for a model with claims to solve robustly complex graduate level exams.

Strangely, I was just talking about this issue last night with someone.   You wrote ""especially for a model with claims to solve robustly complex graduate level exams."".    The question here : where do those claims originate from?   They surely do not originate from researchers like yourself and your colleagues.  Instead, my best guess is that they originated from inflated corporate claims.   

And therein lies the rub.  What was supposed to happen is that researchers exhibit robust complex reasoning (and planning) of LLMs under controlled conditions -- and then afterwards -- go to the press and media and tell them the technology can do these things.  

Instead everything is backwards.  Corporate PR people make claims about LLMs, and then researchers scramble to confirm or deny them with research.  Often showing that the hype was inflated or worse, entirely false.",r/machinelearning,Z0FBQUFBQm0yeGI4Zlg2ZFRwdG10bUxsMVNpbzRMTUdQbnphVG52VXp1TjhRY3ZaNlJSX0dRM1VYS1Y4dmVSclhsLVlKZ3NjbGRRT0RpOWhrZVV2UVl3aTBWaHV4ZkgyT3c9PQ==
"Voice AI is a scam I tried the free trial and got charged 15 bucks for it.  
The program isn't even worth that to me.",r/machinelearning,Z0FBQUFBQm0yeGI4RHc3dFZpNU5XVGxQaDJjZTlvWmdJQUIzTGxiTU1JTmFCazFSeTBwdHowUkJELVJ0ajhUd3hvMHQ4SWtvbE5rekdIbTg1Z0E5RjhobDdYakVhcjNnQlE9PQ==
"Hey I got 7,6,4 🥲

Do you think stand a chance or even consider for submitting rebuttal?",r/machinelearning,Z0FBQUFBQm0yeGI4RXdWTm0wUmRoYmVGazVOSk5rb25lMktiaVNHNG9Ea3VEMGtROEN3U3BHMUdfMWxoRlZJVW9CTFlyUmIzODZoY3RwaVlPVG90ZHE4YlhGUF9jeFNMVFE9PQ==
"Mine is quite mixed. The 5 one is not so descriptive, neither is the 7 one.
Plus, Idk why we can’t see the confidence. It makes the picture clear.",r/machinelearning,Z0FBQUFBQm0yeGI4YVUtVFhUbk1FTVAyemJEcGlvZFhyY3NyS1A4WHRaaWNFc0EwdWx0SFJxTU4tZDM5cHpsSFlfSE9wQnVqalpCNk45V3hYbENmVGNSNzc2cWJVd2JkampZUDJJb3NUU0k4QzFTMDFNaV9ob1U9
That‘s definitely accept. I’ll be surprised if it doesn’t pass through.,r/machinelearning,Z0FBQUFBQm0yeGI4enVSbVItRUdyMEtiR2FnVl9QMXltemV1RFFQNW5iZXZTMi01dDNVYzNnNDRadVAyeG1ZMDJ6WHlHMWJ3NmQ3M0lWVHUwTGF2Z3QxM3hKNE1zanhFWkxKWFdFSDRkRFZiWW1aYjVJWUhTSjQ9
"PhD candidate here, I believe I have significant papers, and still don't know the details of BERT and GPT, it is just not my field, I believe same applies to you, but it does not mean we can't know if we want to, we just happen to work in a closely related area. My best vibes to you.",r/machinelearning,Z0FBQUFBQm0yeGI4UEdnaS1aWm1rZW1IT1owTWJqOXFRemVZSkxud1V5Q3FsejJiaXhENGVtNzNKXzFLV2Y0Z2VtYVE2TjMtRWowckxvakdEdndJTjJOcTEwRHpLbG1iVkE9PQ==
"So you know you are unqualified for managing these technical people? That itself qualifies you, at least you are not one of the stupid but confident folk most managers are. Also, no matter how much knowledge you have, you won’t feel complete. That’s a good thing, keeps your open mindedness and drive intact.  

You should focus on increasing team communication, giving proper credit, working on unblocking team etc",r/machinelearning,Z0FBQUFBQm0yeGI4c3B2ektQR0FmRjhxTkpRbF9HbzRtYlJSclAxSmFPS3c5Qi1mRU0zaTNweFgxNjJWM0pIX1Z4MDliWW1xLWxMX3ZSQVB4Z2hvT09TLU1lcjY4VWZmNzgwLVpScHAzRjFuSEpuQlIzbzg2TDg9
This is really good advice!,r/machinelearning,Z0FBQUFBQm0yeGI4US14bTlENXNJWlV2Z2FOX25oamljQV9QaVI1R1FXMjdGNEg3YmU5YmN1SFFRbFRfMDdtSmhyWV9PcDFDcTNYd29MZW81SktGVjhwa3NBc0c1UjNuVWc9PQ==
"5,5,5

😬😬😬

What're my chances?",r/machinelearning,Z0FBQUFBQm0yeGI4ZjFvQW81Nzc3OUdmb0NRcTZjMjFELXlfaHdrRTFXWFdzRl96LTFBSlJhUGpHNFNSMTB3aEswVFc3cmhxRndIYkxaSVREbWR6X09sMWYxbmpkLVFDNEE9PQ==
"I've been in a similar situation where I've experienced analysis paralysis due to the overwhelming amount of information available. It's easy to feel lost with too many options and not knowing where to go.

My advice would be to take some time off from work and other responsibilities, and instead, focus on listening to podcasts that you genuinely enjoy. This can help calm your mind and refocus your attention on what's truly important. Many people today struggle with artificial ADHD, which is often caused by the constant juggling of multiple tasks and ideas. By taking a break and listening to podcasts, you can give your brain a chance to relax and refocus.

I've found that this approach has worked for me, and I hope it can help you too. It's a simple yet effective way to clear your mind and gain clarity on what you want to learn or achieve. Eventually, you'll likely feel the urge to learn something new or work on a project that sparks your curiosity.

This atleast worked for me, i really wanted to help you in any means with my limited wisdom. Hope it help, take care!",r/machinelearning,Z0FBQUFBQm0yeGI4aHdkWmZYNDdscm9HaHBvM1BYem56eUo0aGtlTFdlWmM4bmFfSldQd1QwOHpQNUhpdG15cW5rMV85NVkyOVBjenhsa3FMeUN3Vm44UC1VU3U4ZjFralE9PQ==
"Lion became my go to optimizer, too. However, I always need to tweak learning rate.",r/machinelearning,Z0FBQUFBQm0yeGI4aWJTWlA2NjlfcUxSV1BFWkl2NzUweWJfd1BYc1VPWDRqWlRjRS1rQ3JHV21UY2prdThpLVhpMkVjckpIaVJKcGxLTXRWRjB6TWJOVFZ2cGhoR25pVEE9PQ==
"the answer is most companies use rules of thumb. Things like if its stuck in local minima, increase learning rate. If its taking too long and loss is ping ponging, decrease the rate. Start with a default rate. 

Finding the most optimal rate might cost more than getting to good enough",r/machinelearning,Z0FBQUFBQm0yeGI4dVJnbnNYTWI0UTF4X2NBLTJKc05yam5mYjVDaERlQTNoRWhiSDNwNEV5UWlJNk5neVBrdFByWGsxcGpmdzl0Yzk0N1VNYzdqZUZrNmdVTXVJNk1ORUE9PQ==
"7, 7, 6
What are my chances? First time submitting here",r/machinelearning,Z0FBQUFBQm0yeGI4NEtrSWJqME1QYWhRbGYzbmZDZEFob2RLMUZpc2U0NFc4bXZ5SmJlNjhCWW5pRG9LcEhiTzM2NDR4U2tjWTFDeDN0cl9RR3Fnb0lWRHViQmZCb0J4bkE9PQ==
Good chances tbh,r/machinelearning,Z0FBQUFBQm0yeGI4WG04bWlYSHF5SHpIUVhpeGV5aVB4eE5MaXFHWnBrVmRkajlHSDlUYlMyRUVyRmFCMTRoQ0JDcHR5NGRPaDdYYUVtdHNpcEFBaE9QM2RLS3lrdjYxRVZWN2JIRDQ2VWdsRFcxdDE4anhEaGs9
[https://en.wikipedia.org/wiki/Automation](https://en.wikipedia.org/wiki/Automation),r/machinelearning,Z0FBQUFBQm0yeGI4RFNhY3FYUWRNOWhJN3EzUGJtS2RVU3VWZ1o3UmtFbmNEUHl1R0trVUZzbzZQZzM2azFnZEo3RktaelJ6OEVkQmdLV3lTUFB3bERKT1ZrWU91enRkQXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4dmlGdUFYV2xZSUE3QTdVSGdLN3ZqOEkxaW1ZblFhRF9JUWtKQmY3VjdLSzdzOTFpbHRiby1YbmVWNDIyLXBFai1tNF8wSGZGNWp0M3ZUODZiYXJiVXc9PQ==
Mine arrived!,r/machinelearning,Z0FBQUFBQm0yeGI4S0U0NDlMQzFESUJIU0hWZWdnNHRid0tvU2ZEYjJUVnJwMnd3NW5pMDdkeDJZOXhteXByS1kzaVpod29tYlhRbEJGaF9WQ3RKWFpkaFNKRl90eTFQNlE9PQ==
"7,6,3. What are the chances? Should I submit a rebuttal?",r/machinelearning,Z0FBQUFBQm0yeGI4U2wwblZpOUVna0VEdm9RWGROODQ0aUNGVzQtYU9NSHZHcVh2cmxEZlZBQUlRdDc1NEFXNG9URUNvRHV1eHpVRUhqWXc0cjVyMzFUSk9xY1lNUms5anBmTWY3UnJQOVJKVktUVmxpRTRjcUU9
"I've never gotten the chance to work with it, so I'm not sure about its practical usefulness, but there are some results from tensor programs that show you can use smaller models to find hyperparameters for larger versions of these models. It's called Maximal Update Parametrization.",r/machinelearning,Z0FBQUFBQm0yeGI4dW5qZXZCYXU5UExWQVIyblEyNmpCRlJCbFY2anRaOW9Dbk1LUEc0TDZ2RHB4UGRMdEFDaUwzOTZlLUt0azVlWDlGYzRFWDAtSFNrcHlJNC1JeUVNZFdWbU8zQXYyTGxzb0pqdlhSZFdqcXM9
Is this based off Microsoft’s paper/project with the same name?,r/machinelearning,Z0FBQUFBQm0yeGI4VjBsQ2lDQ0Vvbk53d2pTVmFScVQ0endqbURtVk9sSFdad2hNMy1OeFRSdzlMVi1MYlZwOGJ0VU1fMWU2NjlDSEV1WDN6eU9IeVBjWUExVzkycmpGMEE9PQ==
"Learning rate is probably the most important hyper parameter to optimize... However it only needs to be the right order of magnitude so you can try a a few 10x , 1/10x etc to see which one is the best",r/machinelearning,Z0FBQUFBQm0yeGI4UnVjWWI1eXpGVTFzQnR0R0RmVUZ2XzRjU2I5am9qcGJKZU5KVGw1RE9MSURWQUZmOU1WRjNadVlYc2lrRm9WbUZSMEh3YUNQMmNSTkhsTEJsX0NlVnBsYXh4R0hSaHBJZTl2OThMMWdBcFU9
"Let your team work through technical hurdles that involve solving the problem, and your goal would be to institutionally pave the way for them. If they're going to need resources, try to get them before they're needed. Is some org in the business constantly being an obstacle? Your role is to go to bat for your team.

Separately, foster an open communication environment, and you'll also find yourself learning a lot about the domain too. So while it may not be necessary for you specifically to solve a technical problem, you should be able to have meaningful discussions and feedback fairly shortly.",r/machinelearning,Z0FBQUFBQm0yeGI4TTFnbU9pQ3BWZWE4bHdfRWZ5NGJUOXMzT1BxTkh3ckJ4MERCc1BQaVlZbmtqVkprTGJOdjJWODJDRHlXdWxYc0lraXFuTlVMRDYwNkVVLTlaWWZyT2c9PQ==
"Get more technical i.e. study harder and try to gain back what you lost, or be less technical, focus on being a lead/manager and use what you’ve learned to status those who do the work",r/machinelearning,Z0FBQUFBQm0yeGI4Ykk0MUM4cW0ydmtKazZXa2lkcGdIcWFfUGx0RmtKZTZzd0tyM0NoWXNIYkVkVjA5ZE9UdUxNN190WXBEeTBfeHowejUyVnliNXVJeGk2d21mY1BIY2ttTmpSQlIwNzJiQXpEZkRYbGxITlE9
"it seems to be a medium range score, however, you should submit a rebuttal, it's only 800 words.",r/machinelearning,Z0FBQUFBQm0yeGI4elBLaW5FOG94WDhSakk2OER3ajNKR1RRSGVsY1NMUEQ5TERMeW9JRzl4Qng1NXFhb0FvNlBOWDhpRnRQLUZqeXJMZnVwQXdSX0dsdWZybmRoc0pKVEE9PQ==
Ok thanks for reply. Also is there any chance of score improvement after rebuttal?,r/machinelearning,Z0FBQUFBQm0yeGI4SkdadkkxanJlQUh2MkQ0YXdPeUkxNjE0bWhnX3UtUExOazZaWlM0cXlSLW02OFlNNHBMcmVmcVpWcFV3dmwtamZ0TkVGd1NvbUVlZGY0VDY1cllEZUE9PQ==
"So… if you want your LLM to generate engaging ad-copy, you just have to accept that every now and then it’s gonna slip in some neo nazi dog whistles?",r/machinelearning,Z0FBQUFBQm0yeGI4cmNQbkRtWk1CUE1MMkJwYi12MFBtYjVnOUFKcGVUSl9jWUx3bmJoQUpzVG1SeXVlT0FhcTBfNVBJY0tlVHhlSmZqZGYyZENXQUVCeXY3ZHJ5dHgtX2c9PQ==
"It's possible, try to improve the score from the reviewer who gives 4.",r/machinelearning,Z0FBQUFBQm0yeGI4QUo3c0g4MUstRHhLR2lQd3ZQdC1URDVUNXp5bUxhR3d4c3ZQaVB6RXcxdG1zel9aQjF1OGZmOUxpcFROWndFLTFjcHEwUTBxRzBIRkRxblJzY3pMNGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4UkpRRDVVN1FRSWE4VEw3ZE8xX2JXSFBVZnUzLVJsWEpYSGxaaGZad3JMcV9teVhHZ0lRbTZOaFYyelBjS2RIY0xFVGg0RUVMRzlwSHZYRWU2Q2ZJYkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4RHFCLVo2V2U5X1ozZTZaMGRKbm9odlZoMzI0NnYzQjVCNUFJQ1c1SEh4b0F2TUU2QkU5TmdSeF93NW9zV3ZvOGwzRjBLZjdHa0UzNzk1UjJCZUFGVWc9PQ==
"It means that the paper is generally pretty good, but you will have a hard time convincing 3 reviewers.",r/machinelearning,Z0FBQUFBQm0yeGI4MDdSbGtCNGtJU3FEbnRIS1Y4ZHl3YUQwemZEZTZJTlBucGc4bVplMUZqeUVRdEx0XzhHQTRCdDJQTHAwazNXOUs2V01OeUk4SmhwOXNpMUE0UW0tanRDa0cteTBZYWRwSVZjWnZuLVZ6VGs9
You have some sound experience that man in the industry would pay for. Hone those leadership and roadmapping skills and use it. Leave the technical to the scientists,r/machinelearning,Z0FBQUFBQm0yeGI4andRbnBMcHV2d3YxRmlhWW5tbllWWkNLbkEzVXVEWHdMVWlyRnU4RFFHeF83QURUYlF3MUx1QWtQSGtTaG1mSGgwdURVbkFBaVg3YTVDSWM3bDdBU1E9PQ==
"There are a bunch of second order approximations. I think the best known one is KFAC and its derivatives. I’m not sure if it’s actually being used in the wild or just an academic exercise. My best guess is that it’s the former.

This is a library that implements a few second order optimizers including KFAC. 
https://docs.backpack.pt/en/master/",r/machinelearning,Z0FBQUFBQm0yeGI4U3ZKLWZsdllHaTBqSGstX212MWZMSUZxOXFJV1Y2UGZMVmVXRGdHVXZFZ2hHOE1SVTVTNWp3ZTZHUnMyMUJwNDQ4RmsxUjFpRnF3NXJ3SDJaNXZOc3c9PQ==
"I imagine instead of a ""governor"" you could make an ""editor"" llm and have it replace problematic bits all on its own. Still expensive but not as bad.",r/machinelearning,Z0FBQUFBQm0yeGI4aU41d0pORVlpQUZEVFhfVDBDYW1jWWxwTkF1aW5QTHYyVE5VTkU4dU1KVTUySDlGUlhWbjZPNU10eEp3Um9SMEtZNkJBckFGLW85NEx4VHRtTzdPM2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4MkM1NEZMOEdqUTE0SGg0QVA2S3V6U3NsTUtrbzdOODh4LUdUcjRhSjEyNVZMVUN4TUp4Tnl3dWhXVHFteWlUREI3c1g1bVdWMzMzTUhUMXNHbUdod0E9PQ==
"Hey, my career/life path is a bit like yours (details in mp if you wish). I've got a huge imposter syndrome too. I've got a nice opportunity for a new job and if it helps, your path is an inspiration for me as i'm going to try going into AI management role.
One thing you have to let go of is the need to prove yourself. Easier said than done I know. What's important is what you feel like doing : try it out and own it. If it does not work out, it'll be another valuable experience. You can do it !! 💪💪",r/machinelearning,Z0FBQUFBQm0yeGI4NS1FNWtaLWdlQWVhRk5aV2Y1Ql94S2Uya2dzQk5pQ2ZWREFIR1kyM29GQmFnSkhaN3FKajItMjhQNnhYOHpSbElPUFVCMHZhcVZhbGRKa0dkenJ6Z2pwTmxPNm5oVzk1Wnp5UDhiazBkUjA9
"FYI, haven't received an official email yet, but my paper status just changed in CMT. However, the meta-reviews/area chair comments are not yet visible.",r/machinelearning,Z0FBQUFBQm0yeGI4VW13ckpqQ0RrRXZRNkNBU0JUMUxFX1Q0eFNhdDZqNUg3MTloTG11T1ZhR2lXbHNuUG43NzBhQV83X200Z1B2VXJ0NDFTLXFFMzVjdDZsa2o4SzdKaWc9PQ==
"1. Feature engineering. I don't think I've ever used all the features that I could think of!
2. Try different models. Hard to say specifically in your case because we don't have the details, but you can always try a different model.
3. Ensembling.
4. Transfer learning (fine-tuning a different model for your specific task).
5. Hyperparameter tuning.
6. More data

These are just the ones that come to mind off the top of my head. You can always try something else!",r/machinelearning,Z0FBQUFBQm0yeGI4YUs0OVB2UFh2QnVqZnZxQ29VZlFoLVZiSkNXcjM5VlhxQlY4emRvamVxSmVURWFLdTF3LV9UaTdxT19tcXpUZmlMRHNUQ3hmRHNrSXA2Wm80NF9lRkE9PQ==
Same,r/machinelearning,Z0FBQUFBQm0yeGI4S1ZWR1N2UFBzYzFUam54cDY1UHNvSDk5MHhUdjRRaFhLY2ZzT1NIRU42QS1PUWhvNGpMNVltTHM5eWNwelBLQkRleDNkM29vcFNmUWVTeUpLN1ppVGc9PQ==
"thank you so so much, this has helped A LOT.",r/machinelearning,Z0FBQUFBQm0yeGI4UElsV0ZvZTlVNWFLWG94Nll2VE9qZXY2Vk1aNVQ0V29BX3RZbFQzVlhrektPQjhWYS1FM0EtN3FSd29qWUhUMXVxNk1hTVJoaDJzaEctSzAyZGxBT3pVSE16M2tERGF1MkdSUUs1dWd0YW89
Same,r/machinelearning,Z0FBQUFBQm0yeGI4WktJUVE1ZndCRGVPUkhqWGQtTW0xRldEdmtpYVI5NnQ1Z3dJYTlVWTBwNEEzbjdWenZnc01aQVJXSVFQSklicFBBRmpzckFGYTlhLXU1bEZXSEczUVF4MEMtU2R6R2xBcDdrS0tqRXk3MUE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4MG1ITl9QS29mTHdXcTU0NUtIRVc2VmVQbjBTTWFqUW5jT2NSQ3pEanMzZTI0UGdmMk5WU21PeTJHcGRHd2JXemR2RjJYMjAtOW9LZjBmZS1KMEEyTVE9PQ==
"I don't have anything to contribute to solve the issue but the topic reminds me of this paper: https://openreview.net/forum?id=BkrsAzWAb

I've implemented this and, although it's kinda nice, it obviously depends on another hyperparameter akin to a learning rate, so... yeah hahaha

Anyways, I never had the exact same issue but I agree with others that it might be a mix of rules of thumb and a bit of hand-waving, hocus-pocus, trial and error kind of thing.

Usually you already know how the curve should look so you let it run for a while and plot how things are going.

There's also some helpers used in bigger models like a visualisation on the model's output, eg, images or text the model generates, or some results on a small test set you can just take a look and say ""ah, it's still sh*t"" and let it run for a few more epochs.

Because then you have that, along with the training metrics, to elaborate a better guess on ""it's learning"" versus ""I trained a giant random number generator"".

Does it work every time? Nay, absolutely not. But at least for me that usually helps a bunch.",r/machinelearning,Z0FBQUFBQm0yeGI4UGswRk8xcnpvRHp3QzRpYnZudmdaZml3eXlxVTBmcF90bmdIcWJfTUpyZzNMVWxuQ1NnRUY5WE5Kb0FKVUFzX2F5VFhvSDFMU0xsS05fb3RGVHZxb3c9PQ==
"I agree most of the advice but I hold similar doubt/hesitation as op: if I am not good enough to know the implementation details, why those ml scientist will follow my lead?  

Some time later, a specialist ml scientist who knows implementation details well will be good enough to replace a manager who knows little about the topics.",r/machinelearning,Z0FBQUFBQm0yeGI4QTAxeFBxdThpWm5feUxzMkFFLW1Sd1NmVXk5Tmo4RUxxRU11NmhpQ0lycWZzcE5OZkNCTjlIVHZuTFEtYTFIaHh0OGNSb1BZY3Fwa0lKeDB4SHdXb3c9PQ==
"It is not about replacing! I would love to have someone that can take my role and job! this means, I helped them grow and become better at other soft skills. I am more worried about if I can't help them technically as I don't have deep expertise, but it seems that is not the important part. As I have never worked in big tech, I was not aware about the work there.",r/machinelearning,Z0FBQUFBQm0yeGI4bXE0UnFaUU1lYjNJMzNwaXFkQmxEUzQxaWN6WFhIamE0NGk0QVdwQk1uemZhNEY0VHl5YVNTamQyMGt2MV91V1MzMDJnMnFmR0IyVW9FN0xZRFlyNXc9PQ==
"[https://medium.com/yandex/yafsdp-a-tool-for-faster-llm-training-and-optimized-gpu-utilization-is-no-632b7539f5b3](https://medium.com/yandex/yafsdp-a-tool-for-faster-llm-training-and-optimized-gpu-utilization-is-no-632b7539f5b3)

Have a nice read !",r/machinelearning,Z0FBQUFBQm0yeGI4amlpVmhzNGRxb3FrTngwSjVhZnB1eDFsZE94RUZnVTlWc1VtWmZjaFNTeTNaRlREdEtHRkhzdUNtSE94dXE2WHZLZHZDZ3ZGVDFjNFhMYkF0S0pOY0E9PQ==
"Reading academic papers is a skill set that only comes with a lot of practice. Humans can barely do it well, there's no hope for an LLM.

Like, sure, you *might* be able to get the LLM to give short summaries derived from the bare text of the paper. But can you get the LLM to say things like:

>The authors claim that their method beats the state of the art, but their comparisons are untrustworthy because they didn't optimize the alternative algorithms for their problem, their dataset is weird, they didn't do any kind of cross validation, and they ""forgot"" to include several of the leading methods for solving the problem

No, you almost certainly cannot.

EDIT: What about stuff like this?

> There's a bunch of math in the paper and it seems to be correct, but it's mostly irrelevant to the thesis of their work and you shouldn't spend too much time on it

That's what I'd really want to hear and there's no way I'm getting that from an LLM.",r/machinelearning,Z0FBQUFBQm0yeGI4c3R0Tm1CZ3pJOFIxSnpmRTlmbW03ZVhaN3FRS1J3aFJoMGpzRklxaWQ5aERQZVRQY1lJMUNGakt4THpGR29EYVlqd1JaajczMmUxcWwyOVNKS1k1UkE9PQ==
That’s why we are not doing it. Can’t let people like you get offended. Stay safe on the internet,r/machinelearning,Z0FBQUFBQm0yeGI4THMyWTFNWEFrd3Zhb1FSVXJNV3pCamk4MGN3eXh1N1lhS3pGTTZZSVlHZGc0OXBrNndjLXhodi1FX2RIdzdLRTNPYjlvZlE3X2JCaURpMk5GLUZSd2c9PQ==
"Because you are not there to lead them. You are not a general leading soldiers, you are technical manager supporting the science team to achieve business goals. The role of a manager is to meet clients, gather business requirements, organize priorities and tasks, communicate with other teams etc.

In particular, this is why a technical team lead and manager are often two different people, especially at large companies. However, a team of good scientists can work without strict technical supervision, but would get extremely boggled down with necessary administrative tasks without a manager.",r/machinelearning,Z0FBQUFBQm0yeGI4dmFCOHItcnpCRVJQSE82ZDNFS3k2RHBwd29ib0t1alk2UmlhZmp1eXVuV3N2bXE4WGZYNkstU0JKc0Rjakw2ZW1MeGEtVC1rendybXVRNzUydDRER0E9PQ==
"If it helps your imposter syndrome, one of the lead authors on the Stable Diffusion XL model was a former famous youtube musician who became a movie director and then got excited about the early Stable Diffusion models, happened to have his name on an early finetuning repo which others contributed to, is probably younger than most people here, and I doubt is an ML expert.

You might be relatively more qualified than you realize.",r/machinelearning,Z0FBQUFBQm0yeGI4c0xXeXFTaWxsR3VqXzZXZWZreDNYZ0hoWHdKZHhQaFB4LXI4bWhnQmwzblh6TlVORmlYaUExdWFVSlZfN1pBdUV5c0k0azIyQURBYUdubDl5cjl4YWc9PQ==
"Geez, being out of ML deployment for even three years puts you way behind. I had to look up a lot of this stuff. Thanks for the education!

  
Is there a comprehensive tutorial that anyone knows that goes over, in detail, the typical recipe for DL deployment without relying heavily on any one particular stack?",r/machinelearning,Z0FBQUFBQm0yeGI4OWp3Y2ZoUFlCRnJLR3RNT3VJNTJZbDRLQW9mWHZubnZoM1NUa2VoYUlNQW9XeERDdWgxTkd4WDNvOUxva0Q3dW5RajZhTVRMY3AzYW9RQkFYeU02U0I1RkNsMnBubU1PcUVLbHhKdmIzd2s9
"I also want to know, hahaha",r/machinelearning,Z0FBQUFBQm0yeGI4ZzZVWU1sZGxUeVR0b2RTUlFSbVNVbmhKZ3ZWSVprSU1vUHVPbG4xOEpQa01PMEE3NnJKd2dhTTJHdTZ1OVh3T2FtczhtR2tiekUtdC1MSHhqemI5c2NVY29YLXhIX1F2VXpONTNZemVDMDg9
"This. I’m a software engineer with quite a few years of experience and ML Eng. PhD student. Despite the “possibly brilliant” career path in ML, I haven’t changed jobs because for the industry, + experience with SE it’s worth a lot more than - experience in ML.",r/machinelearning,Z0FBQUFBQm0yeGI4LWQ5aVRNSmJRZFZDUVFXU01ja25sbWMyTlBnNllFaEswUTM2WkxHLWZlN0RUZTkyQkpsMUVhWEpMMHQ1RlpHanY2czdRdEliWl9QSDNYSzRKOUk3TFE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4bFdXOXBJSWswaElwM2JSQWRqajFtRmEyd3o4cVc1THVlc2JJaUw5Mjc3UTVGN2JlOHYybDJaeldIa2NrR0FXY3NSOHBaVHMwLVNNVXpaV1U2RGg5V0E9PQ==
"But how would you know what is good or bad if a US tech gigacorp didn't explain it? I trust Mr. Zuckerberg and Altman that they will guide us unwashed masses in the right direction.

  
Btw love the newspeak - ""debiasing"". The data actually shows it is the inverse of that.",r/machinelearning,Z0FBQUFBQm0yeGI4UFRUWlZYSE0zVWdkcm16b0tOTzJZc19jcHlBckxtS3pXV3pJODJyVWZ4TUFyWEllaHJWOFN5MzUzelphbmxSSlBTRDhFdW95ZHdrTklOYm9UTTdhdnc9PQ==
Am I having a chance to be accepted?,r/machinelearning,Z0FBQUFBQm0yeGI4MXk2VWNCckhYOHdiVVRfQmtjSnJxT0pnYnJ4eF9kZktFNVBVbjNaZVhzb0V0cjNYNjdZTTZhSnBDanZ3Rm9hMWRQQVVIZzhfVFYzcURqQUpKT2I4N2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4WjA2WXk0S2JjSkNCX0t3Wmkwcl9MeVlkSTU2TFFPTE1hOXBlTXpfc3RMYXJFZGRvYjNVbW1XWXQtS3RscEw4ZlBXdmc0eFQzR3NCTS04T1UwYWpXWEE9PQ==
"I got 5,7,7 and I'm asking myself the same. I suppose it all depends on the rebuttal and if you can convince the reviewer that gave you 5 plus a bit of luck!",r/machinelearning,Z0FBQUFBQm0yeGI4bE5NRjMwZm5QZzBKVTFiOGU2eHRZVGxobVNSV21BRklaTEQ3d21fWTZzN2RuZXJYT1dYVFllMV81LUEwR1FLazMzRWljQVlBNURCRFhmaVBnWmVZb3p3akh6SldyN2RYOE1NbGVGenZNc0E9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI4blBhb3FaNzlvTlRXTUdKeVROOUdScnZKYjFOSE9sZ2lMc1BKM3JVMXRvZGdwV2R6Qk5RSEU5bUZpcWgwekt3TU9nRktFczg1V1kzNVktM2x4VWFxbnpaWUdhYUlpY2NRekVPS04tVHlDc3M9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGI4dWdIQUo1UEo4MVhsYlNlQzRNblFCMjJBUnFUU0pCR1N4SXhmM3VvYkhqcGhUYzFnVW5CSTFWVWprWE5kWC0xVm1fNDRNeV9vc1A3MEdRTlNYUWQ2Mzg5aDdLUDBpbEg5ZlpMNWpCSVBJclE9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4eE1Kb1JnQjVnZ096dnJsS282TUJrSEtVQjR5VmhWN2hyY0xUSE5waGpHQXZ6YlZ4T1J5Vk1NdkRnQVM2TzhZR2hvMUFiLWxzU0RwNGpidEdMVWphWmc9PQ==
"To me it seems like an overfitted LoRA adapter for each training data (or group of data) being served through LORAX or SLoLRA (run time adapter swapping) and picking the adapter during inference using vector search.
A RAG with lots of bells and whistles and makes a great client demo.",r/machinelearning,Z0FBQUFBQm0yeGI4UDNEU3IyNk1wV3BJemVHeUYzLUNpbWlrYmV4a05uc0hFcElzXzhoUDc1T1gxSXpKSVJzM1VVZEtXVzlGMHFDUUgybTFWYzFwSGtKdDVTUW1OdGl2Z015Zk9ZVlpzV1dsM3lCcjNsWHI4UUk9
"Older versions of Python will require different versions of tensorflow that are built for those versions from within the same pip repo.

Same is true for your CPU architecture.",r/machinelearning,Z0FBQUFBQm0yeGI4UF9ZdElkUlFXV1JvSm5pSWFQOXh1SVZldFVpb3o0WVdVMi03Z1hwOGthTjdJZE1UZ005LWFHN1YtWFNKV0k3bGhaLXo1RG1EYmZGTlE3Sm1Dbkc5dlE9PQ==
"""probably"" It really is, in my tests with dropout and batch size it was 60-70% relevant.",r/machinelearning,Z0FBQUFBQm0yeGI4LUJGV0tMUE1vMDlzTnFOaXNOUGxSV3ZHM1FxMFk5OXVIMWVabFd1WFhfYzVaUWxVQ1c5T0ZwUzg4TmpQYWxTY1Z4VzhlZndRMkRjd0xiR2twaU5SQmc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4c3RpODkxaGpjdTdOT1VnN0k2TjkyMFJwVHNxUk5vRzcxUUloMHpoM2N3eWFkQ0hHSGFuODYwUjJDYWFjQXQzaFBxVUJURHZKMTMxSGtLc1dtamNKU3c9PQ==
"I agree, mostly, but I think they're all related, and some of them might be less free to vary than others. E.g. batch size might be limited by available VRAM, in which case you have a hard cap on that HP. Then you need to match the other HPs to work with that.",r/machinelearning,Z0FBQUFBQm0yeGI4dTRESVJIZFVLeXQ4NDNiZ014STExQ05TYkN2UjBhSGxBc1dEMW5BdHBWWEQ3VW93SnJ1YVdyVkE3S2o0MlVfVFBaQXNMQlc1UnhvNllLRDg4TUtUSFE9PQ==
"Your concern is a sign you actually care, which means you are more qualified than most people in management. The other factor to keep in mind is that a principle scientist should be the one to help with working out technical problems and hurdles. 

The ideal setup would be that you are the manager who focuses on helping your team deliver results aligned with business/org priorities and you are developing people on the team (ideally in ways they want to be developed). Then you are partnered with a “technical” leader (often a principle, fellow, or “distinguished” scientist—sometimes a lead or staff depending on the company and org structure). They are responsible for brining a greater level of technical knowledge and problem domain depth to help the team over technical hurdles. 

This doesn’t mean you are not technical—which you clearly are—but that you have a broader technical background and have a better understanding of the overall vision and direction of the org. The technical lead is more focused on HOW to get something done, you become responsible for making sure that it DOES get done and it is what the stakeholders are expecting. 

In the end, if you are passionate about growing people, I would say go for it. It can be a tremendously rewarding job if you enjoy it and are in an org that encourages it.",r/machinelearning,Z0FBQUFBQm0yeGI4WFNPTnBpNnk1S05JSHo0TWlnZ2YzbE5Ga1BfMW9YcHk5RWFJOHpLejh5SU5tLWdJMXA5d1IxTkI2TEdHZjhkNlE2N1lpbDRwUUVDUmNOdEtER245Z1E9PQ==
Is there a free kindle version of this? The pdf is out that's great but the Kindle edition is so fkin expensive man I can't !!!!!!,r/machinelearning,Z0FBQUFBQm0yeGI4ek1RVHBkNUZ2M01fNkpDSjJiRE0tSFY5cVBYNFBqMHFTbGd3ck1mN2M5TlA0YjdLUDI1NjVuLXpBaGI5WmNva1dXNGhHZlgzQTlpRThxWGl2TWVURVE9PQ==
"Does anyone know if we can do multiple responses? I mean if I have 3 reviewers, its very hard to answer everything and every question from each reviewer in the same response in 800 words. So can I do multiple responses like Openreview? The page says this: ""Note that you are allowed to respond only once, so after you press the button you will be unable to change your response anymore.""

Also, they say that they are still preparing the help page, which is quite absurd:  
Help Article is in Preparation . This article is in preparation and will be available soon.",r/machinelearning,Z0FBQUFBQm0yeGI4WGR6N25aZDZ6U0JLLWZialBJOWtSYkNKMWx1Rm5JSkx1VWgybFBVa29pWkVTdVgxd2dROXlVQTZpb3NfTmkwUTBWNm5zcEM5bzk3Znp3TGlwbFpzYmpYVDdUZkpmdDN5SlJqQnB1MVRIbHc9
"**Ratings: 7, 7, 2.** I am puzzled by the significant discrepancies in my ratings. We will certainly provide a strong rebuttal for reviewer 3, but I am concerned about how the low rating might impact the overall assessment. Has anyone else received similar reviews?",r/machinelearning,Z0FBQUFBQm0yeGI4UFZYd011cktPbVZDdDY3NEozRGEtckpWQU5uVWNZWXJRRUZLNHh4bzJuZjhkcEVmSFREUDZ6M2o0bndXOTZuN0xDa3kzZGdYeDN2ZXFLcTdBTlpGS2NYZ2hpeEZaREdPMlZUaDA5S2NtSXc9
Learn managerial skills and become a good leader. Learn to translate business and c-suite nonsense and overly extravagant requirements into doable projects for your team and help them improve and become your technical hand. There is no need to deep dive further. Balancing stakeholder needs and technical knowledge is a powerful combination so become an enabler to your team.,r/machinelearning,Z0FBQUFBQm0yeGI4REp6VnZqRy1nNkRsTjBPa3N5V1RuLWZURklMdF9LRmdQcDZNZG45NkRPZVpOcElueWxtOVlDVk5WeXpDMHRMMmI5NHRnNjRNa0R2RHV2aW5NSXRoWUE9PQ==
"What you described seems extremely hard - I wouldn't count on LLMs being able to handle this exact use case, but you can always use this as a starting point.

Could you break it down into smaller, manageable tasks? For example ""write a wikipedia-like article on topic X"" would be extremely hard, but if you break it down the subtasks might be pretty easy - for example you can check out STORM (Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking) paper [https://arxiv.org/pdf/2402.14207](https://arxiv.org/pdf/2402.14207)

BTW analyzing the actual codebase is pretty time-consuming, because the code from repos is mostly noise from the perspective of algorithm implementation (I actually did some experiments on PwC repo code)",r/machinelearning,Z0FBQUFBQm0yeGI4ZUd1UndwZS1ORUp2c1FmMmJHdEhSMFVjeDBOcmh2RkJBQVdFMHVZaEZtTUdlU3RjMkV5ZEx2SU5DR3UydjJLM1dnUDVYZXRVNEhwVEl3QlRmX2YxRFE9PQ==
"You're welcome, and nice work! I'm glad my experience with something similar was helpful at all. :)",r/machinelearning,Z0FBQUFBQm0yeGI4TlhLZzhYSWIwTWRnY01OVmUyalFTbkM0N1Y1cVd2Q09fZXpVZ05kY0t2SkFaaDA1WUdLY0JuRE9BVzJrNGF1Nzd4elBocVZvSXFvRVozUzNTOXdKVjNvcjZVTzE4NnZoSkNoTkNiTDUxbkk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4UnRXWTM3UW4yV3NIbnEybGplaXQ0UThUOUVFbElRY291TTdOQmRBV1JYanRjVzJ6c0xmMzh6UzBrYUp0cHgydHlTZE9QVVFxM1NCSm1CRmRzQjNkQVE9PQ==
"It seems like this paper reaffirms that we should be able to trade train-time compute for test-time compute in certain settings [https://arxiv.org/abs/2104.03113]. 

I wonder how good performance can get if we continually pre-train on rollouts with a sufficiently high a Q value?",r/machinelearning,Z0FBQUFBQm0yeGI4dlJERW5VMkVLejFLN3dDSWt3MG9uZmpEZWVOR3ZhdzRPSER2ck5yYU9tdmRkRkNIWVd2ODV3b0JkUHBibnVOYmVHM1h2Z0p1dFBjN1RTOWtPbGZveGc9PQ==
"This is just such a bad take to me. To say that you can brute force 100% recall misses the entire point. Basic embedding models only capture the semantic meaning of the word, doing away with multiple meanings and the positional relevance of words in the sentence. This is WHY transformers with attention vectors revolutionized LLM performance. You can have items in the vector DB that use different words to explain the exact same concept of the query, and your naive embedding will miss that every time, even with brute force.

So to say 100% of anything when your fundamental baseline for retrieval is inherently flawed just seems like a HUGE oversight.

  
This is why RAG is so hard to spend time on.. It's fundamental mechanisms are inherently broken, and most people don't even want to address this issue. I am glad someone asked this question, because it can be hard to find relevant research.",r/machinelearning,Z0FBQUFBQm0yeGI4N2VwUWtTajc2LVM3M19ZWExHODhFODlBektxbzVQY3MzcGhRV3lIRWpBd28telN0dDltOVNSZHJ6ZXF6d2t1N2FZZUlpR3hFbWc4OFNYNGFGZ29OQXc9PQ==
"> all it can do is pass some additional instructions back to the generator and ask it to try again until something passes.

The generator should generate multiple responses and the governor could filter them (or bail if they all fail). Then you can balance the stats to give a good enough chance of success.",r/machinelearning,Z0FBQUFBQm0yeGI4cEdDUld5WXluU0NDdHgwTXozemxZQ00wcmNBU1cxZDhEbExRSW9sRThZMFJKZzg0S1pUVHdvSWZubWI3NjVIQnZheHRNRmRWZEVEaE42bUZ5cnlDMHlaS25IYUpGMVY4QVdMbTRUZG1LVVU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4dGxrUjhLTnpQbkwzUWFlRzRhSHo3RFVkTDlwc1p3RVRnOEdyV0lLMjJCUGFJTnRxVFdwS25zLUhLSXlUcmFrUzRkb0VrZGlJYmJyQWNuSDB0RkJLdmc9PQ==
"Of course, 3 can change to 6. If you don't, it's definitely a reject...",r/machinelearning,Z0FBQUFBQm0yeGI4V25kbGtzN2FWQTczNklwMzRVYzFiU1l6SzdpWmJyc0U1T294dE43YXU1cFhPYkNPdW1YZTJSODI2V3lFS0lGQ1QtSTVYaEUzMjBXQ1JZRnMzVjY2ZDUxQ3NSWW04TXJlSFdqS1UzZnpYUTQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4bmFhRFFYMHEtV3hiQ1NobXdTTXRaR1Y1WEVRdTdqbDRQUW5fbml5U3JFc1BlNXdUSGV3dEZSZjRpUkc4SzJyWmdVRHZvZDRDMjFVbUtmbHBoanJUNGc9PQ==
Sounds to me like we should keep letting humans write copy. ¯\\_(ツ)_/¯,r/machinelearning,Z0FBQUFBQm0yeGI4cEcxNHQ2bWhpaHBtb0xEUGdOekY5anZRcTJEazQ3dGEzeWJmNEZwSVEyeDc1TjhtSTNjZ1FiV3N2NzcwaXZNazJVbjR0MW1fR3lFdmJNVG13REd1TVE9PQ==
Sounds like you could benefit from some leadership coaching tbh.  Its kind of like a therapist but for work.   Did a lot of good for me as a former technical IC moving into higher and higher leadership positions.  PM me if you want some contacts.,r/machinelearning,Z0FBQUFBQm0yeGI4bUFRcTVFaTFUQWV2VmpfbTNUSFNWdlJwVmNNUWJFSXNWRTdCaVVsc0VDd2N3eW1RcGRoZ0dNcW5UcmdHMVZ0eElUZEp2TE9lVlJybjZZWkxHb09EM2c9PQ==
"Fast.ai had a really nice utility, LRfind. Uses one epoch to find the good learning rate. Together with cyclical schedules, you're sure to have very fast training",r/machinelearning,Z0FBQUFBQm0yeGI4MVlTcTRxMXZsLUROUlMtUTNrR04tRlpnUTlQdkpDNVVsMVhnNHpicTBHd3hPc3IyZXE1bXYxU2dxcm8ydjZnY0xZQmRzWFZOWDNZcWo2czNHM1VkckE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4eUVJVDB2U0tnY29FSl9ZNnRoWUJiUVpjQTNrc2c3eldVREgtbTlmR3M5aGdoUlBTeHdvMVZERjNZUlo1S3c2YldWc2tBZG05NEtWaGQ4MnVGcHgweHc9PQ==
"There are a lot of pieces of advice that could apply here, but let's start with a few that might be particularly relevant to you.

1. Have lower expectations.  Jensen Huang, CEO and founder of NVIDIA, recently offered the following advice: ""People with very high expectations have very low resilience - and unfortunately, resilience matters in success. One of my great advantages is that I have very low expectations.""  I think you could benefit from having lower expectations, especially when it comes to the bars that you set for yourself for milestones like ""being qualified to manage ML scientists"", ""being capable of working for a tech company in research"", etc.
2. Imposter syndrome is only experienced by people smart enough and aware enough to notice the distinction between imposters and experts.  ""Fake it until you make it"" mostly demonstrates that you shouldn't let imposter syndrome hold you back from pursuing the same opportunities that experts pursue.  Sometimes these ""experts"" are underqualified, and only take the chance on themselves due to confidence, a willingness to gamble, or true ignorance of their own weakness (i.e. ""Lake Wobegon Effect"".)
3. Embrace discomfort and failure.  Experience, mastery, and courage are the things you gain *after* you first need them.  The best opportunity to grow as a person is to find plenty of opportunities for *safe* failure, because especially for a person with ADHD, failure can be an indicator that you're finding yourself in new situations that you wouldn't experience if you had otherwise stayed in your comfort bubble.  Sometimes, growth is the only way to find happiness, and you won't find growth within your comfort bubble.
4. Have patience and compassion for yourself.  Would you give a person who is exactly like you more compassion than you would give yourself?  If so, this might be an opportunity for you to stop internalizing all of your failures into an uncompassionate perspective that fosters negative self-esteem.
5. You don't need to be trapped within a negative outlook.  Imagine that there's a version of you in an alternate universe who is *exactly* like you, except for one *key* difference: he/she doesn't feel the need to place undue importance on negative impressions about themselves and the world around them, but rather instead sees things through the lens of opportunity for improvement, satisfaction, and happiness.  I know that ""it's all in your head"" is a truly unhelpful comment when it comes to depression, but that term has some truth because only the potential that exists inside of your head can help you see things differently.  You need to find that outlet for positive thinking within yourself, and seek to ""pause"" (if not entirely eliminate) the ruminative, negative tendencies that cause you to tend to disproportionately attribute truth to negative perspectives.
6. You are worth it.  I don't wish to imply that some people in society are not worth help and attention, but the fact is that humanity needs people like you more than ever.  I don't know you, but I've already spent 20 minutes trying to help you through your problems.  I would like to believe that my time is valuable, so please take comfort in knowing that someone out there is gambling the value of their own time with the hopes that it might help you.",r/machinelearning,Z0FBQUFBQm0yeGI4WXJLM25FWlo3cWlMa0tMeDhMNzZxX0E1YnBjeGNYZ3laMkJSYlY4dmVZa0NKZG42SENjU3NmeVBHd1drRVVTNWd2b25jeUZDdFJ0X2hZYy1URUh3NFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGI4ZWNSUmEyd1g1emVVSFY2c09oMExSd2lLVExON0hJMTRVRW4zS09uYWlZTEIxZjNyNjZVa0xBZUxVZVNzcjVnYzZOSjcyMUR2aVc5NXEzNXl1dmg3TGc9PQ==
"hey - i think we agree with each other, you'll see that i say:
> but i think the biggest reason there's less work being done here is that no matter how good your retrieval gets the quality of your embedding is what will influence the quality of your results (how close are relevant things to each other in embedding space).

the point being that to improve your retrieval you need to make sure relevant information/context is encoded in your embeddings. this is why (in my opinion) all the focus is going into building as good of language models as possible rather than tinkering with retrieval.

as for ""brute force 100% recall"", the point is that retrieval now is usually done with approximate search for similar embeddings. 100% recall means you find the n most similar embeddings without missing any (even if those embeddings are not actually useful to you because of a bad embedding...).

does this clear things up or am i misunderstanding your disagreement?",r/machinelearning,Z0FBQUFBQm0yeGI4VWtBeV9IV2RvOTdyajVoOHRudDdwNDR6OEI0ZGJiNDZfY1l0MENUQmhIT1VPM3hXXzFMRkxIMTdfN21QNU9SZDM3ZjZIYWFrZl9iTWd3bU40OGRLUlE9PQ==
Really cool!,r/machinelearning,Z0FBQUFBQm0yeGNDQjFHRHJOVWdDNy1RZldBVTN0OTdTVEUwUkdUMS1veUFRVXZrZ0FVNlFXWURsUHgyRE1WeUVvTkZTLWNBbnpHMEpFOVI4Q25oRkZyS3lhMk1lT0RPRmc9PQ==
"Scisummary is pretty good. Otherwise, Claude has been best for this in my experience.",r/machinelearning,Z0FBQUFBQm0yeGNDcXoxWVhkck5iN29Ub3VLcU9OZUlrX1cwZm9leno3WXUwOG91NkY5Ump0dmlmZzJ1V3pHMUl1c2c4THhuRnlTalc2Q3hrX0RwYXVOUFBfcFExZXg4M1E9PQ==
Thanks for the support! It was hard work trying to make the code efficient while keeping it relatively simple.,r/machinelearning,Z0FBQUFBQm0yeGNDVmVCNlg3UDFlZnJfMW5ZOVM0TTlNakRZRnlsNEk2blZTaDNONHhBTDd2RnFscVpDRHFqdWc5eDd2MW5sZnU4a2tha0psUkk1QTFIdkh0WFFKTS05cHc9PQ==
"BTW, feel free to DM me if you would like to work together on a project like this :)",r/machinelearning,Z0FBQUFBQm0yeGNDWGhxdHV2cmJBYkJrckVkeG9DN1NwTGNpWUNSTTA0REJ0Z1hzcXBnX3VFMlg2VUhWQjFNMmI2VUJVeUhzMnlOYmhlOVRFUVo2dWJrTUg4TVFySVgxTFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDYU9FVVV2NllFaDlfbFczZ2s3LVZTYlR5eWhDa3hLS1NXTXlJMndWMTZMZ1hTTXZiZE9ZR2RHRjA0VXljbHkzSkY0M1ppMjEyWW9BdDdacEJKMy1CYWc9PQ==
RemindMe! 1 month,r/machinelearning,Z0FBQUFBQm0yeGNDaG96UGNEMEpQc2xHaFZQXzhGUFVlRG8tN0lMd2FzNTlCT1RhVVlPNjN1cE8zRVFxZ3VBTXRyRUJWZnRHQXlLUzcxSkRnZ0YtVE5ZckZ3cThZdUdfeFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDek10dVh4dzQ3b1FmSEc5UTJ3cVlRNkdRQXJHTTJLSzNZNkdnbjc4Zk4yampaX0pBcFVhbEM0aDRVYzJmeGlTR0wtQW5QbzFKZUtLbEVPellGaV9uUVE9PQ==
Are the documents a graph as well or is 1 document 1 node? Do you embed entire documents for retrieval? Do you think it’s effective to paste entire document in context?,r/machinelearning,Z0FBQUFBQm0yeGNDRnRzdUNOMlV5ZVhHR1hnOUdSbmdodnRIRWdHWWFyWDNocGNUSEk5MEJRYkVpT3ZmblI0cS15WVNBTVJfTzRYRGI3WDBrWDZNUFBkaWxBN0VPR2YyVHBjdmVkWHVGNm1sczN0c3h6dTJ2LTQ9
"I guess I misinterpreted your use of 100% here. That makes more sense. Thanks for the clarification.

However, still missing how improving overall LLM performance is somehow going to solve semantic embeddings though? The embeddings used in autoregressive transformers are meant to represent the tokens, and the attention layers enrich those embeddings with context thereafter. Nowhere in the transformer architecture does the model care about the initial word/token embeddings retaining context. That happens later on (in attention layers/heads). My point being that even with better representations in that initial vector, we lose contextual information.

There still seems to be a need for a retrieval specific architecture, which LLMs do not even aim to achieve atm. Unless I have missed something?",r/machinelearning,Z0FBQUFBQm0yeGNDMmRPUlg2U1JyYUo4MUFLdWpLVXltWF85dFd5emZoQmQ3ci1tcV91VTBCWmp0SjVzWm9VOVVGRjRRcWJVcXpMMk0wRklVaFVkN3Y4LUxUTVBKNllpalE9PQ==
"Hi, thank you so much for your advice, help and Time! I understand what you are saying and I am aligned with you.

 - For point 1: I totally agree! I have never set high expectations for myself, I have never done anything major or impressive work or anything else in life in general. I know that this was really impacted by my depression. Now, as I am feeling better, I wanted to set some challenges for myself. Maybe, I am wrong and too impatient (as I feel I wasted 10 years of my life doing nothing). For the point of being capable of managing a research team at big tech, because I was contacted by a recruiter at Meta for Research Scientist Manager for LLama team, I did a phone screen interview and I am waiting for the results. But, I felt like I am not qualified and at the same time I felt like ""Wow I had this chance, so I can do it"". So, in case I fail the interview (which probably will happen), I want to be prepared for next time if a similar opportunity comes to me. So, I want to take step by step, even if it will take months and years, I want to become better and provide value.

 - For point 2: I know that I might suffer from Imposter syndrome. I know I am kind of smart (in some points) and I am able to find solutions especially when dealing with people, influencing as by nature I have and building a good relationship with people and my colleagues. But, I know my gaps in terms of technical expertise, I don't like to lie when I don't know something. So, I say I don't know but afterwards, I try to find a solution for someone that can help my team, but I feel some frustration because I could not help with the basics about LLM or Coding.

 - For point 3: I totally agree! I am too scared of failures! I failed a lot in my life and it really damaged me internally. I always felt like everything that happened to me even as a child was my fault and then it's my failure. Then, during my studies, it was a failure as I did not do any efforts to become better (I know that I was in deep depression, but I feel like it was my fault, because am the first person in earth that her parents abandoned, being poor, lost her grandmother (it was all my life), ....). Now, I am scared from failing again! I am in a paralysis analysis state.

- For point 4: I am really sensible and have a lot of empathy for people but I am too hard on myself. When I see someone struggling or being sad or lost, I do all that I can do to help because I see myself in them (in some situations) and I don't want them to face and suffer as I do.

 - For point 5: It is really hard but I am working on it, alone and with my psychologist and psychiatrist.

- For point 6: Thanks a lot for your words! I hope I will help people in my turn and provide value, help and some have compatience to people in this world.

Sorry for my grammatical mistakes, I am trying to become better in english (it's my fourth language 😅)",r/machinelearning,Z0FBQUFBQm0yeGNDMVc5QVJmS0RVTjVWUFRuclBGRmN0aEd3c05QLUJuTC1MSEFmTEZjdmdJcVhpanJDMzRuZXZHRGdURm1weUROclZmQmtLOTZLckNJa1NRTjNvT0FUcWc9PQ==
"7 7 8, what are my chances?",r/machinelearning,Z0FBQUFBQm0yeGNDRk1hdGxxQzVpdkZCNEYyN0ZQNDY5SUtTS0hoNUU2VERPTWtXVG5fbkw1cUVoVk9BV0FYNDZoMlcwTktFYnE0b1Y1RTRtWkdvLUFUNTRoMWltZVc3WE1xVWFWZFowNTJkYUFEcXVhMWIzdVk9
"Work for Apple, they are trying to catch-up...?? I don't know...",r/machinelearning,Z0FBQUFBQm0yeGNDaTJnSENRcGdpVlJCWHlEUE5zR21Pb3pzdjBzMmY2Q0pPMjZHbVJKM2hTZ1Z6empCSnprZ2hrQWNMd3BtVGRmczlUVkZGNW85OWg0S3pMMWZkMnlHcWc9PQ==
"This paper is light on details of their methodology. What are the prompts used? They say that they use temperature = 1 (and inexplicably describe that as the maximum possible value), but what about other sampling parameters, like top_p or top_k? In experiment 1, are the fields (name, gender, age, ethnicity, etc.) generated independently, or do you always generate a name first? If the latter, is Figure 6 just showing us the same thing as Figure 1 - once the model selects ""Emily Jones"" instead of ""John Doe"", surely it's locked in to predicting ""female"".",r/machinelearning,Z0FBQUFBQm0yeGNDYklYVWN6eXppc2tmYlV6V1picVBsX3IwaFdDT25EX0pHbGtwSGZLRHBBRTMyTFY2cUtxaVBtdVRDRWxleHdRYzdLVUg5aUphTEFXYWJ0Unl4dlRRZ3c9PQ==
"to me, it's an obvious outcome when you think about how an LLM generate the output. It's not just selecting words from a well defined range of options where you can simply remove any unwanted ones, so any kind of censoring it's going to negatively affect the whole process, leading to less accurate/creative outputs",r/machinelearning,Z0FBQUFBQm0yeGNDOVZMM1dMQXotcXd5Y0szRngxVXM1dm1NMC1UOUNGMmdWSFRLUVlVS290UlNTOUlYdDZiV1hTNUViU2M0ejBGaENVNVh0cmRlS0wzekgxRGozamxFNzYySVFGZml6Vi1rakVaQ0tPa295Wms9
1e-3 is the one true LR. All others are heretical.,r/machinelearning,Z0FBQUFBQm0yeGNDbzcyMHNuN0lEN2NwSngwdC11bE5QeXdncDNHVjZwMzJreEhOUUdJQmVGazh2VWx4UWtSMHVSX1NJbS1reHRuTkMwcEhVWVdxU252OGdmQnVwdzhCclE9PQ==
"it's a rather simplistic way to put it but also not really wrong, turns out it's hard to impose arbitrarily defined moral boundaries to an intelligence that lacks the concept of morality.",r/machinelearning,Z0FBQUFBQm0yeGNDcFVTamp6LW5rOVdyLVlMTDkyTnFtZGdZTzZvVFVFRms4TmlfT0VzNV8xX2hsTTFGeHBlanltZ2c0ZXhQUnZZLWo0cGdncTRwN25Lc1VuS1JvQjNZLU94R1REMXdfNmp3LU5NUjVCQlliUXc9
Agree.. Totally need to look at the overall parameter updates,r/machinelearning,Z0FBQUFBQm0yeGNDNDRYcVZ1cW51ZFFkRWJkNE9jZkppY3l5d1hwN3FWc2hMd29fUkxBSFotSFJEOW5Tc1hiNEpOeXBlYWROdW5fZUNKWno5SFJoQjdYVGlzcVRMUXp3NGxVT2hXRWlxOXVJT0UtdTh5TG5QOWs9
I’m not OP but also dealing with similar struggles. Would love to speak with any of these leadership coaches if you have any recommendations. :),r/machinelearning,Z0FBQUFBQm0yeGNDVXExVm0taWlGOE5WYlJJMC1ab3JpSFllS3NPZ2F2ZENmcDJ4c1JDU3BvRlZmLTR3YmdFZ0hTd2JkQTRvTmhObkJBUnhrMmhzYVo1NERfMDhRQUVxdVE9PQ==
"sure :)

typically you wouldn't extract embeddings from the first layer, but rather from the last layer (before the LM head). 
how you extract the embeddings at this point depends, often the embedding for the last token is used, but you can also sum/take mean of all embeddings (among other methods).
the idea is that by the last layer all relevant context should be encoded in each token embedding.

there are ways to try to be more ""explicit"" about dimensionality reduction (autoencoders etc), but ""simple"" methods like this work quite well.",r/machinelearning,Z0FBQUFBQm0yeGNDTm9NcWZ2YWZjSWx4S0xBWmRVeERQTUhDNU90NEpZR1BiOFh1YmhxbTF3eW5nOHp1RzRUb09LaEFJYTRrU3lzeHZ0UG05d244Ti1kTlNwekMxTENINkE9PQ==
"I wish you the best of luck!  Meta can be a really hard place to work for, so if you get a job there, be extra patient with yourself.",r/machinelearning,Z0FBQUFBQm0yeGNDSENSdUtWZmtkcTVSLWFhMW5Kekk3dkNuejNxUG9LQ20zRW93M2NpclQxekxJVEpzVjhYcEROcXZBUUFkVHJrVHRRR25XcWNHN2haeS1yc0tkcTE2Q0E9PQ==
"I don’t think it’s that they’re arbitrary. I think it’s that you have a predictive model trained on how people talk and you’re trying to prune the output instead of the input.

I imagine that if you tried to get weather models never to predict rain on Sundays you’d create a lot of unexpected errors on weekdays too.",r/machinelearning,Z0FBQUFBQm0yeGNDMTRIV3JUZ2dRajFGLThDS3ZCc25SZFA0M25XQ1JkZHphNkpsenBBaTRkYjNpdkFybnNIWU5YcWdNd2xPTEVnN3NsUUtKZHpkVlNSN293czZWS1FJU2c9PQ==
These are really promising scores. It should get in. ,r/machinelearning,Z0FBQUFBQm0yeGNDZWlEOVUxdDR5ekxLNFZrOUdabW1Hc3djdWJGMXdZY2FKem1QclhwREs1Z1lvWW5oZHJPTXNuSGZjMEhoc19GYW1HYXlUQWpYSlJHX0FQMnBYc3d1Z2M2WDktS2k0WkViNXlTU2JZaHozNzA9
"Barring new algorithmic breakthroughs, there's no way to achieve this without large scale that open source usually can't afford.",r/machinelearning,Z0FBQUFBQm0yeGNDSTNqbFU4VzRqOEU5bzRRVUtMdVZSTnhXQzE5LXJicVlCU2NHaUFvcC1rMHJuYngtSndUUFZBVVJtTjVLNWV0WXhWNGhqeEJjQ2VKRVJrTHhtNDk4QmEyVFJ6cGRuYm1FcGhZamFUUXRNVUU9
Do it. Life isn't a straight line.,r/machinelearning,Z0FBQUFBQm0yeGNDcjVLdGtsSm5vVmVnYThmNHc0UXpqMnJpUGkwSS1LRHVod1lma1RYMHVsNEtuM3pfaWlnZTJnMnBudG5RaEQwZmZJeFhDa2RiUDV3bkRxOWdVZTR1S3c9PQ==
"> I feel I am not truly a research scientist, neither a ML Engineer, neither AI Team manager

Damn. It's a pity that companies and research projects never need people that have interdisciplinary knowledge and a broad spectrum of experiences, to lead their research scientists, ML Engineers, and AI Team managers.

It seems like you are good at what you're doing and you're enjoying what you're doing. You seem to be able to build an AI to answer the question, but seem a generally competent enough person (aka the top 5% of managers) to know to just keep doing what you're doing.

Nobody is truly anything and you can always do whatever you want, when you someday decide not to lead a research and applied science team in NLP at your current company anymore.

If you ever want to go back into science, you'll be fast to catch up if you know what to skip. The hard part comes when you want to reach the cutting edge, but your practical knowledge will not hinder you there. It may even be helpful.",r/machinelearning,Z0FBQUFBQm0yeGNDR1NPR21McTlKLWZDTFBmeERFSm5PcW9xY1hlMmNuUGZwTDdfNUdJYV9TTEhIOThhWTB0WlA1WGZPcHlLRUdzb3U5ZjluYUo4aGxtMVZndndVMEZmdlNqLWN4UktqeGplNUZCNkxnUEFpTXM9
"> I thought I had to be an expert

And I thought PhDs were experts.",r/machinelearning,Z0FBQUFBQm0yeGNDbzN6QjBwdV9ncWVIdTVzcjZMb0JfUllDSWM2QzY0Z0ZxdDBGVExZUW1kY1NsdzlZNFcwMDhIV1dMaEs5TFVXRDQ0OEU3cGwyQUVvb1paMm1LenNOWlNFSTNweUJPNGJjc3o0MUlBT29QSk09
you're being sarcastic now but you'll regret these words once your AI powered toy you bough to your son - to keep him company while you Work Hard^TM 7 days a week in your patriotic duty to the  ~~capitalist death cult~~ land of the free - teaches him about the horrors of communism in a slightly neutral way,r/machinelearning,Z0FBQUFBQm0yeGNDR2cwc09icHBiX0Q1Rk5SRkVqd1Nid3IxNHNUNl9YbU9TOUd3Um5kV1FQX1VzRS1lSlFiWFo3bzN3RTlXbC03WXZzbnIwdGU3T3BTVzNmcjZ4dXJweGFncXQwU3puSHFRM3lDdVVLcm9PVjQ9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDODBGX3d1UVdBVjVmTVBPZGloUi1wMW5wbnA5amtTTkV5Y1FJa3VoTEFGTURfbUhNVnhVV2FCUTZfZ2lUNWxma1N3VmQyOVVraHV2SFVpbG9yODRyS0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDN3JfZF9tTDd2MVZydUpBX2g4NTBBYkFKTXdkTVZGblhmUW04TldwSU92QkVMN2pZS3N5ZU50TnVMeUktV3dEb1dkUkRfZFdIcTlRX1FraE85RVRTLXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDNk9WU1p4S21WSjFzZ1dGYjBlei16cWRjOGlmWTVqa2M3Ml92REZOSFd2dVVJalRQTEtaRHJHS2FGZF9IRWg5MURZODNPZHd1VWVYV1IyQVo0TC0tTlE9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGNDTDVCU3BCakw5SUNwUkNBU1pwTkctS296bjMwYkstTEtqdWVIcXFneDYwMTIxLUlCR1FOa3FvdDc1bzJudGFuZHJMd0YtZUlxbG9EZXdnLU16dTBOM3RpTHcxT2JOVllDb1N3WjRGYTEyLVU9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNDZlJyQ242aGd4V2FNUXFaZF95akRKbW1RcUpBcTNVTGVlWDRnRXNFTnVmMjVtTUplSjBHNzZ0MjZVamZRcVpNNGpoZk5pdk16Z25lTld3WHdaTERJSUxiLXZYQjdfQVBxekRrb2RtVndwcjg9
">  if you tried to get weather models never to predict rain on Sundays

that0s what i meant by arbitrary, though maybe it wasn't the right word, in the sense that they're defined for reasons that don't follow the natural patterns emerging from the training data",r/machinelearning,Z0FBQUFBQm0yeGNDZzc1REVaaVRLWDI0V3RQeG1hZk9QRVNsUW05WE5oUzROZ0Zsa19pN3poZUhuT19zRjZkTXZmb3p2LVI0cnM1NVMyTl9nTnR4YzVKeEw0SHoxWDdSUWQ1N1QxVnRsaXJzYlZwMDdCenZXT3c9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDbzl3YWdYUWR1dHk3Q2oybV9BOWlwV3M5cGVTeUtvaXkzQWNIbFhYbURNcl96XzRjbzk0VU9zRjZQYzlSOC04cGlwYW9TeXBtM3YtOXItLUVpVEdhdEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDT2lpNXJYWTQzYXBVMzdZbzZHWXNRcjNBTWltMnhNVWVtY0ZwWVdXWlZBYjRnR3MzNktFbzhSQ2tMWVNjZGRZSDZoWE5hRm5LUDRzc3h1RjZWNXFHWVE9PQ==
"Okay so I am running your code but I was hoping to see a leaderboard at least for the SOA, but i'm unable to find the results of the AlgoPerf Competition. Am I missing it or are they just not available?

Otherwise great stuff, easy to set up, use and test your new methods on!",r/machinelearning,Z0FBQUFBQm0yeGNDQnBhM0dGSE16enowdllUTUVBZ3VhTlRITjRyZzNaYjJocVVaYW5CdFZaNmlmNU1QWFp6QlR0T3VzNXZDbTdxUHJGTWVVNEpIclVpQVJhdlk5VzRBMVE9PQ==
"Is the interest in all three roles a bit of the adhd aspect coming out itself ? Given your broad interest and competence in all these areas, let me say like this - realistically there is no lasting achievement that comes taking the specialist (research or engineering) route here. I did both on top of being a manager, proving myself in nlp area (and more) as well jump into a competitive faang, only to circle back. The achievements seem brittle, the stimulation not long lasting 😂 still people find the achievements a fun (prestigious?) talking point but meh save yourself the detour. Anyway, more fun when you approach the fun parts as a hobby anyway you gets most bang for your buck in terms of fulfilling your own interests ",r/machinelearning,Z0FBQUFBQm0yeGNDa1kycG16MFRzNGxERndrS0ZYOEhLeEM5ZnMtY2FIWHZTeTJTaVZJXzdGejdEa1VrblRIT2RRYmV6MHVzVWxMQnBlTDlkM2ZPdUVQS0k5QjJ4c2lfUkE9PQ==
"I think the real answer is that big companies do not have any smart, efficient solutions; they just burn money. There are various hyperparameter optimization methods but they're not a great solution to the problem. In my opinion ""efficient ML"" is probably the most important area of ML research and it will determine the shape of ML in the future.

You can use second order methods or approximate second order methods but that's not really a solution either, they supposedly don't do much better. Adam, for example, [is already an approximate second order method](https://stats.stackexchange.com/questions/272118/why-adam-and-batch-normalization-are-considered-approximating-second-order-behav).

I think of the optimal learning rate as being a property of the relationships between the samples in a dataset, and it therefore is something that must be ""learned"" just like any other such property of the dataset. There probably isn't a broadly good solution.",r/machinelearning,Z0FBQUFBQm0yeGNDMXFOVFQ5ZXk3NHhPUDk5UXd6ek5OSGp2WTdOM0YyOXgxVEhEUEFfTXhmS2ppdHNoRWVlVHlQRV9EbnlMVFhzQ04yWDBodkNvMkkyM010LUh0WTV1dHc9PQ==
Get the person / system providing the data to always add the header. Anything else is mental imo,r/machinelearning,Z0FBQUFBQm0yeGNDMy1wT1poV1AxM0pDekVJMGFaYWNpY2RCQk83Ymk1N0VsSFplcW9vVTB2MW9SS0lXSWlVWjhWVWJJcWVtWWNkdHJOUXVyTWVzRzRKblhKUGY4bmVVYmc9PQ==
"Unless you heavily post process the OCR output (like, dictionary lookup, or feeding into an llm), I would not really advise to build your recommendations engine on OCRd text due to inaccuracies. 

I’d rather look into multimodal models like CLIP to build embeddings, and work with those.

If you do have a working recommender system, and you want to keep that, then sure, go ahead.",r/machinelearning,Z0FBQUFBQm0yeGNDRzlZLU5BcTRXR1B6b0FvUEFlVzgwRF8wS2JTaUhYdlh4OHNTd3BEV3BESkduTndYandLLU9ISkR1SmNkbDFrYlIzblFsVWl6UzF5S2pia2trcHAyZVpONzR0Q1ExN3ZnNE9zSXQwdzZ3MEk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDOEV0ZXF6T21fbUZVb0NTd1JJQVNIc2MtakFnWW05aUpJVG1RLUUzVS1mV0IxOFk3anhhc2xnUGlLX191NW5pRWFIYUNYbld1b21meUlZcnB2VVJjU3c9PQ==
"I've spent the last year building a latent music diffusion model (including the VAE) from scratch, project is [here](https://github.com/parlance-zz/dualdiffusion), samples are [here](https://drive.google.com/drive/folders/1aCs0HWvocO1-EN2dXhEa3Hwcje1xeO24?usp=drive_link).

When working with signal data in machine learning it is very important that your model architecture respect the underlying symmetries of the data distribution. Validation vs train performance is largely determined by architecture choices that reflect an intrinsic inductive bias.

In my experience with music generation specifically 1D models need a considerably larger number of parameters than 2D models to reach similar training loss, and validation loss is always worse, _especially_ with a smaller dataset.

Why? Frequency is a dimensional quantity, and trading dimensions for channels is always a bad trade unless you have no other choice. In additional to the aforementioned inductive bias and validation performance the increased parameter sharing in 2D audio models means your model will train faster as each individual parameter is involved in a greater number of gradient calculations.",r/machinelearning,Z0FBQUFBQm0yeGNDUGZhNkFEVnBtU01FM0dGVUlpSXRiSUYzRnFBZnFEakFDZXV3aktKWnhrWTBSeG1ZNC1RS3k0TWJ1eGI5c3RDRFNfemtoZUFJUXBMWmFWSDRKRTU3d2c9PQ==
"You should probably take that opportunity. More coding experience is not a bad thing, even if you want to do more DS/ML later. Also robotics will probably look good on your CV!

While you do this software engineering job, you can do multiple things:
- Continue to learn and experiment with DS/ML on your spare time/personal development time
- Look out for DS/ML opportunities at work - if you can spot something where you can do a bit of data analysis to learn/improve something, that will get noticed 
- If there is a data/ML team at work, show your interest, and if they ever ask for more personnel, even if temporary, be the first to raise your hand
- Continue to look for new opportunities more in line with what you want to do. 

Hope that helps!",r/machinelearning,Z0FBQUFBQm0yeGNDQk5qNE1qSm8xSkZNQVd2M0ZlX1RCX1FNeGdnQXZlNDZEMkE5NVViRzQ5UzJUWnNhZEVtN2hEN2VYdEhMOG9OUURqOGdYUXFvZFJ6cmt5VldaQjBoZGc9PQ==
"My best manager had an ML PhD but never exactly helped me do any research / ML tasks.

For managers, people management and compassion are the most important, and everything else is secondary. This is doubly true for ML managers, where each hire is an expert in a distinct field and the field moves too quickly for a non-IC to catch up.

What made my manager great, is he could always connect me to the right internal-expert if I was blocked. He helped me balance my interests with the priorities of the org. And he made sure I go projects that aligned with where I wanted to take my career.

Tech is a lonely field, and both ADHD and depression are common clinical conditions. As someone who has dealt with it before, you are in a better place to observe & intervene early, instead of letting it fester to a point of no return.

Play to your strengths. Be happy. Tune out the noise.",r/machinelearning,Z0FBQUFBQm0yeGNDcWpXZE5Jd00zWWRHYmZ4eTVRU3AzVVVmdVpoLWQzR2htUkhYMndUR0pUeEpQSGhncWFwM0ZNekotdWZNOGxVX0RBWWJydmtPOFNOS2FHMzdFRGJjR2c9PQ==
This makes sense to me,r/machinelearning,Z0FBQUFBQm0yeGNDMnRQNWRwT2RGZnRCQU9MQVFYTjFmWGpCTFplUFVSSVJHUndkUzc1ZTQ5YlQyNUV6NXFlRFpwTjhiajRlb29VRUoxamd6Y2pMZHdGY21tYjRlMFZ3NkE9PQ==
"I was also a bit underwhelmed when I read the documentation - I hate python, and needed to train a neural net, and got desperate enough to look at basically any other options. Based on the docs that are available I saw some promise, but it did feel a bit akin to Cython, numba, etc. - more-typed python. And critically, it seemed I couldn't train a model with it yet. THowever, after seeing this video that explains the architecture and the internals, I'm much more impressed:

[https://www.youtube.com/watch?v=SEwTjZvy8vw&pp=ygUJbW9qbyBsbHZt](https://www.youtube.com/watch?v=SEwTjZvy8vw&pp=ygUJbW9qbyBsbHZt)

The comment below about Steve Jobs-style presentation does resonate, but having watched this I'm much more sold that it's not just hot air, the things they're discussing in the video are really thought-out and touch on a number of ideas I've had or situations I've encountered where there's a gap and one is left wishing for better tools. 

Still yet to try it properly, but, anyone talking at an LLVM developer conference or CPPCon generally does know what they're doing, so I'm going to give it a shot for something else I've just started.",r/machinelearning,Z0FBQUFBQm0yeGNDUWo4X3FsVEt6cEtkYXhwZ3k1S0dRT3FjcVNUQi1CM3BmZDE5c2l6eDRSZVdiSEI5b242Z1g1N2h4dG01SXAzTC15eklpNW0tYUxOaHR5cThtY0N4a3c9PQ==
Have we gone full circle? AI reading papers about AI/ML?,r/machinelearning,Z0FBQUFBQm0yeGNDS1AteHVNYlRNakpzNVNrSmhiTWRwRVJ2eEZ5NnF3U3BxSElZbFJzWFhMcFU0S3R5Mi1BU0pTMXJueDBVdUF0UU5ReHFjLWUwWjZUWnJkczRRcjFCRlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDQldQUWI2YWlHbXFRS2xUMWdEbE13MWl3U2tGblBvUGwwMEFYNjVYUVAzZHZ1ei05R19vWGFsdTQ0MWo1U2hqbmlyb3Z1b2RHb01HTjBySTNVWjRkVUE9PQ==
"^^ this

This is a data quality problem. Trying to solve something like this by building a hierarchical classifier is crazy IMO.

If you want, you could also try solving this using a few-shot LLM since it's mostly a text classification problem -- you probably only need to sample ~100 records from each column. You could use a long context LLM like Gemini.",r/machinelearning,Z0FBQUFBQm0yeGNDbzM4dHptYjVBQ1FWd29OMFJaVVZReFM3R3lBUzYwblREZV9ZZUx2TUNlRHJXZkZyRWJscm1icjJaT3IyaW9pTFdzNmZUOGlYckJRZTZiNXVoYXJXemljbHFENUQ2RW5NX3hPNkRVMjFDM289
Side question: can PINNs only be used for PDEs pr ODEs? What if I want to do parameter estimation for a complicated polynomial instead?,r/machinelearning,Z0FBQUFBQm0yeGNDVVR1Nnk0bmVsLThoOWZENm51dF9pYmlGcm1EOVJKZy0xelg5VnNfcnl1a0NHQUVTNEprdHV6cFJNcjM5VDcwekNKeUp4VXZTOXJxdzgzRW5NNVNmSkFKZjMxUXZ4OW9xaGZFUlRCYllyX3M9
"We're still scoring them! Then we plan to have a live leaderboard after our initial competition concludes (and we award the $50,000 prize pool) and provides results to seed it.",r/machinelearning,Z0FBQUFBQm0yeGNDMXY2ZGN0LW5QMW8zTWNHbFBWeDEwLWZDQkJQTzllWE9wbDNFQlBCb3BCT2ZpSzdrMlhVMjd3ZDZKZzN5OUJKTkVYUjQ4Vi0tdk5hNUVhZS00WVBncmc9PQ==
"Oh I thought the deadline was passed for submission, or is it still possible to participate? My algorithm is probably too simple to compete with the most complex stuff you've probably received, but I'd be super curious to see how it performs. I'm running some tests of my own, but it won't be as extensive...",r/machinelearning,Z0FBQUFBQm0yeGNDY2x0WXhfU1k4NVJnN1Q3WXdaYkgxSlNub3Q1ZkhpdlZyaXlkbmtGai1yVmF2TEo1X2Q1aEVtZmJldHRkMlBVbHNEbEtlUFFTQUZZVTUxNnBWYk1ubHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDSE55X0dvaXQtTzBjOGF3c3R4US1CZDQ1REswaVZwZ0JOSUh3aHVpYVlVX3lkZkJTQjBzOTVNN29tYVNrOVlsZVpUTEFOaTJwUnh3M041cXdKcml6T3c9PQ==
"Hey could you please share the presentation?

I need to do a similar thing at school but I'm having a really rough time with the documentation of DSPy. Going through your presentation might give me some direction!",r/machinelearning,Z0FBQUFBQm0yeGNDa1FwQ2ZjMnIzaHpDV3kwd3pfdmFhUW5wNXBBSk9LZ1YwUW8zSjJVZDFHZk5wNUY1YXIza3dkc2JCYXZuZ1JJSHJ0MEVCYVRLTlV1OHJaSEZIbnZ4SXc9PQ==
While I agree with all previous points that you just be in the right magnitude of learning rate and that typically companies have a lot of cash to burn. The reality is that we also have methods like learning rate scheduling that adjust the learning rate over time. Even if you start out with a non-optimal learning rate over time you end up at the same learning rate as the training run that used a suboptimal one.,r/machinelearning,Z0FBQUFBQm0yeGNDYTRhRTZKSWNDb3l6V1Zqbnp1bFBLNldDd1I5dUtjVWpqUmNsbDZ5bGRKQW53a3laTWRVaF9sTVdaQlMxc2ctV0xncEZOOWhiQWRUeWtGZnRfQzRYUkE9PQ==
"Open source will always lag 5-10 years 20 in some instances. So if they stop improving closed source , you’ll catch up in 10-20 years 😇",r/machinelearning,Z0FBQUFBQm0yeGNDOGl3ZlBVT1VMLVljai1NYTJ1NXFkZVJLQlBxRE44WmhQTERYSVlYYmttQWVfcjl2ZkFwYlFYWFVWT3RoZ0JNeloyM3hOVTFkaUJ0cFBKVGt6QW5TcGc9PQ==
This was written by chat gpt,r/machinelearning,Z0FBQUFBQm0yeGNDek5VRV9FYUxZVTFHaUV0M0xLVG00WkRUZmFXc0gyQmE0elp6QWNfUjFwUTI3RnMyTUM4bW1GSDA5MXExOFpTVXhsVXByZkZ3X0dlckZBREZpQ2J0a0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDSko2TktWR1lzckJkV01sNVhTQUtXRURCcU05bGZCX09qSVRTQlRDQm81bmlUNzctcmJCblV3UmNBampVR1V5RkpSSU5jQjBpTm9mclc3WVNiS1NQbmc9PQ==
666. Is it good? First time submitting here. ,r/machinelearning,Z0FBQUFBQm0yeGNDQkpTVmV2SDFfTXY2ZnhDMldlOVF3c3dsQVBrc2ZpODU0emxiZGlidmZSVmNtX3FlclA0My0yQ3Z4bWE0YnU5RmZOVXdjZlVtbTZKYV9uUmd2LXVnY3U3cXlBaGZvVFZtUzNyRXp4NkNVS009
Also OPs post reeks of “personal” issues not work issues. OP needs to work on the depression and ADHD first.,r/machinelearning,Z0FBQUFBQm0yeGNDUTNsTEtUM1RIdkNHSGVQYkVEY3ZNQzFkTnFXLWdmem0wa0hnVFVYWlFfdktnajBZdF9BS3czQjBGdFpkbDJBWE5fQVctV1FqeUowbGU0X0JraU90NFE9PQ==
any baseline？,r/machinelearning,Z0FBQUFBQm0yeGNDRThGX1hmVnJrckl2TEx0NHl3NVFUdFJ4QnBNNHpUTHlIZURPdWZ5d3llMVI1cnJNNkMxVWFvamNJakVwUGZUb1RCaGtNbjFDTDlINlZzdGw1OEJJUTREaDBnUi1aZTFnSEVVUHY4QVBzYUk9
"I am not sure what you will/intend to accomplish, but you have to include semantically meaningful information (human-readable text) with any transaction data. Maybe this script skeleton will give you an idea of how to finetune an LLM in a meaningful manner using both text and transaction data: This script provides a basic example of how Generative AI can leverage a data lakehouse architecture to extract insights from both structured and unstructured data.

By integrating Generative AI with data lakehouse architectures, businesses can unlock the full potential of their data and gain a competitive edge in the market.

**Explanation:**

* The script simulates a data lakehouse by creating a DataFrame with structured (customer information, purchase details) and unstructured (product reviews) data.
* It combines the data into a single DataFrame for use in a Generative AI model.
* The script then splits the data into training and testing sets and initializes a summarization pipeline from the transformers library.
* The script uses a placeholder for the actual model training process, as the focus is on illustrating the integration of structured and unstructured data in a data lakehouse context.
* Finally, the script uses the trained model to summarize the product reviews and prints the results.

# Analyze the insights generated by the model  
 This is where the data lakehouse architecture provides a powerful platform for analytics  
 It allows for efficient storage, querying, and visualization of insights derived from both structured and unstructured data 

 In this example, we simply print the summaries, but in a real-world scenario, you could use a BI tool or visualization library to explore the insights in more detail",r/machinelearning,Z0FBQUFBQm0yeGNDaldJTjE4N1dxTVFBMDByTHFRY1E3R1Y4d1RuU0xRSi1ZeDNLdEdhSWIyd0s0TE1ubC1ZU1JDSjlfRUJpSVJGNzVFT0UyTmdUZGFBb05ETHZ1dnN2akE9PQ==
"# Analyze the insights generated by the model  
# This is where the data lakehouse architecture provides a powerful platform for analytics  
# It allows for efficient storage, querying, and visualization of insights derived from both structured and unstructured data  
# In this example, we simply print the summaries, but in a real-world scenario, you could use a BI tool or visualization library to explore the insights in more detail",r/machinelearning,Z0FBQUFBQm0yeGNDQ1c1LTVuSHZ0OFFncGxKSkwyeXR0ZFNWSldUNzVpTDRIcnRPaVU3TjhtaHQ0dTdxdjhreHVCUWlsZFZRUkljNUx1Wl9rUUhmTV9xR05scWxlaUVlWWc9PQ==
"The optimal learning rate changes during training, and that's why you set your optimizer to torch.optim.Adam",r/machinelearning,Z0FBQUFBQm0yeGNDWkhLeWtNd2ZPX3hNYWtSdTlTUXhCaG5EZWVyMVhNTTJmazctczl5OHNmWEJySXZRanM2Q19fSmF0bTVFZWw2OTZwOXM2amNtSnp3cGt1UWJaM1JFWXc9PQ==
"# Import necessary libraries

import pandas as pd

from sklearn.model\\_selection import train\\_test\\_split

from transformers import pipeline

# Simulate a data lakehouse with structured and unstructured data

# This is a simplified example, real-world data lakehouses are much larger and more complex

structured\\_data = pd.DataFrame({

'customer\\_id': \\[1, 2, 3, 4, 5\\],

'product\\_name': \\['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'TV'\\],

'purchase\\_date': \\['2023-01-15', '2023-02-20', '2023-03-05', '2023-03-10', '2023-03-15'\\],

'purchase\\_amount': \\[1000, 500, 250, 150, 800\\]

})

unstructured\\_data = \\[

""This is a customer review about the laptop: It's really fast and powerful."",

""I love my new smartphone, the camera is amazing!"",

""The tablet is great for watching movies and browsing the web."",

""These headphones sound incredible, highly recommend them!"",

""The TV is very clear and has great picture quality.""

\\]

# Prepare data for Generative AI model

# This is where the data lakehouse architecture plays a crucial role

# It allows for efficient and secure access to both structured and unstructured data

combined\\_data = pd.DataFrame({

'customer\\_id': structured\\_data\\['customer\\_id'\\],

'product\\_name': structured\\_data\\['product\\_name'\\],

'purchase\\_date': structured\\_data\\['purchase\\_date'\\],

'purchase\\_amount': structured\\_data\\['purchase\\_amount'\\],

'review': unstructured\\_data

})

# Split data into training and testing sets

train\\_data, test\\_data = train\\_test\\_split(combined\\_data, test\\_size=0.2)

# Initialize a Generative AI model (e.g., a text summarization model)

summarizer = pipeline(""summarization"")

# For example, summarize the reviews for each product

for index, row in test\\_data.iterrows():

summary = summarizer(row\\['review'\\], max\\_length=50, min\\_length=10)

print(f""Product: {row\\['product\\_name'\\]}, Summary: {summary\\[0\\]\\['summary\\_text'\\]}"")",r/machinelearning,Z0FBQUFBQm0yeGNDRk55NUFCY25RbFYxalZfRVJVVkZQRVlhXzRBZjZrYXNpV3Izb2ZzdlhfMXNsX3B1d2xKQXUwV0FXQmpteEliVVNQSVo3a2tLeUs0d0I3WW9lc1VtclE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDck1FLW5GODBGVnJSaWZORU5ZX1R3d2xNeDZ6R1FZa1ZhNU1Kbl9STVdOU3Izakg3WTZONWhuUVdXUnFSWnJqTFpjME9FTjlJWG5LeWN1dzR4aGZUTVE9PQ==
Sounds like ARR's automated filtering system kicked in. Anyone else get this?,r/machinelearning,Z0FBQUFBQm0yeGNDWnhQRTRsZ3dFc2VtLVdmQUo4b05rVzQyV3gzM0JWcVlLNEM5Y01QbGJJaml5OTRSQW9KVXB3T1oxcEt1d295RXNpVEZwYTFLdC1CcDRaLXQwdkhWWFk3Q005STRVaFM3U1NfeEhVbC0tUVE9
"Similar situation, I didn't submit volunteer reviews as there is no author who has published 3 papers or more in the last years, but I received an email for 

# Paper at risk of desk rejection due to missing volunteer

Now I'm confused...",r/machinelearning,Z0FBQUFBQm0yeGNDMXBWYzZDaWNMVWpxQk01M3gyX3ZUZjRjWkR6elI2cEVnWVROcEhwaTdkWDNpOXlJT0RpcngxT1J6N1EtMFN6WGMtZ0Z4MURJNkpfaVM1bGRwVU9hSFJTQ25TSWhJMXU0YUc4ZHM0MmJrSmM9
"I received one. I'm an area chair ;) My guess is that the system was a little overzealous this year

There are lots and lots of papers submitted this year. Please volunteer to review if you feel you are able.",r/machinelearning,Z0FBQUFBQm0yeGNDRkhOOUtTNVA2bXU0VURFdC1sdmd3c0ZNc081Y3ZONGUySk5QUXl6MDV2M21ILUVWQjlZak9zQlhHeVozZGRJZXY4UDVxUTIzcnA5R0cxdS1TdWxmb0E9PQ==
Demo: [https://ditto-tts.github.io/](https://ditto-tts.github.io/),r/machinelearning,Z0FBQUFBQm0yeGNDMzZpSjZVUktmSjRkNGFPRHlKblhuQTVwTGgybkVJYkdkb0R4TzBKNWUwYWV0NmZwRFFSQVFibGxzcENtOWdwTHB6bTdtU2JtcXFkRk00WnNkdzRDeEE9PQ==
Awesome work 💯 love the celebrity voices !,r/machinelearning,Z0FBQUFBQm0yeGNDenhZazZwOWlMX1VPMmhmMWtxdkxLUDF3ckJJeV9mdnBGQUtpWUZrS05rQjhROXN3dzBwTlVMU25VY2RxaGVMS1l3d05RUHNFZU1NV2g2R0RGRjVTTkE9PQ==
"Excuse me, but how could I do if I don't meet the requirements for the number of papers in to-tier confs? still confused what to do next",r/machinelearning,Z0FBQUFBQm0yeGNDMUM0N19JMnhVb3E1R25BdU1yemZLTnFHaEhSQWt5cHpXcVVxNXZMWEJyN0U3amxTb3g1am54aWdCOGM5b0xhMXkxczZwbURzSjJMdkpQVnoyaG5aRUE9PQ==
"Thank you for your comment! I'd like to be a volunteer reviewer, but I'm not a qualified one referring to the ARR requirements...",r/machinelearning,Z0FBQUFBQm0yeGNDRG5Bd3BFU1pXY2JIQzJRSkdMdVRFNi1CcEQ0UlRBNHRKeGpRaXlLYnNQeDdiOS1IQ2V0OHV4U1FLTzJHUmpJMFJZM3JlcG1CWnhNNFJjX3dGTnJ1ZERCSHpVMGEzZ1IyNjZ3Z0FxU19LNkk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDTlpjT0wxSTY5SHNpRk8xUnlPZVV1QWsxQ1NvQURBZVl1T2puelVOZDMxVEN5bTA4V042UzJmeUU1a0RLUldiTS1XdlRjc3dNR0hUOGsxbzkwUHllaVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNDcmVIUWxsTlE4Y3VOdS14bXp2akRUTC1IZTE3WTZsbW5BUUxEU1VWTWx3N013cWt2UTFmMG91cTY4Y3FOZkxReGVveXlnVFFybnR2c1ZtWWNKU0k5UHc9PQ==
Have you considered using DialogBERT or ConvBERT for multi-turn conversations?,r/machinelearning,Z0FBQUFBQm0yeGNDVG9jRGdoMF9JcDhYRklLVVBhNG9ZQzlYTkZTRTdPd1RCcGdfQWZOamc2YnI2N1piLUVIcWh5Q2tld2hySGE0SkRMNzJkSTRjQ0REOENGZUFSejJQS1dEUkgxcXlMVlhGa3FndVRSZlFKbm89
"This reminds me of some of the visualisations in this paper about the positional -> semantic shift of features through the layers in (self-supervised) ViTs

https://arxiv.org/abs/2112.05814 

https://dino-vit-features.github.io/index.html#paper",r/machinelearning,Z0FBQUFBQm0yeGNYTGw2Tk9sYjVodmxyU3lDTHRvRTlqTVBPM1QwNGw2N3gxRVg1ak8tUXk0Mjd5SEs4Rjd5ZjhRN1JJZ09GbnRzVUFfN3p1dmg4OUJVSUJvSkVWRUxXckc2SmVVblo0enVtNm92V2dDVkUxc3c9
Link to repo: [https://github.com/juraam/stable-diffusion-from-scratch](https://github.com/juraam/stable-diffusion-from-scratch) . I will appreciate any feedback,r/machinelearning,Z0FBQUFBQm0yeGNYMnlIenhtMFAySk0yUDNMVS1WaDZ5c2dILUdQUnZVWC05YVRDVTVoQ3pqOU4zMEs5YXZyaEMtR0NCUEpmVTliMXVWYlQ3VE5iNDJGYmR2MDFnNkQ3VWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYQXVJSDJockVOUVVlaWNoS0xwV0JZSE9BekdmeXBKQXJ3MkpkQjVPWElKUkc4OEdDNzAzSjdpMy1HekpYVDFWNjZKbWRTQjFwYlRhVWtyckFfOTVEUFE9PQ==
Relevant paper: [Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth](https://arxiv.org/abs/2103.03404),r/machinelearning,Z0FBQUFBQm0yeGNYaU5mODFrdnFFSV9ueVFJZGtBOHlzVklIbGNvME9ZTmt3RmxNZ2FsdWd6SE5fR0xZUndVdFV6SWlrdlFqREw4OEswMXNaQ1htemFjaldVZG90VUV6UWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYMU1oNDFmSzJNdkR4UXo3VDkzcVNUeGI0UUl3MERpd1BheU4yaF9nekMyREtFbDRzWUlTNGV2dFByNzBZaUNWTnpSWkpvVld3djlac0RKdFo5WlFUeFE9PQ==
"This is a well-documented phenomenon in graph learning. It's actually a bad thing known as oversmoothing.

People have also tried mitigating this homogenization effect in NLP and ViTs and found some performance improvement. Some papers: [https://arxiv.org/pdf/2202.08625](https://arxiv.org/pdf/2202.08625), [https://arxiv.org/pdf/2303.06562](https://arxiv.org/pdf/2303.06562)

I'm not actually entirely sure why this effect is disastrous for graphs versus other domains. It seems like it should be worse for transformers in NLP since their graphs are fully connected.",r/machinelearning,Z0FBQUFBQm0yeGNYc3BuMUEtckhfVHMzOV9mSWVhYmNPUy1yb09GRl9BOURNVmJDaXVqbmRvWmdtNnVlemd6bjlISEhVc2RHYnplVHFUdjJpanZ1R1RSa0pmUHpnWkNvRFE9PQ==
"Representing the operations in ONNX should be possible (although depending on the version of the standard you are targeting some things can be tricky). The most problematic part will likely be the implementation of the runtime or library consuming the ONNX model. Onnxruntime on CPU is usually fine, but support for other hardware tends to vary wildly: unsupported operators, uneven version support, partially supported attributes, limits on tensor shapes or dimensions...
I haven't used Apache TVM myself though, so I can't comment on the quality of that framework in particular.",r/machinelearning,Z0FBQUFBQm0yeGNYbThpZ0JHb2k3X1VFNGt1YXlGQmtZZXpjYWJvSEtFSUxfLTRDMFJHZTI2QVRJR3E0R09TVjZVclE5OFcwUDIwSVpNMklYcUdvZDlQS1UybnFJaWVVQlE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYQThMNXppaWhUUzh4b3VxOTBVLXFNaHg0eFBXcW9TRnB2Nk90SldtYlcyY2Q3azRIYXctWk1XbU9hbU95RjRQMjdCekUwWTVzN1Fqc0hvSklEajFBcXc9PQ==
That's the best way to learn,r/machinelearning,Z0FBQUFBQm0yeGNYbDBKY1gyM0J0WGRabDhJczlFZmswVzZHbHV4dW54aVhvTm92N3BUSkM3RmRvUHZORGFPNGprZG1DeUdYdEc3UmE2aS1fRDhDOVUxSnNKVGttMFllRkE9PQ==
"Good job, but your title and repo name are misleading. This is not Stable Diffusion, but is instead DDPM.   
  
How is it different:  
- Stable Diffusion is a Latent Diffusion Model  
- Stable Diffusion uses text conditioning (without it, it would be LDM, not SD)  
- Stable Diffusion uses a different U-Net structure, which contains transformer layers (not just MHSA)

Also, you should look at the DDIM paper, there's no reason for you to hit every timestep during sampling. That would be required if you were predicting next\\_x, but you're predicting eps. Note that DDIM has an eta parameter, which recovers the DDPM formulation.",r/machinelearning,Z0FBQUFBQm0yeGNYdndKOU9JRmk1OXRTNkpIckRHZ3BLNzBiWHVhZ2JfZGp0YVRpUXE1bFZTNkV6ZExIQU1jQUhPMnFsUHV6cmtRYlN0SzR3Q1Jadlk4WERIX3ZWcmpkSWc9PQ==
I swear 90% of my posts get reddits filters triggered ,r/machinelearning,Z0FBQUFBQm0yeGNYVGVyZzU4eDRiOEVvVHJjZXR6MTRidW1yYkJPcTFGalBxcjVCU0h5dkxITHB2NVA3ODY3TnB3eUtpVnpZQ2xPLVUwdENRZHYtZGR3S19RSmFvd1lodFE9PQ==
The mathematics behind diffusion text-to-image generators is unforgiving and steep.,r/machinelearning,Z0FBQUFBQm0yeGNYRmpXYXNLZW5LUHhORUhpQ2tFWjNNQTQ1WVFsUG5yY0pBUUl3Vmx6cWp4NDVJRnJZdm90VjVZbmxaby1WcENjT0Nrd0lhb2hzXzV3SzlaUUlyTEpFcWc9PQ==
VRAM bandwidth is more like 1TB/s though - and it's still the major bottleneck for NN inference. 15GB/s is very very slow.,r/machinelearning,Z0FBQUFBQm0yeGNYdEJIVXZZVGpmS3owTVk3SU5vV3VEOHJ2ZGhjQ3czVGlLTUVQT2MxNXd6ejlHb1ZNNzdjSDhhazhGM1ZkTDV2ajlHR3g2SE1wWDZQcnJfZDRTdFpSUDlPSnhabjhrQzR4Q0lPS2FBT2dEOWc9
"TIL GPU vram is more like L3 and has a crazy large bus.

> it's still the major bottleneck for NN inference

Really? You're talking about the Vram speed not the gpu transfert speed right? Do you have any ressources (paper or blog) about that I'm curious.",r/machinelearning,Z0FBQUFBQm0yeGNYdHl1ak1faWpoNk5WVHdwbGtQMVMzeDRIbVhodnczSHY4bVZzWVhwTEFoZEJDTmpyS08tV1lQNldyejlyZUhmMDVfTXRSdEdNNmZyczN0N01tZ3FmSUE9PQ==
"This is from Tim Dettmer's blog. Tensor cores can do matrix multiplication in a single cycle, [but it takes hundreds of clock cycles to fill it with data](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/):

>200 cycles (global memory) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 235 cycles.

>From the previous section, we have seen that Tensor Cores are very fast. So fast, in fact, that they are idle most of the time as they are waiting for memory to arrive from global memory. For example, during GPT-3-sized training, which uses huge matrices — the larger, the better for Tensor Cores — we have a Tensor Core TFLOPS utilization of about 45-65%, meaning that even for the large neural networks about 50% of the time, Tensor Cores are idle.

If you think about it for a second - 800GB language model / 1TB bandwidth = 0.8 seconds per token just from shuffling the weights in and out of memory.",r/machinelearning,Z0FBQUFBQm0yeGNYa1Y5Z2ZDXzFKeDZEZVBwbkRUMFZ0TEdQNGsxSHUyV0FYVTRuX0IyN3g0MmFaWTViNm96dmxPbzRBbEZoOXQ2aXNBZlRYVmd6WGd1QXJtUWppOEhPRVNuMmJQUzBpUWt5RVVSbWtCQ3Y4d009
This reminds me of the curse of dimensionality and how distance metrics lose meaning in higher dimensions. Some people argue that contrasting learning mitigates the effects.,r/machinelearning,Z0FBQUFBQm0yeGNYT013RmtPT284ekZzMkdiSjd0TlM5TVh5bTRkckZ2ZUpmMFlRMDI1dWFZcnJmT1lDSTRoVlFselJOQ0UwdXhOMVdwZ1JWaWtLT3Z3RzNkYndCUmVuamc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYdENGWmFBdkJGNlliWGd0cHZLQVRJd3p3Zldrc05aT1ljVXVwczVGV2RrM0tKLU11aGljTGdENnhHRGNkTkRlME1VLWVEMWE5eENzcWpZZklFYUdsdnc9PQ==
The math would be way easier if you learn VAE (pre-trained) first then learn the DDPM (fine-tuned) compared to learn DDPM from scratch.,r/machinelearning,Z0FBQUFBQm0yeGNYbHpNcUlyMTNDdjNQajZjWHlFWDVHNEZacUE3ZGIzRTlOTHBTSkVHeEJRejl0WG45LWloNktHWFE1RXJxWHdMZklTYUN4NmFKRG1ZN1FzQ3JTTHpWemc9PQ==
Amazing 😻 and I hope to play around with it during the weekend,r/machinelearning,Z0FBQUFBQm0yeGNYTGtrWnVkTEt4MGJvaGoydHUwYzZMNFlJbnNXdFZmcUVYTGRRcUgyMFZ5X3FvUlR4UFphczRreFA3QlIwcEdUeDJMTU85ekNEU2FGMWlvMFRKTlJlYmc9PQ==
P==NP? True : False,r/machinelearning,Z0FBQUFBQm0yeGNYMUdZVlBGdHBjemQ5Q0UyeF9uVF9nZ1E1LUdyUlNxZHd0LUNQTmlabXpmTzZDM0JXaHhUYzBNRGx0X3NxTGd3NEc0Y2k1UEZTRHNiQVpCQ0dlNENRMmc9PQ==
The answer is obviously: False.,r/machinelearning,Z0FBQUFBQm0yeGNYQ2JMTW1NVkhLR2duekRBY0d2Ml9wbDd1VnFmTVRGR1h4Um84eU9hTDJ0S2MtcEdCVFU1S0JpbFhBRndudTBnZTN0UWg2czBaQUYzRVo2anVsdDlvUHc9PQ==
[trendingpapers.com](https://trendingpapers.com),r/machinelearning,Z0FBQUFBQm0yeGNYOEVtQUFfYWdNVWlTQTgwODY0QjBCaW5YV0JYSU56allVVURsMlpZNUNJbjVnVlYzM0RTQWFSRlBRN2txVTFBVjVEeS1hV205QXNFNUR3dnc1MmIwdmc9PQ==
"u/sharvil , thanks for this useful tool! Unfortunately, latexdiff doesn't seem to be very robust. Have you considered using [diff-pdf](https://github.com/vslavik/diff-pdf) as a fallback tool?",r/machinelearning,Z0FBQUFBQm0yeGNYQXBiekU4bjZsNGpwQW1PZjlGcEhQX01VeVREU2xza3pMX1N3aDRUc0FuRmJvSU4wal9McDVMcjhYbG5XZXUtNmhpb09YaWh2M0JocmtmYjAzX0NoLVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYR2QydjgwVTc5amI5NzlSamdzUVIzNzktdUdjQW4tbkNJU2NaU0NxZUNVN3lOd0JxcjZHTk5tQ0stdnhseTF0VHBmeFFENDd5VXp6RGxQRVIxWUphUGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYT185R0xULXdmdGJWa1E0QWFteVdWbnc2UVhRMEY1YVJUNWtGbDI3TjhuTGtydjRwSlc3S0c5VHVCTnNzdHFHX3lyLWppMnJXeWdRZHZ6eHBUTXJUOEE9PQ==
"Thanks all for the links and comments. Some papers mention an ongoing debate whether this is related to normalization and/or mitigated by skip connections - fwiw I first noticed the effect w/o normalization but with residual connections already in place.

I think the root issue is the exponential effect by the positive feedback. Most NNs exchange info between spatial/contextual data slots, but not with purely data-dependent connection strengths. Attention scores are based on unique data but shared q-k-v weights AND target the same data from all slots. In contrast, a fully connected layer keeps unique connection weights regardless of data distribution. A convolution does share connection weights between spatial slots but those are not data-dependent and target unique data (neighbours only).

Btw for language models (regardless of masking) a possible countereffect may be that each context slot does its next token prediction, which can actively pull embeddings in diverse directions in later (close to output) layers.",r/machinelearning,Z0FBQUFBQm0yeGNYNnZBOEFISHN0d3lYbG9ycWhqTk1BRU1ob0RfOWVDUk8wN0dKZGZWQkxmR2FENDQ5NEd1OUxCSDlXbUpUMUdoUU1WZldKeFVfSk93RUNxOXhPeFM1eFE9PQ==
Can you please give me the link to the paper - I am new to stable diffusion.,r/machinelearning,Z0FBQUFBQm0yeGNYTmQ5Y2NyX2VTRmIwX3ZlXzZnYTFiUmNyU0NLUVZ0Qnl4cXk3dUdrYzZiWnFDTjdEX0Z4RlpBLXZjdkIzSW9LaXQzOWVNQ1RUQ0RRZXJWQnY4dkdNVVNNd1A3MHhxM0VNNE9ySVFwbjZNdDA9
"Some other papers have already mentioned but in the DeepViT paper they explicitly discuss this increasing similarity between layers of a transformer and call it ""attention collapse"" To counteract it they propose a ""Re-Attention"" module which mixes the attention map with a learnable matrix before multiplying with the values.  
[Re-Attention Module Explained | Papers With Code](https://paperswithcode.com/method/re-attention-module)

[\\[2103.11886v4\\] DeepViT: Towards Deeper Vision Transformer (arxiv.org)](https://arxiv.org/abs/2103.11886v4)",r/machinelearning,Z0FBQUFBQm0yeGNYWURCWWZXTzhtUjZ5TUxYZW5JZzU4cWdWZzlCVlVVTVJSZ05QMkw2MmlyMXlkN0tUUmZjRDVyNGZ5YlFQWGVjTFh2Vm5QcHJZb3hXNzZMbHozN3AwOUE9PQ==
"Thank you for comment.
Yea, title should be about ALMOST stable diffusion, but I said in my repo that the project is not latent diffusion model, it’s just the conditioning diffusion model.

I know ddim, which is a fast way to sample ddpm, but in this example I left only ddpm. But it’s better to mention it in the description.",r/machinelearning,Z0FBQUFBQm0yeGNYNDBZRmRKZE9KakRJS3FKcmt1NjYzd0R2TncxU29NWnhmMlRVVldxMDlma2N5OGprT1JmUUZheXJNNVRwNUtSYUloVzRzeGVpNEdOejN3YjcwTk5vbGc9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGNYQ09ZOWxUOXRjVElleEw2Vm5qZmptazFiaGpXeS1ITDhzSHVoeW9vdmozbDRRcU1lZC1oZzE3dEdCeG1VNXB5SVF1Nlg4S1dGdnBiQUplUkJhVTR3MVE9PQ==
Thank you!,r/machinelearning,Z0FBQUFBQm0yeGNYdlVETWRZSmtZYmZNVXlMSHZpeG1qQjlvcmVwZFdjT2hvTXJLNmFQSVJCZzdGQ1VlN2FpNWRvTkptb0g4ZW8xanJJcEU2c0UtVWt5cDJmd0VuV1NqU1E9PQ==
"I agree with you, for me in the beginning it looked a little bit harder, but after some time it became more understandable.

And I think it’s important to remember, that diffusion models are based on other different papers(and their math) and it took years for researchers to find the ddpm after the GAN, so I’m sure it’s okay to spend some weeks for the math.",r/machinelearning,Z0FBQUFBQm0yeGNYdDhIMENsOXlNWXFqaTNMRVlkeUxRUFdBaWlwX3ZFR3labFRNVmJBUHVWcUtrRV9xYUpPX1N2YTFIZDh1WXc2UUhEcWwyWGJDQXJpeUQybE5ncTRDNWc9PQ==
"Maybe it’s a better way to understand it, thanks!",r/machinelearning,Z0FBQUFBQm0yeGNYZDNKcEtTV0hXbnByYVFBS2F0YkY2Y1dSeDlhTERMSEJoeUpmaWY5WmRyZTNnMGJuLU0zSndCS21jbzFtalI1VGZsdS1SVG95R3BkRmc1YjF5RXcwZGc9PQ==
"By having a goal when reading papers. Why are you reading them? You should not read every interesting paper, there are too many. Find your niche and become an expert of it. You will read papers much faster and be more focused.

Also, sometimes you only care about a paper general idea/method/experiment. You don't need to read the whole paper. Start by looking at figures, then abstract and conclusion. Then, you decide if you really need to dive deeper.",r/machinelearning,Z0FBQUFBQm0yeGNYaHM2VkJPLVQ0cHZYalAyZE5KcVVVNlZhOEx0aUNJa09zZ2I0VHBOWkFnTklRVWwxUXZQTDFkSS01QTk5TW9qdVlYOFlGQXl4elF2VUEwdlFWSVlPY0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYVkpyaW5NV2oyREhKQTZMemVwODM0cjRYSE5oT04wQ0xYY2Q2VnRrR24wa3l6SXdaeU9tMUpLbkM3SVFuT0dOUlRNWnU0cjVWRFNwRFQ2clJMVk9hRmc9PQ==
Can someone suggest any proper university course dedicated to self supervised learning?,r/machinelearning,Z0FBQUFBQm0yeGNYSmpIakF1cFJ2NHBfZ1BIRENUU1pabXNsNXVRcjZubWw2S1VTUHZvb28xTGRSRXBzdDUwTkNDQ3czS3lyVWpPTVl1ZHYyUzZzWGdrUFo1dWpqdkQ0Q3c9PQ==
Can someone suggest any proper university course dedicated to self supervised learning?,r/machinelearning,Z0FBQUFBQm0yeGNYODdzTVRiZ2V0Rno2bm9Fc04wS0pFWXpXUGNLQ3RDdi1hSGtlWGJmWkk4T0Q4aUNjdkNIU1h1S1lQZmtjdjdrX3U5VEhJVFRaRWRDdzZSOVcwRlBrZ0E9PQ==
"For a more real-world feel, think about how you'd approach a business problem with ML. Here's an example: Imagine you're tasked with reducing customer churn for a streaming service. How would you frame this as an ML problem, what data would you need, and what algorithms might you consider? This goes beyond just algorithms and gets at the practical application of ML. It's the kind of question you might actually get asked, and it lets you showcase your thought process.

By the way, I'm building a tool called Interviews Chat (https://www.interviews.chat) to help people prep for these kinds of questions. It's still early, but might be helpful as you get closer to interviewing!",r/machinelearning,Z0FBQUFBQm0yeGNYdlFTb3FNNHg3U3pDMVZtMnVCdUhzenJ4Szg3cjB2Zi03MlIzMm1uSkpMWmxvV0R2RlRraXc4SW1tUzJGbDNaaHB2U05nd09BWlNkZVhPYmxYVkZBU2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYakxRSG91WVFtazRpTWtDLXROZlB4MEgyR1FiZmtOeGRnT29GanVrQ3Y4Y240aDl0QWdPUFVqUTR2U0gtRkxONDg2N2ZmclNmTTA0d0FFUEI0clRKY1E9PQ==
I just got scammed by i2sl conference. almost all conferences online are fraudulent and scam. infact if you are not invited through an organisation you work for or study at all are indian and nigerians sitting at home organised  trust me.,r/machinelearning,Z0FBQUFBQm0yeGNYVHNnMkxTX1htdjJ4S0J3VzNTMnZaVGFjSkF6RVhPRmRsZXh5dExNT0VlWU0xb2VpY2FtMHp1Z3RfM1p6aGZSdkVQZkxCTENnTXF0WFlPMmdrbE00NlVzMWdNa29sMHpWUURkODkxR20xdnM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYdnctMEZ5V1cxOUJtX09QaXhka0hNSEpsU3pYT0VmX3c3ZFVoNG0zYkxnSlY5S0s5NmtrUjdhMzhMeXN4YkVQMVhZTl9zeDVKMkhYTUh6dVEzRHZoUkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYenRodURaSUdTd3NVSEd1d0JHc2R0bDhVUW5vNk9BOGhrTnkyYTBNWTNsRExoeGVJbUEwell1R3JYQlo4U05QaHFuOEk2Z21hS3dNeWVpejl5TVRDV3c9PQ==
"Looks awesome.  Does it have functionality atm, or within the next 3 months?",r/machinelearning,Z0FBQUFBQm0yeGNYd1pYZVpES0lCelhILXNJeEphYnpzclpwcE51ZkNyR2hpeFNSczZNaXVFcnl2QnNxN0NBZXJfRXdMZ0EyMlBSMEJmQS13TFdLV0k3YUlCeHhTb29Henc9PQ==
"Yes it's fully functional atm, and you can test with free credits.",r/machinelearning,Z0FBQUFBQm0yeGNYTUw1RndmWHFEV0trV280UnBNYlNINGNoOEJHNG1DZ0ZGNWRGczYxUzlnd2lZQ0tSMHhQV2s5MENuLW9aZW9qRk8tb2RfTWlGdzlWS3Q2RVFCekljZnc9PQ==
"I really liked this course, it got me curious how useful the representations are it learns https://youtube.com/playlist?list=PL3mKiGE4zNJJ83K4c3IBka6eYfe6v71dS&si=ateKAkrBGqHDWS9Q",r/machinelearning,Z0FBQUFBQm0yeGNYSC03MVZZbWYzUjN2MXVSbnBYQU9hQjlyRGRzaXZTNnVlbG91dFhsMDFwLUFHREtmTDY1SFQzN3EzbGVsU2ZFaHJKcHl1ZVpYQVpXYUdyd01qYnFCV0E9PQ==
Cool work anyway,r/machinelearning,Z0FBQUFBQm0yeGNYWDZQeUp3V3Y1b3F5VUFrYVFfTnBHb0dRNkxoS3o1d3R2QzhMaF9MNTJNRGNTYThUNDI1V2xIaUZuUW52ZTR4RTlCMHI3Q25DbkRXeERTSTFfUFYza1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYRFBlZFhXcFJnSVVvQkozMUsxckMxbVQ2cUx1OEFkRXhYbjNyREpDU3VGUTM5ZjI3SUNWN0JXSzBOYlRHaUg2TmhkVTNKZi05bnVRS3dneUFWNHRZSHc9PQ==
"I think it will help, they did this in the medical domain https://arxiv.org/html/2405.01469v1. You might need to make some tweaks for your domain and it might harder when you have less data.",r/machinelearning,Z0FBQUFBQm0yeGNYUGtJc2YwXzduZ2ViWnZDbENGOXJveUEta2Qxbk9LZlROR0hDMU56V2FUNjJtOHhGamcwVjRWcThsUVV6dzJyWkxxQjljZktUa1loanNaUEFWekIwd2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYTGM5N2NDeHp0bDNmdFQzaFloNDluSmFaRU5SUFRJaF8xSG8tWXZJSF9FT0VIXzZtODJhZ3R1SG90OGl4d3hoMEp3cmJEeDJMUFFlbkstSjAzZWdzT3c9PQ==
Woah. Found my new favorite website,r/machinelearning,Z0FBQUFBQm0yeGNYeXcxd2dwZE1hM1JSSFl5WGV0b29mcmE2VFVBVHppbWFyQkYzTHpUM3NkcFRuZlRpM1BReGN1bUJzYWI3OVdTbzM3TUtWMG1Yamx3T19WalRsdUpocUE9PQ==
Thanks,r/machinelearning,Z0FBQUFBQm0yeGNYdVVTZXJpbjVZT3lCaTRRS1lzaEQ2Wm9YS21zWFJzaXlHanE1LW5wMWItSEc4QlFHcVZrT2RYVllhb0pSTmV0YVJkMWhkZURHdFJuRkRZVkZkdDV1ZXc9PQ==
I found the score-matching perspective very useful to get a good intuition about diffusion: https://yang-song.net/blog/2021/score/,r/machinelearning,Z0FBQUFBQm0yeGNYTTZJSHc4RHByZEF4dnFSS2lhazlzQkcycV9fMDl2VElrV0tuSVlDMndONWx0Q1RSLWZUYkJuc3hnV1ZCYkRxT1Iwa1R0Nml5dU96VzhzbDVjLTRvbWc9PQ==
DDPM finetuned?,r/machinelearning,Z0FBQUFBQm0yeGNYVU83Y0d6UE9fVnBoQVlSY3RKT3h3SW5TdlhtOGhJWlB1aGFXa011MmtNLTJPUXhHZ1pwSl8wM21CTXFBZFFjUENudENFazhHOWFNdjdORE5IUU91SGc9PQ==
wow!,r/machinelearning,Z0FBQUFBQm0yeGNYazl4azlISmNiS1psbFV5N283ajVUZnpfa0lqOXNnT1Nyb1JLQTVadGpMN0lVMHhWWkNZbzBjUFJaNzBYVko5U2dLbjJZdjh6M1dhVHVuVnBob1BkVFdYbE0yMF9UMkw1VFpadjc4VXJ3ZFU9
"It's just an analogy with training a model, like you pre-trained on some datasets first than fine-tuning on different datasets",r/machinelearning,Z0FBQUFBQm0yeGNYSkFmMXdvVEYtMzJMSE9xS1c5V25od0lQXzRUWXFGWmt5azhVRmlfZWNiaEFwd1VZbTZmblE2RzZWVTZVM2tHTFRTMTBxTmMzMTdUeGVuVkpOeTZoaWc9PQ==
"It's common for these companies to list projects representative of their work, even if a new hire wouldn't be expected to jump right in with that specific experience. Your 5 years in ML applications demonstrate practical knowledge, and your Master's shows dedication to the field.

To increase your chances, try tackling a smaller project similar to those listed to showcase your abilities. For example, you could build a simplified version of a tool like Garcon or experiment with fine-tuning a smaller language model for a specific prompting technique. Documenting your process and sharing your code on GitHub will demonstrate your passion and initiative. You can also use these projects to practice answering potential interview questions about your problem-solving process. Speaking of interview prep, you might find a tool like [interviews.chat](http://interviews.chat) (I built it!) helpful for practicing your responses to technical and behavioral questions. Good luck with your job search!",r/machinelearning,Z0FBQUFBQm0yeGNYSUJDdnM1M245ckpsdnl6M0tHN3g3UU5GY0k5c0kxSl9JNHplWDZxSmxwbzA2NUVaVUY3Wm9ud0VCN0gzaWFCaFcwSlpKMFo1WmZfTEtZTHJ0SmxHQ3c9PQ==
"You actually have a device with 80GB of VRAM? As a ""junk guy,"" I'm seriously envious!",r/machinelearning,Z0FBQUFBQm0yeGNYbHNNV3RTNmprNkVZYXJXY0NzZWJJbmQySmRFb253NHY0Sk9WS0pBVnpfc2Z6NF9zQU9pNWJSb3B5N09lalRoNmo3QVRaZ1hNcDRZOE5WcHliRkVVVWZDaFQ4TlJKLUtvUDl3b3VmSjR2RGc9
Obv I don't have it. It's a cloud GPU.,r/machinelearning,Z0FBQUFBQm0yeGNYQk5oNUQ5bklRQ0NYQjh3WFl5WlB2QUdTY3lKZ0pSUEpTOTlmX09lZHJpZGQwLThjYjhySUFBenBIcEQwdEJtZ3JESzREQjdkYThDTHA3RkNGVXYxTUlmNjl0eW1yeExzWnlMd2tKcmtRLUU9
"Hello 
I am working women 
In It company with Mechanical background 
I am studying Data science and ML 
But its been 2-3 years for college so not able to recall any mechanical stuff which can use in Ml and data science
Except ADAS
Can any one suggest what should  i do 
So i can excel in ml and data science career",r/machinelearning,Z0FBQUFBQm0yeGNYV3Q4RXVVd3liLUhmcTBOOHp0Z3o5YUQyNmtEQmxfNTMzRFl5TU81RFFUbmphYThFdURBcVdsZ25BR0pWczZnbDhzQzhQXzdld0dPOFRvanliT3FUWmFaSDRMQmMzMGlGbERoTHhnWlhCMkE9
Hello I am working women In It company with Mechanical background I am studying Data science and ML But its been 2-3 years for college so not able to recall any mechanical stuff which can use in Ml and data science Except ADAS Can any one suggest what should  i do So i can excel in ml and data science career,r/machinelearning,Z0FBQUFBQm0yeGNYNTZBYko4VEZHTzRNSmliU3VIMzk0N204QmF3S3B3Uzh4NVg2a1lsbEl2Qm9RclducTJzQ0NtcVZjdktadW1mR2hlalE5bVNNWENPeWJiV3hOeE5mRTVsMnl1c2xpTVZQSk9QelMtejlOa0E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYTlExWGtiajFRUWJyekNienNaZ0UzOER5a0s5ZnBSbjc1SUszMVgtc2FXajNMYmo5MjNqdWs1X0IwaHNqZDdOX05pQVlfWnNXMGJSTFdNcWJ1bjJrOWc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNYaHA3c3R6RHB3dklMZldUbV92azdJdXlDMDd6dFF0b00xZGNuWWl1Q1hiNmxZd0M3X19mVmJmbllVMVdjNDJ2MzkyYzQtNXAwVzVnVGExT1hleHlnUEYwZkZaOVh6NnJaXzNDLXFiX1dySmc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNYakUzeUZTcDlJZmhwaklGcEdBNUMzaFlDcTZ5NE9fMXpxektJSWczT0dWLV9XdmtITW1ySHI2RmwzT3o2MDEzTHdpM18waXZ4dV9JMFFrbDB0WGJOTjVObkY0SWhGTnJSSW1tWGlxTlRNM3M9
Thanks,r/machinelearning,Z0FBQUFBQm0yeGNYTzA1N1NnRnNmQVFCUERmR0lWRFN6Q2wwMTREaFBVeUJ1ZnQ2WDBxMFhiUnM3d0NXNGhHZmo0a3FHeXRjcUdrMXk4cG51ZUQ0SEJEcUlfNHJUX1VHMGg2aWIyNW10WnY1ZWNIY283Umtqekk9
"Yeah, I agree. In my opinion MuJoCo is a big problem for RL because you are almost immediately CPU-bound, which you never want to have in any kind of deep learning setup. I guess that is also the reason why nvidia isaac recently started to eat into the market share of MuJoCo and other physics engines.

[https://arxiv.org/pdf/2407.08590v1](https://arxiv.org/pdf/2407.08590v1)",r/machinelearning,Z0FBQUFBQm0yeGNYaC1uUG1oMWU2emxPNFFDeGloQWpsSFBESnFmZ2JncS12SDNEZnptNktWcUNYU2hjalJCa1AtTm5mUWFKUGd4czFyaDE4Q0ptN2ExRnAzdUMxZy13Tmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYUkViUGVLcXJ2T19NZ1A0VlpvSU5ud0VQNlN1WmJub2pjWHhRcnZYX2lhMG9UZ280aUs3cS1GU056Q19RaEF5N0pQVjhwMzhTamxSNTJVcmlVdUFsNWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNYRGhiemhnSFFUS0ZnWmV4YUdqUG4zeDlJNFVIcXczYWJHbUE0TE9OcnpXUFJZdlptTFlhNnF5UGI3SzNPMHdyS0E3U2hjQ1pqRWFVREx2Nl9XdGxnZkE9PQ==
ty bro,r/machinelearning,Z0FBQUFBQm0yeGNYUzFQcUpiSl9WUnRmMTlXQmtWS040RjRmZjFtcW53d3JHVjRGYUYwS05jaTkybjBqU3ZoWTF5X2hvLUcxLUIwZmdQZkU1TUVrdk5fb19rUWZqR2VHeFE9PQ==
Did you try mistral 7b for Lora ? ,r/machinelearning,Z0FBQUFBQm0yeGNZRjZnaVFBN1RNM0VfTUctQ0RialgzMlppSW1hQ3hFQ01xVmxqZUxGU0pYRERJMmNsUmdDR2hZeTlILVNLSjdCa2NLeTlZMzNPMmFSTmt2MmlDVGxGVWxCUlAyanZtcU9vM1g4QXlMNkNEdms9
How did it go is it mistral v3 or v1 or v2 ,r/machinelearning,Z0FBQUFBQm0yeGNZZkVKbFk2SThUOXNsVVBNTjZSVlhUcVAwZlFIbGFrdjg4cGZaYVlqRHktbjlwRUNJOElsRjNJNXRGS2tkRncydFBvb1VCWllTNzExUzZreW5DSXRzOTlCYThPaTVlLU5QOEhBejcyYm5odG89
"Clarifying in the repo does not make up for a misleading title, which comes off as deception for the sake of increasing engagement (intention is irrelevant, only perception by others). This is also doing a disservice to Ho et al. who proposed DDPM, instead giving all of the credit to Stability. While Stable Diffusion made it popular, if you did not include any of the contributions from LDM or from Stability, then it is a false attribution.

I don't mean to detract from the effort you put into it, but language and optics matter when sharing with others.

Also, I believe you misunderstood my statement about the sampler. Essentially, I believe you misunderstood the math for sampling, since your implementation implies next\\_x prediction and NOT eps prediction. It's not incorrect, but is along the lines of ""x did y, so I am also doing y"", when y was due to z, which is not the case for you (in academia, this is colloquially called a ""cargo cult"" method).   
Anyway, the typical solution is to allow for a variable number of timesteps which find the nearest points in the alphas/betas grid. Then you can specify the full timescale or a subset of it, but the rationale is described in the DDIM paper.",r/machinelearning,Z0FBQUFBQm0yeGNZaG51NXY5eVhScGpLT1N4US1EUExuQ19MLUFrUTFkMnVXQ3c0enQwMnFTcmxIQzJhMXc2d0d5TkpEeV9mQ0J6WUtUMnNZRmp3X296dG1qc3QwTlFyUUE9PQ==
"It’s abnormal but also you just came out of school so there will be a disillusionment period for everyone when they enter the job market and realize how different industry is from school.   


Even the majority of ML engineers in top tech companies rarely do much innovating, it’s mostly just implementation for their service on top of other teams APIs.",r/machinelearning,Z0FBQUFBQm0yeGNZVmdUSk1HUjloT2p2REdsNzhBTHIzUEVMRFM3aUhiWlRSdllUWUxpWlY2dVRzQWRvbFppdEwtdm51TFZLeURUSlUtTjg5WWZycGVjejZTSlRlN0dVVmV0YlpxWWJSRlZQN2hQRWpPTGxCOHM9
"we used v2 at that time, worked pretty well in our test cases it was about 90% accurate",r/machinelearning,Z0FBQUFBQm0yeGNZbGRMc1FCWEgzX0lPZk1qTmJQU3RIZ0NiMUR6RTQ0Y3IxMWI5ZXRHU2xOaDAtUDFmY2xKM0RvRjItYjhmbUx4SUh0Q2loWThnVnp6OGVLWmRBQ3dTR0E9PQ==
"We are planning to use v2 with Lora, somehow it hallucinate, could share how many layers you trained I'm doing 8
Iterations 2000 
Batch 12 
Learning rate 2e 5 ",r/machinelearning,Z0FBQUFBQm0yeGNZNnAyNEQ5U05kcEFkUnFxSjhCVTMzc0RzUERyMlV3RTM4b3VzWHlTbWpadkNnZjdPcFZQcU5LX0h1ZEpkLUNfeDB2VWRJNG1TQ2FMSGNYdVlTS25rYkZlTmF0RXp2eXZJV0l4bnlXU25hR0k9
"sure, I am not at my computer right now but will find out my lora config",r/machinelearning,Z0FBQUFBQm0yeGNZMnF5N3BMTC1xQ0JGelM4endON0wwUjBZbjlYcHVVQm1BbFJ2TDhmRmlaNWxTeHhTbkIxa0RFVEJCdWhWU1liM1U4aElSd3gzZFk0SjBBVzJzbnZvOWc9PQ==
"I see, thank you. I understand that ML engineers are not conducting exciting research for the most part and I'm totally fine with it, but honestly the project I was assigned to feels excessively dumb and I don't think it even requires much ML knowledge in the first place.. which is weird because during the technical interview for this position I was asked quite a bit of pretty in-depth ML questions.

Right now I'm just trying to decide whether I should stick around anyway to build some industry experience to put on my resume or just start looking for something else..",r/machinelearning,Z0FBQUFBQm0yeGNZTHd0NG5JRXBPbWNKbXI1ZHZvTnpEM21FZlcyNWxzS3B2T0ctYVEyeUE4RXRiaWt6MWhsVGQxUkotdzNudy1ObkRaMVBlRjJtS0lrVzRodEhTN0RselE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZbndnRExuZnMyZnp0NGViY1JCRDdVdFBUaUlTRk1ENlI2R3R1M2VPTW4tWVBPWFVuNnlRS1ZDel8zN1A3blBiSkpsT0pNTndlRGg1Yko5NzlnVGdpelE9PQ==
"I read OPs title and didn't really see any problems with it, but 

> This is also doing a disservice to Ho et al. who proposed DDPM, instead giving all of the credit to Stability.

this is such a good point. 

On a semi-related note since you seem to know a lot about these diffusion models, I recently re-read the Deep Unsupervised Learning using Nonequilibrium Thermodynamics paper which is where the idea came from and whom Ho et al cited, and I was a bit confused why that paper didn't actually take off since the methodology they describe is basically the one still being used in diffusion papers. What exactly was Ho et al's contribution? The DDIM contribution I get, but the DDPM one is, as you said, predicting the next one, which is what the original Thermodynamics paper was doing as well.",r/machinelearning,Z0FBQUFBQm0yeGNZOThUTkpnV0VRM0pIZXotbGd6Zk5mTHM4c0FscVp1b3h4djRwazJHRGtKT3pvaFZ0bThfTm85Q19iU1lSYU9HVWp2NlFOZFBReUFYR3NHUDNSVzFmTENMbVBYZ1N6OGFaOGFfTDNXcHdoYU09
"The math of diffusion doesn't change regardless of whether you are diffusing in latent space (with VAE) or in pixel space, though...",r/machinelearning,Z0FBQUFBQm0yeGNZQkhxdS04Q2hkUnhGU1o5WG4yTjdWeFFUUlFiQzVOeWtoVjltWFNHZHBiMllqRnRodEI0NkFLLWF2cFpxYTA4MzZUY3FhR29YWWR2aEVNTW9QdmRxYUFUMGFLMlAtN3R1TW1BUmd4YjlLXzQ9
"I think I gave credit to Ho et al. because, at the beginning of my repo, I stated that Latent Diffusion Models are based on Diffusion Models, and I wrote an math explanation of Diffusion Models, because the math of LDM is the same as in DM.

In the references, I included links to DM paper and other sources with great mathematical explanations of DM.

I think my title draws attention from people who are not familiar with DM or who want to learn it in detail. My repo is just an entry point for them.

My sampling method calculates the noise (or eps) at every step (from the model). Having this eps, we can calculate the expectation, and with fixed variance, we can derive the formula to calculate the image at the previous step.

Anyway, thank you for your comment. I realized that it's better to understand the DDIM paper 🤓",r/machinelearning,Z0FBQUFBQm0yeGNZSTVJdHVUZjlILTlRd2RJZlpOMnppSV85anlpOTlpUDd6Y2VzeVhOVE1VSjgxNDZFTDJoQWtjYUxlMUM3VVFPMEk2QnozdUdDaWQwVHNOLThxUzkzS1E9PQ==
"There is almost always a valuable but stupid project that somebody needs to support. As a new grad, you'll likely be the front line support for a lot of this stuff while you build skills that will keep you more focused on the important projects.",r/machinelearning,Z0FBQUFBQm0yeGNZSkYyM2x0WndlU2JvWmQ1RlJHM1lPcUN6ZXpWZ01jVHpra0lSYWdpS3NUcUNTWTJWV0huUFdUZ2JleUxIdUZvUDktRl9OVkF3c1ROeGpaeTg3VFZwbGc9PQ==
"Why am I getting downvoted?

""I demand to speak to your manager!""

'...

. . .

...   ...   ...'

FU too.",r/machinelearning,Z0FBQUFBQm0yeGNZUHF6ek9ncmg1TllKdFRINnV2TDZUMkZpWnRJVXpfVGhETUxaVUFBenZQOFVlYjI0VVFBd2wxbHJFTk05dkVUTkJRQjc1YVhvWkxvTm92OTJ5OS15dS1ael9TSEVfNkowZ19EVTJUSFlRSHc9
Censor me harder big daddy government.,r/machinelearning,Z0FBQUFBQm0yeGNZcE9yREVQOTVRbkJzSENid2pabEtiNXZvQTkwYVdodjRYWEtwb1FfSllRUktEcVB4TEFZa1NJV05iWWF3eFVRdTVRX2JmY0RWelVudVhQYmVRTEdVVXp2WlJ3aUxuYVdQbTFOSW1xcDJKUU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZV3F6cEZoZU1tQ1RxbXVyTDNlZjlhMFlKa0NnVWZRZmt6Mmk2TlhTekYtWjU3NGN0eFl5MkVKTUVENUVEa0pGUldnWTRQM0s5YTQ3dmlUWUdySlpwcWc9PQ==
"> Some day AI will understand more from my handwritings  
Indeed, this would be super useful then",r/machinelearning,Z0FBQUFBQm0yeGNZTlRFZGxaa3d5dmFOQmd6T2p4MnRCRzBrZWNldXlqWGcxMnZSNmRBOTFtQ3pTUDBTUXZqUXBCYkdqXzdYeDhFekdGNjV6cl9aWXhxM1FxYWpFTHU5MGc9PQ==
Any references?,r/machinelearning,Z0FBQUFBQm0yeGNZQzRZNUxhb3Fjd0NsT0xYMjQtTHBRUWlGUmtSOF85WXZCRDFzSXlueGVRU0ZnREVPSnVEM2xHTUZlM0JNSlhGWnpxLVFnbmZJTE1IeUFtMjN1YXA2bXV6bzhudV9nLUQyaU1paGV2eC05enc9
"That's a bit of a joke.

In reality, it's probably a bunch of *dudes with trust funds and/or a bunch of arbitrary units (ex. $'s)

.",r/machinelearning,Z0FBQUFBQm0yeGNZWmUxQlg1UG84UERqd242aUM3RGhKT0IxNDNnMEs5SEtGZ2QtQ1VTenVmdnQ3ZmludEJTQ3BKTTFjTlJMZnBJbmIzMzFwdS16VDJVakdiUXVHQ2ROV2djdEdCYzNkVHNXSEJvbzVkeGNyZ1E9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZZ1JaRmx3bUZIV1hxSmNWYm1NVlc1Q0lObHFXTVAzblJwQThraV81UW9xYy03THl0d1dEVlJfRjRXM09DM0VIWTRRaHN6VXBkbWEtbE5wLWRPOE9SRUE9PQ==
Noice,r/machinelearning,Z0FBQUFBQm0yeGNZUGtRa1Nmbjh0Z1VEMkVmdFJwMm5HNEtsakhjcEZuUHpRaFBLc3o0d3R4OTVUZ0FBUG9MRmo4QWpIdlRLTENNcnJjb3g4VjVVZlY5ZlhiTmpMNHZiWWc9PQ==
"""Everyone on Reddit is a male.""

Correct.

'and if you're not, it's probably easiest to pretend you are...'

.

. . .

.",r/machinelearning,Z0FBQUFBQm0yeGNZMUJidzd4eWo1cnBrYmNtYUpuVXR1Rmota2lITFBfLXNXbG9pVEdFRHg0bkRmYVY1ZUpTX21ZYzBEaTZPbVozR0N3MkR5X3R3RjY4a05IcFpNOENVMi1semNwRnotUUdzS0h2NXpvaTh4NWs9
So everything ur phone can do but packaged in a box to deceive consumers that already have hesitations about AI?,r/machinelearning,Z0FBQUFBQm0yeGNZX2RhbGlYT18xUWNfNnRqSm5tMzd0dy1MV3I4MF94Y2NoNWF1ZV9UVkVuME1PODdhT21vMUpyMFdOSGNjMXI0dm1jMG1OUjNpYURpQW95Mjdibm1JakFyYVllUW9mN255XzlMZ0YxN1ZNdW89
"Many jobs are going to stick you on boring projects as a new hire even if you're experienced (if you're an IC), at least for a few months. Unless it's a tiny team they want to make sure that you're actually competent before putting you on business critical work. (It's not uncommon for people to appear more competent in interviews than they really are.) 


You should probably stick it out, and if things haven't looked up after a year, find something new.


Edit: also, like 95% of MLE work is data plumbing and making APIs or gluing APIs together, even if you're working with LLMs (or whatever the current hype is). That's the job. If you want to apply ML knowledge you need to land a Researcher role.",r/machinelearning,Z0FBQUFBQm0yeGNZcVpCTmpiWGpYb0pSZDZULW9uWU8xTG1CQXYxMURGck1EV2c1WGZWeWt4d043aDB1dkVVMEhKSG5tZXpyWnNlaUNhQVNISzJwa3hWTmllX2ZxcW5jRWVkUkMzUVB2R3NyeWZ5aEphZmYxVW89
"Not trying to be a hater but after looking into the specs this is absolutely a waste of time and money. 

There’s so much better things to use or do. 

“HyperAiBox” is a killer name",r/machinelearning,Z0FBQUFBQm0yeGNZbVB3aWc0NHAzUkttQkVRaHJ1ZE9IQkxSZlMwbG1hcDhHYTlhOHpXVWxqdXk0UVY5ZFE2dVdZVVNVa3VSY1JMQUZVa2tRcHBnZ2wwVDAyektYbjEwcVE9PQ==
This is disgusting.,r/machinelearning,Z0FBQUFBQm0yeGNZaGtadmYzZlpzRDNZU2lWeGUtREllVnZlenpFWlpnZjlVcWJ0R1lEWjBaZGVicUpGWG5RTnFLWXhsTlRUY3pmekpBLTBLNzNla1U0SmFGM0R3d1UwSVE9PQ==
It's a complete scam. Another physical wrapper to OpenAI and 11labs API calls.,r/machinelearning,Z0FBQUFBQm0yeGNZVF9ySTdPSEhFZDN3SGxrMzZoVEx0RlA1S1ExalJSM0pQZS00elQzM21xeDQyVDJfc0MzWVNRdVhWdE9kcTRBenN0NU5vTTRQMWtybE9kQWVtVU1mdHEzRXJ4b0drcllEUFhjOHFkRGpxYk09
"Chill out dude. To your point, language and optics matter.  Your language is not constructive and the optics are that you are pissing all over an individual achievement.

I applaud and am grateful for anyone that shares something like this.  Kudos to OP",r/machinelearning,Z0FBQUFBQm0yeGNZei1MeWRiaWJfX0NwcTUyQjJibktUR0NGSmV6U3l3NWpyMWFCRlk2aVBjVlB2eU8wWmFqR3BkYzJONFdfbkhkM0xYREFqc3pYeDFRVE93ZzNtdTBieVE9PQ==
"It is indeed a very tiny team, but I probably was assigned this project because other people are working on the ""main"" (and more complex) product as they already have experience with it.

My doubt was mainly about whether such a job is to be considered ""normal"" (considering I'm a new grad) or just a weird scam..",r/machinelearning,Z0FBQUFBQm0yeGNZU2tWX0FZYl9hSUFPX3ROTnZNZVJKamJFZUJqX1p5NXZVNnVwQzlzY2dvM2lsVVdMQkxSXzdiVTA1czd2T0h2UnhXZ1lOcTEzd1pIdk9xRFNrSHVmbnc9PQ==
"Even in research (NLP domain), a lot of papers nowadays are mostly about some kind of modified or new prompt engineering technique

This is because it usually gets more attention (a broader field of people benefit from this kind of research as most people only have access to llm apis) and its less risky compared to fundamental AI research which involves a lot of math",r/machinelearning,Z0FBQUFBQm0yeGNZT2F0T1hkd3ZoSEt5dmpZa2J4SEdwVUNGa2lfTk5NeExxTUYydWhEQ2dxTHMxdDBLRkpDZXlxRDJXOVhiZVg2VGJ3aGF1R25QRTVUMkJDblAxM0cteHc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZSkE4OExveGpTbGpnNGg0NUJFX1RPODYtcHZfR3pUNzJ0Tm5CQVlpZUNvRzlVSnpwV2FLRzZCaG9OcmFHSXdQZjA3MjZpN3RvWk1TT3Q1cXlwNXBIaXc9PQ==
"Maybe you can try Q-LoRA (I haven't done it, but I plan to try it soon), here is a reference: [https://github.com/QwenLM/Qwen/tree/main](https://github.com/QwenLM/Qwen/tree/main)",r/machinelearning,Z0FBQUFBQm0yeGNZNzkyUnF4VEtycVVkWTBORmhVLXpfZUNkQTNoT0Z1c3ZBTVVLRjQzbU80TWQ4VWY4SWVPa0RkQUFEYkMtMzB1M3JIVUJ4VkRVdzNBTXI0ajNKY3RBZHFwLXhxN3lLSVhNbGQ0TVhCcnBlU2s9
"Now you're the one who is not being constructive. You may have noticed that I gave the OP kudos in my first response, but that does not excuse deceptive naming, especially when others have done similar things and actually implemented a LDM with text conditioning.   
  
My criticism was narrowed specifically to the naming and not their effort (i.e. making it constructive). If the post said ""I was struggle how Stable Diffusion works, so I decided to write my own diffusion model from scratch with math explanation"", then the meaning would have changed to a ""diffusion model"" and not ""stable diffusion"". Same thing with the repo title, ""diffusion-from-scratch"" vs ""stable-diffusion-from-scratch"".   
The issue being, someone who doesn't know the details of image diffusion models may not understand the difference or that there even is one.",r/machinelearning,Z0FBQUFBQm0yeGNZczJlc2EtY3RXbGdEWTd0WTFkNU5vT0ttQlFZczF6R09Bak5jSHFuVUJueWVXVmxFTnZlR25wYVltVVNrdWQ2a0hfMnowaTh6bl9vNl9SVG5SYkV0VFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZQ3loM0hobDJ5aTZ3bHVoSzVFd0VZdnlvUTBqTEJzN0JhVFpHZDNQY3FGSmtrdkN5VnYyWWNaSGN0WkxyNHZYOEFmNkhfRTh2cjk0UXpHeGhjNTIwQ3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZREhZRXk2SE4wSW5Yd3NCSnlTQVo0allib0U5TWM2WXNPZTYwZUVWejdHMmpfc2trZm56bmRfLUNYU0tIS1ZaM0w3aThfZXBBYlpSSHlGSWRXVkttbmc9PQ==
"This is totally normal. But you absolutely should expect, and should pay, a good rate. 400k is definitely for a US senior, and you can find great people outside US for \\~60k a year, but of course you will have to deal with some paperwork, differing time zones etc.",r/machinelearning,Z0FBQUFBQm0yeGNZS3VHbWI5LWtCZXlNU3k3QnBxN1dsbjRGc3draE1iaF95SkF6c3pOU2R0dGxMMV9wd1A3UHVuSDlXZkpmcFVqU0ZPOHk3NEFDNHhsdVlOUFFwSk45akE9PQ==
"I have the information of the Bounding Box as follows:

The upper left point coordinates of the box (x, y)

Width, Height

Rotation (the current rotation of the box is clockwise, the unit is calculated)

How can I crop the box to rotate in the right direction?  
Thank you very much.",r/machinelearning,Z0FBQUFBQm0yeGNZd080ZjdfT0NiT2lMOXhqX1RpejhLUDQ3Z0RaS3ZyazBkY2tGZmJlZ25qYWJFQWMzQlk5b01lalpWNjlqSzV3cDl4T01kUGUxU25WbUpqckhjMFBwNVE9PQ==
"I have the same problem here. It took 8 months to get the first review. Now, I have been waiting for 4 months after submitting a minor revision, and the status stays with 'Reviewer Assignment Pending'. I like the journal, but the reviewing process can be improved.",r/machinelearning,Z0FBQUFBQm0yeGNZTGJ6dGZ2ZXNIdmluVGhpaTlRSlRiZk1QeV9kUEI0RGdEV21tTjh2Nk5TQjVVbHdOVVVvTWpiZ01JVU5KcDZ0eVpzdlUwNFRSRnlFOFNrYk5GY2hTTVhIVGktLUl3b0pERmtRNjJZS3V6ZmM9
"This does not sound like a scam. This sounds very normal. The project presumably makes money for the company, and it seems like a convenient way to onboard since it's isolated, and it doesn't require pulling their existing engineers off the main product.



I would expect that if you demonstrate competence here, you'll be asked to help with the main project in time. You need to set expectations with your manager.",r/machinelearning,Z0FBQUFBQm0yeGNZRnVSd0ZmdnNnc3hwcF9BbjduRnNZWjJheVN5S1pxeTdtaTZ1cHhpbTd4V2lSXzlNcHZ0QUg0czhucW0zMUxvS3RBYjM5cVdQYnI4TmdSOFlJcVVkSGpJaXNzUnh3VlRSbzh2MWFmVzN4dnc9
Your main tool to combat work place abuse is to interview elsewhere.,r/machinelearning,Z0FBQUFBQm0yeGNZdWpqY1NBckhIdlZLdmxya0NiYlRjYTNuRmxDQXdWSVoxR3gyQ0IyLWdtUGF3WlRHa3hKRDNTZTh2bW1nUzhUaE5ZSFp5TjdEYldkUFFZNXlFZU1zM3c9PQ==
"The show Silicon Valley used ""the box"" satirically to show that Jack Barker was incompetent/out of touch. But you guys went and made a reality",r/machinelearning,Z0FBQUFBQm0yeGNZNlMwVnpBVS1uNVo0SWhtR2VYdDRvVWVVdk9NakxSOEN1cFNDWTk1OThwUThZUVdoMThUV0NDdW0yVlBQQVVTQmgycHd1MU1hSUhfNzZ6NnBxUzJ0YXc9PQ==
"I think there's demand for good content about machine learning topics, but I don't think that demand is satisfied by meandering, pseudo-philosophical blog posts whose titles are unsubtle attempts at coining a neologism.",r/machinelearning,Z0FBQUFBQm0yeGNZWjR2M0FYUnhncVVJdzA3eFFNUE15aDBZeWxsV2o2WjUyWEl1VldvUmV4OFJfOVgtSC1IUno4TGo1eHJ5Nm1aYlVobVFsclcxZmVLd2phYmVqZDQtRmc9PQ==
Nice,r/machinelearning,Z0FBQUFBQm0yeGNZVGpKREt0ZGZFMGp3STNPbEF2c0NHWkpvRHZEX3VIcnpfUUk4YnJHUk1DQmF5LXdIS253Ymp3YkJIXzRjeThjeDVIYVVhcHRXcUpSSktVdGNzTS1BaVE9PQ==
"so the natural model for click through rate is logistic regression

you pass in eg the number of trials and the number of successes",r/machinelearning,Z0FBQUFBQm0yeGNZTS1HT3lzeVdieGFLWTM4QkZkXzFhVDJ5XzlCLXRINTVDVVpRRXRlV01oSUdOdGtQcXhpVUZBUHJUMFJ2OFBxUkdyYk51TkpPTzRoN1FfcmRPMUlCRHc9PQ==
"As someone who worked with both seniors and juniors in a startup setting, do not hire someone because they're cheaper. Seniors are important for the foundation with good reason, they've seen it done before. They know what infrastructure they need, they know certain pitfalls and they're better suited to let you know what is likely to work. 

Students - don't. They have to learn things what the industry teaches over several years, whether because of scale or because it needs to become an actual product, not just a paper. 

If you do not have a senior yet, do not hire a junior even if it seems like their research was relevant. If you have a senior and you need to increase research bandwidth, go right ahead. A senior may support 2-3 juniors at most without feeling like they're babysitting. But make sure they are involved in the process, let them interview and select their team members.",r/machinelearning,Z0FBQUFBQm0yeGNZMURVWUw2WnRJTmNYYXgwbDBVaGxTckpnRUNQbFhZSG1nSnhWdk5SbHBCOUpFUjA3c2dpSFhPUlJmdFBaOXlwTVJGaDRZZzctT0dBTXZwOGZEWFNSZ2c9PQ==
You dont see people working on os at large companies because they're actually working on important projects. Eg the t5x codebase available for os isnt the same as their internal one,r/machinelearning,Z0FBQUFBQm0yeGNZZ0VfMkJfbzJmeTRaTEl5ZkoyU2d5MnROWURuaUdJMmdUeDhTSU94bFZ6WG5hcnRBYzh6eHlpWmZSTEljRERkamRlU2M2c0dPUlB4eTVVN0s4WXZyNlE9PQ==
"My first job out of grad school was also in a startup like yours, so the post hits close to home.


> This isn't really what I expected when coming here.


In my experience, this is normal. A few months into my gig, I had to architect and redesign from the ground up a (at the time) pretty important product feature, which was awesome, but I also had to maintain another feature that a parting member owned. I saw similar scenarios happen to other newer hires as time went on, as attrition was generally high there.


Learn to embrace the chaos these places have, make it work in your favor. Try to focus on the business bottom line for most tasks or projects, to maximize impact without burning yourself out (can easily happen if you're not careful). Then, for the projects you're truly passionate about, frame them to learn as much as possible and be very vocal about what you're doing/building/trying. 


As an example for this case, if you feel like you're ""only"" doing prompt engineering, try to throw in a few tests with automated optimizers, or other fancy setups (there's a bunch of cool papers out there on this topic). That way, you've still learned new techniques or tools while maintaining something that may or may not be impactful (hence, going in your CV).


Startups have plenty of bad things going on for them. But the variability is very high in most dimensions, so be on the lookout and try to leverage any space or flexibility they give you regarding e.g. learning on the job, networking, work arrangements (remote, wfh, etc) that may compensate for the negatives. If it gets too bad, job searching on the side can't hurt to maintain marketability.


Best of luck, and enjoy! It's generally a great time to be building products with ML.",r/machinelearning,Z0FBQUFBQm0yeGNZUTYza0V3c3lKNWRXUjNsN21ndzJ3UjQ3OFpYU1lfRndXMHRDQnRjZTRERV9Qc0pfMTFYcTBtS0UzbUFMZE84VEwyd1RMWUNMWk5UR0hxanY3ekN4emc9PQ==
"I am pretty sure I can't contribute right now but Im interested in it, please dm me the details :D",r/machinelearning,Z0FBQUFBQm0yeGNZYjBLNnpWRk9rX1VFU0xlbVVjU3hQekJKQmJxLV9oRFBnUzRXLXIxbFA0dHBqS1RZeDJwR01udGVfOGdjUGRyQW1Ca3ZrTXFseUc2SENqc1ZlTDlxbEE9PQ==
"Hi,

Not sure my problem statement is relevant to this question, just putting my thoughts.

I have worked on big data systems where two tables are joined with data in memory in distributed systems pulled from central storage. These joins are done using hashing or brute force method or sometimes randomly.

(e.g. Mapreduce in hadoop does it through partitioning)

can this problem of joining two tables in distributed memory be solved using AI with AI predicting which node to look for the join without hashing or brute force or random search ? this can reduce join time...",r/machinelearning,Z0FBQUFBQm0yeGNZSkExcmd3TzRqaXhSSnZqckxPWFhFU055Y1puTGJsTGYxTnpROGpMVEFpTGZhWEZZUE9MTXJ5NWVWdUlFZnlXLWJuWl95ZmpfREoyZFdmd0pFNVRuekE9PQ==
Will do for sure 🙏 thank you!,r/machinelearning,Z0FBQUFBQm0yeGNZRXhmdFdpSWE5TW1BaEhuOXBRWWY3bXFMQ1JtYlk4a2hvTlc2MTJRdldLbXgxRnctWHN1SlVMaW5yZnQxcmJuTklDMlZoMXVNcUM0Mktfa19MR3l6RFE9PQ==
Will run it through the system and let you know of the results! It should come up with some extrapolated proposals that should at least sound interesting 🙏,r/machinelearning,Z0FBQUFBQm0yeGNZRVo1R1Z4MHl5SVZVbjc3UEsyOXBtZ3FwdEU3WktXUUQyUGowbVRFMDVIMWJGWU9DTFU3UW1OX2t3QllQVy1lRWJmckZnNnZiZy0tdXhlNl9yVG9pMGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZdFpjTXpVS29XM2pPamR2LUU5ZWkxRy1wSGowb2Zub29ncUxRMVMwQzdOUjVTY2ZBZnZDWm01RS1nYzlYdld3cTB4Q3hzWVBwR09GSkJ3a2JfSWpWRGc9PQ==
"I mean I'm having a hard time finding a half decent frontend guy overseas, really lost and having bad results from upwork, even from toptal. I'm not confident I'll be able to find a good overseas ML guy.. any advice to for generally finding good overseas developers in a sea of bad ones?",r/machinelearning,Z0FBQUFBQm0yeGNZdjV2UmxvTzdoQ1VXZ2hHa2wyazZwajJYMDk4TVNBd1l2YjhmZHB4ZUMwYXhtOWU4T1luQ1NUdWhZTGlXeWcxbFBDQXh6TWxjeFh5cjBxRGl4dUh4VWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZRFRLc3duSmRDZmprWDdBbWtvMktDcmNIci1aMjhtMXlIWm4wNFFGbXhLODYzNEhMbGMxUEJOSE9LT2MwNEpfVjUtOXJtRDJTaHI4ZzkxYU1nOTJlMXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZX3VjQll4STdfeXFFWWFfS1V0YWZRNWNPelBPaG5HaW5zZEJsQ3VEN0ZFRzRYUjlVRWI2S0JrS1dGOU9OcTgwOEp3TG00NGRsbHdPaF9EcmczWnowSnc9PQ==
"Just trying to understand. Why stating that the representation is discrete? In my understanding, as the RL is simulated in discrete-time, all representations are discrete. Some can be analogic, and some digital. Is the whole field using a terminology that dont match the usual ""signals and systems"" terminology?",r/machinelearning,Z0FBQUFBQm0yeGNZbXJmYlgtRFJicjBocVlZam9zdDU1MG54Nk1DZ29EMDBRMllWeGt3SHdIeWxqM2FaUzVsTm5CZHJENzE2dWlfTXQwTzdhd2tNb0RHd2I3N0hYOWszRHc9PQ==
"discrete here means, e.g., binary values for latent vectors.",r/machinelearning,Z0FBQUFBQm0yeGNZbklNVjJrOHVIZWhGS1J3ZjBTNFNJaTFSUHJoUWxTLWRONi0zRVA4SnJZV2MybXBjTzBSWTN1bU9nWUprQmJleFZEVnV0dHNFT2xfM3pNZnduckxHSmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZMVBGUE5lWFRtenVhNkxPOVh6ZW9NSlFZT2FsZkc0QXdvakFNX3ZaZUpvV0ROUXZta0JyRG1VWV8yU0dnUnJhR25CdC16QkViVW9rWGFPaVFZN1RGeWc9PQ==
"reminds me ""the place""",r/machinelearning,Z0FBQUFBQm0yeGNZX0w5VlNBS250V182UW4tM3k4NnZXRFZ1dTN3Y3A5QkFYSUdMMDZ1REhWTDJKZDBpR3Y0cGZqX05DbEtxbGtEX3U5eWppVTByUlI0bDVBdGxGcDdMa1E9PQ==
*Of course* OP's post history is all crypto and sports gambling.,r/machinelearning,Z0FBQUFBQm0yeGNZWXc1dkpDRk5CUVNxQ1BjdlZGYUxkUlBkajFDSHVLb1BHdXR5U0ZWNDFVM010dXJWQW9YWHRpaDV2c1NTOXFCeE9pZGI4OHM4Y1RmaDdfZGhjSWY0RlE9PQ==
"I'm not exactly sure. From a fundamental perspective, I believe Ho's contribution was the inclusion of the noise schedule which allows direct corruption of images with random noise rather than applying a Markov process. It also could have been the use of a U-Net + scale.  
However, from a practical perspective, his contribution was showing that diffusion models can produce high quality images. The Deep Unsupervised Learning paper showed generative results on MNIST (which is an ""easy problem"") but showed poor results on CIFAR10 (a much harder problem). Whereas DDPM showed very good results on CIFAR10, and then showed the same method works on CelebA-HQ, and LSUN, which I believe was the first time a non-GAN was able to achieve quality like that.  
There may be more nuance to the differences though - my background with diffusion models is more so on the architecture side rather than the math. Also, I think optimal transport (i.e. flow matching) is easier to understand than thermodynamic diffusion, especially since it boils down to computing a ODE/SDE (the implementation is easier too as shown by the SD3 paper).",r/machinelearning,Z0FBQUFBQm0yeGNZdm9obXNZeEo2cVdkYWozXzk1M3Zid3lUS1p6M1FUWUtUV2RpS0FoSVVPd1FHOFJNcHpkS3VlUjVQWFd3MWY5UDFFX3pYeUg2MlRabEtLVzBkQ0VxUGc9PQ==
"New hires fresh out of uni are a gamble. You may get the overachiever who is super eager to prove themselves and will work crazy hours and absorb info like a sponge. And you may get the party boy/gal who will take a few months just to start working at reasonable hours. 

If you choose to take the gamble, your hiring process should include a take home test. Provide them with some anonymized data from your company and ask them to build a poc in a week or a couple of weeks. You will find fresh grads a lot more receptive to the idea of a take home test compared to seniors. And you will get the chance to see their work first hand.

Aside from that, you should have at least one senior person to take the juniors under their wing",r/machinelearning,Z0FBQUFBQm0yeGNZS290MjdVaFFRUkJRN1RwRzVyNjF4cWVSeGMybGhfaG5COU44ejVCS28xQ3RuWmFYSGoycXZSdVVsLUJsYkQteFdGVGtKbUhBQVhkVVF1bEgyY2piNnc9PQ==
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGNZTnlqTWt2dlI1YjBGVThGZmhTUzdzaWdpcjcycUpwQlUyZk1hdEVST1prN1RDLWdHYWhZUHRxVHRyTlR2alBrVHZQa0ZiLV9hOFpEWDZLYy1Femk4NllBallNU2l1RXhlM0cwY2tBVFlLUHM9
"Working at a startup that sounds pretty much par for the course. It's sort of the cost of doing business in a small company, you don't really have the workforce / budget to truly specialize. Everyone wears many hats.",r/machinelearning,Z0FBQUFBQm0yeGNZU0U3Ym9aZFY5bEZjR2FpRXB1Rkh3WGpnZ09HXzRYb1ZkOWtrUFdPZHFEZ0NJdWkxeDBqdFpUQUE3OW5VdzlIVVk3MlRRUGNxZS1uZWVhaFNIcEVrNzlRSzJmR2U2c0NvU05Ic2pZcGxCeGs9
"Depends on what type of ML you want them to do. You shouldn't be hiring PhDs unless you are doing actual research. I've met many talented ML PhDs that are not great software engineers so they'd need support. If you want to incorporate chatgpt or stable diffusion or something you don't even need an ML person at all, since that's just calling APIs which any software engineer can do. I think hiring the grad students would be a gamble, but those 400k people are also not guaranteed to be that great either -- they just have more years of experience so thats how much big tech companies pay them because of the way their pay scales work not because those people are super talented.",r/machinelearning,Z0FBQUFBQm0yeGNZc3JpYWpHNk9nZzg5SmdLWkc4bkJNQ3BySjdwNlFzZE8zNUpjeC1lVGdyYmVXbm0yWDBuNURVWFZSZUh4V296WGNwczVwZDBidlhmcVZnNnItd1REbzlGd3FKMFQ3enl2TXZJVnN2ekVYQmM9
"Either a chatgpt or other LLM api that supports TTS

Or Finetune/Use pre trained TTS and STT or multimodal model from hugging face",r/machinelearning,Z0FBQUFBQm0yeGNZSzhUTFJnYThBc1lfc21rekg3cXRfMWl1ZmpnOUdmeGRTb3F1NHpuVUpBSkl2RHd2UnhCSlJhMHQ3SFUyWTlhVnc5ZkFkX3JQZEFjNmtxSDVqcGhlUXc9PQ==
"Yeah I was reading about and considering it as well. 

I had just stumbled upon Beta Regression for proportions and bound dependent variables and saw that there was a relatively new package in statsmodels for implementing it that’s validated against R.

There’s not much beyond the documentation that explains how to best utilize it.",r/machinelearning,Z0FBQUFBQm0yeGNZMXJlOC1STFgzNF9nNXpTOUJyTWZDa2xfZm50X0wyYmNWQllGTjR2WVc4RVE1TDM4OF9idHViVkNMTnZBOWdPZDdRcnBFT19ITjhxazJkUHFPNHdyV0E9PQ==
"As a recent graduate/low-mid level machine learning developer who specialized in audio and would work for ""overseas rates"" for an interesting enough project/work environment, we definitely do exist. As other people here mentioned, whether that meets your requirements depends on how dependent your startup is on senior level expertise; I, for example, find that I can build all the technically different things, like models and support infrastructure, but then require guidance from people with more experience dealing with business requirements and best practices on how to integrate with a larger business ecosystem. As to how to find someone to hire, maybe try job boards at a university graduate program near you (or post a LinkedIn link on this thread).",r/machinelearning,Z0FBQUFBQm0yeGNZR1NXMVB0NmFESlhNVEhhcjBmSjFMTUdCZUVvZWpUTGs3U0R0aDZDQmU0WGx2TnA1eXlGNjRrUU1GbFE5NzZqb3FPUlVhRXlDUjN4c1JBQVk0SmM3QWpid21jZkFNallWUEtJNWg0cnhiYjQ9
"The post specifically talks about a discrete *state space*. Time is typically discrete in RL, but is not part of the state - at each time step, the agent moves from one state to another.",r/machinelearning,Z0FBQUFBQm0yeGNZTnZOV2tiT1hQOHFWdFBuNUNDc2ZQeF81ZGtFemJOV3hGOHNUVjdram9YaU1pbEdVeng0ZTQ1eGRJUHhYeWpsdUp0em9tN2s0ZGNJOXd1aTdKRThXU1E9PQ==
"> There are way too many DS/ML professionals that do not know how to write maintainable or scalable code.

That might have to do with the fact that that's not usually part of their job description. Hiring ML/DS people to write backend code is kinda like hiring a tax lawyer to represent you at a murder trial.",r/machinelearning,Z0FBQUFBQm0yeGNZU2dwUG02Wm1HM0Q3ZzJPSGhna3BXX1p6aWdxZlR5YWRmalNUVkl3R0dtZ0xHbWNHbGRBeGEzSmlkZUFITE1kTFZWX2c4TXVJQnRUbU52VGowcm93aFJPSm9QbWtwZ1BEejJreDIwY3JKRWc9
"Thanks for sharing, I will def. read this",r/machinelearning,Z0FBQUFBQm0yeGNZbUtNcDNGdGpBbE9rMnB4ajY5UGlnYWRGNl93YmFSbkdGVEVtLTE5VGxjMFBBR09SRTA5eTlXVDBPUXFsOWM0eHRkd1M1MHJZcVN5UEFHUTA3QlRYSkhGSkFaSm5IaUgzQ3UxMkFaMkZJd289
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZVEN6N1gtaWI0QTB4RjE4b3B2aWNqdm5waWdzMHNVT3E2QU4wSjdwUm5Hc2NtbkY0NU5pNWVnV3huZjF3V1NRaFFINUhqVWxDa2xrN2ZUWnE3dXZnSlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZOGs2b2Nra1FIVjdMM1NrRm5JNjREaHJkRk9QZ0NCQ2g4a2dFS0JVWHQ0UHE0NllHQTRqWU9ZTThlSUVMV0pTdmtyT25NVjlaWHlmUnp1VnR6LVQ1bXc9PQ==
"Man, I absolutely would not be doing a test that takes a week/couple of weeks just for the chance of getting a job",r/machinelearning,Z0FBQUFBQm0yeGNZaFl3dTZscktMZUNaNmtDNUczTFZSVzFmRDUtd1RyR2MtQzV6RUtnU2RobkxDQXYyVzM1UWF3dFloTEtmWGpoWDVEZWRuWkVXUlRBZTR6TURaZkJpUlE9PQ==
I think the main problem is: even humans could think they know. Do you know what you dont know?. Maybe i think i know and then i figure im wrong. An ai could say a guess in something and maybe is wrong. What if it was trained in the wrong data?. Maybe just check that the model has enough data to answer in a given topic?,r/machinelearning,Z0FBQUFBQm0yeGNZbkFBUDBxQ1Fxck85N0NlazkxWHFURGdtYl9YbWdfRXFvWmpYNURyVjAyd1U5NjFyQlNGZ2dfdjN6cEhEc3BpY2Jybk5zNnhoRUxQczJ5S1pPVDY1c0E9PQ==
"> Even the majority of ML engineers in top tech companies rarely do much innovating, it’s mostly just implementation for their service on top of other teams APIs.

This is a weird framing to make it equivalent to prompt engineering. For the folks I know working at FAANGs they may do tweaks but still have to deal with segmentation and rebuilding models to try out that tweak then do the evaluation . All that is different then just making an API call to OpenAI",r/machinelearning,Z0FBQUFBQm0yeGNZdkJJaHpNTmZNcXlXM0hJcVB5SENvQ0ZrQnpzUmtNVVBnSUZUZ0E3VVNtNDFKbUk2eU9jZzlqYXBfbVNxd1hUTDRVeWpHcThpWGtDRFNjYWkzVnByV1E9PQ==
"Any context?
Looks nice but needs more info",r/machinelearning,Z0FBQUFBQm0yeGNZNWNHM044clFVRWlQWnBmMTZ6cEVqZXpYZVZQbWt1b0hpY0lDSlZjYUFZYnhXZ19aamFwTU5BM19ZLUdHT3FXUFRqNi11ekd1T3lVSFVoSlMySE5ZMUE9PQ==
"If you find a grad student who's put some really good stuff up on github or something, I'd say go for it.  You have more chance of finding a ""novel"" thinker there than with a languishing junior developer on the market, who although may have the required work experience, may have zero capability for independent direction.",r/machinelearning,Z0FBQUFBQm0yeGNZR3liVmt5MmpXR2p3UGxXWFk4cVBJUlphdWRsRVNoT240d21NeElucXV2eDdzbVNyMmZfLVpwRnhFcFNLUGMwTVVFRUQ3SUcxUDFrdUhrZ0pGbFZtTlE9PQ==
"Is a good opportunity.
Turn it into something interesting.",r/machinelearning,Z0FBQUFBQm0yeGNZbVFaVDZBM2x6bENUS0xtRjB6RmpNeVU5cUNGTHhwUURGcjFwYjZmTnJOQ2NLMVdwMm5heldHN0czd1pZcDllbUoyZWpEVlpSNExtV0dJMnNIQTA3QUE9PQ==
"That is fair, but often professionals will need context and surface-level knowledge of surrounding practices to best do their work. To make a model or analysis is useless unless it serves business, software, etc.",r/machinelearning,Z0FBQUFBQm0yeGNZVjFfcnpmMzhKWXBhNkpKZ3ZlRWQwaDRsWmhvU00xdjl0cmxtYXZ3WEdfVlFpa3d1Y2R1ZGROb243Y3VkR29mbjBNWkZLclFadUtycGt0TnZ1WHh3OWc9PQ==
"It’s extremely normal to be given “boring” projects if you’re inexperienced. Since this is your first job, there’s a ton of stuff you need to learn about professional software development that you didn’t learn in school. Even a “boring” project like this is a huge learning experience for you. If you want to work on more interesting stuff you need to prove you can do a great job on the boring stuff, then ask to work on a more interesting project. The best way to work on interesting projects is to propose your own project, but this requires experience.",r/machinelearning,Z0FBQUFBQm0yeGNZRmxrMUFnekJLYnRocC1YWkpEOU40cmhkdU9ZY0ZRWDRaSkJJeE1hUXR6Q3BKZk9LZGZleV9tNTJZNDZrRDFmcjhLTUlJUHVhRGoyMTIzeUt6QXUydmc9PQ==
It is almost a standard practice in europe and ME which are the markets I am familiar with. But i definitely understand. I wouldn't do it unless i was very keen on the job.,r/machinelearning,Z0FBQUFBQm0yeGNZSlZZalhVOF8tTlduZS1WOGd5ZlR6THhSd240dk9YenRGdVo2aG5Rc2tYX3FLaUhJRmlCZWNBUUV2MjZ3cWQxaGdNejNjUjVuU0FpRTdlMDNmVzB2RWc9PQ==
Assuming you are interested in LLMs 🤔,r/machinelearning,Z0FBQUFBQm0yeGNZa1VuaDBUVVB5WkVDQjR2c3padDdOeUswS0QxNjBwRTd2V0kyaW5CLTJ4VWU2eU5SSG9hZlQ2MXFoRWxwcWQ5UnY1S1B0eFM1Yzc2Y2FWY3Q5eEF1MWc9PQ==
"yeah, this seems ideal, actually. training wheels project that isn't as challenging, proximity to experienced devs, and time to adjust to industry practices. you won't be there forever - after a few years, fob it off on the FNG while you work on the fancy thing",r/machinelearning,Z0FBQUFBQm0yeGNZcGR2ZzJiQkkyQXhiaE1YTk5Od2FBaEllY2NtXzVDSWI3NXRhc3EzVDlONGVacmJXcjRjN09MYWFpdlJxbVBfalhLV0pHeHUyczdUMzFfV0RadFlaTUE9PQ==
"> like 95% of MLE work is data plumbing and making APIs or gluing APIs together

am software engineer. it's similar here, the main thing is making sure the plumbing is the right kind",r/machinelearning,Z0FBQUFBQm0yeGNZYXdjWTlpb3FlVVQ2ZHNRTWpkRWp0LUZuQzBaVHRXaElNZFFObmpmNFJ5ZTM5WmcyRklwZE9WNmNhVlNWZVg3WmtueHdPTExwTkpoOHBDam9tMGhaamc9PQ==
I know a lot of ML engineers at one of the FAANGs because I am also an ML engineer. The vast majority of us use prebuilt models or frameworks that build these models for us. Very few people build bespoke models.,r/machinelearning,Z0FBQUFBQm0yeGNZU05SNm9XaU92dUZ0UUh3R013dllER2pySy1vRjk4aEk3RVB3X1FlLUVMLXlLYkl5Sl9DZ29zUi1TbENfd0xadUcwbGR4aW5fQUdqRjNtRTNSWkZCUzNnLU4tVUUyR2FIaVM5cW5RYVpoSWs9
"This is totally normal at a startup and also many corporate companies. What you are doing is ML engineering, and most ML engineers that interface with LLMs are doing API calls to hugging face or openAI, or running pre built local llms.


Also, id appreciate this opportunity to learn some useful skills that will make you a better ""pure"" engineer.",r/machinelearning,Z0FBQUFBQm0yeGNZN1Y0MjRHajFxT0pyOUFxS2RLaGRJaVNyQmNHZkZsNGR5VWhOalg2RmZYQkRzOFlMRE1OcVhuQ3JhMXhxZmU5TlhqdExySWRwYjhDcVV2ZW5LV2oxVWFTLW5qZ0RCYlRKcXhJRDZ4a2JIS2s9
"If you want to apply ML knowledge more extensively, i wouldnt say you need to be a reseacher. I would say though that research scientist jobs are more likely to get you there. But even research scientists at FAANGs sometimes have to demonstrate value and work on engineering for part of their time (maybe as a set allocation of time or a temporary re-org). Many engineer positions at startups can also get you there (without a phd even) and still do actual valuable research that would be worthy of at least submitting to a journal (and get close to publication). And many corporate jobs nowadays offer research engineers or stuff close to that, but those jobs tend be just as limited as ml reseach scientist.",r/machinelearning,Z0FBQUFBQm0yeGNZY1I0XzJicHFtc3RGM0lNaElZTk1nWlNlU2w4dUhZNkMydTlXM1hvV0Ytc1diZ2FnQkdtY2FPeDRzX2JKT3dkT0pMM19YMUloVjVGb2ZvYjI5V0hPdFA5QWtRZ2JhUjdwUEs0c2MyaXF0NVE9
dm when you can,r/machinelearning,Z0FBQUFBQm0yeGNZMVZ4SFdNbEJUVTM2Szk1MWtEeXlZTi1GUE43WTRZdHc3ZUw0RUhIdVhlYk13RGh1eGprVEUzTWhubEQzVkVzWmx4VThyaUVwUEZxdHdLR3FzU2ZpOVE9PQ==
"I think you are more interested in r / learnmachine learning. Or learn r / programming.  Not sure if you want to learn more coding to be ready for machine learning, or you want to learn the coding used specifically in machine learning.

As tor courses, i wouldnt recommend one necessarily. A course or book would suffice for just learning.

If you want to learn python for specifically scientific computing in general, like hard/soft sciences, cs , or machine learning, I would recommend:

https://lectures.scientific-python.org/


[python for data analysis](https://www.oreilly.com/library/view/python-for-data/9781491957653/) It is easy to also search online for this and find more accessible version.",r/machinelearning,Z0FBQUFBQm0yeGNZWmFmZm1FSGJ6cHVJSWpIQVhuNG94ekRmaHgwa3c3SkhoTkZ4azZZdWFkSnk4ZW53WE1KTVlKXzNBUnFTWEVwYjhtX1FUaGhmSmc0d0lpQjBJWUdPdkdVSWlYNDhxTjFpdjlRbGJlc1c5ckE9
Just let a bunch of undergrads summarize them and make a presentation out of it? /s,r/machinelearning,Z0FBQUFBQm0yeGNZdVQ0ZEtKMWhmdml3QWRDWFVkNC1PX280bHBCVDFkR1otRm5McGlrYzZBRHoyeEpJeklFYUFYcFdlV0xFS2lRZHB2TnFROXM3el8zSnA4Q3ZCN2xJOGc9PQ==
"Yeah right now it certainly is one of the few sources of money for the company, so it's pretty important from a business perspective..

I'm probably just going to stick around, trying to do my best and to learn as much as possible, and then I'll re-evaluate things in 1 year, just as you're suggesting",r/machinelearning,Z0FBQUFBQm0yeGNZQThOcFhoZXhRZXJDSE52SGxpV1QxTjlRUTZVUkJVaFRkN2JtYUt3OGdHM01rSkxsX1lXejdLLUdpVldfbU16MGgxTlJjaXBYQlQ0M3A1TEJZM2ZWclE9PQ==
other teams != external services,r/machinelearning,Z0FBQUFBQm0yeGNZVkdTd0tITUV3Z1F1M1htanlUVWVhTmxLWHZBMEpkbGh6VGFVQ0hLWHItWGs4S2M3d0RFYTZ2OWFwZUVETFRHckxXNUU3dXhBOUdQUmxpRU9zdUJBNHc9PQ==
"Thank you, that's a very encouraging take!",r/machinelearning,Z0FBQUFBQm0yeGNZTzNWMUpIVEVJa2NQU09zbjRQblUxcnJZVm83WUxablR4MlF0dEZfcGEybGF3QWU0Um1HbFYwQTZUNWM2RXM1OG1DLU9zcE9aTndiY1VlZmhaWkZKTWc9PQ==
"To be fair, even at this startup people are tweaking/rebuilding the model behind the ""main"" product all the time, trying to improve it. It's just this ""secondary"" project that requires much less low-level fiddling..",r/machinelearning,Z0FBQUFBQm0yeGNZMm5mR3JFemVZWXFxQmlVS3Rna0F0dDZyTzg5Wmx2ZHRHVFB0RkJYcGE1djJnRm1IcWxVS1I3RzU4UHlLVVN1SFhHNGhQbHlDVlJOZS1Hb1haMlhaSmc9PQ==
"context would be nice but it looks like it's a generative model trained to create images of the striped balls. Since they are striped, a separate computer vision program can then analyse the generated images to get the position and rotation of each ball, and move the robot's joints accordingly.

  
this just an educated guess though.",r/machinelearning,Z0FBQUFBQm0yeGNZSE9lQnNycVF2dnhZTUR5ZWpOemtoMnBPM1doNDRLX3FPaWNKZzNUT0c1NnhrN0Uzc0hUMTBKalJLamVmWkk3ZjJCYjU2dmcxbE9zVzdneVdMaFd0bHc9PQ==
"An online data augmentation tool I am making, will release soon: [https://www.mlaugmentor.com/](https://www.mlaugmentor.com/)

I noticed that most of the tools online or super expensive for uploading data in bulk, so this will be a cheaper and better option. Please give advice below",r/machinelearning,Z0FBQUFBQm0yeGNZQXk0OFVRZHNVWURoc1o1dE5FMjVTMlZBQ2Rjc2ZuRHhtcWt6ZnF3ckYtMkVJaWpuYjBxSGZtbGdCbUNmbFM4elJ1LVl1MmFqTkktUTYyREJkaVhYMkE9PQ==
You're selling an image augmentation service without any visual examples. lol.,r/machinelearning,Z0FBQUFBQm0yeGNZSWRmajg3NDRtY0VlbEpZZmotRnkyLVdaeURHTGR1azFjc21zbDJ3bmtfWUFfMGNyRXJ4MWMxTWNlbXdScFVlejQwQ3RKVHpvWC1vazNvanlDcXdiY1E9PQ==
Exactly. Based on people I know in DS and ML its totally not unreasonable to be able to find a job where you aren’t just tweaking API calls although getting your first experience in those roles is tough,r/machinelearning,Z0FBQUFBQm0yeGNZcDVNZXJyYVhpbm1jRWlmbGhBaThiSjI4aDhOX3FaSU5CeTZaNFBobDZhNEZOQWhxYWhLdTk1bk1xcHpqaV9xem0zZFFLWlNaN3dKN1pSRlRpbmhHS0E9PQ==
"Yes, I am still working on that part",r/machinelearning,Z0FBQUFBQm0yeGNZb1ZoSmhHZjF6SmlsSGZtT2FWU2s5UnNCY3lTUWdzVzhWR29obWFsRGpxclNtbFVlRkdDcG13SzRUcXNMVDlfWjVjaFNHb0cwaDZPZURMblVtd3pDY2c9PQ==
image augmentation needs visuals. Not sure if audio augmentation needs visual examples,r/machinelearning,Z0FBQUFBQm0yeGNZRGxHM2NIazZRSVJOblVOOU52V0djQmRRUzd5d0FWc3JYUjdHRGhlTV9CbmxnT0J4LTdiNGttTGdDX2lEUFRvaTRDMGp5YnAtS2RJTjRCM2E3WWNJeFE9PQ==
"Yeah, in this startup the ""principal data scientist"" in my team definitely has the most interesting job.. but he's been there since the beginning.",r/machinelearning,Z0FBQUFBQm0yeGNZNGFyWllxVWZScGdXN0VVNGNIMWlVWUY4RnVta0hidXRNVnZ5UkhvMmZ4X3llZW9objdlSDhWZzZXMW1WQzhjVFM1bmtPWEV2Ykd3XzZ2T01JeVZlNFE9PQ==
also finding,r/machinelearning,Z0FBQUFBQm0yeGNZMDVSWFlZcl9yeE1qU05obFZFRFNkMFpyTExLSmNJN0tIVHRHU3ZtSDhMeXc4bVRFVEI2VG1QWWdLSU5xblJqcXpSbEJUZVFtcVg1cE0ydWk1ZXRtR1E9PQ==
I thought something like whisper was the go to for tts.,r/machinelearning,Z0FBQUFBQm0yeGNZOE5HMkRzcmU5YmNXclBwUFBTZFVoNk9XX3V0VmtMYi1XTkdvbG12X0dWeEJ5aVBTR182SlBMQkRtdnM0S3poYUlqVU5KMlpESnZ1RW1fV01hdU1MdFpCaXZOM3NvejlhWFJJTlhQdkNrQm89
"I'd love to. Although, top-tier universities require some already published papers, no?",r/machinelearning,Z0FBQUFBQm0yeGNZX3JQMnRtb2FUNXl2QTMyNzVYRmtaUDI0dy1uNVl2OENVaW00dHpOR1F3Zy1McFRwMGh1aUJkam5SRnFST0JMT3dhR0ZTemJoa1dtbTVlS0p4bGI0ejBBQ0JDbGRHYkNtRkQyQm9nM3lLTW89
I wil’ try this in the upcoming weeks! I will be training some stuff…,r/machinelearning,Z0FBQUFBQm0yeGNZRHdhUkZ4ZXFMQnM3OXNHLTlpb05oeGhVM21YRTd5ZjBCT0lFejdqcGdIMVpqWnFxRGNCWXZlYTNaZ0JjczQ3Q1FMLVkzOGtFVEVPbV9iaEhKdjdIZFE9PQ==
Get a CS degree just to change the color of a button from blue to green. Welcome to your career,r/machinelearning,Z0FBQUFBQm0yeGNZa0JIU0ZoUnhaMTYtOVJPYnlHdGktSEhBeWpjSmpYenQzYjZINWZrWDhOM1gyMnZ3YWlrZ1BtbDItakI0Y0QxU3B0U1lHSkVFUURqbFRQOU9acFk4VHc9PQ==
"Not sure what's on the screenshot. It seems you are trying to run a logistic regression, which means you need to put your linear regression output through the **logistic function**, so that you receive a probability of buying the stock. From there, you can try to adjust your threshold as you wish.",r/machinelearning,Z0FBQUFBQm0yeGNZclpZLU01UFJCb1M3T25tem0ycGw3LTJuc0xmMmRQbGlodVo4RW9yWEtaQnZSNHBWWEJmX19ENXlRODlZQlRFSUNnekFmZGdmRkhpTHpyb1oxb0p1bEE9PQ==
Can you give me one for free pretty pleaseeeeeeee,r/machinelearning,Z0FBQUFBQm0yeGNZWjBoSllUcFdsNk9qNmxLSmxnTVdON0g2TFBoS3BqSXNudlYtRmJYNXRTbnhibFdCTW1EU21oMGZMOGJtZFpYYzE2Z3pMbGlWSEFlTTRGbWFmaUxfQ3c9PQ==
"There was a comment in the original post that disappeared. Here is original:

Website: [https://genima-robot.github.io/](https://genima-robot.github.io/)

Paper: [https://arxiv.org/abs/2407.07875](https://arxiv.org/abs/2407.07875)

Code: [https://github.com/MohitShridhar/genima](https://github.com/MohitShridhar/genima)

Abstract: Image-generation diffusion models have been fine-tuned to unlock new capabilities such as image-editing and novel view synthesis. Can we similarly unlock image-generation models for visuomotor control? We present Genima, a behavior-cloning agent that fine-tunes Stable Diffusion to ***“draw joint-actions”*** as targets on RGB images. These images are fed into a controller that maps the visual targets into a sequence of joint-positions We study Genima on 25 RLBench and 9 real-world manipulation tasks. We find that, by lifting actions into image-space, internet pre-trained diffusion models can generate policies that outperform state- of-the-art visuomotor approaches, especially in robustness to scene perturbations and generalizing to novel objects. Our method is also competitive with 3D agents, despite lacking priors such as depth, keypoints, or motion-planners.",r/machinelearning,Z0FBQUFBQm0yeGNZelVYWUNiYmc0QmFyLWxRYUt5bGE3NC1iY1lidDJ4eEcybmNidnotamZiZHZ0UXNJRUZPdUVHUXJ6VmNRemJKSjdCWklHcVNlUjY3TXplYTBDNUx0amc9PQ==
"I think unfortunately there maybe a growing trend where ML Eng ends up being thrown a commercial api for a big model or like a prebuilt api and asking to build a product around it.

OpenAi and other big ai companies model is strong and also cheap enough that management just wants to use the api instead of managing the infra and etc…

I miss the days where we build things in house all the time",r/machinelearning,Z0FBQUFBQm0yeGNZbElRT0k0WExTZzA0MW5KVHI0TGRjNkR1VDg0SmItck9WNVJnNC1qSG1sNWU3YWpYWko0aGhXQ2J1dFNGSVg2Z00yQkNZREdTNW9LejJyaUktMzhMemhobzZkVFh0U3d3N0xpSFNLTGdPVDA9
"I'm afraid you are right. Just by looking around among recent NLP papers and AI startups it looks like ""prompt engineering"" (if we want to call it like that) is a much bigger thing than what I initially thought. I think it actually makes sense because it's hard to compete with these giants when they can already provide a solution for your problems..",r/machinelearning,Z0FBQUFBQm0yeGNZZFBpd2dJRFZiYmIyWWRVTzZPMHJTeFhLaXRGUGpreUsySEpZRVhsZ2tzQlYtZGNTY1JVUE1XQU0ycXQ1LVNKODRiZTJNMjloc2c0ZmRaM2I0ak9DeHc9PQ==
"Somehow my original post in the subreddit gets autoremoved by Reddit so I will try to post it here:  
  
Synthetic privacy-preserving dataset for testing private information inference capabilities of LLMs

*TL;DR: We build an LLM-agent simulation framework for Reddit to generate synthetic data to advance inference-based privacy research.*

* [Arxiv preprint](https://arxiv.org/abs/2406.07217)
* [Github](https://github.com/eth-sri/SynthPAI)
* [HuggingFace space](https://huggingface.co/spaces/hannayukhymenko/synthpai_inference) to test out your guessing skills against GPT-4

In our latest research paper we present SynthPAI - a synthetic dataset which provides a foundation for a new benchmark on evaluating LLM-based personal attribute inferences. We have built an LLM-agent simulation framework for Reddit to generate synthetic data to advance inference-based privacy research. 

Using this framework, we constructed a PAI (Private Attribute Inference) dataset consisting of 7800+ comments and 300 synthetic profiles alongside human-verified attribute labels. We showed that our comments exhibit high fidelity (with humans unable to distinguish them from real comments) and informativeness for PAI research, allowing us to draw the same qualitative conclusions as on real-world data across various experiments.",r/machinelearning,Z0FBQUFBQm0yeGNZU1N3WTJXME1EVTFFQWZYSlpaLTRkRGtueDJlUFM3QlF0YWN0c2JKQ2lzUW5CSVN1cnh1SkZ2dHJVWEQ4Ym4zLVBzaUlZeThieGR2djVaWnpvRHFNWlE9PQ==
Maybe lower your sights if this is demonstrating the extent of your ability to research?,r/machinelearning,Z0FBQUFBQm0yeGNZd3Ryb2pMenhtVHlqNFU4SE80QVN5dVo4NmdrajFMb0ZYdjRPeG5aZko1c21FVnluOV9HODZPeTFHdVVZTlIxMzFqRTRja1pFVm92Tl82ME5FRWtQZXc9PQ==
That’s how I have it set up currently. But a lower cost calculated through the total logistic/target difference is not necessarily more correct trades. The photo is of part of the model I have,r/machinelearning,Z0FBQUFBQm0yeGNZZml4elVFYkpnclpqUW5WZjN5VG1QU2ktQWRBMTJRdldvcXFINlg0VGd2VVZMSExLR1RucFdxU1doMzNwTDlTT284ZWtMdUlpQlNJN3loMWpIU0VIclh0WlpmT3lMcjN3VWktdnJlRFFpRzg9
"In my opinion you're looking at this from the wrong angle. Instead of asking us what you should do, just try to find something you'd actually want to do.

Find a problem that's relevant to you in some way and then start from there. There's a very high chance someone else has already tried to do something similar, so you won't have to figure everything out by yourself.

I have an EE background with a lot of signal processing. When I started studying ML I was pretty much on the same boat as you, and things only really clicked for me when I started delving into CNNs and Computer Vision.",r/machinelearning,Z0FBQUFBQm0yeGNZTExjMExVbUdwSGluSXl3R3hHbXJwS25ScVdlVlIxb0s0X3ZfVENCZmZGREdRQmcxT3ZVTkhnX2pURmlydkZiWldsZVJxbHpiMV92TXVua3R5ZUh1ZEE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNZS3o4eFNxN2xLTkdOVUZTdF9CREszTjRxSGVZMy1HOW9ROHZmZjBybzZDcTV0Mm5ES3I2WnNBMVIyY1g5bVExNG85SmszVF80UFlYQ1AyZ3BlS0d6dnZuQVY0MHg5RlJxUU1KUlBsemxSWmM9
"Other specific subreddits maybe a better home for this post:

- r/ArtificialIntelligence 
- r/DataScience 
- r/LearnMachineLearning
- r/LLM
- r/MLOps
- r/MLJobs 
- r/Singularity
- r/ChatGPT 
- r/OpenAI
- r/LLMDevs
-  r/RagAI",r/machinelearning,Z0FBQUFBQm0yeGNZM09ldUV0RGVTaFhHWHhLbHh3NUxhdFM1b1JqWldObVdhZU1OTk1WLTEtTjROQmh3QjRXai0wakxXQktoMm9lZ0JXTUU2Y2trRlk0YXhBT2pkbVJYXzg0eEY3WG5GbjZ1enFqR1hENjFFeUU9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNZNUhwWmF2T3U0a2VRZnhGWjkxZlcwMi11QzdxeXo4OUFHSVRPVE0wbGJQa1NqbmlFdUkycW5mVDduRk5EX2dIUHlzRUFkek9kTWFBSEZkSk1oa05tUmliUVlfQXBKdkJyTnNiQVNHY01FXzg9
I get that. However the issue i feel is isn't there a possibility I end up taking something way beyond my skills at the moment. I was looking it at from an increasing skill point of view that once I've done basic projects i can try doing whatever i want to,r/machinelearning,Z0FBQUFBQm0yeGNZYTJ4RzRxbkp2aUpCUlE4eDBsSGJIdVdtanZydGs0QnZvZGdyd3F5RlFyYU5FbDQ1SEVEVjBzbE5nUkZEZWtkd3AwRXp2WThCRDZUUjVOYUdTOUthUzBqcEFZdHZBM21rX3RjTWhWODU5ZWc9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNZYjNyejlzMTVGd2R4QVJxMG0xa0tTNXAzRUMyMW9Sc0tLOF9GNXpZZEJ0dlg4LXNManYzT0RrOWlocGpxb05Vb3FDZ2d6R3FHSjM0OWQtTmRWRWR3TXZVV05BX2ZGVDhLM09MYURCeDZ1ZGc9
Are these prices for GPU only or all-inclusive?,r/machinelearning,Z0FBQUFBQm0yeGNZWDJSY1lrdHZtbWhsV01HS3kxbFdDX2g5XzNrSlBIYkJDc0lBcXNPYnNBWnZYeEtIOGVtNlhKUmY2dWxqRjQwajA5TzJLZHJuXzNDbWhSeTlJTk1TaVE9PQ==
All-inclusive!,r/machinelearning,Z0FBQUFBQm0yeGNZYXBXZ0EtRm00RGxSdG5FRWY0ZWFPMy1ORlNoT0xUdTRyWE8xMDR3Ymd1S0psa1FtTjlxM29pb0szVlZmYlRuRmpIeGx6TUNETUJjaHFJUFJBZW9WYXc9PQ==
"Hi! I'm a data scientist. But I'm from Russia. If it's not a problem, text me.",r/machinelearning,Z0FBQUFBQm0yeGNZY2lIeXdsd3dTcHJ2VEFvcEppTERpMVIwb2RlajZkelJNdEZjcjBxSEVLY1hUVlp4RENvSE9XN3FjeVRIdmZtT09EM1ZkV3dzNXRPck1QQVBKLUQtWmZ5VHRJX250cHFpZXg4cDZlRmhTVTg9
"Nice work, haven't read it yet, but will. Regarding discrete latent spaces: Could there be a connection between discrete latent spaces in your work and error-correcting codes, which combat noise (typically within communication channels) using discrete but redundant representations?

Additionally, is there something akin to the Hamming distance for the discrete latent space in your RL framework? Specifically, are there interpretable elements similar to codewords and a minimum Hamming distance that ensures error-free decoding, as seen in error-correcting codes?

I would appreciate your thoughts :)",r/machinelearning,Z0FBQUFBQm0yeGNZcG1HU0wxaGJmTjBLUHdibWpFa29ldktpR0V6eGJjbEU4cGlYSEo2UmF1UjNvOXp6VXFXblNwT3NYV1dmX1pfMEVoLWZHR1hyUHpCT3RlRkc5bUxPVHc9PQ==
"I'm an ML Engineer from Ukraine and you can try to contact recruiters from Ukraine who will search people for you, there are couple of benefits:

1. Much cheaper than western europe with the same result.
2. They are used to work for international companies just because majority of market is basically US, Israel, european and other rich countries exporting their work to low-income countries.

The same principle applies to other eastern european and post-soviet countries to a various degree.",r/machinelearning,Z0FBQUFBQm0yeGNZSFdpWWhiUUpOYTJNQURKbzJEc2pVQ1NmMWdfQUhzUmxLbDBfM1BvNVpYWlBRS0t6NmZZWEdBa2l1ZE1mSy11ck5nSGwxUHR4eFU3Mnpja0Z0akdpRFE9PQ==
"I'm finishing my Artificial Intelligence Msc and I have main experiencia working as data engineer with cloud environments and deployment of some personal ML developments. Because of I'm from Colombia, my hourly rate could be more reasonable for you.   
If this sound interesting for you we can talk:  in/luiscopete",r/machinelearning,Z0FBQUFBQm0yeGNZSFgyTFdsY3lReGV3cFh6WTZ1R3hLMTZaNjJGZW9mTTdEVmpUaWdKd1dURGw4ZDNDR2lMcDl2QlJWU1BRZW50cmNhTERCUTNvNDM3bHFqZE9wRkRSLVE9PQ==
Why don't you just try anova? All your variables are categorical.,r/machinelearning,Z0FBQUFBQm0yeGNZZUpScVBrMWxxblFqdmtZblluamRFUDlLdnc3RWF4MHdtcjk2emQ3cWZNd2Mtd0szZEsteVlBYWdiYXhwQWtlSGFvMnl4ZHpvRVI2dzNWX0JOTmNFOHc9PQ==
Nice!,r/machinelearning,Z0FBQUFBQm0yeGNZM09pci1XeGRMSVF1aWRIeTU0MjZid1V5aFhHNXU0dFdpVVBLTnBxSmprVEI3Y1FWWmhUWktZaE1hZDV5cEQ5VEJFVlBfOURTa2hqWllqTlZpQ3g4Z1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZZWF6UzNkazNoVkw0VEFpbUVCTFc0cmpqRFAtNzRNODFzZi1JOHpxZGNIa3pTV1BVak1WT0dsMmtXQUtXMFdvMlZVVVNJSEhaWExpMFh0bjdoMi03LXc9PQ==
Whisper does tts?,r/machinelearning,Z0FBQUFBQm0yeGNZVUVkdEJmQXZlaXA3SjBnRmwxM2NyZnpxYnJyVlB0V2J5RWxUbkxsQWhkeUZuTGx5My1uYTgyNVBOOTdsNk4zZWRLdjdwaUlndWo5UklBZU8wQkFJRGlxaWs1R3FXSDhiRXdFWExNYW00b1U9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNZdmViWmoxbVA4Tk84X2NuMmJFMmdLbGg1Zkg5SGVsa1RPdmc2ZC1QazUtYWFaNEtQN29QMVhKS0hxS3AzajJmcVNocjhTbFljTkZNaGdEN1V2OFg3cEhEMTRTQ1o0LUVrMVYtdnNydnpvTXc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZc1E2TXk5TkVhb1BTRWFjWEw2ZFVHSURscHQxelpBaXN5aXZPX3FEdEJ2em1IYVRaQlE3UW81WWl2dzZDZTNOa0FIdUo1d1M5aXpmMzQ5Z0NLMllsbkE9PQ==
"I can relate, I work in a similar environment. But one caveat I notice is while the flexibility is good, it leads to lesser structure. I have forgotten if CICD is part of our role as MLE, but it's so dynamic that we cannot afford to do CI/CD.",r/machinelearning,Z0FBQUFBQm0yeGNZRGUwSEVrZHNSVEhkRW9TWmRNdHhiZVhFMHdOS2czLWF2aGdqUHRjV1hFTnhhLUxPX0gwV01kcGltMkNsZ2V0NGFnQlFYdjhXYW1HZnB4cm9iWkRoR3c9PQ==
Very interesting — excited to see where this goes!,r/machinelearning,Z0FBQUFBQm0yeGNZeUhwLVM1bEpxSHRuME1uOXQ2dmFfSzBiT05kUHJkNGU2ZExPT1M5amdwQ1Z6TmMyWHBGWjNTRWJrNEc0Q0pFdmVtR1E3S2N3SDhzM3A4Y3JsbDRFcUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZWnFaNnlEaG0wNl82MDUzSXJ1bWtIZ0t1cm1jdUZNa0ZmQm1GdEsyazhYbXhwYnc4QXV2Z0pkeTA0ai1kWnpRSzYxY2lwZ1dkLXpzei1sQWZnZEtXUUE9PQ==
I think ever since LLMs have been taking over this has become a more of a trend. I got my first ever ML job about 13 months ago. then I was doing more model training and evaluation but now only a year later I'm doing more software engineering and tweaking prompts. Of course i still maintain and retrain the models i have created but haven't done much new model training for a new application. also it is becoming cheaper to delegate tasks to openai and pay for api than to rent gpu and have your own models.,r/machinelearning,Z0FBQUFBQm0yeGNZcEdTdEpRNWJBT0JKM3ZZcHp6MXdKdEVtTVF0dHJWNUVZZEZvelpfSnJGNzFJS1I3eHRjMV9sVDU5VEtkY2RyamtSdE5xc2tucTU4T1VaUUpNRXBhb1E9PQ==
"Hi everyone, so I have an on-site interview coming up for an L2 MLE position with a FAANG company and they have ""Project Retrospective"" interview step. I was wondering if anyone has experience with this. There isn't much resources online for this interview step.

The company has told me that they want me to discuss a significant project from my technical career, detailing your role, challenges, and impact.

I have an idea of what they want, but I wanted to know what to focus on more during the interview. should i be very technical or more like high level view and talk about collaboration with people? also please remember this is for a L2 and not a senior role so i don't know what are expectations for an L2 level in this type of interview. any tips would be appreciated!",r/machinelearning,Z0FBQUFBQm0yeGNZVXNCdk5uWHJDbWtMUEhFV012UjRacjVCVl9sYUNTMkRoSzA4emI3Vmt1M0t5YkRRMEhnTFVncmlBVmNNYm9wWVZsdzVIcGcwQmd4RGhJV2hmSnVHLWc9PQ==
"It should:

https://openai.com/index/whisper/",r/machinelearning,Z0FBQUFBQm0yeGNZN0pfZldxaS10NnI5S24wTDVpTWkxbUFhSG1Ra0EzZWVOSDlZOXlfbUJpekdsM2J2Zjh2aGNJTEtNWmRCcl9qbVZnMmVGakZ5ckJjdGJiSHplR21ESnQ4RE5jOFNoazFnVzNaTEJpZGc1Znc9
Thanks,r/machinelearning,Z0FBQUFBQm0yeGNZeFBiVElUTHVZQU9KVDNPRDFrMHZybHBLTC1iYktXa3FYMnlZVk90LXRuYUpRZDZBSEgtSmdfdXdBTnExZUJhRVRTMGRfR2t3WGZZMHU3U0xZbGhzX0E9PQ==
You gotta raise if you wanna compete,r/machinelearning,Z0FBQUFBQm0yeGNZXzFMcjdSRmxIV1d4UzY2bmdPd2ZFS29FMnhmM29HcnR1N1l2cjZkQnBxNHlBaDRLTm1OTVZ6S3V0cjBaN2cwa3NqVzdNMnQ1dURmSGgzT3VhNlljM3c9PQ==
Why should we use your SaaS service when plenty of python libraries can compute augmentations on-the-fly?,r/machinelearning,Z0FBQUFBQm0yeGNZNm84R0FoR1JMSW41M1gwenBBLThuY0xWb3M5b2dVazdDbnRkZUM5RHFaM0k2T1d2NkxUS0lhQmlyUzNDZWZ6dzJ4TnNraFhmbnhRcjZRVWJRX0Y1NmhXa3h1NVZORW44T2FBWFB5UE42aDQ9
because it is quicker than spending 1 hour building an augmentation pipeline,r/machinelearning,Z0FBQUFBQm0yeGNZcUhfekk1bmlZQXZiM2RLMVdXR3FOVWM3VDBpeVZpQmE1b3lEMDc5WnFBYkRxa1ZBV3NXaXA2RHZUM0JLRlJXSGpIX3lCTktYY3FiX1cxbEtNdnU4OEE9PQ==
Just commenting here because I’m in pretty much the exact same situation as you. I have a MS in AI and ML and I just got my first job ever working for an early stage startup doing ML engineering. Any advice you get is equally applicable to me.,r/machinelearning,Z0FBQUFBQm0yeGNZa2xVYWNnMEYweDV6dVJIR2tWa0c2X2x0cFNOLUg3aEgzWGhUU0EwdXgwb090Q0lqMUwtXy1pczdUdHB3Mk1Cek9XUWx5b0lGNnNxOHlIQm5RQ1h4NWc9PQ==
"I beg to differ, it takes less than 1 second to wrap a torchvision.transforms function on an input, more-so a sequence of augmentations.",r/machinelearning,Z0FBQUFBQm0yeGNZbWZfWGVpS0pvWHM0Y2JPRktJakVITDFqT0RHRVJ4TUxGVDl2Z1JlVng4czJTeE5ERGVnTUMzM0Nxa0F4N2JpYmo2eFJtSk5QVXBtWEd4eXRfMHc2QkgyZ04zVjRkd295dVNIb1VBdzAybHc9
In the process,r/machinelearning,Z0FBQUFBQm0yeGNZSGFTRWU2VVRiQWNTNElpU3NSeDMyODNBNmx4WXRnNzRkNHZiNWkxRzgxNnhKWjJjY2l3WEJlU1o2V1A0TXNkUkFhcmVwM19hNXdiaEltbWVDQ29IalE9PQ==
"while it may take not much time to build the pipeline itself, you still dont really have a visual example of what the augmentations would look like on your dataset through raw code, which is what my website will cover aswell",r/machinelearning,Z0FBQUFBQm0yeGNZMVRJRzFBRVhsOHFXd2l5WmhxRWxlTWZMT2pLYkZnT0k2Y3NIbFAwdGI0MGZTQV9uOTZyRnJ2ckhDUTZrcjhxWktsLWtjZmpOakxBTHhhMWRTeHlIMEE9PQ==
This isn't true. Augmented images can easily be viewed using common python libraries e.g. matplotlib.pyplot with plt.imshow and saved with plt.imsave.,r/machinelearning,Z0FBQUFBQm0yeGNZWEJ0alRqTmM0N05wOXM5MVF3U3MxNjJUdW13TG9WUTRCdnhOSWZUQzJiOUcxZmh5OHgyNUtQSDZZUVJHZlNnbGMzaUV4NzJJclFIanpINm1qYWQ2c1FpZVdwWEkxV21LaXBrZFNYQ0xrQmM9
"I would absolutely do it. At best, I'm getting a job. At worst, I got a side project and learned something / solidified my knowledge.",r/machinelearning,Z0FBQUFBQm0yeGNZTWtueXBGTVFONE9HcDJsbWxQUzVkWldIdGhyNGF5cXFIVTd2VnZkT2VHX1FjTm9KWHo5MDhyZ2ljRm9LcW9XUE9nN0RtdkEyeE1XMHlGWlRKTEJTZ1h1NG9FaHNQQVpaRDA2ZEYzZEdpMXM9
"I don't know about you, but it took me more than an hour to build my first object detection augmentation pipeline",r/machinelearning,Z0FBQUFBQm0yeGNZSE12Z05SSnhELS1JX3kyMDAwSG9FTlJIMW9VMUtadms4ck5FQjRfSzVNcVVSWWx0ZFU2U2NTNEhKTk1aRjJJSjFwVE5IOUk0NmJaOGJfMDlHTWV6TEE9PQ==
"Any advice on tracking down good developers? Very open to Ukranian developers in general, I've heard good things. I've worked with various developers on Upwork/Toptal, all highly rated, etc, but found their skillset and/or communication to be lacking, but I know those sites can be very hit and miss. I'm not sure we'd be able to hire anyone full time yet but it would definitely turn into that eventually if someone is great, and I REALLY need help as i'm the sole developer (and co-founder).",r/machinelearning,Z0FBQUFBQm0yeGNZLVNHNHcxTzRXSHFuMDhRaExnR01hT1hMQm1pbEppV3kwNGc0WkNONWJuUTFOQWtOR0kwOHhJSER1elloaWF6bkFVbVlOSUgtOGVCc0JNMHh3dmw5TlE9PQ==
Messaged you,r/machinelearning,Z0FBQUFBQm0yeGNZTjlmdUQ2bm4xNVRoZGZuT1FaQWY2SWhXdGIwRWoyVmt1d2ZWZUFhalgwc0k5VVJFdVBoMkdvUGxqb1RyN2d0T2ZXYnM0RHhhZERRaE5GWWFDNzZ0aVE9PQ==
"As someone likely doing ML hiring in the near future, and also as someone who wants to help however I can people in Ukraine, I'd love to learn more.",r/machinelearning,Z0FBQUFBQm0yeGNZSjdzellTdkVCZTBwMlRtb2dMenVrY1JDeFhOanJtVVB4bmgzenZCYWY0MUptN2dMSDN5U3htcmk4Q1kwQUxxYUozWTQwZjl4S1BpOG95bjRaUHM4cnc9PQ==
I´ve accepted your request,r/machinelearning,Z0FBQUFBQm0yeGNZQlFXUzFKWl9lVTlfcmxsaXdzX3pyUDZvNDZHTFdFMV90aUYxbExOMHVNZUV2UjA3M0xpcnItYk5KWW52U1Z2VzdfY2hzVGc2LWt5TlRuV19WdnotdVE9PQ==
Im trying to make an account but it keeps telling me invalid email address.,r/machinelearning,Z0FBQUFBQm0yeGNZRUtIRk42VTZERUtLLTUxa1A3M25OY0M3eVRwZVVkS1NTNXpQUTUzSVQwRC1fOUdjQ0hCOW1QYm11NWJLR0dkRnBsaDByTzlsUDZ6YnN2MS1Dck94amc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZZXVnT0JHNFFuc0VXMlRmN1pGRHQ0VE9PMDM5NUVQbmxiejFjUkV4ZmJ0VmhUVzlYNFdIR0c3VEVMVW16NjV0VUNiY3JKRlE5LVlYQ1N0VTc2WnpVNHc9PQ==
"Whisper by itself is not a TTS model, rather an ASR one",r/machinelearning,Z0FBQUFBQm0yeGNZS010RXlLZTJGX1ViMm5Fa1lpRy1ZWjBWQTRYaHNDbTlPN3plZmRZOUxOSTRkeXkxRjUteG5RWS1aMExSYy1xOVpJeGxPMnhkZjlTM3NjTjNiN0hHYUNWWlhnUUZJS3pJRGVKZmFoTUhUclk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZWTMyTDdkUE1fN2JuQ1k1VlZYVmZkMmFyQ1hGejRUUHFsa3AzUTdpSGVwdlRKdWdOYjJjNmcza1B0OHdPVmpkbi1QRGhYX05RVmdsT2ZQZ1N3RURpUmc9PQ==
Is that the habit persistence equation? We should chat,r/machinelearning,Z0FBQUFBQm0yeGNZMFdBYkJORF9UdVBSeTllN1JTOEVQbU9sdWI5QjBBVzlCNDBlT0tzNVFINS1jcnFvUlJFMlY3b19QckRlQzlTTy1JMHppZTQybHZMRndtQjJ1S0VaekE9PQ==
Thanks !,r/machinelearning,Z0FBQUFBQm0yeGNZOVZxSkdQd0RHUkNnNV9WczMyU0ZRcE1zaWZlSVktR2FCdVNCVVBibklHWTIxRkVRRmlFRTlGS3NxYWVoNDZsRGstY1NwaUVBN1A2Zm9SLWhaSS10dlE9PQ==
"No thanks. Unless you have something that cannot be done through off the shelf libraries, it is not worth it. Additionally, a pipeline in the dataloader can make near infinite augmentations on the fly. You seem to be aiming for an audience that knows how to train a neural network but doesn’t know how to write a few lines of python.",r/machinelearning,Z0FBQUFBQm0yeGNZNGd5eEsxWFRFU0E2eHBTelR3WjZYbHNXekpQZWE4M0FqQ01xa3VtY1VDUkhoeXMwNFdsWGpvczh1MzRpbUZ0OHUzSC16VnRiaDlKRHVrRmtrM3VBMWc9PQ==
"Thanks so much for letting me know. It should be fixed now, and if it isn't please DM me your email. You and everyone replying/dming us can expect $25 dollars free credits for all this help.",r/machinelearning,Z0FBQUFBQm0yeGNZUTZId3RzdlRIY3VkV0RUUUwtZ3UwdmREREwzazh2N3IxMWZhSlpNTDdBNVJkOFdFNFVMSWhZUTZ4alJiRWViNk81SkZZMFJHdVpkSzFKSU4xUDJfdFE9PQ==
"Ok, I will look into some different ideas",r/machinelearning,Z0FBQUFBQm0yeGNZMFZBVUIyS2YzdHZ5YjR1cF9MM3Z1NDlWZnJTaUstQXZRZ2ltdUpnRktuRGJxVjJQV3EyNHV2R1I1bmRCZFViekJpOERvYVJKQjBrNG42MlFyVWN5bUE9PQ==
"But you are right,I admit this idea is not that good",r/machinelearning,Z0FBQUFBQm0yeGNZSVNRQk5DQjhmY05mVFJmdHUtdzVfQm1najluSnJnWDh5b1M4My1VMlItN1pDZmJaY3lTSF9wNzNVYm15RFdjX2trM1FUMm1jTGl2bXJwY3Vsbzg3RWc9PQ==
"I trained XTTS (xtts-finetune-webui) on 500 samples (11 seconds max each). I can get a nice result at 5 shots or less. It's good for youtube of course, not for a professional level.",r/machinelearning,Z0FBQUFBQm0yeGNZM1NwWEFlSVg2OWhyZTFEa3JTODJoeXZwal80dWpIT3NwV1pDYmx0N1IwQjVGbkQ2cVoxNlBzLUVLNE9aVXZzYWNRak1FYktVUHRfX010bUdIalZaS3c9PQ==
"In general, in engineering you do as little innovation as possible. By definition a tried and true system is better for business purposes, with adaptations that introduce the least risk to accomplish the job. Unless being the best at a technology is your company's business model, spending time in research is a high cost, low return activity.",r/machinelearning,Z0FBQUFBQm0yeGNZZEVHN05GRTVXVG43VF9OaVQ3TkdKV200UTg1VWsybjJDaFVpNllieDJtYzFoeHctTEpXUDRzSTkzenhWSnB5WDdxOU1RajRiRExPdm1lMnJoRmpGZ2c9PQ==
"Interesting results, but allow me to share a couple of thoughts I had.

First, standard, fixed-size floating point variables do *not* constitute a legitimate continuous variable, regardless of the number of bits being used. They, too, very much encode a ""discrete state"". This might sound like pure nitpicking, when obviously *de facto* the range of values available is so much greater that conceptualizing it as ""continuous"" is not going to make a huge difference most of the time. 

But I feel like it hurts the analysis of what's going on here, by turning the narrative into a black-and-white ""discrete vs continuous"", when it's a whole spectrum, encompassing both the number of available states to represent, as well as their distribution (with floating point representations typically choosing to sacrifice a consistent precision over their range and numerical stability in exchange for a much wider range of ""allowed values"", while fixed-point representations generally follow a much simpler uniform distribution) -- in theory, if the ""discreteness"" is really contributing something meaningful, it should be possible to have a whole matrix of results, bridging the whole range from ""discrete"" to """"""continuous"""""", illuminating exactly how performance is affected by each property.

Second, I'm not 100% certain if I'm getting the part with the comparison between what you (a little confusingly, since the actual representations are almost reversed from what those names suggest at a glance, in my view) call ""quantized"" vs ""multi-one hot"" representations, but if I'm following it correctly, then:

> Our results also suggest that the superior performance of discrete representations is not necessarily attributable to their ”discreetness”, but rather to their sparse, binary nature.

I'm not sure I agree that this conclusion necessarily follows here (also, I think you mean ""discreteness""... I'm sure there's a joke here about the lower information states not prodding for details)

My thinking is that what you call a ""quantized"" representation might well simply be less conveniently distributed for the calculations the model needs to do. By spreading the information over several inputs in a somewhat haphazard manner, you've added something the model needs to use its capacity to learn to ""undo"", essentially.

Another potential angle of confoundment is from the loss:

> The quantized model is trained with the squared error loss, but otherwise both models follow the same training procedure.

If I'm interpreting this correctly (and perhaps I'm not) it sounds like your gradient is ""lying"" about the underlying topology for the sake of improving the learning signal (i.e. the gradient isn't accurately depicting the quantization present). This could be totally okay, or it could be hurting the model's performance.",r/machinelearning,Z0FBQUFBQm0yeGNZblJROWFlMkRMSUJTUmZCOFRHczZMRUlsLWRYSFBraHJsWmJEbXJZY2FpY19sNENMSTM5aTM1UThvNVFuVjFXSU9XclRxcjRYYUN2QUl3eVdXRmFyWGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZUjhEV0lKdjBHZUlvS250emlTUDFYR2R1cHh1OXVNRWotOHI4alIwOUNHOEtVak9ZTVZ5enlXdWt0U2VQRVNjMl94WGhGVUdtRXFiOVNkSVpyeTFuWFE9PQ==
"IMO it's related to old ""classification vs regression"" question. I'ts  more or less accepted that classification is more stable and accurate then regression for DNN",r/machinelearning,Z0FBQUFBQm0yeGNZYUZwaUNYNm1KZVhGeGpFVXU1WFV6QTV1cUFnOHFsa0FuZlZOTUgtY2F0YUNWNHFUSGZ1bmtHMmRqNUl4QkViblFPeXRBVGI0SjJLMkNfR19mSnRWUWc9PQ==
Hello，Why is the 6th layer of WavLM-Large used for feature extraction instead of the 7th or 5th layer?,r/machinelearning,Z0FBQUFBQm0yeGNZRFlGT3J4MlJRWklWRWk1SndvYU1xRkM0bzktTWdPLWwyUHczN3FIN1l0RlhaTEN6ZnN3QVI5YU5WOU4tYi0tdGYzQno5UzVHMkdEQURFbzhIcTVfYmpwWHRjUjMydTZLSUhXMkNUMk81QlU9
"It depends on the cost of living. To get top talent, the payment should be around 4-6x average income. That translates to \\~400k in the US, \\~180k in Europe or Japan, and \\~60k or less in very low cost of living places like SEA countries.",r/machinelearning,Z0FBQUFBQm0yeGNZRFhmWGE3SkFlcHFidXVTdXg1MHF2N0RvLTRNQmZkWTdvMnZmQm1TZmZYalpxemFzaFVQQTJTOU5OTUMxbUVnRkVqclI1dkNrMWlOVkZjZlV0Zm5KNWc9PQ==
Was working on some fine-tuning for my grad project. Excited to try it out on this. Thanks u/ntu2323,r/machinelearning,Z0FBQUFBQm0yeGNZRlFBM2VYTjl1RUZ4Ny0wWmhqVFppSTdiTnhkenBySHJURDFSeHdXeFhvalFXa1R2VkRnLUJZaWdTdmdsdnpmeXBZN3pQaUppZE9BaDkzNjZ2ZkxtZUE9PQ==
"You're seeing stuff published by students because people getting $400,000 a year aren't publishing their stuff, it's proprietary",r/machinelearning,Z0FBQUFBQm0yeGNZa2RlSjg5TkFOS0VBSUYxVlM2OFRjakN5TjduRUZ0Z0cwcjFyb2VTS1BSeldSdHVEQkJvQVVIWnA1bEMyOE91Z2dQSDJ3MTZDZ3RRZjVRMEotYlJHM2c9PQ==
no,r/machinelearning,Z0FBQUFBQm0yeGNZV2RueENUeWEteXBieGIwWl9BLVozRVdUV25oWklzajgwQkJoQW92TTZsUGI3ZllXUzN6OUhxbHFvWXhnVld6VWlWaUpYUGUxNjZ1bkpZcmRxUW1BN3c9PQ==
Is this legit? Will test it out for myself soon,r/machinelearning,Z0FBQUFBQm0yeGNZYUgyQWZCWXpmSTlETU1zUlVwaVQ0WkdCdlFDWFN3SllMNDdNSGRKSjR0NXpLdFAyODViSjNrbzYzaGdWYlUtU2xZZlkxQ3JDNlUxRmRyQmU2b3FWSGc9PQ==
Have you tried implementing it on a llama3 model? I am deeply curious about studying features in that model and any guidance would be helpful!,r/machinelearning,Z0FBQUFBQm0yeGNZMVJ1OGZkSzZHZzQ1c0ZvT0FKRzRtajAwQzJueWtiTE1LOEhpVUkwTjZ2UmxNT04wVS1NU28zbFc4MDJLbVJVX1NPOGRwR0dGNTRSdUd6TFVXSWtqamc9PQ==
It seems like their advice was to find a recruiter.,r/machinelearning,Z0FBQUFBQm0yeGNZdGZqMzh1S3Y4cTZiS0s1YWpkakdSSy1jOWlWT3pSc1JzMVNzYzBseWxPYkVRTEZ0WlQ4V3BBT3hzZHkwVWczRkFTaVRMczUweHl0RWtrSG5jbUdyWHpIX3pJZ1dlcDQ1TlVkOXNkeFRpeDA9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZRllpQXloOUlIb2xFUjMzaWw2NjE5VnAyai1LSjhGZkdTSE5HNDdvV1lBVWl0VEE5Zm5OWkJQanlTSmp1akVmVFh4VFR4R05LNVBOX3UwRU9DNGVoclE9PQ==
"At this price and terms, I am tempted to move my non Ai workload from public cloud. Would definitely try.",r/machinelearning,Z0FBQUFBQm0yeGNZdTBDS2hRZXBvd3gydTF0emE2czZOWWRGekpvRjdURFN6YTJkZkdVTDdsTHhxZ1pzMWdvYW03ZkNDOUVGSjRZWjZ3UkVfSTN1WFRYb04yc1lxbFpzdGc9PQ==
Very apt!,r/machinelearning,Z0FBQUFBQm0yeGNZWFpiUk8xaWhaOHNTMlAzR2VGOVN0WDlSdG1tbE1kRmdyZTZFWjY2dXp6THotdjJvaUJxX1dzajBSQmFvZVU3aC1tNFpjUG9RWWVPenoxRTB4OHhqOGNYR2JyYl95TVlfZFZSclBacTBZS289
"If you don't need a managed service and don't require real-time writes things like qdrant or faiss can be completely hosted in-memory in a ""normal"" kind of way. E.g. you could technically ""just"" have the vectorDB on S3 and hot-reload it in your web service (as long as everything fits in memory)

One not-so-crazy thing I've seen is hosting FAISS on triton and exploiting the python backend as a way to save cost by reusing existing infra. 

Now if your usecase and deployments require you to write **and** read in real-time...well that's a different problem. I can see technically with caching + streaming you _may_ get away with some of the things I said above (e.g. triton with their polling of the model repository for changes for example)",r/machinelearning,Z0FBQUFBQm0yeGNZRGZSMjd1LXV0aDByWjk5QkgydWpNRk9KS1BwLVFrZEQ1N3N3M0N3bTZ4SXlwb196MDZGVk9Wd21heDZ5SVU3R1QxUHJCY0V6WmRMRGIwcFdyMGxJUXpYd19ieGJtRk1FTU0yaDEtMTNCNnM9
"Thanks for that, almost missed it. One has to click on a lesson, then go to presentation to find the recording.",r/machinelearning,Z0FBQUFBQm0yeGNZcEVxSGJXUUJoSFFHMTRYcmpwZUdBSmVFTVFYYU9qUzllZnVBeVpzdkJocGxtcWN4SG5yR0U2OEVqNnkxM0Q2UE1yQ3g3MkxIdjI4YVF6MW1COENCYVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZTWU3bVBtcG9qRGgwSzJiUEZxTlVmR19vZnhIaVBCc3NJSjF1RHRIYVZfZFBsWkxOOVBoN0lSNlYzakNnVmoxd1R2ZU5rdnNjNnNWdzhmazRmeWRwVWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZWjBiZ09sc1lLTVV1b1c3bjlNY21PU0ctRU9NZ0xmWW1xR0lJcjVvMXQxUHlHZHV0UElyUDc4ck1lVVFkNVE5ZnBLeEk5bWVhZFpuMnVwTGJvdXQzb2c9PQ==
"Hm, sure …",r/machinelearning,Z0FBQUFBQm0yeGNZZ0Vqa1dmZ000dGxNZ2hOUmZFWllmR1kyMHpDT3hqak9jZkd6T1dFMUNhOFlKNmpyZ1NjcVF3R0I0am5OazJ2Um9QVzJhRVlRcm90WUp0OXdBU3dmSWc9PQ==
LanceDB can run in a Lambda with S3 as the storage layer. Dirt cheap and tolerable latencies for chat depending on Lambda cold starts.,r/machinelearning,Z0FBQUFBQm0yeGNZeGRnUXpXNFVhSVdQeDlyTnVkaDhzMWhZdmRSMjlCWGdUNW5oY1JpMUhRTTNJX2VUUFl1UmxwWVVzOHRzWXlVZFY0ZmIwLUw3dnhvXzgtSHZwWWF1NEE9PQ==
"I think my biggest questions would be “what augmentation options are available” and “how are the augmentation options selected”.

There are some augmentation problems that I would genuinely pay to have someone else deal with, but these also tend to be highly restrictive problems. I don’t think I’d pay for a service that just offered a standard “add noise, rotate, shear, etc…” as I can do that quite quickly if needed (often we would need special permission to send a dataset offsite so for us to use a service like this the problem would need to be sufficiently difficult).

If the user had to select what augmentation options they wanted themselves, I’d only be interested if the augmentation options were things that I couldn’t get elsewhere, or are extremely hard for me to implement. If I can implement it in numpy/tensorflow/pytorch within a week, via either coding it myself or using a GitHub repository, I likely wouldn’t use the service as it would take longer for me to get permission to use the service than it would if I just did it myself.

Throughput would be another issue: how quickly could a very large dataset be augmented?",r/machinelearning,Z0FBQUFBQm0yeGNZUUYyWnA4aXFNVnQ2REZ5VExUYmNHVjVNWFFDRjh1S3EtelVVcFZMUElyV3RwcUliWk9Wd2hCU2pueWlBUkhRZ2YwOXpMcHJKMkFGemxFZDRRaGtKcFE9PQ==
Good to hear,r/machinelearning,Z0FBQUFBQm0yeGNZQ0xVWjhrZTZnaFNUN1R6b3dBS0Z1RlNJeUliVlQtb3ZWS2dOMi1ob1NGMmQ1eHk1VG5IaF9VdFlKUTlwMDlWWEI1VXFKOVV0a04tMWlGQjlwQ3IwUVE9PQ==
100% legit,r/machinelearning,Z0FBQUFBQm0yeGNZUVlPXzBIMldlckYwWmVwNEFLQ3kwRk43MmJvNXRaNGVXY1dfeFFURHpDX2hBbTFzZmJfNVFMY29sZHZCcGMtaWNueHcta3BGekpJZlVoOFJUMUN1dkE9PQ==
Hope to see you sign up,r/machinelearning,Z0FBQUFBQm0yeGNZS3QycEY0a1dUVS1vTFVZYkstbWdGM3BobWVTWWJWcXdaZDZ4UlBwaFpUNi1JNjViaEFQajVTY1R3WmJWT3JNU3lBZGdNdUZRQ0tDaHJxbmttb0p2WFE9PQ==
"Very simple, you look for a good lontgerm partner. Quality hosting companies.. one of the best in Europe offers worldwide best prices and holds another top company specialized in sys admin, networking development, ect..

But storage is no magic, it takes you a 3-5 month real fisical course to learn how to plan, host and secure storage... 

Or you can build starge servers by yourself...
You can build your own server and store it in a hosting facility too..

I suggest you either study this stuff, or find a specialist, or look for cheap storage...",r/machinelearning,Z0FBQUFBQm0yeGNZdUtBWFk3Zml6Z2dWcEo5SnlJN3dvWl91OEdDSUk4MHVBRElwT01Fa3VzVi1yVzROUHJuaWpHVEU2QXE2ejZBMGJhcXNNaTBWZkhaVk1rOWV5RGIySEE9PQ==
Another option to consider is a Postgres cluster that is well partitioned with some additional read replicas.,r/machinelearning,Z0FBQUFBQm0yeGNZUkJ3bFJQaEhkV1ROd3ZjVzlIbWFfVnV0N3NWcjI5UmVLbmk1UHJtakVSZV9aVHozVklGSDdaWkFjeFBRTjdSNEZMODMzNVNOT2xnQ0tmWDkxeWh3NHc9PQ==
Thanks a lot!!,r/machinelearning,Z0FBQUFBQm0yeGNZRVZkUVlOUFMyYTBWNThNRm9QS3p6LXVYdy1DaUV1YzlvN0tGOW4wMnZVYVRPYUp6MVp0eHpINk55Mm9yM2tkQ0tneDk2dGh0cWQ5Y2xaS1BRd2ZHU1E9PQ==
Duckdb,r/machinelearning,Z0FBQUFBQm0yeGNZaFhOVEkyTWNFcU0tOC03SHJyeWh5YmpnY0Y1U2Zsamw5b1VYQUZ0V2VwOHZkUHREZVctVzRkbFdXcE5sdnlrUDZwZHM4YmYxb0xaemx2MGswWWdMMmc9PQ==
Yeah vector dbs seem like a scam for me,r/machinelearning,Z0FBQUFBQm0yeGNZN1hEb3lNaWIxRy1fWVQzUUVrNllvT095OXlvdDhEZ1dhVUFOUkpjaVczRmF3YlpRMVA5ejZCbWpjRHUwZUNpQTRQWldzWjMtTXJONXpaMHZFZ0Z1enkxRHhYU1VXaU5GZFFCQUZPVHFIbDA9
"I was in the same boat (first job) about a year ago. Take it as a chance to get really good at software engineering and soft skills (which is most of an MLE's job anyway).

You can often end up with a lot of free time to chat to non devs at the company and scout for other projects. My current lineup of projects is good mix of browser automation/web scraping, setting up local inference, and OpenAI API calls.

I don't really understand the hate for prompting, it produces results with minimal time and money investment. Why is it any 'lesser' than something like hyperparameter tuning? Because the unwashed plebs can do it too? Non ML people will often hit many invisible walls with things like tokenisation, understanding inference bottlenecks, realistic expectations of what is possible or easy, breaking down large projects into sensible pipeline steps. So your ML knowledge still has great value even just prompting.",r/machinelearning,Z0FBQUFBQm0yeGNZN1lsZ1B3OGhzWndTd2JOWGhhMnpiWFRFS3lLVlJxbGxGUGNMenl6cS1MUElSSzUxYVVRaU1iZXlhWTZ6LUFHSFh0NkhjY09CNWNyZW1jWjU3dDcyckE9PQ==
Hey there I have left you a message on this matter.,r/machinelearning,Z0FBQUFBQm0yeGNZUTNvbE15ZWFpWXZ6ODBIQ3pUMU1MVC1Za0VHYUVvdW1EdmpPWnQ3QTYwdUhxcmRRb0MwTGhUOVdiNFdNYlYzYXhlb1piYWRBLWJaMjdLa0QycWpUbEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZeG1ZaU9yVUFIQ21taFNDQ1hpanI2NkRCNFdtQThsYTFuRmVmQUNMTjc0cTJscjdVYVNTR29QRG1xUW8tdGZoWE9VdFhLbUtaOUZ4TmlCY2RGbldUMVE9PQ==
"Buying a vector db in a can at retail is expensive because vendors are selling convenience to people who are desperate to build solutions quickly due to AI hype. 

You can buy that same compute at GCP/AWs/Azure for a fraction of that cost. And OpenAI is going to pay even less at volume. They likely also develop their own software.

Also, realistically, if I were running a service like OpenAI's, I wouldn't store the data in a huge living vector db. Instead, I'd persist each company's data in a local-oriented vector DB in cloud storage, and then ""swap them in"" to an application server at time of use, with some caching to avoid unneeded ""swaps"". So much of the data in their system is ""cold"", it just doesn't make sense to pay for hot storage for it.",r/machinelearning,Z0FBQUFBQm0yeGNZa254MHExelZpOVlxeW02WERRcVMtTjJ3eTBJUlI1bFN1SnNGTGtUbnNpMF90UUU5MG9TWlhtQW9oa2NiaGl0anNNeWJITG45MVRqU1NYX1RCUG4xWVE9PQ==
Oh Hi Edan (I'm subscribed to your Youtube Channel) congrats on the Thesis,r/machinelearning,Z0FBQUFBQm0yeGNZa0tVLURMckk1Zllhb3hpc0tDcXJ1TWRqbHlHR1ZDSjFrWi1LbTNLWTlCSUNJSnBCdzlsSWJxa2lzMFBOdDYwSm9aWVhWODE4OTdtdU1NTXRBV2dRZlE9PQ==
"This has always been my experience, but I've never heard any principled reasoning as to why. I'd love to hear if this anecdotal wisdom has been described formally.",r/machinelearning,Z0FBQUFBQm0yeGNZanBSb1lWWmtMMWtGXzRIYm04X09hdnJVX2pHQmx2RXJjOXVvUkt4bHBGbzc4b051U3BXZENBemVFdTE4bTQ4b0dXNlI4X2dqUndDZi1LTVBmbWt3amc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZSnlYUnVPOWpvRGZEU3pYVUtjaGFBVVhtT0FhNWw1UXh0T3VGbGROdnFRWThFZnZzS1FFYmhJZ0xsSUVTS0VaZ0Jia2ZZdnhxb0hLVENVMkR6NnZWQ0E9PQ==
I'm not affiliated with the authors so perhaps try to reach them on email.,r/machinelearning,Z0FBQUFBQm0yeGNZUUZmS0xZd084VXU2VElfWUxtQ1lYM2ItR2FSZnhLdmFyRHJDcTlCekJKQW9mMlF0bDBQaWVLSUx6eFJ4RUdDZ2tialFUa2xHelM2aEY5aHgwVk45dWdteDYySExmWFlqVFVTZ2RGUEZOTTQ9
"If you have a small budget, it's realistic and sensible to hire passionate graduate students or PhD students for your startup's machine learning (ML) needs. Here are some reasons and guidelines for doing this:  
  
Benefits of Hiring PhD/Graduate Students  
  
Current knowledge:  
  
Graduate students and PhD candidates are usually up-to-date on ML and audio processing research, methods, and tools.  
  
Drive and Passion:  
  
Graduate students love their job and want to solve real-world challenges. Interesting tasks and innovation may motivate them more than hefty compensation.  
  
Cost-Effectiveness:  
  
Graduate students often earn less than experienced professionals. If they believe in your startup, they may work for cheaper hourly rates, internships, or equity.  
  
Collaboration Potential:  
  
Long-term relationships can result from hiring a graduate student. They may take on greater responsibility as your startup grows.  
  
Attracting and Working With Graduate Students  
  
Contact universities:  
  
Talk to university ML, computer science, and audio engineering departments. Academic counsellors and professors can recommend talented pupils.  
  
To find applicants, attend university employment fairs, research symposiums, and networking events.  
  
Utilise Online Platforms:  
  
Find and contact graduate students with interesting projects or publications on LinkedIn, GitHub, and academic forums.  
  
Graduate students seeking part-time work may use Upwork and Freelancer.  
  
Make Interesting Projects:  
  
Highlight your projects' originality and potential impact. Graduate students choose challenging, academically relevant work.  
  
Promote publishing and conference presentations to help them progress academically and professionally.  
  
Flexibility in Pay:  
  
Instead of hefty salaries, give equity or performance-based bonuses.  
  
Make your budget clear and offer mentorship, networking, or data and resources.  
  
Supportive Environment:  
  
Ensure learning and innovation-friendly workplaces. Give users necessary tools, data, and resources.  
  
Be flexible with their schedules as they juggle employment and school.  
  
Promote Teamwork:  
  
Promote teamwork and learning. Talk about progress, problems, and fresh ideas to motivate them.  
  
Appreciate their contributions formally and informally.  
  
Potential Issues  
  
Time Restriction:  
  
Graduates generally have heavy academic loads. Expect changes in availability and plan initiatives.  
  
Experience Level:  
  
They may know cutting-edge stuff but lack experience. Be ready to mentor when needed.  
  
Retention:  
  
A better academic or professional opportunity may tempt them to quit. Create an inspiring vision for their involvement in the company's future.",r/machinelearning,Z0FBQUFBQm0yeGNZS2g5RVE5NzF5bDlWd0t0ZXlOa0JqeXlrZTBzaUNmZUw4UkE5ZVBNRjUzdUlOSGZWQllNc1F4ZlM0YzV6Tk4yaWFWSHlzZHVlQnA5MVJpV1duWmtmcnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZT0lVS0NOWm1nRmhid0tfU3JfX0R1N2YzUnpweExZV2RkYlloa0hqSVVnZklUR21nbl8zdmItV2hBN2t5RnA0eFBEUF9BZUNiTVhhcndZLTdSby1EZ0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZcDNnVV96MWNnamNiTUFLbE1Za041TG03MGZsY3pXNkhNVzVxREJZWUkzOFZHdjlTNHBkSHFHc2w1T2MzdE9oWW9xdGxMUU1PMW1QNVVId1VGS1VmZnc9PQ==
"That's definitely more of a real world problem question than what I've been practicing, thank you!


I havent tested your tool yet, but its feature offering is strong! I will try it out over the next few days",r/machinelearning,Z0FBQUFBQm0yeGNZdW9FTnczWnpSRUsyVkUzS1R1OXRLMlZsX0M5UGZRTlJSTkQ5X3NTUTFXRUxYcmtnSjNyZmZvT1d6LUNpbEY4Ymhma0llNVcwanpSd3d3RVNOVFF1eGc9PQ==
"I solve the problem with the information overflow in two ways:

1. Implemented custom news reader with tags (produced by LLM) and scoring/filtering by them: https://github.com/Tiendil/feeds.fun

It reduces my time of filtering news 2-5 times, depending on the day.

For now, I subscribed to 441 RSS/ATOM feeds and 382 rules to score news.

You can play with it here: https://feeds.fun/

I plan to improve the processing of news about new papers to provide a tagged flow of science articles for everyone for free, but it requires some time. Currently, my wife tests how the reader could be used to read news about new papers from the bioinformatics field.

2. Implemented custom GPT to produce abstracts of long articles: https://chatgpt.com/g/g-sN3k8IPLq-abstractor

Just give it a URL, pdf, or text, and it outputs a short abstract.

So, I can very quickly understand if it is worth reading the article or not.",r/machinelearning,Z0FBQUFBQm0yeGNZVXZKSWNWSEg3M0VLMlVXbW5SQUtRM0RHY3dZczlLYWFzUUxLMDY5eHQtTU90Y2pWWDQ4RURwejFBbnltWml4Ql9NZXZRQnJ5RHlGN1VrNHZpampZNHc9PQ==
"Even though I haven't watched it (probably yet), the effort must be simply acknowledged. 

Thank you sir.",r/machinelearning,Z0FBQUFBQm0yeGNZZnVmR0x2YVlYbXduNE9CS0xGRnhnYUxVaTY2U2phZW83ejF4Q0hDUGttUWQ5Y2x2LXJNQXlYMUtJVVVJejNGVnZDWmVPTk1BaWhGNko4RERHelVXZnc9PQ==
Sent you a DM!,r/machinelearning,Z0FBQUFBQm0yeGNZdEVQMFF1cFhaWjRINDdTYmt0MlRFNWhmWGVYclptMGRRdFNlSjQ3M0JLNGFiMWhKWVB3UlpYYTNRYXZta3VlYXFsYUdqX1RfX0pVZmdBLUhydDAxLUE9PQ==
Thanks! Please watch it and let me know the feedback :),r/machinelearning,Z0FBQUFBQm0yeGNZSE90ZHNDRFhZR0tYdy15dGpSbTA4YkFIbGU5NEI3ZWROUkdyTWNQVlp2X05GaHhQWVdCRThka184bnVLZnViSzB1Znk1cldocDVvVGIzeFBubDJqeFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZWVh1NDc5TUxuN1l5N29OenBlczJIWjAybkhnUnpvVkNsSThZdGJPcERhVldyUGNVaXE1eWQ3a3BSTi1GRVlKaEZtQVFzbURHMnNPTGo2SG1PeFFibkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZN0MzLWpKeXNnTHNKWXROeURZUTdqWXpuMGVUbE9MXzFQQ2E3SUFLT1NoSF9EbW5hNXVuUm9XVmFyQ25RS05wS3VGSlNXWGZvSk13VHhzVHVOOF9IYXc9PQ==
"First, sorry for the self-ad. I just finished my masters applied AI thesis based on the DCASE challenge (so, audio classification on low memory) which you may feel appealing as I'm already interested in this area, (bit obsessed could be said) and looking for a job. I do think we could get a good match. I come from a CS background and love coding. Only ""obstacle"" is that I'm from Spain.

I do think myself hiring students/graduates is a bit of a gamble, but you dont have to stick with them forever either and you can make tests and ""tryouts"" in the worst case.",r/machinelearning,Z0FBQUFBQm0yeGNZMzI1bWhVbUlkeXRvNWswdXI4ZVZYVkZKZlBXbjktX1pQT20tLXlHUFJOdEJpc0RPVlhPM1V0RlgtemdQdGdvZko3U243aG4wV0d5OGZYU0lkeklvOEE9PQ==
When the reviews for all the papers will be available to everyone on openreview?,r/machinelearning,Z0FBQUFBQm0yeGNZWkYzOTlmWmRGM2tmcER6MFBiRGZvZlJRUWpscktYRkxIQ0JaOWdkVWg0cGhiTnltazJXdkRIQzdNaDZwcVdBTGg2a09QM0Jidnp2SlJKOU5EVmhZOVE9PQ==
"IMO first level explanation would be that cross-entropy have much sharper loss then regression loss and thus produce more consistent gradient. Also it works as logarithmic barrier function not letting  value wander off the target area, like barrier function in interior point method. Effectively classification reduce degrees of freedom. Just my opinion.",r/machinelearning,Z0FBQUFBQm0yeGNZbmx3UmNXSzE4Q1F0MW1hNGRRRXRJSXcybGhPdldiQUxhd0d0RDl1TThoVEh2cW5iS0s3ZlpsQnNUbVZNY1ZPZ2Z4SG1Wa08xRlZ2VW5NYy1ncF9ha3c9PQ==
"You do realize Qdrant is open source right?  You can run it anywhere and save money.  I run local copies, Qdrant databases on bare metal clusters, and Qdrsnt instance inside various cloud environments within Kubernetes.  With their managed service you are paying for the convenience of having someone else manage it.",r/machinelearning,Z0FBQUFBQm0yeGNZeWQ3LUhCMXlHdUIyemU5bUpINnNkMDRpWW9Hb0VqZ0l4U2xfX0dRZjdzWlNPOU5hdnMyMHVYd3NHc0FiTFpjUFh3RUU4OXowZGs5aFRLMGktNzZ0TlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZb2hYcUtjdFdaX0RfUGxNaU5SZDRka0NvV2N1TGFTLV93SEtqOWJSTVYtbUo0QTh6MDE1OC1oMHRSMERPOW5oVDNkU1BsTGZBMXFjUDVYX1BhVVRvRGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNZZDBpM2tXNVVDOHZzQm1aeDB4SUhwZTFtcDV5QWZ2Y3VrT2lVSFpCVmJheUpxWWU5LWd2WkdMOE1yMlFib09ncmg2ZHZHX1F5TWh3MmVwRTNnTHZuTXc9PQ==
I am going through but would you mind adding the name of the book you showed in neural network part? Thanks.,r/machinelearning,Z0FBQUFBQm0yeGNZUmdtYmtBQmxZdkI3azBTNExiNU83bWUtM0hVdFZHSDNFQTBQSW1fMGpqQmc4RXFlclY4RDdfa3o0ck1EaDFsendxSUFzZjhUY2xKaWUtVTdrS3VjYkE9PQ==
"> any advice to for generally finding good overseas developers in a sea of bad ones?

imo, hire
- *in* countries/cities where tech hubs exist (e.g. Zurich, Berlin, London, Prague, Bangalore, ...)
- *from* countries that have a tech culture and/or famed universities or famed university programs (e.g. Sweden, Netherlands, Romania, China, ...)

It's more about environment and resources (family, culture / work ethic / attitude, university quality / funding, first job & colleagues, ...) than it is about ethnicity.",r/machinelearning,Z0FBQUFBQm0yeGNZWlltZnpURXF5czJVRTZzdzdzR1FUZVBUUDRtZF9EUEFLZ1gtMmxhNWRhMGlLMExiek5GcFp3OWpqMmVVSjVvMGszMjAtRVoyTVY0Rk1WcU91VlRPbWc9PQ==
"Hi! I will most definitely input this into the system. Just wanted to let you know I'm working on the UI to put these data into the system, so it can generate issues and sub-issues. So it might take a bit of time, couple of days, but I will get back to you!

I appreciate the interest and patience :) 

Have a great rest of weekend :)",r/machinelearning,Z0FBQUFBQm0yeGNZRUVNTmJwN0FHMkxLS29iUzQzdU91ZDN3NThuT2JRY1Z1RmN1MFF4VmNLZHF2TWVWNWppMjNXS2wzYzZIalpwX2trRXJoTTlfUUEwQklOWV9sM2hmY1E9PQ==
What is your startup about? Maybe I could volunteer,r/machinelearning,Z0FBQUFBQm0yeGNaWlZqMk9xR0FNemZQT3J3NkM1MnJLeXEyaXkwbVROUHdoeWFnOTdkSzBnd0JOOEZSYjBRRGx1bEVURHZ5NDQ2azZ4NFhlSjdTeUItOXdBY3RJVWVPLVE9PQ==
"> But this matrix is generated by a network, thus is not restricted by such made up rules.

Not entirely true. The mask is applied to the matrix, so it zeros out those values in the upper triangle and ensures no information will be passed future tokens. 

The graph is directed, not undirected. If you try multiplying by hand any NxN matrix with zeros in the upper triangle by an NxD matrix, you'll see that the result for each position is only considering the values for the position itself and previous ones, the rest gets multiplied by 0.",r/machinelearning,Z0FBQUFBQm0yeGNaUHlQSnZxMS1xX1dKYUNueTAyOTFQdldHcHo3UVNiSW9ZRjl6NkFrbVZkU3RoS0xLbkhjSGpELUh4V2FBZURRci1lOUJQbTNfQkt1ajl6ZnV1d2h0RWc9PQ==
"Whatever you need to tell yourself to make you feel better.
You made accusations of dishonesty and cargo culting
This isn’t a dissertation - it’s a pet project posted on Reddit.",r/machinelearning,Z0FBQUFBQm0yeGNaek14WjhTWWhZZHdoendTcjVweUtQdF9iREVYd0ZGZ1hBQ3ZzY0hBNl9kSkhwLTlob002dnAwdjVFNl9QMk9hWjZQcHB3SG1yS1ZrZEtDVE9JT2JuY1E9PQ==
">The graph is directed, not undirected. If you try multiplying by hand any NxN matrix with zeros in the upper triangle by an NxD matrix, you'll see that the result for each position is only considering the values for the position itself and previous ones, the rest gets multiplied by 0.

Considering each row of the matmul(NxN, NxD) = NxD matrix, I agree that each row, only saw only the previous tokens. And I guess here is where the real question lies. If you consider the matrix as a whole, each node is connected to each one. Wouldn't it be the case that in the following layers, the information of the whole matrix is mixed together, so there is no information hiding. Or does each row stay in its own lane throughout the whole network.

    output1 = softmax(KQ)V
    
    # Does a mixing happen here?
    next_k = nn.linear(output1)
    next_q = nn.linear(output1)
    next_v = nn.linear(output1)

EDIT: After checking the matrix multiplication of the linear layer, it seems indeed each row stays in its own lane, without a transfer of information to happen. This implies that each token row in the (batch, token, channel) matrix is processed in parallel. Maybe someone can check my logic",r/machinelearning,Z0FBQUFBQm0yeGNacm9XVlRjbm5haDhBQkZ0ZHplV2E1RjZrWjdJdFFKZmFvcDhVSUEzeDVwMDE4M25RX1VCeFlZa0g5bmJBb0w1TjF5Z2NRUHE5TVJqYkQ1SkQ1eXZLY1E9PQ==
"But even if you spend a full day implementing image augmentation it's gonna be code that you can reuse, that you can tweak now and then, that won't be subjected to potential price changes.",r/machinelearning,Z0FBQUFBQm0yeGNaWFhsTzFBQVg0X0d5NHY3OEowTEhOWkRSdEt4YnNRb1ZmMkhjWkJEeFJlUUgtNkFjRlZpekw0T2FQT0hrVEl2M1BtT3VSRHh1V2NFMEEta0hxSFEwQWc9PQ==
"If you don't apply a mask, then indeed there is nothing stopping that information from future tokens flowing to previous ones. 

Mixing doesn't happen in the linear layers, it only happens in the attention. Everywhere else the rows stay in their own lane. Technically, the equation is more like:

    mask(softmax(QK))V

where mask is zeroing out the upper triangle. In practice (e.g. the Huggingface implementation), it's actually done by adding a large negative number to the upper triangle and then softmaxing, but it's the effectively the same thing.

Edit: Indeed every token is processed in parallel. This is actually the main advantage transformers have over RNNs, since you don't have to wait for computation of a previous token to start on the next one.",r/machinelearning,Z0FBQUFBQm0yeGNaMFFXV3F3QlpHQ1Z1MzRqZnJIV243Ty0xWXlNZWloTDU4Tl93bklsMzNSQUx0c0VlYnFaM0NXalFnMExYNGg3dGFtUHNEb1FsenB0d3N2VUhGUW9LMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaNlBTM242Q09Qb1RKUGhTT0ROcy14UVdLYkRtUjYzazdqYjJ3XzF3cEI3QU1ZZTY4b2hsQ1VUamZraTRNTmZwNmFCaWZFWDdneFZSenNYVmMtTFYydXc9PQ==
"I am not sure if I understand.

PCH theorems (by Pearl, Bareinboim et al.) clearly show that we cannot (in general) learn an underlying data generating process from observations alone unless we make additional assumptions.

Do you suggest otherwise?",r/machinelearning,Z0FBQUFBQm0yeGNadFB5UUFUNkEwODQ1dWs3TzZ5dXE5VFJXdmpELU5NOG9QaHJYUnhudXdTYkh5NHhsM19jMXJZX3hIQXpGZjFZbXdTazZxcUhlc1I1QTE5UFdKVDNRZUE9PQ==
The other operations in transformer all just act on a single embedding vector (ie a single token) at a time. Attention is the only place there's potential mixing.,r/machinelearning,Z0FBQUFBQm0yeGNaZ2xPVUQ1bFdMWTN5c2pBY0JjbG83anU4R1pXdUpoc1VubmhEcUJQc0F3N20tS21oQThsU1ZQVjVVOENQYldOX19zaHNYdDU3OXRHdDc1dGpIa3ZiRUE9PQ==
HuggingFace? Easy to use and should work perfectly for MNIST-sized data. It's also free!,r/machinelearning,Z0FBQUFBQm0yeGNadGllU3RKY2lyZC1VeEpTUmxPSkx0alJ3R24yaWhpMFNGWFFCNGxaTEVSaTNxSmJNNFBzUWtSOUlOTEU1am9vaUVOZTlYSG9QREdocWFsMmxPaTcybWc9PQ==
Oops misread the post. My bad.,r/machinelearning,Z0FBQUFBQm0yeGNaVmRPbDV1azA1NzZOTm9lWURVTXpFODhjb2VNXzZ2eGpQUWJ2eTc4UGhic0NMNHBSeElQc3lJbGN5UlFSd05HQ0NuTXl4Z2lPYXU5cHNrUFozNm5uenc9PQ==
"You can use LLMs to do classification as well, but usually they perform better if the text classification task is its own API call, and no other asks are in the same prompt. But this will add to latency.",r/machinelearning,Z0FBQUFBQm0yeGNaTXJGWGlYQ2l1ZmtzU3hBOGRjUzQ4YndvNFdodWJfU2ItVzdzN01vVy1BWXhCYTh1eGFmbjF3TTFnejFkZ0U1N0pNUjVpNUx1VnRoaXRMS3RRZlhWN0E9PQ==
If I were to perform text classification then I was thinking that that would be its own model rather than a LLM.,r/machinelearning,Z0FBQUFBQm0yeGNaVlUyQTM4MEpKWTNNdHNKSDNDbGllRWlEdlFLOUFVYWhIMzRKaG1jWlpDLUw2NmlSaG15OWxOc1pkQ3pHdU5Gd2NzTWx5U0JxWEItcFdLdFB6RUVZVUE9PQ==
"I think this is highly dependent on the task. Some tasks LLMs have already been implicitly trained on and are as good as dedicated models, and some tasks LLMs cannot perform well at all. For example, anything requiring numerical reasoning is best left to a dedicated model.

The best thing would be to take a small sample of your data and check the quality of both. 

If you are going to use an LLM though, the best practice is to give it multiple examples in the prompt, and if the task is complex, prompt it to write out its reasoning step-by-step (with examples).",r/machinelearning,Z0FBQUFBQm0yeGNaV1hVMDdXTFJSY0Z5RWVhM1ZuWVdJaGdhY1RKVDl0TVQxWHhxaE8wQnJCeGM5Mi16a185bkFqNnlNU0xlUDlSbEdlRnBQeEFhT2lhXzhySW1zVjEyV2c9PQ==
"If you have the time and the data to train your own model it would work better in terms of accuracy, but in cases with no data, LLMs do seem to work fairly fine. In my work, we use LLM calls to identify the user intent, and appropriately choose which function calls have to be run further.",r/machinelearning,Z0FBQUFBQm0yeGNabldra2pGYVB3T1AyZGpyN3pPWHBpSjM3Z0l4SExfWHJFaFNQNWZNTDZ5RGxDS3ZTLVFWc0JhTEl3R0tGU05rMWo0QW1pRXlwckU0d3JGaEpmUmdMNkE9PQ==
"You're paying for a managed service with support, extra tooling, etc. It's click, put in CC, go.

~1TB is a lot of vectors. Ideally at that point you have some kind of business model where $780/mo is nothing. If that's not the case for you it's probably worth re-thinking whatever you're trying to do in the first place.

Also, given the value of your time (or a consultant/employee) and opportunity cost (time you could spend doing something else) if you save yourself (or payroll) ~three hours a month (US rates) managed vs DIY it pays for itself. Then you still need to pay to host it somewhere and even the cheapest VPS is still going to cost something ($100?), bringing the ""human cost"" delta even lower.

PLUS there's the initial cost (time) to get ""roll your own"" stood up. If you can get it done in a single eight hour workday (really low estimate for most people) that's $2000.

Of course do whatever works for you but a lot of takes saying something like ""Oh that's expensive you can 'just' do [insert complex engineering project taking days/weeks of work for many people]"" it widens even further.

If it were me I would click and go with managed something, pay for it for a few months, then re-assess how things are going (the business, etc). You can always migrate out when or if it makes sense.

In the end a vector DB is a tiny portion of the entire stack/effort for usable RAG and for most people and applications their time is better spent elsewhere.",r/machinelearning,Z0FBQUFBQm0yeGNaOWRHRTdUTVU2WFBicW5yQzNIOWY3bUlhTUt3MVNlRDVmc1hVaThwRGJEMDlOOHFHM2JRSkRVM0pyRXZkLXMwSUhNejVGMFg4ZlVXYkJndm9RWW1hQkE9PQ==
You can use Postgres with vector extensions as a vector db. Super cheap.,r/machinelearning,Z0FBQUFBQm0yeGNaX2pHczhhb0sxcVU0MlR2bHp1UXpfTXhVbkdGVjQ2RVlUR1RPRXBwMzBzTE96UWJheXZLRHl5TFVzVHI0c0tUZUtjeEs1NXAzSVdRQUZNVThlOHFocWc9PQ==
"Thanks for the feedback. What do you mean when you say ""appropriately choose which function calls have to be run further?""",r/machinelearning,Z0FBQUFBQm0yeGNaeVRvMnZpVU9yaUZYSW1fc1dxU0ozbDViaVF1M25fM3NMVnJhRFR3SFJzZ0VWM2hBSC1ObExiSEdqWk9MNDNlWGduTGVyZmg4YVlFUjVoTWNtTTk3Q1E9PQ==
"Pretty normal. Many use cases where just using OpenAI models as-is is good enough. I work at a huge enterprise company (if you are based in the US, you definitely heard of it) and we have a similar use vase. 

It's also normal to pick up others' projects when there is a staff shortage.",r/machinelearning,Z0FBQUFBQm0yeGNaTHhzMGZ6UkxseEluVVhhaVZweEpGeUpIUldqdE90ajdPRTR0Q19YOFdXeTBhZ2kwcEE5bTllWk9sX2dzcmdNY1E5N3ZWZjhGcTg4cTBXUTFnUnktRlNCQUpXX3VreU9WMXZ0NFlCXzZBb1E9
TensorFlow probability was a 20% project and remained so for about 1 year (with only 1 FTE). 20%'ers continued to contribute in a major way. Only 1 member was Google Brain. The other members worked on applications and just liked math. The team has not left Google.,r/machinelearning,Z0FBQUFBQm0yeGNaYTktdFJ2d25GT2hSN0p3dEdxMnI3M3V5SVNkMEhDV3NSLUs4SUlRWWhHeGFaVms3NTNMNVN3UEY4UlJjRU9wcjdZaGRDemZlOVpRUURMaGhaWlBuMGoxQXd6dVVxMzB3T3NKMVV1U3RkQzA9
"Welcome to ML engineering. What you described is how it is in countless numbers of companies. You are fresh out of university, but this is the real world. You need to get products out that are useful and bring value, regardless of whether it's intellectually cool or interesting. It's actually precisely the reason why I'm trying to leave the MLE profession.",r/machinelearning,Z0FBQUFBQm0yeGNaUGx2MGxBU0Q0ejh5ZWdPRXNZX1c1Ri1jSmM2eGVEZF9rbGNmaWtXQWtIRHphamcxYkxVaDZXZFI3eVFObGdqN1U0Q2FJakZJcXRicFc2bDNpNllkZUlsMDExeWc0RHdkcnZ2cEdoNXliclk9
I actually tested this when learning the world model. Using an MSE vs. a cross-entropy error didn't make a large difference. And in the policy learning experiments the value function learning is a regression problem. Learning the policy is neither.,r/machinelearning,Z0FBQUFBQm0yeGNaaHdtM2tTd1U0OVVhblJVZVUwTG9rSmMxSGdfNTFVN2VqYTFJaUZnamI2Mm1ibk9qVG1sLXBNamV0TjNVeXJ6X2xLbFlTTGtxbmNEVUx2aDhGLWhWOHc9PQ==
Very interesting questions! Unfortunately I don't know the answer to either of them.,r/machinelearning,Z0FBQUFBQm0yeGNaTmN0QVBVVV9NdmtUeTBxQUlKWTJxOVBESkNjZlZydTZEczRJU2lvd294M0k2MkpzRlFwVHliVzZsbGNtSm8wRVJnTUFBb2VwWldLYUM0Z0JwdzQzaWc9PQ==
"Cool, thank you so much. It finally makes sense to me",r/machinelearning,Z0FBQUFBQm0yeGNaRU0zRnNSWEQzbnVsOVZYbldNd2RMNXFzc1ZnV1BnVUxhN1hNM1lucUVTY1VsaHA4bEZoQ1FERGlGUUs0M0Mtb0lHcFFVT3oxS2JmNVA0SE5lMERNeVE9PQ==
"I see, thank you!",r/machinelearning,Z0FBQUFBQm0yeGNaMVdRWDN1Wno5SjRZb21Fb0VqVHJkekhtbkoyMmppR2RFVm1WTFUwcFREVXI2ZXdQYzlCX0hkSDl4SFZCRXljb3VXdEZoZFJMMnJnRjFwTF9YWU1DYmc9PQ==
"Thanks for checking out the work, and thanks for the thoughts!

In a way, you are certainly right that both types of representations are really discrete, but thinking of it this way doesn't quite make sense in the context of the work. It doesn't make sense because we represent discrete and continuous values differently. Each discrete variable is represented by a one-hot encoded vector, whereas each continuous variable is represented by a floating-point value (as opposed to a one-hot encoded vector with 4.2 billion elements). That being said, the FTA results are meant to be a sort of a bridge between the two methods, and we do see that it does almost as well as the discrete method despite being a ""fuzzy"" discrete.

  
On the second point, you're hitting the nail on the head. Despite the experiment being perhaps overly complicated, the point is simply that the way the data is represented matters. It's obvious, but important to show I think in the context of this work, and especially to show how much of a difference it can make. The idea is that there is nothing special that the VQ-VAE learns that the vanilla AE doesn't, it's just that the representation of what is learned by the VQ-VAE is more conducive to learning.",r/machinelearning,Z0FBQUFBQm0yeGNaSS1tbF9IQzA5UmhjdV9MdDN1ZVp2ZkF6VnlvOHZIOGJNYUtleThYMTFhbG1la0UyV2V0T0lCaGtRV1ozMFA4aXdRekZRV0JsdVozbnlUMG1DUGRkbFE9PQ==
Thanks :),r/machinelearning,Z0FBQUFBQm0yeGNaemtIWVpNUlRzeTZXT0ZHS0RONnd1a184U0VjbDFicmZxM05FdUltekU3ZG4td0xCNnZ5VmdFTnNmWkdHcnJfZFlwUFNXd0MzQkpQY1dnLVVpTnNhN1E9PQ==
"Graph Vision aims to create a topological map connecting neighbouring image segments, capturing each segment's spatial and semantic features. It also offers custom mapping options for segment topology creation and supports comparing semantic features, generated by vision-language models for performing visual queries on the graph.

Please check it out on GitHub, and consider giving it a star or providing feedback.

GitHub: [https://github.com/mishra-18/GraphVision/tree/main](https://github.com/mishra-18/GraphVision/tree/main)",r/machinelearning,Z0FBQUFBQm0yeGNaTkpJYUJ2Q0FzcDduODRjX1Z2UmN0TW9ZVTNfUmpfTGFNOGhQSlRHUHJNZWsyck14aHV4SVd2ejg3cGlIQTVHeDBMU25rV3VaWkpjRTZFeGhGRWg1NEE9PQ==
"Yeah in large companies, it’s not uncommon to have teams whose AWS bills are $2k-10k/mo. OpenAI can probably afford $780.",r/machinelearning,Z0FBQUFBQm0yeGNabEExV0szZk5DMDZ5VWx3bF9BZVljbFR3eHNhcWNqUlN3VGIyM2owNU52MGs1YTU3R3ZQRDV5c0VJVHFMRnh0Q0JpaFBTbWh4QUhBbS1ERVVSWHdZSWc9PQ==
Pretty much this. You don't need to use some fancy new db that came out in the past two years because of the hype. A lot of older databases already had vector search support for a while now. I think even Mongodb has support for it as well.,r/machinelearning,Z0FBQUFBQm0yeGNaT09uTVRveUk5ejhOV2pBR1R1aWUtcmpEZzREYUgwdzVWMWdXUjluSGV2TURUMHkzYXVuUnJVd2hETXB6NHFYTU04dHItWVR0bGdFdEVwQVBZN0FTaGl2T1BYUmVyRnNDYzRaUDZOS0Rvdzg9
"Say, You have an use case where you are trying to help users query their database, but the users also ask things like ""Hey, what can you do for me"", ""Who are you"", and so on which is about Bot's identity and capabilities. In this scenario, if the main prompt, which in this case is the querying one gets complicated, it will not handle the out of context questions like bot capabilities. So, you add an intermediate call which identifies whether the question is about database querying or capabilities or any other intent. Then based on the response different paths of code with different prompts and other things are executed.",r/machinelearning,Z0FBQUFBQm0yeGNaLWNxYjJKQm80Zm9ZWGRLekplOXBzUlZjWDV1NmZMTlhRbElRZ1ZFZWt3aEU2TDJXTFhsNlFQQU1yV05aYnlrNVVSMEVveVNHMGNVb0xkdUFaNEFQZ1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaeUtDcmt5NEo5dWZnVjdXbXdVVlFNcHdMclpoMTlEb1VJbHpra0RYdGVtU3JMRUpWUldYd0p4VkxFN01PSi1VT2g4Nk0zZUxjSnZtVXpvTnNjME5NM0E9PQ==
The neural network series here is quite 👍,r/machinelearning,Z0FBQUFBQm0yeGNaVFZoOUJyRXY3VjRDRUFUNXZnbkhYZXFyYzJ4RWUweUhfclZqY3Rra1MxS3Q2bkF0czItaG9ybzI5Q1FhNE1VbzV6djB5eVdRbUtCWmRIY0NFbHc0aFE9PQ==
"[https://medium.com/@tusharsadana/how-i-approached-text-to-sql-without-machine-learning-3849255d89a](https://medium.com/@tusharsadana/how-i-approached-text-to-sql-without-machine-learning-3849255d89a)

&#x200B;

please read this once",r/machinelearning,Z0FBQUFBQm0yeGNaUTQtMGpFRHdWcjdzV3J1Wm5hS1l2S1J5ck9EeXExZGlSSFFqbmZZXzhULTM5VkZKR2l5OXY5cG9aTzdnRGdnWWZhZWZLWWs0bFRfa1pKYWxyanRnMnc9PQ==
"In my experience, LLMs can do a pretty good job at classification too, but it requires very specific prompts. Its important to not only provide a detailed description of what kind of queries each request serves, but its as important to provide several examples of what kind of user questions would lead to which request being called. Make sure to cover all the edge cases too (cases where choosing between request_a and request_b isnt obvious or may be ambiguous). 

You can also try using few shot/zeroshot NERs or text classification models from huggingface to help you since you wont need to train from scratch and may be faster than building your own model.",r/machinelearning,Z0FBQUFBQm0yeGNaZWhqYzRRVG1iemlhTmhFUUVHbU80b1NKSlA2NXROQzhUcXJaRWVLdFhvZWxUYXlodXBNaWh2YkhQZlFQWFNFc3FSTG1KNDdwVURocHd6a1ZneFNFWmc9PQ==
Supervised learning / fine-tuning an LLM on the classification task would work. But it very well could be overkill if the task is simple,r/machinelearning,Z0FBQUFBQm0yeGNaUWZJdHNHTVZfWkpKZGtrWDVmajdKR05VMDVFREdoNG9uZ1NUQy1rZDN3TFQwREFzTkRPRm1BNzItQk03aFhnbHJ5N3FXeUp2MTRVajRCMTQzWGM1V1E9PQ==
"Yea I actually like those. I had a take home test over a year ago for some startup that was doing ""AGI"". And the test was to implement a probabilistic float8 implementation. And I did not get the job but I was so glad that I took the time to do it because I learned so much about how floating point works internally that I didn't really know. 

And that led me to doing a personal project on compression using arithmetic coding which required detailed knowledge of floats because in arithmetic coding you are essentially encoding all the data into a single N-bit float (where N is a function of how much data you're saving).

Something tedious like data cleaning I wouldn't do, but if it's an interesting question I feel like I'm back at school trying to figure out a problem set and learning a lot in the process.",r/machinelearning,Z0FBQUFBQm0yeGNaX0xZbGxDcE1jbG92U0lEcmNEVC1OM3d4WTFIX0ZkSnR0X3pzMFVNZm40YVRwdF9PZnZQcU9kMzFja25HdTkzcWdXWUhhNldESE54aHU0Snhic0hPZi0xMGJXNHZxMzE0WHN5d2tMWG9XOVk9
Adults are talking. Go away,r/machinelearning,Z0FBQUFBQm0yeGNaRzllX2h0YTJfQ1A1ZjBfaDd1Q19zRjR5ZGRlR1dpdUtWZzROb1daTDJYWTlxMFZueDJralllYm45V0FPWTFENWNmSGFNUXJneHI3UWcybWZWMkNYdkE9PQ==
"space complexity, sure, but how can it improve time complexity?",r/machinelearning,Z0FBQUFBQm0yeGNaVTFDaWFqa25vVUJiTzVxQW1od3NJbklKY1FqUHB3dGRZaGIwWFB3VzYyOFkxWnBqdk0yZXNXTXI2U3JzYVVvS3R2Y1RUYjF1WmJ1QUlxWmFDdlhGb0RxSlpDWEVlMWZVellPd0ItODlfbFE9
"Already thought of that, but that’s more for archival, right? So it’s immutable and I can’t just change things as this is work in progress",r/machinelearning,Z0FBQUFBQm0yeGNabVBFdXdNZEJqYzd0STdtSklvSkxoNEI0SW5iWVl1RUxNZHFzdUotd20xX0QxRlgwTzZBTEVNZnc1MlNjWjdFWGp1VUo5ZEtSbGdrQXRvQWp6bHpSeWc9PQ==
"You can also reduce the size of your vector massively. E.g. faiss offers product quantization or if you can fine-tune the model, you can add some bottleneck layer with fewer dimensions and reduce e.g. a 1024 dim vector to 128 for often little loss in accuracy.",r/machinelearning,Z0FBQUFBQm0yeGNaVHpMbnVpeHNPZGd2dEIxS2M1d3dTQWRqN0drZTQ1SFJld3dnOWphc2JxcFRhck5Mcktud2c2SmNLNkVVdWRfUHVHdDBmN3pxaEFCeWNCcGFjdzYzU3c9PQ==
I thought about cloudflare r2 as it’s cheap and has no egress cost!,r/machinelearning,Z0FBQUFBQm0yeGNacXNKME91ajl4Q29kdEhvZ0NJSWI0MmtManlYSTk1QjZtdERwU21EcDVIenp1Z0ZRNE94eEdjUlFtXzhFVURGSXg4aXl2LW90RGxaWUJsOVo0NlFMV2c9PQ==
"Solid opinion, imo",r/machinelearning,Z0FBQUFBQm0yeGNadkJNOElQU1ZRTzM2cTNyRXRoaUp2cVFGSWxYcFI5WTVJUmljYjFVLUpvM2tlczh4WHFoTnVUZWlPcExRSlA1SllORWRtUzNBemhzeFdYdEprQXJpNGc9PQ==
"If youre building a tool for data augmentation, make sure your dataset is diverse enough to train your model effectively. Also, consider checking out Atlas for any AI-related educational needs. Its been a game-changer for accuracy in my assignments, which is a huge time-saver! Good luck on your project!",r/machinelearning,Z0FBQUFBQm0yeGNaQXY0REFMX3d3LTBxWUdHbXVlLTlMNlp1ZmJLemFxZUtWR01mLTlfY3p5Vmo0MFZ3S0Y2aHczOWluYUVLV2Nra0FWMXUwXzJLN2ZNLUVxdnBFUEoyUUE9PQ==
"Are there any details on the data and training infrastructures of OpenAI, Anthropic, Meta?",r/machinelearning,Z0FBQUFBQm0yeGNabVN3WWRLcHpGSjlTUE1JUUhfVWd1amh3X1RLUnFnWlpLZ3pKZXR2LVRyalJpcE9OMTRnaWpndEh0b05UUnExSkp6anh6V2tsSUYtLWt0dEJ6RmhWTWc9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNaNDBtSnZkSHVVZWNqbjROZFJJOTJMOEpFbzI0bml6azBuSEl5SDRORDRVVGp2dGRYbXBRTnVTMllXcWV3NVo3U0xWaXMxaXN4TGNwR1lkckVvYlFlWHJhWXNtNUFmQlAxd0hOMEpOTV9NTlU9
It improves time but not time complexity.,r/machinelearning,Z0FBQUFBQm0yeGNaMndFS3RsYm1zcGdDMk5IN1FOTW9qanFtZjB2Ymc2dTZLUkMzenhGMUlxVnEzRFBzbGxaREQzNmxwZExENDh3TDhNbEl6MllhcE1LWUgwQjJmcEtHUWc9PQ==
For most cases you won't need the custom vector DB. Start with something like Postgres pgvector (https://github.com/pgvector/pgvector) You can enable the pgvector extension on most cloud postgres providers like supabase (e.g. https://supabase.com/docs/guides/database/extensions/pgvector).,r/machinelearning,Z0FBQUFBQm0yeGNaMWQ0dm90MEE4Um4xTEdVaFF2MUc1eE1TVTJ0YS16TDJZM0dRZnlXa2tiS21KOWZvbUVDZ25Ib0xOM1FJVFJwbnd3d2c4WEYyVFB5ODBtM0xJMHlWSGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaMVV3YWhsMFlIMkRhY2hrQUttTkZmdXFVanhsMWJmNHhFLVE0NHl3SlBpa3JuMG9WTXdram9KR0REUDhyWFJGaDF6ZV9feWF4RTRSQ1ZjSXV0SnA2MGc9PQ==
"It is the right of passage. Every one starts by doing small changes, bug fixes, writing unit tests, improving documentation on the team. It is the best way to learn and grow. Once you establish yourself it will be easier to move to things you find more ""interesting"". Most of software development in reality is just making small changes in a large app and maintaining it v/s doing v1 stuff every time.",r/machinelearning,Z0FBQUFBQm0yeGNaX2VGcXRxRFdYbHdpU0lCSjROUXBleTJZUS1wOHZBeUZ4eng2WlhVcTE0QlFBY0ZUeHR4WXBWMGF0TXM3UWVETzAwaE5OR2xZbmJMSnZqS0pDM0VvaFE9PQ==
Not for everything. For segmentation regression is sometimes more accurate.,r/machinelearning,Z0FBQUFBQm0yeGNadUJjNVUyU1I3djhrUEhpdFo4dEVOeDdRWFBZX2hzcGxGQ1lCdGE3cG0xdU1DS3VhcEJYeTFkNHlfcXVPWjM0REV5UWRfM19QbG9CUThteW9qS2U5a0E9PQ==
"1. We do make additional assumptions. In particular, the training process has a bias towards smaller, simpler solutions. The simplest solution for an addition dataset is the actual algorithm for addition.

2. You're not really guaranteed to learn the *correct* algorithm, only *an* algorithm. In practice the learned algorithm tends to match well in-domain but poorly out-of-domain.",r/machinelearning,Z0FBQUFBQm0yeGNaaVRVUlR0ZUdYWjg3QURUdmlpdE01Q3BxODQwcXEtOVZRNGtqa21jdkdIM3pYempjQS1RTndqd19Dd3BpVlpnM1hlanBCeG9lSjlMWHJ5Y01iVmJ0dWxJalhZYzdSWTVIRERZNjlGTmhIcEk9
"You need to keep in mind that its a two step process.

When you have vqvae, you have

Input image -> encoder -> quantized latent -> decoder -> reconstruction

During the first stage of training, the model is doing this process to learn a good code book and therefore good latent space. Once the model has converged, you have a latent space of shape (c h w) where c is the dimension of the vectors in the code book.

If we feed any properly quantized latent code we should get a corresponding image. Therefore, sampling the latent space lets us sample image space. 

For the second step, to generate latents, the transformer generates each of the h\\*w vectors autoregressively (and you train it to do this). We can do this because the latent space is quantized, so its just next token prediction with a vocabulary equal to the codebook size.

So the generation step looks like

Transformer -> quantized latent -> decoder -> generated image

The reason you do it in two steps is because if you don't the transformer is fitting a probability distribution to a latent space that is itself shifting as the autoencoder is being trained. This is unstable.",r/machinelearning,Z0FBQUFBQm0yeGNaQzVXeEhIWnR6MFVSOGk2a3Z0VzE1OW40V05NVF9HWjRVblk4Y2Z6N0ZaeXBETTJPNVJPczRDeVNkN2JmdmFEWm1RWlpQUjFhclVpa2J0bWFTeG54WlJFWmVXc0ZZV3F1WFRlVjdsU3pWX3M9
"So let me get this right:

1. We train the VQ-VAE module to get good codebook
2. The transformer is used only for sampling new images

Also, I don't think the transformer 'generates each of the h\\*w vectors' I think it predicts the next code vector index, and not the actual vector. Correct me if im wrong

Also, how does the transformer generate new images? Like, a single code vector in the decoder = a single pixel patch?",r/machinelearning,Z0FBQUFBQm0yeGNaTXRMYjIwbHl5Q2xLWms1RjNkN3FkUnZrcGVzMEMxUVNXSWZwSmlfcklielpSNHNDYW1IaFpsSG9vWjRhWHhFekVrQXpLQU5LSEFhSGFFc2MwUlgyNXc9PQ==
Why hasn't this been done earlier?    It seems that GNNs would be a natural fit to scene understanding.,r/machinelearning,Z0FBQUFBQm0yeGNaRTYxMjByeGRxR2Y5a20zQUMyMDlsUk9BaFJZRVRsWDM3b0xRaGJyN25jYWhMaWRtRlVGMHkwNHhKQmxJRGwzX0NyZ1pWendYdUl5NG14aVptN2ZNRVE9PQ==
It has been. Lookup regional adjacency graphs. There's minor support in skimage: https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_rag.html,r/machinelearning,Z0FBQUFBQm0yeGNaOGUtdmNJMkw0TC1pQVdvQklPbGQ5UW1QVmtDNVNnR2RFU1BwNXduV1VGVmFjeDFHSEt2RkJQMTBibGdSVktKcTFaa3U2bW1ITWtzeG9XRmpUcFNZVXc9PQ==
"I've had good experience with Amazon Polly for real-time voice generation, and Google Cloud Speech-to-Text for transcription works quite well too. If you need accurate context-based responses for any educational aspect, you should try Atlas. Its my secret weapon for schoolwork!",r/machinelearning,Z0FBQUFBQm0yeGNaZEF2Zk5PaEtINHVaaDNRSWs1bENvbEphQTU2cURlNGppdkZVYWZhaVdYYkg1NnBVRmRVbXNlYl95cnBIMHJpdXhvb010UHRGOWJybVpzYlJaZldQWUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaajdsX1JwTEl0dDVNRnNvMEF3cjlFd2R5ODRWWmhXakRwN3lUMlgzSFR2TnVtak5vVkRiYS1EcnA1dFI0UkI4b082WTU2Q2toQXJ3QXA3TE9xcE56NUE9PQ==
"I'd recommend against hiring offshore until you have enough staff to vet them. Students are good but will take about a year to really develop. If you can afford one decent middle-to-senior and keep them happy, you can hire a few other recent grads to round out your team. 

Or, if you have the luxury to wait a year for them to grow, you can chance it with recent grads. But keep in mind they tend to wildly overinflate what they can actually do without expert guidance.",r/machinelearning,Z0FBQUFBQm0yeGNaU2tCYnZGRFpWQjA0YTFtVkktNkkyU19rbEdjck14c1AzZnBxeUpISW9oSDQ2dlh0OWJPa0wzRHFSNFd5QWV1VDhqdGlubWtiR1NWUlNYU1Y3WFFCSHJMbTFIckNPUF9JM1g5Z2R1ZXd0dmc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaTEprX2JtLTVjZVlJQUJac2NJaDMydDBQb3l2dHhXcnhtUHZ2cjZoWjZZYUxialUzWGt1YldZUmI3Q3JYdktCUzA5ajNPYXJFdGlnNE9aeHBYX3IyVWc9PQ==
"This is great, thank you!


It reflects my thoughts on the work I'm currently doing, and provides some justification for my thinking. 


I think that you'd enjoy reading about what Andrew Gordon Wilson and his team is researching. Not at all immediately related, but his perspectives on inductive biases is fantastic. The power of an (overly) expressive model backed up by well-chosen and useful inductive biases is, potentially, the lynchpin of modern ML.


The way I interpret your results is within that framework. Worth musing over for you, I think. ",r/machinelearning,Z0FBQUFBQm0yeGNaS2ZMdFNaMkhIaGpjVGg5S3A5OF9CNW5YVmVTSEZtWGNjSkp3MXpudGxPWnRmMzVhejBsYnFxVzN2M0dwdGtzeDhlYTY5Y21pbTJyZkswVEZTa3pGdlE9PQ==
"The VQVAE itself is trained only to reconstruct images. So you give it an input, put it through the network and enforce similarity between in and output.

After that is completely done, you next can train pretty much any generative model that can generate discrete sequences in this latent space. So usually the first thing you do is take your entire training set and compute the latent encoding for each one. Then you train a generative model in this latent space. This can for example be done with masked prediction similar to masked token prediction used in language modeling. 

It's similar in concept to how latent Diffusion models work. You first train the VAE (which has a continuous latent space, unlike the VQVAE) and then train the diffusion generative model on the distribution of encoded images.

So we don't use the (VQ)VAE as generative model here. Instead it's really just a mapping that transforms data to a lower dimensional subspace on which we then train the generative model. This is done since the latent space has much lower dimension than pixel space so it makes training the generative model easier.",r/machinelearning,Z0FBQUFBQm0yeGNaVURfc2E2QzVZa044MlR6bWE1elVuSlIzLVIwcVVsZy1qTWVhNXNCblZCUTI0aURFU1Zrblg3MndEbjR6UmVUS0pkVE1wMUJDbWRpNzRKQk5VVUNFVlE9PQ==
"I’ve spent a lot of time working on chatbots in an eCommerce startup so feel free to message me to discuss further detail. 

But I would say that using LLM API endpoints for each individual task is a perfectly fine starting place. It’s true that LLMs are most uniquely good at text generation, but they are also great for task classification with little to no fine tuning examples. The issue is that smaller models can get equally good or better performance when fine-tuned or trained on your data. And the smaller models will be faster and more efficient.

Just make sure to separate each task into its own API call and don’t just mash everything into one prompt.

But using an LLM for every task is like using a nuke to solve every problem. It will work as an MVP, but more precise solutions can be implemented over time as you improve the system.",r/machinelearning,Z0FBQUFBQm0yeGNaVGNTSGd3OUQxMFpnVnVoNENSZVEyZ2dhVnhteXBNODBtSk1qbVhTdWxFTll5cVJkSzV1OW5YOXNqbGZGaVZBdE5RZGRsc3p3RVQwT2RjSXRFb2M3Rnc9PQ==
"""Garbage in, Garbage out.""",r/machinelearning,Z0FBQUFBQm0yeGNaRHlmZ0wtVGx6bWZwcUJlcWdDMHoxamNPdmVCZWFSNm9DNWhMeW9fbUhveE81MDAyNkdHc2YyYWd0YVBjalFQSnVRTEg0aUR5ME9ZN0FScmloQldzNThZR1N0TWhhc25ZU19yckt5VW5IRVU9
"Did someone figure this out? I was training my 70B model using a machine which has 8 A100s (40GB VRam each) with device\\_map=""auto"" and it all went well. But the same isn't work out with Deep speed (I have chosen zero-3, since it partitions the model params). Here is my deep speed config:

    compute_environment: LOCAL_MACHINE
    debug: True
    deepspeed_config:
      gradient_accumulation_steps: 8
      gradient_clipping: 1.0
      offload_optimizer_device: none
      offload_param_device: none
      zero3_init_flag: true
      zero3_save_16bit_model: true
      zero_stage: 3
      zero_quantized_weights: true,
      zero_hpz_partition_size: 8,
      zero_quantized_gradients: true,
    
      contiguous_gradients: true,
      overlap_comm: true
    distributed_type: DEEPSPEED
    downcast_bf16: 'no'
    enable_cpu_affinity: false
    machine_rank: 0
    main_training_function: main
    mixed_precision: bf16
    num_machines: 1
    num_processes: 8
    rdzv_backend: static
    same_network: true
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
    tpu_env: []
    tpu_use_cluster: false
    tpu_use_sudo: false
    use_cpu: false
    

  
Above all, I noticed a very weird thing. The weights are being loaded multiple times and I'm getting the OOM multiple times (once for one GPU). Isn't it a bit odd? I'm expecting it to partition the model across the GPUs and hence shouldn't the error come only once?

Any help is appreciated thank you!",r/machinelearning,Z0FBQUFBQm0yeGNaRjlIdi04QVAyc2Z6ekhHN0sxX2ZDLWk4V1NlOF9UOFlhU25tU2UwRmNzZ1A4MVBJVk5HQnhaX0hzc2JsVUZCWDMxUDFyWXl1OHc5a1d4dXRWRF9pQ2c9PQ==
It's faster because gpus are memory bottlenecked not because it has better time complexity.,r/machinelearning,Z0FBQUFBQm0yeGNaVE5iaGlqZno1WVVPeGF2Tnh3Q0UtX3dUcWRtcWJUN0JFZXJWaUNyc0ZXUG5YTHVLNlR5Nlh4TVpMaGdkWHJPdzRFRmlkMnhuNUJ2Qml0cnFqcTdZMzFaV0FDSjhvVWQ3cS15U1JZbDE3QUU9
"Generating each code index is equivalent to generating each of the h\\*w vectors (just map each of the h\\*w indices to their vectors)

Generating a new image is as simple as passing the latent code through the decoder. The transformer is in charge of generating the latent code (which has shape (c h w)). Also h and w here are the input image size divided by some number (usually 4 or 8). So in a sense each vector corresponds to some patch in the generated image, but also not really.",r/machinelearning,Z0FBQUFBQm0yeGNadmJPMkhZenB2d2tFU1pqLTJiLU9nNHlFYUdiTTVHN0VkQlY3SzJZamdTM01HdTFUVHlvSC1wZGZmR0NNVU5VRS04cUwwUjZrcHVkRDhGcWZZS3h4U0o3NWRlMFgzTmRKWDFtMWNjZzhPTjg9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaZ1F2cFhYeDM1RkF1T2s1VVVoRTJVenVXS0dJQWlwX2NHVGRIRW9ZLXRySXJUWUIyXzJaU3NiOVUyXzdlR3A5UWhoSGRtZ0hFUmFHRHVwR2c1OXVPM3c9PQ==
Which onnxruntime backend are you using?,r/machinelearning,Z0FBQUFBQm0yeGNaQ08tRjNtbU9ZR0FhcWozTkxNaERlWnZDOUxyRUQxODlzSUVLWEpnRV9QemowUWxZYS1FUDdGdW9HQl9BMzludU9LRk9OdHBMaEhrc2Jaakg3TlI2R3c9PQ==
"So your saying that a single latent vector is responsible for generating the image, like in VQ-VAE?

Then what does the transformer do? It doesn't change the codebook! So what it does? It outputs a latent vector in the codebook, or arbitrary latent vector? I don't understand the prediction. A single vector is used to generate an image yet the transformer is used multiple times for multiple patches? So its not a single latent vector?

I'm sorry if I sound dumb.",r/machinelearning,Z0FBQUFBQm0yeGNaX1c4UG5TNkNIWGp2eUdSbV8yamk3bGtvdmtEcVVKYko5VmtBb1lERUh3aHBmVjNmR1lrV3F3SERKNHBRYjdUdFVZbHh4U2o0TEpfMDBRdGVqV2VuVmc9PQ==
"Execution provider?
I am using the GPU execution provider at the moment.",r/machinelearning,Z0FBQUFBQm0yeGNadXFMR09JMHNDcldjZV80bGpEM1lGYmwzN25wYzVGOWFFenpLaDh5a25DenN4NHhybnljeGQyaGt5ODdxT295eE5jWmdxa0h4RTFkWk1KMVB4UHJVZ3c9PQ==
"By vector, i mean code book entries. So you might have c=4 and codebooksize 8192 for example.

Now the latent space of the encoder has shape (c h w). In other words, it is a collection of h\\*w latent vectors. So it's not a single vector that decodes to an image, it's a collection of them. Therefore if you have h\\*w vectors, you can create an image.

Okay, so how do you get those vectors? Since the codebook is discrete, really what we want to do is predict a sequence of indices with length h\\*w. So we do this with autoregression, predicting the next token in the sequence based on the previous ones.",r/machinelearning,Z0FBQUFBQm0yeGNaRlVJRkx1c2t5UUNKTW9nWmxOZml1ZHhaZXIzV3pFVEhucXJrRnFqeXh6M21hZmdnTm95dDNpanI5TWZTbVB3eFJ2RGU2ZmxSaERfYUZwVTcwUjlKWm51U1pXa2t1XzZUN2xGdGYwNnFaX2s9
"For Ukraine there are 2 options.  
  
One is [https://djinni.co/](https://djinni.co/) which is a very popular website in Ukraine, you can read terms here.

Another option is via recruiter agency. I can search for recruiter from my linkedin network and contact you if you want.

As for how to pick good candidates, I guess just interview a lot of them until you find a good match.",r/machinelearning,Z0FBQUFBQm0yeGNab2ZNNERVeFBIODAxekR5NGhqTjBSc2RBNENaUV82QXYtdFNCS0lhREhRWkJtc0dQdnFkOHdmSHRReGpldzF4YTNDN2Z3YUNUVGtybWpxdjR3dnQyYWc9PQ==
See my reply to the original thread,r/machinelearning,Z0FBQUFBQm0yeGNaTkVCZktMUlNBSGpyUFd6WFI0VVZ0M1RSM0tEVzhMMS11QV9lOWVVN3ZaU1hlal9MaGZvRF9QNXNTVjJPcHlyN19aSDBIMmtOSGRSODBCZ0Z0N0VRdGc9PQ==
"I hope i can give you an idea what to look for in fresh grads based on my experience. I just finished my data science masters and dedicated 5 years of uni to machine learning engineering. Been working a year and a half as a fullstack developer in a small company (dozen of employees, foreign clients) but each time when a ML use-case creeps in, as a solo ML guy i get tasked to do research and if possible develop and deploy a model.

I would advocate of giving a younger person a shot. But be careful! Look for profesionalism in us young ones. Some signs a young person is dedicated to his ML work: informs himself of industry best practices and tries best to stick to them, works on setting up an efficient development and deployment environment, dedicates an hour daily to read papers/explore new topics/refine and deepen old knowledge. That person wont dump all the code in a single unorganized jupyter notebook. That person spends time to learn deployment options, workflow orchestration, model registry, load balancing, edge device deployment etc. Look for someone who takes full scale responsibility for the ML project.

I know many fresh grads who think the job is done when the model is trained… yet they dont even track their experiments. But i also know some highly accountable and domain-aware guys who are work horses and dedicated learners. They are worth the shot!",r/machinelearning,Z0FBQUFBQm0yeGNaaWQ3WHhuUlFwMXV0NHdiME1aMTgzUWY5Zm9kZDFkaUZnSjFPUDBpbzdZMThTaE1OY09XaFBhcVAzNUpTNlJRTnZkcmtCaU9GRklHYS1jaVdkZjZBZHdiSGdCWG9WemJvZjBFSzgyQXlsSms9
What are the biggest problems in the industry right now?,r/machinelearning,Z0FBQUFBQm0yeGNaNTFucjFueGJWUGxESTVFdlVMMDJzQXNxSGVOOUU2T1otN2hiLTFycFlIXzVfVS1RWkJiV0F4ZHFMYjIzWUw2aFdrUWdubVdLbHFWa2FJVm5yWnRqNFE9PQ==
Thank you. Saved to library,r/machinelearning,Z0FBQUFBQm0yeGNaekJpc2hRQ0FoWlN2WS1GX0hldU1SMHl0eE1CaGtibjVWT2l6V1FFWmpYVk5tQS1yaHMzQnJBUkpGSGRuczZ5Ymc3Y3MzSDBsUE8wV1pLbWdYTzV2WHc9PQ==
"GraphRAG is pretty cool! I looked into it for my CS project last semester. For studying tho, I found this amazing AI assistant called [Atlas.org](http://Atlas.org) that literally reads your textbooks and notes to give you spot-on answers. Major game changer, especially for tough subjects!",r/machinelearning,Z0FBQUFBQm0yeGNaVHBVZnFiM0xiNkp1ZmZHcFRUbjVDdHNuRlY2WTA5MklfSEk2bTdsVzVtTlJaVzdTOHgxX19MaU1PYnZ4eWNLV0NNY0t3M2hybWlZUDdqdXdZOWxRQ3c9PQ==
"This may be an unrelated question, but what are the biggest problems in the industry?",r/machinelearning,Z0FBQUFBQm0yeGNabUZWRWRwX0ZfX3ZCTzVadUhDaWdWWGpnRzhTWWNnZlRKSWw2Y3VxVkdkdnI0VGEwTDExZkJzVmY0QkQxNENSQzBiMjFFV3loYl9TbENMY2NiSlF1Nmc9PQ==
I'm not sure I'm understanding your explanation. Are you saying that the loss function in weight space has steeper wells for classification objectives than regression ones?,r/machinelearning,Z0FBQUFBQm0yeGNaVS1zV3dxVmI2bzhDVE5maXVERTg4QU8zd0FsbkFSUFIyOENVeGRTX0xVcFRGaS1XUHZtQUVVdXRLbWZWd0YzUVR3UWg5UWFTVlY2akJHdmRmQVVKT1E9PQ==
"Why can't you though? It's git based, you can just push changes (though obviously you should have some sort of version marker, but that goes for everything)",r/machinelearning,Z0FBQUFBQm0yeGNaOXNaVklmamVHX2VJVk40Q3dIT0ktN2ZMYXNHTTBXUWtIQnVNS2xXVDBCNld0WDRWZzFsUnJuWVdZa3Mza2UtQmUxX1JQNXJOXzZhV0J2TzdDX3NxNmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaNnQzYmxkUFJ4dWVWVUI1aVhEN0ZmWFFMX0xZRGdENlVlRWwzLWhwb0o1R05YWkFENnZFQ0NpbUo0YmZ3dVgyVHk3QUFTejF3MG1mREZWSUg4T1JrRnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNacTMxbEZHUU13NkpGX1FmWHZ2S0dDek40amNrVTFoUl96RjZTNlFNSlV4OUozNGJ6dFBVRk9mcjlnQ2hGQk90bE1WZVdYUFVhZGdvRjVHTTU5OC1LQ3c9PQ==
Oh maybe I misunderstood it! I have to look into this,r/machinelearning,Z0FBQUFBQm0yeGNaMUxuNnRxWjIwM2dMcDJkdHBNZVZCdVBLa3gwaGZUUG4yc1NxOXVVZHJ3dTRfMWpqQXlSV3RVRE1FUDhZOGZMVE1PUk55YzJBMVI0am9ON29ibVdLX0E9PQ==
"It's a little difficult to parse what you're looking to accomplish, and I think that's an important aspect (for any project). You mention that you're, ""looking to detect ads"" but what about the ad are you looking to detect? Are you trying to find the brand logo? Or are you looking to find people in the ad? Are you trying to understand what the ad is offering? Without the purpose of your project, it's next to impossible to provide you input with respect to ""would this work?"" or ""is this a good idea?"" Additionally, you should be clear (at minimum for yourself, but helpful for others too) on what you mean by ""unseen"" as several people might have different interpretations of what this term means.",r/machinelearning,Z0FBQUFBQm0yeGNaei01Mjk4TlNNb3RkcVJscjFwQjZ3OFpFdEJ6Z1hhdVNMUTVBZjVlS0RUTkp0cnNpMGh0NjM3M3Y5WjRDTS00LUpQRTJSdXJzNnktUkhBSHRiRWExeW5MajMzYURCa01DZFl1NGMtMFFWbEk9
Is Postgres truly a good vector db? We had massive issues with our AWS Postgres cluster (40+ second cosine sim queries) so we switched to dedicated OpenSearch and all queries are sub 500ms now. But I think our postgres was just poorly configured.. What do y'all say?,r/machinelearning,Z0FBQUFBQm0yeGNaVDVYaG5fTlFKNVp2OVpJdnFBbi02TUJzX1VBWkVVakVZdGVaY08xenJWdmxVZ0xuQWhDSE5ZcUFGZWhXVFVsMUQ1TDVWalJTN3FSTHZwczVaMlYtV3c9PQ==
"Will check it out, thanks for the recommendation!",r/machinelearning,Z0FBQUFBQm0yeGNaZmYwUUFjSk1hcVN1OVE0Ry1ZcVgzamxhcV9qUzJ0M2haTEhfc0dieDRUVzM0ZVRCR1NqOWFEd25BUU9nbENwSFdCdElpU3lLd09jMDJaWEhyeWNXYVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaTC1kTlVyaHB6VkQ3bzBTQno2U3IwckhZZW5iQ005N01qUjhiTmo0amIyNGNqa1ZmWG1kN0cwVHp6emlNQ2ZwTXNXWXFEc2h5Q2p1cHpDbFFpQTBNT1E9PQ==
"This. Swapping, virtualization, indexing, sharding, and in some edge cases even replacing a database type with something cheaper if the disadvantages are negligible (and not telling it anybody) and hundreds of other techniques. It’s a massive field and it wasn’t that long ago when all this stuff was all the rage. 

Like literally before LLMs exploded, all cloud architects were talking about was how deep a data lake has to be to drown yourself and your bored ass in it because deep down everyone hates database optimization.

That’s why they want 800 bucks from you even though it’s not even worth 25% of it. But when your client has no problems paying it, and just thinking about configuring vnets and SQL databases with decentralized role and identity management brings up some dark and repressed thoughts, it’s suddenly money well spent.",r/machinelearning,Z0FBQUFBQm0yeGNaVEgyeXl1TG82cENqQW9oY2FHOU9LYmJuUWFXenJsb1lPWmFMSFBtMWVJMDl4eUxZZ3hIdlN1RjVFNkVNaDRhOTdKdTdOSmI2QUpUWkRwWkJfWG5PNnc9PQ==
"I agree! Hand-drawn figures add a personal touch and make articles more engaging. They can simplify complex ideas and break the monotony of traditional diagrams.

Creating these figures can be a hassle, though. That’s why I developed Sketch2scheme, an app that converts hand-drawn sketches into polished digital diagrams automatically. It saves time and effort, allowing you to focus on research.

Check it out if you're interested: [https://sketch2scheme.com](https://sketch2scheme.com)",r/machinelearning,Z0FBQUFBQm0yeGNadk52ZnAtTWUyLUNWcEkzcGxreW4zYm4zS0VJcnJaN1F6dmNXajRKMnM5LXQwckQ3d0p6VWxncW1hbmpSSkhYUi1CR09Yd045NmY4Zzd5ZmVfYlg1WlE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaRGJ0OGJnZ1N1RjdydjdwOS1VSGZsakNiODFIb0FqbzZUeElNOHpKWFpjX0RPSE5uS29TV1JlUUxhOExneXN1Y0hZcDFtSE5RZjYydmNDS0oxbF9Ob2c9PQ==
I would give https://github.com/RichardKelley/dendron a look. It's a library for building behavior trees with models.,r/machinelearning,Z0FBQUFBQm0yeGNaRHFNUW0tSjZIekdJeDA4VWJCcFlOMjdEQWRzbXFBbTkwNklBQUhjM1NBZWxUbzgwSE44YjNGVS1NVVdmRTNLbmZVUThGSGdKZWZiU0dTc0tFMGFFVmc9PQ==
"If you’re looking for front end work, my boyfriend loves doing front end stuff. He’s about to graduate with his CS degree (bachelors) in December but would be totally willing to begin work soon at part time hours.

u/Xylamyla",r/machinelearning,Z0FBQUFBQm0yeGNaeE5VN1VuZGIwd2ZCZVIzcm5rOGo1dnl3dDZNT2pBeGxCSXZ4V01sTHppTXpFZHZ2a2VKcV8ydDhVTDVOQlVVMFItR1FZMGpmWmZlV1JKU203Uy12UUE9PQ==
"Very possible, many people are working on this, I worked at a startup building exactly this kind of platform - the risk is that when you chain a bunch of agents together that aren’t 100% perfect on their respective tasks, you end up with exploding errors and garbage being spat out. Take a look at the LLM as a judge paper, it gives some hope in this direction showing that people and LLMs have similar levels of agreement when used to judge task performance",r/machinelearning,Z0FBQUFBQm0yeGNaMjB3NjVUUzNDUXB6UlBTZ3lDOXJqUlczcm9SN2U3LTB1dTVSWEpaaTk4SVhsMnNhRnRLcXBvZTJDNUNhMmxINDJ4UDZ5M1NNUjJDLUFQbUFfaXV3dmtNeUpyYWR2SlNXQWVSRXFWdHlsZHc9
"I've been using the self-critique approach with some success, using HelixNet as my guide -- https://huggingface.co/migtissera/HelixNet

He fine-tuned Mistral-7B to optimize it for each of the three phases of inference, but I've been applying the same idea successfully with untuned Starling-LM-11B-alpha.",r/machinelearning,Z0FBQUFBQm0yeGNaczVaQ0Q3dXBtam43cXZLdWFUZ0VHUVAwaW1hNVgxS3plNW5ESjFKaTF5cFhOX0RYRWdUWFZaU09PbzlLSlNONUNPS3phZ1N4N1YzMWF5WFFCNWlFSXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNadnFES1lidFFVZlBxbkVhdWlNWVl6S1N1Z3NkajN6TXdhY1ZrLUFSZ1JYd2N3M005cXY3Y05XdzNLakw0NEJ0dVZtZUxsQmVES1RTS2t0QjhucXZBYXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaSGFfbFJnb0d6VjdSdDJVXzNLMFFXX0ZWMlIyUUVTSnpNMGRjUXlVZ19XdHpaNlZCNVZLQk5JNGJ3XzFyNzJYS0Fia1F6eHliTUh1eXNybDNXT0k3Tmc9PQ==
"Yes, but some are deprecated now, there is a new AI master with more flexibility for selecting courses, which was not the case when I studied so I did two masters.",r/machinelearning,Z0FBQUFBQm0yeGNaaWFubkZ4UXp6dGk1NUhFTUtqZTA1Qm5zSEs0M1pWX212N2YwSjF5VGdOSEQ3NUFfd2RQV0JtenY4UmM0Vk1VTGRqQjVSMjlRWTBzLU1tRGdhVjdpSkE9PQ==
Where do you fine tune your models,r/machinelearning,Z0FBQUFBQm0yeGNaUVV3ZDh3WGdUUGducWNzT3BiSGptakJnWTNDR3dWclUxc3Rsa2R0NGlEc3FHbVNTREpxNzJuX0dBUHZyb2xrb2laYUY0Q0pIbFktSzZjUkpjaVF0Yjk3djBIN3Z6d1hPcUxnMjR5VHNTWU09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaeUFWUi1GN1BPb3NERDhyaE1Ja2dvNklzR1RXYkk3TWdaSGVlQXFZLXpYM0V6ckpCTkJJRDA4WS1JU3NVb1hGMmxFdlRlczY5bC1IWmNXd3BBWWoyN1E9PQ==
https://www.crewai.com/,r/machinelearning,Z0FBQUFBQm0yeGNabTRJbDNvYmtYMHVMbWk5a2JLTGF3V0hKTlg3MFNHeEw3QWdTZ0pjYkI3VjZ5TDRJbERJTTNaZGFjYWpRSGFQYXBoYThtZC1EbnBKSGVXdFN6eEVITUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNab1VneVFPS1Q2T3RSdUhQSDA5dDdRSEI1RTNQRzEwQWNCNVY1SWt1ZmNVdmlJcXZWZzBNX1ZtRWpJSjFPaHhnYXNnUG9DSDlKNGpPRjByT2JHOTZpZ3c9PQ==
"Awesome paper! Love seeing wavelets used in vision architectures, especially how you used 3 levels of decompositions in a feature pyramid type structure as part of a well established vision backbone and demonstrated the robustness. Curious whether this type of wavelet convolution or wavelet based downsampling can be used efficiently with MAE style pertaining. In theory it could be done with unfolding but that would be quite slow in practice based on my experience.",r/machinelearning,Z0FBQUFBQm0yeGNaVmZUTFFjb2FoSkJhUnNMeUlhM3NqYjhOaFVTc3dmbTFMcDZxRUNDOHh2M1YwWTF5dlM5bWpzRXZNUDlNMzkzbWVIM2x1elBLeXJhZlphUG43MVZLVEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaY3dZODRYc0E4ci05cDRsR3lCT0U2b0ozaEFKUnVJemE3NGZFMWVjc3RBTnJxOC1aa0l3clMzVTFxSzJ5UnpJZ193dktEUUV2QXh3VHpzVVc3U2VrdXc9PQ==
"Hey u/moschles thnx for your reply, as pointed out by u/SeveralKnapkins sk-image provides support for plotting regional adjacency graphs. However, [GraphVision](https://github.com/mishra-18/GraphVision/tree/main) keeps the spatial and semantic (vision embeddings) information as well for every node, providing different arguments for creating the segment map. Though this can be achieved by creating custom embedding and plotting functions, graph vision aims to simplify this process, with an additional demonstration of visual queries.",r/machinelearning,Z0FBQUFBQm0yeGNaMkh3Q0dObC1TZmhUcTFXenJMVVlxSTQ1Y3VVRzcyYkc0dHR5bXB0YWtUUlhEa0VfMk96LUtCeTRoS3hSRUcxNTlaaWZwWl9ubDk1cUxOeTA3QkxmRUE9PQ==
Because it's not 2017 anymore.,r/machinelearning,Z0FBQUFBQm0yeGNaREFVa1ZxNnFiODN2X0pmclBRM0J6MU8tWGRrLVdycmtDVjJsNG9XYzJ2dkdsbTRaanRDWmFIamRqOGd6djk0bzZpLXYxUWZNU2JKMjFTaVNRN0JITGc9PQ==
"I spent a year or so, tinkering with gnn and hoping that it was a next big thing. 

I couldn’t get the damn thing to converge on my use cases.",r/machinelearning,Z0FBQUFBQm0yeGNaaG9qWmF2QW5ZYXg4Sy1hcF85TUxCWXcxU0J6MkNLMmhpTDFNdERvZHI5eTJMT0xXU1FBSXE2ZFBZaVBLcGFDY1lsRW55NWtuQWExOUJIT0xWbWlBelE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaRVMyc2g3c01NS1l4TU1xRVkzaGs2dUpkOUJTTEYtQkdjYjBKMXZ1Z0tNM0RMTHpjX1AyTDFMRDBnVjFIVmxfOGJkSlJJMjlTR0dYU3NVOE53dHhvZXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaNG9TcFN3Y3VTekVmV0lHU1d3d0ltSHNrVXhCRTZOTkh0akc0VXBQTHo1SHNjUlQxQ1JBbTlQWHNhQlVuM3VZRlpGQzJOTUpOOS1TX1BGaXEtZGhsMHc9PQ==
Transformers can implement anything that GNNs can.,r/machinelearning,Z0FBQUFBQm0yeGNaZWNveGdtQl84bzhmX3czRXFqNDFaNng5czJRYXNJdmhXQXJhUnktZ0IxZ21mOFBqb0QyMGE5VkZlRG4yRC1LRlNCWmhqcmRRTTJJcG9fcFRiNERtSlBrRGs0SEU1M2lJVzBkNTlmV05KYlE9
"Back in 2018 we had a team of 4 PhDs dedicated to apply GNNs to our problems (dataset is from telecom providers, which is inherently a social graph). After 4 months of meticulous hand-tuning, it still hadn't beat our decision tree models with simple neighborhood aggregation as features that took 1/10 the resources to create. Maybe it wasn't a fit for our problem but yeah I haven't really seen GNNs applied successfully in real-world with massive amount of nodes, say a few dozens to a few hundred millions. Usually what works is some simple but clever aggregation functions that acts on the neighborhood of the node of interest, then those features are passed through a simple classifier.",r/machinelearning,Z0FBQUFBQm0yeGNab2s4Tkd2enVUbGNQWGVjLU5QbUl2Z2plYXZFb1BsYmJZZndQZERiMXdRVDd3ajNzV25sS1VYeGZZVl9YMkVZRTRVdGNJQ21sRVV0ZGU5REszQUtrM2E2OThqeGs2c0NBZW9obW5tN28xTnM9
Thanks for sharing.,r/machinelearning,Z0FBQUFBQm0yeGNaWWY0cHVPbjMwQUxpRVFScmUzMGdNSUx6QzI2ZHBiWUVSYVF5Qi1DbS05bzd2MExubTF6UjdvVFJzS2cwNGtqRVpoWkt2dUs4emxiQjloVHI1WE9RYmc9PQ==
Even when it comes to the problems that gnns were supposed to dominate like protein folding. They are just llms too now lol,r/machinelearning,Z0FBQUFBQm0yeGNaRERiTTQzLWFkekt1ZmJublhhWGZWdnBiX1dtY3BEZ0tVNDdYSGMyLWFTU21oM1VCcXpPWXVzQUJIcXBpV2FiNzRNQ1VXOXg2LXUyOXJvbUxsR1RENWVCVkYxNVlzWks2TmdFNkRjN3Q1WnM9
Not ML related.,r/machinelearning,Z0FBQUFBQm0yeGNaY1loSXlkU2RIbHN6aGNOVU1Ja3pfQk9ZTWdGeUZBSjZWdWlPLUYyT2VkSDJkdGNxdEt2dGZFQUNtOXhhNXEzOXE3REktdGN2MlB5c1RWLXdCaExmSnpmWFF5ZTM2ay10VWZUaUlLbzRzdkE9
What if the customer classifies their own query,r/machinelearning,Z0FBQUFBQm0yeGNaYnZqNVZtN2pmaXVzNl9wWF93MmZBdVVUVzY0Y1ZYT3VrbmV5Q1RrOHc5ZzNPQmFfakRTRndxV2JpWC1zbG9nZUpURmF6Q1lianJiSjFhdWhhemhXRWc9PQ==
"Just use binary embeddings

Can usually keep >90% performance. Storage is 1/32 size, search uses a flat index with hamming distance",r/machinelearning,Z0FBQUFBQm0yeGNaUTE0eUZGWmlGZkFITkVwZzZhLVhsVWRPUi11RFJkMTZWYXBFZUxmRWp5UEFVN0Y5b1JiYVVFRmdlWkhOS0tUSFpjRUEwREx5bTVzeHk3LURXS0I1NVE9PQ==
"I actually found it works well when you use it for things it’s designed for in my use cases.

GNN - non-Euclidean data
Normal NN - anything you can make Euclidean 

Keep in mind with enough parameters you can model Euclidean spaces with extra dimensions to the non-Euclidean. Don’t have time to link math proofs but you can find them online easily.

Which means you can usually get away without GNN if you just add more parameters. However GNN work really well for variable data sizes.",r/machinelearning,Z0FBQUFBQm0yeGNaOWhlTUxiWUdJMkFDa0M4NWxqeDI2LXc1dE1WNnVzSTJMR3hDc1FfVjkxQnFOdEdWZU5YakpoOHVQcXJ0RTlZR1Y4MFhNOEJvMTA2Y1JUalgyQm92U3JOUHl6XzdqYzg0NG1YZHZiY1g1aGs9
"I think there are a lot of uses for graph ML because so many problems can be defined as graphs. However, I think with these problems there are lots of overlapping domains where you can use a more approachable algorithm to solve the problem much more easily without bothering with graph conventions or frameworks. Like if you want to figure out a simple way to predict graphs consisting of ten nodes connected in a row, you might as well simply consider it as a regression problem. Maybe that isn't the best example but hopefully you get what I mean.",r/machinelearning,Z0FBQUFBQm0yeGNaT0VGclBUaDV4LW9udVl6Njhsd1hwLVp5bUhiV1B6R1ktbUdodWxkaWgwdEwwNFhUai1jWU5NQWxBcVRmZGFjY0tNcGlyWHJ4MTl4MEZ4c2lBd3B6Y1E9PQ==
"I personally would say is you need to determine if your data is Euclidean or not. Your data is Euclidean therefore normal NNs can work fine. 

You also need to try things like Graph attention that give it context size like a transformer in different directions.",r/machinelearning,Z0FBQUFBQm0yeGNabjAyckU5Z2x1bC1ReGg0OTNMRHpYaElvRll1TEppb3JXQlBMa0R1VXkwUHhHVnNFV3FmWFJSMEZwTWxDOFNTbi12TkRjY3JRRmlXSU90TTE4MnBWLWtiNXZYVHF0cTZqc3Bfb2VOQXdmQUk9
You can think of transformers as ultra powerful GNN that can learned edges and edge weights without labels,r/machinelearning,Z0FBQUFBQm0yeGNaTkJBdzBlcE9fRVRJbXdNSl9qZ2hCQ2xIaFdnRlROSzIxRzhpRnVCVjR5SUtQVjItMXFQeU16aWdhbG9uWENtcmwwcHZuNndFYTlnLTZTNko5YlFhc1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaRVkxS0ZGUGRVOFZyd0NldnZ6aTMtVFNfa2lnSGNwMC1jaUZaS2RwckZUYk01Wk9sb1ZZODg3bHdQWk5CLVBqMThDWmdCLXl1Z3BndldlQTJOTTJXR2c9PQ==
"it doesn't really converge, hence does not work well. Why? Some say it's because of oversquashing, which kinda makes sense for certain problems.

You can think of transformers as bipartite graphs - a subset of graph neural networks. So transformer working better than gnn makes sense.",r/machinelearning,Z0FBQUFBQm0yeGNackF2SVhIb1pmcWRCa0J5RkZOT2xONFI5TWNDbzhtbDBKVmlYM1kwY090R3Iybm5jOGRXTkZFdElwakh6RWRPTXBQaG8tcW9ZaE9tbnZCdnJ3RUtzbEE9PQ==
GNNs could have an edge when the graph is very sparse & compute is limited or data is vast,r/machinelearning,Z0FBQUFBQm0yeGNaVG9qZDdaN2hnd1FEYXk0c0tRR3dXNGJ3UDljcjBSSDNERklqZmhkd3lJQUpsNXAxYUpSdnA1QjJabzFfR0ZjaU5hN0Vwa0tDSFpBVzNXS0NiTzVPNWc9PQ==
"IMO, **Autogen** is a great open-source framework for this. Best one I've tried so far. It also has the benefit of being backed by Microsoft, so is somewhat *less* likely to disappear overnight like the 100 other single-developer agent-based frameworks out there. 

https://www.microsoft.com/en-us/research/publication/autogen-enabling-next-gen-llm-applications-via-multi-agent-conversation-framework/",r/machinelearning,Z0FBQUFBQm0yeGNaQXRhbk5uaV8wby0yMUdMelI4cWJWblFudzBDWG9zUEdSX3hrR3NBOTJRbWh0X1lPbVFmYW1PcXVkcWFyc2FLN3pLN0FKdEdRbEZsbWZnLVRlUEdOMmc9PQ==
Hey max. I have sent you a chat request.  Please check if you have not already,r/machinelearning,Z0FBQUFBQm0yeGNaQ1dESFpQbFg0NFZ4WGN3b05janU0d0xleUlwODFmSGJIREtHdUFVREVUQnFIb3JVTWpEbzJSeDg4UW9Lb0lNcTlUV2dnNVdiWmZ0WVhWODdVRU11Vnc9PQ==
"That’s a valid concern however it’s not always about coding. Sharing and explaining what you created are important as well. Maybe write a blog post or create a demo of your work. For demo, you can try streamlit if relevant.",r/machinelearning,Z0FBQUFBQm0yeGNaVENyXzV0QUlGTVE3TlplakxZUkhRRUdNc0dqMkl1OS0xdE5aVUI0dFEzbTJVNm9pWnkweFBTRXBGbWdMNldNNlF4dDNUZV9hdHFRX2plTGYzNHJhdDcyNURoLWEyb3ZWY3ItMVJ1cG5EZmc9
"Having troubles finding the paper ID. The faq says the ID should be created with a new submission, but did not find when I create it. It just says regular add author, abstract, and pdf upload option. Any suggestions?",r/machinelearning,Z0FBQUFBQm0yeGNaZm0zVnltdUZ0WUZmWHNtUnhwMjUtUFY5MGIxQW95MDVEZFNWZURiUzM0bXFtZjZ4Y2VKQkFfVHdMODZZeGJIUVlLdUVwSm11Y0tXMzhtMEkxc21YVVE9PQ==
what is this site? I also want to get into this field and would appreciate any advice,r/machinelearning,Z0FBQUFBQm0yeGNaVG5hRWgtcGtMMTgxWURGblFzbkJIZUFnWWhnRE1UTHFFNGJ4NVJuOUw2MUs4TURLU0hybHdxT3FnTFlLT29pRDhIN0pNeVhtSzYzRG9fZUprelJ2emg2NUtFVTJsX2czU2c1eWdMYnhtWmM9
"Hello there,

I hope the answers we shared have given you a proper understanding of data annotation and data labeling. If you have any further queries or if you're interested in diving deeper into the topic, I’d love to hear your thoughts on a few related questions:

1. How do you see the balance between AI and human involvement evolving in data annotation over the next few years?
2. Have you come across any specific tools or platforms that effectively combine AI and human efforts for high-quality data labeling?
3. What are some of the biggest challenges you’ve faced or heard about in the data annotation process?

Looking forward to your insights!",r/machinelearning,Z0FBQUFBQm0yeGNac0dhcEd6b1RXR2Zyb05pUWdBcEhhTnMzSXliQTg1R19VUDJpNWtrODl3bnd3VFlzNTdLMGh6T2NlZS11YV9zdTBCc2dBOVozRFRHbWFqbzJnMFVETUE9PQ==
"Good amount of applications of GNNs on the chemistry side of things. It really depends on use case and how well they fit for your data, even then choosing the right architecture of it and training takes practice.

And you still need to do feature engineering, fyi…",r/machinelearning,Z0FBQUFBQm0yeGNaSHBLUjN6SF9rT2YydlJLQWxLcE5WRzdnNjdaaC1OQ1JmZDhPU2QwTEw0QW9NaFdOTzFLMHM0MFh0Vlg1MWUzM3lDSmtVaHRMb2hWb2hXNGFha2RyaGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaVExjUjB3VGd6NlZtR0NITGlVajNCVXBLblFiNnFhSzlMM3pxbE1HV2pKTzFDZnluOTRzZHNRWUZNS0p2Y0FTYURmbXVVVGtKaW1FWTZvN0lONWRIeFE9PQ==
"We have tried all of that, they were not anything new, even 5 or 6 years ago, Graph attention is just attention mechanism on edges or nodes. They just failed to deal with the real-world dataset, i.e. millions upon millions of nodes that change very quickly.

Back in 2021 I did briefly join a small research group in Canada that worked on Graph Signal processing, which seemed to be a more fruitful endeavor, at least to me. They deal with the problems of interconnected sensors, which seem to be much more tractable than social graphs.",r/machinelearning,Z0FBQUFBQm0yeGNaY0hlRC1VV0lyZDlJQjRfdGVPZlhSUV9oeFR0RzhnMTF4Ym1BRC1kQnNEdHl4M1E0cDdpejhpUDBNSHA5c1h2YUtnTXJwNUh4WFdVMUtHYXBYYkYwRnRQUUtIZU9Ia1h2YkJhRHRQTnEzdE09
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaTDFXOTItbldsb2NOVlJSU1FUN1RlNHZpZUo3VmNKMVl6VURTZjNBN09QV1VITXhKSjR3b0pLUVB6NUxaSExBM2JkTE5Bc0tBTUJoVWF1RTVUc2ZwZnc9PQ==
"This comment is confusing. Did you mean that it improves space but not time complexity? Because that is true since we do not really change the number of operations, we just optimize the memory operations, which is space, not time — and it gives the speed up simply because we use a faster memory throughout. Although I would argue that a) reducing the number of memory swap calls can be seen as time complexity since we reduce the number of operations in the algorithm, which by the way kind of dominate the runtime, and b) they do kernel fusion to merge several operation together — and I am not acquainted enough with cuda and all this low level jazz, but it is possible some sort of time complexity reduction might be happening there",r/machinelearning,Z0FBQUFBQm0yeGNaWkxMS210OFpLU0xDMEJpSXlHMmlsWS11RWZPbkdqbG11c2lCdGVqYkxaczducy1feW1CVlVYRG1lb1RRX1loTExvRERLUjdSRzVYalFPUXRjazY2blE9PQ==
"You have the right idea. Start with a real problem. Then you can build a solution that helps people.

Recommendation systems are very much desired. Content-based and collaborative filtering are useful in many domains: movies (Netflix), anime (Crunchyroll), music ([Spotify](https://www.youtube.com/watch?v=pGntmcy_HX8)), shopping (Amazon), books, restaurants, etc.",r/machinelearning,Z0FBQUFBQm0yeGNab2NsQW4tWDRXLVhkMHpGb0ZDaFIxczJiM3kxdHg2bS16Y1JtTGRrVTY5V3FHOEVUbnBITW9EZmlSUFJuMDdHaVlIemNBdzRCbEtGT19WbnFrTmdfaFE9PQ==
Got any papers?,r/machinelearning,Z0FBQUFBQm0yeGNaSFpvYlpXcmlBS0xVZmZveHBGZ2JPNTE5UGJzOFl0akdUb3F2blhNbVB5NUdkWlVucS1MWHEzOGNaM2c1bEJzSUp3aUJWandrUDhDajA4cTc0OVpZa2F1ZmF1MGxKcW15WVRNcmJqaWRTbEU9
Great article!,r/machinelearning,Z0FBQUFBQm0yeGNaR3FGeUQ5azRUUWNsRV95US1ObjU5WGFpeUNfbkl3QVhYS0NSbkVvSzljazA1Vk1IbldmeWxMdThNM25GT1RVVGExM19KSktrbDlrX0JTdlRDZnBTYUE9PQ==
Hey all has any one tried ABACUS.Al and wanted to know if it’s worth it compared to ChatGPT 4.0,r/machinelearning,Z0FBQUFBQm0yeGNaTlNtLTdGUXBpcU1uVXVnNW1qdEkxOGQ0RWh0MjNCN19DcnJubTZQZU9POEpDN2hQZFFwMG8tbEVZVTJ0OTdGLXBjaldNNGhPU1RvcENDWFNkTUZGN3c9PQ==
"DeepMind's project ""Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning"" (also known as the OP3 Soccer project) is a fascinating exploration of how advanced machine learning techniques can be used to teach a bipedal robot to perform complex tasks, such as playing soccer.

The project uses a technique known as deep reinforcement learning, which is a type of machine learning where an agent learns to make decisions by taking actions in an environment to achieve a goal. The agent is 'rewarded' or 'penalized' based on the outcomes of its actions, and over time, it learns to make better decisions to maximize its rewards.

In the case of the OP3 Soccer project, the 'agent' is a bipedal robot, and the 'environment' is a soccer field. The robot is trained to perform various soccer skills, such as dribbling, shooting, and passing, by interacting with the environment and receiving feedback.

The video of the experiments from this project showcases the impressive results of this approach. The robot is able to perform a variety of soccer skills with a high degree of agility and precision, demonstrating the potential of deep reinforcement learning for teaching complex physical tasks to robots.

However, it's important to note that while the results are impressive, there are still many challenges to overcome in this field. For example, training a robot to perform tasks in a controlled environment is one thing, but getting it to perform reliably in the real world, with all its unpredictability and complexity, is another. Furthermore, training a robot using deep reinforcement learning can be a time-consuming and computationally intensive process.

Overall, the OP3 Soccer project is a significant step forward in the field of robotics and machine learning, and it opens up exciting possibilities for the future.",r/machinelearning,Z0FBQUFBQm0yeGNaRlZOT21abHlqd2lvVHQxUU9rZnRNeF9DT1FDcm4tb0lZNGZwV0ZPWlBYTGdOSmVTYVJMODFHWTJnWlNEV202X3gtdkc2UURkWG4tVzVzbkFFbnhWOTdkZGNOMWpsUk9XY1VSM09ZMlpIXzQ9
"Anything citing MoleculeNet or Therapeutics Data Commons (TDC). Also DeepFRI and similar architectures for protein function prediction. Off the top of my hear, architectures: D-MPNN, AttentiveFP, GROVER, GraphMVP. Also almost everything pretrained is pretrained for chemistry, e.g. GraphCL, JOAO, also GROVER and GraphMVP.",r/machinelearning,Z0FBQUFBQm0yeGNaUDJoMkZNUUc3Q2tzMFVYWUZXa2t3SlpXS2RGVVdzQW1RdEVGbWhDXzVXVUVwdnZWcEwzZ2VOdk5HOGxUVlBzcTlrZi04V0Z2czllMGExS1Y2VmFHSXc9PQ==
I've developed a number of such POCs (even more complex). You can check them here : https://youtube.com/playlist?list=PLnH2pfPCPZsKhlUSP39nRzLkfvi_FhDdD&si=hEmInzqZtEq6eyQb,r/machinelearning,Z0FBQUFBQm0yeGNaQU1HMUMzTGlFVzFhOHBzQUxVS2w4R3o4OVhLOGJpOHpjaXdVNWRfMUw0cEpFd2ZZYUQwcHhqM25zczEyMk5SYUNUYVhMUmtiT3dDSEpKQ1RVTS1JVnc9PQ==
"As far as I know, flash attention requires support on hardware level. I guess it doesn't improve time complexity?",r/machinelearning,Z0FBQUFBQm0yeGNaU1o0dTNGS05PbjVqRWJvdGJsVTRoSFdzczJUak9lZ2Zib0Fza2ZCNUFpb3YtQ2pYNU1oUUYxdjNQN1dzbHZPWnd0U3JhUlRXQTdQQzhfWVhjVjZEYUE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaRXRVbmEyTk12WTl2eXgtS05oaGx2M0d4Q1QwQzFNQm5OYUJSdVVYcFV6Wl9QRUlRQjFxUmlPM1NENm1XdzVnSjV6UDBNYmsxRUhuT1ZrWGRmZUhySVE9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaWE4zb0laQk4tcTVVSmFPTzdXWnVudS10MWQzcU9aeW1BNi1BQ3JNQTZBaUNwU1UwT3g2RWNGWGVHM0JHZWFpd2dyanFObXY0Y1lJd2lXWlJEVEpGZ3c9PQ==
Thanks. Seems like gnns truly arent used outside this realm,r/machinelearning,Z0FBQUFBQm0yeGNaQkdVZkI3ZzhRSkNBMzdPUzJmV19FbmZ1RElDaUJUSWJTdkV6ZWdmV2R3c09rc0NUY2RzZjFGMkczMHFqeUcxSzFXUVBoQ0xGSkJHTnNpeFVzQklybjgyX181RFpxODJKSmNkUC1MUWtiVEU9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaZjM3eGM1V2xmdnlmOFBNdVVPYWRtcnhwQ0tqNHhscEtSX2dkY1pWaURGejAwMGNjSjNVQkgtZ1ZyajBfaGg0TWVlMmdyblp6Q2dGZlF1VWdGMTBib1E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaUWkteUFaeElNUmJ0UEVIdF9TQ19mUTcyM1J0a3FNZFE2RzVtUjFCbWNfTlVPM1pra2dTUXFrSnlQMFJvS3FDbjhqcG1kOFNSYmRNclVLdjRIbUxfbEE9PQ==
"Chemistry and biology and naturally non-Euclidean and have been processed as graphs since... well, forever, so GNNs are quite an obvious fit. There is also a lot of information in the graph structure, compared to other domains, where graphs are more or less artificially created. But even in chemistry feature engineering methods (e.g. molecular descriptors, fingerprints) still outperform GNNs for many (or most) applications.",r/machinelearning,Z0FBQUFBQm0yeGNaRmhIeEdabGljdHpSY09QZGVOcXdPTkZiQkZtdWpad3dKNzdVT2lIUi0wS3BaUVprLWdKQjFHNnpYTVN3d29QSXRxS1dqVUlqM253VjhOM1VESWU4YkE9PQ==
"So why invest in gnns? I have seen llms used for protein folding stuff. And you said basic methods do better. Seems to me that gnn requires too much architecture design.

I just dont get the hype of gnns",r/machinelearning,Z0FBQUFBQm0yeGNaMndzRktHUmxXZHRqNFJ6OE1ncW5xbm5jMXhlV2pyMmt0MHhGRGhySmNxWGFQVUplWkpzT0dXRTBXUGl6aS1VcVR5RFVBZmF3eGZGc1FBSGxKdDFoTGI3aUxXcmhkMndxU1kwTzV6T0E2dWs9
"I'm not quite sure what you mean by orchestrator, but the Langchain framework will probably work well in speeding up the dev process.",r/machinelearning,Z0FBQUFBQm0yeGNaOXVuZ2dmU0VMV0YxRDI0Xzl4NXdsSDNiV3M0dmg2bzdDUzJLRmN5WjhaZlA3NGNKMGpvRGxsZzhVY0MwX0FGYTc1VEYyYTE3d1J2M0g5M0Y3UkJaWEE9PQ==
"Just wanted you to know that I was sick and subsequently had to leave my humongous paper till the last minute, and this saved me, thank you so much",r/machinelearning,Z0FBQUFBQm0yeGNaUUxEY1Z3bEk2RllUZ190b3BGMEJIYVBNdU8wUFlGZ1dUMk5yaDdNVmdsaXJ3SU1HT0k3UkhCYk9LQ3dsYktKdy16NWdIQ19wTlR6U1RFSU1Lcm9tV21ReDB2TkVjY211cFVBa1B6YUFMNHM9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaZ29kN2F4TWV2YWstLUNnb2pJT3J1WExxNHBRTnZteGN4ZTNtWTZzbkdLc0NnSkZ4UmM1U3NHX1FDdEtnNThobWRZekxlRVZoVkRYVlUtWjY4Z3V1VVE9PQ==
"Because if you have neural networks, you can have transfer learning, and this is a huge deal. In chemistry, typical datasets can have about 1000 samples, and sometimes can be as low as 300-500. And since the data is naturally graph-based, hence GNNs. Although the pretraining only really started working quite recently, 2020 and later. And using pretrained models is really dead simple, just like with CNNs or transformers.

And also nice things like e.g. interpretability, since gradient tracking is really more reasonable than what you can do for most molecular fingerprints. Continous representations also make more sense generally than discrete ones, which are typically the result of feature engineering.

But text-based models on SMILES representation for molecules, and on FASTA for proteins seem to work great, so we'll see what the future will bring.",r/machinelearning,Z0FBQUFBQm0yeGNaUm9BNDZPMEpCdVpVSU1TbzRZS0c3N2pKS0ZpOXVvVjlrMEotUUlCTkNHWlAwTnpoS05UTkEwV0VvTWhkcWQ5MnhKdWNPUUQ3UkhaWmc5UHVndGZLSHc9PQ==
"Text based as in llms? 

Thanks for all the info. That makes a lot of sense.


I am surprised this field still uses gradient tracking. I have done stuff like that for genetics and it is incredibly noisy. I switched to interpretable layers instead. Gumbel softmax for the win. And there are things like shap too.",r/machinelearning,Z0FBQUFBQm0yeGNad1Ywa0FGWU03U0hZTEJULTBMUWdtOFMzT0VORVVfQlF4X3VkeVRUQXdfWWJ4V1RaRUxFbC1vemRGNnFzMkFTc3ltQmQ0YTUwYXZZMEN4dEYtV1dsdHV3a1hEeW9FbWlGS09sbnJaRWd2dDg9
I found myself feel boring on basic ML like SVM and KNN you have mentioned. Therefore I start working on projects with deep learning and discover a lot of fun from it.,r/machinelearning,Z0FBQUFBQm0yeGNad3Y0UUlQcHJNTWpCMW1tYzdnekpKSDdfaUhIMDVSVnlmRGFSdDBoMFROWEEzY215S21CZ1JkNDZ0MFUyNnJXYjFPemZLSmFpZm5xNFpGcVBIYmRUdEE9PQ==
"I use langchain and it's great, I can do pretty much everything I need and still didn't run into any issues or limitations. However, what I read is that langchain can get pretty complicated to use while llama-index tends to be better and what a lot of people are now using.

I don't think there are other options for now.",r/machinelearning,Z0FBQUFBQm0yeGNaUmZzQkV4NzRnMndEczlzbGZmdXBQUmFJQ3dZd0ZBWFpiVFlCZjNIM3NFTWR5b2U0bFpSQktnaTJDY1NWTlprWU9OeFFLb0lHdWJCRFo4dmI2QlBLeVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaMlNCM0cyaGFQQW03cEU5ckt3M25aVkhyd2FGX3BfY1ZDVlBMZGpreUhabjlBb0I3SEExUFFiZlJYMHhpWTZBOWZMQWdVZ0hBcGpaR01reFJseUdkR1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaNHZHQWxJczllQU1jbE51dENLRWlZcDcwVGtkU3R3REN0NTV6UEtwYXZZTFc4akplc25jd2c3SlNjTEhCdF8wbWNtSm5ldXNkN1N4dENjQ0RHR3RLQ1E9PQ==
"The comment you're responding to seems to be drawing a distinction between runtime and algorithmic complexity

Improving the complexity would be like turning an O(n^2) algorithm into an O(n log n) algorithm. Improving runtime would be like turning something with runtime 0.05 n^2 + 0.1 n + 3 seconds into 0.01 n^2 + 0.05 n + 1 seconds. Notice that both are O(n^2)

So basically, if the new runtime is bounded by a constant multiple of the old runtime, then the time complexity hasn't changed",r/machinelearning,Z0FBQUFBQm0yeGNaYl96cXozUXJFRERodHlEV3ZIYzJYSXk3VDQ4RndTR1pZM25CTTdhR3NVWG1zVkliX2hhekZwNWJKcnJNalljM05nS2lPYm5HOVp5OEtoRnFUUF9ZWEJnYUg2Tm5TTUYxelB5TktnWkJUQmM9
Get into deep learning and do small projects. Read some research papers and try to replicate it in code.,r/machinelearning,Z0FBQUFBQm0yeGNacXBsLS1jOGxzcWU3bXltSWRrSE1FV0pCLUFtRjVWMFppWXo4MkJHdWt6clZYRHNVeUhscVU2WDJyN0t6X19fYW1remV2ZHJNSHNJaEstaVVUOFhQbUE9PQ==
Use llamaindex or haystack..have been using haystack before GenAI era but llamai dex has a good community and rolls out features much faster but not sure how robust they are from production gradr standpoint...,r/machinelearning,Z0FBQUFBQm0yeGNaUlI0OFFfNk9xV1o4c05LWWlPVXVaR0xrWWtDTnR6WE40RkFqMFB5QW1uUzhXRXRPR3pXQmVHcklQR1JVUzdqX0RvYzBZOVY0UzEyeEViRTkxMWt6OGc9PQ==
"I wouldn't call it an ""LLM"", since those are BERT-sized models, e.g. ChemBERTa, MFBERT, MolBERT. They are definitely not particularly chemically sound, but well, they seem to work.

Gradient tracking is just an example, but I had seen quite nice things with it. There are also counterfactual examples (requiring graph generation, which is interesting in itself), graph version of SHAP, and more. [https://arxiv.org/abs/2206.09677](https://arxiv.org/abs/2206.09677) is a nice overview.",r/machinelearning,Z0FBQUFBQm0yeGNaVnU1SUk1SEpXRFk0YVZpYkFwN1dkVGc2MTlOQy1CTU1ybzBpS184RWxEVWtHVHlFRXlKUjFTcU01SlMySkd4RW1LY21mU3J3aFhwaWdxYzMyTzkwYlE9PQ==
Thanks once again!,r/machinelearning,Z0FBQUFBQm0yeGNaWjVkUzdrbXd3Ni1yQ2ZSVFdFaDhzd1piamtwc0diOW15Z2hub1h6V2stRVdKUW5YSHZWdUw1dUdXWDhNV2FpOGxHdVZMa1U5SEx5TC03YV9vbUwtQ0l6RnhXdFotTjhlYUppdnlCUFJNaWs9
"This post is old but now it's my time. Get a MacBook Pro with 24GB of ram, which will be by far better than any RTX laptop (in the similar range) in terms of giving you more VRam to run large models too. I mean I have an 8GB 4060 laptop but even mid size models sometimes do not work on that machine. With that been said. I am really keen to get a MacBook.",r/machinelearning,Z0FBQUFBQm0yeGNaTzdTM1dLWHB0S184QzhEdUt6cjJQNEJhNDE5VDJzNm93WWZweUFabDFES05UQTBaVlFJNnE4WndONDJYdWhBc2hvbU9IU2tQQVRzSWtTeGdWNUJIVWttNUFhUHFOZ2lvaDVEcURVNGpwMUk9
"You cannot really answer this. However, classical statistical learning theory predicts that the estimation test error decays of the order of 1/sqrt(m) where m is the number of samples. So for an error (e.g. accuracy in classification) of 1% you would need ballpark 10000 data points.

This is theory and also there are potentially massive constants involved. Still, it may be a guideline.",r/machinelearning,Z0FBQUFBQm0yeGNaN2NKbmhQdEZjaWlucE9MSG40RG01T0ZSU19qMHhmWjNqaEdaMEs4RXlTbFFMcFRkSnhpMHZNRHNMRU0wS0tLck5fMUZBMV9oaXN2bUNKdC1kdzZsV1E9PQ==
\\*How much data is enough.,r/machinelearning,Z0FBQUFBQm0yeGNaX3R6QW13VW03Ni13ZE54bFVxTTFkd1ZHb2xsUkliRVlkbUNDekhUcUJ3ZUxNaUM4djFwYnlwSzM1MDg0Uy15SmlVazNSS1I0TTF0TUZ1amEtM3k4NXlPOE4zekJyaF9EQk5VUDBrN2hfcWs9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaUXFISXhiaG95VW80cDF0VGFUazJ0ZFhQdHcwUkxqZlpOMEhCcERIREFCT3NJMU12cENVMUJsYWtxd3NsSjBvdXJhakFQbFcxWnQ1Yk4zUWxnT0dEeEE9PQ==
Have you read the rules of this sub?,r/machinelearning,Z0FBQUFBQm0yeGNadTdkQTZ2YldxRU1VSmpQS0hadHBwNEx0NU9YRGlLVlZvbUhaUWZLckpDY3NoRnE0VmlEdnB5LVRrMmlidDk0OUYtT0E3eVU2VWUwajROX0xlR1dlUEE9PQ==
"It really depends on what kind of specifics model you're planning to build - and the number of predictive features - you could build a (gradient boosted) forest with a small number of small trees with 100 - 200 samples, just don't expect good performance. With samples in the hundreds, an expert system would almost certainly outperform. If not possible, linear regression would be my first port of call. 

The golden rule in ML is more data is always better.",r/machinelearning,Z0FBQUFBQm0yeGNaY3IwcEc2am1ybi15Q2c0YnlhOGRfVVhHSVpLYTFiRkVOamJiMllGeVF2SElCN1JlY3ktUUJsQXFrM1BETTNCN3l3bkpDa3Q2Ukh5dU5LWHpua0VqUWc9PQ==
"Hello, it shows me 404. What happened? Did you lost interest in the project or was shutdown? :)",r/machinelearning,Z0FBQUFBQm0yeGNaZTRaUldZT09fT1ZyR0pwY1FsMHFXS2NSOFhoQzd5bl9scS1hSkphZkI5UWpRX3Y0a09MV1JjT0RoUExadFkyTFlGVzhxNm5nVEUzRUdNdFFxempvX3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaZ3NkX2s1Umt2a0R1bk1USzBwaWg4QU1Xc3pRV2hldjlFbnlqVWhQVWYyNVU4MmlMUEVCVUdPa3puTGtXZkMxOXBha2owSzNoTHBvZmIyZjlIaVZlWGc9PQ==
"I also work with medical data so I am very familiar with the problem. Getting more data can be extremely expensive. I don't think there is a way to give a definite answer, but here is what I do when asked this question:

I artificially limit the number of samples during training and evaluate on a fixed set using whatever metric is useful for the task. Then, it continue to include more and more of the available samples and I look at the how the performance changes between the training runs. You can do cross-validation for each of the runs to improve your measurements for each data point. Make a plot and extrapolate the results. It usually gives you a rough indication when you will hit a plateau.

Obviously that is not a definitive answer. It is model-specific and you already need enough data to get at least meaningful results. Usually management wants to know before they start the project. But in that case I can just guess.",r/machinelearning,Z0FBQUFBQm0yeGNad21HeXp4eFd0bEdxR2V2ZnRVS1BqcmNpYU9aME1tVUVJUzI3aXBWaWlGOTVnT1F2Tk03YlpKOEtSS3dmS3hjY1Y3QlFDUUhVenFzVmYtSVdOS082OTRVWXhhS0dHZkZDNmdqNng4ODR4alE9
"You can look at it a bit more empirically. Let's say you have 200 data samples. Split in 40 test samples and 160 training samples.

Now you train many models on a training set with increasing number of samples and note down the final error/loss on the training and test set. You can plot this and see how the error/loss changes with increasing number of samples.

With above example you could run 160 trainings, with 1, 2, ... 160 sample sized training set (at lower numbers you can also average over k-folds). The test set stays at 40 at all times. It should look something like this sketch [1]. The plotted value is the final error/loss after each training is complete. For # of samples = 1 the training error is very low as the model overfits, and the test set error is very high. As you increase the number of samples, the training error increases and the test error decreases. At some point the test error sort of upper bounds the training error. For # samples -> inf the test error should converge to the same value as the training error-ish.

Depending on where in this curve you are you can decide how much more data you need. If you are at the beginning of the blue curve, you need more data. If you are at the end of the blue curve, there are diminishing returns.

[1] https://postimg.cc/9RB1thHH

Edit: Similar to PassionatePossums answer",r/machinelearning,Z0FBQUFBQm0yeGNaWXREVkRZeVlSQktSQVVnZER2X3NSX0lVN2VNZ3JIdDVOeEFQV21tdGIwc3pIdzJxN2lCc0hyVXNtNEdzeFFjS2hqVDVCcFF2ZVE0ZGR3TklEenVaaEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaUWpyT2hZSG9VekExVkFZczZmY1J4LXp5Z0U3ZFp4Y21VVDFuZDRBRU1nWG5lQ0RWTXhqS3owUy14V2ZIdmREd29oa0hSQWNBOE9oTEZ4aEVOS2d0SVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaV3RGR1U1b0NGc093b0NTRkNCTEdJZUM2YU1uLXBlQTY4bEVUR0E2azZ0VDl5RVM3TkxjT09mbVpiMkI1RzIybGVyd2xFUjJNUFV0LWpYeTFiN1FrZUE9PQ==
Do you have access to publicly available datasets that are similar to yours? or from previous projects? You could plot a learning curve and then forecast how much data you may need for the new project. More complex tasks would require more data.,r/machinelearning,Z0FBQUFBQm0yeGNaa3pWWmgtblR1ajhueXpWNmhqTDFiSXdCejdyOWNUaURieEY0UHJXc3ROUi1YdG9yQW9qbHR5YmhVOHhsOFI1RllYVWt1ZUdBVXpPRG5Mb0k0dXlKQ2c9PQ==
Unfortunately I had about 7/8 users at peak and couldn't justify spending money on the server,r/machinelearning,Z0FBQUFBQm0yeGNaVmpMemkwd1FHUEFiNjFtaW0wb3hOTGQ3T29BM3NMbUFwekZDQl9Pb2dKUklyNVZ1bzAzb29iRGJFTXdUWGJJMXRqTzcxUzI3WXpxTUpjaVlQTW91R0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaeDNYWERBdFhTaWphMlFsSkcxREZBZ01qQVFhSC1kTGR5VFpHNDdwdVNsYkI0U0M4bktTblctRjNTT2toZ2ZPQkt3dEdsdmxobWgyWjdhSUVxWE9yeXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaU2dNTjRMTUl0U00xVjRYbEEtTG1lNlJyLW1jX1hWQm5ScWV4ZERQbDhpOFY3NXhfSEN2Y2VuSVBnX3JrZEQxTnNiTk0yRi1SUDNyVDRxZ2tCX0ladXc9PQ==
"Thanks for your kind words :) just please note that we use up to 5 levels of decomp at some stages of the network :)

It can be interesting to find a way to use it efficiently in MAE, we haven't tried that",r/machinelearning,Z0FBQUFBQm0yeGNaUF9TTGo0V1B2b3J2OUozTjBRcVh5Y3FGZFQzYVlWMy0tXzMxM3pVNUhtSF9JcTYzQU5LaE43aUtaNVRpbWp5Rk1UZWxZV21IVmJaNnE3ejIxU0VfTlE9PQ==
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNaaW1RbnhpTGV0ejdYYjF2OWN3LVdQdDJxX1Y5VTdfQ2ZKOVMwQzd5ZjJSYTdnTVM0SmtHQUpsWnNJU2V4cmtOODRnS0hKNXREakZ3ZDhfeWdEZ3l6MUVMUmp1VnUxUXd6a3hXVkx2dXZJNzg9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNaMUhVRnBiUGlLUHlDeFY4bThDTkxGT2JEWnNCRWFSMVMzNkZhamdzRnRmLXVUNHZqT0hJamRpOEl4ekV0TnJXNjdSQlNLUVg2eWcxQlBka0plcmZ6WTg4TWt4am1NZHdadnNLTmlqU1RvTkk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaUF9JR0lSSHIxXy1WZG10ZllaVVN4SnNfQWhZUGQ2ZW1LTlhQTEhnVk5PWXFILXZ6WmI3V0lqWGtoSmtzeGhzS2Fma3pKMm1HOUtSNE1nanMtMGZ1LUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaanJGYlYzN1p4cTVSUEJrZHBDQl9zVjlralQ4VXdIMW1qVVRKZWxUTlBwdF9kNnVvYUwxR3kyaEF2RE9RQ1c5QUE2aTdkc2Rnd3o3cHhJTG5vSndFdXc9PQ==
"Something that takes ""a couple of weeks"" is absolutely insane for a take home project though, unless you're paying for this time.",r/machinelearning,Z0FBQUFBQm0yeGNaVXZKTFZPVFF3UjVvTGhWdVBfSkdpM1hPN3AzUWp6aGIwNGI4V2VteVpVMml3emNtaV94UWhJUnZySFdQSjNXa3dXejN6cnVMQ3JFV0N0anh4bEx1dUlYa1ZOUHlTRFZWM3pYQ0UxT0ZLaW89
A Python script,r/machinelearning,Z0FBQUFBQm0yeGNaRUJGSkNqM0ZLZTE0aVY4OER1RDluNzF4RDhLbjM3UTJDMFNkRjh0eHVhdUtLQ0htNTBMbVZJSUYwUmRzMDEwUkxVY0p3dzlJelk5SEFqUjJkZDNxd2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaTm5IcFdRMlFmV0JULVZnMFVpNXJMNW56d1l6aVhheFBsWmVZVUlxdXl0bDUzT0ZyVjk4dmxnNHdROW5xOTRITGFKeXF1MThzdy0xSjBtVHIyUFFMUHc9PQ==
"Minor note: I think it should be `softmax(mask(QK))V` ; otherwise, the (denominator of the) softmax will be influenced by ""future"" tokens that haven't been masked yet.",r/machinelearning,Z0FBQUFBQm0yeGNacmFjOGNDV05pX0htcWhlT05FMkhwUVdNaG41M0pIT1M5d0stVVZkbWY4VjRuUXJtUGpvQmFjSVFRUUZwSjFSN3U0Sm8yVGFwb1FFeHBaeTQzM0VwbGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaTVdaV3JhMWIyRzVZV3A4bkZ5bERQOHN1VG9oMUFNLU9hbFB3NGdDbG5VeTk2WmhUc1ZSRWI5ajF4U0hmQk5GVEMtZFpMTUFPZ2k1NXJnWXphVHNxZmc9PQ==
By coincidence I just saw your yt video today. Nice research and video,r/machinelearning,Z0FBQUFBQm0yeGNaOHRqdVFDd080WG94VDAtZ1dCa2Y0bHNBWGZfR25CdmY2ekN0cmlCR0dUY0ViYUc2UGphZTBJM2lJblhtNzRGZi1TVXdtaG4tbVJfTHhkOTNRQVk3T0E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNadThJQ1pFNnIybHlMdUhDV3kxREpSdHlIUXFaVThQeUJreWExNU1MT3VVTXpsdC1DaURxYWhRbTQ1Y2JGTGpxeW1uc3pjbmVhR3hMTFY3bzBtNGdObFE9PQ==
"Llama3 is quite decent for both, but it really depends how you retrieve data from graph. Basically any query language generation approach will most likely not work. That limits your retrieval operations, but you get more qccuracy and robustness in return",r/machinelearning,Z0FBQUFBQm0yeGNaSHJONjh1Tmx4Y1NnSGxzOW9YWkhRNS1tUnJ4ako0RUhKOEpMMUJLcmE0dDhWUEY1dlBCR1dhSVpFVW1GZi1TMGUtQUJWTkh3QVEtN0Nxd0lyTXNiUVJQaXAwQ2VnSUNuTHZvS05VZnU0cmM9
"I would be interested too...

I would love to know what this is all about...",r/machinelearning,Z0FBQUFBQm0yeGNaNGFVQldaM093Z3FnblEtRWZIM3BzTXJtVURqVDd6MmV6TDc2QWFzVE5PWlI1bXJZOUJaMVdxUUVVeV90V0NqOWRuZkxLbFktdWZhQXM5dGVidjRxTEE9PQ==
"Can I ask why you decided to use MongoDB?

(It was also one of my top choises)

I would love to explore the reasoning behind it...",r/machinelearning,Z0FBQUFBQm0yeGNaZ0JpejR3QUF3d3h4NUdBNE1iQ01RMlphRWVBcFh4X0dOUjl4OEE5QVZxYzJHOEhZdnFJc0VsdVVOdEhkbXBNdzFQa0FVcGZTMTFDa0x2MnNqMzdhRGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaYzBubXFJcy1ObG5IdldWelFETE1NaEJ4MXM0b2V3NlI2VExhQ1RhY1pGVlRjNUI1VGlGbTBlME5FZS14YTl6MGo0aHdnWHBxUHFucTl0VWZWb0xUUWc9PQ==
"Do you mean something like this?

https://posgnu.github.io/rci-web/

It shows LLMs interacting with a GUI",r/machinelearning,Z0FBQUFBQm0yeGNad3NzczdlQjZRRUpCaUFpVHJrekZDdFJpcWxsR3IxNTNiWDJ1NHVVeGJKODFyMEtvWTdSVkJZSFZZeWpvVl9LYkgxNTE5MkhMRTVCbDh5TXk3RE9vWUE9PQ==
"Yes couple of weeks is pretty ridiculous. It shouldn't take more than a few days. The float8 problem the interviewer when he told me about it, he said that the CEO of the startup apparently solved it on one 8-hour flight. It took me a few days. 

A few weeks is definitely too long.",r/machinelearning,Z0FBQUFBQm0yeGNaM0pQV3BDUHdiVEYybUgzS2Z2YmtScVA2S0NNS2NOTlVCR3EwWDlCWGdKN3BabmhuOUhYX21KTVEtX3dXM3NjaTNyRGZJMTh5TzdFcWRQZG8zWks0b0lnb1MyYkVkRmJlWWVCLUhwLTNLSHM9
"> a connection between discrete latent spaces in your work and error-correcting codes

I had the same intuition. The quantization stage could be analogous to an analog-to-digital step which suppresses noise and reduces the accumulation of error. The continuous version of this would be something like a Hopfield net which has continuous representations but a discrete set of attractor basins (and ends up [looking a whole lot like transformers](https://arxiv.org/abs/2008.02217)).",r/machinelearning,Z0FBQUFBQm0yeGNaTDgzcGdONHhaLWhIeUdTeDZrSVg2UmFCZjRNQTVTY3VsVG1LR2dSc2ZEUDhjSm5ZeEF0U21fdmVFV196V1hNNGNRSTQtSzBzRHZNT1pqeGpyTWZrSlE9PQ==
"Check this out https://github.com/OSU-NLP-Group/HippoRAG

And GraphRAG but it requires extra efforts",r/machinelearning,Z0FBQUFBQm0yeGNaVVdXUnlhSGkxc1ZJeTFiUHNZRkFDMkhmYVJsTEpxak5OVzIzU19NdzJXZF9HTzkwZXlXZjhBVUlEcmtSc3NTSFFWNHVNa3BBYmJ4YjBLOE5TWDVwQUN2MUNJbE9MZDhfbWg4Y29wSDZKNFU9
Any suggestions for free and open sourced ones? I have classified docs to work with.,r/machinelearning,Z0FBQUFBQm0yeGNaN3drZTRGYzlSN3lGUXVqdy02c2ZBazF5RlNPeTVoank1TlAtNnBmeU4tSVJzei04UmhkZjF5UUxjaEVuWjF6cHlURThjc2ZpdXNVYUVmRDgyR0F2THc9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaeEsySExiUlpnNXl6dEhiX2VDSjNaY2V4RWZOOFZVWGdiX29DV1UxSWQwWkRRUEtyNmstU2dwWTVZMjViNENSWklGcjZVcklaOEZpbl9pOFBJdjBPVmc9PQ==
"I'm working in an app that will require using computer vision, ocr and nlp models.
I'm trying several approaches, included quantized models running on device.
If you're interested I can help you finding a similar use case",r/machinelearning,Z0FBQUFBQm0yeGNaZkZ2MDNHREc0ZXB1ZjhMUG5pXy1RSlhpSHFsNVMtYW9IY21FUjlESDNVM0RTdGk5VEZMeGFUcV9ZSGMzd28zQXUzMzl3MmQ4VWtmMDFRLWloWjFOQ3c9PQ==
I use gpts plug-in like scholar ai to read papers and summarize key points for me,r/machinelearning,Z0FBQUFBQm0yeGNaZUxQZnJEWWc0SE90R1Q3RjJiWTFUcnVLRnVXSm1ZSk1xbllKUjRHVkZFRThKY2xWTDJFSjhpNVNoaHh3WlYteFgyc1lCT3R3bWJJTW41a00tbmdBWWo1Y3Z4Y19vVzJxMWRGNmt4VFg2OGc9
"I use langchain extensively too. Should be easy to get started, very well documented and have lots of examples. Here's a simple guide for RAG: [https://python.langchain.com/v0.2/docs/tutorials/rag/](https://python.langchain.com/v0.2/docs/tutorials/rag/) and more examples at [https://github.com/langchain-ai/langchain/tree/master/cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook).  
The community is very active and lots of new development.",r/machinelearning,Z0FBQUFBQm0yeGNaYmJ0V1ItRzhuMHY5cUdNMW0zM2JYVDJtRDNxNnpQYktUWmRXOF9yNEIzSWtjenFSS3NEd1RmZXF2TTM5cmtLODJfTzIxQ3g2UkZ2UU9iQUE2RXBCVFE9PQ==
"How do you want to create the knowledge graph?  
Do you have a set of fixed questions and then want the LLM to extract the answers and find the relationships?  
Or are you planning to mine the unstructured data for the relationships/entities?

In terms of LLMs, i dont know how big your corpus is, so how many entries, and what document size you're dealing with.  
If you're working on a POC and dont have the infra setup already, i would recommend using an online LLM like chatgpt 4-o in batch mode, its json response is really good and the context window is very large.

However, if you're ready for moving to production and need to care about the scaling costs you should run your own LLMs for extracting the knowledge graph. it depends on the compute you have available to you, but the PHI3 models are really good at reasoning for their size, and have big (128k) context window, but be mindfull of the GPU ram. These smaller LLM can be really accurate if you finetune them correctly.  
I would probably still recommend a larger LLM for generating the queries though, or create a big golden set and then finetune.",r/machinelearning,Z0FBQUFBQm0yeGNaNmU0ZTJ4M2Zqc2h3NUo1T2hQSkl5ekR4akJsa0otUUxyNzBxRVNtRjd2ZzQ5aHp3UW5nREVuZC1VRk82dG5YbVI3LS1UZHo1TndJMFpzbmNlUlJza1E9PQ==
"It's linear regression using the embeddings as X.  The OLS coefficients are the new weights of the last layer.

Just code it yourself.  

Loop over the dataset to compute X.  Regress against Y.  Dump coefficients into the model.",r/machinelearning,Z0FBQUFBQm0yeGNaUE5ScGVOWFM2ZFpnY3R3T2I0cFhVcmV0eV9WcnFnazhnakFUNVdTRWVmOHZhMHBjaFp6NjF5QzhYckU5RWQxX21QR1hEVmFRa1k5M0FiZllkT0l3a3c9PQ==
"From my experience, I could get BERT to give me good results for Hindi and Bengali after finetuning. Did it not work for you?",r/machinelearning,Z0FBQUFBQm0yeGNaOEZ6c3hLT1VSY1NQNEZtdGdKRzBKalBXNGJWZ0tQQTJ6bmJ2Z2FHeVNSdDR5bDE3SXJBdnNZZlFjU3hZbzd1Yi01cnNsTmw2SGZ2eEpvN1k2WGRYdVE9PQ==
What dataset did you use to fine tune the model. I tried with base uncased model and the problem I faced was it divides some words into subwords along with # which results in wrong output,r/machinelearning,Z0FBQUFBQm0yeGNaSk1XcVpvUG5oOFczalREQUlRWlBCaXF4Wm5tU3J4TnVnTURYMzdDeVFKcDJ1ZTVGampwUTBtbk5VSloxeF9MeXZMYnBzQmk3T3hhNHR5bW0xY3gxcjNVU2otNGpEMDNDdmlzN3dOcWJRRVk9
"> “Monoliths are, by nature, strongly coupled systems in which each entity is heavily dependent on the functioning of other entities and cannot be independently accessed or scaled. ”

This is not strictly true. Monoliths can have submodules that are strictly tested independently. Additionally, while they can be deployed as one piece, one can deploy subsets of the service differently across many machines (eg routing, celery tasks, etc). Additionally, monoliths allow for having complete and compatible code that one can easily run without much overhead, where microservices often are plagued with mismatching versions and poorly-styled code that teams fail to navigate",r/machinelearning,Z0FBQUFBQm0yeGNaWXVwWjRGaXZXclJRVzM1bk5VWDVoNXVtQUpMSTZFQmN5LUNJcTU0N2llVW1NOTFRZlZyUTJ0Y0xaWUtjbUpKa2FPa0RkS1FVdUhxN01hTEZtcmFSaEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaVThUdllhQWhVRGFpYVJTOHAzWFpRZ0xZXzQxTmFkVDlSdnJudExqb1VneGZpTWVZRng1RjJ4QWdxRmc1eUV1R0FnZTV1VlBiSU9Feml2YlNXYkxDVkE9PQ==
"This... Write your own.


> i plan on using MongoDB for the vector db to keep things simple.


Make a poll and ask how many developers think this is a good idea, before you get started. ",r/machinelearning,Z0FBQUFBQm0yeGNaZXJkUzlFb3hYNFB4WlIzNGtxbC1MX0ZwSWdZRjRRQVJVdDg3V2xUSGVVcHFKczdKUTIzbjRnR0dpamM5WEFSUmQzQXhidTJmelZVZnFnOFF0aGQ1RXc9PQ==
"The Meta open source ""seamless"" project is a pretty great little ecosystem of ASR and STT. They focus on including translation. Whisper seems to be one of their core dependencies.",r/machinelearning,Z0FBQUFBQm0yeGNaY2ptenUzQ1FGdkNPbmJRbkN4Y2hKNmkwelYzU2Y2RjVDdjN6T25PMklxWDhvTkhaWlZPQ2hMVTBQdlFnWEtSdG93QnVQSlRfSGotV1BBOFNGd05WUWE3TDZRbjJ3dEUzNnFuU3FKTXI2QXM9
Reply to add. Their examples are often speech to text to translated text to speech but they make it easy to mix and match so you can do whatever you want,r/machinelearning,Z0FBQUFBQm0yeGNabVNDeW5NQ2pCQ3Itamdia0Z4dmw3OEU1em9jMk9nNk1CcmJRWXE2SDB1V3Q0TERXQWNuVnBEZThOUFc4Vl9PaHAwR0M1YlhrUVdpUVhtblN6TmoxR29SWVZDa0hpWFI4SkJldWZGNTZvVWs9
"Don't use MongoDB as a vectordb. There are much better options like ChromDB and Qdrant. If you are familiar with sql databases, you can use [https://github.com/asg017/sqlite-vec](https://github.com/asg017/sqlite-vec)",r/machinelearning,Z0FBQUFBQm0yeGNaWWl1SWhxTzFTZnQ0c014Y1lfbmU2bHB5UmlvdGdlYU41ZFZZb1c5bFR1Qk9SeGZuR0VERnlTdlNReVZUbW1mMjg0UGlZSkFBOFdvTzFaN1pnQW5Ybmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaeTZ4U2IwaXRUbTVXaGFNcFBIYTV4N1EyUUwwbS1Mck9xZjBpYklKRzlpNjkyMEFuWGdLWWlrNXp6cG5Cc2NNTEpTalVobUw3S1ZSeXJQRW9zMnZzUnc9PQ==
Suggestions for vector db or orchestrator?,r/machinelearning,Z0FBQUFBQm0yeGNaa2dxb0djSzRYS01CT3cxZ2MyYkRBd2xNU0NLbF9DY2pvQVhtWkRtOXNwcDZpeGQtV2xXOU1LOVdBQUpYNEJzMFVtZlVpU3luUUVPRjc1NjVNbi05Ymc9PQ==
Hm. Maybe I should publish my findings then cause I get my things working usually….,r/machinelearning,Z0FBQUFBQm0yeGNaSlBmazdUWmY1RE02UGN0NVBsT3FlamZiNjNGRThsTjFnTHNHOEhmcS1FSnJwME85dUs3Q3NZbkROTFQtSGc4MEVlRmJYblpoUXJycldtNXVfQjh4clZqamdUdURsa2tEeDU1WU9uc0FiMm89
"Self promotion without being a bot

Comments and posts should be first and foremost about topics of interest to ML observers and practitioners. Limited self-promotion is tolerated, but the sub is not here as merely a source for free advertisement. Such posts will be removed at the discretion of the mods.",r/machinelearning,Z0FBQUFBQm0yeGNaM0k1X0toVDhzTC04THpwRVlHNkl2SVJNU2t5TXRTSDlndUM4RDIzY3VTZEpPZWl2bWZ5VWp2YmhJUHdVYWxaVHMtcmtVaWdnN01sMHhsd3MxMnVTVWlZdDRlTWxpMFF5Q0h4bTMxSFYzNXc9
I always used to be made fun of on here for saying these things.,r/machinelearning,Z0FBQUFBQm0yeGNaVDJ5cHNkYUc3Mmg5X1ZpUzl6eHhSZVJQemttYTM3MWh1N3dlTTdiVkJuVk9xNU1zYU1iSW1sLXNScnV3WHVPb0JpNENCRTlYTXVnMTg2WG9oWno0cEE9PQ==
"I think OP was assuming that -- but asking which python libraries are helpful.

I kinda like [AutoGen](https://www.microsoft.com/en-us/research/project/autogen/) for coding applications.

Couldn't find a good fit for fiction writing, though - so am writing my own.",r/machinelearning,Z0FBQUFBQm0yeGNaUEo0dnBjbmozSWdMa2tXWl90SjZvUnVlTTllZGd1OUM5OEY5Wmk5WDZ2YUVIdDd0dlgtVFRTTGxDZGhFTkVGX0VKMkstVEpxdXBRNUU4X1NfdVJLbTBRTGtOaDVBOTFjeWtlS3Axb21MclU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNaajc0eFR5Ung1ckkxYk9rcGUzMEhDcUt4NVNiS2tCaUNzNzI2LWlzcUdTSkJMUDF1Wk1sS21pQm9jX29IVThxVTVZdHhNbVFHMzBUVjZESm5oV001OHc9PQ==
"If the decoder takes in one latent vector as input and image as output, how the transformer able to use multiple codebook vectors (the sequence)? How the forward process works?",r/machinelearning,Z0FBQUFBQm0yeGNaRzBvVGR5d3pacHotMDBtbEpybmtvVE9rRnNPd2ZpY2hOQkx1dy1IR2x5MUR4bFEtdFlpUVFUdGxOZlFSTFc0N2VXemdwOEM0V3EtUFlqZTI4SXhZWlE9PQ==
"The Decoder Takes in a grid of codebook entries. The encoder transforms the input into a sequence of vectors coming from the codebook. This sequences is typically laid out in a 2d grid fashion, like 8x8. The Decoder Takes that grid and outputs an image. The generative transformer operates in this space of 8x8 sequences.",r/machinelearning,Z0FBQUFBQm0yeGNaeWhBdjJ4RlNUcnpLQW1BWWhZcDhqNTA4VTFSXzM0eV9ycUZTZzBYejFnUDFYVXBMU0o2Tm5RQzBHWjZIYW52R3FsXzY1c3IteXNPNy1uRXp4ZWlaLVE9PQ==
"You might want to look at the [Langroid](https://github.com/langroid/langroid) multi-agent LLM framework, from ex-CMU/UW-Madison researchers. We have exactly this type of hierarchical agent delegation. You can specify the number of ""turns"" in any loop. See the docs on  [task delegation](https://langroid.github.io/langroid/quick-start/multi-agent-task-delegation/), and an example of a [tree-structured computation](https://langroid.github.io/langroid/examples/agent-tree/)

I don't have your exact example but there are numerous multi-agent example workflows you can draw inspiration from [here](https://github.com/langroid/langroid/tree/main/examples)",r/machinelearning,Z0FBQUFBQm0yeGNaQmNRSzRXWkhqaXVpV0F0TlZFTFpMbVlqNUxuT25oRC1NLXFhWDhocE5qalp2LWw2UkUxOUxoMEs3c0E0ZHJNRmtJaW41Zm8yOU1uYTlSVDZPUDJrTFE9PQ==
"Have a look at Langroid's transparent, extensible RAG implementation, which I wrote about last week here: [https://www.reddit.com/r/LocalLLaMA/comments/1e033xj/comment/lcnu3da/](https://www.reddit.com/r/LocalLLaMA/comments/1e033xj/comment/lcnu3da/)

For vector-db, we don't have MongoDB but have Qdrant, Chroma, Lance.",r/machinelearning,Z0FBQUFBQm0yeGNaa3hCeTNsRWZPWWIxMFIyZkxxcFZHWmdGejhoczBCVU9wLTlVaWFnRXQ0a1BVVUxNWl9PeXUtUUpGdFphTXJURHpuS3AyV0Y5YTBmY1V0M04xZW52UUE9PQ==
"For a production ready RAG application for enterprises, I suggest avoiding frameworks like langchain etc. But for a small scale POC or pet project llamaindex or haystack can also help speed up things.
For vector DB, again for small scale PoC consider chroma DB or FAISS. But for proper large scale system consider full scale vector DB like Milvus, Qdrant etc. You can consider pgSQL too, but only with vector DB extensions that have come up which are quite fast like the full scale vector DBs.
Consider Graphrag if you think that would help your use case. 
If you would need ready made solution, vectara also could be a good option, but not free. Then again there are few other RAG as a service solutions as well.",r/machinelearning,Z0FBQUFBQm0yeGNaTVVSb3lzWEtOSmExSmp3X2plb1AtLWlrT0RERlBTalhsVHM1aEhlTjYyTmVjYWIxRC1MTGVuR2lFdHhXTnJkOWlfcWk3MDM0N0pobnJoMlljU0VFaVE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhSzBISGRSMVlMLWd1YXBEWGx6eTcxN2ljeFA5Q3RWTUFrMTJzZlBjTmEtWEd5TVdxOTJCMFN6dTBrb0M5ek9abnFWMXg4clE4ejRkNDNrb3c4WXVhT2c9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhX19LSnZfN2FiNFZ5MGZxRThsRmd3QmZsaHY1cGlRcXlvdGxyRkNkY0E3ejVYTWkyUEV4SWZEV2hLeXVUQk1WUmJzTzU1OEF6UDBsb09ZOU5LSkR3Rmc9PQ==
"All else being equal, in person is better. On the other hand, all else is not equal. Leaving your job might be a terrible idea. If you want to work in the US (do you?), Austin might be better than Leuven.

I don't think either program would guarantee you a transition to ML Research Engineer.",r/machinelearning,Z0FBQUFBQm0yeGNhMkVIT2lCdlBBR3FudnNfYnQ4dkx2TVpiUHFtV3ktWFc0NmFmSW1DMUw1TDRTOXFhMElfZmluOXJTcDhPeXkxZ09SY05uWWxXdG44REczQ2lqeW1QMVE9PQ==
"I love how more and more even respected scientists take the path of „AI influencers”. My five cents:
1. What even is AGI? I’m yet to see any concrete definition beyond „a smart/human-like model”
2. On the threat: sandboxing exists. That’s like comp security 101
3. Not much on the topic, but (as far as I’m aware) we haven’t had any major *scientific* breakthrough in ML since the beginning of the whole thing. Most of the progress now comes from more powerful hardware and calculation optimization, but not anything fundamentally new",r/machinelearning,Z0FBQUFBQm0yeGNhQURWbVI0UlZhWGxvM1NpNHNKT0RodWNNR1RVYzRSZm11c2FBS3Q0ZHM2VFoxeDM2SVlhZVRaazgyU1ZvRTZnZWFDS052eVQyQ2FsSllWdFhyTFE3Tmc9PQ==
"Can't take all this AI safety that seriously when it's always about AGI and ASI in what feels like a deliberate effort to distract from the infinitely more likely economic and political disruptions that currently available AI can easily effect

AGI and ASI ""concerns"" always sound like hubris and marketing thinly veiled as warning.

I'm much more concerned about a world filled with highly plausible sounding hallucinations that suit any particular person's view of the world than I am about AI running away as some super race

Reminds me of Elon Musk trying to solve living on Mars when we can't solve our own climate. These people are up their own asses",r/machinelearning,Z0FBQUFBQm0yeGNhMGhYUEpPMXdwWlBuQWoxOGcwX25WQXhLTjhKN0YyLUJjTl9HU2J2SEdaNDlwb3hUaGRWdnRqSEljU2JHeW5IT2hOaTMwUkd2VVF0ZlFXby1aNGFJYUE9PQ==
Also is ASI just a new acronym that became necessary because AGI had the goal posts moved as far as the goal posts moved on logistic regression from basic statistics to machine learning to artificial intelligence?,r/machinelearning,Z0FBQUFBQm0yeGNhZkFOVHFvVVpDaGl4ZjlLcXZwc3BwdGRUcUtjdl9SVFZtbnkyRzJJa3pSMm9PQ2VIWFFOUFdPbmpFOFJtRGVBMFJBZXNQNkpBZlVEcHk5cktnQ3pHUVE9PQ==
Because you're not one of the godfathers of ai,r/machinelearning,Z0FBQUFBQm0yeGNhZ1NjcUhLZEJtRGxNOUU2bmZNWGN0ejRJdmtEVWN6N1VvV01WdDNwR1NzWFg2QzZKV1lwLTZSSXRlNjRMYkhmQS1LeFhMek54aDVMUWRnVDdrdjk2c3c9PQ==
"Please explain why university professors (several of them!) would engage in ""a deliberate effort to distract from the infinitely more likely economic and political disruptions that currently available AI can easily effect"".",r/machinelearning,Z0FBQUFBQm0yeGNhTnRiV0dsVFpnSlpnRXc3UkVTekRXZzFDVGlISFpDQnIxZEJhU2hlcmtYYi11ZTlfeEpEcFp4dV9tc0NVYjI4bUkxNDVDcGNMOVNZYlQ3a09FXzZBLUhCblF3N1p2dmVJdnlsMTZEOHo5VUk9
"These people became the godfathers of AI because they believe in AI and invested in building it when people were deeply sceptical. After people like that laid the groundwork for a more practical, pragmatic, profitable industry, tons of people who do not actually believe in the possibility of true AI flooded in and filled in the Machine Learning space. Now these ""pragmatic"" late arrivers consider those who agree with the luminaries on the possibility of true AI as crackpots. And of course such a concept will inevitably attract crackpots.",r/machinelearning,Z0FBQUFBQm0yeGNhSjRIN01Zb1pHcms5UXZJM1hfbFRySEVtR0lpYlY4TlJPRU82aWN6YzE2aERPOUw5MzFXd1ZhYTFpemJVVl9NNjZZTDdjZHdFblpUWVQxczVrOUg1X3NlYkR3R1JsX0ZoVW9YeURUb2RwZnM9
"Post beginner questions in the bi-weekly ""Simple Questions Thread"", /r/LearnMachineLearning , /r/MLQuestions http://stackoverflow.com/ and career questions in /r/cscareerquestions/",r/machinelearning,Z0FBQUFBQm0yeGNhQUh0YVhjRFBDNnY1Z1pEZnNNSWRPLWpUZ1lHMHR3bzh0c0xjN08tWU9uTk94azVwZ1IyeDNJOTIzSDBHQnlPb0h1MkZ1cHNNX3ozdWJBVzVUb3FmcWVadk95V1YtbTZ3N0VpLW9GdkFDd1E9
"You don't consider transformer models to be a scientific breakthrough? Or multimodal?  I mean, if not that, then what counts for you?",r/machinelearning,Z0FBQUFBQm0yeGNhdm5HZk9iZUtMWDVJUEFJMkotQVlBN0UzUXNyQnc4Yks3U3lwaWp1ZzdQdi1ueUItZ1BMMmxPeTl0Mkxtai1EVjdqN2ZJaGVvQW0wdmFaQ0FrWXlpdkE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhT0s0cTNTOW9IVk02Skp5aUNiWUdIR1d2Si1INnczOFZqb3ZzZkY4TlVFZHJBTGNwTTFUUXlFNXczRTdfS1BSdTFlenRJTzQtUTdVM1ptZnJJb3JmT0E9PQ==
Sounds like something \\[graphrag\\](https://github.com/microsoft/graphrag) would do,r/machinelearning,Z0FBQUFBQm0yeGNhSmJBVGg2ckE2dDhVclpXbENiSzJMS1BKbzNxWlJjTWZFZmlVQlNqaXRydFJka19ael9rbEJ3ZFM3TW81YTRrQnprTnA1VFpQQ1pXdThfSkx2SDF6ZkE9PQ==
"Do the ""safety experts"" even have actual solutions aside from gatekeeping AI to only megacorporations, or absurd ideas like ""a license and background checks to use GPU compute""?",r/machinelearning,Z0FBQUFBQm0yeGNhUWVsYWhlSFhQM29URThPRUV0LUh6R3dfbEJ1TjJOZlhkTFpjVFduc3o1WlE5MmRZX2VZNDE2NF9pSF9Pbm41RjBmU0FFbTR4dEhQN3ZINDlydDBaT2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhTnM1bXQ4b2FwRFBJODNzVmliV0o2U0NsOGs3N0p0bnpadFlsTUpuNU5QbGh3Wi1adGVTUUtwWVV4OHJnTnd1cU9QLVpaSEpsbE1UUFlabVloMTVsMUE9PQ==
Sandboxing works for the model you train. It doesn’t work for the model I train if I don’t sandbox it. How does sandboxing help in any way?,r/machinelearning,Z0FBQUFBQm0yeGNhZ2o5NXZvWERzd2pNWHl0U1pFeEtSX2VvQzZmVDJIYU9RR29Sbml4Z2ZKcUZCUzN3ZHRNSWVIQXBrUWJ4ZUdVTXRsaVF4eWlfNHpsSjdhekNxdzRNR0lWbm92Q2owZXY3TWhsX1NiLTJ1Njg9
"> what counts to you

Frankly, I won't know until I see it. But if I had to speculate a little - something cardinally different from just a fancy statistical model. As most of the community usually refers to chatbots as the first step to the A(whatever)I, even an advanced self-supervision model would be a step in the right direction. So far, I don't see it going much further from deliberately mimicking statistically average people with the current framework",r/machinelearning,Z0FBQUFBQm0yeGNhRWF1elhzSkpmWDFQS1ZPNHNjc2ozSkYtWktJdEV2RDByRm9qUmFoRVFVSHNSYkt2LXZHWlFoYmY2NFFZNU0zWDl3bGpKcnV3VW9aX2tWbTgzR3VKMXc9PQ==
"Not really. Transformers (or rather the attentions) are a curious idea, but they primarily serve as a way to calculate/approximate multiple dot products and better parallelize the process, solving a computational problem.",r/machinelearning,Z0FBQUFBQm0yeGNhVFZIR3NpeWVSRjBkTlpwY2hndXpFbnJxLU1oYm5nRVQ4NGRmSkhERFU0UUJHXzRWd2lCOWlLOEdjVEh0NFpUeFc1M1NDUWdZeU11cDJNUXRRVFlQVVE9PQ==
"few read, everyone keeps a copy in the shelf ;-)",r/machinelearning,Z0FBQUFBQm0yeGNhTGNCM2VrSXlEWS1oQVJ2RVY0cXlIYU9aVmJscElFdkZpQlg1QlJwRzNuc0c3a3k1NEdaTU5McDZYRDNFQ0cxX2tyVnZHbWhVQzFwaVBSVVlMS0lvQ1E9PQ==
Don't you think these disruptions will get worse as models get more powerful?,r/machinelearning,Z0FBQUFBQm0yeGNhS2ExWFdYMHA3YlN3QWtObUIwdkZyMFZNSEQtRmNKdnl5MVdWYUk5VHY5cExTRHhOT25aeVJubDQyUHVoQ3VBTGxRdWZUSTg4UE83WjU0bWg4MDljVkE9PQ==
"The earliest mention of superintelligence I know of is in the seminal 1993 Vernor Vinge's essay on technological singularity. Who, in turn, refers to Drexler's Engines of Creation published in 1986, but I haven't read it. 

The acronym itself was recognizable to people in the field perhaps from early 00's.",r/machinelearning,Z0FBQUFBQm0yeGNhekVYNWtBV005RDNBUVc3VnFkYS1XdnhER2pqeDJEUHBubW9fRXFiaEJrN0pLYmxFNVF6eXkyNm9TR1FWVmNnT05Mc3J0aGhKYThiaUlINGduNnF3Yzk1TDVMRjRlVTFZdXlHQ2lmUVU2ZkE9
"That's a highly speculative topic as we don't have any examples to operate with, but I'd say it's more about where you run it rather than how you train it. If a malicious actor wants to put the world into chaos, there are far easier methods than AGI ;)",r/machinelearning,Z0FBQUFBQm0yeGNheEtheG84UXhoaTlldTZ2OUIyd2xTRm9oaU5vanYxVGhEXzJSa2ZNcmVJMUJWdmRqeE5Lc0h0ZHJEdC1tSFhQYjlDcmRmaGpIVjlDa0EzSG5oVjJNWGc9PQ==
"If you give them a large enough budget, they’ll definitely produce reports about it.",r/machinelearning,Z0FBQUFBQm0yeGNhT2c1TW1fU3FnSlJEbkQ1VWdQU0xvNUdPQlJ0R1NaVGZuNWpza3lRblR0VUJNQm9iSTRCZ2FJWkVuVVhrRFBJQVlmbE1QdmZ4OVVXaTIxRGFTNlN1Nnc9PQ==
"'Deliberate' might be a strong word, but why would you expect professors to be more rooted in grounded real world current negative impacts of machine learning vs more theoretical big picture concerns? Isn't that kind of the stereotype of professors even?

If we're to be fair to Bengio and others though, it's not exactly a new idea that biased recommender systems, crime prediction algorithms, loan application systems and so on all cause very tangible real world harm. Those problems are (to various degrees) being actively worked on, so I suppose there's a case to be made for people trying to push the window farther out into more theoretical risks, especially when the negative impacts of those future risks could be even more severe than the real world impacts of currently existing tech.

If you're just pointing out it's unlikely to be some kind of a conspiracy that they're focusing on AGI risks on purpose for marketing reasons or whatever though, I agree with you there 100%, not sure why the top commenter implied that might be the case.",r/machinelearning,Z0FBQUFBQm0yeGNhQjBDMTU3R3I1V1pIRlp2ZDc2ZFowRk52Ny0wTDZjNlN1X25KTnFiS2t3RzJ2MVFFTmhONWtFRkc3R3JidFllMm14VU1wM0RXSjY3Y0NXcGdTRlZnbUE9PQ==
"Exactly my view too. People want to regulate something that doesn’t yet exist instead of taking steps to mitigate safety/ethics issues that already exist, as if one doesn’t lead to the other.",r/machinelearning,Z0FBQUFBQm0yeGNhZll5LU9lVGZHTi1RdHdHSVNfY3o2ckx3TWNNdkQ3OWQwREgwQXdDNVV6VlZiaTNLeVV0S3p4X2pIZ3NYUFR2bDNqN29MTVZ2aGxOREg3QjVXTWZXa21wZldoa09UQVNGbi1IbjBwRm0zWDA9
">When the AI is given a main goal G under the constraint to satisfy S, if achieving G without violating all the interpretations of S is easy, then everything works well. But if it is difficult to achieve both, then it requires a kind of optimization (like teams of lawyers finding a way to maximize profit while respecting the letter of the law) and this optimization is likely to find loopholes or interpretations of S that satisfy the letter but not the spirit of our laws and instructions.

This section feels like the weakest argument to me. We are to imagine an AGI system which has such a deep understanding of the world that it is capable of destroying humanity, but it cannot understand the concept of ""spirit of the law""?",r/machinelearning,Z0FBQUFBQm0yeGNhb2FFVmhvdkJNYUVHRHpJQmQwTFkyOFdmU1g2VG5CcEZQY09CdmVlMkVoQjJiOWpKR3ZSSHV2WUw2Vk0tc3BBQW9vVklFSjk2Z3lfeXpQR092MTNnNnc9PQ==
"Because their current work is economically and politically disruptive.

Edit: to be clear, I don’t think this is some grand conspiracy. It’s just that naturally people aren’t going to push for regulations which will probably make their current work at best more difficult.",r/machinelearning,Z0FBQUFBQm0yeGNhSVYtQ2pWOFQ2SmJSMVB2andNM05Qc3otc1E1NTIxRkVlUXB6clZCR2FSSS1UMXRUZUJhQ05rU1JOYng5Y0hacG1OMy1pZlh4SG5McXlxTzh5dHJPN1JJRVU3SURsUXE3UjV1RzR5QjVLZkk9
"First, please dont attribute or limit AI success/knowledge to Yoshua, Hinton, Yan

These people have the least knowledge and just modern-day influencers living off their grad students' work.

These people can not even now formulate a new problem now. The least knowledge about SOTA than the first few authors can not even prove a theory on their own now. They're living off their past successes and self named God's.

I would recommend working on your and doing own research. I worked many old-timers, they have least knowledge, but rather have strong research experiences. 

They may not be any better than a fresh product manager.
I don't want to dis-credit their achievements, but rather urge not to get influenced now, since they are no better now, rather I would say a lot of people are good now.",r/machinelearning,Z0FBQUFBQm0yeGNheGhuN0VuRkhlSWtKT2RtOUdlTGpSZVV3dnNSQWV2M0g5RUdpV1JELXZBM3ZUYmJYUWFZUGtMbHpwaWRVdE8ySHpLR1p0ZGoyVFVzV2N2WEFLYlBOYWc9PQ==
"Asking them for solutions is missing the point. Their position appears to be more that we need to allocate resources and political capital at a societal level to develop solutions. That is in part because, even if people come up with ideas on their own, that does not result in political action.",r/machinelearning,Z0FBQUFBQm0yeGNhM0tueC1LMUVHVjA5b19XaDFoODdRcWpGVjgxRkx6X2o1S3VONGJhRVVQWlc1Mzc2MDFBcU4zbWdxNUlJcUphVmNWVGtyX0tGM1hzVW1mZ19iSmpUY2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhRUFvUWZDbzBpWDlBb2tYT204YWU5dE9zdFlWUFdCMmZicHo5ZXQ5LXFzY1ZNVm1DY1ZZb1o3T3gzWlJZdjM3cExIX1k0QkJpWEU4MGFMbFpDYVc1ZVE9PQ==
"Why GPT-4o can't count past 10 though?

I hope this doesn't indicate we shouldn't take AI safety seriously, right?",r/machinelearning,Z0FBQUFBQm0yeGNhOV9CZC01UG9mRlJpaGlJaHE5RU9aS2xuMThGVWQ1MzFKWXhvSUdobzg1MlpDbkUyZS1jUEhHaWFhNVRpb0dVYjhidEM4NVBoeFJFNEYxbmJ5UU1wZlc3cWZuckFzcTNuZ2xfcFM1NURIUlk9
"I mean... in what way exactly are biological information processing systems cardinally different from just being a fancy statistical model? They're still fundamentally structured around prediction (at least for lower level information processing, the only areas of neuro I know much about from the algorithmic perspective). There's a ton of really cool bio inspired advances it'd be fun to see hit state of the art (and some interesting crossover papers even my outsiders skimming has found) but I'd expect that sort of a thing will change power efficiency and learning rate improvements with low data more so than like... somehow not being a statistical model under the hood ultimately.",r/machinelearning,Z0FBQUFBQm0yeGNhTENVUUIyczRyZ056d2dGMy1pWEhKWkpBdkFwcEdwbG4xazZUcFg2VmQzdHpNNFVvYVZfTUcxVjBGNW1TQ1lmNGFSb0pYTGNlYTFuYndNdzdERzdEX1E9PQ==
Well python isn’t a given. You can use any language to build rag apps.,r/machinelearning,Z0FBQUFBQm0yeGNhX0ZTSnNhbWRpcEVJX0lqWG5VUlZsUmpvUHh1Ql9neG51cERyS21GbTd5RDVLM0Exa0tyai1ZQmNHYV9fdkx2ZHVybEI4Ynp0Rld1LThWTHZYT3dwemc9PQ==
"I didn't mean to say that I believe that's what's happening. I just said it almost feels that way because it's so far forward to looking with assumptions of exponential growth that it seems to me almost so ridiculous that someone that intelligent can't possibly think this is the best use of their time 

You can't explain ten years ago technology to Congress to get them to do something but you're going to come at them with your sci-fi theories?",r/machinelearning,Z0FBQUFBQm0yeGNhbGkxUFF5X244am1oUGN1QzJQemVsTHZ2WFJnVWI2b0I4WDdrQXo2SFVnMzlpcTIxdGF3M3dFY1BTNk5ZVWYwcFBCZ2o1akVDdjNoNTJseEszS0psYXc9PQ==
Is physics informed machine learning actually useful in the industry? Do you know of any real life applications using PIML?,r/machinelearning,Z0FBQUFBQm0yeGNhc0lsZmJtSWNhQ0M0eUc5TVBuV3lXeUwxTzZoX3lLVlJiRXQzQUFETzlvQ0lXNzBteWxaU1FGRXBaZ1pJaUYtZXduaUo0LV9XcDVTUnVvM1E2TFk5Q2c9PQ==
"Should a codebook vector be thought of as an abstract semantic description of an image-region, including potential local relationships, or as a representation at the semantic level of a patch of pixels for the decoder to smooth/interpolate when composing patches? Or is there a better perspective?",r/machinelearning,Z0FBQUFBQm0yeGNhTHcyTWVWSFRRR19PSHN1T29SSmVfZzBOVFpMcUJWNTR2NWdZcEpWTkc1eE9ZQ0VvT2p4LTJHX0x3WDd4eHlLb2swTjhETFhxTFhSTTYtWnF5MnNQNGdQZnlnOEtRUTBqbGJQdnA3M2RMelU9
"Fair point, I definitely misspoke re: training vs inference. And I agree that it seems like sandboxing would be less useful for a malicious actor, and more useful for inadvertent AGI, so thanks for making that point.",r/machinelearning,Z0FBQUFBQm0yeGNhY09OM1J4bm56LXZJMEdPbUhfQjlGeHYxOGdXX2c4Tm42SUx6TFN3UVduSS1oRkNTSm43Z25ObWpNRDBaVktwX2sxdEhld3JPWE1iUk9Ca1RtR3VkOTI3aUVQR1ZlSlA5THUwYmZfRUFKVHc9
"I'd like to hear any of y'alls thoughts on definitions for AGI. It seems to be a vaguely defined future goal that researchers are simultaneously rushing towards and making dire warnings about. How exactly do we determine if we've reached such an ill-defined goal?


And I don't just mean theoretically, I mean empirically. How do we go about testing if a model has reached AGI/ASI?",r/machinelearning,Z0FBQUFBQm0yeGNhM0VVVERUX0Rsb3Q0MVhraGVfdzBRckFBMjZyQ2xzcFVLdGN6MHRhUHZTS0ZDMzlfUHhsbWszaWZtSDRHcUlzcW9kSmlKdEVTam16TzNlQmdGTm9pRm4yWTVwUWdXQUtlbjJGWE9FT0VVcWc9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhNk1BSmR5bWRsNjJRa2VzRDNYSWJZM1Y3MUZzekNEQklYUWRySHNMcHVJOHY4ZDNYN09sRzl3Wld3VmFOYk9tWjg1QUFZSDN0bENJQjVpNUtHbm5WZ2c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhX00tTVAtd0MybV9DX3c0Vk1Qc3V6bG1DUTlXbDFmRC1wRV9JNmlBaGhiNDdKbEJSdWNtOGt2Y0xPbktQVmMybnQ5eGVTT3ZvNkVxTnlaTlRSaFFYdEE9PQ==
He mansplained the AI pi joke,r/machinelearning,Z0FBQUFBQm0yeGNhUTg3ZE5UY0Z3NkY2TklGSGwxRC1CX2taNXNMUjlBbUVNa2d4RGFka1hOX1lhMGQyTzFnS1JVUGhETGQxZHBtN2dJLVBKemt5Ym1yQ2xleDNvaHdsa1E9PQ==
"I feel like people in this comment section, are at the peak of the dunning kruger effect. Just because you are a machine learning researcher, doesn't mean you can now dismiss opinions of one of the most renowned AI researchers in the world.

Like, it seems little if none of them have actually read the source paper itself. And are just spewing their knee jerk reaction thoughts. Without addressing anything in the paper.",r/machinelearning,Z0FBQUFBQm0yeGNha3ZPTzh3MmZTWW8yQThSZ0xrVFBXVzB3QzN1THJySnByU2Q3QkRLR3J1WE5tTlNEUnpYb3BVQ2Y2NWRhY3RkMjM3Y1A2YXpqbUVpelZTa2RNTVpKRnc9PQ==
"Well, it depends. It depends on how you partition your table, on the size of the data, on your use case (and more). From my point of view the two main advantages of Postgres as a VDB are row level security and the fact that you can basically implement all other search patterns (full text search and graphs) on the same infrastructure.",r/machinelearning,Z0FBQUFBQm0yeGNhVjhNTHpjVUxpdk1qOVBudzNVVUtYVXdwMWo4OXFjY3ltNkJBVGVhSktSbjFLMHlYWGMwTUhZTy1tb1VFeXdfX2ZsbzlEdE1YVW9JWkdhbkE2ZXBKMXc9PQ==
Do you know about the HiNER paper? Maybe that is one step to start from if you haven't seen the paper already.,r/machinelearning,Z0FBQUFBQm0yeGNhSXhLZmN2ZVJMdWlkaHZrTXRpTEhJTGkwemFQNmk1OFg1b1VicmRCUkZJdUVNaEZDTlJQc20wT3ptaFpnM2hlTWl2SmZtc3EzTnladmp3Ni1iRVF5MlE9PQ==
time to move on to pytorch !,r/machinelearning,Z0FBQUFBQm0yeGNhREJfSVNoRnJXRHc2QTBLWmxwcF9hNklBQV80Wi0zcFdnYUVOUkR0UHdnNWF1ZnBGN2FCMThDU0VieWZpTjBYdnAta3l6YTJFTnM2R19idmg3V1Y1VFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhWGc5NDdLR1dqTWlJdXNRWTRySE5UR0tXcDNubUlFNGRTNWpURHVtQUgtU0NJMGJvRlhBcnYxeUhjYlAtaFRoMm5CZHkwRFFFdDZ2WGh3OTBJWjN4aUE9PQ==
"I am commenting here so that I can follow. 

Apologies, because I do not have an answer.",r/machinelearning,Z0FBQUFBQm0yeGNhMEUzejQ4MkxMbmFPYXhpUzVya084WDViWVdpMGo4ZGZpZ3RMUEhTZkMyRHZiRGtjZFpuTUpIYlRkX1ZuUW1tVzRYUHZHNGpfdUpHeWdXTWlaMy13Ul9jSWdDWTNscDJyWHB2SnNNVmVDMlU9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhR2lEN0VkeUhOZF9Wb2dCT1pTU2R0UTI2RW1lS0psUGEwakhOT1NBVVhkSnl2eERCeUM0UTlUdlM0WDdaSmI0cUVBRmNORDE1QzZFN0FtUnBIVzRCNmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNheW1yMHVraXV5YkZnRHVrSmt2ZjZBQzIwTFhBM0g0LWNiZHR1Qjc1bWwxc2NNYWdsY0V2OHMxZVM0WGY0clhXZFhad1lMRV8zVzNDMVVpODhzREtRbmc9PQ==
"Please give an example of a plausible Canadian regulation that would make Yoshua Bengio's work more difficult.

And then explain how Bengio's raising a red alarm about AGI risk would *reduce* rather than *increase* the likelihood of such a regulation being put in place?",r/machinelearning,Z0FBQUFBQm0yeGNhWS1DTHRkLXJNWk43MURuMlpJNFVud3pNUjhWNlhUalBrV1N5dmZSb1I5MWhTY3NyUGtBeFR0S1FLV1pkYmxjSmQxZXo5S1J6YW1BZXM0N243eWdlN3VWcXVhMnYybzBfM0VtZzhfdWF3eWc9
"Oh yes, they say all those problems will be solved by democratic processes. Specifically ones that result in closed source solutions that you and I can't be trusted to touch.

They say this as if I would ever vote against my ability to access AGI in favor of a profit maximizing corp using it for ""my best interests""",r/machinelearning,Z0FBQUFBQm0yeGNhNDRaMmJaSHhjTUc5QTRJeExtbGlDdHZJUVBPT2RleWZ3LU9mR2d6aENCRjhfQ3RwLVpfUEJzeGJCZFlKVjhETkFLRDlHbHlBUjBEb2ZoaXZlUDRlNmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhOF9KOGhNYmhMMmk4SnBOYUMzNEVwVGRFaE1kQXppOUxUYVB6Z3BidDVNUlFSRVlpOVFrMU5QRzQxdmk5RkVyemlyb2c4RFRua09TazdiMVVvTWVhYnc9PQ==
">'Deliberate' might be a strong word, but why would you expect professors to be more rooted in grounded real world current negative impacts of machine learning vs more theoretical big picture concerns? Isn't that kind of the stereotype of professors even?

Sure, and thinking far ahead is precisely what we pay professors to do.

In 1980 they mocked Hinton (and later Bengio) for foreseeing how neural nets might lead to ChatGPT in 2022. Then he was briefly a hero for having foreseen it. Now they are trying to look into the future again and they are ridiculed again. By the same kind of ""pragmatic"" people who would have defunded their work in the 80s and 90s.

>If we're to be fair to Bengio and others though, it's not exactly a new idea that biased recommender systems, crime prediction algorithms, loan application systems and so on all cause very tangible real world harm. Those problems are (to various degrees) being actively worked on, so I suppose there's a case to be made for people trying to push the window farther out into more theoretical risks, especially when the negative impacts of those future risks could be even more severe than the real world impacts of currently existing tech.

>If you're just pointing out it's unlikely to be some kind of a conspiracy that they're focusing on AGI risks on purpose for marketing reasons or whatever though, I agree with you there 100%, not sure why the top commenter implied that might be the case.

I'm not sure in what way you are disagreeing with me. I agree with everything you said.",r/machinelearning,Z0FBQUFBQm0yeGNhR3JkX2N3OEg3ZjY1ZjN3REZyQklUbnJ4SmltTHhJN1FzQUZVVG8yQmdtaFJOX0dhQUgwUFlSSU9SN0pDbmRDamZLakJ0UXN4RlZVd2d0VEYzd1NZWnc4QWpkZDVSaXlrOEc3cW9hUVhPQms9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhU011a0l0VHVxSFQtQlhlZEF2Tm10SThLOUtJZUJBZUtheWJjZlhhRUNTa0ZQTkVqd3dfZlhaMDE3VTVxY1lCenJ3QXFBQXdRNkIwVVlOT21JTkZPNEE9PQ==
"Blog post: [https://ajolicoeur.ca/2024/07/15/stgg\\_improved/](https://ajolicoeur.ca/2024/07/15/stgg_improved/)

Code: [https://github.com/SamsungSAILMontreal/AnyMolGenCritic](https://github.com/SamsungSAILMontreal/AnyMolGenCritic)

Abstract:

Generating novel molecules is challenging, with most representations leading to generative models producing many invalid molecules. Spanning Tree-based Graph Generation (STGG) is a promising approach to ensure the generation of valid molecules, outperforming state-of-the-art SMILES and graph diffusion models for unconditional generation. In the real world, we want to be able to generate molecules conditional on one or multiple desired properties rather than unconditionally. Thus, in this work, we extend STGG to multi-property-conditional generation. Our approach, STGG+, incorporates a modern Transformer architecture, random masking of properties during training (enabling conditioning on any subset of properties and classifier-free guidance), an auxiliary property-prediction loss (allowing the model to self-criticize molecules and select the best ones), and other improvements. We show that STGG+ achieves state-of-the-art performance on in-distribution and out-of-distribution conditional generation, and reward maximization.",r/machinelearning,Z0FBQUFBQm0yeGNhcF9QckgwZnlpQzc4bXFOZnNXbVdDLU10R21wUmNsZ21oTUlxQ2dINnhnTmdhMFBnZWU2djZVVjNwQWJrbGNyQklzV2tBT1BVb3QzSXhPTXg3dmlWa1E9PQ==
"> For those who think AGI and ASI are impossible or far in the future 
He challenges the idea that current AI capabilities are far from human-level intelligence, citing historical underestimations of AI advancements.
The trend of AI capabilities suggests we might reach AGI/ASI sooner than expected.  

I'm sorry but I just can't take this line of reasoning seriously. Yes transformers are cool and we have a ton of computatinal resources to make really useful generative models, but I feel like these guys just woefully underestimate the leap between what we have and human intelligence. I'm a nobody which makes me feel like I'm taking crazy pills but I just don't see a path to the type of intelligence they are talking about. It's science fiction on the level of interstellar travel to me.",r/machinelearning,Z0FBQUFBQm0yeGNhYzJ6MDZ1eUkzVmZFNXR5RWw4ekhBTUdoblNKZWFwZnNwX3Q3ekE0UHZwdEZaNXFVMTlGWlhuVnY0XzVlN19Gc2pqaU1HOXFDNXYyYkl0Q19CZzhsTGc9PQ==
"For the same reason understanding Christianity doesn't make you Christian, understanding the spirit of the law might not work.",r/machinelearning,Z0FBQUFBQm0yeGNhOUdGUzNmaU9KWGxjc3FIa1NxbkNkVGEtSjNsdzZXaWZkMUJVTGw1QVU5Z1d4SkJEQnpFYXlUUURVM0FsUldJVmp6cm15QlluVEtNeHJLXy14ZHd3aEE9PQ==
One can arguably say that about LeCun but absolutely not Hinton and Yoshua who has tons of original works including on the latest methods.,r/machinelearning,Z0FBQUFBQm0yeGNhaVFTYnN6aTJGODU3MTNhc1pUOUJRNTk3UmJxZWRkRGw4U1JjNGpPaTljdGotd0g2a1dzUHhaTVZ6OVNreTlaZVY2NDlBMXJyLTk5Z3BURXJIUndUZFE9PQ==
"It's a ""you'll know it when you see it"" threshold. But at a minimum, it should be able to 100% the ARC-AGI dataset, or a more complicated version of it, like you or I can do effortlessly. No current approach comes even close.",r/machinelearning,Z0FBQUFBQm0yeGNhQVJuSldoSnNXbmN3UUVWd3BzT2JTLWdtT0ZJeUhiS2FaVW5HMWF4ME9seWFrNTBCV29wMkkxMUdqeng3c3p6ckNxUFZ3VFMzWWdVaFI0VVdKeTloaVE9PQ==
">I didn't mean to say that I believe that's what's happening. I just said it almost feels that way 

If you're going to essentially accuse a person, especially a distinguished scientist with a track record of both integrity and success, of manipulating public opinion to the detriment of society's wellbeing, you shouldn't do it on an ""almost feels that way."" Your post impugning Bengio's integrity is very highly upvoted.

>because it's so far forward to looking with assumptions of exponential growth that it seems to me almost so ridiculous that someone that intelligent can't possibly think this is the best use of their time

Are you aware that these are the people who foresaw the current deep learning revolution 20 or 30 years ago???

They relied on exponential growth of Moore's law 20-40 years ago and they have seen their plans come to fruition as the exponential continued. What is so crazy about them thinking that this trend which they predicted 20-40 years ago and have observed for several decades will continue???

>You can't explain ten years ago technology to Congress to get them to do something but you're going to come at them with your sci-fi theories?

  
You're saying that Congress is always ten years behind technology and therefore we should *wait* to explain the risks of advanced AI to them? So we should want them to hold a discussion of it *ten years after* super-human intelligence has arrived?",r/machinelearning,Z0FBQUFBQm0yeGNhUE1UVDZxZFZ6QW02aG5MQ2Q0WE1GYkozZzdVa2U4MXN1YUstMGpYWGpSVDZZVHNWdUppS3ZyRXA2TVJhZXRVOUE3N19pZTlBVTFLTVd4VEFOTTNHNExSZDBjeW5YTXc0dnM5ZjJSc2hTdWs9
"Just making conversation, not disagreeing. Sorry if I came across as a 'well actually...' Simpson's comicbook guy, haha. I mostly wrote in the first place just because I was thinking about my time in university. Half my professors worked part time in industry (networking class was cancelled one time because the professor had to go to China on short notice to help with an xbox live arcade port, haha) while others were just pure academic with no industry experience. It was interesting to see the differences in perspective, so I do think it's an interesting topic, especially since ivory tower dreamers (like you pointed out with Hinton) can sometimes have the more grounded long-term vision in spite of not being rooted in the trenches. Or likely, because of it.

Anyway, have a good day, sorry if my comment came across as combative, that wasn't the intent. If anything, any flavor of 'I disagree' seeped in from my thoughts on the person you were responding to, not your comment.",r/machinelearning,Z0FBQUFBQm0yeGNhRnJzN3Y2VVpuQ2ZaTGM5OUhtc0RETVVSMjl4Z054RE1jQzJCbEMxNmZnUXpOeFlvODBjcjVzSWhnTFlrVnJET0VRMDkyenBtSHpKRmVYbGs2M19XZkE9PQ==
TimesFm from google has quite good zero shot performance. It does not support covariates at the moment but we still got pretty good results.,r/machinelearning,Z0FBQUFBQm0yeGNhb3A4LUJtWEUwS2hFcFY3eDR2V3RjNnJFVWU1bFdVSHh6T1piVG9CMnZ5WWZockowdnFrWndfeEpTVXllbGNQanN5bURfMkp4ZjhYTWVqXzhRZHNUb3c9PQ==
i was at a seminar and the instructor used it as the vector db but this threads making me think otherwise but im still exploring and if the demand of my project can be handled by mongodb,r/machinelearning,Z0FBQUFBQm0yeGNhWVRnNGNtMmhFcmtpZW1yN0k0UTJOa2ZhRms0VHRpMjV0NnkxV1ByemZMMXVwQ2dZcE5KamNHSmZnN1E1SDhsY2w0cXJGWkQ1Z3ZiQ0hpU2tXOUNNSTJTUU1mSDBRWmY1OGNkYWJ4SEhCNEU9
"Thanks for the suggestion!
Unfortunatley, this solution does not give quantiles at the moment, and in my usecase that is quite important.",r/machinelearning,Z0FBQUFBQm0yeGNhNlhEZl9Ea3hOdkxqS18xa1Zaam9zaTB6ZzlZZWx4OXRFY1h0YzhZdXYzVmVubWZaeWlpdmFRYkV5UzNSaHVTMFJiZ1ZwT0ZqbldqSzVJVHEyRVE4V2c9PQ==
"Exactly this – because the AI might disagree with your spirit of the law, and think it knows better.",r/machinelearning,Z0FBQUFBQm0yeGNhTE9Nazg2dl9BQXdfNXAzbHItR2JOUllzbEljLUhiYW8yd0M1dHVPaFBjcTVlRlNGb0E4Qm1nd1FHQXhLOW9UT2NBaHNfLTZhRG54bG5UMWNwRmhyOGc9PQ==
"TimesFm does give quantiles but you cannot customize them. It gives 0.1,0.2...0.8,0.9",r/machinelearning,Z0FBQUFBQm0yeGNhblV3LS1uSk5PQ2ZvdDZZeDM0cEY3YTlQOXdHbUprVDM5Wnc4ekFiTndFSUJBRzB1d1p5M3RLM3c2cjdMVTY4bENvcTE3ZU5XVTFpd29lSjJUV2hwMEE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhOENDVlhTVUY1ZFFHd05JSjdCdEdMTlp6azA0eUNlYU5ZWmsxNUY1dFdtc1FVRnRZSUhkbXBVcTJ2NWdKS3NRSzJuZ2NNRmwybk9rNTVtb1p6SEs2LWc9PQ==
"Weird, in their repo they say its experimental.
Ill look into it, thanks!",r/machinelearning,Z0FBQUFBQm0yeGNhVnpBbUNvcmwyeVVhR0FRR0o3Wm5mQmNuQzlKXzNoOFIwSGRHTW1SRDhGcFlOb1FFeVJkand5cTJ2ajkyN1JlRHljbEhHNlNwSGN6OXRMdlZPd0tUN3c9PQ==
"Ye its weird, but it gives them by default",r/machinelearning,Z0FBQUFBQm0yeGNhU3g5Zl91dm1qZHE3dGxRX3FmdTBGQkJBLW1aazVTRF83TFZWRERHSzRHMnVQNlZhOGIzRVhmcWZ0WG5MVU5xM29JSzJ5RG5sNE5hV0xaTFBZWllNY2c9PQ==
"When in a year or two, some algorithm/model passes ARC-AGI, we'll get a new definition / test. That's how it always is.",r/machinelearning,Z0FBQUFBQm0yeGNhU3JISjg4d0R1N3lrNER4OXJzYldLVmRFTVNWU3dLY3NoSWZrSUdhN2NNQVYxZnlBSE44emE5dWVHaHd1dXJ5dW9hLXNGLW5ITWFET1RMTUF1U1FiSnZmeG5jRFJ6MkY3dGpBaFBCTU1Rdms9
"It's not yet a scientific breakthrough, but an engineering breakthrough.  They're more removed from natural intelligence plausible implementations---primates have no exact 8k to 1M token buffer preserved of recent emissions.  Transformers have technical advantage of not being a RNN with dynamical instability (i.e. no positive Lyapunov exponent in forward or backward direction) that has to be simulated iteratively.  That lets them train more easily and map to hardware more easily at large scale.

The scientific breakthrough would be something other than iterating simulation from a distribution, or understanding the essential elements and concepts that can predictively link capabilities, or lack thereof, to outcomes.",r/machinelearning,Z0FBQUFBQm0yeGNhVjFEV0NXOEVzaHMxbXpCRVM2Zi1JOGZIdGlvbldkVVZWUVNhclBoT1JGTGw1M2pIdmxZNC11OFRNY3V6WTlWTXVvcU9IYlM1c2JCSmd3WllsS1RTVUE9PQ==
"Do you think the Lawyers are not ""intelligent"" enough to understand the ""spirit of the law""?",r/machinelearning,Z0FBQUFBQm0yeGNhZ0ZhZ3kxdklwUkt1VG1hSnpzSmhHNVdGNGlpeEdmTHNpVHdPMWg0UGozYlV1YjhIZHFlTXVvYTBBVUh5YmpPb09oNXc0MFZYMXFxRDBVMUswb1RoM1IzZTNIN3M0VFB1UTQwY3JLY1d2S0k9
"> I'm a nobody which makes me feel like I'm taking crazy pills but I just don't see a path to the type of intelligence they are talking about.

I agree, but Bengio's point, was that researchers also didn't see the leap prior to 2017 either to current capabilities---todays LLMs shouldn't be anywhere near as good as they actually are.",r/machinelearning,Z0FBQUFBQm0yeGNhWHNJck5ma1NFN3lYUHRFcjAyOXczRTdncGdsVU1Ncms0RVRrX1BJWG9HVGsyLV9wTENfSm5LSWVOOUhMYnhZY21uNk8tdURVVHBwVVFRQzJ1T1l3U2c9PQ==
It's not true about LeCun either---being a research director takes plenty of knowledge and experience to guide other people into promising directions and assisting on how to explore the space.,r/machinelearning,Z0FBQUFBQm0yeGNhRmJfNUNvbFJhLUFla1piQy04QnpJTXEzMkU4T2ZxMVo3ZHEtNmZTLVI4S3UtQlBYR1ZjdXhBWkswY0l4U0tJMUhLVkFWLTdZSWdJeGViQTByY1E5RkE9PQ==
I think someone with his level of sway is a limited resource. He argues that it is not zero sum having people think about shorter term consequences vs longer term consequences. But there are only so many people (1) with his level of reach. So it is a waste of a finite resource in my opinion to be thinking about ASI when there are very real problems to be solved here and now.,r/machinelearning,Z0FBQUFBQm0yeGNhMFhpbDJfbTlsMUpWX1RRbzRELWN5UzhmX0hGeDBvY21tQVJRRW1Ja0F3ZVdBNUlpeVlEbHhUdVp0Q3pwZ0tTeERvWndsTVo3VHlMNUktVHlHVjc0YVE9PQ==
"They recently add a notebook to run timesfm with covariates, not sure if their trained model can run with them.
https://github.com/google-research/timesfm/blob/master/notebooks%2Fcovariates.ipynb",r/machinelearning,Z0FBQUFBQm0yeGNhV3lWdVhqZzFtWDhNbllOaHdwNEUtTmprNXoxeGs5SnN1QTgxTG9wOUsxdHhtVWhpR3BRdFBkMV9YTXFWYTQxcWkxZF83aC13dmh4WlQ2akkzbGh0a0ZXeTJka0FzbmFENU41bGtSbVRsRWs9
"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/google-research/timesfm/blob/master/notebooks%2Fcovariates.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/google-research/timesfm/master?filepath=notebooks%2Fcovariates.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",r/machinelearning,Z0FBQUFBQm0yeGNhdnZmQi12dW9RcEkxLVJWbjh3alJscUFfRmVQZFMzcGIzbFd0aEtWTnFHVFl6OUZ2cnJ6UUVPYk8zUW1Kc3hMMktDcDFmem9PWmdRUG5SUEk0VjRPUGc9PQ==
"You have a legitimate disagreement with him on how he should use his resources. Fine.

Your highly upvoted top comment implying that he's involved in a conspiracy to promulgate unsafe near-term technology is not reasonable, not fair and not ethical.

Just because he disagrees with you, you implied that he must be corrupt.",r/machinelearning,Z0FBQUFBQm0yeGNhTE9Tb3l4UXhic29wRDZIOVhpYTVLVE5nUnRqNGhkREtzLXlFQ1lrMThidEVGS3FxWjNMQjd3STJIM1Bfd3BKRTFPMjlFeGFDSWdMVC1ncGh3dFlmQy05U3JxcFJFN0NnU3JLMVRiNGhxbW89
"Alright, I'll check it out. Thanks!",r/machinelearning,Z0FBQUFBQm0yeGNhWnRwbjJKN3ZuZWZaVm9RZXpPcjNfN2xHblp4NndPS2FxUXBtTC1DTmpqUzY3UTFrNGI0YlI2ZEhvdG9JZ2hSenpLZS13S01hOE5jRFluRDRQcG5yZ0E9PQ==
"Good point I didn't realize that, that explains why it's implemented like that in practice.",r/machinelearning,Z0FBQUFBQm0yeGNhNXlHd3FSQ19mY1pOUFhGSUpCZ1RINWY2Q3NPeVdZNXdfVWlKem9XVl8zNzlDYTNmN3dJdkhpSFIxeDFjdC1vY3RfLWRwSElfa1I2cU1neGJCUThKbUE9PQ==
this would be a really cool capability,r/machinelearning,Z0FBQUFBQm0yeGNha3R0amxndWU5MG45LUtweUFrQkZVZUQwdE9td3c1TDI4NkRkRjdqaWRELVB6MkJuRmd4ajI3em15WERmejVRdEl0cGhBekh6Q1YzMmV5RzAyYXpnNFE9PQ==
"This is what massive companies have massive teams for. Basically impossible but here are my very opinionated two cents...

1. You will definitely need to include RMSE at the very least and have rules to choose between the MAPE and RMSE. MAPE gets a lot of hate but it is generally ok if all of your values are greater than like 500 or so. If less than that then use RMSE. I hate MASE, so don't use that. 

2. This does not seem like a scalable solution - hyperparameter tuning across all of those methods will be computationally expensive if you have to handle millions of time series. You may want to make some adhoc logic to hone in on a smaller subset of the models and parameters to try. Like do tests for seasonality and if it's not seasonal do only nonseasonal parameters. Segmentation can be your best friend in these problems.

3. You will probably encounter a TON of intermittent time series, I'm not saying you need a croston in the mix (I am also not a big fan of croston haha) but I would add something that can handle that scenario well, like IMAPA or THIEF, temporal aggregation stuff always does well for me.

4. You are over-processing your series. Outliers are a slippery slope and I prefer methods that are more robust to them rather than removing them, but that also will depend on the size of your data if you can take advantage of those methods. SG filters on every series is also a lot. I wouldn't ever smooth my data unless my eyes tell me I need to. In other words, I would never do automatic smoothing. So don't do automatic smoothing.

5. A lot of time series is hierarchical by nature and a system that doesn't take that into account will cause lots of headaches for you when the client looks in aggregate and sees WONKY stuff. 

Now if this is me I would think about that segmentation piece I mentioned before. If you have a large number of decent time series meaning:  
1.  Many observations and many seasons  
2.  Not super intermittent  
Then I would take that bundle and fit an auto nbeats on that. For the super intermittent fit IMAPA, then the rest I would do smoothers/sarimax.   
  
If that nbeats sample size is small, like only 50 time series, then fit them with smoothers.

If the client provides hierarchical data then do a hierarchical method on top so the aggregates look ok.

This also doesn't even get into exogenous data, if you have that then it might be best to do automl trees but be careful of long range forecasts if you do a recursive fit! A tree's performance here depends on if the signal from the exogenous axis is stronger than the signal from the time axis. If it isn't then nbeats will probably win out.

If you have complicated and multiple seasonality then replace smoothers with TBATS. 

If your data is nice then nbeats is probably best.   
  
If your data is messy then smoothers are probably be safest.",r/machinelearning,Z0FBQUFBQm0yeGNhNEx1WHZJeVJjTWNRc1NkejBEMEdKNU5FWlY3VFhjcHo3WDh6dEhoZnJkTlQ3NFNmVHJGRGM3My1FLW1jdk0yU3hUTG1VbTEtUl9WelVSTzFrd1VobEE9PQ==
It's possible that someone could write a purely theoretical paper by themselves. But I doubt it. You probably can't do anything in isolation there.,r/machinelearning,Z0FBQUFBQm0yeGNhbmljNDlNZWFrT1dKZzBYMWVuN3NmU0hQX3gzX2owOVVJbDkwLXFrNlR1TE1hcUNPV2k5enhnRTNZdkp5NWh4UVpyN0hUYjJTQVdHT1BLbFlSdWRrQktwam5GUlNMWnR0MTJKZzNPSzRtcUU9
"And yet this feels to me like seeing the moon landing, which I assume was also unpredictable in around 1960 (E: I stand corrected, the moon landing became plausible earlier than the early 60's), and predicting that intergalactic travel is 5 years away. We have no basis to stand on to suggest that GPUs can replace the type of machinery in our brains that facilitates inductive reasoning. By comparison, LLMs are glorified autocomplete tools.",r/machinelearning,Z0FBQUFBQm0yeGNhbXZOdERCLXdfcjNjVl9PcEVtd1pwVVI4QUlxWGRsek9lNUt5cE1ZSzNkQWlpUGpqOVFrd1R1NWt2a0tYbk9WckhHU1hndjVQZkRFdl9NNjNPRGpVdmc9PQ==
"To add to everyone else' incredible responses. We have just released [Scikit-Longitudinal](https://github.com/simonprovost/scikit-longitudinal). A collection of longitudinal-based machine learning classifiers that understand the temporality in the data from the ground up, without using mixed effect models (despite being a great starting point, as pointed out by many): [github.com/simonprovost/scikit-longitudinal](https://github.com/simonprovost/scikit-longitudinal) (Random Forest variant for Longitudinal Data is available based on a paper in the literature) – as well as an Automated Machine learning variant of it: [github.com/simonprovost/auto-sklong](https://github.com/simonprovost/auto-sklong) – Paper's incoming.",r/machinelearning,Z0FBQUFBQm0yeGNhdDNEaExUeUFIaE1jMm50X3JSbndiSjdHSDRmenZhcXlmTGRUd0V4WjNZaTFKMDJEMWZ3TVhRY1JSWkx0U0s0ZHFEMnRwak9VOUVidVNROHhPeDJYQXc9PQ==
I can tell you right now that ARC-AGI is still very narrow in nature. Any system with some spatial logic capabilities should perform well,r/machinelearning,Z0FBQUFBQm0yeGNhb29vZFNBTm9WSW5FbFNXVDdBOC1vbG1rSVdSWjExZ0thQ19BRHpTME1VUjNPMFVMR2lSRThZdVVXSjJzLWphZzlJd1ZtMFU3ajNOc2VydEw0LUN3Nmc9PQ==
"Why are either of those ideas ""absurd""?  That's basically how we stopped nuclear proliferation.",r/machinelearning,Z0FBQUFBQm0yeGNhUXk3Z0dQckVKMmxhYVdmOTEtX19NVi1QNDFoV0ZkbXJtSzdyamZjUS12aWp1UHN2TGw1UmxvWEZqZWpIaTdVc3dhVlhlRWNqaW8yRnV0NVhIcFZWZ3c9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhME85emlHa1NUdW9zbWV4RFBKRkw4WTNuZHNVMk9tNWsxcDFsWnBicFdJN0FNMzFibG51bTIzUUlEQmthc0w3ZWpUVFBGTWhPSGtTZG1BU05uM3hnUGc9PQ==
"After looking at it back when it came out, that was my opinion as well. It's a cool benchmark but it doesn't seem fundamentally harder than any of the ones that have been beaten already. It kind of reminds me of this benchmark that Douglas Hofstadter proposed shortly after AlphaGo beat Lee Sedol and everyone was wondering why we don't have AI yet, that involved ""thinking in analogies"" instead of the raw compute that beat Go.",r/machinelearning,Z0FBQUFBQm0yeGNhMExSYkUzUEFHT19abWUycU1oV2VXdGo3Zm8tWnV5SmUzMlRSQ1A0NHRHZGdvcVcxWUhJWDNudkJ2cEpUZ2RPMWRVSVVObHo5N1VucE9TemkwZUl0VXVrUGNtOFVhVlNCRXJjTEpXWnJBcFE9
"Like many arguments of this type, this one does not address what I think is the most substantive criticism of this sort of reasoning: it is based on an agent-based and goal-based conception of AGI/ASI that just does not look like it is where the technology is trending. Our best AIs today are not based on goal-oriented reasoning, and for general intelligence, goal-based approaches have mostly been a failure. And this framing effectively downplays all the potential risks of the non-goal-based near-AGI that seems much more proximal, because it frames safety as being about the behaviors of an agent as opposed to about the effects of a technology on society.",r/machinelearning,Z0FBQUFBQm0yeGNhYkF4YUNqVjJuenBjQUw3Wm5XcHBUcXZacDJsbHVlT1Z6YkRxNHppVWlXb202eFJTY2ZOd0ZqeFFZUHVRZXBlbXFoM2I4ckJ4N2JxR0J3T3YyLVY5Y0E9PQ==
"Moon landing was not at all unpredictable in 1960, as there were prototype plans to get there.

> We have no basis to stand on to suggest that GPUs can replace the type of machinery in our brains that facilitates inductive reasoning.

There's fact that GPUs have replaced the sort of neural wetware which does many other useful tasks like high quality voice recognition, face recognition and now ordinary writing and question answering with some sort of approximate reasoning. 

The history we've seen is the gap between capabilities may be large, or it may be a small technical tweak away, and we can't say for sure ahead of time, and that's Bengio's point. 

The success of autocomplete tools at what seems to be semi sophisticated tasks is remarkable---they should be much stupider than they are.  And maybe human brains have their own similar tricks to use simple mechanisms to achieve strong outcomes.

Maybe it's a big gap and decades away, or maybe it's some new planning concept and technology (i.e. beyond iterating the markov model on tokens) which will become as ordinary as a conventional neural network is today, and be taught to undergraduates.",r/machinelearning,Z0FBQUFBQm0yeGNhYmhjVzJxbWcwVGpWQXQ1MHNWN3NLRVZldk03NEtaTUFnQ3BfR045OXVCODVwUkJXSG9iRGdORkF6azFXYnNGaGZpcy1hb0RsZHBfTS1SbzlLbzBvZmc9PQ==
This so much. You will probably be downvoted but you are 100% correct. People take so much personal offense at the slightest notion of potential harm/downsides of their work. Like they made it into their identity or something. It's not a personal attack. Most science and technology is a double edged sword. Nothing wrong with acknowledging that. Reminds me of people in banking in the few years before the financial crisis. People who were in the field were dismissive of concerns because they presumed that others don't know better. It's a defense mechanism of being faced with the hard truth of their work.,r/machinelearning,Z0FBQUFBQm0yeGNhZDNjUnhRb3VtMmZSeWphV1MxNGZJRDEzZnpDVFhEYWMwdENqNFRfU2FOSU44R1hfa1pPbjE3Uk9KbHBZeWV1NEZ1T05HcXJiOF9KWXlCa3FCcy1CNFNVQUI5Q3F1Wk5TcXFmWHA0UnZ2Tkk9
Sent you a DM^^,r/machinelearning,Z0FBQUFBQm0yeGNhSDRtbF9mT3h5SlhNVkFWSUpaS1lUcXMzRDd3M1JKX2NrVV9TZW9qMmhHWjd3WlM5dWsyWm92YzdpWVVtSlNycmZ0WGFzLWpsYi1sM1k0VVNpdDZUQk1hVkV1TldCZWVRREhpMXoxdjFHRGc9
"It does. Like you say, it is guiding. it is not doing your own research. It can also be a lot easier to get your name on a bunch papers that way, and many probably want it just because of his fame.",r/machinelearning,Z0FBQUFBQm0yeGNhWjNNZ0tCTkktUms4TkRPM2trSHpEUmlDZU8xTmRmVG43S1kxaGVUZEFhR1B0VjRua1FYdzhhN2pfdDd5MmE3VXJQd3JjTTZJRVJ3eTFlalZfVFB5N1E9PQ==
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNheEpzSFM1ZDk3V250TmIySngtTEhuclVFZk5xYkZ0b3Y0aVU5N1BqLUJ6My02ZG5GTnQ2aGk0d3pzNTZSZWJ1aXIyb243RWdCNnZSajN6Z19pRkdldWc9PQ==
">There's fact that GPUs have replaced the sort of neural wetware which does many other useful tasks like high quality voice recognition, face recognition and now ordinary writing and question answering with some sort of approximate reasoning.

It's one thing to (correctly) say that we have high quality voice and facial recognition models and good generative models, which to me can be explained by the availability of data and compute, and another thing entirely to say that software has approximate reasoning. Personally I'm not seeing it. All of us here know how ML models work - the output of a trained model is entirely dependent on the characteristics of the training set and some randomly generated numbers. Saying that they can reason in my opinion is anthropomorphism, it's an extraordinary claim that requires extraordinary evidence.

>The history we've seen is the gap between capabilities may be large, or it may be a small technical tweak away, and we can't say for sure ahead of time, and that's Bengio's point.

Again, the history of jumping from word2vec to modern LLMs, while impressive, is not necessarily indicative of a trend whatsoever. 

>The success of autocomplete tools at what seems to be semi sophisticated tasks is remarkable---they should be much stupider than they are. And maybe human brains have their own similar tricks to use simple mechanisms to achieve strong outcomes.

As someone who's main academic background is in biology I simply find the view that our software is anywhere near the level of plasticity and complexity of higher animals to be naive.",r/machinelearning,Z0FBQUFBQm0yeGNhVGFGdnQ5TjY2R0RaMkFnRVVUMHlySTRwSHYyamM0SzNjNEFrX21FWk95bi0yRmlHNkhNbWZNa1Q1Qy1DTWg0YkxMM0dXWTBUbHhKOXJ3SUFXMVlDUlE9PQ==
"Also, the idea that the federal government is dragging their feet on near-term AI risks is quite incorrect.

It took more than a decade after the invention of the Web for them to mandate EHR interoperability. But they are [ALREADY](https://www.imohealth.com/ideas/article/regulating-ai-in-healthcare-a-look-at-bidens-executive-order/#:~:text=Advancing%20responsible%20AI%3A%20HHS%20initiatives%20and%20collaborations&text=This%20regulation%20sets%20standards%20for,and%20Safe%20use%20of%20AI) regulating the integration of AI into EHRs.

I really don't see any evidence that Congress is asleep at the wheel when it comes to AI which is:

  
**Fair:** Outcomes of model do not exhibit prejudice or favoritism toward an individual or group based on their inherent or acquired characteristics.

**Appropriate:** Model and process outputs are well matched to produce results appropriate for specific contexts and populations to which they are applied.

**Valid:** Model and process outputs have been shown to estimate targeted values accurately and as expected in both internal and external data.

**Effective:** Outcomes of model have demonstrated benefit in real-world conditions.

**Safe:** Outcomes of model are free from any known unacceptable risks and for which the probable benefits outweigh any probable risk

What is your evidence that they are dropping the ball and Yoshua must put aside his fears about the future because of this deep negligence?

What specific regulation do you think he needs to advocate for which is not already in the works?",r/machinelearning,Z0FBQUFBQm0yeGNheXduemg1c3JxaGp4cG1SUkN3S2ViT0Z0MU5yWFpDeXdrUEJYQmdoV2sxWnhsdENJSWpRcUdLN1VoN1RyRWZkT09NWEM3bXpsMVRYdlRVdHJPOFFhanBtUkVwSjd2Y1R0R0JsTWt4TXFGUG89
"That sounds super ambitious but totally doable. Maybe start by trying with just 2 LLMs first and see if the communication flow can be established over multiple iterations. Also, kind of a side note but for my schoolwork, Ive been using [Atlas.org](http://Atlas.org) and its insanely good for getting accurate info pulled straight from my textbooks and notes. It might be cool to see if something like that could add accuracy to your hierarchical model too. Good luck!",r/machinelearning,Z0FBQUFBQm0yeGNhLU9ENDJVRWtrSVFjRzdOdnloekZZZlpjUzdyMjVkWUY2UG9JWXE3eENpa0l5UV85c25SbWtYRDM0UE85b1RiNFpsbmZ2QWFEUFpWeEVoNnRRTjFpcWR5aEdQczNadUhFR3ZEVld4aG02Wlk9
"It's probably more on the semantic level though they're might be a bit of both and also there are interactions between neighbouring codebook entries during decoding. Since the decoder is usually a CNN type architecture, a codebook vector in the top left corner will mostly influence that region in the output,but it's not like one vector contains all the information for one patch since neighbouring vectors will have an influence on the same region.",r/machinelearning,Z0FBQUFBQm0yeGNhQzdQMnBpUC0yVWd2Qi15NnBsSTF4T051aDQwOEdCcWlXOGpPMU5VeUZWTjFOcFQzMm1aY0xpV0dvNEZGSWVmSDBUVXlhTXdscVVTRW82SHBMV3Uta3c9PQ==
"Neural networks were considered AI as far back as the 1960s, so I have no idea what goalposts you are claiming were moved and when they were moved.

AGI is simply human level intelligence and ASI is what happens if they greatly go beyond. These terms were not explicit back to the 1950s but the concepts go back that far. They didn’t need an acronym for concepts that were 100 years in the future but they discussed the concepts.",r/machinelearning,Z0FBQUFBQm0yeGNhRHZuNWlUSVRVV2E4UFBiUzhrSGdpamUtX1UyYlpNam1LNnFPTVVyb2xHVS1tZzdoT19qcDdJX0pUNTdSQzhIRUtfSTVCcktwbnlaY3F3QjhwOVVHNHc9PQ==
"I hear more about AI researchers concerned about AGI taking over, whether we live in a simulation or an alien invasion instead of real meaningful things that are hurting the field every single day: Literature review before ""a new novel method"", code reproducibility and a culture of benchmarking novelties without adequate testing with rigorous statistical significance.

Everything else is hype and folklore.",r/machinelearning,Z0FBQUFBQm0yeGNhdUxZUE8zWUxLenNDVWNqb2NfS3ZyMERqbGVXNFZlM0Z2YXJzUFZ6ZzFPQzg0YjQ5WDliVXVRc2E3Q3RUd19aTEtNMDluUGg3OGdZWmhxeHhkNTM0anc9PQ==
"There can exist more than one problem worth spending time on. Outside of AI, some people are focused on the very immediate effects of poverty, and others are focused on long-term risk of nuclear annihilation. Neither choice is irrational, and if the most extreme outcomes of advanced AI (e.g. extinction) are even remotely possible, then I'd think we'd prefer some people work on those issues even if more pressing issues also abound.",r/machinelearning,Z0FBQUFBQm0yeGNhQmNZYllNQlZHcWtiSFMySXlVcHNyNFR6WDRrZF80YVB1Rmswa3lDaVNYYU1TcVVaV2tNMmExZmVxSXppMF9HRjQwNS14aEkxXzd3MC1xUTUycjY5TEE9PQ==
"We already have this, but up until now only for malicious organizations with alot of money, like the government or mega corporations.",r/machinelearning,Z0FBQUFBQm0yeGNhaVNqcVFXU1RrQUNJdk1zdGgwRHdvZHdKT25zSW1zNFFKV0JnRGNqdzBZdTQwR2NySzQwLUEyMV85Q1VnMjJ5bnUtb1NodkxEZ0ZIUmRvN2dFelhZUlE9PQ==
"The GPU market was valued at $65 billion in 2024, and is projected to grow to $274 in the next five years (which might be conservative.) Consumers and businesses all over the world buy them. Regulating that the way nuclear activity was regulated is not even remotely practical or sensible. One might say the idea is absurd.",r/machinelearning,Z0FBQUFBQm0yeGNhLVFpdXVfbFdLaFd5dWIwLWdndi1VZTB5Q0FGU3N5a3F4bEMzVnJmam04Zzc4WXFMQ2JBQUtSYlJ4dlIyWWk0QWxxMFBZejBfa0RnY29Ja082Y3RUeFE9PQ==
"Mandatory open sourcing all llms is the only solution. What we really don't need this this Führer Principe open AI promoting. AI is not like nukes. Nukes make both sites destroy each other, but AI is good to defend against AI.",r/machinelearning,Z0FBQUFBQm0yeGNhVmtoaWlPODd2MkV6T2ZxUHoydk5kNzBZZ2Q5ZFFuUVAyR0N5ZDRmMGdFdmloemRINEMzTUhDTEd3VGkxcXBYSW04ODI1dVNlSGY1X05BZHBlWUhYdHc9PQ==
What would be some tasks that you would expect no AI system to be capable of within the next 5 years?,r/machinelearning,Z0FBQUFBQm0yeGNhMDVRTVotOWFLSXdFd1UwWjNYRXhGWUtTcWRmSG5XUDFrU2NBM1BqZTJWTm9kaTVmckZZSTJubGR5MlRmcFJGeVMyTmwyN0dJXzlHNGNuOER6VU5DNkE9PQ==
"I fail to see what makes it so absurd. You need a massive number of GPUs to train a frontier LLM. 


Sudafed is also a huge market.. and somehow we managed to make it hard to individual consumers to buy a lot of it",r/machinelearning,Z0FBQUFBQm0yeGNhS2JsVDJCcmdONm04QUhqdDcyXzViV1dyM1B5ald3VHVwNTJXUm8zSDVGSEZkem8yWjVQYXFwZ0JjSFRwUGFiN1JhREJQaDBqV0dHcjVjZENhNXBzMFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhVWxOTTNRSW5Wa2NTSDBZcFZmUlB1ckxPeHJ0RUNmN3lKTV91RG9YWHZRSlNZcHpsdzN1Q0ZjYmpMcVBHVW1wTVViZFVlWGxMbUh4TDlKdnJLUVBFTXc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhbWdxUGVCZjZyM1R3ZmJicEtvY0x0VzliMFpZVF9oaW9pNFdRQ19yT0Fzb180ZkJBM2gyQ0dJY3otYktDeVlmYjZXOXVBUkpMNWJtdVF1R2ZHWlI0X0E9PQ==
"Thank you!
This is super helpful.
Another question if I may. We are basically making our offering to small-medium businesses, so any result which is pretty ok is better than what they have. Would you say that this might be a use case for which automl might be suitable? Ive been looking at Autogluon as an idea.",r/machinelearning,Z0FBQUFBQm0yeGNhZlcwd21yU2ZYdXZ0WlN2QWRkYzh2ZXNQX2x6RTRtYXRRWTZqY0FGU256ckM5QVZFUU5aVUNaVXVLT3ItdFhOU3VERWNPS0JXX1o0Rlp5NHZOcms2bGc9PQ==
"* Generating actionable novel ideas for research (ideas that would likely be published in a field it was trained on, that don't include the low hanging ""further research"" paragraph fruit)
* Producing new genres of music
* Producing new styles of art
* Looking at results from a pioneering scientific experiment and coming up with plausible explanations that didn't come up in its training set
* Consistently accurate medical diagnoses that are not obvious

Basically, any creative works that are actually novel.

P.S., self-driving cars as well.",r/machinelearning,Z0FBQUFBQm0yeGNheWhPenpfR2xUWFplN2M3OEtoLWViNDExU29DdUhhMnlEWEhSbWZiTl9wcTdvOVQ3TFl1Q1VCaHBrM0xKcHRpcnVLVmt3UU9FQkZxaHJMbjFMUmF3Q2c9PQ==
Maybe all we can do is just fine tuning or (test this) use a lot of good quality audios with clear accent as reference wavs,r/machinelearning,Z0FBQUFBQm0yeGNhWUhQd2xDck0tbWRWaE4wR2p4TFBJQ05fcTVyUzhOdzdLMWtTcXVZVklpRHY3TW5vLWVUQkZkR1VsclRSdF9yY1dDdHh1MVhXNVBmeTRtbWs3MkI4N3c9PQ==
"Are people who understand ""the spirit of the law"" bound to it?",r/machinelearning,Z0FBQUFBQm0yeGNhUHRiSkQxcFlfMlNTbE9jd2lIR0VhUTY1ZENWbTlLQXpFNlR5ckdRbEIxVkRkTWd3d0Y3bjlyZFZxRGJoaFVyT3Y0ZlJhOUc3VDhzdEJOdk0wOWN3cXhlZ3B0RUtaODhqZDJ6aVZfMVVCeWc9
"Your post was automatically removed for being a link post on the weekday, please read [rule 5](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhUElabXhQbUx4bDdhWXhOYWIxSzNJVVNhRXpUdFJiTUNrVVpid2NibXlNSzVWNVJiWUZmS3F0TEExRjR2S092TGpVdkNMc0swdlNTNHBqZWxfZHUyRXc9PQ==
"Nuclear proliferation isn't happening because people voluntarily decided not to get nuclear weapons.

It's within the capabilities of all but the smallest and poorest countries.

Furthermore, these companies are not reliable or trustworthy. You've seen all the information gathering by the ad companies and that router company that sent passwords back to their own servers, and you've seen companies like the NSO group.

The big firms are worse than even a quite irresponsible individual.",r/machinelearning,Z0FBQUFBQm0yeGNhX0g3b1d5NnlVX2VjajYwZldVR0RvdHk5Si1sWDNsZ3FKc3N1QmxvTks2WXd2VXFWTXc2aDBSbVA0eUM0RDJyWEFPdk5ZemlvSnRkMjNhajl4OWFYaUE9PQ==
"Here's a gross simplification: LLMs are a ""jack of all trades, master of none"".

For most people with fairly straightforward use cases, LLMs are a great place to start because they're easy to implement. 

However, LLMs can be fickle, nondeterministic, and slow. If those are a dealbreaker, you can look into other options like training your own classification models, but you'll need to set some time for this.

[Taylor](https://www.trytaylor.ai/) can also help you (it's free to prototype classifiers and see if they get you the results you need). You also get back scores for each classification, so you can threshold classifications by score.",r/machinelearning,Z0FBQUFBQm0yeGNhSnQ3b3laT2liSURSbk9EQXE2NUozT0x2eFFUeGlOWUVod19Ub0RIeUdfTVhFQmtLamtDdTZPVmktVmw5WXIwdXJMWUZJdXdrTEtCNDVnVmdXSV9iM3dKdjBrN0ljOU9fVGxZMHdmdEs5ZDA9
"> As someone who's main academic background is in biology I simply find the view that our software is anywhere near the level of plasticity and complexity of higher animals to be naive.

Current ML systems are inferior to biology in many ways, but also superior in others, and that superiority may be overcoming their deficiencies.  For instance, LLMs on a large context buffer can pick up exact correlations that no animal can do. They run at 6 GHz cycle speed vs about 100 Hz in biology. Backprop might be a better learning algorithm than whatever is possible in neural biology.

Aircraft are inferior to an eagle, but also superior.

> Again, the history of jumping from word2vec to modern LLMs, while impressive, is not necessarily indicative of a trend whatsoever. 

If you look back to 1987, starting with Parallel Distributed Processing and the first nets, there is a long term trend. The observation then was very simple algorithms on connection oriented networks can automatically form interesting internal representations. The connectionists have been proven right all along: more hardware, much more data and a few algorithmic tweaks will solve many AI problems and some problems that natural intelligence wasn't able to solve natively on its own either (like protein folding).

There's enough history there to call it a trend.",r/machinelearning,Z0FBQUFBQm0yeGNhSlB5NVpYNlRVS3NFTHNIdVlxS3IwY1pFMmZneWhVUUJLOXBhenItWTVOZ09CREpfdzAxTEYwd2RiY3BpRVVUUjlxSzIzOEpZbG9nZHFRd0RNdHVBdUE9PQ==
Meta prophet is a good choice to try,r/machinelearning,Z0FBQUFBQm0yeGNhdS1Sb0Y1RHhvSkg2U0JndlN1aldITkhPUGNNUFdMcXNfREw3M0pBQVpFWUMwZkEySkc2aE5zRjlnMG9SSlQxVUF3RkdsdkhSakQ3SEM2NlVzRlZ5ckFfZVJ1WFVINVBkbDlfMHNWRzREemc9
"I first want to see an AI attached to a robot bag groceries before I think about how AI might destroy the planet


Also, can't anyone build an irl aimbot with openCV anyways? I feel like a lot of the ""dystopian tech"" is already here",r/machinelearning,Z0FBQUFBQm0yeGNhdkpWU3B1bWlUUER0Vm8zOF9PeVJwOVZic294ZlNJNEFWWER5OS1SLVlYWlUwdjdlMkR3T3dFVndfeUFBV0tpbjJXaFRRaGpKcDBBeFRXRFpGTXFqUlE9PQ==
"Who said they use a vector DB? They might be using elastic search with BM25 as a retrieval engine. It works pretty well, and you rely on the summarizer LLM to do the magic.

Using LLMs for retrieval is the new thing, but the previous technology wasn't that far off. It just doesn't understand semantics.",r/machinelearning,Z0FBQUFBQm0yeGNhbUlCOG12ek85OURvei1lR3hQQlEzTTRVNTJoRlZ4cVB2cEsxdDliNUZ0WXVOS2YyZ2JwZnNiZFh1cnp5ZENSRkVoUFNXdWpKM3NyT1dkNFFfWmZISVE9PQ==
"Sudafed is a great example. Yes, we made it hard for individual consumers to buy a lot of it. To what end exactly? Meth availability has only increased since then. On the plus side for meth consumers, average purity has gone up and price has gone down, so I guess the regulations did help *some* people.

Besides, Sudafed is a drug that's only needed for specific conditions. GPUs are general purpose devices that have many legitimate uses by individuals and companies.

> You need a massive number of GPUs to train a frontier LLM. 

Currently. Until something like a [Bitnet variant](https://arxiv.org/abs/2402.17764) changes that. Putting in regulations **now** to restrict technology that's needed **now** to guard against a currently **imaginary** future threat is absurd.",r/machinelearning,Z0FBQUFBQm0yeGNhY2tkYS1ka2xTSkhvR005QWQ0alpTeEdLLXR6N3VFWWJVZ1VEZ1MxVTJSY3BDd1h4ZklRVEVjQVRJTU14NjhXWXpwM0RGb2dKWVhuZ04xVmk1bHJMMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhekJNQzRvSzNtc2pCRlhocDhKUWZ4aGFpbHNQMlJONGhZOEEyWm9pZzhQSi1XNVE0SnlEaUNIbGZTODEwbTRGSDUzT2tOMXpWMTdxbDl3N1hwbEdLTnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhbjVLQVFWUXZEblNJd0J1el9RT3Q0UjgzdGg1NXgzX0s3OW1EMmZrT256MjFyakI1empDT3NnLXVNdUZ6T1Rra2h6RzltU2lFek40UUlKTWstMlByY1E9PQ==
Cool. Do you plan to release MobileNet2 results and weights?,r/machinelearning,Z0FBQUFBQm0yeGNhejdUS3VRSlQyVEdNTXdVdWZqVjNDTUdQRVd3YmRoOEZXVTV3RnBSLW1yTGQ1X1ZVNFo1Z0o5MGVPVjJYTEJfZ0xjVElEY09MRjV6cU1fRVRHdHZfRVE9PQ==
"It appears to me that your time series model is univariate，which normally performs badly in terms of prediction. To improve the performance, you should use multivariate models by considering auxiliary data such as quarter,monthly yearly weekly, date-to-year.",r/machinelearning,Z0FBQUFBQm0yeGNhUXpEd3h6SWRsWWp5MlFqaXBYdzB3MkZTaGpxdm1mNUluMjFvbWZLTDd4NXBMeE1iWHRUWUZCU3RrTnVCS0JNWDdLSXhBNUhKS01jWnZMNXhBdXh2WnpSeGxOWTNaWXM2YWFlOWhMSzlacmc9
"Ehhh… I think this is misunderstanding the arguments. I’ve heard we need to stop scaling and go back to model design. That doesn’t bar people from having gpu access, just encourage more flexibility in the research.",r/machinelearning,Z0FBQUFBQm0yeGNhWVFiUEExLTgzSzdWZFhjd09NMVZfODRnWEVfd3l3VXhXWDlCMzhlZ01ocVlVRFY5MmVtejl1Y0l3ZTJiOFB4UG5LZ1BzQndhci1RaW5BSUdKNVdXNFE9PQ==
You’re asking Reddit man… you’re not going to get a good answer here,r/machinelearning,Z0FBQUFBQm0yeGNhQk1INzVuNkdpT3NHYy0xY2VDWGMyckoxT0I5dkdyRDhkRGxDV0QzZnlEa3REZXhib3hNV1JGQXd0X3QwZVFnMzhsSC0yci1Ba0dtZGZfM2hvMUg5M1E9PQ==
"Converting time series models into a regression model and solving the problem using xgboost modules, which perform better in terms of training cost and predictability",r/machinelearning,Z0FBQUFBQm0yeGNheXdaMld0SUNhZEJBZHdoMnEtcnFOU2xEMHNGT1c3TWctOG5GNFViNTR2QTI1dk5wMWdKanVrWk9SV0pCYnZhX1U4S1IyZWtHdUNIN2VfWF9kTjNYbFRyN0w2OS16ekkxUk04YkhTNlljbGc9
"Hey all, I’m starting my PhD after several years in industry this fall. Does anyone have any recommendations for online courses to serve as refreshers for reading math/computational complexity/understanding graph structures? 

I haven’t done much theory since graduate school and am struggling getting back into research papers!",r/machinelearning,Z0FBQUFBQm0yeGNhVlNJTWYzVnFyRFA3eVpFeXFacDFSaXc2YlpxTk5iNGFXeFg4c3RvLWp1cU9DZWFKSG5KNEFhcTZFZnJ6N3Y1eldyS2NKMExXQkZnd2RwZzMwTGE4alhwb2g3czhCQmtJQjR3NWg2UUo4ZGs9
"I don't think it's as easy as you think. The list of possible tasks is pretty diverse, you can't just brute force optimize your way through them. Internally, it would have to perform some kind of program synthesis, and then also run the program accurately. I don't think any current method plus bells and whistles will achieve that, even if you wastefully throw a few million dollars at it for training. Anyway - that's why I mentioned a hypothetical more complicated version of it.",r/machinelearning,Z0FBQUFBQm0yeGNhMmRtenRhLVhkQy1PQkRvM0VGR2pGNGdYamUtMGR6Zl84ZXROSGs0bWllRWJRenZNdEtuSjVUSzk5d0I5OVY4YVlTSkRtcFQwd0FYR1NNUTJzc3pENnc9PQ==
"To the contrary, the vast majority of coverage and analysis of AI focuses on current and near-term models, threats of bias and abuse  etc. Your complaint is made (repeatedly) whenever AGI/ASI is brought up at all, even when more near-term threats are also mentioned, as they are here.",r/machinelearning,Z0FBQUFBQm0yeGNhSVZwZGZGY2VuSUdBT0ZIV05qSlJScFlERG44SEp2WlZwc2p5MHJGdTBkV3lGWDNpbGU5cTNDejgxOVh1QncwMlg1S0kxUG5GTFdYallaRXFTSjJEMWc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNhMl9ZMjU5bnRPZ2thUWRjdmhOZTdvbm5zMk1veG5oV3REWlVjdHc5ZVFBajYzVmlqb1MtbTNFd3J1YUFNcl9HdzZKSTJKdzBQNWtTMnI2TzhLeDJ6Snc9PQ==
"I absolutely despise the fact that the top comment is so highly upvoted. I see this sentiment more and more these days, and it's incredibly frustrating.",r/machinelearning,Z0FBQUFBQm0yeGNhSUVXV2o3b0ptaTZLZzhYcDhNMURjaGZVMHRya29OVGtQelptNFJaU01TTElyT1gyOHdlVjVMa0xWdUlMdjVrOXRhMWlwWVJxYXg2Yk1ucGRleDhramc9PQ==
"Please correct me, but isn’t a temperature of 1+ spreading the distribution? Anyways, nucleus sampling and top-k are practically always used. Repetition seems to be largely solved by better models and training processes.",r/machinelearning,Z0FBQUFBQm0yeGNhMDRZZjYxRnBuNUQySTh1Ymt6Nk9TZ3E2M0JCc3l0SGlBdHZqRDJTOFpTTVpnNS1keldCMl9JRlcwVk16N2JRRkxJcHVaakhQVjMxQ2RmdzNCNHNUN0NQNDNXV0hkdnJGMGxRNWtYbWNFUU09
How would it handle something with 5 data points? Not well. Or highly intermittent and non-seasonal. Also not well. Prophet is a bad swiss army knife.,r/machinelearning,Z0FBQUFBQm0yeGNhQ1BPVGlzNXplLVBReHNFemY0OEE2UWpzV1d4X2o0aEw0U3RvUU53UkVWamNzdUlLZ0t1WjREaG8zWXJCemJIS1p0NEtUZFd6Rzcybm1wRUMwOWRUOEE9PQ==
"Easy. There's a lot of money on the table being offered to any cretin willing to say they're working on <insert trendy buzzword>.

Sam Altman has gone from being ""some random researcher"" to a billionaire. The motivation is not hard to grasp.",r/machinelearning,Z0FBQUFBQm0yeGNhZlpfbHdfVTVJQjlDbnRKa3RUZXZ5UzFTRlI4VmVxRWZmZjUwY3NnTXhZSDRHdElpcEZtRkhSSVpfdWRRTkliUWUteS1VSVFQOFdaMFRxYXRFeVBmb3c9PQ==
Vectara is really good for retrieval too,r/machinelearning,Z0FBQUFBQm0yeGNhOGNlU21tT0FMZExBMEl5VGtVWW1BVW1SRWhFQlZDalM2WHhKeXktblZRblZpa1E0eHJFRnJWemlDM2tyYVVZYXFqNXM0YW8tUkI2clJ0WDZMVWw5WUo0UFhqbExrcHotaU5qV1ZhTzUxRGc9
Europe is so heterogeneous that it becomes meaningless to generalize what is standard practice and what isn't,r/machinelearning,Z0FBQUFBQm0yeGNhU1c2MENLeTdnS3VmMUpIbWczWl9JYVlRT0NRd3Y0Yll3bmRrNkpZVWpMY3Z2OW9fdDg4Tk41WktZMmRJcGk0bGl0bU1ZV2U2eFJpdGlMZnVTR21CeWc9PQ==
"Yes, but I don't think nucleus sampling and top-k are the default anymore. For example, the default top-P for GPT models (via API or playground) is 1, meaning that all tokens are considered, which is something that nucleus and top-k sampling both try to avoid.",r/machinelearning,Z0FBQUFBQm0yeGNnWWhUQXJSOTljZ3VXQVRPMFhVRTQ0b2ZZa1ZuYXVXX1F2V0dTWmtIUWxxMG1rN0pJMG1kdU94YldkTTQzRkxxNU03QzBNcFBObGZVcjQ3ak9IdVVxakE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnTHNGbFFsMmJGaEdVVVJQVjN0WWcxX3QzRnlfVU1SWFgxZXZra25vUnhvSXpyMXBxRlhPSnFkaDhrNTFhMHRZeXNyaUNmeVZJWTRJZE9KWWhpQmQ3Y1E9PQ==
">For a production ready RAG application for enterprises, I suggest avoiding frameworks like langchain etc.

If it isn't too much trouble, could you tell what's wrong with langchain? And what would be a suitable alternative in production?",r/machinelearning,Z0FBQUFBQm0yeGNnUFlVVWlvenFVeTdkZ2VZUkNpWTlJaWZ3ZHNhTDV0UVROaUcxbGExenF3RFUtOHNrdU1NNzlTak1zU29MYXkxNVVfREM1OC00d3VVVXhkd1N1c0hfZ1E9PQ==
"Yep,  beyond that point it shouldn't be something you need to actively think about.",r/machinelearning,Z0FBQUFBQm0yeGNnRWxjaUxrcmcxSkw0LWZ4S1ZtZ1ZlT1lVeWV3RjVTOVdVbVpVSzE0dkl0SFF6ei1oeDQ3Z3ZLcWFhTXJNMHVNX0ZzOTRXSVZWZGtMTUp6dk5MUktCYnc9PQ==
"If I may ask, what are you trying to move toward?",r/machinelearning,Z0FBQUFBQm0yeGNnMEVpWjVZYU5DSVNiNWY1czRQdnJ3M0hKRmVCclhuUzJndWd1MkJ5eGlmREFXcmZJMnVvczZRcC1fRTZSRmFkTm1YNjNBaEl1TkxTcHBNVVZOQ0RFaEE9PQ==
Well this is a little depressing :(,r/machinelearning,Z0FBQUFBQm0yeGNnb3FVVGptRllCRlI4TkgwRS1sdDFEb2tDMEdSbTdzZXUyd1Q0MmlXVWFrWHBITlRGUVdWci0xbm10N1FKNVhMcXhieWVGOHVhX1JBTDZFZVROekFVa3c9PQ==
Yeah I think it actually makes sense from a business perspective.. but it’s a little sad from mine!,r/machinelearning,Z0FBQUFBQm0yeGNnSUNEOGVIdXdhWDNLV2VtU2VtM2hjUUhOZzJDUGo3TVE1SXhLd2ZmMlJkcm1QSVZjdGc3alVoa2ZDZFg5a2pNVmRSd0tCRmJKNFlrVEFSejBNdlBCT3c9PQ==
"There is a massive difference between the concrete goal oriented focus of reinforcement learning and the conceptual frameworks that AGI operates in. The reason that AI safety focuses on agent based concepts is mainly because no matter the underlying framework, any AI system that acts in the real world will necessarily be attempting to achieve some goal, else it would not be acting in the real world, it's not making a prediction that AGI will necessarily come about due to RL based agent frameworks. 

The current state of the art and the issues with them and their intelligence are a separate issue, much of the concerns about AGI and ASI specifically focus on AI systems that can do something. The fact is that if an AI system lacks the inherent ability to perform actions in reality, like current LLMs, it is infinitely less dangerous that a true AGI/ASI would be.",r/machinelearning,Z0FBQUFBQm0yeGNneFNHWVhjWElTVWVpei1HbVdDUTMxTnpzRzFieVlFZDE3eUpxWjJfYWtEMFJyaU9FMjE2cjlsZmhpRXFnZHBKX0VQNUNUbzFWMk15cHZsc0J4a0dnb2c9PQ==
"Which to use might also be a technical/speed consideration, as it does not seem to matter that much for quality anyways. Nucleus needs softmax->sort->cumsum over the tokens, which takes a measurable amount of extra time over greedy. Top-k needs sort->select_range->softmax and is a lot faster. Doing top-k before nucleus is a lot faster than just nucleus, or I dinged the implementation.",r/machinelearning,Z0FBQUFBQm0yeGNnWExIc1EwTGFKanRMczMtcjZpd0djZHpQczZLT0UzM3hhaFk3UnFsX1dYOFZ1V3FSbkQ0OEtRY1VxdnBoWDNKV3E5a1cwUUNTeUVVRXEydUVvSjM3UF9jYTJlQWYyMGVSeXYxdVo1Vk94VGs9
"> that it seems to me almost so ridiculous that someone that intelligent can't possibly think this is the best use of their time
> 
> 

The vast majority of AI safety researchers would tell you that an uncontrolled AGI/ASI would be at minimum unfathomably damaging to humanity, if not an actual apocalypse. There are far more concrete and immediate concerns, but they are essentially trivial issues compared to the potential impact of an ASI.",r/machinelearning,Z0FBQUFBQm0yeGNnaUYzbmNDNUQ4dmlLZDFnZXdVY1ZLOUVZUnBmb05uUUNyeC1BMmhzXzU3U0pDNW83WEt4V3VGa0M5dC1jZWZramd3VjU3d3ZTNDRkQktpcGdCQ0RTUEE9PQ==
Data / data platform engineering,r/machinelearning,Z0FBQUFBQm0yeGNnWTdVZndRQlRXV0V3R21KSUxlc1lKVENtajVTZjZsUWVYaHE0SlpqMWxfeFlpSTBYdkQ4ZGdjRkhpNHFSNzlHbzNsc19wWkhJTXN4Rmp4VUE4bDRTeEcwTktXTmlWbXk0WlBDeV96eWtGZ3c9
People will disagree but I think langchain just for the prompting and conversation management tools is fine. I would recommend writing your own retriever and indexer from scratch though unless you need to distribute the index across multiple machines.,r/machinelearning,Z0FBQUFBQm0yeGNndDFLTWZCSWxoclBFTGwtNkVock56d1dhMGZubnNDVU9QRTVNYU42WUxmTmh2b3J1UTk5NVVqbU9icUZVdmZrX21UajBhZDJkZ3VkdkFwa3ZuQndsaVE9PQ==
"Some of these may work in the short term, but I don't know of any advantageous technology that has been stopped from developing because of regulation. In the long term, refusing to take advantage of technology just means you're out competed and left behind. And there's no reason to believe we could feasibly stop a more intelligent being from achieving it's goals, so if ASI is possible, then it's inevitable no matter what we do. I see this more as the next stage of evolution, a natural consequence of physical laws, than something that humans can have an influence over.",r/machinelearning,Z0FBQUFBQm0yeGNnYmQweEJVcmpBVHFLRUEteGhJMGR1ekpLZmpOVUVROHdQOU1iR0twZVpzZ0ZZYWZETU1EVWg2YUdqS29sY0s1TjU2dk8tUTdfNVVhamJzNF9EdXpGYmc9PQ==
"The premise of the section in which this argument appears is that the agent is ""well-behaved"" but will end up violating the spirit of the law. My point is that a well-behaved agent would be equally capable of understanding and respecting the spirit of its instructions.

This is not the same as a situation where a lawyer understands the spirit of the law but seeks to violate it anyway. If you don't believe the agent will be well-behaved, the letter/spirit distinction is irrelevant.",r/machinelearning,Z0FBQUFBQm0yeGNnUHZVNFI2VzhYVVllY2wwbG53UGM3dXNtcFdRSnhhallfeEdIdVhOWEJ5QVdWLUZSc0p2Y2gxb0YyaGtQS1F1QTRxR3hPM2NENEZQV1FWWnNWLUZDOGc9PQ==
You need that iteration for Turing completeness. I.e. a pretty large set of often used calculations just isn't possible without iteration.,r/machinelearning,Z0FBQUFBQm0yeGNna2otcDV2a3c0LUVSaFlYLTJ2OWtGNXRTdWxHTXNybDhkRVQtcGhJamM5YkNhNjktYjcyRUdGN2hCblJpLU9INFNxdDRjcG05TXpyU2RZV2JGRjdlY3IzcWp2LTBYckRKa2F5TVlrSXFWd2c9
I’m not very familiar with such role.. is it about building tools/pipelines to handle (big) data?,r/machinelearning,Z0FBQUFBQm0yeGNnTVhma1lhbUlaSS05V01XdUlnb3BEZVFxOHBiRmhkRnQ3X01CXzFtWkM3Vm14cHN2RFRtdW8xYjVYQjJENlM1TkRwZjhmenl0TjVGbkdMSlN0OTZ6b3c9PQ==
"Check out the sample repo [https://github.com/rotemweiss57/gpt-newspaper](https://github.com/rotemweiss57/gpt-newspaper) which uses Langgraph from Langchain. It's close to what you're looking for.

>GPT Newspaper consists of six specialized sub-agents in LangChain's new [LangGraph Library](https://github.com/langchain-ai/langgraph):

>**Search Agent**: Scours the web for the latest and most relevant news.

>**Curator Agent**: Filters and selects news based on user-defined preferences and interests.

>**Writer Agent**: Crafts engaging and reader-friendly articles.

>**Critique Agent** Provide feedback to the writer until article is approved.

>**Designer Agent**: Layouts and designs the articles for an aesthetically pleasing reading experience.

>**Editor Agent**: Constructs the newspaper based on produced articles.

>**Publisher Agent** Publishes the newspaper to the frontend or desired service",r/machinelearning,Z0FBQUFBQm0yeGNnXzkzX0xmTDFqaEd1SUduU0hGZU5EUFMtOGNhREpOeHM4Y2RHZU1ZMl9yVUYydG5xZWhTdEhXQXFIT284WHUtdk9MMVRqSDA5aE5YVGJJUzFSQ2pscGc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnVENXWFhTbTdnNUI2eGx6TWh2QzAwVnBXLUpJbHE5dDhscWp6MW1KTVd6bS1tOXZoOU5KZFZIb0NQUVBJRDJhai1xYld2OF9pOVdid3NaUTNSOUc4bVE9PQ==
"Indeed that may be one outcome of some future innovations.

Let's take a look at the basic production inference loop of the LLMS. Today, this is written by humans and is fixed.

* predict p(t_i | t_i-1, t_i-2, t_i-3, .... ) 
* sample one token from that distribution
* emit it
* push it onto the FIFO buffer
* repeat

That's the conceptual 'life' or 'experience' of the decoder-only language model. 

Now suppose the various elements of that loop were generalized and the operations and transitions somehow learned---this requires some new ideas and technology.

Like for instance there are internal buffers/stacks/arrays that can be used, and the distribution of instructions to be executed themselves can be sampled/iterated from its own model which somehow there is also a learning rule for and somehow this can be made with end to end gradient feedback and bootstrapped from empirical data. 

OK, there's a long term research program. 

\\begin{fiction}

breakthrough paper:    <author>, <author>,<author>, <author> (random_in_interval(2028,2067)) **Learning the Inference Loop Is All You Need For General Intelligence**   (\\* ""we acknowledge the reddit post of u/DrXaos"") 

\\end{fiction} 

Maybe someone might discover This One Weird Trick that cracks that loop open.

Here's a very crude instantiation of the idea. 

there's an observed token buffer t_i and an unobserved token buffer y_i. 

* predict p(t_i | t_i-1, t_i-2, t_i-3, ....y_i-1, y_i-2, ... ) 
* sample one token from that distribution
* With probability emit_token(i | history) which is another model, emit it
* if emitted push it onto the FIFO buffer
* predict p2(y_i | t_i, t_i-1, .... y_i-1, y_i-2, ...)
* with probability push_token(i | history) which is yet another model, push y_i onto its internal buffer.  maybe implement a pop_token() operator too.
* repeat

for instance y_i could count from 1 to 100 and only at 100 the emit_token() triggers.  Now you have counting and a loop.  y_i might also be directly accessible registers (RNN type with an update rule) or some vector dictionary store. 

Who knows?  But maybe there's some technically suitable breakthrough architecture that's computationally efficient and can be trained stably and in massive parallel that is amenable technologically.

Does this look like biology? Not at all.",r/machinelearning,Z0FBQUFBQm0yeGNnV3JhMlVpZ2pkZ004UzJvd2xiamQ0T2JaRUNaYWNyZkROZG5DMjRHWkliYm9LZlNJaldoLWxjUG5waU5iVkdpc19QU2Z4QW1jcGxxTzM0REItTjdkclE9PQ==
The climate is an actual apocalypse. ASI is a sci fi concept.,r/machinelearning,Z0FBQUFBQm0yeGNnbzRoMVJNSE1kamNZTEpTcHZSTkJ6d0FrVjVxd1Q1eXlzcFpwTVNSVVFfMTNUVjNiRGtEVGljeTc1VE5TS2FVQjJFV3puaGt0LTNNNldpUmlMZ1B2dmc9PQ==
My starting point would be to ask LLM to translate between natural text and OpenCypher queries.,r/machinelearning,Z0FBQUFBQm0yeGNnR3ZIempUMS11cE4yRHl5UnNObkZPVkFyLW1TVjVnQ2cyT01JWUJPWHFjQnAwRllOcDhydEF1LUhISWRYNTBNY2xkbTMtMkZXMmNxaXEtc3MxRE01SzQ1VGdyZ1h2MEliM1V5OUdvNGFhNm89
Yeah that's more or less on the nose,r/machinelearning,Z0FBQUFBQm0yeGNnVjlsT2hqMHd5WU1CcDhWZDZnMzZzTmxVUUlPMk1JZTBvbU1vQzQycjJRZkN5WTN3UmhULXU5SXpIVUlGank3SXFLaFlFSkhSOVppWFNvaDhDbmFma3Z6QUFjX2JjZXRPLTVydnBpOENLUlU9
"AGI is inevitable, it's a matter of when not if, as intelligence based on electrical connections is demonstrably possible. And with AGI an ASI is as close to guaranteed as possible, there are many reasons to believe it is possible and few to say it isn't.

The timescales are fuzzy, maybe it'll be 10 years, maybe it'll be 40, but the singularity is approaching. And an ASI that is not safely designed can and will make climate change look like a minor blip, that's why people dedicate time and resources to it.",r/machinelearning,Z0FBQUFBQm0yeGNndlpsWnVmd1JiUEd2dE5Wa0lOUDZMU2t3OEdHZmdna1NzOWttXzl2Z0ducVpaOXVUTm5NTGhGVjNHZDdteWV3NUZCS3JTaW43X1hpNWcwbE4tMTFnZUE9PQ==
There are highs and lows. You can’t be writing high octane code forever or you never build anything people use. There’s always grunt work involved for any project of importance.,r/machinelearning,Z0FBQUFBQm0yeGNnR3lTMWxTdHZ0TGF1eFNYMk9wYmliVTZUdGQwb3p5MDg0eURieDVLOWxaQnZBdnR1UmhlMFJyQzlUcjJLeG9PUGF2S2VDS0tNeTU1MmY0d0huZWdxSHc9PQ==
Sounds like you need DML,r/machinelearning,Z0FBQUFBQm0yeGNnS1lvOWhfZnVMcm5DSFlYMnJsNVlQbGY4N0t1cHYyZ3hSOHdrQktHNEQ1WXRaX1lsdkVDeE84Mm9aMDA5bGYwTi1oVkJrdTNsREYzUS04RUFXWk1YZUE9PQ==
"Agreed. The success of the transformer requires us telling the system whether their answer is right or wrong. We are literally imposing our notion of right and wrong onto it, it’s baked into the system. An LLM is nothing without human involvement.",r/machinelearning,Z0FBQUFBQm0yeGNnRXdmUU5oekQ3ekw5ME45VktlbUszQ281ZnMyNENOOXM5Vld3STVYRjFOV0tObkU3cjlLeWhHWDVxalI2OTN0NlZqTXV5WWt0Vm9SWncxNElTR1JETHc9PQ==
"Am I the only one who finds it weird that LLMs have changed the landscape so much? I mean, to me all they seem to be are tasks that are good at performing text generation. Human beings are sensitive to visual stimuli, which is why I think that this whole thing has been blown out of proportion.

I don't think they're anything more than next token prediction models.",r/machinelearning,Z0FBQUFBQm0yeGNncnFoX0tpcHA0dVBHVjJKOUJBNHpHOW13R1hINTBfWDh4SG9vdlRJb1hEb0FLYUpoR3hyRE5iNEc4NEQ0cXBRTlhjUFQ3RHcta3F5dk10QTMwMXNhSUE9PQ==
Do you have/know of any implementations for the transformer sampling the code indexes?,r/machinelearning,Z0FBQUFBQm0yeGNnVTlpc3ZXWXAwR0hyU2hIMW9uWlRuWmFhTDZUMmRjN2lKOFlRQzJ2MVd0WHdvaGk2OG1xd3l1TDZudW1Xb0k1OWZEbVg4ZVdJTFd2MU5qTXcyMFBSbGc9PQ==
"These people don't see the obvious, we can't control AI, the same way we can't control the Internet",r/machinelearning,Z0FBQUFBQm0yeGNnWTFlam1tTWc5RVBtZEhIQ3lPS1lFS29Pb1VPalYxZU9TaDVzOEJVR3U3Z1F6OTRDY2pLS2dXekFqdXl2em5Cd3Uwb0xxaW90N3dWbUI0d3h2dVFDZUE9PQ==
"Connection oriented networks can form connections, but it takes a natural intelligence to find it interesting.",r/machinelearning,Z0FBQUFBQm0yeGNnUm1qa1RZbkhOdVFndlp4ekRQalBrV0xZWHpDeUc4TXlsMGxuRHhSUWZwcGVDd0x0VElWcWp1azlMYVRDOFFHaUpuYWdqbDNDZFZZRzdWMm1KSFZhb2c9PQ==
"About that 

https://amp.theguardian.com/technology/2014/feb/28/seven-people-keys-worldwide-internet-security-web",r/machinelearning,Z0FBQUFBQm0yeGNnVnZ3Z3pLeTJWbDRoaXRXdnFHNFRTYlg4dmlkV2dxVjRvWll0ZWdpd1RrRnZQMHNCbFgya1pNVDRLZ3ppcWtaS0t2cXM5WE1ud3ZwSms2U2xVaUZobGc9PQ==
That’s not in any way a solution and even if it happened you still wouldn’t have the hardware even to run inference in frontier models.,r/machinelearning,Z0FBQUFBQm0yeGNnVDdHYnRuUEVpaFMzc01rZ3hVYnl5R19ESl9BQnRYZV9fZTg4R3I2a0dzdGtseTlybHFFOXdhdGpWWGJmeHFuVXQ3cWR0T0FYcUxoV0d4ZFdNYkhjQWc9PQ==
Saying that LLMs understand and comprehend text is the equivalent of saying that a calculator understands math,r/machinelearning,Z0FBQUFBQm0yeGNnakRxaERxX1JGYmVjVVNWU1A5RTFoR3p3dV9RaHF3b2RjMTVfcE0yOUhuQzI5a3JhTGQ4QTVaR055eTk1Z2FYQnJzTFZGa1paSTFzY0FoMDgyS2x3Mnc9PQ==
why am I filtered...,r/machinelearning,Z0FBQUFBQm0yeGNnbEs2ZXpXZ0swUWdoa1dSanFnRFZ0N0VNcU1COHdGalFtVlF6T09yYnloRlZ3XzZvVUkxai1QdHZBMlBJRlU4eG9xQk5yUDZkLTFpTkhUQXQyVTRGZTFCSGhkRXYweTQ2X0lQVnZOVHlMaUE9
Please use the biweekly self promotion thread.,r/machinelearning,Z0FBQUFBQm0yeGNnNXdjWG5RMDlPZVJjcFUxZkh0OWk0Wm9kT0g4ai0xYk5FcmlUc1paazlvdGlUZ1d2aWswV1RqVmJSOVZQdUROS2Y4Tk9rRVo4QTJ3MURUOGlLQTFtbERvZmExc2s0blRaNXNVcFM4VFpPVmM9
Just ban mega corps’ safety lobbyists and we will be in a safer situation.,r/machinelearning,Z0FBQUFBQm0yeGNnTlJOUGduWm1PYkdobmVsV2s4VlJFd0ZpNUk2V0F4U0ZVUkFVNWZNeEhnQXRyTXJBQW5lRGJYQ1liWlFNZjY1SGVoUkM5UGowSDk5bmRDUm5PZ1NHeFE9PQ==
"This line is more from a software engineering perspective. Easy to use frameworks will make you overlook the actual source code for implementing the functionality. With a lot more abstraction brought in now, it makes it more difficult for you to troubleshoot, should you face any issue with that piece of code. Customisations beyond the parameters allowed will be difficult. Underlying code can be inefficient for the way you utilise the functions in your code. I believe that for a production ready code, you should have complete control over your code. Also, dependence on such library would make you look for all functionalities within the framework. Say you are using it for semantic search using a certain embedding model and a vector db. Then your would of course expect to use the same framework for incremental indexing or authentication in the vector db. And you would be disappointed to find that the implementation for the same is not as thorough though existing.

I have experienced the inefficiencies, difficulty in troubleshooting and customisation to my requirement level etc. I have found similar feedback for other such frameworks as well. Afterall, this field in itself is quite new and evolving fast.

Hence, use langchain or other such frameworks only when you can verify and be comfortable with the actual source code of the functions you'll use. You should be in control of the code in production. It being possible with a popular framework is one thing, but the lure of being lazy about it is also quite possible. That recurrent character text splitter might be a good enough chunking approach for POC. But eventually you will need to customize and have a proper chunking strategy based on your use case.

BTW, I do use langchain in production because I started the POC with it, but the functionalities I use are limited after reducing from POC level usage and after my thorough verification of the source code of the functions we use.",r/machinelearning,Z0FBQUFBQm0yeGNnTkVBWXJ2eTVwbGJNY0NVa0V4aGtiOXBLbGVhbnp5UG4xaWpHUWtWdFVJT1Ftb1ZFLVhLbFN0THVjM2pacFBySnQ3a0NQYzJEd1JfTWpYOW1SYTJ5T2c9PQ==
"Yea, from my experience, if you have a strong model and a clean data, you dont need worry about repetition a lot in many situation.

But for some situation such as math or code, they need low temp for correctness. In such situation, except decoding strategy, you may need some postprocess to detect repetion and break it.

For example, when we test the gpt4-turbo, we find it if it generate content in some repetition pattern it will break automatically.",r/machinelearning,Z0FBQUFBQm0yeGNnZlBGLXpzMG5NZkNVak9JNC1SWkRhWkxmbVVYYUVudmRXQzhTZF80bktnLUJ0alIzc3BSQ3RHaldwU3JJT3lIalgtOFpMZnBiY2diZ0R4OUhCQlNNcmc9PQ==
"No, none at all. Also, you see how that makes the situation worse rather than better, right? If there's a problem, having no answer isn't reassuring *at all*.",r/machinelearning,Z0FBQUFBQm0yeGNnbFNTTWRIRnlDTWh0RXp0empzTHlicFJXZEMxSDB5S1lTMERoWEoyMVNRR214SXd1b1pGemJZd0N1X01YREVLNFBOSUFwREdISGtJYWliaUIzd3o5Y1E9PQ==
https://arxiv.org/abs/2107.02367,r/machinelearning,Z0FBQUFBQm0yeGNndVM0bHE2eURVOTg3VkVNUmpEM0NDTmZ3OEkxN0F1dGxEUW1TVDM5QTRxV2liZjBCanlwTzFIbnhVUlBlZmpOMXViak9TM2E2dmhqYTk1Tm5zS2JYUEE9PQ==
Can you DM please ,r/machinelearning,Z0FBQUFBQm0yeGNnaHZ3NE1VZnRiU3FsX1hSSVZRSExfU09HeWRRTjFaaGZ5aW53QkFmVWxMY1VWSkUwekhLTGNIbGhXMlpMS0FXZ2pBdGNuVEtZcXRaQkF4SFpiNjhCeW9XUG93WERaSEt0WW9mSkRrbGRaNU09
"just a question.. how is the quality of the medium sized models? im assuming you're using whisper.cpp? do you think the quality is actually good.. i tried the regular whisper models of base and small and oh boy are they terrible.. making me puke fr.. 

i hope your implimentation works well tho.. i'd love to know your thoughts",r/machinelearning,Z0FBQUFBQm0yeGNnWDIySU14dTByRnliaGtuRHNsX1d5cEpfMnR6Q09PbnpHTUFYVDk0UkpVY201eEtsMTczY2huVzNiQ0hEX1YyV3Vqci1rOE9YZnVzVGJEWm5nYWhJS0E9PQ==
"Worthy of note is the AAAI 2024 paper: 

# Robustly Train Normalizing Flows via KL Divergence Regularization

This paper reveals that we can enhance the learning ability of Normalizing flows by utilizing the KL  divergence regularization. This is because the KL divergence regularization can increase the depth of normalizing flows.",r/machinelearning,Z0FBQUFBQm0yeGNnV3JkbnBKY0puV09ZR2tqWmQzbHRfcUYxUUhDdVN5UFN3VG96Wm9fbTVBaThHTEpkQllodDVwZ2Y2MWdJVmtsU0tqVy1HNzEySHN5b1d2STNiaUR0WkE9PQ==
"I was using transformers implementation of whisper but it has a lot buggy when it comes to short sentences..

Looking forward to use quantization and speculative decoding strategies.",r/machinelearning,Z0FBQUFBQm0yeGNnUTFBWTNaU19Pb0pOZzltVUpwMTFMazJ0YXNoc2U1MGtuVDJwLTZNYjROaDdTSjZUMzB0dVJEdF9sdWNSYVBHc01UTTY5eEVEN3Nwa0JGS3hvOFEtT1E9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnSmMzLXdPZm56TUhuc3R3NXA4SU9KNl9iOTZuX25OVWdBQ3FyckFxVDMtTTNVMXZac2hKcWFSaktRU2NVM3RmazNzSjBDU24yUFBFR1BjNk9yWEpROGc9PQ==
Vllm is talking about dropping beam search: https://github.com/vllm-project/vllm/issues/6226,r/machinelearning,Z0FBQUFBQm0yeGNnVU9EOUtOdGV2Nl9ZZjBQYUpwaGR4TVZLQzVEWGtsd0lGbnhGWDVWSWw0Z1dSMC0wRlBtd0o1S3BxV1M5S1hZRGtBZVFmWnh4SHZKVmJsdERZY1BOWnc9PQ==
"Even with all the recent advancements, I feel that machine learning (ML) still has some fascinating challenges to tackle. Here are a few interesting unsolved problems that researchers are actively working on:

1. **Explainability and Interpretability**: Right now, many models just give an answer, but without explaining how reliable it is. This can be risky in situations where trusting the wrong answer could have big consequences.
2. **Data Efficiency**: Models needing less data to perform well is a key goal. Techniques like few-shot learning are promising but not yet perfect.
3. **Robustness and Security**: ML models are vulnerable to adversarial attacks, where small tweaks in input can lead to drastic changes in output. Making models more robust is essential.
4. **Bias and Fairness**: Ensuring models are fair and unbiased is critical, especially since biases in training data can lead to unfair outcomes.
5. **Generalization**: Getting models to generalize well from training data to real-world scenarios remains tough.
6. **Ethics and Privacy**: Balancing powerful ML capabilities with privacy and ethical considerations is an ongoing concern.

Solving these challenges will advance the field and ensure responsible AI deployment.",r/machinelearning,Z0FBQUFBQm0yeGNnaEZFMGUzVkpWZU9nUWRyWlExRHBUc2g1OHpFWjB1ekRjOXBRMFhja0pZcnd4bjRFQ2VGVm4ydm1hNXBuZ2NOTElnSEpoRnUzMjlpMS1DR0pUck81anc3QXQ2VjRLSE14Q0FOaHptYU9QV2c9
"Their solution is to allocate more funding to them so they can raise concerns about how the problems they're paid to confabulate about need to be taken more seriously, which means they need more funding, so that they can raise concerns about...

Wait... Hm...

Oh, also, they need to be given unilateral policy control on a totalitarian level. It also needs to be international, and bypass sovereign authority. For reasons.",r/machinelearning,Z0FBQUFBQm0yeGNnZHNEZ3Y5UTM5TGQzM1pKOVZaQmx3ZTloUUlJNWZMZENlWEE4VFU2ZkhmUXpGZGVESVlvcURfcUJyLWd1QTBiVDZxNHlUdTJPYjZJODBCQUF6TlhCdG1EbW5yUU8tZG5HQW5seXhyUElRT0U9
"Well, I am not personally very worried. I am kind of with Aschenbrenner in thinking we will engineer our way to a robust safety solution over the next several years.

That said, *if* you accept Bengio's position, arguendo, then it really doesn't refute his position to say that he doesn't have a solution. And if you really take it seriously, like if you literally believe that AGI will result in doom by default, then all kinds of radical solutions become reasonable. Like shutting down <3nm foundries, or putting datacenters capable of >10^26 FLOPs per year under government monitoring, or something like that.

Like, take another severe civilizational threat. Take your pick... climate change for those vaguely on the left, birthrate decline for those vaguely on the right, or microplastics, or increasing pandemic severity, or the rise of fascism/communism, or choose another to your taste. If you think the threat is real, then surely it's worth highlighting these threats and increasing their salience *even if* there isn't one weird trick to solve it without negatively affecting anyone in any way. And Bengio thinks this threat is much worse than those others, and I think it's a reasonable and well founded belief system even if I happen to disagree with him.",r/machinelearning,Z0FBQUFBQm0yeGNnUVNtMG1RSF84M3Bsb0VvcmE3NFVqaGY4TWxZVkdaRjY2VzBKc2NSNlhVbGR4cEExOTlqQ1g5VXFJb0VyTVFzX1VZOHUyU1UtdVFEWkRHeU1JeWE1V3c9PQ==
Hola amigo. Cuanto dinero gastaste para llegar a ese resultado?,r/machinelearning,Z0FBQUFBQm0yeGNnWi0wRHVnalc2REJCSEJkZzZRNEFSUmE4Rk5LZUphZ3Bqd3dWal85cXM1MGVGR0JnR2IwbHRZazN2RFVkbC1SRk9QdHBtNWRxWEJKdGJHZDJteHZGZXc9PQ==
I'm using haystack with a runpod vllm serverless worker for the language model. Embedding is fast enough to do CPU on your side,r/machinelearning,Z0FBQUFBQm0yeGNnS0ZsYjJxLWpjVFNuQXhYcEE2RWVrMlUweWFhVDdUNV9tRUEzUG9tbUQtVm1RblNMVm5iM2d0cE5PenNyTU5nOVNiTDkyWmNnOWlkZzlOb2NCZWZXQlE9PQ==
">  gatekeeping AI to only megacorporations,

The opposite should be safer!!!

***ONLY*** allow corporations with an ***UNDER*** $50 million budget to work on AI.

Those are the ones of a size already proven to be safe (by virtue of the fact of being not much smarter than humans). 

Any company with more resources like that is an existential threat and should be broken up.",r/machinelearning,Z0FBQUFBQm0yeGNnTVItSjJyTFFoZ2dVSmdnZENfMlZMWDF6d1JYYl9Hbm1iNTdmUGE5b0g3czZqdkxweklkbnhEekxTb0V6ZFZoUExZR1hiQlQ2Ml90blV2VWJfNHhKOXFXTDJ1VHNvOUJHbHAzWUR5NllocEk9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnSWJ4TGUxN0hZMDYyS25CMG1wU2hwXzBzeV9UTlRCV3NqZkd4V3FjclNmdlhyN0UwQ1JGTTZoSUZVQ0w4ZjRpOUNyX2pxMzNVbEk2V2lhd25kVUtrY2c9PQ==
"I completely agree with using AutoML tools as a quick baseline. These tools have advanced significantly, making it easier for data scientists and analysts to automate the entire machine learning pipeline. The benefits are manifold: Time Efficiency, Accessibility, Consistency, Performance.

For example, tools like H2OAutoML and PyCaret offer robust frameworks that can handle various data types and complexities, often providing feature engineering suggestions and model explanations. This way, they not only serve as a baseline but can sometimes outperform custom models due to their extensive optimization.",r/machinelearning,Z0FBQUFBQm0yeGNnd1RhbE9qNnZZbmdEdFY3SHM4akhsZjZkTnhqWHJtSXdCNXAwdXByT2JtLUVGMkVUSU5OTHBQZHZKOG0yWkVDZXJETTJmeWxyVXZ1NVBxVTlYcmliZVFXQlZYR0VMYjRUN0FLMFF4cEtEXzA9
"[https://getdeploying.com/reference/cloud-gpu](https://getdeploying.com/reference/cloud-gpu)  
  
\\[  
Available At	GPU Model	Min. Price (per hour)	Price per day

Hetzner, Paperspace	Nvidia RTX4000	0.38	9.12001

DataCrunch	AMD 7900XTX	0.39	9.36

AWS	Nvidia T4G	0.42	10.08

Paperspace	Nvidia M4000	0.45	10.8

DataCrunch, Lambda Labs, Linode	Nvidia RTX6000	0.5	12.0

Paperspace	Nvidia P4000	0.51	12.24

Replicate, Azure	Nvidia T4	0.53	12.72

AWS, Azure, OVH, DataCrunch, Paperspace, Lambda Labs	Nvidia V100	0.62	14.8799

Scaleway, OVH, GCP	Nvidia L4	0.71	17.04

AWS, Lambda Labs	Nvidia A10G	0.75	18.0

AWS, Azure	Nvidia M60	0.75	18.0

\\]",r/machinelearning,Z0FBQUFBQm0yeGNnOGYwY3dXSEtXcHJ0ck9aVFRFNlFKajhuNmxXbEV0Y0d0YU9lV3k3emRGSkFmS3hHOUl0R2NNRUJkSVR6X3I3Ykk2OUxjWWZMbXF4aFU3QWdYalV6VFE9PQ==
"\\[  
Paperspace	Nvidia A4000	0.76	18.24002

Paperspace	Nvidia P5000	0.78	18.72

DataCrunch, Paperspace, Lambda Labs	Nvidia A6000	0.8	19.20

Paperspace	Nvidia RTX5000	0.82	19.68

OVH	Nvidia V100S	0.88	21.12

AWS, Azure	Nvidia K80	0.9	21.6

Scaleway	Nvidia RTX3070	1.07	25.68

Paperspace	Nvidia P6000	1.1	26.40002

Fly.io, AWS, Azure, GCP, OVH, Civo, Replicate, DataCrunch, Paperspace, Lambda Labs	Nvidia A100	1.29	30.96

Azure, Scaleway	Nvidia P100	1.35	32.40006

Scaleway, Fly.io, OVH, Civo, DataCrunch	Nvidia L40S	1.36	32.64

Paperspace	Nvidia A5000	1.38	33.12

Fly.io	Nvidia A10	1.5	36.0

Replicate	Nvidia A40	2.07	49.7

Azure	Nvidia P40	2.07	49.7

Scaleway, AWS, OVH, Civo, DataCrunch, Paperspace, Lambda Labs	Nvidia H100	2.49	59.76

TensorWave	AMD MI300X		

Civo	Nvidia GH100		

Lambda Cloud	A100 (80GB)	1.5	36.0

TensorDock	A100 (80GB)	2.25	54.0

Scaleway	A100 (80GB)		

Massed Compute	A100 (80GB)	1.89	45.36

OVHCloud	A100 (80GB)	3.07	73.68

DataCrunch.io	A100 (80GB)	1.75	42.0

Cudo Compute	A100 (80GB)	1.69	40.56

Oblivus Cloud	A100 (80GB)	2.5	60.0

CoreWeave	A100 (80GB)	2.21	53.04

\\]",r/machinelearning,Z0FBQUFBQm0yeGNnQ1d0ZUVTdVFIdWNEVVFIQzBDQm9mTXJ6aE9CVWdMTHZnRlJqTlQtUGhLYVg4Nm55SXhwSTBHWTJaLV92d09ncXR0c09yYVlqaC1jeTJpWk5yOWNwOEE9PQ==
"\\[  
Cirrascale	A100 (80GB)	3.25	78.0

Hyperstack	A100 (80GB)	2.75	66.0

[Latitude.sh](http://Latitude.sh)	A100 (80GB)	2.9	69.6

Shakti Cloud	A100 (80GB)		

Oracle Cloud	A100 (80GB)	4.0	96.0

[Vast.ai](http://Vast.ai)	A100 (80GB)	1.35	32.4

TensorDock	H100 SXM5 80GB	2.43	58.32

TensorDock	A100 SXM4 80GB	1.84	44.16

TensorDock	A100 PCIE 80GB ​​		  
\\]",r/machinelearning,Z0FBQUFBQm0yeGNnVUFIZVNKdndpVHliUmVRYmxtcURRWUNZLUJnQk96S21yeThUc0RhTnFkcDBlRTVxUDZUcmEzVXVKQ2M2RnY2ajBBV1EyblU4bnlqR00tRFByRmVVZ3c9PQ==
"Honestly, haven't dabbled much in open source for this exact thing but you might wanna check out Atlas.org. It's a pretty neat AI for students and stuff, super accurate with all the textbooks and lectures. Might be a bit of a hack, but its been a lifesaver for me.",r/machinelearning,Z0FBQUFBQm0yeGNnZkkxUTBQVGFtSlJiNHgzUGpoLUJnZFg5TVZCTVpheXhNOUdJb20wdlZONlp5akgtRlZRZFlnM1lFMk5RYm5vb2plamIxdlFTWEUyNUhfNnE4WmozUFE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnbEdzSzBjdkRKc1NBVzlaMGtOa3hGelRmYTdLYzVoUW9WVGtYaHBHWTdCTThMOFc1dkVTbzhhNGlVbmZNM0c4ajVXczVkWjBmd05pQ05YYlUzdHJxeWc9PQ==
How about MuRIL ? [https://huggingface.co/google/muril-base-cased](https://huggingface.co/google/muril-base-cased),r/machinelearning,Z0FBQUFBQm0yeGNnNHNHUk92WjJNWjFCeGE2RGJVdFFmVnNBYS1MN1gtVWVUM21KTFdJRnFjMXd0T2VpNklFbW1rSVZNVmJ1WGljUlAtSG1KUS1fWDIwMU1ya3M3MktPLVE9PQ==
what does degrees of freedom mean？,r/machinelearning,Z0FBQUFBQm0yeGNnRDd3S3U1LTlKMFJPaG94NGhrVUcxVzNLN29WYUI2bVI4Rno2WHU4UHdfb2gxeG5XZmlEdWN6Uk53SURGZHJSUno4d2dySG5kODFQWUtoM2lxanBINUE9PQ==
"I need to sit down with Bengio and have a quiet talk about where we actually are. (What is most ironic is that he himself agrees with me on nearly all these points.) 

+ Stakeholders are being promised that reasoning has ""emerged"" from LLMs.  The presence of this *emergent reasoning ability* has not been demonstrated in any thorough test.  

+ Stakeholders are being promised that AI models can reason beyond and outside the distribution of their training data. This has not been exhibited by a single existing model.

+ Stakeholders are being promised that AI can engage in life-long learning.  No system of any kind does this.  

+  AGI requires that a piece of technology can quantify its uncertainty, imagine a way to reduce that uncertainty, and then take action to reduce it.  In more robust forms of **causal discovery** , an agent will form a hypothesis, and then formulate a method to test that hypothesis in an environment.  We don't have this tech , nor anything like it today. 

And then to top it all off, we are skating on a claim -- little more than science fiction -- that all the above properties will spontaneously emerge once the parameter count is increased.  

I guess what bothers me most about this , is that it was Bengio himself who told me these things cannot be resolved with increasing parameter count.     Now I found myself today wandering /r/MachineLearning   only to see him saying that if we don't move quick  on safety we're all going to be sorry.",r/machinelearning,Z0FBQUFBQm0yeGNnYmtlRkNSWUVoWHhJeXVVQ2VxWDlMakVCTWYwSDVxOXJuVUFIaENidDJ5c0hBSHNrWThScHZJaU9nV2dlSW9CWGZLcWhCRjM3OFBMZ3ctMWh0UUlZMUE9PQ==
"Thx! Appreciate it, really helpful",r/machinelearning,Z0FBQUFBQm0yeGNnQlZVNWtBVm50amZIV3hCSXp5MmVxdzFnT2VoaXJSanFMM0ZBOVQ2STBFcUQ1a0FEYXZ2Zmc2eGVvZVRCVXlGZmxWSkR3bmhMRGo3SVJEMnl2M3Y2T1E9PQ==
I totally agree. Butt what OP brought us is an open letter from a major AI researcher essentially only considering the one much less present concern.,r/machinelearning,Z0FBQUFBQm0yeGNneGNvU3didjdIWHZMYjdWUlY5a3ZmNFNwNk5GZHd3cTdaUEJpSWxFQVljWExCSzQ5WU1CUEhJdFJNWUJfSFA0djJxT29YQklDWXd0ZjBacUxQZjB2cWc9PQ==
"i posted this right after going through this repo, its based on gpt-4o, i m looking for an open source model that probably can do the same thing as gpt-4o would. to be more specific, any open source LLM finedtune for these tasks.",r/machinelearning,Z0FBQUFBQm0yeGNnRDVYdm5vd1MtSkJnRVpBX0NTMm51cHE5WTgtVFJHbjUtR21xTnV6SU81Rl9DNkhyRlBBS1B1VzJoQkk4TV9pbXhsWGUwZ3I3TkZSdkhLZC1VRUNEbkE9PQ==
Yeah tried that. It cannot even find the tags just returns the whole sentence for ner,r/machinelearning,Z0FBQUFBQm0yeGNnc3o0d29HZllEYlNtazFBSVpmVGhYMmYxallzWEtnbGhyOWFuZjB4dUd2X3V1ZllzMmZDdzZCMkxINXA3Rm5ybEdfU040U1d5YTVGOENSWWRqUEFkelZhQzJ1UlJjOUJlYUFvcDl4a1B3YkE9
"> some people are focused on the very immediate effects of poverty, and others are focused on long-term risk of nuclear annihilation.

These people need to work harder.  There's poverty everywhere and the odds of a nuclear war are just as high as ever.",r/machinelearning,Z0FBQUFBQm0yeGNnZFI1Z1lmUFFqX0VHNnRjUUVMb0t5dWtlUGFKdzIydmg4THV6aV8zUzYwZ0xtOURmc2R2M1czRWFma1BZMGV2cTlsdnBzbDBQcEx2MzBfREcxdjAydGc9PQ==
"We won't, we'll just keep moving the goal posts.  ""Oh sure, this model can write best selling books and direct movies, but has it made any breakthroughs in physics?  Not AGI"".",r/machinelearning,Z0FBQUFBQm0yeGNncDNBODdhb1JQQmMzT3FFSmxPc2k5eFRGWVZXWnJWZjFNVjVwMl9LRnBndW04QXZsRnhwVGM4dlVOVmtCSkRkM2F4LU1qTWRNWlpBZ0RZdTI1YWt4Z0E9PQ==
"oh wow, interesting! thanks for sharing",r/machinelearning,Z0FBQUFBQm0yeGNnVWFidUVLSkNaM3k3MGMxaVBXVHpiVE41RWpDdnlKeVNjT0lkb3BBY3NLRjYxR0RYY2ltWklQaGpKTDVxTmV5N3Blakw2ZGpqX1FJSnYwUlVlWWVURFE9PQ==
"Also wondering, I saw that ~10% of accepted papers will have an oral presentation but I’m not sure. I don’t know if I’m eligible based on overall score tho",r/machinelearning,Z0FBQUFBQm0yeGNnWjhzVnFjVGMxbGZpOWJkeEFoWXhHZ3lhSUk5ZmZDODZnMUtYRE5jY3lHUTNnanUzd0xCOUNIVWZtMkVIV3E0SDBPNlQySnFKci1TZnoyaXZQaC1Eamc9PQ==
We've already got self driving cars.  Waymo taxis are driving around San Francisco and Phoenix right now.,r/machinelearning,Z0FBQUFBQm0yeGNnMHdvdnIydjR3c21reDFyUmMteEhPY1JBNEs1Vzk0dURRTlg2b1FBek1fRnRHYndWRVlCY2hoSWgwVTNSaDBQNU9vbkRMQkxWMk9DLXdpZXFpQ3lZWUE9PQ==
"TLDR

> Here's what we've decided to do:

> 1. We'll add a deprecation warning for beam search ([Misc] Add deprecation warning for beam search #6402) and plan to release a new version next week.
> 2. After the release, we'll gather user feedback and usage data (Report usage for beam search #6404) for 2-3 weeks.
> 3. In the meantime, we'll work on a separate branch to remove beam search and implement code simplification and optimizations.
> 4. For the v0.6.0 release, unless we receive strong pushback, we'll merge the changes from the branch developed in step 3.",r/machinelearning,Z0FBQUFBQm0yeGNnQzlJQ3l6NjdhM2Nuai1yeVB0Ym1YRjJBazF4b0JlUXRlcHFMaUFCcmVkSTZaM2Nkb1dnR2V3cVdYR204REM5djc5T2F4RDJmQTJsanYyUDFmN0hiOUE9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnOUpSaVE4X2ZVQkIxOF9TdEd3RmpXRXJvcXFqSWl3MnVldjBmaldSeVJLVWRWM3RCbFN6NXV1Uk5Ub0hRa2M3cG9LNHgya2VmWDlPd0E0Rmpfcm1Sb1E9PQ==
[Here](https://arxiv.org/abs/2311.02462) is a paper from DeepMind trying to more formally define AGI,r/machinelearning,Z0FBQUFBQm0yeGNnTWZNbFd3RVp2LW5tREUyZnlhbVF1bzZfRGR4WnBTMDB5UXNSckQ4cFRGTHZUY1FBR0FDYzU0T3JnMmgtcWNrT05wMDR3ODgzN3dmMGs4b2RfeGl5X2c9PQ==
"I worked on AI safety from 2000-2010, I came to conclusion it was pointless. Now it's more important to actually work on AI and deal with the real economic and social consequences.


AI gone crazy being protected against by well meaning safety experts demonstrates a fundamental misunderstanding of how complex systems work.",r/machinelearning,Z0FBQUFBQm0yeGNnOEhzZUhPRnRCeGx2U2VhTnpsTElVR3gwa2tmQVlkZUNYYlk4Ui13RDZCZnRkQmM1dG83QncwNDhwbHF6bi1TTFBUQ2NJTjNackpZVWkxX1dvV1hHYjFQZXZBQlN6VzJ6MWo0bGxvRmRoUlE9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnNmk0RWc3UEFJR0UyQTBZdjBBRWxKMTRrUk5fM3FNcEVlV0JrVG5BSmNnZGdBVm9ELUIyOUdDbXJ5ejNJb2RGUl92WUdQcUNleV9NRzNlTjN3ODJnSVE9PQ==
ChatGPT is already agent-based and goal-based. The reinforcement learning from human feedback step means that it tries to optimize towards a goal (of human reviewer satisfaction).,r/machinelearning,Z0FBQUFBQm0yeGNnZGhTRVB1QlRFdXV3YWdCQlRmeHNoZFJsS2pNQnFDZE1RbjdydVlqX1lhNjNKOFZDLTZHdmVqdWdRU3VxR3VPNllnMG85a3k2czNnZ2VlQm9hR1ZiRlgzSTlxeWFKTlJBOUZJc1d5c01nZms9
，,r/machinelearning,Z0FBQUFBQm0yeGNnTERJNWQ1NHgwWlBOel9PQUNYVWJET2pGcXJtdURWcXJxaVlEN3l0czBuOHBOWExPUVdJM0pBNjNPVmw3dlY3ZjRfTS1TLU9oNGhkRjV6UU5mOFExTkJKX2RKaTFPLW9nT1J5YWF4dUJZeHM9
Here I mean dimensionality of the search space,r/machinelearning,Z0FBQUFBQm0yeGNnZmJ6M2lud2x4cFZOUEVKUVIxZFpfc1U4ajgwMjV0djNINkdFYzFDODNLSzVQSFdTOEdmN3lhV1NuX2JkbkEyZERWVnJXcThWeEwtRG14YTdQaXVSTkE9PQ==
"I don't think gpt-4 was fine tuned for this. Just throw this technique at mixtral or whatever the largest, most capable model you can run is",r/machinelearning,Z0FBQUFBQm0yeGNnUXRZb3J3VWpuNEZ3RTJ1Q1RqejExTUdqM0U0dmNrQ2d3OXdJMDhKZlk3dG9wb3lESENwd05qZnZ4eU1OSTVXdDF5bVA2UWJkZlBLbmU4X1R4UUlTalE9PQ==
"Thanks. Tried using this dataset to fine tune Bert model and f1 score is 0 😂
Figuring what can go right now",r/machinelearning,Z0FBQUFBQm0yeGNneHhveWhkakw5RmF4T0xsOHltVW4tMXpyRFA0dFd5WUFIa0JmdTNpb3FsVEh3cmdTc0Y5Qm1lMEowTlNXY0hBaWNiUHBUbUVyOTI4TVNBY1V3c0Fxc3JSOGF2SkhIaHB6aWptLUZ4MXlWTk09
"What are the differences between Triton and Cutlass?   
When would you recommend using each one?   
Are both equally performant and easy to use?   
If my goal is to take an off-the-shelf kernel and add an epilogue while changing the data type, which one would you recommend?",r/machinelearning,Z0FBQUFBQm0yeGNnU3otSThKMDVRSkhOTGg4dHUyNUp4MnJ3N1Zzenp3R2FjOTZrdlpxaGhJVHJGQzhmeUx1NVhnTzlwTm56RVpWQ2NUS1FYb3ltRjlKVmticG5Td3RlNDZhcWY0RW96bHNYTWhXaGNqUl83T2c9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnbUxpLUp5QW9YM0hOMENVbktkX3UydlNaYl9lNnE0b3dHbXRxR1l0QjRHaTAxZWxyOGQwUVQ1dTJRNHQ4X05VeHU2WDhkSDZ6TXdSV0c3YXI0a043d2c9PQ==
"What are the differences between Triton and Cutlass? 

When would you recommend using each one? 

Are both equally performant and easy to use? 

If my goal is to take an off-the-shelf kernel and add an epilogue while changing the data type, which one would you recommend?",r/machinelearning,Z0FBQUFBQm0yeGNnUWFSaVVSdFdWNGRNYnFDbDExajBkdTk2U19ETkcxTnpaeHgzYnFnSnhraWdFQWhPWTBTdGZOWnB6VHpJaTNOZ1dsLWlBMDNOQlZCNVFQNm9qS3BJblowTXhaSHJRNVFSSV83WDRCbHBjRWM9
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnSmpubDg3Ty00bDlZaHN6SGNTWjBnN2NXSVQxOF9TUlFnbmR4QnJjTFhxeUpOZ0JzWEM5TnRNVWVYM0Q3Tm5iVEo3azNYYzk0bk5MNHI3LTAwaXRsSmc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnV2lzQTJnaVc3MDRLN2xiZ1pZb21oTm5RWmpXNUZIZ0Fhd0RqakhULURoLWYwUmR1ekM2V3hrdlU1Ui1qSFk5WXdfRUlRV1pwbGVsZDJ5a0ZOZ2hNd3c9PQ==
I don’t think it’s particularly productive to strawman like this,r/machinelearning,Z0FBQUFBQm0yeGNnalZZcm9BS2pEdExPQjREWlpST25kUC1FS0Rlend2Z2NKY2tucmdFaGJrZ3ZiQlB6V1dlZHBWaG43RTJ2MTVKaFpqZXhCQmcwV3JwYm0tMERzVXJhS0E9PQ==
"If your output is structured (YAML, JSON, code...), filtering the tokens and then do beam search/greedy decoding is actually quite useful.

When there is an objectively correct answer, it doesn't make sense to do random sampling.",r/machinelearning,Z0FBQUFBQm0yeGNnZnozVmFGaXBxTXZqQWZFVFpfcWdLME0zb2hJQjFTUVhaZHY0VEh3dXdGQnkxd0VoN0tpVjNHX0JXS3FuSUxqRl9OTWlCNWJqYVgxMGVTamJIX29MZnc9PQ==
"Your post was automatically removed for not having a tag in the title (i.e. [R], [N], [P], or [D]). Please read [rule 3](https://www.reddit.com/r/MachineLearning/about/rules/). **The moderators will not respond to questions regarding this removal unless you suggest which rule you most likely broke.** If you have a beginner related question, visit  /r/MLQuestions or /r/LearnMachineLearning.

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/MachineLearning) if you have any questions or concerns.*",r/machinelearning,Z0FBQUFBQm0yeGNnRGZ6Ql9raE9mTGthREo4M0dITTFpMHRncUFUQ2JjT053M1ZmTHFyRk1LOXNaSVJKSldiV1JQX21pN21jVEdJMGttTkdRTHoyd1lWa0E3ZUhVX1dpWWc9PQ==
Geoffrey Hinton and Paul Christiano share the views of Yoshua Bengio. It would be very arrogant to dismiss their opinions out of hand.,r/machinelearning,Z0FBQUFBQm0yeGNncjJxTFNBQkpvclQ2UTJ4QzN4bU5LcmRZSXh6QW1TUTdWX0pOZjVFb0tia00wTGFrTXphb3I0dFFyX2F6QWtaUGRLMkdPR0QyNEtUSDlJN21kVzlqUndFZmFVWmR2LURnMmdmYjVKaFp6SXM9
"I got accepted! (Albeit to a workshop, I didn't know about ICML main until past the deadline). I'm happy. One reviewer had mild reject, others accept.   
7/8/4

[https://openreview.net/forum?id=gGnJBLssbb](https://openreview.net/forum?id=gGnJBLssbb)

""Protein language models expose viral mimicry and immune escape""

  
See y'all at ICML and the ML4LMS workshop!",r/machinelearning,Z0FBQUFBQm0yeGNnZXJHZnBLSm10TzRZc25ZN0RGU3FGMUpWd3dxd2FmcXlvV3lBckFNQmRSWWd1OWZyYlhkd3c5aUgxR3o0bW9ZUTcwM1RFYXBBYWoxUFVOOHcyRVlOOVE9PQ==
"These ternary quantized models are for text prediction though, not for training.

Maybe you can do some kind of QLoRA type thing in multiple stages with a new QLoRA for every 1000 batches or something, but it'd still be expensive and there's no established publicly known process for training from scratch using a small number of GPUs and there might well not be any such process which is likely to practical.",r/machinelearning,Z0FBQUFBQm0yeGNnTkxwVVZUdjRqNVZkNkowSnJLNEhBb3ZaQ0tyY1N5Rlo1RzdCVGZkT0dPemZ2ekp0NkNaRkV6aVlhLUZYZGp6a3BSQ3dvQTJmUGFpdExSc3FZeVlwV2c9PQ==
